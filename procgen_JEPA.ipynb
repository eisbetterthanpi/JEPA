{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "567781f2-98d5-4638-c18a-2721139d7a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq procgen faiss-cpu vector-quantize-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "nEY9MmwZhA8a"
      },
      "outputs": [],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# conv = Conv().to(device)\n",
        "# # print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# # input = torch.rand((4,1,256,256), device=device)\n",
        "# out = conv(input)\n",
        "# print(out.shape)\n",
        "\n",
        "# conv = Deconv(256).to(device)\n",
        "# # print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# input = torch.rand((4,256), device=device)\n",
        "# out = conv(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "56ae113f-dc4e-4a5d-b5f4-b24f8b922a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "\n",
        "ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "FuA25qQknUAX"
      },
      "outputs": [],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model)\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            )\n",
        "        # self.pred = gru(emb_dim, rnn_units, num_layers)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=1e5): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        num_steps = 5 # 10\n",
        "        for i in range(num_steps):\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sy_ = self.pred(sxaz)\n",
        "                # print(\"y_, y\",y_.shape, y.shape)\n",
        "                loss = lossfn(sy_, sy)\n",
        "                # loss.backward()\n",
        "                # optim.step()\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "            with torch.no_grad(): z = torch.clamp(z, min=-1, max=1)\n",
        "            # print(\"argm in\",loss.item())\n",
        "        # print(z.squeeze())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29O1eyvhnRSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5dad8e3-08a6-4a90-b8eb-8ca1a54a7913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title agent pixel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    # 0.08171599994438941 0.03272812710184608 1.0\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=20) # 20\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        # x = nn.Parameter(torch.zeros((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "        x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(3): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "                sx_ = sx_.detach()\n",
        "                # print(loss.item(), lact)\n",
        "        # print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = -self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=32):\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(sxaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    # repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy_))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "\n",
        "                    # # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    # # ae loss\n",
        "                    # state_ = self.deconv(sy)\n",
        "                    state_ = self.deconv(sy.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "                    # # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # # loss = jloss + conv_loss\n",
        "\n",
        "\n",
        "                    try:\n",
        "                        st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    # with torch.cuda.amp.autocast():\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    closs = F.mse_loss(stt, r)\n",
        "\n",
        "                    loss = loss + jloss + conv_loss + closs\n",
        "\n",
        "\n",
        "                if i+1 in lst:\n",
        "\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # loss = loss + closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    # c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                # else:\n",
        "                #     scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "# agent = Agent().to(device)\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = Agent(d_model=1024,dim_v=4096).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "!gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_b7ZSW6IF1-",
        "outputId": "747a1939-87c2-405e-b4ee-17ce53aca9ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_\n",
            "From (redirected): https://drive.google.com/uc?id=12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_&confirm=t&uuid=3a12a185-446a-4a43-9648-672b9b64e099\n",
            "To: /content/agentoptim.pkl\n",
            "100% 44.2M/44.2M [00:01<00:00, 26.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ShHQ_ynlwoyJ"
      },
      "outputs": [],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "def save(folder, name='agent.pth'):\n",
        "    torch.save(agent.state_dict(), folder+name)\n",
        "    # agent.mem.save(file=folder+name)\n",
        "    with open(folder+'buffer.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "def load(folder, name='agent.pth'):\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=torch.device(device)), strict=False)\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=device), strict=False)\n",
        "    # torch.load(folder+name, map_location=torch.device('cpu'))\n",
        "    # agent.mem.load(file=folder+name)\n",
        "    with open(folder+'buffer512.pkl', 'rb') as f: return pickle.load(f)\n",
        "\n",
        "# save(folder)\n",
        "# save(folder, name='agent_jepa753333256.pth')\n",
        "# buffer = load(folder)\n",
        "# save('/content/')\n",
        "# buffer = load('/content/')\n",
        "\n",
        "# name='agent.pth'\n",
        "# print(folder+name)\n",
        "# torch.load(folder+name, map_location='o')\n",
        "# with open(folder+'buffer512down.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "with open(folder+'buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl').values()\n",
        "# # modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "# agent.load_state_dict(modelsd)\n",
        "# optim.load_state_dict(optimsd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "torch.save(checkpoint, folder+'agentoptim.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "cellView": "form",
        "id": "NVcknabHMxH6"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = self.data_process(buffer)\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    # def data_process(self, data): # str 10780437\n",
        "    #     return torch.tensor([self.stoi.get(c) for c in data]) # list of int 4570571 # stoi.get(c,UNK_IDX)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "        # return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        return state, action, reward\n",
        "        # state, action, reward = self.data[idx]\n",
        "        # # print(\"__getitem__\",state)\n",
        "        # state = self.transform(state)\n",
        "        # # print(\"__getitem__\",type(state))\n",
        "        # return state\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 64 #512\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e3fpbtNOiz1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "train_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "train_data = Datasetme(train_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    train_data=list(zip(state,reward))\n",
        "    train_data = Datasetme(train_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "trainiter = iter(c_loader)\n",
        "images, labels = next(trainiter)\n",
        "imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# print(labels)\n",
        "for x in range((len(labels)//10)+1):\n",
        "    print(labels[10*x:10*x+10])\n",
        "\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "        pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "        # print(pred)\n",
        "        for x in range((len(pred)//10)+1):\n",
        "            print(pred[10*x:10*x+10])\n",
        "        # print((labels==pred).sum())\n",
        "except: pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OksdjCeJYpYh",
        "outputId": "c7d5d7a8-cfc9-45c2-96bd-cc942ef25927",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "repr, std, cov, conv, closs 0.0007101340452209115 0.474365234375 0.00026224879547953606 0.06333639472723007 0.015330460853874683\n",
            "4.7325557965662535 0.03878951277634176 1.0\n",
            "repr, std, cov, conv, closs 0.0004999304655939341 0.474609375 0.0002611961681395769 0.0637114942073822 0.00023694982519373298\n",
            "4.7325557965662535 0.038557588112117035 1.0\n",
            "repr, std, cov, conv, closs 0.001360379159450531 0.475830078125 0.00019841198809444904 0.06519012153148651 0.00023849649005569518\n",
            "4.737288352362819 0.03817412444316437 1.0\n",
            "repr, std, cov, conv, closs 0.001511698472313583 0.474365234375 0.00022651813924312592 0.05882084369659424 4.69940505354316e-06\n",
            "4.737288352362819 0.037983825099388246 1.0\n",
            "repr, std, cov, conv, closs 0.001005765749141574 0.474609375 0.00020527164451777935 0.06145159527659416 0.03622107580304146\n",
            "4.775319568875606 0.03802180892448763 1.0\n",
            "repr, std, cov, conv, closs 0.0010054695885628462 0.474853515625 0.00018502608872950077 0.06735033541917801 7.490577991120517e-05\n",
            "4.765783236619132 0.03771899868811312 1.0\n",
            "repr, std, cov, conv, closs 0.00035951382596977055 0.4755859375 0.00018481560982763767 0.06345130503177643 0.030081648379564285\n",
            "4.746767666355896 0.03756849913028565 1.0\n",
            "repr, std, cov, conv, closs 0.0006332064513117075 0.47509765625 0.000227377749979496 0.06571848690509796 0.0003633096057455987\n",
            "4.751514434022251 0.03745601866876733 1.0\n",
            "repr, std, cov, conv, closs 0.00031698125530965626 0.476318359375 0.0001706262119114399 0.06717953085899353 0.0001792548573575914\n",
            "4.770549019855751 0.03745601866876733 1.0\n",
            "repr, std, cov, conv, closs 0.0002476742956787348 0.474365234375 0.00025652279146015644 0.0638565719127655 0.03128327056765556\n",
            "4.784874983332925 0.03738121884984879 1.0\n",
            "repr, std, cov, conv, closs 0.0016190834576264024 0.47314453125 0.0003133295103907585 0.06785564869642258 6.339556421153247e-05\n",
            "4.8184697582290985 0.03700945443117186 1.0\n",
            "repr, std, cov, conv, closs 0.0006282706744968891 0.4755859375 0.00022281520068645477 0.0744631439447403 3.749581810552627e-05\n",
            "4.8184697582290985 0.036751421413838505 1.0\n",
            "repr, std, cov, conv, closs 0.0005169475916773081 0.472412109375 0.00032604439184069633 0.05783987045288086 0.00029372406424954534\n",
            "4.756265948456273 0.03563015723180009 1.0\n",
            "repr, std, cov, conv, closs 0.0020070201717317104 0.4736328125 0.00025306688621640205 0.05737531930208206 0.00031857372960075736\n",
            "4.713672804452216 0.03502986161919936 1.0\n",
            "repr, std, cov, conv, closs 0.0016643896233290434 0.472900390625 0.00024334038607776165 0.06724755465984344 0.00020297944138292223\n",
            "4.690174980872841 0.03426799675896061 1.0\n",
            "repr, std, cov, conv, closs 0.0004574116610456258 0.47607421875 0.00021123234182596207 0.06999292969703674 4.609749521478079e-05\n",
            "4.737288352362819 0.03426799675896061 1.0\n",
            "repr, std, cov, conv, closs 0.0019601990934461355 0.474365234375 0.00027395947836339474 0.06288724392652512 7.261706196004525e-05\n",
            "4.775319568875606 0.034199563432532123 1.0\n",
            "repr, std, cov, conv, closs 0.0014230104861781001 0.47607421875 0.00016900594346225262 0.06420238316059113 0.00014754306175746024\n",
            "4.8088472548721 0.034336567020475287 1.0\n",
            "repr, std, cov, conv, closs 0.002888574730604887 0.475341796875 0.00017160200513899326 0.058643996715545654 0.0005415062187239528\n",
            "4.876610476784195 0.034855236535430205 1.0\n",
            "repr, std, cov, conv, closs 0.0009333413909189403 0.475830078125 0.0001667267642915249 0.06795409321784973 0.0004376365104690194\n",
            "4.910849329793843 0.034994866752446924 1.0\n",
            "repr, std, cov, conv, closs 0.0012514728587120771 0.47509765625 0.00020285975188016891 0.05853363126516342 0.00045769885764457285\n",
            "4.965139581047699 0.03573715462959734 1.0\n",
            "repr, std, cov, conv, closs 0.0025038975290954113 0.474853515625 0.00022161495871841908 0.0638759657740593 2.631317693158053e-05\n",
            "4.965139581047699 0.035630157231800096 1.0\n",
            "repr, std, cov, conv, closs 0.00074844213668257 0.474853515625 0.0001793059054762125 0.05121062695980072 0.01608545146882534\n",
            "4.990014980024971 0.03595211432997372 1.0\n",
            "repr, std, cov, conv, closs 0.00042705918895080686 0.4755859375 0.00018701073713600636 0.057131797075271606 0.00018317012290935963\n",
            "5.0 0.03591619813184188 1.0\n",
            "repr, std, cov, conv, closs 0.0021071003284305334 0.476318359375 0.00016553071327507496 0.06358476728200912 0.000800761510618031\n",
            "4.9800499001747225 0.03584447334068717 1.0\n",
            "repr, std, cov, conv, closs 0.00115263182669878 0.475341796875 0.00019905087538063526 0.0637672021985054 0.00022696430096402764\n",
            "4.945328574990031 0.035630157231800096 1.0\n",
            "repr, std, cov, conv, closs 0.0009570612455718219 0.473388671875 0.000204386655241251 0.059900812804698944 2.3518578018411063e-05\n",
            "4.901042344063373 0.03478563048882208 1.0\n",
            "repr, std, cov, conv, closs 0.0007289849454537034 0.47607421875 0.00019616959616541862 0.06925134360790253 7.68884492572397e-05\n",
            "4.891254942922586 0.03454310215835001 1.0\n",
            "repr, std, cov, conv, closs 0.005127672106027603 0.470947265625 0.00046484917402267456 0.0585084967315197 7.513885066146031e-05\n",
            "4.881487087260978 0.03399508233189402 1.0\n",
            "repr, std, cov, conv, closs 0.0009558091405779123 0.475341796875 0.00021555041894316673 0.06077706068754196 5.182737368158996e-05\n",
            "4.837772567359259 0.03338894545717364 1.0\n",
            "repr, std, cov, conv, closs 0.0008321037166751921 0.474365234375 0.00026839785277843475 0.059783875942230225 0.015071375295519829\n",
            "4.794449518174574 0.03279361608417687 1.0\n",
            "repr, std, cov, conv, closs 0.0007627819431945682 0.4755859375 0.00018350454047322273 0.0663529559969902 0.0004003695794381201\n",
            "4.799243967692748 0.03295791242885875 1.0\n",
            "repr, std, cov, conv, closs 0.0010953909950330853 0.47607421875 0.00019348273053765297 0.07000468671321869 0.00010109502181876451\n",
            "4.8088472548721 0.032859236109961304 1.0\n",
            "repr, std, cov, conv, closs 0.0013079297496005893 0.47265625 0.0002839835360646248 0.05648375675082207 0.046578049659729004\n",
            "4.751514434022251 0.03237026843253302 1.0\n",
            "torch.Size([3, 64, 64])\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "repr, std, cov, conv, closs 0.004028043709695339 0.47412109375 0.000262607354670763 0.055000096559524536 6.269215373322368e-05\n",
            "4.727827968597657 0.03176134086656375 1.0\n",
            "repr, std, cov, conv, closs 0.0017547367606312037 0.474609375 0.00024035759270191193 0.0558863990008831 0.00011789645941462368\n",
            "4.746767666355896 0.031729611255308446 1.0\n",
            "repr, std, cov, conv, closs 0.008102611638605595 0.474609375 0.0002606839407235384 0.067603699862957 0.014204277656972408\n",
            "4.842610339926618 0.03185672020494737 1.0\n",
            "repr, std, cov, conv, closs 0.006058551836758852 0.477783203125 0.00016855495050549507 0.06531715393066406 0.0004751683445647359\n",
            "4.871738738046149 0.0321767247889104 1.0\n",
            "repr, std, cov, conv, closs 0.0018503046594560146 0.478271484375 0.00013742176815867424 0.05980755388736725 0.0009481740999035537\n",
            "4.9403881868032276 0.03295791242885875 1.0\n",
            "repr, std, cov, conv, closs 0.00047047296538949013 0.477783203125 0.00013748113997280598 0.05912087857723236 0.01544950157403946\n",
            "4.970104720628746 0.033455756737033444 1.0\n",
            "repr, std, cov, conv, closs 0.0021438910625874996 0.477294921875 0.00015227659605443478 0.07117114216089249 7.166036812122911e-05\n",
            "5.0 0.03454310215835001 1.0\n",
            "repr, std, cov, conv, closs 0.0012062035966664553 0.4765625 0.00016056071035563946 0.06369714438915253 0.015436716377735138\n",
            "4.9950049950049955 0.03478563048882208 1.0\n",
            "repr, std, cov, conv, closs 0.0003911683161277324 0.475830078125 0.00019137142226099968 0.05532139539718628 0.0003230933507438749\n",
            "4.985029950074897 0.03502986161919937 1.0\n",
            "repr, std, cov, conv, closs 0.0008562671719118953 0.4775390625 0.00014616549015045166 0.057097386568784714 0.00015208555851131678\n",
            "4.965139581047699 0.034994866752446924 1.0\n",
            "repr, std, cov, conv, closs 0.003738728351891041 0.476318359375 0.00018102861940860748 0.06370341777801514 0.015339074656367302\n",
            "4.886368574348238 0.034336567020475287 1.0\n",
            "repr, std, cov, conv, closs 0.0004401766345836222 0.474609375 0.00024010427296161652 0.06263931095600128 2.6158373657381162e-05\n",
            "4.832939627731529 0.033724341427984486 1.0\n",
            "repr, std, cov, conv, closs 0.002532810205593705 0.47509765625 0.00022570043802261353 0.05479922890663147 5.1016595534747466e-05\n",
            "4.780094888444481 0.032892095346071265 1.0\n",
            "repr, std, cov, conv, closs 0.004387237131595612 0.47509765625 0.00023578619584441185 0.06958805024623871 0.00011308517423458397\n",
            "4.742025640715181 0.03259754122129085 1.0\n",
            "repr, std, cov, conv, closs 0.0037149612326174974 0.472900390625 0.00023900531232357025 0.07040800899267197 0.000313860917231068\n",
            "4.690174980872841 0.03192046550207746 1.0\n",
            "repr, std, cov, conv, closs 0.001897988491691649 0.4755859375 0.00019697030074894428 0.06382094323635101 0.00012697189231403172\n",
            "4.657474687914274 0.031539898136744696 1.0\n",
            "repr, std, cov, conv, closs 0.0009066211641766131 0.472900390625 0.0002823900431394577 0.05950221046805382 9.996540029533207e-05\n",
            "4.620382002136052 0.031008515062845077 1.0\n",
            "repr, std, cov, conv, closs 0.0009260571678169072 0.47509765625 0.00017715105786919594 0.06592658162117004 3.230451693525538e-05\n",
            "4.579005721225054 0.030608212089268692 1.0\n",
            "repr, std, cov, conv, closs 0.0015494663966819644 0.47509765625 0.0001925916876643896 0.05885627865791321 1.5435420209541917e-05\n",
            "4.601946585701347 0.030455629082855006 1.0\n",
            "repr, std, cov, conv, closs 0.00031986148678697646 0.47509765625 0.00018240325152873993 0.06232830137014389 0.00016080032219178975\n",
            "4.5881683116732255 0.03030380670805803 1.0\n",
            "repr, std, cov, conv, closs 0.0009097916190512478 0.474853515625 0.000264244619756937 0.06273601949214935 0.00038641365244984627\n",
            "4.620382002136052 0.030243289884998158 1.0\n",
            "repr, std, cov, conv, closs 0.0016372818499803543 0.476806640625 0.00014800205826759338 0.07231993973255157 0.00022518300102092326\n",
            "4.652821866048226 0.030455629082855006 1.0\n",
            "repr, std, cov, conv, closs 0.0035087214782834053 0.472900390625 0.0002305039670318365 0.05095627158880234 2.4735079932725057e-05\n",
            "4.680808682698761 0.03051657079664979 1.0\n",
            "repr, std, cov, conv, closs 0.0009951409883797169 0.47705078125 0.00014093471691012383 0.06391805410385132 0.015912599861621857\n",
            "4.6854894913814595 0.03036444462528085 1.0\n",
            "repr, std, cov, conv, closs 0.0023665977641940117 0.47412109375 0.00024159718304872513 0.06486481428146362 1.702244480838999e-05\n",
            "4.676132550148613 0.029942513735131664 1.0\n",
            "repr, std, cov, conv, closs 0.0017604324966669083 0.47509765625 0.00014396896585822105 0.07150827348232269 0.00029908507713116705\n",
            "4.666794294764789 0.02979324925826628 1.0\n",
            "repr, std, cov, conv, closs 0.0037072335835546255 0.47607421875 0.00016856659203767776 0.0739118903875351 0.00046681705862283707\n",
            "4.708963840611605 0.0301527411731026 1.0\n",
            "repr, std, cov, conv, closs 0.001184541266411543 0.475830078125 0.0001649470068514347 0.065875343978405 7.786742207827047e-05\n",
            "4.727827968597657 0.030002428705115658 1.0\n",
            "repr, std, cov, conv, closs 0.002078376477584243 0.474853515625 0.000182395800948143 0.05050147697329521 8.328648982569575e-05\n",
            "4.723104863733924 0.029526445809981816 1.0\n",
            "repr, std, cov, conv, closs 0.0010662500280886889 0.47607421875 0.00013964436948299408 0.059960704296827316 3.878137067658827e-05\n",
            "4.746767666355896 0.02946748137974096 1.0\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "for i in range(30):\n",
        "    print(i)\n",
        "    # agent.train_ae(train_loader, optim)\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "    state = buffer[7][80][0]\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    out= agent.deconv(sx_).squeeze(0)\n",
        "    print(out.shape)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n",
        "\n",
        "# 10 epochs 15m23s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PraFUAPB3j7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091fe299-ad56-4e15-a0d7-7a2ea8801a4f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ded\n",
            "time\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # out = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68270476-735e-4093-b4ea-e320151bf571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ded\n",
            "time\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 #### train ####\n",
            "repr, std, cov, conv, closs 0.09844094514846802 0.4897046983242035 4.808874109585304e-06 1.5543413162231445 0.4272165298461914\n",
            "5.162504980811407 0.05162504980811409 1.0\n",
            "repr, std, cov, conv, closs 0.29408344626426697 0.4854440987110138 0.0001309133367612958 1.1579381227493286 0.48204535245895386\n",
            "5.256224162173725 0.05256224162173726 1.0\n",
            "repr, std, cov, conv, closs 0.6667881608009338 0.4867760241031647 6.91275781719014e-05 0.8461161255836487 0.33414924144744873\n",
            "5.4270566834966285 0.054270566834966276 1.0\n",
            "argm 1.1508173942565918 0.8624275922775269\n",
            "argm 1.150539755821228 0.8741869330406189\n",
            "argm 1.149749755859375 0.8384445309638977\n",
            "argm 1.1516046524047852 0.8476881980895996\n",
            "argm 1.1519715785980225 0.8789501190185547\n",
            "argm 1.153049111366272 0.8753296136856079\n",
            "argm 1.1547811031341553 0.8692529201507568\n",
            "argm 1.1531176567077637 0.8530669212341309\n",
            "argm 1.1531163454055786 0.8593634366989136\n",
            "argm 1.1526660919189453 0.8839624524116516\n",
            "argm 1.1511558294296265 0.8673310279846191\n",
            "argm 1.1510554552078247 0.8628800511360168\n",
            "argm 1.150519609451294 0.8613592982292175\n",
            "argm 1.15113365650177 0.8508003354072571\n",
            "argm 1.151079535484314 0.8604375123977661\n",
            "argm 1.1499511003494263 0.857129693031311\n",
            "argm 1.1499327421188354 0.8705748915672302\n",
            "argm 1.150909423828125 0.8715466856956482\n",
            "repr, std, cov, conv, closs 1.150909423828125 0.4881921410560608 4.319609797676094e-05 0.6180972456932068 0.23151512444019318\n",
            "5.525578488603779 0.05525578488603779 1.0\n",
            "argm 1.5319786071777344 0.5856181383132935\n",
            "argm 1.5310134887695312 0.5735638737678528\n",
            "argm 1.532170295715332 0.5794238448143005\n",
            "argm 1.5313105583190918 0.6106293201446533\n",
            "argm 1.532691478729248 0.5659154653549194\n",
            "argm 1.5334436893463135 0.5662880539894104\n",
            "argm 1.531671166419983 0.5378533601760864\n",
            "argm 1.5322147607803345 0.5413526296615601\n",
            "argm 1.5323245525360107 0.5547681450843811\n",
            "argm 1.535154938697815 0.53734290599823\n",
            "argm 1.533917784690857 0.6117246150970459\n",
            "argm 1.5329264402389526 0.5764312148094177\n",
            "argm 1.533088207244873 0.5615377426147461\n",
            "argm 1.5338597297668457 0.5861030220985413\n",
            "argm 1.5338026285171509 0.5673650503158569\n",
            "argm 1.534334421157837 0.5154211521148682\n",
            "argm 1.5375696420669556 0.5733024477958679\n",
            "argm 1.5368622541427612 0.576135516166687\n",
            "argm 1.5342531204223633 0.5699988007545471\n",
            "argm 1.537736415863037 0.5829080939292908\n",
            "argm 1.5370798110961914 0.5641647577285767\n",
            "argm 1.5360463857650757 0.5692367553710938\n",
            "argm 1.5353273153305054 0.5647060871124268\n",
            "argm 1.5338047742843628 0.6016371250152588\n",
            "argm 1.5322942733764648 0.572855532169342\n",
            "argm 1.529229998588562 0.5469419360160828\n",
            "argm 1.5311076641082764 0.6008603572845459\n",
            "argm 1.528306007385254 0.5499520897865295\n",
            "argm 1.5274147987365723 0.572031557559967\n",
            "argm 1.52759850025177 0.6241207718849182\n",
            "argm 1.5283161401748657 0.6325788497924805\n",
            "argm 1.5272407531738281 0.5447605848312378\n",
            "repr, std, cov, conv, closs 1.5272407531738281 0.4746933579444885 0.0037761549465358257 0.46770092844963074 0.28272658586502075\n",
            "5.705165293856277 0.05705165293856279 1.0\n",
            "argm 1.6291636228561401 0.9303221702575684\n",
            "argm 1.6296075582504272 0.9281735420227051\n",
            "argm 1.6291332244873047 0.9307013750076294\n",
            "argm 1.6316214799880981 0.9121814966201782\n",
            "argm 1.632613182067871 0.922797441482544\n",
            "argm 1.6348543167114258 0.9228184223175049\n",
            "argm 1.6366773843765259 0.9256404638290405\n",
            "argm 1.6342129707336426 0.916293740272522\n",
            "argm 1.6345595121383667 0.9280316233634949\n",
            "argm 1.6351196765899658 0.9332615733146667\n",
            "argm 1.6358169317245483 0.9151585102081299\n",
            "argm 1.636111855506897 0.9300424456596375\n",
            "argm 1.635607361793518 0.9258260130882263\n",
            "argm 1.636406660079956 0.9485428929328918\n",
            "argm 1.636834979057312 0.9276588559150696\n",
            "argm 1.6372509002685547 0.918673038482666\n",
            "argm 1.6363588571548462 0.9292417168617249\n",
            "argm 1.6362993717193604 0.9127284288406372\n",
            "repr, std, cov, conv, closs 1.6362993717193604 0.4826682507991791 0.0006857843836769462 0.3516911268234253 0.23214904963970184\n",
            "5.808735832357313 0.05808735832357314 1.0\n",
            "argm 1.5378872156143188 0.9466034770011902\n",
            "argm 1.536611795425415 0.9483051300048828\n",
            "argm 1.5345128774642944 0.9490616917610168\n",
            "argm 1.5335414409637451 0.9532370567321777\n",
            "argm 1.5355796813964844 0.9575260877609253\n",
            "argm 1.5379424095153809 0.9537382125854492\n",
            "argm 1.5417722463607788 0.9470773935317993\n",
            "argm 1.5414079427719116 0.9632599949836731\n",
            "argm 1.54108464717865 0.9546483159065247\n",
            "argm 1.5377533435821533 0.9612494707107544\n",
            "argm 1.5332283973693848 0.9539331197738647\n",
            "argm 1.528946042060852 0.9457363486289978\n",
            "argm 1.5278735160827637 0.9520655274391174\n",
            "argm 1.526434302330017 0.9500752687454224\n",
            "argm 1.52754807472229 0.941888689994812\n",
            "argm 1.5277936458587646 0.9529860615730286\n",
            "argm 1.5272362232208252 0.9530777931213379\n",
            "argm 1.5254398584365845 0.9506050944328308\n",
            "argm 1.5297983884811401 0.9503771066665649\n",
            "argm 1.5307787656784058 0.9432262182235718\n",
            "argm 1.5288770198822021 0.9591172337532043\n",
            "argm 1.5308476686477661 0.956087589263916\n",
            "argm 1.5303072929382324 0.9499386548995972\n",
            "argm 1.5342696905136108 0.949779748916626\n",
            "argm 1.533881425857544 0.9458339810371399\n",
            "argm 1.5377932786941528 0.962022066116333\n",
            "argm 1.5373376607894897 0.9480032920837402\n",
            "argm 1.5385732650756836 0.9564154148101807\n",
            "argm 1.5388511419296265 0.954262375831604\n",
            "argm 1.5397342443466187 0.9538941979408264\n",
            "argm 1.5444239377975464 0.9586710929870605\n",
            "argm 1.544264793395996 0.9535098671913147\n",
            "repr, std, cov, conv, closs 1.544264793395996 0.4852483868598938 0.0002737812465056777 0.2706885039806366 0.24956804513931274\n",
            "5.997525533352466 0.059975255333524685 1.0\n",
            "argm 1.6903233528137207 0.9996309280395508\n",
            "argm 1.692679762840271 0.9962620139122009\n",
            "argm 1.6905690431594849 0.9977298378944397\n",
            "argm 1.688337802886963 0.9973723888397217\n",
            "argm 1.688065767288208 0.9998393654823303\n",
            "argm 1.6882331371307373 0.9980263710021973\n",
            "argm 1.684719443321228 0.9983868598937988\n",
            "argm 1.688117265701294 0.9991269111633301\n",
            "argm 1.685691237449646 0.9966739416122437\n",
            "argm 1.6881040334701538 0.9977980852127075\n",
            "argm 1.6885613203048706 0.9954874515533447\n",
            "argm 1.686530590057373 0.997826099395752\n",
            "argm 1.6820838451385498 0.9976531267166138\n",
            "argm 1.6839048862457275 0.99880051612854\n",
            "argm 1.6827412843704224 0.9974103569984436\n",
            "argm 1.6790539026260376 0.9968806505203247\n",
            "argm 1.6795663833618164 0.9991849660873413\n",
            "argm 1.6784404516220093 0.9965712428092957\n",
            "repr, std, cov, conv, closs 1.6784404516220093 0.48427286744117737 0.0003766712034121156 0.21729564666748047 0.2356421947479248\n",
            "6.106403526744161 0.06106403526744164 1.0\n",
            "argm 1.6101036071777344 0.9815011620521545\n",
            "argm 1.6089485883712769 0.9793732762336731\n",
            "argm 1.6095367670059204 0.9784361720085144\n",
            "argm 1.604877233505249 0.9772888422012329\n",
            "argm 1.605178713798523 0.9758498072624207\n",
            "argm 1.606002926826477 0.9761282801628113\n",
            "argm 1.6004828214645386 0.9772818088531494\n",
            "argm 1.6029155254364014 0.9798040390014648\n",
            "argm 1.6019575595855713 0.9813246726989746\n",
            "argm 1.5973588228225708 0.9812358021736145\n",
            "argm 1.599613070487976 0.9804088473320007\n",
            "argm 1.6028563976287842 0.984333872795105\n",
            "argm 1.602243423461914 0.9822906851768494\n",
            "argm 1.604286551475525 0.9770135283470154\n",
            "argm 1.6051753759384155 0.9753789901733398\n",
            "argm 1.6071974039077759 0.9714586138725281\n",
            "argm 1.6145122051239014 0.9656369090080261\n",
            "argm 1.6132832765579224 0.9677783846855164\n",
            "argm 1.6182575225830078 0.9681110978126526\n",
            "argm 1.617946982383728 0.9599803686141968\n",
            "argm 1.6206104755401611 0.9494171142578125\n",
            "argm 1.6221709251403809 0.9501423239707947\n",
            "argm 1.6304829120635986 0.9461523294448853\n",
            "argm 1.6322309970855713 0.9446577429771423\n",
            "argm 1.6402021646499634 0.9366520047187805\n",
            "argm 1.6434907913208008 0.9289079308509827\n",
            "argm 1.6449133157730103 0.9317541122436523\n",
            "argm 1.6384587287902832 0.9423294067382812\n",
            "argm 1.635920524597168 0.9435718059539795\n",
            "argm 1.6267069578170776 0.9402304291725159\n",
            "argm 1.6279704570770264 0.9392006993293762\n",
            "argm 1.6304876804351807 0.9383372068405151\n",
            "repr, std, cov, conv, closs 1.6304876804351807 0.4798577129840851 0.0016034748405218124 0.184747114777565 0.2332599014043808\n",
            "6.304867724332218 0.06304867724332221 1.0\n",
            "argm 1.6979594230651855 0.9577693939208984\n",
            "argm 1.6974486112594604 0.9592757821083069\n",
            "argm 1.6920526027679443 0.9671223163604736\n",
            "argm 1.6923654079437256 0.9579321146011353\n",
            "argm 1.6944867372512817 0.9668213129043579\n",
            "argm 1.6713619232177734 0.9740350246429443\n",
            "argm 1.671169400215149 0.9757858514785767\n",
            "argm 1.667635440826416 0.980617880821228\n",
            "argm 1.669843077659607 0.9740004539489746\n",
            "argm 1.6742500066757202 0.9723158478736877\n",
            "argm 1.6736074686050415 0.9697385430335999\n",
            "argm 1.6758586168289185 0.9705094695091248\n",
            "argm 1.6829779148101807 0.973943829536438\n",
            "argm 1.6878001689910889 0.9776012301445007\n",
            "argm 1.6875619888305664 0.9787164926528931\n",
            "argm 1.6867042779922485 0.9745684862136841\n",
            "argm 1.6832003593444824 0.9838863611221313\n",
            "argm 1.6883175373077393 0.9807446599006653\n",
            "repr, std, cov, conv, closs 1.6883175373077393 0.4845259487628937 0.00041857484029605985 0.15701092779636383 0.22263959050178528\n",
            "6.419325152251102 0.06419325152251104 1.0\n",
            "argm 1.4794760942459106 0.8472192883491516\n",
            "argm 1.4760621786117554 0.8444359302520752\n",
            "argm 1.4704773426055908 0.8563225269317627\n",
            "argm 1.4736826419830322 0.8560197353363037\n",
            "argm 1.4890834093093872 0.869055986404419\n",
            "argm 1.485623836517334 0.8745871186256409\n",
            "argm 1.4890292882919312 0.8872097730636597\n",
            "argm 1.4865596294403076 0.8747121095657349\n",
            "argm 1.4837981462478638 0.8768093585968018\n",
            "argm 1.4776830673217773 0.8788193464279175\n",
            "argm 1.4833574295043945 0.874634325504303\n",
            "argm 1.4793998003005981 0.9056013822555542\n",
            "argm 1.4773892164230347 0.9261362552642822\n",
            "argm 1.4731215238571167 0.9016346335411072\n",
            "argm 1.482322335243225 0.9182220697402954\n",
            "argm 1.481353759765625 0.9297819137573242\n",
            "argm 1.4863643646240234 0.9281185865402222\n",
            "argm 1.480488896369934 0.9117793440818787\n",
            "argm 1.4791022539138794 0.9148061275482178\n",
            "argm 1.4819828271865845 0.8908326625823975\n",
            "argm 1.4711675643920898 0.8823187351226807\n",
            "argm 1.472663164138794 0.880855917930603\n",
            "argm 1.4713994264602661 0.8598674535751343\n",
            "argm 1.4709283113479614 0.8758984804153442\n",
            "argm 1.4698606729507446 0.8609845042228699\n",
            "argm 1.467883825302124 0.8859698176383972\n",
            "argm 1.4494030475616455 0.8767203688621521\n",
            "argm 1.4517709016799927 0.86899334192276\n",
            "argm 1.4522336721420288 0.8589884042739868\n",
            "argm 1.4647655487060547 0.8666108250617981\n",
            "argm 1.4622849225997925 0.8428335785865784\n",
            "argm 1.4724980592727661 0.8435874581336975\n",
            "repr, std, cov, conv, closs 1.4724980592727661 0.4869879484176636 0.00014729591202922165 0.1550600677728653 0.20744681358337402\n",
            "6.627959614388853 0.06627959614388858 1.0\n",
            "argm 1.439563512802124 0.9417451024055481\n",
            "argm 1.4439040422439575 0.9432713985443115\n",
            "argm 1.4426523447036743 0.926967978477478\n",
            "argm 1.4419108629226685 0.934174656867981\n",
            "argm 1.4477142095565796 0.9394389390945435\n",
            "argm 1.4519290924072266 0.9576653838157654\n",
            "argm 1.470104694366455 0.9589604735374451\n",
            "argm 1.4769426584243774 0.9463034272193909\n",
            "argm 1.4707919359207153 0.9457854628562927\n",
            "argm 1.4724981784820557 0.9583126306533813\n",
            "argm 1.482202172279358 0.9610767960548401\n",
            "argm 1.4791502952575684 0.9699845910072327\n",
            "argm 1.4837373495101929 0.9672330617904663\n",
            "argm 1.4911223649978638 0.9516057968139648\n",
            "argm 1.435555338859558 0.9264383912086487\n",
            "argm 1.4476318359375 0.9634654521942139\n",
            "argm 1.4422763586044312 0.9561913013458252\n",
            "argm 1.456985354423523 0.9702591896057129\n",
            "repr, std, cov, conv, closs 1.456985354423523 0.48593538999557495 0.0002416296920273453 0.13905306160449982 0.29171353578567505\n",
            "6.748282394022353 0.06748282394022358 1.0\n",
            "argm 1.8028169870376587 1.0\n",
            "argm 1.7887229919433594 0.9404329061508179\n",
            "argm 1.7647385597229004 0.9710478186607361\n",
            "argm 1.7533625364303589 0.9850230813026428\n",
            "argm 1.7271232604980469 0.9539337158203125\n",
            "argm 1.7211116552352905 0.9583799839019775\n",
            "argm 1.6920766830444336 0.9920714497566223\n",
            "argm 1.681810736656189 0.9735075831413269\n",
            "argm 1.6818403005599976 0.9498355388641357\n",
            "argm 1.7028985023498535 0.9691545367240906\n",
            "argm 1.6714600324630737 0.9900155663490295\n",
            "argm 1.6576288938522339 0.9938228130340576\n",
            "argm 1.63649320602417 0.985061526298523\n",
            "argm 1.6303895711898804 0.9907616972923279\n",
            "argm 1.6294169425964355 0.9846988320350647\n",
            "argm 1.6190319061279297 0.9875028133392334\n",
            "argm 1.6155253648757935 1.0\n",
            "argm 1.6143287420272827 0.9613316655158997\n",
            "argm 1.610978364944458 0.9417770504951477\n",
            "argm 1.6389881372451782 0.9471892714500427\n",
            "argm 1.644216775894165 0.9649693369865417\n",
            "argm 1.639857292175293 0.9834261536598206\n",
            "argm 1.648576021194458 0.9846972227096558\n",
            "argm 1.642359972000122 1.0\n",
            "argm 1.634666919708252 0.9965410232543945\n",
            "argm 1.6373181343078613 0.9813684821128845\n",
            "argm 1.6293816566467285 0.9798016548156738\n",
            "argm 1.634705662727356 0.9741353988647461\n",
            "argm 1.6519826650619507 1.0\n",
            "argm 1.6524670124053955 0.9712071418762207\n",
            "argm 1.6760811805725098 0.9790534973144531\n",
            "argm 1.6943128108978271 0.9859930872917175\n",
            "repr, std, cov, conv, closs 1.6943128108978271 0.48603010177612305 0.0002383578976150602 0.14092054963111877 0.20620647072792053\n",
            "6.967608294212468 0.06967608294212473 1.0\n",
            "argm 1.269741415977478 0.9567173719406128\n",
            "argm 1.289387822151184 0.9159517288208008\n",
            "argm 1.310712218284607 0.949338972568512\n",
            "argm 1.3279812335968018 0.9700304269790649\n",
            "argm 1.3111084699630737 0.9873590469360352\n",
            "argm 1.296874761581421 0.9761171340942383\n",
            "argm 1.33037531375885 1.0\n",
            "argm 1.3230246305465698 0.9953933954238892\n",
            "argm 1.3115618228912354 0.9894971251487732\n",
            "argm 1.329655647277832 0.982353687286377\n",
            "argm 1.3187568187713623 0.9833723306655884\n",
            "argm 1.3264809846878052 0.9691868424415588\n",
            "argm 1.3231157064437866 0.986204981803894\n",
            "argm 1.324123740196228 0.9825578927993774\n",
            "argm 1.3256616592407227 0.9908433556556702\n",
            "argm 1.3091551065444946 0.978930652141571\n",
            "argm 1.3161088228225708 0.9674602150917053\n",
            "argm 1.299556851387024 0.9773329496383667\n",
            "repr, std, cov, conv, closs 1.299556851387024 0.48697009682655334 0.00014716488658450544 0.12570665776729584 0.21997623145580292\n",
            "6.967608294212468 0.07094096994526373 1.0\n",
            "argm 0.9031339883804321 0.9813656806945801\n",
            "argm 0.902189314365387 0.9452663660049438\n",
            "repr, std, cov, conv, closs 0.8602845668792725 0.48718276619911194 0.0001396978332195431 0.10288961976766586 0.2709091007709503\n",
            "6.967608294212468 0.07324662213720332 1.0\n",
            "repr, std, cov, conv, closs 0.6178955435752869 0.4878253936767578 8.701145998202264e-05 0.09487747400999069 0.2508490979671478\n",
            "6.967608294212468 0.07457632806286707 1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8775dd10a4a0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# agent.train_jepa(train_loader, optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_jepa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-1bdbc6f9b5ab>\u001b[0m in \u001b[0;36mtrain_jepa\u001b[0;34m(self, dataloader, c_loader, optim, bptt)\u001b[0m\n\u001b[1;32m    263\u001b[0m                     \u001b[0;31m# # ae loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# state_ = self.deconv(sy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                     \u001b[0mstate_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                     \u001b[0mconv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0;31m# # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a537c38204a2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvTranspose2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         )\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    950\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             output_padding, self.groups, self.dilation)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "for i in range(30):\n",
        "    # # buffer=[]\n",
        "    # print(\"#### simulate ####\")\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n",
        "\n",
        "    state = buffer[7][80][0]\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    out= agent.deconv(sx_).squeeze(0)\n",
        "    # print(out.shape)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "    c_loader = make_weighted(buffer)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    # train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "b8zxYU9jpE8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "2ddd9cb3-36dd-45db-a986-f3385079115e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*4 -2\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*3 -1.5\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "4ad29030-4c15-4a86-902d-ecce152091f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240823_103908-3o415bps</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/3o415bps' target=\"_blank\">frosty-armadillo-21</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/3o415bps' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/3o415bps</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(\n",
        "    project=\"procgen\",\n",
        "    config={\n",
        "        \"model\": \"res18\",\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.cuda.amp.autocast():\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.cuda.amp.autocast():\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjm2kV3H7ZVR",
        "outputId": "d4040132-28f1-4347-8028-2e951476da85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6872065\n"
          ]
        }
      ],
      "source": [
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad))\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.cuda.amp.autocast(): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ],
      "metadata": {
        "id": "gJ3X_hQelW2x",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi4ODp-XlZoU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "QYbOgNoZn6JL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kcajtpjr7Io",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.cuda.amp.autocast(): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wUhKd009Qvk3"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}