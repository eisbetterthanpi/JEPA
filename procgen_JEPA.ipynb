{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "80893cee-5e44-4e2e-93ac-ad4fd63d8389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m477.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq procgen faiss-cpu vector-quantize-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nEY9MmwZhA8a"
      },
      "outputs": [],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# conv = Conv().to(device)\n",
        "# # print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# # input = torch.rand((4,1,256,256), device=device)\n",
        "# out = conv(input)\n",
        "# print(out.shape)\n",
        "\n",
        "# conv = Deconv(256).to(device)\n",
        "# # print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# input = torch.rand((4,256), device=device)\n",
        "# out = conv(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko5qJO7Et09L",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "2f58aed3-3a31-4c3e-95ca-40ee272637de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "\n",
        "ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FuA25qQknUAX"
      },
      "outputs": [],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model)\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            )\n",
        "        # self.pred = gru(emb_dim, rnn_units, num_layers)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=1e5): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        num_steps = 5 # 10\n",
        "        for i in range(num_steps):\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sy_ = self.pred(sxaz)\n",
        "                # print(\"y_, y\",y_.shape, y.shape)\n",
        "                loss = lossfn(sy_, sy)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z = torch.clamp(z, min=-1, max=1)\n",
        "            # print(\"argm in\",loss.item())\n",
        "        # print(z.squeeze())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCD647ZpPrGf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cIF--UQMEEFx"
      },
      "outputs": [],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(3): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "                sx_ = sx_.detach()\n",
        "                # print(loss.item(), lact)\n",
        "        # print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29O1eyvhnRSD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title agent pixel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=1) # 20\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(3): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "                sx_ = sx_.detach()\n",
        "                # print(loss.item(), lact)\n",
        "            # print(x)\n",
        "        print(\"search\",loss.item())\n",
        "        # print(lact)\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=32):\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=torch.tensor(0)\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(sxaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    reward_ = self.tcost(sy).squeeze(-1)\n",
        "                    clossl = F.mse_loss(reward_, reward) # [batch_size]\n",
        "                    try:\n",
        "                        st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    # closs = F.mse_loss(reward_, reward) + F.mse_loss(stt, r)\n",
        "                    closs = clossl + clossb\n",
        "                    # print(loss, jloss, clossl, clossb)\n",
        "                    # print(loss.dtype, jloss.dtype, clossl.dtype, clossb.dtype)\n",
        "\n",
        "                    # loss = loss + jloss + conv_loss + closs\n",
        "                    loss = loss + jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    print(loss, loss.dtype)\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "!gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_b7ZSW6IF1-",
        "outputId": "69ab0a3d-4041-4b7e-a390-f3babceb08ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_\n",
            "From (redirected): https://drive.google.com/uc?id=12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_&confirm=t&uuid=7a45c8ca-269c-4a6a-845c-a79ddbc78173\n",
            "To: /content/agentoptim.pkl\n",
            "100% 44.2M/44.2M [00:01<00:00, 38.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ShHQ_ynlwoyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5046c2-b3ae-46ec-ce17-67d2f110a1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "def save(folder, name='agent.pth'):\n",
        "    torch.save(agent.state_dict(), folder+name)\n",
        "    # agent.mem.save(file=folder+name)\n",
        "    with open(folder+'buffer.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "def load(folder, name='agent.pth'):\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=torch.device(device)), strict=False)\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=device), strict=False)\n",
        "    # torch.load(folder+name, map_location=torch.device('cpu'))\n",
        "    # agent.mem.load(file=folder+name)\n",
        "    with open(folder+'buffer512.pkl', 'rb') as f: return pickle.load(f)\n",
        "\n",
        "# save(folder)\n",
        "# save(folder, name='agent_jepa753333256.pth')\n",
        "# buffer = load(folder)\n",
        "# save('/content/')\n",
        "# buffer = load('/content/')\n",
        "\n",
        "# name='agent.pth'\n",
        "# print(folder+name)\n",
        "# torch.load(folder+name, map_location='o')\n",
        "# with open(folder+'buffer512down.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "with open(folder+'buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "# # modelsd, optimsd = torch.load(folder+'agentoptim.pkl').values()\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "# agent.load_state_dict(modelsd)\n",
        "# optim.load_state_dict(optimsd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVcknabHMxH6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader old\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 64 #512\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e3fpbtNOiz1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "train_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "train_data = Datasetme(train_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    train_data=list(zip(state,reward))\n",
        "    train_data = Datasetme(train_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# trainiter = iter(c_loader)\n",
        "# images, labels = next(trainiter)\n",
        "# # imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# # print(labels)\n",
        "# for x in range((len(labels)//10)+1):\n",
        "#     print(labels[10*x:10*x+10])\n",
        "\n",
        "# try:\n",
        "#     with torch.no_grad():\n",
        "#         # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "#         pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "#         # print(pred)\n",
        "#         for x in range((len(pred)//10)+1):\n",
        "#             print(pred[10*x:10*x+10])\n",
        "#         # print((labels==pred).sum())\n",
        "# except: pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OksdjCeJYpYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77d544d9-7efe-417d-9bbc-2713423d13e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "repr, std, cov, closs 0.08747327327728271 0.4903256595134735 3.7056101973576006e-06 0.018899040296673775 0.5910208225250244\n",
            "tensor(41.0307, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05 1.0\n",
            "repr, std, cov, closs 0.0023124725557863712 0.4948121905326843 3.2914135861261684e-09 0.0003168071270920336 0.4206911325454712\n",
            "tensor(9.9252, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05090769095342922 1.0\n",
            "repr, std, cov, closs 0.001711460528895259 0.49495553970336914 1.2637026980399924e-09 0.00012477867130655795 0.47341370582580566\n",
            "tensor(17.1624, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05256224162173726 1.0\n",
            "repr, std, cov, closs 0.0014268800150603056 0.49498602747917175 8.249739086307883e-11 0.001675314037129283 0.41765886545181274\n",
            "tensor(9.1129, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.053516447045977494 1.0\n",
            "repr, std, cov, closs 0.0014533705543726683 0.4949691593647003 7.516112177086143e-10 0.005313791800290346 0.365246444940567\n",
            "tensor(15.1991, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05525578488603779 1.0\n",
            "repr, std, cov, closs 0.0013349514920264482 0.49494078755378723 2.6082636050972496e-09 0.02367875725030899 0.4656113386154175\n",
            "tensor(8.3597, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05625888840735156 1.0\n",
            "repr, std, cov, closs 0.001442225999198854 0.4948742687702179 1.1039943181856415e-08 0.02126917615532875 0.37456849217414856\n",
            "tensor(14.3970, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05808735832357314 1.0\n",
            "repr, std, cov, closs 0.0015376165974885225 0.4946044087409973 1.228822554821818e-07 0.035721465945243835 0.3060245215892792\n",
            "tensor(7.7303, grad_fn=<AddBackward0>) torch.float32\n",
            "5.162504980811407 0.05914186571675133 1.0\n",
            "repr, std, cov, closs 0.0013242724817246199 0.49384379386901855 1.5644304767192807e-06 0.05468317121267319 0.3145696222782135\n",
            "tensor(13.1186, grad_fn=<AddBackward0>) torch.float32\n",
            "5.0 0.057280202088498315 1.0\n",
            "repr, std, cov, closs 0.001046986086294055 0.49350249767303467 2.8518745693872916e-06 0.08435922861099243 0.2854461669921875\n",
            "tensor(7.3485, grad_fn=<AddBackward0>) torch.float32\n",
            "4.910849329793843 0.05625888840735156 1.0\n",
            "repr, std, cov, closs 0.0014106122544035316 0.4904162585735321 4.902832006337121e-05 0.11698592454195023 0.2650420367717743\n",
            "tensor(13.3837, grad_fn=<AddBackward0>) torch.float32\n",
            "4.756265948456273 0.054487974942843666 1.0\n",
            "repr, std, cov, closs 0.0007582295802421868 0.4918466806411743 1.764562512107659e-05 0.11572021245956421 0.28317826986312866\n",
            "tensor(7.4650, grad_fn=<AddBackward0>) torch.float32\n",
            "4.704259581030575 0.05389218789563711 1.0\n",
            "repr, std, cov, closs 0.0007381105097010732 0.4880959689617157 0.00014563339937012643 0.12321948260068893 0.2628364861011505\n",
            "tensor(13.6212, grad_fn=<AddBackward0>) torch.float32\n",
            "4.556179217759504 0.05219577326893609 1.0\n",
            "repr, std, cov, closs 0.0005005862331017852 0.49219265580177307 1.2056851119268686e-05 0.11560215055942535 0.2684807777404785\n",
            "tensor(7.5625, grad_fn=<AddBackward0>) torch.float32\n",
            "4.510867016328032 0.051831859964197195 1.0\n",
            "repr, std, cov, closs 0.000487723940750584 0.4897187352180481 6.297224899753928e-05 0.10967256128787994 0.27866339683532715\n",
            "tensor(13.0367, grad_fn=<AddBackward0>) torch.float32\n",
            "4.47047146013085 0.051935575515985544 1.0\n",
            "repr, std, cov, closs 0.0004196498775854707 0.49302035570144653 5.135326318850275e-06 0.10831599682569504 0.25312092900276184\n",
            "tensor(7.3121, grad_fn=<AddBackward0>) torch.float32\n",
            "4.395153117123986 0.051111627367070304 1.0\n",
            "repr, std, cov, closs 0.00044597056694328785 0.48751887679100037 0.00015578631428070366 0.08923604339361191 0.26335853338241577\n",
            "tensor(12.8428, grad_fn=<AddBackward0>) torch.float32\n",
            "4.325424838596704 0.050351051751751016 1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-88eebbb95fa5>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# agent.train_ae(train_loader, optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# agent.train_jepa(train_loader, optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_jepa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# state = buffer[7][80][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-81951286ae0a>\u001b[0m in \u001b[0;36mtrain_jepa\u001b[0;34m(self, dataloader, c_loader, optim, bptt)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# optim.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_coeff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print(i)\n",
        "    # agent.train_ae(train_loader, optim)\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "    # state = buffer[7][80][0]\n",
        "    # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    # out= agent.deconv(sx_).squeeze(0)\n",
        "    # print(out.shape)\n",
        "    # imshow(state.detach().cpu())\n",
        "    # imshow(out.detach().cpu())\n",
        "\n",
        "# 10 epochs 15m23s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PraFUAPB3j7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ded1b6-e17d-44fe-fe55-080b58724f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "<ipython-input-61-5999dd6ec2cf>:24: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3675.)\n",
            "  bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "search -0.004781814757734537\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "search -0.004781814757734537\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "tcost icost -0.004781814757734537 0.0\n",
            "search -0.004781814757734537\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "tcost icost -0.0047865756787359715 0.0\n",
            "search -0.0047865756787359715\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "tcost icost -0.004781249910593033 0.0\n",
            "search -0.004781249910593033\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "tcost icost -0.004786956124007702 0.0\n",
            "search -0.004786956124007702\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "tcost icost -0.0047876848839223385 0.0\n",
            "search -0.0047876848839223385\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "tcost icost -0.004786223638802767 0.0\n",
            "search -0.004786223638802767\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "tcost icost -0.004787627141922712 0.0\n",
            "search -0.004787627141922712\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "tcost icost -0.004785649944096804 0.0\n",
            "search -0.004785649944096804\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "tcost icost -0.004787559621036053 0.0\n",
            "search -0.004787559621036053\n",
            "ded\n",
            "time\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    agent.eval()\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # out = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Parameter(torch.empty((4,5,3),device=device)) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "xx = torch.split(x, 5, dim=1)\n",
        "for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    la, lact = quantizer(x)\n",
        "# print(xx)\n",
        "print(x)\n",
        "print(la)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_VgsenYLpM",
        "outputId": "59a873c2-964c-408a-e827-a71735049d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[ 0.0802,  0.3557,  0.4046],\n",
            "         [ 0.4610,  0.2339, -0.2854],\n",
            "         [-0.4339,  0.3213, -0.1077],\n",
            "         [-0.2197,  0.1823,  0.4601],\n",
            "         [ 0.0789,  0.1214, -0.0021]],\n",
            "\n",
            "        [[ 0.3509, -0.3400, -0.0577],\n",
            "         [-0.3121, -0.3316,  0.1402],\n",
            "         [-0.3047,  0.1295, -0.0393],\n",
            "         [-0.1396, -0.0857, -0.3933],\n",
            "         [ 0.2932, -0.0498,  0.4478]],\n",
            "\n",
            "        [[-0.0607,  0.2992,  0.2298],\n",
            "         [ 0.1823, -0.0217,  0.3734],\n",
            "         [ 0.3363, -0.1199, -0.3895],\n",
            "         [ 0.4462,  0.1263, -0.3820],\n",
            "         [ 0.0985, -0.0637, -0.1477]],\n",
            "\n",
            "        [[ 0.4375, -0.0122, -0.4023],\n",
            "         [-0.3738, -0.0780, -0.3988],\n",
            "         [-0.3659, -0.1077,  0.4109],\n",
            "         [ 0.2406,  0.0619,  0.2601],\n",
            "         [ 0.0410, -0.3293,  0.3457]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dca2d4-faaa-4a64-e3fd-442b1d0d86f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "search 0.4267578125\n",
            "tcost icost 0.0068817138671875 0.4227501153945923\n",
            "tcost icost 0.0068817138671875 0.42038026452064514\n",
            "tcost icost 0.0068817138671875 0.4203834533691406\n",
            "search 0.42724609375\n",
            "tcost icost 0.00701141357421875 0.41959837079048157\n",
            "tcost icost 0.00701141357421875 0.4229119122028351\n",
            "tcost icost 0.00701141357421875 0.41988620162010193\n",
            "search 0.427001953125\n",
            "tcost icost 0.0071563720703125 0.42026636004447937\n",
            "tcost icost 0.006908416748046875 0.4208675026893616\n",
            "tcost icost 0.006908416748046875 0.42065346240997314\n",
            "search 0.427490234375\n",
            "tcost icost 0.007720947265625 0.4204835295677185\n",
            "tcost icost 0.006778717041015625 0.4207017421722412\n",
            "tcost icost 0.006778717041015625 0.42370063066482544\n",
            "search 0.430419921875\n",
            "tcost icost 0.007720947265625 0.41666579246520996\n",
            "tcost icost 0.00717926025390625 0.41639062762260437\n",
            "tcost icost 0.00717926025390625 0.41873085498809814\n",
            "search 0.42578125\n",
            "tcost icost 0.007602691650390625 0.41461166739463806\n",
            "tcost icost 0.007038116455078125 0.4142364263534546\n",
            "tcost icost 0.007038116455078125 0.4192182123661041\n",
            "search 0.42626953125\n",
            "tcost icost 0.00725555419921875 0.4157907962799072\n",
            "tcost icost 0.007198333740234375 0.41566720604896545\n",
            "tcost icost 0.007198333740234375 0.4143744111061096\n",
            "search 0.42138671875\n",
            "tcost icost 0.00766754150390625 0.4199468493461609\n",
            "tcost icost 0.007152557373046875 0.4162716269493103\n",
            "tcost icost 0.007152557373046875 0.41685113310813904\n",
            "search 0.423828125\n",
            "tcost icost 0.007740020751953125 0.41392895579338074\n",
            "tcost icost 0.00731658935546875 0.4155501425266266\n",
            "tcost icost 0.00731658935546875 0.4139297306537628\n",
            "search 0.421142578125\n",
            "tcost icost 0.00806427001953125 0.4149298667907715\n",
            "tcost icost 0.0074005126953125 0.41616058349609375\n",
            "tcost icost 0.0074005126953125 0.4179653525352478\n",
            "search 0.42529296875\n",
            "tcost icost 0.00792694091796875 0.4189217686653137\n",
            "tcost icost 0.007717132568359375 0.41556206345558167\n",
            "tcost icost 0.007717132568359375 0.41895371675491333\n",
            "search 0.4267578125\n",
            "tcost icost 0.0079498291015625 0.4184076189994812\n",
            "tcost icost 0.007381439208984375 0.4161761403083801\n",
            "tcost icost 0.007381439208984375 0.4159010946750641\n",
            "search 0.42333984375\n",
            "tcost icost 0.00800323486328125 0.418245792388916\n",
            "tcost icost 0.007080078125 0.41718530654907227\n",
            "tcost icost 0.007080078125 0.4172084927558899\n",
            "search 0.42431640625\n",
            "tcost icost 0.008026123046875 0.41619911789894104\n",
            "tcost icost 0.007404327392578125 0.41738802194595337\n",
            "tcost icost 0.007404327392578125 0.41722044348716736\n",
            "search 0.424560546875\n",
            "tcost icost 0.00789642333984375 0.4176567792892456\n",
            "tcost icost 0.0080413818359375 0.4150907099246979\n",
            "tcost icost 0.0080413818359375 0.41692984104156494\n",
            "search 0.425048828125\n",
            "tcost icost 0.00792694091796875 0.41322049498558044\n",
            "tcost icost 0.00753021240234375 0.4144574701786041\n",
            "tcost icost 0.00753021240234375 0.41423463821411133\n",
            "search 0.421875\n",
            "tcost icost 0.00785064697265625 0.41652828454971313\n",
            "tcost icost 0.0080108642578125 0.4162776470184326\n",
            "tcost icost 0.0080108642578125 0.4128851890563965\n",
            "search 0.4208984375\n",
            "tcost icost 0.0074462890625 0.4190939962863922\n",
            "tcost icost 0.00713348388671875 0.4169134199619293\n",
            "tcost icost 0.00713348388671875 0.41814470291137695\n",
            "search 0.42529296875\n",
            "tcost icost 0.008056640625 0.4156309962272644\n",
            "tcost icost 0.00737762451171875 0.4189251959323883\n",
            "tcost icost 0.00737762451171875 0.41939181089401245\n",
            "search 0.4267578125\n",
            "tcost icost 0.0079498291015625 0.41759106516838074\n",
            "tcost icost 0.00691986083984375 0.4181256890296936\n",
            "tcost icost 0.00691986083984375 0.4192677438259125\n",
            "search 0.426025390625\n",
            "tcost icost 0.00730133056640625 0.42225831747055054\n",
            "tcost icost 0.00737762451171875 0.4192284345626831\n",
            "tcost icost 0.00737762451171875 0.4182921051979065\n",
            "search 0.425537109375\n",
            "tcost icost 0.00768280029296875 0.41918236017227173\n",
            "tcost icost 0.006923675537109375 0.4189715087413788\n",
            "tcost icost 0.006923675537109375 0.4235202968120575\n",
            "search 0.430419921875\n",
            "tcost icost 0.007396697998046875 0.4192553460597992\n",
            "tcost icost 0.007396697998046875 0.41872844099998474\n",
            "tcost icost 0.007396697998046875 0.4189111292362213\n",
            "search 0.42626953125\n",
            "tcost icost 0.007442474365234375 0.42024558782577515\n",
            "tcost icost 0.00720977783203125 0.42002010345458984\n",
            "tcost icost 0.00720977783203125 0.41982418298721313\n",
            "search 0.42724609375\n",
            "tcost icost 0.007244110107421875 0.42314401268959045\n",
            "tcost icost 0.0069580078125 0.4230886399745941\n",
            "tcost icost 0.0069580078125 0.4235512316226959\n",
            "search 0.4306640625\n",
            "tcost icost 0.007610321044921875 0.416993647813797\n",
            "tcost icost 0.006595611572265625 0.41648155450820923\n",
            "tcost icost 0.006595611572265625 0.41679590940475464\n",
            "search 0.42333984375\n",
            "tcost icost 0.00650787353515625 0.422334760427475\n",
            "tcost icost 0.00640106201171875 0.4203425347805023\n",
            "tcost icost 0.00640106201171875 0.4215894639492035\n",
            "search 0.427978515625\n",
            "tcost icost 0.00710296630859375 0.4193476736545563\n",
            "tcost icost 0.006786346435546875 0.4192248284816742\n",
            "tcost icost 0.006786346435546875 0.4192248284816742\n",
            "search 0.426025390625\n",
            "tcost icost 0.006793975830078125 0.41673094034194946\n",
            "tcost icost 0.006793975830078125 0.41673097014427185\n",
            "tcost icost 0.006793975830078125 0.41673094034194946\n",
            "search 0.423583984375\n",
            "tcost icost 0.006511688232421875 0.4189456105232239\n",
            "tcost icost 0.0076446533203125 0.424368679523468\n",
            "tcost icost 0.0076446533203125 0.41993582248687744\n",
            "search 0.427490234375\n",
            "tcost icost 0.007297515869140625 0.4174036979675293\n",
            "tcost icost 0.007022857666015625 0.41758114099502563\n",
            "tcost icost 0.007022857666015625 0.41846704483032227\n",
            "search 0.425537109375\n",
            "tcost icost 0.00682830810546875 0.4193837642669678\n",
            "tcost icost 0.00644683837890625 0.4197289049625397\n",
            "tcost icost 0.00644683837890625 0.41971537470817566\n",
            "search 0.426025390625\n",
            "tcost icost 0.0071868896484375 0.4226478040218353\n",
            "tcost icost 0.006931304931640625 0.41913333535194397\n",
            "tcost icost 0.006931304931640625 0.41878893971443176\n",
            "search 0.425537109375\n",
            "tcost icost 0.0074462890625 0.4186985194683075\n",
            "tcost icost 0.007144927978515625 0.42009586095809937\n",
            "tcost icost 0.007144927978515625 0.4188660979270935\n",
            "search 0.426025390625\n",
            "tcost icost 0.00664520263671875 0.4219304621219635\n",
            "tcost icost 0.006374359130859375 0.4219818115234375\n",
            "tcost icost 0.006374359130859375 0.4221377968788147\n",
            "search 0.428466796875\n",
            "tcost icost 0.007236480712890625 0.4220695197582245\n",
            "tcost icost 0.006450653076171875 0.423829048871994\n",
            "tcost icost 0.006450653076171875 0.42165690660476685\n",
            "search 0.427978515625\n",
            "tcost icost 0.007579803466796875 0.42182132601737976\n",
            "tcost icost 0.006542205810546875 0.42193758487701416\n",
            "tcost icost 0.006542205810546875 0.42191287875175476\n",
            "search 0.428466796875\n",
            "tcost icost 0.007282257080078125 0.4224070906639099\n",
            "tcost icost 0.006511688232421875 0.4217614531517029\n",
            "tcost icost 0.006511688232421875 0.4223577380180359\n",
            "search 0.428955078125\n",
            "tcost icost 0.006534576416015625 0.42422762513160706\n",
            "tcost icost 0.006366729736328125 0.42273619771003723\n",
            "tcost icost 0.006366729736328125 0.4216693043708801\n",
            "search 0.427978515625\n",
            "tcost icost 0.00688934326171875 0.42376285791397095\n",
            "tcost icost 0.00666046142578125 0.4214319884777069\n",
            "tcost icost 0.00666046142578125 0.42151010036468506\n",
            "search 0.42822265625\n",
            "tcost icost 0.00640869140625 0.4223572015762329\n",
            "tcost icost 0.00640869140625 0.4225218892097473\n",
            "tcost icost 0.00640869140625 0.4223330020904541\n",
            "search 0.4287109375\n",
            "tcost icost 0.00716400146484375 0.4222349226474762\n",
            "tcost icost 0.00641632080078125 0.42222511768341064\n",
            "tcost icost 0.00641632080078125 0.42228925228118896\n",
            "search 0.4287109375\n",
            "tcost icost 0.007476806640625 0.4246533215045929\n",
            "tcost icost 0.00667572021484375 0.42219316959381104\n",
            "tcost icost 0.00667572021484375 0.42290395498275757\n",
            "search 0.429443359375\n",
            "tcost icost 0.007274627685546875 0.4230166971683502\n",
            "tcost icost 0.006988525390625 0.4248340129852295\n",
            "tcost icost 0.006988525390625 0.4218064844608307\n",
            "search 0.428955078125\n",
            "tcost icost 0.0075836181640625 0.4219200909137726\n",
            "tcost icost 0.006511688232421875 0.4266873002052307\n",
            "tcost icost 0.006511688232421875 0.4222583472728729\n",
            "search 0.428955078125\n",
            "tcost icost 0.006378173828125 0.4229772984981537\n",
            "tcost icost 0.006671905517578125 0.4232023358345032\n",
            "tcost icost 0.006671905517578125 0.4228248596191406\n",
            "search 0.429443359375\n",
            "tcost icost 0.00742340087890625 0.4234439432621002\n",
            "tcost icost 0.00637054443359375 0.4300937056541443\n",
            "tcost icost 0.00637054443359375 0.4282096326351166\n",
            "search 0.4345703125\n",
            "tcost icost 0.00762939453125 0.4234260320663452\n",
            "tcost icost 0.00650787353515625 0.42343243956565857\n",
            "tcost icost 0.00650787353515625 0.42340245842933655\n",
            "search 0.429931640625\n",
            "tcost icost 0.00727081298828125 0.423720121383667\n",
            "tcost icost 0.006488800048828125 0.4252817630767822\n",
            "tcost icost 0.006488800048828125 0.42335039377212524\n",
            "search 0.429931640625\n",
            "tcost icost 0.007114410400390625 0.4262552261352539\n",
            "tcost icost 0.006885528564453125 0.4252522885799408\n",
            "tcost icost 0.006885528564453125 0.42324891686439514\n",
            "search 0.43017578125\n",
            "tcost icost 0.006832122802734375 0.4231823980808258\n",
            "tcost icost 0.006443023681640625 0.4232022166252136\n",
            "tcost icost 0.006443023681640625 0.423202246427536\n",
            "search 0.429443359375\n",
            "tcost icost 0.00778961181640625 0.4227321147918701\n",
            "tcost icost 0.006439208984375 0.4243660867214203\n",
            "tcost icost 0.006439208984375 0.4227844774723053\n",
            "search 0.42919921875\n",
            "tcost icost 0.00652313232421875 0.42323410511016846\n",
            "tcost icost 0.006435394287109375 0.42406007647514343\n",
            "tcost icost 0.006435394287109375 0.42299360036849976\n",
            "search 0.429443359375\n",
            "tcost icost 0.0074005126953125 0.4225831925868988\n",
            "tcost icost 0.00659942626953125 0.42323774099349976\n",
            "tcost icost 0.00659942626953125 0.42578256130218506\n",
            "search 0.432373046875\n",
            "tcost icost 0.006984710693359375 0.42775121331214905\n",
            "tcost icost 0.00635528564453125 0.42777490615844727\n",
            "tcost icost 0.00635528564453125 0.4275726079940796\n",
            "search 0.433837890625\n",
            "tcost icost 0.00690460205078125 0.4279848337173462\n",
            "tcost icost 0.006378173828125 0.42810165882110596\n",
            "tcost icost 0.006378173828125 0.4279903173446655\n",
            "search 0.434326171875\n",
            "tcost icost 0.00688934326171875 0.4291456639766693\n",
            "tcost icost 0.006381988525390625 0.43085557222366333\n",
            "tcost icost 0.006381988525390625 0.42777204513549805\n",
            "search 0.43408203125\n",
            "tcost icost 0.006847381591796875 0.42776861786842346\n",
            "tcost icost 0.006420135498046875 0.4288776218891144\n",
            "tcost icost 0.006420135498046875 0.42926791310310364\n",
            "search 0.435546875\n",
            "tcost icost 0.00716400146484375 0.427966445684433\n",
            "tcost icost 0.00641632080078125 0.42944076657295227\n",
            "tcost icost 0.00641632080078125 0.4292048513889313\n",
            "search 0.435546875\n",
            "tcost icost 0.0070648193359375 0.43091028928756714\n",
            "tcost icost 0.0068511962890625 0.4292543828487396\n",
            "tcost icost 0.0068511962890625 0.42946159839630127\n",
            "search 0.436279296875\n",
            "tcost icost 0.00717926025390625 0.4294414222240448\n",
            "tcost icost 0.00717926025390625 0.4294414222240448\n",
            "tcost icost 0.00717926025390625 0.4324800968170166\n",
            "search 0.439453125\n",
            "tcost icost 0.006900787353515625 0.42963123321533203\n",
            "tcost icost 0.006443023681640625 0.43057766556739807\n",
            "tcost icost 0.006443023681640625 0.429871529340744\n",
            "search 0.436279296875\n",
            "tcost icost 0.0065155029296875 0.42978930473327637\n",
            "tcost icost 0.006458282470703125 0.43049684166908264\n",
            "tcost icost 0.006458282470703125 0.42984873056411743\n",
            "search 0.436279296875\n",
            "tcost icost 0.006961822509765625 0.42971161007881165\n",
            "tcost icost 0.006771087646484375 0.4302694797515869\n",
            "tcost icost 0.006771087646484375 0.42954665422439575\n",
            "search 0.436279296875\n",
            "tcost icost 0.007114410400390625 0.43086808919906616\n",
            "tcost icost 0.006397247314453125 0.4313150644302368\n",
            "tcost icost 0.006397247314453125 0.4299645721912384\n",
            "search 0.436279296875\n",
            "tcost icost 0.006832122802734375 0.43276211619377136\n",
            "tcost icost 0.006439208984375 0.43254554271698\n",
            "tcost icost 0.006439208984375 0.43073025345802307\n",
            "search 0.43701171875\n",
            "tcost icost 0.006885528564453125 0.43429234623908997\n",
            "tcost icost 0.006885528564453125 0.43133899569511414\n",
            "tcost icost 0.006885528564453125 0.4323219656944275\n",
            "search 0.439208984375\n",
            "tcost icost 0.00647735595703125 0.43114563822746277\n",
            "tcost icost 0.0064239501953125 0.43102964758872986\n",
            "tcost icost 0.0064239501953125 0.43072840571403503\n",
            "search 0.43701171875\n",
            "tcost icost 0.00714111328125 0.4312603771686554\n",
            "tcost icost 0.00641632080078125 0.43119367957115173\n",
            "tcost icost 0.00641632080078125 0.4331497848033905\n",
            "search 0.439453125\n",
            "tcost icost 0.006938934326171875 0.43150562047958374\n",
            "tcost icost 0.00634765625 0.4317573308944702\n",
            "tcost icost 0.00634765625 0.4317573308944702\n",
            "search 0.43798828125\n",
            "tcost icost 0.007167816162109375 0.43216472864151\n",
            "tcost icost 0.00666046142578125 0.43483495712280273\n",
            "tcost icost 0.00666046142578125 0.432024210691452\n",
            "search 0.438720703125\n",
            "tcost icost 0.0080718994140625 0.432360976934433\n",
            "tcost icost 0.007755279541015625 0.4320928454399109\n",
            "tcost icost 0.007755279541015625 0.4353296160697937\n",
            "search 0.443115234375\n",
            "tcost icost 0.007442474365234375 0.4341348111629486\n",
            "tcost icost 0.007442474365234375 0.4332088828086853\n",
            "tcost icost 0.007442474365234375 0.4358179569244385\n",
            "search 0.443115234375\n",
            "tcost icost 0.0079345703125 0.43486326932907104\n",
            "tcost icost 0.007480621337890625 0.4322868883609772\n",
            "tcost icost 0.007480621337890625 0.43298840522766113\n",
            "search 0.440673828125\n",
            "tcost icost 0.0079345703125 0.43534088134765625\n",
            "tcost icost 0.007511138916015625 0.4322958290576935\n",
            "tcost icost 0.007511138916015625 0.43361514806747437\n",
            "search 0.441162109375\n",
            "tcost icost 0.00791168212890625 0.4369770884513855\n",
            "tcost icost 0.006805419921875 0.4410897493362427\n",
            "tcost icost 0.006805419921875 0.4366415739059448\n",
            "search 0.443359375\n",
            "tcost icost 0.007598876953125 0.44060951471328735\n",
            "tcost icost 0.00679779052734375 0.4394606053829193\n",
            "tcost icost 0.00679779052734375 0.4408029019832611\n",
            "search 0.44775390625\n",
            "tcost icost 0.0079803466796875 0.4407057464122772\n",
            "tcost icost 0.0078125 0.44017791748046875\n",
            "tcost icost 0.0078125 0.44072815775871277\n",
            "search 0.448486328125\n",
            "tcost icost 0.00748443603515625 0.4408409893512726\n",
            "tcost icost 0.006694793701171875 0.4409260153770447\n",
            "tcost icost 0.006694793701171875 0.4429701566696167\n",
            "search 0.449462890625\n",
            "tcost icost 0.007801055908203125 0.4410158395767212\n",
            "tcost icost 0.00691986083984375 0.44499486684799194\n",
            "tcost icost 0.00691986083984375 0.44094786047935486\n",
            "search 0.44775390625\n",
            "tcost icost 0.0080108642578125 0.4412671625614166\n",
            "tcost icost 0.00807952880859375 0.4407764673233032\n",
            "tcost icost 0.00807952880859375 0.4404815435409546\n",
            "search 0.448486328125\n",
            "tcost icost 0.00812530517578125 0.4420020878314972\n",
            "tcost icost 0.0080718994140625 0.4408130347728729\n",
            "tcost icost 0.0080718994140625 0.44081300497055054\n",
            "search 0.448974609375\n",
            "tcost icost 0.0080413818359375 0.4413681924343109\n",
            "tcost icost 0.007518768310546875 0.44124919176101685\n",
            "tcost icost 0.007518768310546875 0.44124919176101685\n",
            "search 0.44873046875\n",
            "tcost icost 0.00797271728515625 0.4410771131515503\n",
            "tcost icost 0.00809478759765625 0.44190284609794617\n",
            "tcost icost 0.00809478759765625 0.44212326407432556\n",
            "search 0.4501953125\n",
            "tcost icost 0.007373809814453125 0.44114699959754944\n",
            "tcost icost 0.007373809814453125 0.44261589646339417\n",
            "tcost icost 0.007373809814453125 0.44236963987350464\n",
            "search 0.44970703125\n",
            "tcost icost 0.00775909423828125 0.4413229525089264\n",
            "tcost icost 0.007381439208984375 0.44431355595588684\n",
            "tcost icost 0.007381439208984375 0.44203445315361023\n",
            "search 0.449462890625\n",
            "tcost icost 0.0079193115234375 0.44124579429626465\n",
            "tcost icost 0.007354736328125 0.4409184455871582\n",
            "tcost icost 0.007354736328125 0.4411141872406006\n",
            "search 0.448486328125\n",
            "tcost icost 0.00794219970703125 0.44080960750579834\n",
            "tcost icost 0.007747650146484375 0.44098785519599915\n",
            "tcost icost 0.007747650146484375 0.44098785519599915\n",
            "search 0.44873046875\n",
            "tcost icost 0.00768280029296875 0.4408440887928009\n",
            "tcost icost 0.00768280029296875 0.4408177137374878\n",
            "tcost icost 0.00768280029296875 0.4410296380519867\n",
            "search 0.448486328125\n",
            "tcost icost 0.0079498291015625 0.4408077001571655\n",
            "tcost icost 0.00785064697265625 0.44100213050842285\n",
            "tcost icost 0.00785064697265625 0.4402454197406769\n",
            "search 0.447998046875\n",
            "tcost icost 0.007564544677734375 0.4415290653705597\n",
            "tcost icost 0.007232666015625 0.4405279755592346\n",
            "tcost icost 0.007232666015625 0.44151678681373596\n",
            "search 0.44873046875\n",
            "tcost icost 0.007732391357421875 0.44351711869239807\n",
            "tcost icost 0.007274627685546875 0.44306710362434387\n",
            "tcost icost 0.007274627685546875 0.44306710362434387\n",
            "search 0.450439453125\n",
            "tcost icost 0.007843017578125 0.4437074661254883\n",
            "tcost icost 0.00710296630859375 0.4434514343738556\n",
            "tcost icost 0.00710296630859375 0.4438481330871582\n",
            "search 0.450927734375\n",
            "tcost icost 0.007801055908203125 0.444305956363678\n",
            "tcost icost 0.007450103759765625 0.44403019547462463\n",
            "tcost icost 0.007450103759765625 0.4442180395126343\n",
            "search 0.451904296875\n",
            "tcost icost 0.00762939453125 0.4443499743938446\n",
            "tcost icost 0.006832122802734375 0.447020024061203\n",
            "tcost icost 0.006832122802734375 0.4447745382785797\n",
            "search 0.45166015625\n",
            "tcost icost 0.007175445556640625 0.44360414147377014\n",
            "tcost icost 0.00685882568359375 0.446120947599411\n",
            "tcost icost 0.00685882568359375 0.44405481219291687\n",
            "search 0.450927734375\n",
            "tcost icost 0.00748443603515625 0.4451983571052551\n",
            "tcost icost 0.00716400146484375 0.4446212947368622\n",
            "tcost icost 0.00716400146484375 0.4446433484554291\n",
            "search 0.45166015625\n",
            "tcost icost 0.007732391357421875 0.44771960377693176\n",
            "tcost icost 0.0079498291015625 0.4444754123687744\n",
            "tcost icost 0.0079498291015625 0.4448660612106323\n",
            "search 0.452880859375\n",
            "tcost icost 0.007503509521484375 0.44475820660591125\n",
            "tcost icost 0.0069732666015625 0.44470447301864624\n",
            "tcost icost 0.0069732666015625 0.44425395131111145\n",
            "search 0.451416015625\n",
            "tcost icost 0.006832122802734375 0.4439508020877838\n",
            "tcost icost 0.006439208984375 0.4426433742046356\n",
            "tcost icost 0.006439208984375 0.4423884451389313\n",
            "search 0.44873046875\n",
            "tcost icost 0.006450653076171875 0.44785451889038086\n",
            "tcost icost 0.006435394287109375 0.44555649161338806\n",
            "tcost icost 0.006435394287109375 0.44555649161338806\n",
            "search 0.451904296875\n",
            "tcost icost 0.00682830810546875 0.44807642698287964\n",
            "tcost icost 0.0064849853515625 0.4453577399253845\n",
            "tcost icost 0.0064849853515625 0.4453577399253845\n",
            "search 0.451904296875\n",
            "tcost icost 0.0066680908203125 0.44589027762413025\n",
            "tcost icost 0.006351470947265625 0.446077436208725\n",
            "tcost icost 0.006351470947265625 0.446077436208725\n",
            "search 0.452392578125\n",
            "tcost icost 0.006832122802734375 0.44116759300231934\n",
            "tcost icost 0.00640106201171875 0.44104328751564026\n",
            "tcost icost 0.00640106201171875 0.44104328751564026\n",
            "search 0.447509765625\n",
            "tcost icost 0.007335662841796875 0.4478681981563568\n",
            "tcost icost 0.006778717041015625 0.44729894399642944\n",
            "tcost icost 0.006778717041015625 0.4472759962081909\n",
            "search 0.4541015625\n",
            "tcost icost 0.0074920654296875 0.4482922852039337\n",
            "tcost icost 0.007213592529296875 0.44925928115844727\n",
            "tcost icost 0.007213592529296875 0.44834384322166443\n",
            "search 0.45556640625\n",
            "tcost icost 0.007366180419921875 0.4485343098640442\n",
            "tcost icost 0.007080078125 0.44847339391708374\n",
            "tcost icost 0.007080078125 0.4487372636795044\n",
            "search 0.455810546875\n",
            "tcost icost 0.008026123046875 0.44766756892204285\n",
            "tcost icost 0.00716400146484375 0.44750162959098816\n",
            "tcost icost 0.00716400146484375 0.4501399099826813\n",
            "search 0.457275390625\n",
            "tcost icost 0.007488250732421875 0.4471262991428375\n",
            "tcost icost 0.00637054443359375 0.44942936301231384\n",
            "tcost icost 0.00637054443359375 0.4472704827785492\n",
            "search 0.45361328125\n",
            "tcost icost 0.00751495361328125 0.44205036759376526\n",
            "tcost icost 0.00751495361328125 0.44205036759376526\n",
            "tcost icost 0.00751495361328125 0.44205036759376526\n",
            "search 0.44970703125\n",
            "tcost icost 0.0079345703125 0.43862515687942505\n",
            "tcost icost 0.00785064697265625 0.4386361241340637\n",
            "tcost icost 0.00785064697265625 0.44065579771995544\n",
            "search 0.448486328125\n",
            "ded\n",
            "time\n",
            "21 #### train ####\n",
            "repr, std, cov, conv, closs 0.02945471554994583 0.327880859375 0.31918826699256897 0.0634469985961914 0.01601552590727806\n",
            "46.925490473840185 7.392640060334186 1.0\n",
            "repr, std, cov, conv, closs 0.03686666488647461 0.331787109375 0.2648024559020996 0.0675748884677887 0.01562986522912979\n",
            "47.11347417642725 7.526844710428666 1.0\n",
            "repr, std, cov, conv, closs 0.032552897930145264 0.333984375 0.3008521795272827 0.059804193675518036 0.015541963279247284\n",
            "47.53919549255947 7.717291288961148 1.0\n",
            "repr, std, cov, conv, closs 0.034827157855033875 0.334228515625 0.291976660490036 0.06965071707963943 0.015591872856020927\n",
            "47.77736733760687 7.818220237111288 1.0\n",
            "repr, std, cov, conv, closs 0.03266805782914162 0.333740234375 0.3150567412376404 0.05731627345085144 0.030288174748420715\n",
            "47.82514470494447 7.976079054470414 1.0\n",
            "repr, std, cov, conv, closs 0.03368587791919708 0.334228515625 0.266230970621109 0.06390094757080078 0.0006099424208514392\n",
            "48.11281390756523 8.088472895719768 1.0\n",
            "repr, std, cov, conv, closs 0.036261703819036484 0.333740234375 0.307547390460968 0.060426995158195496 0.02121959812939167\n",
            "48.257296735842445 8.161561017257375 1.0\n",
            "repr, std, cov, conv, closs 0.03900273144245148 0.330078125 0.3315250873565674 0.06306350231170654 0.029244715347886086\n",
            "48.35385958661085 8.169722578274632 1.0\n",
            "repr, std, cov, conv, closs 0.036994680762290955 0.32470703125 0.3308931887149811 0.06045500561594963 0.004722394049167633\n",
            "47.968763662318544 7.960150792734154 1.0\n",
            "repr, std, cov, conv, closs 0.04432150721549988 0.320556640625 0.3577211797237396 0.07007986307144165 0.0015397153329104185\n",
            "47.63432142274007 7.833864495805746 1.0\n",
            "repr, std, cov, conv, closs 0.034891240298748016 0.32421875 0.33216166496276855 0.06898332387208939 0.0025457600131630898\n",
            "47.160587650603674 7.610055223119162 1.0\n",
            "repr, std, cov, conv, closs 0.028554361313581467 0.33154296875 0.3294844627380371 0.0631723552942276 0.003680998459458351\n",
            "46.73825682997955 7.526844710428666 1.0\n",
            "repr, std, cov, conv, closs 0.028072871267795563 0.326904296875 0.30789661407470703 0.05858589708805084 0.015906376764178276\n",
            "46.69156526471484 7.407432733094913 1.0\n",
            "repr, std, cov, conv, closs 0.042742770165205 0.322998046875 0.3534260392189026 0.05965282768011093 0.035275474190711975\n",
            "47.01938838027833 7.363143278898984 1.0\n",
            "repr, std, cov, conv, closs 0.03479210287332535 0.32861328125 0.30674540996551514 0.07145294547080994 0.008913529105484486\n",
            "47.44425952924147 7.2246328144569665 1.0\n",
            "repr, std, cov, conv, closs 0.036143794655799866 0.328857421875 0.33126452565193176 0.06972857564687729 0.0015431403880938888\n",
            "47.72963769990697 7.275357214562424 1.0\n",
            "repr, std, cov, conv, closs 0.04687732085585594 0.32861328125 0.3312234878540039 0.05352654308080673 0.01165681704878807\n",
            "48.16092672147279 7.304502324672662 1.0\n",
            "repr, std, cov, conv, closs 0.030400503426790237 0.33203125 0.2882832884788513 0.05183185264468193 0.014480320736765862\n",
            "48.35385958661085 7.319118633824331 1.0\n",
            "repr, std, cov, conv, closs 0.04044190049171448 0.332763671875 0.3120619058609009 0.05857604369521141 0.0008362189400941133\n",
            "49.03523147134977 7.451988589244286 1.0\n",
            "repr, std, cov, conv, closs 0.0411936491727829 0.330078125 0.30816513299942017 0.06591726839542389 0.0008208859944716096\n",
            "49.08426670282111 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.030319757759571075 0.3310546875 0.31061336398124695 0.05225894972681999 0.002719379495829344\n",
            "49.4783179480689 7.519325385043623 1.0\n",
            "repr, std, cov, conv, closs 0.03644060716032982 0.32861328125 0.3259038031101227 0.06254765391349792 0.023322559893131256\n",
            "49.330179370090356 7.579690950843743 1.0\n",
            "repr, std, cov, conv, closs 0.04108539596199989 0.330810546875 0.31582677364349365 0.06975989788770676 0.00037092319689691067\n",
            "49.23166680481393 7.678820322319725 1.0\n",
            "repr, std, cov, conv, closs 0.026471637189388275 0.33349609375 0.3041272759437561 0.0687018483877182 0.02218148671090603\n",
            "49.182484320493444 7.7714746614764 1.0\n",
            "repr, std, cov, conv, closs 0.038767144083976746 0.332763671875 0.3002321720123291 0.0661235898733139 0.030859429389238358\n",
            "49.62690138634525 7.976079054470414 1.0\n",
            "repr, std, cov, conv, closs 0.04006534069776535 0.329345703125 0.307106077671051 0.0630357414484024 0.021613191813230515\n",
            "50.02530893325793 8.064255927106414 1.0\n",
            "repr, std, cov, conv, closs 0.03023051656782627 0.32958984375 0.3597344756126404 0.05400259420275688 0.03212813660502434\n",
            "49.72620481601932 8.088472895719768 1.0\n",
            "repr, std, cov, conv, closs 0.03837570175528526 0.3359375 0.29680752754211426 0.05799705907702446 0.0004911364521831274\n",
            "49.72620481601932 8.056199727379036 1.0\n",
            "repr, std, cov, conv, closs 0.03707669675350189 0.3310546875 0.3132837414741516 0.06232535466551781 0.0016815703129395843\n",
            "49.52779626601696 8.13712522207835 1.0\n",
            "repr, std, cov, conv, closs 0.03809582442045212 0.32666015625 0.3387763500213623 0.062223926186561584 0.00026720052119344473\n",
            "49.379509549460444 8.040111464338896 1.0\n",
            "repr, std, cov, conv, closs 0.03729349374771118 0.326416015625 0.35562995076179504 0.06047782301902771 0.028797514736652374\n",
            "48.93730791820545 7.865246988319233 1.0\n",
            "repr, std, cov, conv, closs 0.045051224529743195 0.327880859375 0.34283334016799927 0.06388239562511444 0.011346714571118355\n",
            "48.693353728846894 7.787025382274013 1.0\n",
            "repr, std, cov, conv, closs 0.046617504209280014 0.324462890625 0.32345515489578247 0.06425592303276062 0.025990765541791916\n",
            "48.59611290692016 7.648181675925595 1.0\n",
            "repr, std, cov, conv, closs 0.033263564109802246 0.328857421875 0.36280959844589233 0.061373718082904816 0.0005924502620473504\n",
            "48.45061565964365 7.526844710428666 1.0\n",
            "repr, std, cov, conv, closs 0.037466369569301605 0.328125 0.29813316464424133 0.07321497052907944 0.0021549267694354057\n",
            "48.11281390756523 7.377876928600059 1.0\n",
            "repr, std, cov, conv, closs 0.045208126306533813 0.330322265625 0.3489632308483124 0.07453795522451401 0.014980498701334\n",
            "48.35385958661085 7.392640060334186 1.0\n",
            "tcost icost 0.002780914306640625 0.41897228360176086\n",
            "tcost icost 0.003284454345703125 0.4196327328681946\n",
            "tcost icost 0.003284454345703125 0.4195226728916168\n",
            "search 0.422607421875\n",
            "tcost icost 0.0034351348876953125 0.41905882954597473\n",
            "tcost icost 0.0028972625732421875 0.4205518364906311\n",
            "tcost icost 0.0028972625732421875 0.41834715008735657\n",
            "search 0.42138671875\n",
            "tcost icost 0.0031261444091796875 0.4171995222568512\n",
            "tcost icost 0.0028972625732421875 0.4160756468772888\n",
            "tcost icost 0.0028972625732421875 0.41729936003685\n",
            "search 0.420166015625\n",
            "tcost icost 0.002780914306640625 0.41583094000816345\n",
            "tcost icost 0.003284454345703125 0.41564837098121643\n",
            "tcost icost 0.003284454345703125 0.41482698917388916\n",
            "search 0.41796875\n",
            "tcost icost 0.0031337738037109375 0.4172188341617584\n",
            "tcost icost 0.00290679931640625 0.415690541267395\n",
            "tcost icost 0.00290679931640625 0.4166392982006073\n",
            "search 0.419677734375\n",
            "tcost icost 0.00363922119140625 0.4155253469944\n",
            "tcost icost 0.0033168792724609375 0.41327551007270813\n",
            "tcost icost 0.0033168792724609375 0.41495242714881897\n",
            "search 0.41845703125\n",
            "tcost icost 0.003757476806640625 0.4129236042499542\n",
            "tcost icost 0.00339508056640625 0.4109572470188141\n",
            "tcost icost 0.00339508056640625 0.411373108625412\n",
            "search 0.414794921875\n",
            "tcost icost 0.0029163360595703125 0.4108351171016693\n",
            "tcost icost 0.0034732818603515625 0.4102841913700104\n",
            "tcost icost 0.0034732818603515625 0.4122125208377838\n",
            "search 0.41552734375\n",
            "tcost icost 0.003231048583984375 0.4076095223426819\n",
            "tcost icost 0.0028133392333984375 0.40900489687919617\n",
            "tcost icost 0.0028133392333984375 0.4106142520904541\n",
            "search 0.41357421875\n",
            "tcost icost 0.003322601318359375 0.41091153025627136\n",
            "tcost icost 0.00289154052734375 0.4107944071292877\n",
            "tcost icost 0.00289154052734375 0.4091681241989136\n",
            "search 0.412109375\n",
            "tcost icost 0.0029315948486328125 0.406786173582077\n",
            "tcost icost 0.002674102783203125 0.408995121717453\n",
            "tcost icost 0.002674102783203125 0.40677258372306824\n",
            "search 0.409423828125\n",
            "tcost icost 0.0030574798583984375 0.4053567051887512\n",
            "tcost icost 0.002666473388671875 0.4071384072303772\n",
            "tcost icost 0.002666473388671875 0.4047043025493622\n",
            "search 0.407470703125\n",
            "tcost icost 0.0031948089599609375 0.4041869044303894\n",
            "tcost icost 0.002780914306640625 0.4041258990764618\n",
            "tcost icost 0.002780914306640625 0.4041258692741394\n",
            "search 0.40673828125\n",
            "tcost icost 0.0028171539306640625 0.402678519487381\n",
            "tcost icost 0.00334930419921875 0.4012397229671478\n",
            "tcost icost 0.00334930419921875 0.4026866853237152\n",
            "search 0.406005859375\n",
            "tcost icost 0.0033054351806640625 0.4027179479598999\n",
            "tcost icost 0.0028858184814453125 0.4036640226840973\n",
            "tcost icost 0.0028858184814453125 0.40276867151260376\n",
            "search 0.40576171875\n",
            "tcost icost 0.003131866455078125 0.4020152688026428\n",
            "tcost icost 0.002910614013671875 0.40204110741615295\n",
            "tcost icost 0.002910614013671875 0.4040101170539856\n",
            "search 0.406982421875\n",
            "tcost icost 0.00308990478515625 0.4010876715183258\n",
            "tcost icost 0.00286102294921875 0.40088045597076416\n",
            "tcost icost 0.00286102294921875 0.4027441143989563\n",
            "search 0.40576171875\n",
            "tcost icost 0.0030231475830078125 0.39844632148742676\n",
            "tcost icost 0.002780914306640625 0.39884570240974426\n",
            "tcost icost 0.002780914306640625 0.3987368941307068\n",
            "search 0.4013671875\n",
            "tcost icost 0.00308990478515625 0.4002439081668854\n",
            "tcost icost 0.0028705596923828125 0.39790353178977966\n",
            "tcost icost 0.0028705596923828125 0.39722466468811035\n",
            "search 0.400146484375\n",
            "tcost icost 0.00315093994140625 0.39545875787734985\n",
            "tcost icost 0.0034027099609375 0.3970440626144409\n",
            "tcost icost 0.0034027099609375 0.3950951397418976\n",
            "search 0.3984375\n",
            "tcost icost 0.0032806396484375 0.3932332396507263\n",
            "tcost icost 0.00286102294921875 0.39493033289909363\n",
            "tcost icost 0.00286102294921875 0.3949974775314331\n",
            "search 0.39794921875\n",
            "tcost icost 0.0027828216552734375 0.3920941948890686\n",
            "tcost icost 0.0027828216552734375 0.39169222116470337\n",
            "tcost icost 0.0027828216552734375 0.3929098844528198\n",
            "search 0.3955078125\n",
            "tcost icost 0.0028629302978515625 0.39141592383384705\n",
            "tcost icost 0.0028629302978515625 0.394993394613266\n",
            "tcost icost 0.0028629302978515625 0.3933756649494171\n",
            "search 0.396240234375\n",
            "tcost icost 0.0030765533447265625 0.3917482793331146\n",
            "tcost icost 0.00286102294921875 0.3901401162147522\n",
            "tcost icost 0.00286102294921875 0.3901401162147522\n",
            "search 0.39306640625\n",
            "tcost icost 0.0030765533447265625 0.38804391026496887\n",
            "tcost icost 0.002838134765625 0.3879423141479492\n",
            "tcost icost 0.002838134765625 0.3911936581134796\n",
            "search 0.39404296875\n",
            "tcost icost 0.0033721923828125 0.3896700143814087\n",
            "tcost icost 0.002857208251953125 0.3862791359424591\n",
            "tcost icost 0.002857208251953125 0.3880453407764435\n",
            "search 0.390869140625\n",
            "tcost icost 0.0030879974365234375 0.38804030418395996\n",
            "tcost icost 0.002899169921875 0.3852007985115051\n",
            "tcost icost 0.002899169921875 0.38804057240486145\n",
            "search 0.390869140625\n",
            "tcost icost 0.003063201904296875 0.3864663541316986\n",
            "tcost icost 0.00284576416015625 0.3864695131778717\n",
            "tcost icost 0.00284576416015625 0.388045072555542\n",
            "search 0.390869140625\n",
            "tcost icost 0.003269195556640625 0.38643747568130493\n",
            "tcost icost 0.00286865234375 0.38571491837501526\n",
            "tcost icost 0.00286865234375 0.38804227113723755\n",
            "search 0.390869140625\n",
            "tcost icost 0.002780914306640625 0.3864787220954895\n",
            "tcost icost 0.002780914306640625 0.38603317737579346\n",
            "tcost icost 0.002780914306640625 0.38491421937942505\n",
            "search 0.3876953125\n",
            "tcost icost 0.0045013427734375 0.38384759426116943\n",
            "tcost icost 0.003360748291015625 0.3839404881000519\n",
            "tcost icost 0.003360748291015625 0.3841750919818878\n",
            "search 0.3876953125\n",
            "tcost icost 0.003643035888671875 0.386043518781662\n",
            "tcost icost 0.00333404541015625 0.3858124613761902\n",
            "tcost icost 0.00333404541015625 0.3861130177974701\n",
            "search 0.3896484375\n",
            "tcost icost 0.003879547119140625 0.3866584599018097\n",
            "tcost icost 0.0033054351806640625 0.38457420468330383\n",
            "tcost icost 0.0033054351806640625 0.3851032853126526\n",
            "search 0.388427734375\n",
            "tcost icost 0.003910064697265625 0.3849910497665405\n",
            "tcost icost 0.003330230712890625 0.38516107201576233\n",
            "tcost icost 0.003330230712890625 0.38876381516456604\n",
            "search 0.39208984375\n",
            "tcost icost 0.0035610198974609375 0.3893846869468689\n",
            "tcost icost 0.0035610198974609375 0.3890360891819\n",
            "tcost icost 0.0035610198974609375 0.3875665068626404\n",
            "search 0.39111328125\n",
            "tcost icost 0.003986358642578125 0.3938947021961212\n",
            "tcost icost 0.0031261444091796875 0.3920849561691284\n",
            "tcost icost 0.0031261444091796875 0.390275239944458\n",
            "search 0.3935546875\n",
            "tcost icost 0.0039005279541015625 0.39170584082603455\n",
            "tcost icost 0.0032100677490234375 0.3905240595340729\n",
            "tcost icost 0.0032100677490234375 0.39237579703330994\n",
            "search 0.3955078125\n",
            "tcost icost 0.0038509368896484375 0.39240485429763794\n",
            "tcost icost 0.003139495849609375 0.39630627632141113\n",
            "tcost icost 0.003139495849609375 0.39630627632141113\n",
            "search 0.3994140625\n",
            "tcost icost 0.0037403106689453125 0.39383935928344727\n",
            "tcost icost 0.002864837646484375 0.39237841963768005\n",
            "tcost icost 0.002864837646484375 0.39317360520362854\n",
            "search 0.39599609375\n",
            "tcost icost 0.0033550262451171875 0.3955858051776886\n",
            "tcost icost 0.0033206939697265625 0.39590930938720703\n",
            "tcost icost 0.0033206939697265625 0.39405885338783264\n",
            "search 0.3974609375\n",
            "tcost icost 0.0030765533447265625 0.3951794505119324\n",
            "tcost icost 0.002437591552734375 0.3943566083908081\n",
            "tcost icost 0.002437591552734375 0.39533576369285583\n",
            "search 0.397705078125\n",
            "tcost icost 0.0033473968505859375 0.39813825488090515\n",
            "tcost icost 0.0024394989013671875 0.39585214853286743\n",
            "tcost icost 0.0024394989013671875 0.3978613018989563\n",
            "search 0.400390625\n",
            "tcost icost 0.003376007080078125 0.3955124020576477\n",
            "tcost icost 0.003345489501953125 0.39650148153305054\n",
            "tcost icost 0.003345489501953125 0.3967311382293701\n",
            "search 0.400146484375\n",
            "tcost icost 0.0036563873291015625 0.3967888057231903\n",
            "tcost icost 0.0034332275390625 0.3967476785182953\n",
            "tcost icost 0.0034332275390625 0.3968609869480133\n",
            "search 0.400390625\n",
            "tcost icost 0.0033130645751953125 0.3994900584220886\n",
            "tcost icost 0.0024318695068359375 0.4002421200275421\n",
            "tcost icost 0.0024318695068359375 0.3998960256576538\n",
            "search 0.40234375\n",
            "tcost icost 0.0026569366455078125 0.40120929479599\n",
            "tcost icost 0.0023403167724609375 0.4026812016963959\n",
            "tcost icost 0.0023403167724609375 0.40276098251342773\n",
            "search 0.4052734375\n",
            "tcost icost 0.0026683807373046875 0.40308257937431335\n",
            "tcost icost 0.0024204254150390625 0.402765691280365\n",
            "tcost icost 0.0024204254150390625 0.40316057205200195\n",
            "search 0.405517578125\n",
            "tcost icost 0.002552032470703125 0.40372103452682495\n",
            "tcost icost 0.0020160675048828125 0.4031841456890106\n",
            "tcost icost 0.0020160675048828125 0.4057048559188843\n",
            "search 0.40771484375\n",
            "tcost icost 0.0026988983154296875 0.40792739391326904\n",
            "tcost icost 0.0020999908447265625 0.40572288632392883\n",
            "tcost icost 0.0020999908447265625 0.40675970911979675\n",
            "search 0.408935546875\n",
            "tcost icost 0.0027065277099609375 0.4089095890522003\n",
            "tcost icost 0.0020999908447265625 0.41042113304138184\n",
            "tcost icost 0.0020999908447265625 0.4085812568664551\n",
            "search 0.410888671875\n",
            "tcost icost 0.0031890869140625 0.406612366437912\n",
            "tcost icost 0.0023021697998046875 0.40832385420799255\n",
            "tcost icost 0.0023021697998046875 0.40738779306411743\n",
            "search 0.40966796875\n",
            "tcost icost 0.0030956268310546875 0.4071815311908722\n",
            "tcost icost 0.00279998779296875 0.40725064277648926\n",
            "tcost icost 0.00279998779296875 0.40675437450408936\n",
            "search 0.409423828125\n",
            "tcost icost 0.00323486328125 0.40954968333244324\n",
            "tcost icost 0.003047943115234375 0.40738099813461304\n",
            "tcost icost 0.003047943115234375 0.4070475101470947\n",
            "search 0.409912109375\n",
            "tcost icost 0.0033130645751953125 0.40891629457473755\n",
            "tcost icost 0.003269195556640625 0.40655726194381714\n",
            "tcost icost 0.003269195556640625 0.4107755422592163\n",
            "search 0.4140625\n",
            "tcost icost 0.00311279296875 0.4096551239490509\n",
            "tcost icost 0.0028476715087890625 0.40901052951812744\n",
            "tcost icost 0.0028476715087890625 0.4108906686306\n",
            "search 0.413818359375\n",
            "tcost icost 0.0028820037841796875 0.4106135070323944\n",
            "tcost icost 0.0027942657470703125 0.41108331084251404\n",
            "tcost icost 0.0027942657470703125 0.41108331084251404\n",
            "search 0.413818359375\n",
            "tcost icost 0.0022563934326171875 0.4093724191188812\n",
            "tcost icost 0.0027751922607421875 0.40921205282211304\n",
            "tcost icost 0.0027751922607421875 0.41082772612571716\n",
            "search 0.41357421875\n",
            "tcost icost 0.00270843505859375 0.41491082310676575\n",
            "tcost icost 0.0031795501708984375 0.4140893518924713\n",
            "tcost icost 0.0031795501708984375 0.4140893816947937\n",
            "search 0.417236328125\n",
            "tcost icost 0.003009796142578125 0.4115773141384125\n",
            "tcost icost 0.0030269622802734375 0.413712739944458\n",
            "tcost icost 0.0030269622802734375 0.41451025009155273\n",
            "search 0.41748046875\n",
            "tcost icost 0.0037975311279296875 0.4128337502479553\n",
            "tcost icost 0.003414154052734375 0.4152524173259735\n",
            "tcost icost 0.003414154052734375 0.41341838240623474\n",
            "search 0.416748046875\n",
            "tcost icost 0.0027523040771484375 0.41584208607673645\n",
            "tcost icost 0.002803802490234375 0.41280248761177063\n",
            "tcost icost 0.002803802490234375 0.4158124029636383\n",
            "search 0.41845703125\n",
            "tcost icost 0.0020580291748046875 0.4135366976261139\n",
            "tcost icost 0.002178192138671875 0.415862500667572\n",
            "tcost icost 0.002178192138671875 0.41319605708122253\n",
            "search 0.415283203125\n",
            "tcost icost 0.0027313232421875 0.4133557379245758\n",
            "tcost icost 0.002590179443359375 0.41427189111709595\n",
            "tcost icost 0.002590179443359375 0.4149174690246582\n",
            "search 0.417724609375\n",
            "tcost icost 0.0026493072509765625 0.41216200590133667\n",
            "tcost icost 0.002498626708984375 0.41525593400001526\n",
            "tcost icost 0.002498626708984375 0.41271740198135376\n",
            "search 0.4150390625\n",
            "tcost icost 0.003231048583984375 0.4127248525619507\n",
            "tcost icost 0.002826690673828125 0.41526493430137634\n",
            "tcost icost 0.002826690673828125 0.41376829147338867\n",
            "search 0.416748046875\n",
            "tcost icost 0.0031108856201171875 0.41219615936279297\n",
            "tcost icost 0.0027408599853515625 0.41531750559806824\n",
            "tcost icost 0.0027408599853515625 0.4145366847515106\n",
            "search 0.417236328125\n",
            "tcost icost 0.0025997161865234375 0.41341739892959595\n",
            "tcost icost 0.002506256103515625 0.4124390482902527\n",
            "tcost icost 0.002506256103515625 0.4143352806568146\n",
            "search 0.416748046875\n",
            "tcost icost 0.002960205078125 0.4142829179763794\n",
            "tcost icost 0.002681732177734375 0.4162128269672394\n",
            "tcost icost 0.002681732177734375 0.41425615549087524\n",
            "search 0.4169921875\n",
            "tcost icost 0.0028438568115234375 0.4160541594028473\n",
            "tcost icost 0.00251007080078125 0.4163456857204437\n",
            "tcost icost 0.00251007080078125 0.41583120822906494\n",
            "search 0.418212890625\n",
            "tcost icost 0.002162933349609375 0.41567230224609375\n",
            "tcost icost 0.00203704833984375 0.4156593084335327\n",
            "tcost icost 0.00203704833984375 0.4137886166572571\n",
            "search 0.415771484375\n",
            "tcost icost 0.0036029815673828125 0.41391855478286743\n",
            "tcost icost 0.00335693359375 0.41297242045402527\n",
            "tcost icost 0.00335693359375 0.41421401500701904\n",
            "search 0.417724609375\n",
            "tcost icost 0.00312042236328125 0.41572245955467224\n",
            "tcost icost 0.0025081634521484375 0.41358357667922974\n",
            "tcost icost 0.0025081634521484375 0.4133911430835724\n",
            "search 0.415771484375\n",
            "tcost icost 0.0031337738037109375 0.41441610455513\n",
            "tcost icost 0.0022830963134765625 0.41464102268218994\n",
            "tcost icost 0.0022830963134765625 0.4169537425041199\n",
            "search 0.419189453125\n",
            "tcost icost 0.0035457611083984375 0.41384992003440857\n",
            "tcost icost 0.003467559814453125 0.41314420104026794\n",
            "tcost icost 0.003467559814453125 0.41396793723106384\n",
            "search 0.41748046875\n",
            "tcost icost 0.0035991668701171875 0.41609853506088257\n",
            "tcost icost 0.0033416748046875 0.4174681305885315\n",
            "tcost icost 0.0033416748046875 0.4152606129646301\n",
            "search 0.418701171875\n",
            "tcost icost 0.0026683807373046875 0.41530361771583557\n",
            "tcost icost 0.0025997161865234375 0.41549381613731384\n",
            "tcost icost 0.0025997161865234375 0.4172159731388092\n",
            "search 0.419921875\n",
            "tcost icost 0.0037975311279296875 0.418241024017334\n",
            "tcost icost 0.0029201507568359375 0.41823431849479675\n",
            "tcost icost 0.0029201507568359375 0.42006897926330566\n",
            "search 0.423095703125\n",
            "tcost icost 0.002811431884765625 0.42030757665634155\n",
            "tcost icost 0.002513885498046875 0.4198918342590332\n",
            "tcost icost 0.002513885498046875 0.42093634605407715\n",
            "search 0.42333984375\n",
            "tcost icost 0.0036563873291015625 0.4219169318675995\n",
            "tcost icost 0.00337982177734375 0.42037224769592285\n",
            "tcost icost 0.00337982177734375 0.4207562506198883\n",
            "search 0.424072265625\n",
            "tcost icost 0.0030670166015625 0.4236954152584076\n",
            "tcost icost 0.0030670166015625 0.42361658811569214\n",
            "tcost icost 0.0030670166015625 0.4212351441383362\n",
            "search 0.42431640625\n",
            "tcost icost 0.0037097930908203125 0.42267411947250366\n",
            "tcost icost 0.003452301025390625 0.4227942228317261\n",
            "tcost icost 0.003452301025390625 0.4229004681110382\n",
            "search 0.42626953125\n",
            "tcost icost 0.0040435791015625 0.4261679947376251\n",
            "tcost icost 0.0035381317138671875 0.42242470383644104\n",
            "tcost icost 0.0035381317138671875 0.4221050441265106\n",
            "search 0.425537109375\n",
            "tcost icost 0.00405120849609375 0.4220467507839203\n",
            "tcost icost 0.003978729248046875 0.4202200472354889\n",
            "tcost icost 0.003978729248046875 0.4188731014728546\n",
            "search 0.4228515625\n",
            "tcost icost 0.003025054931640625 0.4211869537830353\n",
            "tcost icost 0.0026702880859375 0.42197564244270325\n",
            "tcost icost 0.0026702880859375 0.42071059346199036\n",
            "search 0.42333984375\n",
            "tcost icost 0.005107879638671875 0.41926053166389465\n",
            "tcost icost 0.003879547119140625 0.4186622202396393\n",
            "tcost icost 0.003879547119140625 0.42082178592681885\n",
            "search 0.4248046875\n",
            "tcost icost 0.0033168792724609375 0.41939449310302734\n",
            "tcost icost 0.00330352783203125 0.4195843040943146\n",
            "tcost icost 0.00330352783203125 0.4199022948741913\n",
            "search 0.42333984375\n",
            "tcost icost 0.0031299591064453125 0.4201720356941223\n",
            "tcost icost 0.002899169921875 0.4216270446777344\n",
            "tcost icost 0.002899169921875 0.42065638303756714\n",
            "search 0.423583984375\n",
            "tcost icost 0.0028896331787109375 0.4205836355686188\n",
            "tcost icost 0.002750396728515625 0.4212048053741455\n",
            "tcost icost 0.002750396728515625 0.4212048053741455\n",
            "search 0.423828125\n",
            "tcost icost 0.0028972625732421875 0.42031049728393555\n",
            "tcost icost 0.0027599334716796875 0.422359436750412\n",
            "tcost icost 0.0027599334716796875 0.4200926423072815\n",
            "search 0.4228515625\n",
            "tcost icost 0.0025310516357421875 0.42105984687805176\n",
            "tcost icost 0.0025310516357421875 0.4229945242404938\n",
            "tcost icost 0.0025310516357421875 0.4215034246444702\n",
            "search 0.423828125\n",
            "tcost icost 0.002838134765625 0.4220496416091919\n",
            "tcost icost 0.00231170654296875 0.42195576429367065\n",
            "tcost icost 0.00231170654296875 0.42401623725891113\n",
            "search 0.42626953125\n",
            "tcost icost 0.0025463104248046875 0.4216478765010834\n",
            "tcost icost 0.0025463104248046875 0.42224636673927307\n",
            "tcost icost 0.0025463104248046875 0.421819269657135\n",
            "search 0.42431640625\n",
            "tcost icost 0.0030498504638671875 0.4251139461994171\n",
            "tcost icost 0.002483367919921875 0.42212969064712524\n",
            "tcost icost 0.002483367919921875 0.4233212471008301\n",
            "search 0.42578125\n",
            "tcost icost 0.002941131591796875 0.4247244894504547\n",
            "tcost icost 0.00252532958984375 0.4232214093208313\n",
            "tcost icost 0.00252532958984375 0.4236133396625519\n",
            "search 0.426025390625\n",
            "tcost icost 0.004001617431640625 0.42134594917297363\n",
            "tcost icost 0.003635406494140625 0.4207617938518524\n",
            "tcost icost 0.003635406494140625 0.4207725524902344\n",
            "search 0.42431640625\n",
            "tcost icost 0.00209808349609375 0.42419666051864624\n",
            "tcost icost 0.0021381378173828125 0.42345792055130005\n",
            "tcost icost 0.0021381378173828125 0.422162801027298\n",
            "search 0.42431640625\n",
            "tcost icost 0.0037097930908203125 0.4223100543022156\n",
            "tcost icost 0.00335693359375 0.4216616153717041\n",
            "tcost icost 0.00335693359375 0.4214839041233063\n",
            "search 0.4248046875\n",
            "tcost icost 0.0029430389404296875 0.42507609724998474\n",
            "tcost icost 0.002552032470703125 0.4230842888355255\n",
            "tcost icost 0.002552032470703125 0.42267701029777527\n",
            "search 0.425048828125\n",
            "tcost icost 0.0029125213623046875 0.42421838641166687\n",
            "tcost icost 0.002590179443359375 0.4284472167491913\n",
            "tcost icost 0.002590179443359375 0.4265631437301636\n",
            "search 0.42919921875\n",
            "tcost icost 0.00235748291015625 0.4244123101234436\n",
            "tcost icost 0.0021915435791015625 0.42377060651779175\n",
            "tcost icost 0.0021915435791015625 0.42385920882225037\n",
            "search 0.426025390625\n",
            "tcost icost 0.0029296875 0.4237489104270935\n",
            "tcost icost 0.0024242401123046875 0.423536092042923\n",
            "tcost icost 0.0024242401123046875 0.4236629009246826\n",
            "search 0.426025390625\n",
            "tcost icost 0.0026302337646484375 0.42471829056739807\n",
            "tcost icost 0.002532958984375 0.4256260395050049\n",
            "tcost icost 0.002532958984375 0.4245634078979492\n",
            "search 0.427001953125\n",
            "tcost icost 0.002655029296875 0.4239284098148346\n",
            "tcost icost 0.002593994140625 0.4244995415210724\n",
            "tcost icost 0.002593994140625 0.4238455295562744\n",
            "search 0.426513671875\n",
            "tcost icost 0.002960205078125 0.4224490523338318\n",
            "tcost icost 0.002826690673828125 0.4249093532562256\n",
            "tcost icost 0.002826690673828125 0.4237573742866516\n",
            "search 0.4267578125\n",
            "tcost icost 0.0033206939697265625 0.4241933226585388\n",
            "tcost icost 0.002593994140625 0.42606547474861145\n",
            "tcost icost 0.002593994140625 0.4260654151439667\n",
            "search 0.4287109375\n",
            "tcost icost 0.00292205810546875 0.4238225519657135\n",
            "tcost icost 0.0025882720947265625 0.42575034499168396\n",
            "tcost icost 0.0025882720947265625 0.42341405153274536\n",
            "search 0.426025390625\n",
            "tcost icost 0.0029468536376953125 0.42301666736602783\n",
            "tcost icost 0.00246429443359375 0.42528849840164185\n",
            "tcost icost 0.00246429443359375 0.42327171564102173\n",
            "search 0.42578125\n",
            "tcost icost 0.0030670166015625 0.42230042815208435\n",
            "tcost icost 0.0019359588623046875 0.4214574992656708\n",
            "tcost icost 0.0019359588623046875 0.4228975176811218\n",
            "search 0.4248046875\n",
            "tcost icost 0.0025463104248046875 0.42502763867378235\n",
            "tcost icost 0.003170013427734375 0.4228896200656891\n",
            "tcost icost 0.003170013427734375 0.4241529405117035\n",
            "search 0.42724609375\n",
            "tcost icost 0.003742218017578125 0.4269607663154602\n",
            "tcost icost 0.003345489501953125 0.42423200607299805\n",
            "tcost icost 0.003345489501953125 0.4251185953617096\n",
            "search 0.428466796875\n",
            "tcost icost 0.0026340484619140625 0.42338287830352783\n",
            "tcost icost 0.0019474029541015625 0.42280587553977966\n",
            "tcost icost 0.0019474029541015625 0.4231320023536682\n",
            "search 0.425048828125\n",
            "tcost icost 0.002521514892578125 0.42421630024909973\n",
            "tcost icost 0.0027217864990234375 0.42592859268188477\n",
            "tcost icost 0.0027217864990234375 0.4235527813434601\n",
            "search 0.42626953125\n",
            "tcost icost 0.002758026123046875 0.42523300647735596\n",
            "tcost icost 0.0025081634521484375 0.42579951882362366\n",
            "tcost icost 0.0025081634521484375 0.42518746852874756\n",
            "search 0.427734375\n",
            "tcost icost 0.0025844573974609375 0.42401123046875\n",
            "tcost icost 0.0030364990234375 0.4245568513870239\n",
            "tcost icost 0.0030364990234375 0.4251498281955719\n",
            "search 0.427978515625\n",
            "tcost icost 0.00266265869140625 0.42212146520614624\n",
            "tcost icost 0.0019550323486328125 0.4246237874031067\n",
            "tcost icost 0.0019550323486328125 0.4227792024612427\n",
            "search 0.4248046875\n",
            "tcost icost 0.0033016204833984375 0.424940824508667\n",
            "tcost icost 0.00262451171875 0.4256051480770111\n",
            "tcost icost 0.00262451171875 0.42411965131759644\n",
            "search 0.4267578125\n",
            "tcost icost 0.003437042236328125 0.4243408441543579\n",
            "tcost icost 0.0030841827392578125 0.423949658870697\n",
            "tcost icost 0.0030841827392578125 0.424617737531662\n",
            "search 0.427734375\n",
            "ded\n",
            "time\n",
            "22 #### train ####\n",
            "repr, std, cov, conv, closs 0.04766629636287689 0.326904296875 0.31004956364631653 0.062166087329387665 0.019123557955026627\n",
            "48.98624522612365 7.444544045199088 1.0\n",
            "repr, std, cov, conv, closs 0.048450618982315063 0.326904296875 0.3304611146450043 0.05790693312883377 0.041942089796066284\n",
            "49.4288890590099 7.5118135714721515 1.0\n",
            "repr, std, cov, conv, closs 0.047737255692481995 0.3291015625 0.34029728174209595 0.07235341519117355 0.038856714963912964\n",
            "49.97533359965828 7.648181675925595 1.0\n",
            "repr, std, cov, conv, closs 0.03665103390812874 0.329833984375 0.305420845746994 0.06435969471931458 0.011218068189918995\n",
            "50.07533424219118 7.717291288961148 1.0\n",
            "repr, std, cov, conv, closs 0.035108525305986404 0.331298828125 0.31541702151298523 0.06118461489677429 0.016659514978528023\n",
            "50.02530893325793 7.740466322419187 1.0\n",
            "repr, std, cov, conv, closs 0.04323992505669594 0.330078125 0.30208754539489746 0.05623108893632889 0.015359197743237019\n",
            "50.225710520995804 7.794812407656286 1.0\n",
            "repr, std, cov, conv, closs 0.05219355598092079 0.326416015625 0.348130464553833 0.049181073904037476 0.0017004769761115313\n",
            "50.32621216774831 7.678820322319725 1.0\n",
            "repr, std, cov, conv, closs 0.04471339285373688 0.32275390625 0.40247178077697754 0.06278635561466217 0.015968533232808113\n",
            "50.12540957643337 7.556997280453546 1.0\n",
            "repr, std, cov, conv, closs 0.03183192387223244 0.328857421875 0.30995091795921326 0.05462568253278732 0.04239051416516304\n",
            "49.72620481601932 7.45944057783353 1.0\n",
            "repr, std, cov, conv, closs 0.04424940049648285 0.324951171875 0.36024898290634155 0.06106546148657799 0.0013762122252956033\n",
            "49.330179370090356 7.385254805528658 1.0\n",
            "repr, std, cov, conv, closs 0.04614788293838501 0.32421875 0.385730504989624 0.055447712540626526 0.06110022962093353\n",
            "49.4288890590099 7.2972051195531105 1.0\n",
            "repr, std, cov, conv, closs 0.036006633192300797 0.33154296875 0.3219258189201355 0.05882048234343529 0.0006421279394999146\n",
            "49.379509549460444 7.282632571776986 1.0\n",
            "repr, std, cov, conv, closs 0.029333502054214478 0.329345703125 0.33158883452415466 0.05136136710643768 0.01637798547744751\n",
            "49.28089847161874 7.26082829713985 1.0\n",
            "repr, std, cov, conv, closs 0.045380398631095886 0.326904296875 0.3454285264015198 0.0589505136013031 0.001192791503854096\n",
            "49.28089847161874 7.311806826997334 1.0\n",
            "repr, std, cov, conv, closs 0.04933296516537666 0.32666015625 0.35993656516075134 0.06255397200584412 0.032116372138261795\n",
            "50.1755349860098 7.392640060334186 1.0\n",
            "repr, std, cov, conv, closs 0.032015588134527206 0.334228515625 0.24019724130630493 0.05442728102207184 0.000180838571395725\n",
            "50.67955426655792 7.4893231266335505 1.0\n",
            "repr, std, cov, conv, closs 0.03588992729783058 0.33349609375 0.28666701912879944 0.0750102549791336 0.02126765251159668\n",
            "50.93345934048234 7.655829857601519 1.0\n",
            "repr, std, cov, conv, closs 0.039827924221754074 0.332275390625 0.3352828025817871 0.07529763877391815 0.002551062498241663\n",
            "51.08641256981525 7.732733588830357 1.0\n",
            "repr, std, cov, conv, closs 0.0372086837887764 0.330078125 0.30663740634918213 0.06661230325698853 0.01584594137966633\n",
            "51.29106494296664 7.8809853475428575 1.0\n",
            "repr, std, cov, conv, closs 0.0361274853348732 0.3369140625 0.2782251834869385 0.07033298909664154 0.015878429636359215\n",
            "51.3936983639175 7.912556606376934 1.0\n",
            "repr, std, cov, conv, closs 0.03471197560429573 0.32666015625 0.3525426983833313 0.07144664227962494 0.0030954815447330475\n",
            "50.47734183321425 7.787025382274013 1.0\n",
            "repr, std, cov, conv, closs 0.03231682628393173 0.330810546875 0.3211514949798584 0.07188694179058075 0.016414042562246323\n",
            "50.225710520995804 7.709581707253895 1.0\n",
            "repr, std, cov, conv, closs 0.032122742384672165 0.326416015625 0.32758277654647827 0.06533943116664886 0.014005325734615326\n",
            "49.52779626601696 7.526844710428666 1.0\n",
            "repr, std, cov, conv, closs 0.03571401536464691 0.32861328125 0.3102800250053406 0.0628712922334671 0.03696573153138161\n",
            "49.23166680481393 7.407432733094913 1.0\n",
            "repr, std, cov, conv, closs 0.036274850368499756 0.32568359375 0.32056546211242676 0.059562064707279205 0.019017228856682777\n",
            "48.693353728846894 7.26082829713985 1.0\n",
            "repr, std, cov, conv, closs 0.03608105704188347 0.323974609375 0.3318638205528259 0.06075882911682129 0.005006336607038975\n",
            "48.79078912965831 7.210205193864046 1.0\n",
            "repr, std, cov, conv, closs 0.037137772887945175 0.3291015625 0.30001625418663025 0.07142852991819382 0.03969646617770195\n",
            "48.93730791820545 7.152782256849166 1.0\n",
            "repr, std, cov, conv, closs 0.047972120344638824 0.329833984375 0.33950376510620117 0.07413230836391449 0.015844525769352913\n",
            "49.03523147134977 7.1171253874511935 1.0\n",
            "repr, std, cov, conv, closs 0.035573266446590424 0.327880859375 0.32291993498802185 0.060880303382873535 0.01178424246609211\n",
            "49.4783179480689 7.145636620228938 1.0\n",
            "repr, std, cov, conv, closs 0.02821793407201767 0.333251953125 0.27660804986953735 0.07191115617752075 0.040173664689064026\n",
            "49.72620481601932 7.268089125436989 1.0\n",
            "repr, std, cov, conv, closs 0.0407525971531868 0.332275390625 0.29770588874816895 0.06446724385023117 0.0190935917198658\n",
            "50.42691491829596 7.429677260999828 1.0\n",
            "repr, std, cov, conv, closs 0.04369562864303589 0.333984375 0.27596163749694824 0.06462782621383667 0.003024906385689974\n",
            "50.984392799822814 7.504309262209943 1.0\n",
            "repr, std, cov, conv, closs 0.03605053573846817 0.33203125 0.2863864302635193 0.056227974593639374 0.001727644819766283\n",
            "51.90995424203243 7.717291288961148 1.0\n",
            "repr, std, cov, conv, closs 0.03892170637845993 0.33203125 0.3240290880203247 0.06131424754858017 0.011870958842337132\n",
            "52.01382606047073 7.810409827284005 1.0\n",
            "repr, std, cov, conv, closs 0.047343939542770386 0.322509765625 0.3850674033164978 0.05754683166742325 0.029781263321638107\n",
            "52.11790572641772 7.8809853475428575 1.0\n",
            "repr, std, cov, conv, closs 0.035921625792980194 0.33349609375 0.27573296427726746 0.06641885638237 0.028681235387921333\n",
            "52.01382606047073 7.944254339800216 1.0\n",
            "tcost icost 0.01788330078125 0.4228866994380951\n",
            "tcost icost 0.017425537109375 0.42260149121284485\n",
            "tcost icost 0.017425537109375 0.42469316720962524\n",
            "search 0.442138671875\n",
            "tcost icost 0.01788330078125 0.4232829213142395\n",
            "tcost icost 0.017425537109375 0.42573294043540955\n",
            "tcost icost 0.017425537109375 0.4234558939933777\n",
            "search 0.440673828125\n",
            "tcost icost 0.017303466796875 0.4221888780593872\n",
            "tcost icost 0.017333984375 0.42654916644096375\n",
            "tcost icost 0.017333984375 0.4216132164001465\n",
            "search 0.43896484375\n",
            "tcost icost 0.017303466796875 0.4214840233325958\n",
            "tcost icost 0.017333984375 0.4212837517261505\n",
            "tcost icost 0.017333984375 0.42161110043525696\n",
            "search 0.43896484375\n",
            "tcost icost 0.0172576904296875 0.4201594591140747\n",
            "tcost icost 0.017425537109375 0.42201679944992065\n",
            "tcost icost 0.017425537109375 0.42090392112731934\n",
            "search 0.438232421875\n",
            "tcost icost 0.017333984375 0.4212837517261505\n",
            "tcost icost 0.017303466796875 0.41869378089904785\n",
            "tcost icost 0.017303466796875 0.42028167843818665\n",
            "search 0.4375\n",
            "tcost icost 0.0172271728515625 0.41957738995552063\n",
            "tcost icost 0.0174102783203125 0.41892147064208984\n",
            "tcost icost 0.0174102783203125 0.4189395010471344\n",
            "search 0.436279296875\n",
            "tcost icost 0.017242431640625 0.4174554944038391\n",
            "tcost icost 0.017425537109375 0.41940662264823914\n",
            "tcost icost 0.017425537109375 0.42074668407440186\n",
            "search 0.43798828125\n",
            "tcost icost 0.0171356201171875 0.41819554567337036\n",
            "tcost icost 0.0173492431640625 0.4182303547859192\n",
            "tcost icost 0.0173492431640625 0.4207230806350708\n",
            "search 0.43798828125\n",
            "tcost icost 0.018096923828125 0.420567125082016\n",
            "tcost icost 0.0180511474609375 0.42014750838279724\n",
            "tcost icost 0.0180511474609375 0.4201892614364624\n",
            "search 0.438232421875\n",
            "tcost icost 0.0177459716796875 0.4203096628189087\n",
            "tcost icost 0.0178375244140625 0.42025694251060486\n",
            "tcost icost 0.0178375244140625 0.42284369468688965\n",
            "search 0.440673828125\n",
            "tcost icost 0.018310546875 0.4232791066169739\n",
            "tcost icost 0.0177154541015625 0.42064565420150757\n",
            "tcost icost 0.0177154541015625 0.4204804301261902\n",
            "search 0.438232421875\n",
            "tcost icost 0.0185394287109375 0.42319488525390625\n",
            "tcost icost 0.0177001953125 0.4217829704284668\n",
            "tcost icost 0.0177001953125 0.42044636607170105\n",
            "search 0.43798828125\n",
            "tcost icost 0.0185089111328125 0.42066940665245056\n",
            "tcost icost 0.01849365234375 0.4203275442123413\n",
            "tcost icost 0.01849365234375 0.4217148721218109\n",
            "search 0.440185546875\n",
            "tcost icost 0.018218994140625 0.41730937361717224\n",
            "tcost icost 0.0180206298828125 0.4164832532405853\n",
            "tcost icost 0.0180206298828125 0.4205516576766968\n",
            "search 0.438720703125\n",
            "tcost icost 0.0176239013671875 0.4167346656322479\n",
            "tcost icost 0.0177154541015625 0.41675788164138794\n",
            "tcost icost 0.0177154541015625 0.41696327924728394\n",
            "search 0.434814453125\n",
            "tcost icost 0.0172576904296875 0.41239598393440247\n",
            "tcost icost 0.017486572265625 0.4141807556152344\n",
            "tcost icost 0.017486572265625 0.4148405194282532\n",
            "search 0.432373046875\n",
            "tcost icost 0.01837158203125 0.4145853817462921\n",
            "tcost icost 0.01837158203125 0.4168960154056549\n",
            "tcost icost 0.01837158203125 0.41993504762649536\n",
            "search 0.438232421875\n",
            "tcost icost 0.0183258056640625 0.4070080518722534\n",
            "tcost icost 0.017913818359375 0.4059327244758606\n",
            "tcost icost 0.017913818359375 0.40882399678230286\n",
            "search 0.4267578125\n",
            "tcost icost 0.0185394287109375 0.4113624393939972\n",
            "tcost icost 0.0177001953125 0.41144034266471863\n",
            "tcost icost 0.0177001953125 0.41144034266471863\n",
            "search 0.42919921875\n",
            "tcost icost 0.0177001953125 0.40324872732162476\n",
            "tcost icost 0.017913818359375 0.40312209725379944\n",
            "tcost icost 0.017913818359375 0.4027497172355652\n",
            "search 0.420654296875\n",
            "tcost icost 0.0183258056640625 0.4113122820854187\n",
            "tcost icost 0.0182952880859375 0.40752679109573364\n",
            "tcost icost 0.0182952880859375 0.4119966924190521\n",
            "search 0.430419921875\n",
            "tcost icost 0.017669677734375 0.4060693681240082\n",
            "tcost icost 0.0171661376953125 0.40503570437431335\n",
            "tcost icost 0.0171661376953125 0.4031553864479065\n",
            "search 0.420166015625\n",
            "tcost icost 0.018096923828125 0.4058978259563446\n",
            "tcost icost 0.0180511474609375 0.40812474489212036\n",
            "tcost icost 0.0180511474609375 0.405383437871933\n",
            "search 0.42333984375\n",
            "tcost icost 0.0178680419921875 0.4069069027900696\n",
            "tcost icost 0.017730712890625 0.4068504869937897\n",
            "tcost icost 0.017730712890625 0.40695691108703613\n",
            "search 0.4248046875\n",
            "tcost icost 0.017669677734375 0.4021536409854889\n",
            "tcost icost 0.0178070068359375 0.4044029414653778\n",
            "tcost icost 0.0178070068359375 0.4038561284542084\n",
            "search 0.421630859375\n",
            "tcost icost 0.018096923828125 0.4085948169231415\n",
            "tcost icost 0.0181427001953125 0.4065941572189331\n",
            "tcost icost 0.0181427001953125 0.40728867053985596\n",
            "search 0.42529296875\n",
            "tcost icost 0.017120361328125 0.40221408009529114\n",
            "tcost icost 0.0164031982421875 0.40220966935157776\n",
            "tcost icost 0.0164031982421875 0.40342071652412415\n",
            "search 0.419677734375\n",
            "tcost icost 0.01617431640625 0.4031689465045929\n",
            "tcost icost 0.01666259765625 0.4011177718639374\n",
            "tcost icost 0.01666259765625 0.40250736474990845\n",
            "search 0.419189453125\n",
            "tcost icost 0.0162506103515625 0.4022432863712311\n",
            "tcost icost 0.0162506103515625 0.4026394486427307\n",
            "tcost icost 0.0162506103515625 0.4015082120895386\n",
            "search 0.41796875\n",
            "tcost icost 0.01480865478515625 0.4016810357570648\n",
            "tcost icost 0.01474761962890625 0.40185490250587463\n",
            "tcost icost 0.01474761962890625 0.4028686285018921\n",
            "search 0.41748046875\n",
            "tcost icost 0.01611328125 0.4023471772670746\n",
            "tcost icost 0.016876220703125 0.4014786183834076\n",
            "tcost icost 0.016876220703125 0.40319138765335083\n",
            "search 0.419921875\n",
            "tcost icost 0.0159149169921875 0.4032004773616791\n",
            "tcost icost 0.01666259765625 0.3998909294605255\n",
            "tcost icost 0.01666259765625 0.4008644223213196\n",
            "search 0.41748046875\n",
            "tcost icost 0.0157928466796875 0.3999852240085602\n",
            "tcost icost 0.0164947509765625 0.399745374917984\n",
            "tcost icost 0.0164947509765625 0.3995181620121002\n",
            "search 0.416015625\n",
            "tcost icost 0.017242431640625 0.4021940529346466\n",
            "tcost icost 0.0168914794921875 0.40362945199012756\n",
            "tcost icost 0.0168914794921875 0.4077223241329193\n",
            "search 0.424560546875\n",
            "tcost icost 0.0163726806640625 0.40555936098098755\n",
            "tcost icost 0.01561737060546875 0.404541015625\n",
            "tcost icost 0.01561737060546875 0.40386301279067993\n",
            "search 0.41943359375\n",
            "tcost icost 0.017120361328125 0.4038148820400238\n",
            "tcost icost 0.0167236328125 0.4044015407562256\n",
            "tcost icost 0.0167236328125 0.4041411280632019\n",
            "search 0.4208984375\n",
            "tcost icost 0.01543426513671875 0.4062286913394928\n",
            "tcost icost 0.01531982421875 0.40654870867729187\n",
            "tcost icost 0.01531982421875 0.40601006150245667\n",
            "search 0.42138671875\n",
            "tcost icost 0.0168304443359375 0.4051412045955658\n",
            "tcost icost 0.0168304443359375 0.40576332807540894\n",
            "tcost icost 0.0168304443359375 0.40552419424057007\n",
            "search 0.42236328125\n",
            "tcost icost 0.0166473388671875 0.40815988183021545\n",
            "tcost icost 0.0171966552734375 0.40397581458091736\n",
            "tcost icost 0.0171966552734375 0.4041835367679596\n",
            "search 0.42138671875\n",
            "tcost icost 0.0170745849609375 0.4094488024711609\n",
            "tcost icost 0.01751708984375 0.4067094624042511\n",
            "tcost icost 0.01751708984375 0.4072994291782379\n",
            "search 0.4248046875\n",
            "tcost icost 0.017242431640625 0.4095538258552551\n",
            "tcost icost 0.0172119140625 0.408840537071228\n",
            "tcost icost 0.0172119140625 0.40876200795173645\n",
            "search 0.42578125\n",
            "tcost icost 0.01751708984375 0.4060220420360565\n",
            "tcost icost 0.0175323486328125 0.4042019844055176\n",
            "tcost icost 0.0175323486328125 0.408145010471344\n",
            "search 0.42578125\n",
            "tcost icost 0.0174102783203125 0.4073532521724701\n",
            "tcost icost 0.017333984375 0.40719443559646606\n",
            "tcost icost 0.017333984375 0.40741416811943054\n",
            "search 0.4248046875\n",
            "tcost icost 0.017425537109375 0.40726369619369507\n",
            "tcost icost 0.0173187255859375 0.4088020622730255\n",
            "tcost icost 0.0173187255859375 0.40954822301864624\n",
            "search 0.427001953125\n",
            "tcost icost 0.0175933837890625 0.4077050983905792\n",
            "tcost icost 0.0177001953125 0.408657044172287\n",
            "tcost icost 0.0177001953125 0.40806272625923157\n",
            "search 0.42578125\n",
            "tcost icost 0.01617431640625 0.4081408679485321\n",
            "tcost icost 0.015716552734375 0.40738800168037415\n",
            "tcost icost 0.015716552734375 0.4084092676639557\n",
            "search 0.424072265625\n",
            "tcost icost 0.0176239013671875 0.4084412455558777\n",
            "tcost icost 0.0177001953125 0.408694863319397\n",
            "tcost icost 0.0177001953125 0.4089842438697815\n",
            "search 0.4267578125\n",
            "tcost icost 0.0174102783203125 0.4126664400100708\n",
            "tcost icost 0.017333984375 0.4108016788959503\n",
            "tcost icost 0.017333984375 0.40996357798576355\n",
            "search 0.42724609375\n",
            "tcost icost 0.0174713134765625 0.4123954772949219\n",
            "tcost icost 0.01739501953125 0.41061902046203613\n",
            "tcost icost 0.01739501953125 0.4095739424228668\n",
            "search 0.427001953125\n",
            "tcost icost 0.017364501953125 0.4080715775489807\n",
            "tcost icost 0.01751708984375 0.40889793634414673\n",
            "tcost icost 0.01751708984375 0.40741005539894104\n",
            "search 0.425048828125\n",
            "tcost icost 0.017547607421875 0.41349461674690247\n",
            "tcost icost 0.0175018310546875 0.41082578897476196\n",
            "tcost icost 0.0175018310546875 0.4113004207611084\n",
            "search 0.428955078125\n",
            "tcost icost 0.0176544189453125 0.40894371271133423\n",
            "tcost icost 0.0175628662109375 0.4088006913661957\n",
            "tcost icost 0.0175628662109375 0.4090367257595062\n",
            "search 0.426513671875\n",
            "tcost icost 0.01715087890625 0.4087256193161011\n",
            "tcost icost 0.01739501953125 0.40685391426086426\n",
            "tcost icost 0.01739501953125 0.4085439443588257\n",
            "search 0.42578125\n",
            "tcost icost 0.0174560546875 0.41262808442115784\n",
            "tcost icost 0.0174102783203125 0.4116966128349304\n",
            "tcost icost 0.0174102783203125 0.41073963046073914\n",
            "search 0.427978515625\n",
            "tcost icost 0.0171051025390625 0.41264644265174866\n",
            "tcost icost 0.0172119140625 0.41243234276771545\n",
            "tcost icost 0.0172119140625 0.41121143102645874\n",
            "search 0.42822265625\n",
            "tcost icost 0.0176239013671875 0.41256412863731384\n",
            "tcost icost 0.0175018310546875 0.4082300066947937\n",
            "tcost icost 0.0175018310546875 0.40815719962120056\n",
            "search 0.42578125\n",
            "tcost icost 0.01800537109375 0.4081004858016968\n",
            "tcost icost 0.0183563232421875 0.4050341546535492\n",
            "tcost icost 0.0183563232421875 0.40483832359313965\n",
            "search 0.423095703125\n",
            "tcost icost 0.017822265625 0.41021227836608887\n",
            "tcost icost 0.0179901123046875 0.4101879894733429\n",
            "tcost icost 0.0179901123046875 0.4077061712741852\n",
            "search 0.42578125\n",
            "tcost icost 0.01751708984375 0.41374996304512024\n",
            "tcost icost 0.0176544189453125 0.41381439566612244\n",
            "tcost icost 0.0176544189453125 0.4139702022075653\n",
            "search 0.431640625\n",
            "tcost icost 0.0174102783203125 0.41735562682151794\n",
            "tcost icost 0.0174407958984375 0.41614240407943726\n",
            "tcost icost 0.0174407958984375 0.4162120521068573\n",
            "search 0.43359375\n",
            "tcost icost 0.0174102783203125 0.41662126779556274\n",
            "tcost icost 0.0174102783203125 0.4180634915828705\n",
            "tcost icost 0.0174102783203125 0.41662126779556274\n",
            "search 0.433837890625\n",
            "tcost icost 0.0174713134765625 0.41532424092292786\n",
            "tcost icost 0.0175628662109375 0.4121629595756531\n",
            "tcost icost 0.0175628662109375 0.41071441769599915\n",
            "search 0.42822265625\n",
            "tcost icost 0.01739501953125 0.41457417607307434\n",
            "tcost icost 0.017486572265625 0.4123091697692871\n",
            "tcost icost 0.017486572265625 0.41252055764198303\n",
            "search 0.43017578125\n",
            "tcost icost 0.017486572265625 0.4112851619720459\n",
            "tcost icost 0.017486572265625 0.4103356599807739\n",
            "tcost icost 0.017486572265625 0.41239839792251587\n",
            "search 0.429931640625\n",
            "tcost icost 0.0175323486328125 0.411801278591156\n",
            "tcost icost 0.0175628662109375 0.410794734954834\n",
            "tcost icost 0.0175628662109375 0.4093499183654785\n",
            "search 0.427001953125\n",
            "tcost icost 0.0179443359375 0.40678760409355164\n",
            "tcost icost 0.0182647705078125 0.4034228026866913\n",
            "tcost icost 0.0182647705078125 0.40233007073402405\n",
            "search 0.420654296875\n",
            "tcost icost 0.0177459716796875 0.406072199344635\n",
            "tcost icost 0.0180511474609375 0.4022820293903351\n",
            "tcost icost 0.0180511474609375 0.4024142622947693\n",
            "search 0.42041015625\n",
            "tcost icost 0.01763916015625 0.4009152948856354\n",
            "tcost icost 0.01763916015625 0.40089723467826843\n",
            "tcost icost 0.01763916015625 0.40174633264541626\n",
            "search 0.41943359375\n",
            "tcost icost 0.01654052734375 0.4122784435749054\n",
            "tcost icost 0.016357421875 0.4125344753265381\n",
            "tcost icost 0.016357421875 0.41289860010147095\n",
            "search 0.42919921875\n",
            "tcost icost 0.018402099609375 0.39871466159820557\n",
            "tcost icost 0.0175323486328125 0.38578498363494873\n",
            "tcost icost 0.0175323486328125 0.3874218761920929\n",
            "search 0.405029296875\n",
            "tcost icost 0.01763916015625 0.41926783323287964\n",
            "tcost icost 0.01763916015625 0.4192816913127899\n",
            "tcost icost 0.01763916015625 0.41712018847465515\n",
            "search 0.434814453125\n",
            "tcost icost 0.0166168212890625 0.41545459628105164\n",
            "tcost icost 0.0164794921875 0.411345511674881\n",
            "tcost icost 0.0164794921875 0.41248971223831177\n",
            "search 0.42919921875\n",
            "tcost icost 0.0180816650390625 0.4118938148021698\n",
            "tcost icost 0.0184783935546875 0.4057987928390503\n",
            "tcost icost 0.0184783935546875 0.4053650200366974\n",
            "search 0.423828125\n",
            "tcost icost 0.0180511474609375 0.40967512130737305\n",
            "tcost icost 0.0184478759765625 0.4068281352519989\n",
            "tcost icost 0.0184478759765625 0.4055944085121155\n",
            "search 0.424072265625\n",
            "tcost icost 0.019287109375 0.4013044536113739\n",
            "tcost icost 0.0194549560546875 0.3968314826488495\n",
            "tcost icost 0.0194549560546875 0.3981798589229584\n",
            "search 0.417724609375\n",
            "tcost icost 0.01959228515625 0.3986629247665405\n",
            "tcost icost 0.01959228515625 0.39614468812942505\n",
            "tcost icost 0.01959228515625 0.3955899178981781\n",
            "search 0.4150390625\n",
            "tcost icost 0.017578125 0.41411441564559937\n",
            "tcost icost 0.017486572265625 0.41327011585235596\n",
            "tcost icost 0.017486572265625 0.4145829677581787\n",
            "search 0.43212890625\n",
            "tcost icost 0.017669677734375 0.4193201959133148\n",
            "tcost icost 0.0175628662109375 0.4187455475330353\n",
            "tcost icost 0.0175628662109375 0.418558806180954\n",
            "search 0.43603515625\n",
            "tcost icost 0.0176849365234375 0.4181325435638428\n",
            "tcost icost 0.0176239013671875 0.4175644814968109\n",
            "tcost icost 0.0176239013671875 0.41766518354415894\n",
            "search 0.435302734375\n",
            "tcost icost 0.0175323486328125 0.41881364583969116\n",
            "tcost icost 0.0172119140625 0.41705384850502014\n",
            "tcost icost 0.0172119140625 0.4180624186992645\n",
            "search 0.43505859375\n",
            "tcost icost 0.0173492431640625 0.4169130027294159\n",
            "tcost icost 0.0173492431640625 0.4183569550514221\n",
            "tcost icost 0.0173492431640625 0.41664567589759827\n",
            "search 0.43408203125\n",
            "tcost icost 0.017578125 0.42023542523384094\n",
            "tcost icost 0.017333984375 0.41632959246635437\n",
            "tcost icost 0.017333984375 0.41682565212249756\n",
            "search 0.43408203125\n",
            "tcost icost 0.017364501953125 0.41915345191955566\n",
            "tcost icost 0.0175628662109375 0.4193054437637329\n",
            "tcost icost 0.0175628662109375 0.4191581606864929\n",
            "search 0.436767578125\n",
            "tcost icost 0.0177001953125 0.42050856351852417\n",
            "tcost icost 0.0177154541015625 0.418992817401886\n",
            "tcost icost 0.0177154541015625 0.418720543384552\n",
            "search 0.4365234375\n",
            "tcost icost 0.017669677734375 0.4211127460002899\n",
            "tcost icost 0.017486572265625 0.4172869920730591\n",
            "tcost icost 0.017486572265625 0.41890203952789307\n",
            "search 0.4365234375\n",
            "tcost icost 0.0178070068359375 0.42004919052124023\n",
            "tcost icost 0.0176849365234375 0.41998565196990967\n",
            "tcost icost 0.0176849365234375 0.41998565196990967\n",
            "search 0.4375\n",
            "tcost icost 0.0168609619140625 0.41807809472084045\n",
            "tcost icost 0.01715087890625 0.41646790504455566\n",
            "tcost icost 0.01715087890625 0.4157063364982605\n",
            "search 0.432861328125\n",
            "tcost icost 0.0176239013671875 0.4165169298648834\n",
            "tcost icost 0.0175628662109375 0.4118324816226959\n",
            "tcost icost 0.0175628662109375 0.4128313958644867\n",
            "search 0.430419921875\n",
            "tcost icost 0.01849365234375 0.4058256447315216\n",
            "tcost icost 0.01910400390625 0.4021407663822174\n",
            "tcost icost 0.01910400390625 0.4010072648525238\n",
            "search 0.420166015625\n",
            "tcost icost 0.0173187255859375 0.42347288131713867\n",
            "tcost icost 0.01739501953125 0.42095986008644104\n",
            "tcost icost 0.01739501953125 0.42080795764923096\n",
            "search 0.438232421875\n",
            "tcost icost 0.0157928466796875 0.4178842008113861\n",
            "tcost icost 0.0155487060546875 0.4176637530326843\n",
            "tcost icost 0.0155487060546875 0.4178670644760132\n",
            "search 0.43359375\n",
            "tcost icost 0.0175933837890625 0.4208275377750397\n",
            "tcost icost 0.0173492431640625 0.4198567569255829\n",
            "tcost icost 0.0173492431640625 0.41974735260009766\n",
            "search 0.43701171875\n",
            "tcost icost 0.0177459716796875 0.42121225595474243\n",
            "tcost icost 0.0176849365234375 0.4216049611568451\n",
            "tcost icost 0.0176849365234375 0.42108353972435\n",
            "search 0.438720703125\n",
            "tcost icost 0.017578125 0.4204317033290863\n",
            "tcost icost 0.017333984375 0.41879913210868835\n",
            "tcost icost 0.017333984375 0.4202798008918762\n",
            "search 0.4375\n",
            "tcost icost 0.0174407958984375 0.4219852089881897\n",
            "tcost icost 0.0173492431640625 0.4205192029476166\n",
            "tcost icost 0.0173492431640625 0.421113520860672\n",
            "search 0.4384765625\n",
            "tcost icost 0.0174102783203125 0.4244006276130676\n",
            "tcost icost 0.0173797607421875 0.4227679371833801\n",
            "tcost icost 0.0173797607421875 0.42042598128318787\n",
            "search 0.437744140625\n",
            "tcost icost 0.017578125 0.42758938670158386\n",
            "tcost icost 0.0172119140625 0.4245537519454956\n",
            "tcost icost 0.0172119140625 0.42686399817466736\n",
            "search 0.44384765625\n",
            "tcost icost 0.016998291015625 0.42606455087661743\n",
            "tcost icost 0.0169525146484375 0.4269486665725708\n",
            "tcost icost 0.0169525146484375 0.4256027042865753\n",
            "search 0.4423828125\n",
            "tcost icost 0.0175018310546875 0.43056410551071167\n",
            "tcost icost 0.01739501953125 0.4279305040836334\n",
            "tcost icost 0.01739501953125 0.4274503290653229\n",
            "search 0.44482421875\n",
            "tcost icost 0.0177001953125 0.4287710189819336\n",
            "tcost icost 0.01776123046875 0.42825472354888916\n",
            "tcost icost 0.01776123046875 0.4307420551776886\n",
            "search 0.448486328125\n",
            "tcost icost 0.0174102783203125 0.4253891408443451\n",
            "tcost icost 0.0174102783203125 0.42527276277542114\n",
            "tcost icost 0.0174102783203125 0.4253404438495636\n",
            "search 0.442626953125\n",
            "tcost icost 0.0174102783203125 0.42567920684814453\n",
            "tcost icost 0.017364501953125 0.4254436194896698\n",
            "tcost icost 0.017364501953125 0.4254436194896698\n",
            "search 0.44287109375\n",
            "tcost icost 0.0176544189453125 0.4278480112552643\n",
            "tcost icost 0.017333984375 0.4236232340335846\n",
            "tcost icost 0.017333984375 0.42558082938194275\n",
            "search 0.44287109375\n",
            "tcost icost 0.0177001953125 0.42850008606910706\n",
            "tcost icost 0.017364501953125 0.42428433895111084\n",
            "tcost icost 0.017364501953125 0.4254591166973114\n",
            "search 0.44287109375\n",
            "tcost icost 0.0175628662109375 0.42588135600090027\n",
            "tcost icost 0.0173187255859375 0.4231336712837219\n",
            "tcost icost 0.0173187255859375 0.42189010977745056\n",
            "search 0.439208984375\n",
            "tcost icost 0.0174560546875 0.4179641306400299\n",
            "tcost icost 0.0175628662109375 0.41538670659065247\n",
            "tcost icost 0.0175628662109375 0.41596147418022156\n",
            "search 0.43359375\n",
            "tcost icost 0.0174560546875 0.42411938309669495\n",
            "tcost icost 0.01727294921875 0.4218398630619049\n",
            "tcost icost 0.01727294921875 0.4212115406990051\n",
            "search 0.4384765625\n",
            "tcost icost 0.0174102783203125 0.4232919216156006\n",
            "tcost icost 0.0173797607421875 0.4216074049472809\n",
            "tcost icost 0.0173797607421875 0.4198261499404907\n",
            "search 0.437255859375\n",
            "tcost icost 0.0175628662109375 0.4243866205215454\n",
            "tcost icost 0.0174102783203125 0.42440667748451233\n",
            "tcost icost 0.0174102783203125 0.4237189292907715\n",
            "search 0.441162109375\n",
            "tcost icost 0.016815185546875 0.42374587059020996\n",
            "tcost icost 0.016998291015625 0.4232088327407837\n",
            "tcost icost 0.016998291015625 0.42313888669013977\n",
            "search 0.440185546875\n",
            "tcost icost 0.0175323486328125 0.4281647801399231\n",
            "tcost icost 0.0177764892578125 0.42863619327545166\n",
            "tcost icost 0.0177764892578125 0.4282645881175995\n",
            "search 0.446044921875\n",
            "tcost icost 0.0177001953125 0.42916399240493774\n",
            "tcost icost 0.01763916015625 0.42711126804351807\n",
            "tcost icost 0.01763916015625 0.4277464747428894\n",
            "search 0.4453125\n",
            "tcost icost 0.0166168212890625 0.4238576889038086\n",
            "tcost icost 0.016021728515625 0.42074596881866455\n",
            "tcost icost 0.016021728515625 0.41990333795547485\n",
            "search 0.43603515625\n",
            "tcost icost 0.017181396484375 0.42842981219291687\n",
            "tcost icost 0.017333984375 0.4255555272102356\n",
            "tcost icost 0.017333984375 0.42580661177635193\n",
            "search 0.443115234375\n",
            "tcost icost 0.017425537109375 0.4260922968387604\n",
            "tcost icost 0.0173797607421875 0.420990914106369\n",
            "tcost icost 0.0173797607421875 0.4225703477859497\n",
            "search 0.43994140625\n",
            "tcost icost 0.0146331787109375 0.41368040442466736\n",
            "tcost icost 0.01464080810546875 0.4089912176132202\n",
            "tcost icost 0.01464080810546875 0.4098450541496277\n",
            "search 0.424560546875\n",
            "tcost icost 0.0154876708984375 0.4121415913105011\n",
            "tcost icost 0.01490020751953125 0.40608254075050354\n",
            "tcost icost 0.01490020751953125 0.40734362602233887\n",
            "search 0.422119140625\n",
            "tcost icost 0.017120361328125 0.4261772930622101\n",
            "tcost icost 0.01702880859375 0.4261307418346405\n",
            "tcost icost 0.01702880859375 0.4263889789581299\n",
            "search 0.443359375\n",
            "tcost icost 0.016510009765625 0.4241943657398224\n",
            "tcost icost 0.015869140625 0.4235323965549469\n",
            "tcost icost 0.015869140625 0.4254035949707031\n",
            "search 0.441162109375\n",
            "tcost icost 0.017669677734375 0.42855304479599\n",
            "tcost icost 0.01763916015625 0.42576301097869873\n",
            "tcost icost 0.01763916015625 0.42586028575897217\n",
            "search 0.443359375\n",
            "tcost icost 0.0164031982421875 0.4244404435157776\n",
            "tcost icost 0.0164031982421875 0.423647940158844\n",
            "tcost icost 0.0164031982421875 0.4241572618484497\n",
            "search 0.4404296875\n",
            "tcost icost 0.0178070068359375 0.4257207214832306\n",
            "tcost icost 0.0177764892578125 0.4254624843597412\n",
            "tcost icost 0.0177764892578125 0.42830705642700195\n",
            "search 0.446044921875\n",
            "tcost icost 0.0178070068359375 0.4255124628543854\n",
            "tcost icost 0.0176239013671875 0.42578285932540894\n",
            "tcost icost 0.0176239013671875 0.42578285932540894\n",
            "search 0.443359375\n",
            "tcost icost 0.01776123046875 0.42514270544052124\n",
            "tcost icost 0.017608642578125 0.42584720253944397\n",
            "tcost icost 0.017608642578125 0.42629000544548035\n",
            "search 0.44384765625\n",
            "tcost icost 0.0166473388671875 0.42500874400138855\n",
            "tcost icost 0.0169830322265625 0.4252435564994812\n",
            "tcost icost 0.0169830322265625 0.42605945467948914\n",
            "search 0.443115234375\n",
            "tcost icost 0.0185394287109375 0.4261612296104431\n",
            "tcost icost 0.0177001953125 0.42547741532325745\n",
            "tcost icost 0.0177001953125 0.42678338289260864\n",
            "search 0.4443359375\n",
            "tcost icost 0.0172576904296875 0.4218197762966156\n",
            "tcost icost 0.0164947509765625 0.421796053647995\n",
            "tcost icost 0.0164947509765625 0.42171981930732727\n",
            "search 0.438232421875\n",
            "tcost icost 0.0157928466796875 0.4194062054157257\n",
            "tcost icost 0.0157623291015625 0.419156938791275\n",
            "tcost icost 0.0157623291015625 0.4196443259716034\n",
            "search 0.435546875\n",
            "tcost icost 0.015472412109375 0.41875532269477844\n",
            "tcost icost 0.0141754150390625 0.41708555817604065\n",
            "tcost icost 0.0141754150390625 0.4170854985713959\n",
            "search 0.43115234375\n",
            "tcost icost 0.01617431640625 0.41637760400772095\n",
            "tcost icost 0.01617431640625 0.41440925002098083\n",
            "tcost icost 0.01617431640625 0.41448503732681274\n",
            "search 0.4306640625\n",
            "tcost icost 0.0184326171875 0.41704797744750977\n",
            "tcost icost 0.0183868408203125 0.4183759093284607\n",
            "tcost icost 0.0183868408203125 0.41808435320854187\n",
            "search 0.436279296875\n",
            "tcost icost 0.0182342529296875 0.4165399372577667\n",
            "tcost icost 0.0182342529296875 0.4159591495990753\n",
            "tcost icost 0.0182342529296875 0.41747450828552246\n",
            "search 0.435791015625\n",
            "tcost icost 0.017730712890625 0.41813066601753235\n",
            "tcost icost 0.017852783203125 0.4162417948246002\n",
            "tcost icost 0.017852783203125 0.41624176502227783\n",
            "search 0.43408203125\n",
            "tcost icost 0.0178375244140625 0.4185355305671692\n",
            "tcost icost 0.017852783203125 0.4158863425254822\n",
            "tcost icost 0.017852783203125 0.4162418842315674\n",
            "search 0.43408203125\n",
            "tcost icost 0.0179443359375 0.41949620842933655\n",
            "tcost icost 0.01800537109375 0.4179450571537018\n",
            "tcost icost 0.01800537109375 0.4207330644130707\n",
            "search 0.438720703125\n",
            "tcost icost 0.0176849365234375 0.4176425337791443\n",
            "tcost icost 0.0177459716796875 0.41811394691467285\n",
            "tcost icost 0.0177459716796875 0.4190775454044342\n",
            "search 0.43701171875\n",
            "tcost icost 0.0177001953125 0.41800427436828613\n",
            "tcost icost 0.0178985595703125 0.41787731647491455\n",
            "tcost icost 0.0178985595703125 0.41798362135887146\n",
            "search 0.435791015625\n",
            "tcost icost 0.0183258056640625 0.41034314036369324\n",
            "tcost icost 0.017913818359375 0.40940579771995544\n",
            "tcost icost 0.017913818359375 0.40982547402381897\n",
            "search 0.427734375\n",
            "tcost icost 0.0176849365234375 0.41409337520599365\n",
            "tcost icost 0.0178680419921875 0.41629961133003235\n",
            "tcost icost 0.0178680419921875 0.4141922891139984\n",
            "search 0.43212890625\n",
            "tcost icost 0.0177764892578125 0.41333818435668945\n",
            "tcost icost 0.0177764892578125 0.41366103291511536\n",
            "tcost icost 0.0177764892578125 0.41504621505737305\n",
            "search 0.432861328125\n",
            "tcost icost 0.01739501953125 0.4149950444698334\n",
            "tcost icost 0.0178070068359375 0.4147733449935913\n",
            "tcost icost 0.0178070068359375 0.4129927158355713\n",
            "search 0.430908203125\n",
            "tcost icost 0.0173187255859375 0.4151688814163208\n",
            "tcost icost 0.0170440673828125 0.4155602753162384\n",
            "tcost icost 0.0170440673828125 0.4155603349208832\n",
            "search 0.4326171875\n",
            "tcost icost 0.0175628662109375 0.41592180728912354\n",
            "tcost icost 0.017486572265625 0.41569530963897705\n",
            "tcost icost 0.017486572265625 0.417283833026886\n",
            "search 0.434814453125\n",
            "tcost icost 0.0178985595703125 0.4174861013889313\n",
            "tcost icost 0.0178070068359375 0.4177664816379547\n",
            "tcost icost 0.0178070068359375 0.41575315594673157\n",
            "search 0.43359375\n",
            "tcost icost 0.0177764892578125 0.4171577990055084\n",
            "tcost icost 0.017791748046875 0.41797545552253723\n",
            "tcost icost 0.017791748046875 0.4159822165966034\n",
            "search 0.433837890625\n",
            "tcost icost 0.0172119140625 0.4162085950374603\n",
            "tcost icost 0.0171356201171875 0.41567784547805786\n",
            "tcost icost 0.0171356201171875 0.41786816716194153\n",
            "search 0.43505859375\n",
            "tcost icost 0.0176849365234375 0.4204268157482147\n",
            "tcost icost 0.0176849365234375 0.41820627450942993\n",
            "tcost icost 0.0176849365234375 0.41623765230178833\n",
            "search 0.433837890625\n",
            "tcost icost 0.0177764892578125 0.41567885875701904\n",
            "tcost icost 0.017791748046875 0.41711312532424927\n",
            "tcost icost 0.017791748046875 0.4166789650917053\n",
            "search 0.4345703125\n",
            "tcost icost 0.0176544189453125 0.41728055477142334\n",
            "tcost icost 0.0177459716796875 0.4167183041572571\n",
            "tcost icost 0.0177459716796875 0.4164603650569916\n",
            "search 0.434326171875\n",
            "tcost icost 0.017181396484375 0.41223475337028503\n",
            "tcost icost 0.01641845703125 0.4124792814254761\n",
            "tcost icost 0.01641845703125 0.4128067195415497\n",
            "search 0.42919921875\n",
            "tcost icost 0.0169830322265625 0.4121037423610687\n",
            "tcost icost 0.0176239013671875 0.4121885299682617\n",
            "tcost icost 0.0176239013671875 0.4121885299682617\n",
            "search 0.4296875\n",
            "tcost icost 0.01751708984375 0.4091437757015228\n",
            "tcost icost 0.016632080078125 0.4119829535484314\n",
            "tcost icost 0.016632080078125 0.41233131289482117\n",
            "search 0.428955078125\n",
            "tcost icost 0.0182037353515625 0.41582295298576355\n",
            "tcost icost 0.0175933837890625 0.41531556844711304\n",
            "tcost icost 0.0175933837890625 0.41363340616226196\n",
            "search 0.43115234375\n",
            "tcost icost 0.0177154541015625 0.41738229990005493\n",
            "tcost icost 0.017913818359375 0.413593053817749\n",
            "tcost icost 0.017913818359375 0.41546863317489624\n",
            "search 0.433349609375\n",
            "tcost icost 0.01629638671875 0.4147600829601288\n",
            "tcost icost 0.016693115234375 0.4162670075893402\n",
            "tcost icost 0.016693115234375 0.413629949092865\n",
            "search 0.43017578125\n",
            "tcost icost 0.0175628662109375 0.4157547950744629\n",
            "tcost icost 0.0174560546875 0.4166463315486908\n",
            "tcost icost 0.0174560546875 0.41500037908554077\n",
            "search 0.4326171875\n",
            "tcost icost 0.01824951171875 0.41459181904792786\n",
            "tcost icost 0.0177764892578125 0.41442573070526123\n",
            "tcost icost 0.0177764892578125 0.4150134027004242\n",
            "search 0.432861328125\n",
            "tcost icost 0.0184173583984375 0.4154801666736603\n",
            "tcost icost 0.0181121826171875 0.4155382812023163\n",
            "tcost icost 0.0181121826171875 0.4144589304924011\n",
            "search 0.4326171875\n",
            "tcost icost 0.017791748046875 0.415944367647171\n",
            "tcost icost 0.0178375244140625 0.4154021143913269\n",
            "tcost icost 0.0178375244140625 0.4154021143913269\n",
            "search 0.43310546875\n",
            "tcost icost 0.0174560546875 0.4155419170856476\n",
            "tcost icost 0.017425537109375 0.41775789856910706\n",
            "tcost icost 0.017425537109375 0.4176921248435974\n",
            "search 0.43505859375\n",
            "tcost icost 0.017486572265625 0.41478732228279114\n",
            "tcost icost 0.0169219970703125 0.41675105690956116\n",
            "tcost icost 0.0169219970703125 0.414800226688385\n",
            "search 0.431640625\n",
            "tcost icost 0.016845703125 0.41688382625579834\n",
            "tcost icost 0.01708984375 0.4155195951461792\n",
            "tcost icost 0.01708984375 0.41521283984184265\n",
            "search 0.432373046875\n",
            "tcost icost 0.0177001953125 0.4184679687023163\n",
            "tcost icost 0.01800537109375 0.41968220472335815\n",
            "tcost icost 0.01800537109375 0.4174253046512604\n",
            "search 0.435546875\n",
            "tcost icost 0.0181732177734375 0.41693300008773804\n",
            "tcost icost 0.0177001953125 0.4168879985809326\n",
            "tcost icost 0.0177001953125 0.4176459014415741\n",
            "search 0.435546875\n",
            "tcost icost 0.0169525146484375 0.41813892126083374\n",
            "tcost icost 0.0172119140625 0.41903242468833923\n",
            "tcost icost 0.0172119140625 0.41894298791885376\n",
            "search 0.43603515625\n",
            "tcost icost 0.0182037353515625 0.4195635914802551\n",
            "tcost icost 0.018280029296875 0.41748693585395813\n",
            "tcost icost 0.018280029296875 0.4195486009120941\n",
            "search 0.437744140625\n",
            "tcost icost 0.0174102783203125 0.4139559268951416\n",
            "tcost icost 0.017486572265625 0.4151666760444641\n",
            "tcost icost 0.017486572265625 0.41762688755989075\n",
            "search 0.435302734375\n",
            "tcost icost 0.0177001953125 0.4158158600330353\n",
            "tcost icost 0.0178985595703125 0.41534554958343506\n",
            "tcost icost 0.0178985595703125 0.417919397354126\n",
            "search 0.435791015625\n",
            "tcost icost 0.017547607421875 0.41709640622138977\n",
            "tcost icost 0.0176849365234375 0.4151768982410431\n",
            "tcost icost 0.0176849365234375 0.41715553402900696\n",
            "search 0.434814453125\n",
            "tcost icost 0.0180816650390625 0.4168274998664856\n",
            "tcost icost 0.0176849365234375 0.41471096873283386\n",
            "tcost icost 0.0176849365234375 0.41499215364456177\n",
            "search 0.4326171875\n",
            "tcost icost 0.015777587890625 0.41568323969841003\n",
            "tcost icost 0.0156402587890625 0.41611939668655396\n",
            "tcost icost 0.0156402587890625 0.4154132604598999\n",
            "search 0.43115234375\n",
            "tcost icost 0.01543426513671875 0.4140254259109497\n",
            "tcost icost 0.015411376953125 0.4152776598930359\n",
            "tcost icost 0.015411376953125 0.4134168028831482\n",
            "search 0.4287109375\n",
            "tcost icost 0.0145416259765625 0.4093451499938965\n",
            "tcost icost 0.013916015625 0.4089328348636627\n",
            "tcost icost 0.013916015625 0.41026175022125244\n",
            "search 0.424072265625\n",
            "tcost icost 0.01445770263671875 0.4091668128967285\n",
            "tcost icost 0.01412200927734375 0.40865272283554077\n",
            "tcost icost 0.01412200927734375 0.4084794819355011\n",
            "search 0.422607421875\n",
            "tcost icost 0.0151824951171875 0.40280112624168396\n",
            "tcost icost 0.01470947265625 0.4006620943546295\n",
            "tcost icost 0.01470947265625 0.3995053768157959\n",
            "search 0.4140625\n",
            "ded\n",
            "time\n",
            "23 #### train ####\n",
            "repr, std, cov, conv, closs 0.030641168355941772 0.32958984375 0.2910078465938568 0.06161855161190033 0.048106104135513306\n",
            "51.54803369149802 7.794812407656286 1.0\n",
            "repr, std, cov, conv, closs 0.035005949437618256 0.327392578125 0.33858999609947205 0.06375168263912201 0.023156428709626198\n",
            "51.03537719262263 7.671149173146579 1.0\n",
            "repr, std, cov, conv, closs 0.032489046454429626 0.321044921875 0.3519546687602997 0.06044764444231987 0.016060424968600273\n",
            "50.225710520995804 7.429677260999828 1.0\n",
            "repr, std, cov, conv, closs 0.041579969227313995 0.3212890625 0.34089696407318115 0.06315021961927414 0.0004969612928107381\n",
            "49.72620481601932 7.2972051195531105 1.0\n",
            "repr, std, cov, conv, closs 0.04348630830645561 0.32373046875 0.3461635112762451 0.07402476668357849 0.0006364225409924984\n",
            "49.23166680481393 7.145636620228938 1.0\n",
            "repr, std, cov, conv, closs 0.03746216744184494 0.32568359375 0.3613604009151459 0.06478734314441681 0.0006167585961520672\n",
            "48.83957991878796 7.032272437632244 1.0\n",
            "repr, std, cov, conv, closs 0.039081037044525146 0.32763671875 0.31366631388664246 0.06765013933181763 0.013185673393309116\n",
            "49.133350969523924 6.983242844959728 1.0\n",
            "repr, std, cov, conv, closs 0.043675683438777924 0.32373046875 0.3282221555709839 0.06909734010696411 0.0006240357179194689\n",
            "49.4783179480689 7.039304710069875 1.0\n",
            "repr, std, cov, conv, closs 0.0408661849796772 0.329345703125 0.29140323400497437 0.06202470511198044 0.0018220794154331088\n",
            "50.02530893325793 7.239089304718693 1.0\n",
            "repr, std, cov, conv, closs 0.031770970672369 0.332763671875 0.31711024045944214 0.05838094279170036 0.03105308674275875\n",
            "50.275936231516795 7.333764190210612 1.0\n",
            "repr, std, cov, conv, closs 0.04061141610145569 0.33056640625 0.31013205647468567 0.055700525641441345 0.02069578506052494\n",
            "50.780964054645295 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.04398457705974579 0.33349609375 0.31019240617752075 0.06480877101421356 0.00018474854005035013\n",
            "51.08641256981525 7.6024527703488145 1.0\n",
            "repr, std, cov, conv, closs 0.029765691608190536 0.334716796875 0.2620537281036377 0.060117609798908234 0.002289110329002142\n",
            "51.85809614588655 7.810409827284005 1.0\n",
            "repr, std, cov, conv, closs 0.03648822382092476 0.332275390625 0.27364081144332886 0.06073775887489319 0.0164914820343256\n",
            "52.11790572641772 7.896755199223289 1.0\n",
            "repr, std, cov, conv, closs 0.047114789485931396 0.334716796875 0.2763988971710205 0.06386049091815948 0.015900665894150734\n",
            "52.326690265281464 8.008031259074912 1.0\n",
            "repr, std, cov, conv, closs 0.03962226212024689 0.328125 0.28622132539749146 0.06761237978935242 4.402193735586479e-05\n",
            "52.37901695554674 7.976079054470414 1.0\n",
            "repr, std, cov, conv, closs 0.040808260440826416 0.32421875 0.3987191915512085 0.06249147653579712 0.01803336851298809\n",
            "51.7028324882216 7.802607220063941 1.0\n",
            "repr, std, cov, conv, closs 0.04272880405187607 0.326171875 0.3251381814479828 0.07306604087352753 0.030350374057888985\n",
            "51.2398251178488 7.671149173146579 1.0\n",
            "repr, std, cov, conv, closs 0.046048104763031006 0.322265625 0.3612544536590576 0.07335203886032104 0.003632161533460021\n",
            "50.73023382082447 7.4893231266335505 1.0\n",
            "repr, std, cov, conv, closs 0.03355392813682556 0.3271484375 0.3197792172431946 0.06899666041135788 0.058274127542972565\n",
            "50.42691491829596 7.370506422177882 1.0\n",
            "repr, std, cov, conv, closs 0.037775732576847076 0.323974609375 0.33349132537841797 0.06161458045244217 0.002779762027785182\n",
            "49.72620481601932 7.195806385287089 1.0\n",
            "repr, std, cov, conv, closs 0.04379873722791672 0.324462890625 0.3543877601623535 0.0656275525689125 0.0004874759470112622\n",
            "49.67652828773159 7.110015372079115 1.0\n",
            "repr, std, cov, conv, closs 0.030468925833702087 0.330322265625 0.2823171615600586 0.05345335602760315 0.0010332127567380667\n",
            "49.67652828773159 6.990226087804687 1.0\n",
            "repr, std, cov, conv, closs 0.03942297399044037 0.327880859375 0.3323593735694885 0.05539025366306305 0.015281436033546925\n",
            "49.97533359965828 6.983242844959728 1.0\n",
            "repr, std, cov, conv, closs 0.038300104439258575 0.332763671875 0.31832757592201233 0.059804659336805344 0.001261914148926735\n",
            "50.5783469942225 7.1171253874511935 1.0\n",
            "repr, std, cov, conv, closs 0.03215532749891281 0.33349609375 0.2737354040145874 0.061059944331645966 0.01815541461110115\n",
            "50.780964054645295 7.231857447271422 1.0\n",
            "repr, std, cov, conv, closs 0.04824353754520416 0.330322265625 0.31451117992401123 0.07027283310890198 7.645714504178613e-05\n",
            "51.54803369149802 7.45944057783353 1.0\n",
            "repr, std, cov, conv, closs 0.04647555574774742 0.332275390625 0.2773323953151703 0.06357026100158691 0.00023625046014785767\n",
            "52.17002363214413 7.594857912436379 1.0\n",
            "repr, std, cov, conv, closs 0.047443658113479614 0.32861328125 0.34813693165779114 0.05842521786689758 0.0001768832007655874\n",
            "52.85231815920079 7.7637109505258755 1.0\n",
            "repr, std, cov, conv, closs 0.03288927674293518 0.3359375 0.2481955736875534 0.055804818868637085 0.003643905511125922\n",
            "52.90517047735999 7.857389598720513 1.0\n",
            "repr, std, cov, conv, closs 0.037895653396844864 0.33740234375 0.2589944303035736 0.06414167582988739 0.0011921047698706388\n",
            "52.79951864056024 8.008031259074912 1.0\n",
            "repr, std, cov, conv, closs 0.04630887135863304 0.327880859375 0.31921815872192383 0.07699562609195709 0.047527678310871124\n",
            "52.48382736847478 8.040111464338896 1.0\n",
            "repr, std, cov, conv, closs 0.0428604930639267 0.328125 0.2953483462333679 0.055350106209516525 0.016362007707357407\n",
            "52.17002363214413 7.833864495805746 1.0\n",
            "repr, std, cov, conv, closs 0.03675079345703125 0.326171875 0.3326812982559204 0.0639549046754837 0.0005094219231978059\n",
            "51.7028324882216 7.725008580250108 1.0\n",
            "repr, std, cov, conv, closs 0.040380965918302536 0.322998046875 0.3389771580696106 0.060774948447942734 0.00024412178026977926\n",
            "52.01382606047073 7.564554277733999 1.0\n",
            "repr, std, cov, conv, closs 0.03669891133904457 0.3212890625 0.31688255071640015 0.06309802830219269 0.015432286076247692\n",
            "51.90995424203243 7.474366918429774 1.0\n",
            "tcost icost 0.0203094482421875 0.4117130637168884\n",
            "tcost icost 0.0209503173828125 0.40996357798576355\n",
            "tcost icost 0.0209503173828125 0.411448210477829\n",
            "search 0.432373046875\n",
            "tcost icost 0.022216796875 0.4123598635196686\n",
            "tcost icost 0.0200653076171875 0.4109274446964264\n",
            "tcost icost 0.0200653076171875 0.4126437306404114\n",
            "search 0.4326171875\n",
            "tcost icost 0.0210113525390625 0.40886446833610535\n",
            "tcost icost 0.0200653076171875 0.41168880462646484\n",
            "tcost icost 0.0200653076171875 0.4083830416202545\n",
            "search 0.428466796875\n",
            "tcost icost 0.022216796875 0.4101574718952179\n",
            "tcost icost 0.0200653076171875 0.40848690271377563\n",
            "tcost icost 0.0200653076171875 0.41199374198913574\n",
            "search 0.43212890625\n",
            "tcost icost 0.020050048828125 0.4103359580039978\n",
            "tcost icost 0.0200653076171875 0.4158596992492676\n",
            "tcost icost 0.0200653076171875 0.41077330708503723\n",
            "search 0.430908203125\n",
            "tcost icost 0.0210113525390625 0.41168081760406494\n",
            "tcost icost 0.0200653076171875 0.4131642282009125\n",
            "tcost icost 0.0200653076171875 0.4113257825374603\n",
            "search 0.431396484375\n",
            "tcost icost 0.0210113525390625 0.41085341572761536\n",
            "tcost icost 0.0200653076171875 0.4132040739059448\n",
            "tcost icost 0.0200653076171875 0.4105582535266876\n",
            "search 0.4306640625\n",
            "tcost icost 0.0196075439453125 0.4116957187652588\n",
            "tcost icost 0.0209503173828125 0.4116126596927643\n",
            "tcost icost 0.0209503173828125 0.41104525327682495\n",
            "search 0.43212890625\n",
            "tcost icost 0.02093505859375 0.4131948947906494\n",
            "tcost icost 0.0213775634765625 0.41392621397972107\n",
            "tcost icost 0.0213775634765625 0.41203930974006653\n",
            "search 0.43359375\n",
            "tcost icost 0.0210113525390625 0.41111084818840027\n",
            "tcost icost 0.0200653076171875 0.41630274057388306\n",
            "tcost icost 0.0200653076171875 0.41219186782836914\n",
            "search 0.43212890625\n",
            "tcost icost 0.0225677490234375 0.41219714283943176\n",
            "tcost icost 0.0202484130859375 0.4117453992366791\n",
            "tcost icost 0.0202484130859375 0.41482388973236084\n",
            "search 0.43505859375\n",
            "tcost icost 0.0212860107421875 0.41379600763320923\n",
            "tcost icost 0.0202484130859375 0.4148334562778473\n",
            "tcost icost 0.0202484130859375 0.41398459672927856\n",
            "search 0.434326171875\n",
            "tcost icost 0.020050048828125 0.4119907021522522\n",
            "tcost icost 0.02008056640625 0.4120272099971771\n",
            "tcost icost 0.02008056640625 0.41202718019485474\n",
            "search 0.43212890625\n",
            "tcost icost 0.0211334228515625 0.41270631551742554\n",
            "tcost icost 0.0204010009765625 0.41181397438049316\n",
            "tcost icost 0.0204010009765625 0.41281235218048096\n",
            "search 0.433349609375\n",
            "tcost icost 0.0221099853515625 0.4118291735649109\n",
            "tcost icost 0.020904541015625 0.41392743587493896\n",
            "tcost icost 0.020904541015625 0.4114252030849457\n",
            "search 0.432373046875\n",
            "tcost icost 0.0212249755859375 0.41420993208885193\n",
            "tcost icost 0.0204925537109375 0.41569995880126953\n",
            "tcost icost 0.0204925537109375 0.41407451033592224\n",
            "search 0.4345703125\n",
            "tcost icost 0.0200653076171875 0.4138774573802948\n",
            "tcost icost 0.0207366943359375 0.41472387313842773\n",
            "tcost icost 0.0207366943359375 0.4164251983165741\n",
            "search 0.437255859375\n",
            "tcost icost 0.0210113525390625 0.4138701558113098\n",
            "tcost icost 0.0214691162109375 0.413707435131073\n",
            "tcost icost 0.0214691162109375 0.41624218225479126\n",
            "search 0.437744140625\n",
            "tcost icost 0.02215576171875 0.4181077778339386\n",
            "tcost icost 0.02093505859375 0.4142780601978302\n",
            "tcost icost 0.02093505859375 0.4154762625694275\n",
            "search 0.4365234375\n",
            "tcost icost 0.0218658447265625 0.41778481006622314\n",
            "tcost icost 0.0206756591796875 0.4160180389881134\n",
            "tcost icost 0.0206756591796875 0.41640040278434753\n",
            "search 0.437255859375\n",
            "tcost icost 0.0208740234375 0.4210832118988037\n",
            "tcost icost 0.0203094482421875 0.42035192251205444\n",
            "tcost icost 0.0203094482421875 0.4213976562023163\n",
            "search 0.441650390625\n",
            "tcost icost 0.021148681640625 0.4190608263015747\n",
            "tcost icost 0.0204010009765625 0.4205417037010193\n",
            "tcost icost 0.0204010009765625 0.42144179344177246\n",
            "search 0.44189453125\n",
            "tcost icost 0.0223541259765625 0.4194619059562683\n",
            "tcost icost 0.0201263427734375 0.4229275584220886\n",
            "tcost icost 0.0201263427734375 0.4196709096431732\n",
            "search 0.439697265625\n",
            "tcost icost 0.0201873779296875 0.4201095402240753\n",
            "tcost icost 0.0193023681640625 0.41899573802948\n",
            "tcost icost 0.0193023681640625 0.4198981821537018\n",
            "search 0.439208984375\n",
            "tcost icost 0.01947021484375 0.4216349422931671\n",
            "tcost icost 0.019287109375 0.4226776957511902\n",
            "tcost icost 0.019287109375 0.421595960855484\n",
            "search 0.44091796875\n",
            "tcost icost 0.01947021484375 0.4217586815357208\n",
            "tcost icost 0.0194244384765625 0.4223143458366394\n",
            "tcost icost 0.0194244384765625 0.4202762544155121\n",
            "search 0.439697265625\n",
            "tcost icost 0.0190277099609375 0.4191143214702606\n",
            "tcost icost 0.019500732421875 0.41911569237709045\n",
            "tcost icost 0.019500732421875 0.4187633991241455\n",
            "search 0.438232421875\n",
            "tcost icost 0.01953125 0.42294037342071533\n",
            "tcost icost 0.019378662109375 0.4191194474697113\n",
            "tcost icost 0.019378662109375 0.41911938786506653\n",
            "search 0.4384765625\n",
            "tcost icost 0.020477294921875 0.4191170036792755\n",
            "tcost icost 0.0194549560546875 0.41887375712394714\n",
            "tcost icost 0.0194549560546875 0.4214458167552948\n",
            "search 0.44091796875\n",
            "tcost icost 0.019195556640625 0.42180371284484863\n",
            "tcost icost 0.0193634033203125 0.42102983593940735\n",
            "tcost icost 0.0193634033203125 0.41954681277275085\n",
            "search 0.438720703125\n",
            "tcost icost 0.0195159912109375 0.42148783802986145\n",
            "tcost icost 0.019500732421875 0.4214763045310974\n",
            "tcost icost 0.019500732421875 0.42117732763290405\n",
            "search 0.440673828125\n",
            "tcost icost 0.019622802734375 0.4242146909236908\n",
            "tcost icost 0.0201416015625 0.4245326519012451\n",
            "tcost icost 0.0201416015625 0.4249527156352997\n",
            "search 0.4453125\n",
            "tcost icost 0.01910400390625 0.42224353551864624\n",
            "tcost icost 0.019378662109375 0.4226389527320862\n",
            "tcost icost 0.019378662109375 0.42488622665405273\n",
            "search 0.444091796875\n",
            "tcost icost 0.019378662109375 0.4241787791252136\n",
            "tcost icost 0.0201568603515625 0.42518433928489685\n",
            "tcost icost 0.0201568603515625 0.426540344953537\n",
            "search 0.44677734375\n",
            "tcost icost 0.0198974609375 0.42592698335647583\n",
            "tcost icost 0.019989013671875 0.4232668876647949\n",
            "tcost icost 0.019989013671875 0.42356956005096436\n",
            "search 0.443603515625\n",
            "tcost icost 0.01953125 0.4260461926460266\n",
            "tcost icost 0.019378662109375 0.42499080300331116\n",
            "tcost icost 0.019378662109375 0.4239901900291443\n",
            "search 0.443359375\n",
            "tcost icost 0.019439697265625 0.4243778586387634\n",
            "tcost icost 0.019317626953125 0.42381054162979126\n",
            "tcost icost 0.019317626953125 0.42602670192718506\n",
            "search 0.4453125\n",
            "tcost icost 0.019256591796875 0.42418617010116577\n",
            "tcost icost 0.0201416015625 0.42306283116340637\n",
            "tcost icost 0.0201416015625 0.42306283116340637\n",
            "search 0.443359375\n",
            "tcost icost 0.01947021484375 0.4237479865550995\n",
            "tcost icost 0.0193328857421875 0.42370760440826416\n",
            "tcost icost 0.0193328857421875 0.42370760440826416\n",
            "search 0.443115234375\n",
            "tcost icost 0.01983642578125 0.42192205786705017\n",
            "tcost icost 0.019317626953125 0.42134973406791687\n",
            "tcost icost 0.019317626953125 0.4213509261608124\n",
            "search 0.440673828125\n",
            "tcost icost 0.0193023681640625 0.424487441778183\n",
            "tcost icost 0.0199432373046875 0.42238038778305054\n",
            "tcost icost 0.0199432373046875 0.42184826731681824\n",
            "search 0.44189453125\n",
            "tcost icost 0.019378662109375 0.42499053478240967\n",
            "tcost icost 0.019287109375 0.42395225167274475\n",
            "tcost icost 0.019287109375 0.4234708547592163\n",
            "search 0.44287109375\n",
            "tcost icost 0.0201416015625 0.42559248208999634\n",
            "tcost icost 0.0193328857421875 0.4255010187625885\n",
            "tcost icost 0.0193328857421875 0.4255010187625885\n",
            "search 0.44482421875\n",
            "tcost icost 0.019561767578125 0.4277101755142212\n",
            "tcost icost 0.0192108154296875 0.4273932874202728\n",
            "tcost icost 0.0192108154296875 0.4270451068878174\n",
            "search 0.4462890625\n",
            "tcost icost 0.01959228515625 0.43016475439071655\n",
            "tcost icost 0.0191802978515625 0.43111345171928406\n",
            "tcost icost 0.0191802978515625 0.4301639795303345\n",
            "search 0.449462890625\n",
            "tcost icost 0.0195159912109375 0.4335751533508301\n",
            "tcost icost 0.019378662109375 0.430965781211853\n",
            "tcost icost 0.019378662109375 0.4320896863937378\n",
            "search 0.451416015625\n",
            "tcost icost 0.019134521484375 0.4341661334037781\n",
            "tcost icost 0.0196075439453125 0.4337281584739685\n",
            "tcost icost 0.0196075439453125 0.43400102853775024\n",
            "search 0.45361328125\n",
            "tcost icost 0.0207977294921875 0.4379010498523712\n",
            "tcost icost 0.021728515625 0.43371671438217163\n",
            "tcost icost 0.021728515625 0.433959037065506\n",
            "search 0.45556640625\n",
            "tcost icost 0.01953125 0.435884028673172\n",
            "tcost icost 0.0192413330078125 0.43294355273246765\n",
            "tcost icost 0.0192413330078125 0.43255460262298584\n",
            "search 0.451904296875\n",
            "tcost icost 0.019622802734375 0.43168288469314575\n",
            "tcost icost 0.01947021484375 0.4333447217941284\n",
            "tcost icost 0.01947021484375 0.4336200952529907\n",
            "search 0.453125\n",
            "tcost icost 0.01934814453125 0.4315831661224365\n",
            "tcost icost 0.019195556640625 0.4330320954322815\n",
            "tcost icost 0.019195556640625 0.43204957246780396\n",
            "search 0.451416015625\n",
            "tcost icost 0.0195159912109375 0.43673181533813477\n",
            "tcost icost 0.019256591796875 0.4360958933830261\n",
            "tcost icost 0.019256591796875 0.43646344542503357\n",
            "search 0.455810546875\n",
            "tcost icost 0.0201568603515625 0.43550047278404236\n",
            "tcost icost 0.019317626953125 0.4363192021846771\n",
            "tcost icost 0.019317626953125 0.4363192021846771\n",
            "search 0.45556640625\n",
            "tcost icost 0.0199737548828125 0.3909437358379364\n",
            "tcost icost 0.019439697265625 0.3796321153640747\n",
            "tcost icost 0.019439697265625 0.3796321153640747\n",
            "search 0.399169921875\n",
            "tcost icost 0.0215606689453125 0.3785933256149292\n",
            "tcost icost 0.0206451416015625 0.36365965008735657\n",
            "tcost icost 0.0206451416015625 0.36455586552619934\n",
            "search 0.38525390625\n",
            "ded\n",
            "time\n",
            "24 #### train ####\n",
            "repr, std, cov, conv, closs 0.05142394080758095 0.320068359375 0.38010966777801514 0.053917210549116135 0.0037392396479845047\n",
            "51.7028324882216 7.275357214562424 1.0\n",
            "repr, std, cov, conv, closs 0.04495435953140259 0.322509765625 0.4220435619354248 0.05891769751906395 0.0015670245047658682\n",
            "51.3936983639175 7.174262069119264 1.0\n",
            "repr, std, cov, conv, closs 0.03991799056529999 0.322998046875 0.3494378626346588 0.06422122567892075 0.014303749427199364\n",
            "51.18863648136744 7.039304710069875 1.0\n",
            "repr, std, cov, conv, closs 0.04713984578847885 0.330810546875 0.33002132177352905 0.0742170661687851 0.0025792717933654785\n",
            "51.13749898238506 6.990226087804687 1.0\n",
            "repr, std, cov, conv, closs 0.05453714728355408 0.325927734375 0.3102775514125824 0.06079325079917908 0.030225779861211777\n",
            "51.54803369149802 6.9972163138924905 1.0\n",
            "repr, std, cov, conv, closs 0.041800692677497864 0.332763671875 0.2762823700904846 0.06262365728616714 0.014313495717942715\n",
            "52.01382606047073 7.102912459619496 1.0\n",
            "repr, std, cov, conv, closs 0.04776036739349365 0.329833984375 0.27749955654144287 0.05855082720518112 0.015703748911619186\n",
            "52.588847507039084 7.311806826997334 1.0\n",
            "repr, std, cov, conv, closs 0.03951093554496765 0.331787109375 0.3118816018104553 0.06194622442126274 0.012366010807454586\n",
            "52.74677186869155 7.414840165828007 1.0\n",
            "repr, std, cov, conv, closs 0.03790033981204033 0.334716796875 0.2825608253479004 0.060872890055179596 0.0012938095023855567\n",
            "52.85231815920079 7.564554277733999 1.0\n",
            "repr, std, cov, conv, closs 0.04469282925128937 0.338623046875 0.259376585483551 0.056721340864896774 0.015083893202245235\n",
            "53.06404475720865 7.655829857601519 1.0\n",
            "repr, std, cov, conv, closs 0.03526041656732559 0.33203125 0.3332449793815613 0.0671120434999466 0.00010857157758437097\n",
            "53.59707946563695 7.873112235307551 1.0\n",
            "repr, std, cov, conv, closs 0.037027448415756226 0.331787109375 0.3298119306564331 0.06324117630720139 0.00017261314496863633\n",
            "53.9194669713686 7.928389632146293 1.0\n",
            "repr, std, cov, conv, closs 0.05380428582429886 0.33154296875 0.31392645835876465 0.05786452442407608 0.062430113554000854\n",
            "53.86560136999861 7.849540058661852 1.0\n",
            "repr, std, cov, conv, closs 0.04413045197725296 0.329833984375 0.3083844780921936 0.06085140258073807 0.006317565217614174\n",
            "53.650676545102584 7.755954995530346 1.0\n",
            "repr, std, cov, conv, closs 0.05494919419288635 0.3212890625 0.3481413424015045 0.06219726800918579 0.0007039193878881633\n",
            "52.90517047735999 7.519325385043623 1.0\n",
            "repr, std, cov, conv, closs 0.054614223539829254 0.32275390625 0.34281712770462036 0.05708842724561691 0.0005571712972596288\n",
            "52.641436354546116 7.385254805528658 1.0\n",
            "repr, std, cov, conv, closs 0.05511601269245148 0.318115234375 0.4371660351753235 0.055881135165691376 0.023448489606380463\n",
            "52.222193655776266 7.174262069119264 1.0\n",
            "repr, std, cov, conv, closs 0.0441056489944458 0.32373046875 0.36033374071121216 0.05705402418971062 0.00011727547826012596\n",
            "52.222193655776266 7.088727915061459 1.0\n",
            "repr, std, cov, conv, closs 0.04960772395133972 0.326171875 0.34773069620132446 0.06610918045043945 0.017150459811091423\n",
            "52.326690265281464 6.990226087804687 1.0\n",
            "repr, std, cov, conv, closs 0.044714972376823425 0.325439453125 0.3514483571052551 0.06261052936315536 4.512111627263948e-05\n",
            "52.37901695554674 6.955379566587508 1.0\n",
            "repr, std, cov, conv, closs 0.03263910859823227 0.332763671875 0.2911277711391449 0.05907759070396423 0.015561148524284363\n",
            "52.588847507039084 7.046344014779945 1.0\n",
            "repr, std, cov, conv, closs 0.03865095227956772 0.3310546875 0.3161105811595917 0.06724201887845993 0.029509253799915314\n",
            "52.69407779090066 7.145636620228938 1.0\n",
            "repr, std, cov, conv, closs 0.05807666480541229 0.329833984375 0.32387903332710266 0.0747009739279747 0.0003780921979341656\n",
            "53.276619532815246 7.355787491407577 1.0\n",
            "repr, std, cov, conv, closs 0.047586847096681595 0.334716796875 0.30685219168663025 0.07138809561729431 0.015226870775222778\n",
            "53.650676545102584 7.481841285348203 1.0\n",
            "repr, std, cov, conv, closs 0.03850312903523445 0.333740234375 0.2887856364250183 0.06447117775678635 0.00019461975898593664\n",
            "53.86560136999861 7.709581707253895 1.0\n",
            "repr, std, cov, conv, closs 0.0465695895254612 0.333984375 0.2851974368095398 0.06454078108072281 0.0004208978498354554\n",
            "54.0273598247783 7.818220237111288 1.0\n",
            "repr, std, cov, conv, closs 0.04095521196722984 0.331787109375 0.27478712797164917 0.0587787888944149 0.0003970175748690963\n",
            "54.46109449876867 7.992039188658408 1.0\n",
            "repr, std, cov, conv, closs 0.03605937212705612 0.33056640625 0.32380688190460205 0.0687502846121788 0.00046506713260896504\n",
            "54.352335475482235 8.056199727379036 1.0\n",
            "repr, std, cov, conv, closs 0.0399191752076149 0.33154296875 0.2883502244949341 0.0633181780576706 0.00010608982120174915\n",
            "53.86560136999861 8.1046579299841 1.0\n",
            "repr, std, cov, conv, closs 0.04576631635427475 0.326171875 0.32092058658599854 0.06178335100412369 0.015891365706920624\n",
            "53.70432722164768 8.128996225852498 1.0\n",
            "repr, std, cov, conv, closs 0.05249816179275513 0.32470703125 0.36355942487716675 0.06300924718379974 0.0007171601755544543\n",
            "53.01103372348517 7.8888663328904 1.0\n",
            "repr, std, cov, conv, closs 0.03587445989251137 0.3212890625 0.33831357955932617 0.06531378626823425 0.00022919363982509822\n",
            "52.37901695554674 7.7637109505258755 1.0\n",
            "repr, std, cov, conv, closs 0.03991391137242317 0.326171875 0.37656736373901367 0.060244858264923096 0.025434503331780434\n",
            "52.01382606047073 7.519325385043623 1.0\n",
            "repr, std, cov, conv, closs 0.042062461376190186 0.323486328125 0.40505659580230713 0.07078352570533752 0.00901543814688921\n",
            "51.75453532070982 7.429677260999828 1.0\n",
            "repr, std, cov, conv, closs 0.03801373392343521 0.3232421875 0.3712471127510071 0.06712445616722107 0.043320465832948685\n",
            "51.13749898238506 7.253574722417433 1.0\n",
            "repr, std, cov, conv, closs 0.04352327808737755 0.324951171875 0.35027462244033813 0.06638173758983612 0.01587572693824768\n",
            "51.18863648136744 7.1886177675195695 1.0\n",
            "tcost icost 0.0295257568359375 0.433548241853714\n",
            "tcost icost 0.0283966064453125 0.4323786795139313\n",
            "tcost icost 0.0283966064453125 0.43261459469795227\n",
            "search 0.4609375\n",
            "tcost icost 0.0283966064453125 0.432377427816391\n",
            "tcost icost 0.0283966064453125 0.4327771067619324\n",
            "tcost icost 0.0283966064453125 0.43237748742103577\n",
            "search 0.460693359375\n",
            "tcost icost 0.033203125 0.4386787712574005\n",
            "tcost icost 0.029266357421875 0.43620434403419495\n",
            "tcost icost 0.029266357421875 0.4346832036972046\n",
            "search 0.4638671875\n",
            "tcost icost 0.0283966064453125 0.4323926270008087\n",
            "tcost icost 0.0283966064453125 0.4328157305717468\n",
            "tcost icost 0.0283966064453125 0.43259403109550476\n",
            "search 0.4609375\n",
            "tcost icost 0.032012939453125 0.43532586097717285\n",
            "tcost icost 0.0283966064453125 0.43281570076942444\n",
            "tcost icost 0.0283966064453125 0.43281570076942444\n",
            "search 0.461181640625\n",
            "tcost icost 0.0295257568359375 0.4361855983734131\n",
            "tcost icost 0.0283966064453125 0.43281570076942444\n",
            "tcost icost 0.0283966064453125 0.43281570076942444\n",
            "search 0.461181640625\n",
            "tcost icost 0.032012939453125 0.43797725439071655\n",
            "tcost icost 0.0283966064453125 0.4326401650905609\n",
            "tcost icost 0.0283966064453125 0.4328773617744446\n",
            "search 0.461181640625\n",
            "tcost icost 0.032012939453125 0.4381062686443329\n",
            "tcost icost 0.0283966064453125 0.43538588285446167\n",
            "tcost icost 0.0283966064453125 0.43538588285446167\n",
            "search 0.463623046875\n",
            "tcost icost 0.029266357421875 0.4374975264072418\n",
            "tcost icost 0.033203125 0.4389239549636841\n",
            "tcost icost 0.033203125 0.4389239549636841\n",
            "search 0.47216796875\n",
            "tcost icost 0.032012939453125 0.43786752223968506\n",
            "tcost icost 0.0283966064453125 0.4352227449417114\n",
            "tcost icost 0.0283966064453125 0.43538588285446167\n",
            "search 0.463623046875\n",
            "tcost icost 0.032012939453125 0.4382459223270416\n",
            "tcost icost 0.0283966064453125 0.4353858530521393\n",
            "tcost icost 0.0283966064453125 0.4353502690792084\n",
            "search 0.463623046875\n",
            "tcost icost 0.032012939453125 0.44012606143951416\n",
            "tcost icost 0.0283966064453125 0.43702682852745056\n",
            "tcost icost 0.0283966064453125 0.4366788864135742\n",
            "search 0.465087890625\n",
            "tcost icost 0.032012939453125 0.4465996325016022\n",
            "tcost icost 0.0283966064453125 0.43853795528411865\n",
            "tcost icost 0.0283966064453125 0.43853795528411865\n",
            "search 0.466796875\n",
            "tcost icost 0.0283966064453125 0.43853795528411865\n",
            "tcost icost 0.0283966064453125 0.43853795528411865\n",
            "tcost icost 0.0283966064453125 0.43853795528411865\n",
            "search 0.466796875\n",
            "tcost icost 0.033203125 0.444641649723053\n",
            "tcost icost 0.029266357421875 0.442617267370224\n",
            "tcost icost 0.029266357421875 0.44439074397087097\n",
            "search 0.4736328125\n",
            "tcost icost 0.03607177734375 0.4463473856449127\n",
            "tcost icost 0.0283966064453125 0.44064846634864807\n",
            "tcost icost 0.0283966064453125 0.43903788924217224\n",
            "search 0.46728515625\n",
            "tcost icost 0.029266357421875 0.4422849714756012\n",
            "tcost icost 0.029266357421875 0.443927526473999\n",
            "tcost icost 0.029266357421875 0.44400447607040405\n",
            "search 0.473388671875\n",
            "tcost icost 0.033203125 0.4443201422691345\n",
            "tcost icost 0.029266357421875 0.44250261783599854\n",
            "tcost icost 0.029266357421875 0.4422849416732788\n",
            "search 0.4716796875\n",
            "tcost icost 0.0295257568359375 0.4417506456375122\n",
            "tcost icost 0.0283966064453125 0.43928202986717224\n",
            "tcost icost 0.0283966064453125 0.43928202986717224\n",
            "search 0.467529296875\n",
            "tcost icost 0.03143310546875 0.441482275724411\n",
            "tcost icost 0.0283966064453125 0.43928202986717224\n",
            "tcost icost 0.0283966064453125 0.43928202986717224\n",
            "search 0.467529296875\n",
            "tcost icost 0.029266357421875 0.4453350007534027\n",
            "tcost icost 0.029266357421875 0.44398483633995056\n",
            "tcost icost 0.029266357421875 0.4436255693435669\n",
            "search 0.472900390625\n",
            "tcost icost 0.0360107421875 0.44770118594169617\n",
            "tcost icost 0.0283966064453125 0.44032472372055054\n",
            "tcost icost 0.0283966064453125 0.43990179896354675\n",
            "search 0.46826171875\n",
            "tcost icost 0.032012939453125 0.444904625415802\n",
            "tcost icost 0.0283966064453125 0.44032472372055054\n",
            "tcost icost 0.0283966064453125 0.44141173362731934\n",
            "search 0.4697265625\n",
            "tcost icost 0.031463623046875 0.4428544342517853\n",
            "tcost icost 0.0284271240234375 0.4404645264148712\n",
            "tcost icost 0.0284271240234375 0.4404645264148712\n",
            "search 0.46875\n",
            "tcost icost 0.0361328125 0.4463033974170685\n",
            "tcost icost 0.0284271240234375 0.4404645264148712\n",
            "tcost icost 0.0284271240234375 0.4404645264148712\n",
            "search 0.46875\n",
            "tcost icost 0.032012939453125 0.4448210597038269\n",
            "tcost icost 0.0283966064453125 0.44032472372055054\n",
            "tcost icost 0.0283966064453125 0.4411787986755371\n",
            "search 0.469482421875\n",
            "tcost icost 0.03314208984375 0.44615480303764343\n",
            "tcost icost 0.0291748046875 0.4433748722076416\n",
            "tcost icost 0.0291748046875 0.4435690641403198\n",
            "search 0.47265625\n",
            "tcost icost 0.031646728515625 0.44456979632377625\n",
            "tcost icost 0.0285186767578125 0.44085073471069336\n",
            "tcost icost 0.0285186767578125 0.44085073471069336\n",
            "search 0.469482421875\n",
            "tcost icost 0.0322265625 0.44512540102005005\n",
            "tcost icost 0.02850341796875 0.44312840700149536\n",
            "tcost icost 0.02850341796875 0.4407826364040375\n",
            "search 0.46923828125\n",
            "tcost icost 0.035980224609375 0.44519007205963135\n",
            "tcost icost 0.0284881591796875 0.44073787331581116\n",
            "tcost icost 0.0284881591796875 0.44073787331581116\n",
            "search 0.46923828125\n",
            "tcost icost 0.0298614501953125 0.4444623589515686\n",
            "tcost icost 0.02850341796875 0.4408062994480133\n",
            "tcost icost 0.02850341796875 0.4408062994480133\n",
            "search 0.469482421875\n",
            "tcost icost 0.035614013671875 0.4456951320171356\n",
            "tcost icost 0.028900146484375 0.4474184513092041\n",
            "tcost icost 0.028900146484375 0.4442974328994751\n",
            "search 0.47314453125\n",
            "tcost icost 0.03106689453125 0.4412263333797455\n",
            "tcost icost 0.02825927734375 0.4383403956890106\n",
            "tcost icost 0.02825927734375 0.43871402740478516\n",
            "search 0.467041015625\n",
            "tcost icost 0.0289764404296875 0.44169890880584717\n",
            "tcost icost 0.0282745361328125 0.4386986494064331\n",
            "tcost icost 0.0282745361328125 0.4424985647201538\n",
            "search 0.470703125\n",
            "tcost icost 0.0289154052734375 0.44156593084335327\n",
            "tcost icost 0.0282440185546875 0.44079679250717163\n",
            "tcost icost 0.0282440185546875 0.4382041394710541\n",
            "search 0.466552734375\n",
            "tcost icost 0.031158447265625 0.4429854154586792\n",
            "tcost icost 0.0282745361328125 0.439043253660202\n",
            "tcost icost 0.0282745361328125 0.4387072026729584\n",
            "search 0.467041015625\n",
            "tcost icost 0.02880859375 0.44293543696403503\n",
            "tcost icost 0.02880859375 0.44293543696403503\n",
            "tcost icost 0.02880859375 0.44389697909355164\n",
            "search 0.47265625\n",
            "tcost icost 0.032012939453125 0.4446793794631958\n",
            "tcost icost 0.028411865234375 0.4396471679210663\n",
            "tcost icost 0.028411865234375 0.440143346786499\n",
            "search 0.468505859375\n",
            "tcost icost 0.031402587890625 0.44212424755096436\n",
            "tcost icost 0.0283966064453125 0.43957048654556274\n",
            "tcost icost 0.0283966064453125 0.43923163414001465\n",
            "search 0.467529296875\n",
            "tcost icost 0.02947998046875 0.4462476074695587\n",
            "tcost icost 0.0286865234375 0.44559988379478455\n",
            "tcost icost 0.0286865234375 0.4424039423465729\n",
            "search 0.47119140625\n",
            "tcost icost 0.028228759765625 0.43803077936172485\n",
            "tcost icost 0.028228759765625 0.43803077936172485\n",
            "tcost icost 0.028228759765625 0.43803077936172485\n",
            "search 0.46630859375\n",
            "tcost icost 0.0288238525390625 0.44091588258743286\n",
            "tcost icost 0.0282135009765625 0.43781164288520813\n",
            "tcost icost 0.0282135009765625 0.43781161308288574\n",
            "search 0.466064453125\n",
            "tcost icost 0.0288238525390625 0.44185900688171387\n",
            "tcost icost 0.0282135009765625 0.4385824501514435\n",
            "tcost icost 0.0282135009765625 0.4385824501514435\n",
            "search 0.466796875\n",
            "tcost icost 0.031585693359375 0.44510728120803833\n",
            "tcost icost 0.028289794921875 0.4394364058971405\n",
            "tcost icost 0.028289794921875 0.4394364058971405\n",
            "search 0.4677734375\n",
            "tcost icost 0.0298614501953125 0.44537392258644104\n",
            "tcost icost 0.0291290283203125 0.444764107465744\n",
            "tcost icost 0.0291290283203125 0.4460621476173401\n",
            "search 0.47509765625\n",
            "tcost icost 0.035552978515625 0.4474984109401703\n",
            "tcost icost 0.0288543701171875 0.44391030073165894\n",
            "tcost icost 0.0288543701171875 0.44391030073165894\n",
            "search 0.47265625\n",
            "tcost icost 0.0291748046875 0.4438987970352173\n",
            "tcost icost 0.028350830078125 0.442780077457428\n",
            "tcost icost 0.028350830078125 0.442780077457428\n",
            "search 0.47119140625\n",
            "tcost icost 0.0285797119140625 0.4432276785373688\n",
            "tcost icost 0.0285797119140625 0.4432276785373688\n",
            "tcost icost 0.0285797119140625 0.4456978142261505\n",
            "search 0.474365234375\n",
            "tcost icost 0.028106689453125 0.4420586824417114\n",
            "tcost icost 0.028106689453125 0.4423145651817322\n",
            "tcost icost 0.028106689453125 0.44472959637641907\n",
            "search 0.472900390625\n",
            "tcost icost 0.027374267578125 0.44146448373794556\n",
            "tcost icost 0.027374267578125 0.4391191303730011\n",
            "tcost icost 0.027374267578125 0.44162946939468384\n",
            "search 0.468994140625\n",
            "tcost icost 0.0284271240234375 0.4364355206489563\n",
            "tcost icost 0.02777099609375 0.4316931962966919\n",
            "tcost icost 0.02777099609375 0.4316931962966919\n",
            "search 0.45947265625\n",
            "tcost icost 0.0311126708984375 0.44398197531700134\n",
            "tcost icost 0.02813720703125 0.4372957646846771\n",
            "tcost icost 0.02813720703125 0.4372957646846771\n",
            "search 0.46533203125\n",
            "tcost icost 0.030914306640625 0.445556640625\n",
            "tcost icost 0.0281219482421875 0.43589383363723755\n",
            "tcost icost 0.0281219482421875 0.4358937740325928\n",
            "search 0.4638671875\n",
            "tcost icost 0.031463623046875 0.44481855630874634\n",
            "tcost icost 0.0282440185546875 0.4387059509754181\n",
            "tcost icost 0.0282440185546875 0.4387059509754181\n",
            "search 0.467041015625\n",
            "tcost icost 0.032135009765625 0.44619515538215637\n",
            "tcost icost 0.0289764404296875 0.44345101714134216\n",
            "tcost icost 0.0289764404296875 0.44586458802223206\n",
            "search 0.474853515625\n",
            "tcost icost 0.031524658203125 0.44680169224739075\n",
            "tcost icost 0.029693603515625 0.44663992524147034\n",
            "tcost icost 0.029693603515625 0.4447900354862213\n",
            "search 0.474609375\n",
            "tcost icost 0.0290679931640625 0.44432222843170166\n",
            "tcost icost 0.0277557373046875 0.44263532757759094\n",
            "tcost icost 0.0277557373046875 0.44263532757759094\n",
            "search 0.470458984375\n",
            "tcost icost 0.0288848876953125 0.44180405139923096\n",
            "tcost icost 0.0272979736328125 0.4388373792171478\n",
            "tcost icost 0.0272979736328125 0.4426056742668152\n",
            "search 0.469970703125\n",
            "tcost icost 0.03070068359375 0.44033002853393555\n",
            "tcost icost 0.0281219482421875 0.43609365820884705\n",
            "tcost icost 0.0281219482421875 0.43648427724838257\n",
            "search 0.464599609375\n",
            "tcost icost 0.03314208984375 0.4304526448249817\n",
            "tcost icost 0.0268096923828125 0.41521990299224854\n",
            "tcost icost 0.0268096923828125 0.4151017963886261\n",
            "search 0.44189453125\n",
            "tcost icost 0.0288238525390625 0.42734748125076294\n",
            "tcost icost 0.0267486572265625 0.4190480411052704\n",
            "tcost icost 0.0267486572265625 0.4190480411052704\n",
            "search 0.44580078125\n",
            "tcost icost 0.028411865234375 0.43718743324279785\n",
            "tcost icost 0.0277862548828125 0.4321863651275635\n",
            "tcost icost 0.0277862548828125 0.4341403543949127\n",
            "search 0.4619140625\n",
            "tcost icost 0.0301361083984375 0.43679678440093994\n",
            "tcost icost 0.02703857421875 0.42391058802604675\n",
            "tcost icost 0.02703857421875 0.42452552914619446\n",
            "search 0.45166015625\n",
            "tcost icost 0.03082275390625 0.4420647919178009\n",
            "tcost icost 0.0281219482421875 0.4401961863040924\n",
            "tcost icost 0.0281219482421875 0.4402778744697571\n",
            "search 0.46826171875\n",
            "tcost icost 0.03399658203125 0.4447798430919647\n",
            "tcost icost 0.027435302734375 0.42916616797447205\n",
            "tcost icost 0.027435302734375 0.42926499247550964\n",
            "search 0.45654296875\n",
            "tcost icost 0.027740478515625 0.43236079812049866\n",
            "tcost icost 0.027740478515625 0.43236079812049866\n",
            "tcost icost 0.027740478515625 0.43236079812049866\n",
            "search 0.460205078125\n",
            "tcost icost 0.0302734375 0.4410325884819031\n",
            "tcost icost 0.027252197265625 0.4274452328681946\n",
            "tcost icost 0.027252197265625 0.4274452328681946\n",
            "search 0.454833984375\n",
            "tcost icost 0.026763916015625 0.4208509027957916\n",
            "tcost icost 0.026763916015625 0.41948753595352173\n",
            "tcost icost 0.026763916015625 0.42004990577697754\n",
            "search 0.447021484375\n",
            "tcost icost 0.0289306640625 0.4389807879924774\n",
            "tcost icost 0.0271148681640625 0.4336920380592346\n",
            "tcost icost 0.0271148681640625 0.4336920380592346\n",
            "search 0.460693359375\n",
            "tcost icost 0.029693603515625 0.43190598487854004\n",
            "tcost icost 0.0267486572265625 0.4174162745475769\n",
            "tcost icost 0.0267486572265625 0.41631418466567993\n",
            "search 0.443115234375\n",
            "tcost icost 0.0288238525390625 0.42534303665161133\n",
            "tcost icost 0.0267333984375 0.41842636466026306\n",
            "tcost icost 0.0267333984375 0.4176458418369293\n",
            "search 0.4443359375\n",
            "tcost icost 0.0300140380859375 0.39778199791908264\n",
            "tcost icost 0.029937744140625 0.37766027450561523\n",
            "tcost icost 0.029937744140625 0.37766027450561523\n",
            "search 0.40771484375\n",
            "tcost icost 0.031982421875 0.44171303510665894\n",
            "tcost icost 0.0269317626953125 0.431244432926178\n",
            "tcost icost 0.0269317626953125 0.4309599995613098\n",
            "search 0.457763671875\n",
            "tcost icost 0.0289154052734375 0.4377362132072449\n",
            "tcost icost 0.026947021484375 0.43332594633102417\n",
            "tcost icost 0.026947021484375 0.4316537380218506\n",
            "search 0.45849609375\n",
            "tcost icost 0.028900146484375 0.44375094771385193\n",
            "tcost icost 0.0273895263671875 0.4413391649723053\n",
            "tcost icost 0.0273895263671875 0.4413391947746277\n",
            "search 0.46875\n",
            "tcost icost 0.0309906005859375 0.4207354485988617\n",
            "tcost icost 0.0275726318359375 0.4006709158420563\n",
            "tcost icost 0.0275726318359375 0.4006709158420563\n",
            "search 0.42822265625\n",
            "tcost icost 0.0328369140625 0.43168747425079346\n",
            "tcost icost 0.0269317626953125 0.40776026248931885\n",
            "tcost icost 0.0269317626953125 0.40776026248931885\n",
            "search 0.4345703125\n",
            "tcost icost 0.0289306640625 0.4362224340438843\n",
            "tcost icost 0.0268096923828125 0.430877149105072\n",
            "tcost icost 0.0268096923828125 0.4296155869960785\n",
            "search 0.45654296875\n",
            "tcost icost 0.0298309326171875 0.4333204925060272\n",
            "tcost icost 0.0267333984375 0.41902804374694824\n",
            "tcost icost 0.0267333984375 0.41902804374694824\n",
            "search 0.44580078125\n",
            "tcost icost 0.029266357421875 0.42314139008522034\n",
            "tcost icost 0.0272064208984375 0.40406084060668945\n",
            "tcost icost 0.0272064208984375 0.40406084060668945\n",
            "search 0.43115234375\n",
            "tcost icost 0.02752685546875 0.42121803760528564\n",
            "tcost icost 0.0272216796875 0.3991171419620514\n",
            "tcost icost 0.0272216796875 0.3987326920032501\n",
            "search 0.42578125\n",
            "tcost icost 0.029052734375 0.40849804878234863\n",
            "tcost icost 0.0277862548828125 0.39886409044265747\n",
            "tcost icost 0.0277862548828125 0.39780741930007935\n",
            "search 0.425537109375\n",
            "tcost icost 0.0294952392578125 0.43580710887908936\n",
            "tcost icost 0.0274505615234375 0.43001070618629456\n",
            "tcost icost 0.0274505615234375 0.429477721452713\n",
            "search 0.456787109375\n",
            "tcost icost 0.0288848876953125 0.4409634470939636\n",
            "tcost icost 0.02716064453125 0.4359632432460785\n",
            "tcost icost 0.02716064453125 0.4359632432460785\n",
            "search 0.463134765625\n",
            "tcost icost 0.028564453125 0.4012950658798218\n",
            "tcost icost 0.0294952392578125 0.37514472007751465\n",
            "tcost icost 0.0294952392578125 0.37450531125068665\n",
            "search 0.404052734375\n",
            "tcost icost 0.02880859375 0.409150630235672\n",
            "tcost icost 0.0292816162109375 0.3842303454875946\n",
            "tcost icost 0.0292816162109375 0.38475537300109863\n",
            "search 0.4140625\n",
            "tcost icost 0.02862548828125 0.40542730689048767\n",
            "tcost icost 0.02777099609375 0.39609673619270325\n",
            "tcost icost 0.02777099609375 0.39609673619270325\n",
            "search 0.423828125\n",
            "tcost icost 0.033721923828125 0.44115734100341797\n",
            "tcost icost 0.0268402099609375 0.42218926548957825\n",
            "tcost icost 0.0268402099609375 0.4231579005718231\n",
            "search 0.449951171875\n",
            "tcost icost 0.0268402099609375 0.41485726833343506\n",
            "tcost icost 0.0268402099609375 0.4137246906757355\n",
            "tcost icost 0.0268402099609375 0.4144119620323181\n",
            "search 0.441162109375\n",
            "tcost icost 0.0286865234375 0.4205481708049774\n",
            "tcost icost 0.0268707275390625 0.41237887740135193\n",
            "tcost icost 0.0268707275390625 0.4121110439300537\n",
            "search 0.43896484375\n",
            "tcost icost 0.02789306640625 0.4361945390701294\n",
            "tcost icost 0.02789306640625 0.43427574634552\n",
            "tcost icost 0.02789306640625 0.43427574634552\n",
            "search 0.462158203125\n",
            "tcost icost 0.0294036865234375 0.42587897181510925\n",
            "tcost icost 0.02691650390625 0.40909749269485474\n",
            "tcost icost 0.02691650390625 0.40909749269485474\n",
            "search 0.43603515625\n",
            "tcost icost 0.02935791015625 0.40917709469795227\n",
            "tcost icost 0.02874755859375 0.39004290103912354\n",
            "tcost icost 0.02874755859375 0.3891143500804901\n",
            "search 0.41796875\n",
            "tcost icost 0.032379150390625 0.35202813148498535\n",
            "tcost icost 0.032379150390625 0.353304386138916\n",
            "tcost icost 0.032379150390625 0.353304386138916\n",
            "search 0.3857421875\n",
            "tcost icost 0.034149169921875 0.3369433581829071\n",
            "tcost icost 0.034637451171875 0.33193954825401306\n",
            "tcost icost 0.034637451171875 0.33193954825401306\n",
            "search 0.36669921875\n",
            "tcost icost 0.032623291015625 0.3677365183830261\n",
            "tcost icost 0.03216552734375 0.3550182580947876\n",
            "tcost icost 0.03216552734375 0.3550182580947876\n",
            "search 0.38720703125\n",
            "tcost icost 0.0290374755859375 0.4088003635406494\n",
            "tcost icost 0.027679443359375 0.39821216464042664\n",
            "tcost icost 0.027679443359375 0.398372083902359\n",
            "search 0.426025390625\n",
            "tcost icost 0.032135009765625 0.418865829706192\n",
            "tcost icost 0.0285797119140625 0.39038652181625366\n",
            "tcost icost 0.0285797119140625 0.39038652181625366\n",
            "search 0.4189453125\n",
            "tcost icost 0.0278778076171875 0.401947557926178\n",
            "tcost icost 0.0281829833984375 0.3934193551540375\n",
            "tcost icost 0.0281829833984375 0.3941771388053894\n",
            "search 0.42236328125\n",
            "tcost icost 0.0271148681640625 0.41741466522216797\n",
            "tcost icost 0.0269012451171875 0.409969300031662\n",
            "tcost icost 0.0269012451171875 0.4099693298339844\n",
            "search 0.436767578125\n",
            "tcost icost 0.0321044921875 0.4237389862537384\n",
            "tcost icost 0.0278472900390625 0.395813912153244\n",
            "tcost icost 0.0278472900390625 0.39649879932403564\n",
            "search 0.42431640625\n",
            "tcost icost 0.02862548828125 0.4284020662307739\n",
            "tcost icost 0.02655029296875 0.4193286597728729\n",
            "tcost icost 0.02655029296875 0.4193286597728729\n",
            "search 0.446044921875\n",
            "tcost icost 0.0308685302734375 0.40824413299560547\n",
            "tcost icost 0.02911376953125 0.3750596046447754\n",
            "tcost icost 0.02911376953125 0.3750596344470978\n",
            "search 0.404052734375\n",
            "tcost icost 0.033111572265625 0.4332282245159149\n",
            "tcost icost 0.0268096923828125 0.4146783947944641\n",
            "tcost icost 0.0268096923828125 0.4146783947944641\n",
            "search 0.441650390625\n",
            "tcost icost 0.028656005859375 0.4298313856124878\n",
            "tcost icost 0.026519775390625 0.42097797989845276\n",
            "tcost icost 0.026519775390625 0.42097797989845276\n",
            "search 0.447509765625\n",
            "tcost icost 0.0271759033203125 0.4274594187736511\n",
            "tcost icost 0.0271759033203125 0.427908718585968\n",
            "tcost icost 0.0271759033203125 0.4286127984523773\n",
            "search 0.455810546875\n",
            "tcost icost 0.030029296875 0.37943556904792786\n",
            "tcost icost 0.030487060546875 0.3710859417915344\n",
            "tcost icost 0.030487060546875 0.3710859417915344\n",
            "search 0.401611328125\n",
            "tcost icost 0.0291900634765625 0.41721197962760925\n",
            "tcost icost 0.027801513671875 0.39796632528305054\n",
            "tcost icost 0.027801513671875 0.39796632528305054\n",
            "search 0.42578125\n",
            "tcost icost 0.02960205078125 0.4304647743701935\n",
            "tcost icost 0.0268096923828125 0.41429707407951355\n",
            "tcost icost 0.0268096923828125 0.4154738485813141\n",
            "search 0.4423828125\n",
            "tcost icost 0.0270233154296875 0.43050268292427063\n",
            "tcost icost 0.0270233154296875 0.43045350909233093\n",
            "tcost icost 0.0270233154296875 0.4304267168045044\n",
            "search 0.45751953125\n",
            "tcost icost 0.0255889892578125 0.4262583553791046\n",
            "tcost icost 0.02117919921875 0.3985077142715454\n",
            "tcost icost 0.02117919921875 0.3985077142715454\n",
            "search 0.419677734375\n",
            "tcost icost 0.028411865234375 0.43889763951301575\n",
            "tcost icost 0.027862548828125 0.43372130393981934\n",
            "tcost icost 0.027862548828125 0.4333045780658722\n",
            "search 0.461181640625\n",
            "tcost icost 0.0287017822265625 0.4420030415058136\n",
            "tcost icost 0.02691650390625 0.43958520889282227\n",
            "tcost icost 0.02691650390625 0.4402221441268921\n",
            "search 0.467041015625\n",
            "tcost icost 0.033782958984375 0.43896427750587463\n",
            "tcost icost 0.0269317626953125 0.4215547442436218\n",
            "tcost icost 0.0269317626953125 0.4207003712654114\n",
            "search 0.447509765625\n",
            "tcost icost 0.033905029296875 0.4376082122325897\n",
            "tcost icost 0.027130126953125 0.42503029108047485\n",
            "tcost icost 0.027130126953125 0.42599934339523315\n",
            "search 0.453125\n",
            "tcost icost 0.027923583984375 0.43340864777565\n",
            "tcost icost 0.027923583984375 0.43340864777565\n",
            "tcost icost 0.027923583984375 0.43340864777565\n",
            "search 0.461181640625\n",
            "tcost icost 0.027313232421875 0.4103828966617584\n",
            "tcost icost 0.0271759033203125 0.40295934677124023\n",
            "tcost icost 0.0271759033203125 0.40295934677124023\n",
            "search 0.43017578125\n",
            "ded\n",
            "time\n",
            "25 #### train ####\n",
            "repr, std, cov, conv, closs 0.03719896078109741 0.32275390625 0.3635871112346649 0.061667777597904205 0.01491750217974186\n",
            "51.44509206228141 7.074571697095573 1.0\n",
            "repr, std, cov, conv, closs 0.039232153445482254 0.328857421875 0.3341255784034729 0.06820961833000183 0.0002890495234169066\n",
            "51.496537154343685 7.046344014779945 1.0\n",
            "repr, std, cov, conv, closs 0.05654895678162575 0.326904296875 0.3540871739387512 0.052332233637571335 0.00041948462603613734\n",
            "52.37901695554674 7.124242512838644 1.0\n",
            "repr, std, cov, conv, closs 0.057082369923591614 0.33056640625 0.3100006878376007 0.05332323908805847 0.01535297092050314\n",
            "52.588847507039084 7.231857447271422 1.0\n",
            "repr, std, cov, conv, closs 0.04888679087162018 0.332275390625 0.3057239353656769 0.06843826174736023 8.118060941342264e-05\n",
            "53.3832260485004 7.444544045199088 1.0\n",
            "repr, std, cov, conv, closs 0.05072425678372383 0.335205078125 0.2688084542751312 0.06954894959926605 0.030348248779773712\n",
            "53.758031548869326 7.564554277733999 1.0\n",
            "repr, std, cov, conv, closs 0.0553206242620945 0.33154296875 0.31841957569122314 0.06346669793128967 0.015647366642951965\n",
            "54.0273598247783 7.725008580250108 1.0\n",
            "repr, std, cov, conv, closs 0.04484137147665024 0.330322265625 0.29501765966415405 0.06155058369040489 0.011211706325411797\n",
            "54.46109449876867 7.818220237111288 1.0\n",
            "repr, std, cov, conv, closs 0.052737802267074585 0.326904296875 0.3352513313293457 0.05769335478544235 0.01687300205230713\n",
            "54.679265861229545 7.717291288961148 1.0\n",
            "repr, std, cov, conv, closs 0.03287776559591293 0.330078125 0.3263319134712219 0.06453707814216614 0.013229763135313988\n",
            "54.13546857178767 7.648181675925595 1.0\n",
            "repr, std, cov, conv, closs 0.03717814385890961 0.327392578125 0.3034754991531372 0.07683862745761871 0.0005835203337483108\n",
            "52.90517047735999 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.032215408980846405 0.3271484375 0.3041626214981079 0.06518547236919403 0.02902791276574135\n",
            "52.48382736847478 7.429677260999828 1.0\n",
            "repr, std, cov, conv, closs 0.030257614329457283 0.325439453125 0.3159688711166382 0.0586082860827446 0.053809717297554016\n",
            "51.90995424203243 7.2463283940234104 1.0\n",
            "repr, std, cov, conv, closs 0.04125692695379257 0.323486328125 0.3472394645214081 0.06605811417102814 0.00015511378296650946\n",
            "51.85809614588655 7.217415399057909 1.0\n",
            "repr, std, cov, conv, closs 0.03908157721161842 0.327392578125 0.32232666015625 0.06180199235677719 0.0013437398010864854\n",
            "51.2398251178488 7.074571697095573 1.0\n",
            "repr, std, cov, conv, closs 0.044704537838697433 0.326171875 0.3579849600791931 0.06404401361942291 0.04722925275564194\n",
            "51.29106494296664 7.032272437632244 1.0\n",
            "repr, std, cov, conv, closs 0.044365569949150085 0.326416015625 0.3058791756629944 0.06372778117656708 0.0007624795543961227\n",
            "51.7028324882216 6.948431135452057 1.0\n",
            "repr, std, cov, conv, closs 0.0505751371383667 0.3310546875 0.31975841522216797 0.06171226501464844 0.0003652437881100923\n",
            "52.065839886531194 6.976266578381347 1.0\n",
            "repr, std, cov, conv, closs 0.04121493548154831 0.3291015625 0.30762094259262085 0.06687009334564209 0.0003542298509273678\n",
            "52.37901695554674 7.124242512838644 1.0\n",
            "repr, std, cov, conv, closs 0.04774376377463341 0.33447265625 0.28775039315223694 0.06753773987293243 0.01479227002710104\n",
            "52.95807564783734 7.231857447271422 1.0\n",
            "repr, std, cov, conv, closs 0.04617458954453468 0.3330078125 0.264184832572937 0.05378212034702301 0.01967048831284046\n",
            "53.9194669713686 7.414840165828007 1.0\n",
            "repr, std, cov, conv, closs 0.0381304994225502 0.33154296875 0.3244030475616455 0.06140640377998352 0.01515603344887495\n",
            "54.13546857178767 7.5118135714721515 1.0\n",
            "repr, std, cov, conv, closs 0.043008118867874146 0.3349609375 0.2696305215358734 0.06568561494350433 0.00042606814531609416\n",
            "54.73394512709077 7.725008580250108 1.0\n",
            "repr, std, cov, conv, closs 0.03855802118778229 0.33203125 0.3016214370727539 0.06632550060749054 0.012257056310772896\n",
            "54.46109449876867 7.678820322319725 1.0\n",
            "repr, std, cov, conv, closs 0.0465913750231266 0.32763671875 0.32076597213745117 0.06388585269451141 0.015660325065255165\n",
            "53.59707946563695 7.564554277733999 1.0\n",
            "repr, std, cov, conv, closs 0.0477459616959095 0.3291015625 0.28759312629699707 0.06151595711708069 0.031417373567819595\n",
            "53.59707946563695 7.5118135714721515 1.0\n",
            "repr, std, cov, conv, closs 0.032723743468523026 0.329345703125 0.30659955739974976 0.05891150236129761 0.02748795598745346\n",
            "53.17022591076781 7.437106938260827 1.0\n",
            "repr, std, cov, conv, closs 0.03775550797581673 0.323974609375 0.36008375883102417 0.0634218081831932 0.009357710368931293\n",
            "52.85231815920079 7.385254805528658 1.0\n",
            "repr, std, cov, conv, closs 0.03369978815317154 0.33056640625 0.2847849130630493 0.05799204111099243 0.0006289373268373311\n",
            "52.43139597250228 7.253574722417433 1.0\n",
            "repr, std, cov, conv, closs 0.0380261167883873 0.326416015625 0.35864758491516113 0.067591592669487 0.0009059166768565774\n",
            "51.90995424203243 7.16709497414512 1.0\n",
            "repr, std, cov, conv, closs 0.04848919436335564 0.329833984375 0.2776573896408081 0.0677393227815628 0.016051044687628746\n",
            "52.065839886531194 7.09581664297652 1.0\n",
            "repr, std, cov, conv, closs 0.037171974778175354 0.330810546875 0.29333215951919556 0.06404707580804825 0.03576525300741196\n",
            "52.17002363214413 7.1171253874511935 1.0\n",
            "repr, std, cov, conv, closs 0.04035623371601105 0.324951171875 0.31674906611442566 0.06177554652094841 0.013801331631839275\n",
            "52.37901695554674 7.09581664297652 1.0\n",
            "repr, std, cov, conv, closs 0.04533596709370613 0.33056640625 0.2771138548851013 0.06657871603965759 0.031053798273205757\n",
            "52.79951864056024 7.2030021916723745 1.0\n",
            "repr, std, cov, conv, closs 0.039616893976926804 0.331787109375 0.2822933793067932 0.07302738726139069 0.017765473574399948\n",
            "53.01103372348517 7.355787491407577 1.0\n",
            "repr, std, cov, conv, closs 0.04080259054899216 0.333740234375 0.2732223868370056 0.07107704132795334 0.0005088144680485129\n",
            "53.329896152348056 7.45944057783353 1.0\n",
            "tcost icost 0.0423583984375 0.4489858150482178\n",
            "tcost icost 0.035675048828125 0.4460476040840149\n",
            "tcost icost 0.035675048828125 0.44629737734794617\n",
            "search 0.48193359375\n",
            "tcost icost 0.04803466796875 0.44997748732566833\n",
            "tcost icost 0.037689208984375 0.4473848342895508\n",
            "tcost icost 0.037689208984375 0.44743502140045166\n",
            "search 0.485107421875\n",
            "tcost icost 0.037689208984375 0.4501498341560364\n",
            "tcost icost 0.044219970703125 0.4551199674606323\n",
            "tcost icost 0.044219970703125 0.4523368179798126\n",
            "search 0.49658203125\n",
            "tcost icost 0.038726806640625 0.45142826437950134\n",
            "tcost icost 0.037689208984375 0.45152756571769714\n",
            "tcost icost 0.037689208984375 0.4501498341560364\n",
            "search 0.48779296875\n",
            "tcost icost 0.044189453125 0.4524073600769043\n",
            "tcost icost 0.03765869140625 0.45018282532691956\n",
            "tcost icost 0.03765869140625 0.45018282532691956\n",
            "search 0.48779296875\n",
            "tcost icost 0.03887939453125 0.45130038261413574\n",
            "tcost icost 0.037872314453125 0.45006707310676575\n",
            "tcost icost 0.037872314453125 0.45006707310676575\n",
            "search 0.48779296875\n",
            "tcost icost 0.03912353515625 0.44994300603866577\n",
            "tcost icost 0.035675048828125 0.4489143490791321\n",
            "tcost icost 0.035675048828125 0.44961756467819214\n",
            "search 0.4853515625\n",
            "tcost icost 0.047882080078125 0.4546225965023041\n",
            "tcost icost 0.03570556640625 0.4485481381416321\n",
            "tcost icost 0.03570556640625 0.4485481381416321\n",
            "search 0.484130859375\n",
            "tcost icost 0.046295166015625 0.45257675647735596\n",
            "tcost icost 0.03570556640625 0.4485480487346649\n",
            "tcost icost 0.03570556640625 0.4485480487346649\n",
            "search 0.484130859375\n",
            "tcost icost 0.038665771484375 0.4526981711387634\n",
            "tcost icost 0.035675048828125 0.4486643373966217\n",
            "tcost icost 0.035675048828125 0.4486643373966217\n",
            "search 0.484375\n",
            "tcost icost 0.038726806640625 0.4500288665294647\n",
            "tcost icost 0.03564453125 0.44852039217948914\n",
            "tcost icost 0.03564453125 0.44867053627967834\n",
            "search 0.484375\n",
            "tcost icost 0.0423583984375 0.4513680338859558\n",
            "tcost icost 0.035675048828125 0.4486415982246399\n",
            "tcost icost 0.035675048828125 0.4486415982246399\n",
            "search 0.484375\n",
            "tcost icost 0.048065185546875 0.4524324834346771\n",
            "tcost icost 0.0377197265625 0.44987952709198\n",
            "tcost icost 0.0377197265625 0.45009374618530273\n",
            "search 0.48779296875\n",
            "tcost icost 0.04833984375 0.4520260691642761\n",
            "tcost icost 0.038055419921875 0.4499339163303375\n",
            "tcost icost 0.038055419921875 0.45250779390335083\n",
            "search 0.490478515625\n",
            "tcost icost 0.037994384765625 0.4499724805355072\n",
            "tcost icost 0.044281005859375 0.45202797651290894\n",
            "tcost icost 0.044281005859375 0.45202797651290894\n",
            "search 0.496337890625\n",
            "tcost icost 0.042877197265625 0.45116347074508667\n",
            "tcost icost 0.035675048828125 0.44891512393951416\n",
            "tcost icost 0.035675048828125 0.44891512393951416\n",
            "search 0.484619140625\n",
            "tcost icost 0.042816162109375 0.4511996805667877\n",
            "tcost icost 0.03564453125 0.44886264204978943\n",
            "tcost icost 0.03564453125 0.44886264204978943\n",
            "search 0.484619140625\n",
            "tcost icost 0.0462646484375 0.45251789689064026\n",
            "tcost icost 0.035736083984375 0.4484668970108032\n",
            "tcost icost 0.035736083984375 0.4484668970108032\n",
            "search 0.484130859375\n",
            "tcost icost 0.0421142578125 0.4542884826660156\n",
            "tcost icost 0.0357666015625 0.45087552070617676\n",
            "tcost icost 0.0357666015625 0.45308083295822144\n",
            "search 0.48876953125\n",
            "tcost icost 0.0377197265625 0.45264720916748047\n",
            "tcost icost 0.04425048828125 0.45789214968681335\n",
            "tcost icost 0.04425048828125 0.4547986388206482\n",
            "search 0.4990234375\n",
            "tcost icost 0.038909912109375 0.45383232831954956\n",
            "tcost icost 0.037933349609375 0.45524492859840393\n",
            "tcost icost 0.037933349609375 0.45258277654647827\n",
            "search 0.490478515625\n",
            "tcost icost 0.03912353515625 0.45246410369873047\n",
            "tcost icost 0.035675048828125 0.4532092213630676\n",
            "tcost icost 0.035675048828125 0.4539870321750641\n",
            "search 0.48974609375\n",
            "tcost icost 0.044281005859375 0.45481178164482117\n",
            "tcost icost 0.037872314453125 0.4526232182979584\n",
            "tcost icost 0.037872314453125 0.4526232182979584\n",
            "search 0.490478515625\n",
            "tcost icost 0.042510986328125 0.45396584272384644\n",
            "tcost icost 0.03564453125 0.45121151208877563\n",
            "tcost icost 0.03564453125 0.45121151208877563\n",
            "search 0.48681640625\n",
            "tcost icost 0.042266845703125 0.4541071057319641\n",
            "tcost icost 0.03570556640625 0.4510590434074402\n",
            "tcost icost 0.03570556640625 0.45382076501846313\n",
            "search 0.489501953125\n",
            "tcost icost 0.03997802734375 0.45457908511161804\n",
            "tcost icost 0.035675048828125 0.4523807764053345\n",
            "tcost icost 0.035675048828125 0.4523807764053345\n",
            "search 0.488037109375\n",
            "tcost icost 0.038787841796875 0.4565485119819641\n",
            "tcost icost 0.03564453125 0.4524441361427307\n",
            "tcost icost 0.03564453125 0.4524441361427307\n",
            "search 0.488037109375\n",
            "tcost icost 0.038482666015625 0.45394086837768555\n",
            "tcost icost 0.03570556640625 0.4522218704223633\n",
            "tcost icost 0.03570556640625 0.4522218704223633\n",
            "search 0.48779296875\n",
            "tcost icost 0.0426025390625 0.45513319969177246\n",
            "tcost icost 0.035614013671875 0.452261745929718\n",
            "tcost icost 0.035614013671875 0.4551066756248474\n",
            "search 0.49072265625\n",
            "tcost icost 0.040496826171875 0.45459985733032227\n",
            "tcost icost 0.035736083984375 0.4527367055416107\n",
            "tcost icost 0.035736083984375 0.4527367055416107\n",
            "search 0.48828125\n",
            "tcost icost 0.03594970703125 0.45280128717422485\n",
            "tcost icost 0.03594970703125 0.4526934325695038\n",
            "tcost icost 0.03594970703125 0.45558691024780273\n",
            "search 0.491455078125\n",
            "tcost icost 0.0357666015625 0.4520944058895111\n",
            "tcost icost 0.0357666015625 0.4520944058895111\n",
            "tcost icost 0.0357666015625 0.4520944058895111\n",
            "search 0.48779296875\n",
            "tcost icost 0.042205810546875 0.455583781003952\n",
            "tcost icost 0.035736083984375 0.45219001173973083\n",
            "tcost icost 0.035736083984375 0.4534958302974701\n",
            "search 0.4892578125\n",
            "tcost icost 0.03948974609375 0.45448121428489685\n",
            "tcost icost 0.03582763671875 0.4520249366760254\n",
            "tcost icost 0.03582763671875 0.4520249366760254\n",
            "search 0.48779296875\n",
            "tcost icost 0.038177490234375 0.4556875228881836\n",
            "tcost icost 0.037384033203125 0.4540131986141205\n",
            "tcost icost 0.037384033203125 0.4543602764606476\n",
            "search 0.49169921875\n",
            "tcost icost 0.039398193359375 0.45435482263565063\n",
            "tcost icost 0.03594970703125 0.4518539011478424\n",
            "tcost icost 0.03594970703125 0.4518539011478424\n",
            "search 0.48779296875\n",
            "tcost icost 0.03802490234375 0.4557788074016571\n",
            "tcost icost 0.037261962890625 0.45450514554977417\n",
            "tcost icost 0.037261962890625 0.45450514554977417\n",
            "search 0.491943359375\n",
            "tcost icost 0.039520263671875 0.4552513659000397\n",
            "tcost icost 0.035797119140625 0.45277321338653564\n",
            "tcost icost 0.035797119140625 0.45277321338653564\n",
            "search 0.48876953125\n",
            "tcost icost 0.047882080078125 0.45751476287841797\n",
            "tcost icost 0.03759765625 0.4561891555786133\n",
            "tcost icost 0.03759765625 0.45480820536613464\n",
            "search 0.492431640625\n",
            "tcost icost 0.039794921875 0.4553256034851074\n",
            "tcost icost 0.035675048828125 0.452976793050766\n",
            "tcost icost 0.035675048828125 0.452976793050766\n",
            "search 0.488525390625\n",
            "tcost icost 0.04241943359375 0.456100195646286\n",
            "tcost icost 0.03564453125 0.45314109325408936\n",
            "tcost icost 0.03564453125 0.45314109325408936\n",
            "search 0.48876953125\n",
            "tcost icost 0.035614013671875 0.4528034031391144\n",
            "tcost icost 0.035614013671875 0.45317378640174866\n",
            "tcost icost 0.035614013671875 0.45317378640174866\n",
            "search 0.48876953125\n",
            "tcost icost 0.048126220703125 0.4573221802711487\n",
            "tcost icost 0.037750244140625 0.4546830654144287\n",
            "tcost icost 0.037750244140625 0.4546830654144287\n",
            "search 0.492431640625\n",
            "tcost icost 0.039581298828125 0.4575527012348175\n",
            "tcost icost 0.035736083984375 0.4528449773788452\n",
            "tcost icost 0.035736083984375 0.4528449773788452\n",
            "search 0.488525390625\n",
            "tcost icost 0.042266845703125 0.4562966823577881\n",
            "tcost icost 0.03570556640625 0.4529767632484436\n",
            "tcost icost 0.03570556640625 0.4529767334461212\n",
            "search 0.488525390625\n",
            "tcost icost 0.038360595703125 0.4543093144893646\n",
            "tcost icost 0.044342041015625 0.45656898617744446\n",
            "tcost icost 0.044342041015625 0.45656898617744446\n",
            "search 0.5009765625\n",
            "tcost icost 0.038299560546875 0.45437753200531006\n",
            "tcost icost 0.0443115234375 0.45665088295936584\n",
            "tcost icost 0.0443115234375 0.45665088295936584\n",
            "search 0.5009765625\n",
            "tcost icost 0.043304443359375 0.4553341865539551\n",
            "tcost icost 0.038421630859375 0.4542350769042969\n",
            "tcost icost 0.038421630859375 0.4542350769042969\n",
            "search 0.49267578125\n",
            "tcost icost 0.0369873046875 0.4536496102809906\n",
            "tcost icost 0.0369873046875 0.4536495804786682\n",
            "tcost icost 0.0369873046875 0.4536495804786682\n",
            "search 0.49072265625\n",
            "tcost icost 0.039398193359375 0.45480427145957947\n",
            "tcost icost 0.0386962890625 0.45553058385849\n",
            "tcost icost 0.0386962890625 0.4536890983581543\n",
            "search 0.4921875\n",
            "tcost icost 0.0394287109375 0.4590426981449127\n",
            "tcost icost 0.035736083984375 0.45622652769088745\n",
            "tcost icost 0.035736083984375 0.45622649788856506\n",
            "search 0.491943359375\n",
            "tcost icost 0.03948974609375 0.45797228813171387\n",
            "tcost icost 0.035797119140625 0.4552771747112274\n",
            "tcost icost 0.035797119140625 0.4552771747112274\n",
            "search 0.4912109375\n",
            "tcost icost 0.04241943359375 0.4589526951313019\n",
            "tcost icost 0.035675048828125 0.4556911587715149\n",
            "tcost icost 0.035675048828125 0.45569121837615967\n",
            "search 0.491455078125\n",
            "tcost icost 0.03875732421875 0.45895034074783325\n",
            "tcost icost 0.03765869140625 0.45745453238487244\n",
            "tcost icost 0.03765869140625 0.45745450258255005\n",
            "search 0.4951171875\n",
            "tcost icost 0.042144775390625 0.45915719866752625\n",
            "tcost icost 0.035736083984375 0.4554499685764313\n",
            "tcost icost 0.035736083984375 0.4554499685764313\n",
            "search 0.4912109375\n",
            "tcost icost 0.038421630859375 0.45703911781311035\n",
            "tcost icost 0.0357666015625 0.455075740814209\n",
            "tcost icost 0.0357666015625 0.455075740814209\n",
            "search 0.49072265625\n",
            "tcost icost 0.047607421875 0.46026626229286194\n",
            "tcost icost 0.0357666015625 0.4549359679222107\n",
            "tcost icost 0.0357666015625 0.4549359679222107\n",
            "search 0.49072265625\n",
            "tcost icost 0.042205810546875 0.4587514400482178\n",
            "tcost icost 0.03570556640625 0.4551454782485962\n",
            "tcost icost 0.03570556640625 0.4551454782485962\n",
            "search 0.49072265625\n",
            "tcost icost 0.03997802734375 0.4576644003391266\n",
            "tcost icost 0.035675048828125 0.45781999826431274\n",
            "tcost icost 0.035675048828125 0.45531973242759705\n",
            "search 0.490966796875\n",
            "tcost icost 0.0435791015625 0.4597717523574829\n",
            "tcost icost 0.035980224609375 0.4557744562625885\n",
            "tcost icost 0.035980224609375 0.4557744562625885\n",
            "search 0.49169921875\n",
            "tcost icost 0.03839111328125 0.45715051889419556\n",
            "tcost icost 0.035888671875 0.4548887014389038\n",
            "tcost icost 0.035888671875 0.4548887014389038\n",
            "search 0.49072265625\n",
            "tcost icost 0.039398193359375 0.45743057131767273\n",
            "tcost icost 0.035980224609375 0.45470744371414185\n",
            "tcost icost 0.035980224609375 0.45470744371414185\n",
            "search 0.490478515625\n",
            "tcost icost 0.042449951171875 0.45855844020843506\n",
            "tcost icost 0.035675048828125 0.4553544521331787\n",
            "tcost icost 0.035675048828125 0.4553544521331787\n",
            "search 0.490966796875\n",
            "tcost icost 0.0472412109375 0.4596365690231323\n",
            "tcost icost 0.035675048828125 0.4556473195552826\n",
            "tcost icost 0.035675048828125 0.4556473195552826\n",
            "search 0.4912109375\n",
            "tcost icost 0.039276123046875 0.45754215121269226\n",
            "tcost icost 0.038543701171875 0.4562791883945465\n",
            "tcost icost 0.038543701171875 0.4562791883945465\n",
            "search 0.494873046875\n",
            "tcost icost 0.03900146484375 0.45828184485435486\n",
            "tcost icost 0.038055419921875 0.4568708837032318\n",
            "tcost icost 0.038055419921875 0.4568708837032318\n",
            "search 0.494873046875\n",
            "tcost icost 0.040924072265625 0.459224134683609\n",
            "tcost icost 0.037017822265625 0.453348308801651\n",
            "tcost icost 0.037017822265625 0.453348308801651\n",
            "search 0.490478515625\n",
            "tcost icost 0.04913330078125 0.45816871523857117\n",
            "tcost icost 0.038726806640625 0.4558323621749878\n",
            "tcost icost 0.038726806640625 0.4559367895126343\n",
            "search 0.494873046875\n",
            "tcost icost 0.041656494140625 0.4579421281814575\n",
            "tcost icost 0.036285400390625 0.45581918954849243\n",
            "tcost icost 0.036285400390625 0.4558192193508148\n",
            "search 0.4921875\n",
            "tcost icost 0.0418701171875 0.4590192437171936\n",
            "tcost icost 0.035888671875 0.45746415853500366\n",
            "tcost icost 0.035888671875 0.4548887014389038\n",
            "search 0.49072265625\n",
            "tcost icost 0.03790283203125 0.45911121368408203\n",
            "tcost icost 0.037200927734375 0.45779144763946533\n",
            "tcost icost 0.037200927734375 0.45779144763946533\n",
            "search 0.494873046875\n",
            "tcost icost 0.038330078125 0.4606023132801056\n",
            "tcost icost 0.0361328125 0.45572569966316223\n",
            "tcost icost 0.0361328125 0.45572569966316223\n",
            "search 0.491943359375\n",
            "tcost icost 0.039337158203125 0.45876243710517883\n",
            "tcost icost 0.036041259765625 0.45594993233680725\n",
            "tcost icost 0.036041259765625 0.45594993233680725\n",
            "search 0.4921875\n",
            "tcost icost 0.0401611328125 0.4576779007911682\n",
            "tcost icost 0.036041259765625 0.4571266174316406\n",
            "tcost icost 0.036041259765625 0.4571266174316406\n",
            "search 0.4931640625\n",
            "tcost icost 0.039215087890625 0.4592745304107666\n",
            "tcost icost 0.0384521484375 0.45760107040405273\n",
            "tcost icost 0.0384521484375 0.45790669322013855\n",
            "search 0.49658203125\n",
            "tcost icost 0.041290283203125 0.4592955708503723\n",
            "tcost icost 0.036041259765625 0.4597398638725281\n",
            "tcost icost 0.036041259765625 0.457126647233963\n",
            "search 0.4931640625\n",
            "tcost icost 0.04156494140625 0.4569178819656372\n",
            "tcost icost 0.036865234375 0.4572485089302063\n",
            "tcost icost 0.036865234375 0.4572485089302063\n",
            "search 0.494140625\n",
            "tcost icost 0.04168701171875 0.4605638086795807\n",
            "tcost icost 0.0360107421875 0.4560288190841675\n",
            "tcost icost 0.0360107421875 0.45589765906333923\n",
            "search 0.49169921875\n",
            "tcost icost 0.0462646484375 0.45649710297584534\n",
            "tcost icost 0.040557861328125 0.4552549123764038\n",
            "tcost icost 0.040557861328125 0.4552549123764038\n",
            "search 0.495849609375\n",
            "tcost icost 0.04345703125 0.45940113067626953\n",
            "tcost icost 0.035919189453125 0.45711106061935425\n",
            "tcost icost 0.035919189453125 0.45711106061935425\n",
            "search 0.492919921875\n",
            "tcost icost 0.03643798828125 0.45514801144599915\n",
            "tcost icost 0.03643798828125 0.45514801144599915\n",
            "tcost icost 0.03643798828125 0.45514801144599915\n",
            "search 0.491455078125\n",
            "tcost icost 0.03814697265625 0.4614108204841614\n",
            "tcost icost 0.0369873046875 0.45975354313850403\n",
            "tcost icost 0.0369873046875 0.46169134974479675\n",
            "search 0.49853515625\n",
            "tcost icost 0.0423583984375 0.4600278437137604\n",
            "tcost icost 0.03564453125 0.4564780294895172\n",
            "tcost icost 0.03564453125 0.4564780294895172\n",
            "search 0.4921875\n",
            "tcost icost 0.0321044921875 0.4494006931781769\n",
            "tcost icost 0.0298309326171875 0.4413079023361206\n",
            "tcost icost 0.0298309326171875 0.4413079023361206\n",
            "search 0.47119140625\n",
            "tcost icost 0.0283355712890625 0.4304562211036682\n",
            "tcost icost 0.029998779296875 0.42821407318115234\n",
            "tcost icost 0.029998779296875 0.42665380239486694\n",
            "search 0.456787109375\n",
            "ded\n",
            "time\n",
            "26 #### train ####\n",
            "repr, std, cov, conv, closs 0.03200172632932663 0.331787109375 0.30713582038879395 0.056596945971250534 0.03200491890311241\n",
            "53.490045883823434 7.526844710428666 1.0\n",
            "repr, std, cov, conv, closs 0.03910031169652939 0.33349609375 0.27553847432136536 0.06932909786701202 0.00016184660489670932\n",
            "53.543535929707254 7.632908226564242 1.0\n",
            "repr, std, cov, conv, closs 0.04930201545357704 0.32373046875 0.36684805154800415 0.049727004021406174 0.0003885492333211005\n",
            "53.490045883823434 7.587270641794586 1.0\n",
            "repr, std, cov, conv, closs 0.03699767589569092 0.332275390625 0.3279382288455963 0.0499543622136116 0.01635384000837803\n",
            "53.17022591076781 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.03647317737340927 0.330322265625 0.29014068841934204 0.05092880129814148 0.014905708841979504\n",
            "53.22339613667857 7.466900018411363 1.0\n",
            "repr, std, cov, conv, closs 0.03701052442193031 0.329345703125 0.3164323568344116 0.051004961133003235 0.029056282714009285\n",
            "53.11710880196585 7.392640060334186 1.0\n",
            "repr, std, cov, conv, closs 0.037732869386672974 0.330322265625 0.2963505983352661 0.06045518442988396 0.013417378067970276\n",
            "53.11710880196585 7.400032700394519 1.0\n",
            "repr, std, cov, conv, closs 0.043717823922634125 0.326171875 0.35624486207962036 0.06399565935134888 0.01622067391872406\n",
            "53.276619532815246 7.407432733094913 1.0\n",
            "repr, std, cov, conv, closs 0.04538331925868988 0.327880859375 0.3264322280883789 0.07376235723495483 0.02985302358865738\n",
            "53.06404475720865 7.348439052355222 1.0\n",
            "repr, std, cov, conv, closs 0.034615445882081985 0.3310546875 0.2918983995914459 0.07126548886299133 0.00035904059768654406\n",
            "52.90517047735999 7.392640060334186 1.0\n",
            "repr, std, cov, conv, closs 0.03803016245365143 0.329833984375 0.3000525236129761 0.05591902881860733 0.015035728923976421\n",
            "53.3832260485004 7.407432733094913 1.0\n",
            "repr, std, cov, conv, closs 0.04409293085336685 0.32470703125 0.34041154384613037 0.06074494868516922 0.05917617306113243\n",
            "53.490045883823434 7.422255005993835 1.0\n",
            "repr, std, cov, conv, closs 0.04116209223866463 0.32861328125 0.30489861965179443 0.06837095320224762 0.02292776294052601\n",
            "53.650676545102584 7.407432733094913 1.0\n",
            "repr, std, cov, conv, closs 0.03910187631845474 0.32861328125 0.30787843465805054 0.06096977740526199 0.0001395791332470253\n",
            "53.59707946563695 7.370506422177882 1.0\n",
            "repr, std, cov, conv, closs 0.035176441073417664 0.331787109375 0.30036550760269165 0.06371370702981949 0.016015859320759773\n",
            "53.9194669713686 7.45944057783353 1.0\n",
            "repr, std, cov, conv, closs 0.0431942455470562 0.334228515625 0.26296281814575195 0.07115429639816284 0.0004554504994302988\n",
            "54.18960404035945 7.556997280453546 1.0\n",
            "repr, std, cov, conv, closs 0.0431981198489666 0.330322265625 0.3090229034423828 0.05829288065433502 0.001053539919666946\n",
            "54.679265861229545 7.648181675925595 1.0\n",
            "repr, std, cov, conv, closs 0.050129834562540054 0.327392578125 0.30452287197113037 0.06997862458229065 0.0003517775039654225\n",
            "54.46109449876867 7.671149173146579 1.0\n",
            "repr, std, cov, conv, closs 0.04051203280687332 0.32568359375 0.3651488423347473 0.06794749200344086 0.01180794183164835\n",
            "54.0273598247783 7.504309262209943 1.0\n",
            "repr, std, cov, conv, closs 0.04453881084918976 0.326171875 0.3164326548576355 0.06807693839073181 0.010657435283064842\n",
            "53.650676545102584 7.392640060334186 1.0\n",
            "repr, std, cov, conv, closs 0.0365779846906662 0.32568359375 0.35500234365463257 0.061912901699543 0.0002424785343464464\n",
            "52.74677186869155 7.217415399057909 1.0\n",
            "repr, std, cov, conv, closs 0.047579988837242126 0.3251953125 0.3291189670562744 0.06606438755989075 0.00026932594482786953\n",
            "52.48382736847478 7.152782256849166 1.0\n",
            "repr, std, cov, conv, closs 0.04015538468956947 0.325927734375 0.3386293351650238 0.06274829804897308 0.045624665915966034\n",
            "52.53631119584325 7.046344014779945 1.0\n",
            "repr, std, cov, conv, closs 0.04050173610448837 0.325927734375 0.32005777955055237 0.05958493798971176 0.04375302046537399\n",
            "52.641436354546116 7.011217743736587 1.0\n",
            "repr, std, cov, conv, closs 0.043109502643346786 0.33056640625 0.2874649167060852 0.07033219933509827 0.005673195701092482\n",
            "53.70432722164768 7.145636620228938 1.0\n",
            "repr, std, cov, conv, closs 0.06122410297393799 0.327880859375 0.328188955783844 0.07288168370723724 0.014658160507678986\n",
            "53.9194669713686 7.210205193864046 1.0\n",
            "repr, std, cov, conv, closs 0.03439777344465256 0.335693359375 0.25830334424972534 0.06577104330062866 0.015503374859690666\n",
            "54.352335475482235 7.2972051195531105 1.0\n",
            "repr, std, cov, conv, closs 0.05099920183420181 0.326904296875 0.33185577392578125 0.06669499725103378 0.014777084812521935\n",
            "54.57007114886069 7.363143278898984 1.0\n",
            "repr, std, cov, conv, closs 0.03501197695732117 0.33203125 0.29078516364097595 0.07120893895626068 0.012908156029880047\n",
            "54.78867907221785 7.481841285348203 1.0\n",
            "repr, std, cov, conv, closs 0.0517377033829689 0.33154296875 0.3299311399459839 0.06479552388191223 0.0003534192219376564\n",
            "54.95320953026038 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.06089905649423599 0.32373046875 0.2955361008644104 0.06545781344175339 0.018488651141524315\n",
            "55.339037939659136 7.6024527703488145 1.0\n",
            "repr, std, cov, conv, closs 0.05015547573566437 0.330322265625 0.27715471386909485 0.06299184262752533 0.029113559052348137\n",
            "55.39437697759879 7.6176652783422805 1.0\n",
            "repr, std, cov, conv, closs 0.053272999823093414 0.322998046875 0.37999430298805237 0.05814730376005173 0.06262264400720596\n",
            "55.063170902530416 7.400032700394519 1.0\n",
            "repr, std, cov, conv, closs 0.04818040877580643 0.327880859375 0.3091181218624115 0.06749056279659271 0.010939383879303932\n",
            "55.339037939659136 7.341097954400822 1.0\n",
            "repr, std, cov, conv, closs 0.06734821200370789 0.32568359375 0.33918341994285583 0.06445088982582092 0.012109196744859219\n",
            "54.62464122000954 7.16709497414512 1.0\n",
            "repr, std, cov, conv, closs 0.051041603088378906 0.3251953125 0.3457413911819458 0.06258659064769745 0.0020035274792462587\n",
            "54.13546857178767 7.053390358794724 1.0\n",
            "tcost icost 0.033111572265625 0.4414225220680237\n",
            "tcost icost 0.03082275390625 0.4283594489097595\n",
            "tcost icost 0.03082275390625 0.4283594489097595\n",
            "search 0.459228515625\n",
            "tcost icost 0.03436279296875 0.45116159319877625\n",
            "tcost icost 0.03082275390625 0.4263719916343689\n",
            "tcost icost 0.03082275390625 0.42819637060165405\n",
            "search 0.458984375\n",
            "tcost icost 0.036102294921875 0.43993517756462097\n",
            "tcost icost 0.03082275390625 0.42438453435897827\n",
            "tcost icost 0.03082275390625 0.42438453435897827\n",
            "search 0.455078125\n",
            "tcost icost 0.036102294921875 0.43727752566337585\n",
            "tcost icost 0.03082275390625 0.42239710688591003\n",
            "tcost icost 0.03082275390625 0.42239710688591003\n",
            "search 0.453125\n",
            "tcost icost 0.035430908203125 0.43913260102272034\n",
            "tcost icost 0.03082275390625 0.4204096496105194\n",
            "tcost icost 0.03082275390625 0.4204096496105194\n",
            "search 0.451171875\n",
            "tcost icost 0.033355712890625 0.439579039812088\n",
            "tcost icost 0.030059814453125 0.41350945830345154\n",
            "tcost icost 0.030059814453125 0.4151299297809601\n",
            "search 0.445068359375\n",
            "tcost icost 0.0323486328125 0.42381224036216736\n",
            "tcost icost 0.03021240234375 0.4130662977695465\n",
            "tcost icost 0.03021240234375 0.4130662977695465\n",
            "search 0.443359375\n",
            "tcost icost 0.034027099609375 0.43204593658447266\n",
            "tcost icost 0.030487060546875 0.4147879183292389\n",
            "tcost icost 0.030487060546875 0.4131126403808594\n",
            "search 0.443603515625\n",
            "tcost icost 0.03521728515625 0.4221499562263489\n",
            "tcost icost 0.0301055908203125 0.4086669683456421\n",
            "tcost icost 0.0301055908203125 0.40799084305763245\n",
            "search 0.43798828125\n",
            "tcost icost 0.034423828125 0.4264179468154907\n",
            "tcost icost 0.030853271484375 0.4106365442276001\n",
            "tcost icost 0.030853271484375 0.41263264417648315\n",
            "search 0.443359375\n",
            "tcost icost 0.03564453125 0.42194947600364685\n",
            "tcost icost 0.033416748046875 0.4227086007595062\n",
            "tcost icost 0.033416748046875 0.41994407773017883\n",
            "search 0.453369140625\n",
            "tcost icost 0.03509521484375 0.4170530438423157\n",
            "tcost icost 0.03302001953125 0.41141650080680847\n",
            "tcost icost 0.03302001953125 0.4137175679206848\n",
            "search 0.44677734375\n",
            "tcost icost 0.0445556640625 0.4258537292480469\n",
            "tcost icost 0.0335693359375 0.41241809725761414\n",
            "tcost icost 0.0335693359375 0.41479015350341797\n",
            "search 0.4482421875\n",
            "tcost icost 0.04339599609375 0.4215351343154907\n",
            "tcost icost 0.036224365234375 0.42118099331855774\n",
            "tcost icost 0.036224365234375 0.4174399971961975\n",
            "search 0.45361328125\n",
            "tcost icost 0.050506591796875 0.4247244596481323\n",
            "tcost icost 0.039703369140625 0.4174450933933258\n",
            "tcost icost 0.039703369140625 0.4206428825855255\n",
            "search 0.46044921875\n",
            "tcost icost 0.036651611328125 0.4164658784866333\n",
            "tcost icost 0.034576416015625 0.4097072184085846\n",
            "tcost icost 0.034576416015625 0.41192784905433655\n",
            "search 0.446533203125\n",
            "tcost icost 0.035003662109375 0.4093495309352875\n",
            "tcost icost 0.0302734375 0.39872434735298157\n",
            "tcost icost 0.0302734375 0.4005800485610962\n",
            "search 0.430908203125\n",
            "tcost icost 0.03472900390625 0.41033682227134705\n",
            "tcost icost 0.03472900390625 0.40736374258995056\n",
            "tcost icost 0.03472900390625 0.40736374258995056\n",
            "search 0.442138671875\n",
            "tcost icost 0.04217529296875 0.4048860967159271\n",
            "tcost icost 0.03289794921875 0.4030206799507141\n",
            "tcost icost 0.03289794921875 0.4030206799507141\n",
            "search 0.43603515625\n",
            "tcost icost 0.029998779296875 0.3956678807735443\n",
            "tcost icost 0.029449462890625 0.38778045773506165\n",
            "tcost icost 0.029449462890625 0.38778045773506165\n",
            "search 0.417236328125\n",
            "tcost icost 0.03466796875 0.4017069637775421\n",
            "tcost icost 0.03350830078125 0.4007643759250641\n",
            "tcost icost 0.03350830078125 0.4007643759250641\n",
            "search 0.434326171875\n",
            "tcost icost 0.037994384765625 0.3984745740890503\n",
            "tcost icost 0.03570556640625 0.39547258615493774\n",
            "tcost icost 0.03570556640625 0.39547258615493774\n",
            "search 0.43115234375\n",
            "tcost icost 0.042144775390625 0.3949095606803894\n",
            "tcost icost 0.03570556640625 0.39234742522239685\n",
            "tcost icost 0.03570556640625 0.39234742522239685\n",
            "search 0.427978515625\n",
            "tcost icost 0.037078857421875 0.39166074991226196\n",
            "tcost icost 0.035430908203125 0.39548251032829285\n",
            "tcost icost 0.035430908203125 0.39243122935295105\n",
            "search 0.427734375\n",
            "tcost icost 0.034271240234375 0.38955265283584595\n",
            "tcost icost 0.032073974609375 0.38912713527679443\n",
            "tcost icost 0.032073974609375 0.3900277614593506\n",
            "search 0.422119140625\n",
            "tcost icost 0.03717041015625 0.38960662484169006\n",
            "tcost icost 0.035186767578125 0.39246252179145813\n",
            "tcost icost 0.035186767578125 0.39215198159217834\n",
            "search 0.42724609375\n",
            "tcost icost 0.0296173095703125 0.3677732050418854\n",
            "tcost icost 0.0306549072265625 0.3625447154045105\n",
            "tcost icost 0.0306549072265625 0.36272382736206055\n",
            "search 0.3935546875\n",
            "tcost icost 0.03619384765625 0.38690438866615295\n",
            "tcost icost 0.0274200439453125 0.37931522727012634\n",
            "tcost icost 0.0274200439453125 0.37803974747657776\n",
            "search 0.4052734375\n",
            "tcost icost 0.0386962890625 0.38671252131462097\n",
            "tcost icost 0.03631591796875 0.3845376670360565\n",
            "tcost icost 0.03631591796875 0.3845376670360565\n",
            "search 0.4208984375\n",
            "tcost icost 0.035888671875 0.3883167505264282\n",
            "tcost icost 0.03466796875 0.38507279753685\n",
            "tcost icost 0.03466796875 0.384034663438797\n",
            "search 0.418701171875\n",
            "tcost icost 0.044769287109375 0.38749396800994873\n",
            "tcost icost 0.03662109375 0.39118388295173645\n",
            "tcost icost 0.03662109375 0.3936001658439636\n",
            "search 0.43017578125\n",
            "tcost icost 0.035491943359375 0.3828621208667755\n",
            "tcost icost 0.0279083251953125 0.3821173310279846\n",
            "tcost icost 0.0279083251953125 0.3821173310279846\n",
            "search 0.409912109375\n",
            "tcost icost 0.03778076171875 0.38035422563552856\n",
            "tcost icost 0.035430908203125 0.37863776087760925\n",
            "tcost icost 0.035430908203125 0.37863776087760925\n",
            "search 0.4140625\n",
            "tcost icost 0.036346435546875 0.37967896461486816\n",
            "tcost icost 0.035736083984375 0.38403570652008057\n",
            "tcost icost 0.035736083984375 0.38163989782333374\n",
            "search 0.417236328125\n",
            "tcost icost 0.03662109375 0.38650327920913696\n",
            "tcost icost 0.03662109375 0.38650327920913696\n",
            "tcost icost 0.03662109375 0.38650327920913696\n",
            "search 0.423095703125\n",
            "tcost icost 0.035552978515625 0.3785686790943146\n",
            "tcost icost 0.0333251953125 0.37978312373161316\n",
            "tcost icost 0.0333251953125 0.3825313150882721\n",
            "search 0.416015625\n",
            "tcost icost 0.0350341796875 0.3788396716117859\n",
            "tcost icost 0.0325927734375 0.3833160400390625\n",
            "tcost icost 0.0325927734375 0.3781088590621948\n",
            "search 0.41064453125\n",
            "tcost icost 0.042144775390625 0.3727782666683197\n",
            "tcost icost 0.038299560546875 0.36690282821655273\n",
            "tcost icost 0.038299560546875 0.370341420173645\n",
            "search 0.40869140625\n",
            "tcost icost 0.037322998046875 0.3840174674987793\n",
            "tcost icost 0.033721923828125 0.3833644688129425\n",
            "tcost icost 0.033721923828125 0.3833644688129425\n",
            "search 0.4169921875\n",
            "tcost icost 0.03857421875 0.37304186820983887\n",
            "tcost icost 0.03857421875 0.3763517141342163\n",
            "tcost icost 0.03857421875 0.37304186820983887\n",
            "search 0.41162109375\n",
            "tcost icost 0.040740966796875 0.3812080919742584\n",
            "tcost icost 0.03271484375 0.3738366961479187\n",
            "tcost icost 0.03271484375 0.37438490986824036\n",
            "search 0.406982421875\n",
            "tcost icost 0.039337158203125 0.3805568218231201\n",
            "tcost icost 0.036651611328125 0.38323143124580383\n",
            "tcost icost 0.036651611328125 0.3806619346141815\n",
            "search 0.417236328125\n",
            "tcost icost 0.0433349609375 0.38410425186157227\n",
            "tcost icost 0.037811279296875 0.3844902217388153\n",
            "tcost icost 0.037811279296875 0.38599830865859985\n",
            "search 0.423828125\n",
            "tcost icost 0.0288848876953125 0.38324621319770813\n",
            "tcost icost 0.0298004150390625 0.38067272305488586\n",
            "tcost icost 0.0298004150390625 0.3817567229270935\n",
            "search 0.41162109375\n",
            "tcost icost 0.034637451171875 0.38171032071113586\n",
            "tcost icost 0.0321044921875 0.38298049569129944\n",
            "tcost icost 0.0321044921875 0.38060474395751953\n",
            "search 0.41259765625\n",
            "tcost icost 0.03826904296875 0.38328444957733154\n",
            "tcost icost 0.03564453125 0.3843548595905304\n",
            "tcost icost 0.03564453125 0.38612625002861023\n",
            "search 0.421875\n",
            "tcost icost 0.036865234375 0.38684287667274475\n",
            "tcost icost 0.036163330078125 0.38464832305908203\n",
            "tcost icost 0.036163330078125 0.3845768868923187\n",
            "search 0.420654296875\n",
            "tcost icost 0.03997802734375 0.38778793811798096\n",
            "tcost icost 0.03936767578125 0.37666937708854675\n",
            "tcost icost 0.03936767578125 0.3756101727485657\n",
            "search 0.414794921875\n",
            "tcost icost 0.044219970703125 0.38586148619651794\n",
            "tcost icost 0.037200927734375 0.38884496688842773\n",
            "tcost icost 0.037200927734375 0.3890562057495117\n",
            "search 0.42626953125\n",
            "tcost icost 0.03900146484375 0.38833674788475037\n",
            "tcost icost 0.03900146484375 0.3895331621170044\n",
            "tcost icost 0.03900146484375 0.38833674788475037\n",
            "search 0.427490234375\n",
            "tcost icost 0.03802490234375 0.3868658244609833\n",
            "tcost icost 0.038177490234375 0.3838285207748413\n",
            "tcost icost 0.038177490234375 0.3835550546646118\n",
            "search 0.421630859375\n",
            "tcost icost 0.042877197265625 0.3931806981563568\n",
            "tcost icost 0.039154052734375 0.387500524520874\n",
            "tcost icost 0.039154052734375 0.38922974467277527\n",
            "search 0.42822265625\n",
            "tcost icost 0.03741455078125 0.371997207403183\n",
            "tcost icost 0.033843994140625 0.35654884576797485\n",
            "tcost icost 0.033843994140625 0.35565078258514404\n",
            "search 0.3896484375\n",
            "tcost icost 0.0343017578125 0.3824949264526367\n",
            "tcost icost 0.03466796875 0.3721696734428406\n",
            "tcost icost 0.03466796875 0.3732711970806122\n",
            "search 0.407958984375\n",
            "tcost icost 0.0364990234375 0.3848980963230133\n",
            "tcost icost 0.0362548828125 0.36996421217918396\n",
            "tcost icost 0.0362548828125 0.37184104323387146\n",
            "search 0.408203125\n",
            "tcost icost 0.0401611328125 0.3878079354763031\n",
            "tcost icost 0.0411376953125 0.3809424042701721\n",
            "tcost icost 0.0411376953125 0.3775489628314972\n",
            "search 0.41845703125\n",
            "tcost icost 0.038970947265625 0.3921065330505371\n",
            "tcost icost 0.036529541015625 0.3928581476211548\n",
            "tcost icost 0.036529541015625 0.39203575253486633\n",
            "search 0.4287109375\n",
            "tcost icost 0.0394287109375 0.39181265234947205\n",
            "tcost icost 0.038818359375 0.38524535298347473\n",
            "tcost icost 0.038818359375 0.3852449655532837\n",
            "search 0.424072265625\n",
            "tcost icost 0.044769287109375 0.39460253715515137\n",
            "tcost icost 0.041168212890625 0.37680134177207947\n",
            "tcost icost 0.041168212890625 0.3785785734653473\n",
            "search 0.419921875\n",
            "tcost icost 0.04345703125 0.39804327487945557\n",
            "tcost icost 0.03460693359375 0.3969094157218933\n",
            "tcost icost 0.03460693359375 0.3981599509716034\n",
            "search 0.432861328125\n",
            "tcost icost 0.043670654296875 0.39809349179267883\n",
            "tcost icost 0.041961669921875 0.38694456219673157\n",
            "tcost icost 0.041961669921875 0.3857899606227875\n",
            "search 0.427734375\n",
            "tcost icost 0.04443359375 0.39851221442222595\n",
            "tcost icost 0.042083740234375 0.39982476830482483\n",
            "tcost icost 0.042083740234375 0.39789849519729614\n",
            "search 0.43994140625\n",
            "tcost icost 0.0489501953125 0.39797741174697876\n",
            "tcost icost 0.0418701171875 0.3987865149974823\n",
            "tcost icost 0.0418701171875 0.3987865149974823\n",
            "search 0.4404296875\n",
            "tcost icost 0.048919677734375 0.3978937566280365\n",
            "tcost icost 0.0450439453125 0.3928166329860687\n",
            "tcost icost 0.0450439453125 0.3940984904766083\n",
            "search 0.43896484375\n",
            "tcost icost 0.044708251953125 0.398663729429245\n",
            "tcost icost 0.04364013671875 0.3929476737976074\n",
            "tcost icost 0.04364013671875 0.3929476737976074\n",
            "search 0.436767578125\n",
            "tcost icost 0.04449462890625 0.3955296576023102\n",
            "tcost icost 0.04449462890625 0.39562487602233887\n",
            "tcost icost 0.04449462890625 0.3955296576023102\n",
            "search 0.43994140625\n",
            "tcost icost 0.05120849609375 0.4011988341808319\n",
            "tcost icost 0.042572021484375 0.40216556191444397\n",
            "tcost icost 0.042572021484375 0.4003821015357971\n",
            "search 0.44287109375\n",
            "tcost icost 0.052734375 0.39787566661834717\n",
            "tcost icost 0.04437255859375 0.40028858184814453\n",
            "tcost icost 0.04437255859375 0.40106001496315\n",
            "search 0.445556640625\n",
            "tcost icost 0.04302978515625 0.3962157964706421\n",
            "tcost icost 0.0421142578125 0.3901226222515106\n",
            "tcost icost 0.0421142578125 0.3914138078689575\n",
            "search 0.43359375\n",
            "tcost icost 0.05169677734375 0.4017503261566162\n",
            "tcost icost 0.046875 0.39138123393058777\n",
            "tcost icost 0.046875 0.3924197554588318\n",
            "search 0.439208984375\n",
            "tcost icost 0.045318603515625 0.3979291021823883\n",
            "tcost icost 0.044403076171875 0.3922511339187622\n",
            "tcost icost 0.044403076171875 0.3922511339187622\n",
            "search 0.436767578125\n",
            "tcost icost 0.040008544921875 0.40389227867126465\n",
            "tcost icost 0.038787841796875 0.40108662843704224\n",
            "tcost icost 0.038787841796875 0.4027480185031891\n",
            "search 0.441650390625\n",
            "tcost icost 0.049713134765625 0.39878058433532715\n",
            "tcost icost 0.046600341796875 0.38722652196884155\n",
            "tcost icost 0.046600341796875 0.3867146670818329\n",
            "search 0.433349609375\n",
            "tcost icost 0.046630859375 0.40346843004226685\n",
            "tcost icost 0.042236328125 0.3872218132019043\n",
            "tcost icost 0.042236328125 0.38955920934677124\n",
            "search 0.431884765625\n",
            "tcost icost 0.045074462890625 0.4029187262058258\n",
            "tcost icost 0.04345703125 0.3935859799385071\n",
            "tcost icost 0.04345703125 0.39205655455589294\n",
            "search 0.435546875\n",
            "tcost icost 0.03887939453125 0.4090873897075653\n",
            "tcost icost 0.036224365234375 0.4081372022628784\n",
            "tcost icost 0.036224365234375 0.4100169837474823\n",
            "search 0.446044921875\n",
            "tcost icost 0.0384521484375 0.408751904964447\n",
            "tcost icost 0.036712646484375 0.4049588739871979\n",
            "tcost icost 0.036712646484375 0.4044727683067322\n",
            "search 0.441162109375\n",
            "tcost icost 0.03533935546875 0.4090690314769745\n",
            "tcost icost 0.03424072265625 0.40283554792404175\n",
            "tcost icost 0.03424072265625 0.4045282304286957\n",
            "search 0.438720703125\n",
            "tcost icost 0.0374755859375 0.40610507130622864\n",
            "tcost icost 0.03765869140625 0.39230796694755554\n",
            "tcost icost 0.03765869140625 0.39287158846855164\n",
            "search 0.430419921875\n",
            "tcost icost 0.037445068359375 0.4109548032283783\n",
            "tcost icost 0.033599853515625 0.41248035430908203\n",
            "tcost icost 0.033599853515625 0.41043785214424133\n",
            "search 0.444091796875\n",
            "tcost icost 0.0396728515625 0.4130636751651764\n",
            "tcost icost 0.03704833984375 0.41225892305374146\n",
            "tcost icost 0.03704833984375 0.4124920666217804\n",
            "search 0.44970703125\n",
            "tcost icost 0.03875732421875 0.4101468622684479\n",
            "tcost icost 0.035430908203125 0.41099855303764343\n",
            "tcost icost 0.035430908203125 0.4115024209022522\n",
            "search 0.447021484375\n",
            "tcost icost 0.04046630859375 0.4098794758319855\n",
            "tcost icost 0.035125732421875 0.38591110706329346\n",
            "tcost icost 0.035125732421875 0.3875996470451355\n",
            "search 0.4228515625\n",
            "tcost icost 0.0341796875 0.40907812118530273\n",
            "tcost icost 0.035369873046875 0.40690675377845764\n",
            "tcost icost 0.035369873046875 0.40620431303977966\n",
            "search 0.441650390625\n",
            "tcost icost 0.050384521484375 0.41237592697143555\n",
            "tcost icost 0.044281005859375 0.40094590187072754\n",
            "tcost icost 0.044281005859375 0.4022119641304016\n",
            "search 0.4462890625\n",
            "tcost icost 0.043182373046875 0.4041362702846527\n",
            "tcost icost 0.045318603515625 0.3991428017616272\n",
            "tcost icost 0.045318603515625 0.3958204686641693\n",
            "search 0.441162109375\n",
            "tcost icost 0.04815673828125 0.41229575872421265\n",
            "tcost icost 0.041748046875 0.41219115257263184\n",
            "tcost icost 0.041748046875 0.41313788294792175\n",
            "search 0.454833984375\n",
            "tcost icost 0.05609130859375 0.41277197003364563\n",
            "tcost icost 0.0452880859375 0.4111356735229492\n",
            "tcost icost 0.0452880859375 0.40949398279190063\n",
            "search 0.45458984375\n",
            "tcost icost 0.056732177734375 0.41129857301712036\n",
            "tcost icost 0.049072265625 0.4008006751537323\n",
            "tcost icost 0.049072265625 0.40134838223457336\n",
            "search 0.450439453125\n",
            "tcost icost 0.0460205078125 0.41058897972106934\n",
            "tcost icost 0.0433349609375 0.39170026779174805\n",
            "tcost icost 0.0433349609375 0.3910786509513855\n",
            "search 0.4345703125\n",
            "tcost icost 0.050537109375 0.4078880846500397\n",
            "tcost icost 0.0472412109375 0.39643362164497375\n",
            "tcost icost 0.0472412109375 0.39770182967185974\n",
            "search 0.44482421875\n",
            "tcost icost 0.042144775390625 0.40508779883384705\n",
            "tcost icost 0.040802001953125 0.39693397283554077\n",
            "tcost icost 0.040802001953125 0.39803993701934814\n",
            "search 0.438720703125\n",
            "tcost icost 0.03826904296875 0.414764404296875\n",
            "tcost icost 0.0374755859375 0.41318830847740173\n",
            "tcost icost 0.0374755859375 0.41301754117012024\n",
            "search 0.45068359375\n",
            "tcost icost 0.04278564453125 0.403780460357666\n",
            "tcost icost 0.040130615234375 0.3839898407459259\n",
            "tcost icost 0.040130615234375 0.38397976756095886\n",
            "search 0.424072265625\n",
            "tcost icost 0.04241943359375 0.4124591648578644\n",
            "tcost icost 0.041717529296875 0.4011801481246948\n",
            "tcost icost 0.041717529296875 0.40230533480644226\n",
            "search 0.444091796875\n",
            "tcost icost 0.0430908203125 0.3975974917411804\n",
            "tcost icost 0.039642333984375 0.3790128827095032\n",
            "tcost icost 0.039642333984375 0.3818361163139343\n",
            "search 0.42138671875\n",
            "tcost icost 0.042205810546875 0.39727306365966797\n",
            "tcost icost 0.038543701171875 0.3822157084941864\n",
            "tcost icost 0.038543701171875 0.3822157084941864\n",
            "search 0.4208984375\n",
            "tcost icost 0.0411376953125 0.402669221162796\n",
            "tcost icost 0.037384033203125 0.3841984272003174\n",
            "tcost icost 0.037384033203125 0.38403835892677307\n",
            "search 0.42138671875\n",
            "tcost icost 0.041290283203125 0.420184463262558\n",
            "tcost icost 0.0408935546875 0.40515443682670593\n",
            "tcost icost 0.0408935546875 0.4055885672569275\n",
            "search 0.4462890625\n",
            "tcost icost 0.036773681640625 0.4184615910053253\n",
            "tcost icost 0.036956787109375 0.40638425946235657\n",
            "tcost icost 0.036956787109375 0.40747395157814026\n",
            "search 0.4443359375\n",
            "tcost icost 0.036773681640625 0.42026379704475403\n",
            "tcost icost 0.034210205078125 0.4015826880931854\n",
            "tcost icost 0.034210205078125 0.3990098536014557\n",
            "search 0.43310546875\n",
            "tcost icost 0.0333251953125 0.42022404074668884\n",
            "tcost icost 0.033294677734375 0.4135395884513855\n",
            "tcost icost 0.033294677734375 0.4140530228614807\n",
            "search 0.447265625\n",
            "tcost icost 0.032623291015625 0.41663357615470886\n",
            "tcost icost 0.032196044921875 0.41150084137916565\n",
            "tcost icost 0.032196044921875 0.4103240966796875\n",
            "search 0.442626953125\n",
            "tcost icost 0.0298309326171875 0.4087415039539337\n",
            "tcost icost 0.0272674560546875 0.4094647467136383\n",
            "tcost icost 0.0272674560546875 0.4108055531978607\n",
            "search 0.438232421875\n",
            "tcost icost 0.0341796875 0.40537309646606445\n",
            "tcost icost 0.034576416015625 0.4019168019294739\n",
            "tcost icost 0.034576416015625 0.4012501537799835\n",
            "search 0.43603515625\n",
            "tcost icost 0.0408935546875 0.41954317688941956\n",
            "tcost icost 0.041107177734375 0.40540823340415955\n",
            "tcost icost 0.041107177734375 0.4052404463291168\n",
            "search 0.4462890625\n",
            "tcost icost 0.039306640625 0.407594233751297\n",
            "tcost icost 0.035736083984375 0.39420828223228455\n",
            "tcost icost 0.035736083984375 0.39569994807243347\n",
            "search 0.431396484375\n",
            "tcost icost 0.043212890625 0.413997083902359\n",
            "tcost icost 0.040863037109375 0.39711275696754456\n",
            "tcost icost 0.040863037109375 0.39618822932243347\n",
            "search 0.43701171875\n",
            "tcost icost 0.040802001953125 0.4195858836174011\n",
            "tcost icost 0.04022216796875 0.41203203797340393\n",
            "tcost icost 0.04022216796875 0.4132327735424042\n",
            "search 0.45361328125\n",
            "tcost icost 0.04388427734375 0.416523277759552\n",
            "tcost icost 0.042022705078125 0.40224379301071167\n",
            "tcost icost 0.042022705078125 0.4036348760128021\n",
            "search 0.445556640625\n",
            "tcost icost 0.042266845703125 0.42572852969169617\n",
            "tcost icost 0.040008544921875 0.426066130399704\n",
            "tcost icost 0.040008544921875 0.42624226212501526\n",
            "search 0.46630859375\n",
            "tcost icost 0.04656982421875 0.4199109673500061\n",
            "tcost icost 0.04656982421875 0.4185529053211212\n",
            "tcost icost 0.04656982421875 0.4174641966819763\n",
            "search 0.464111328125\n",
            "tcost icost 0.04376220703125 0.4203498959541321\n",
            "tcost icost 0.04315185546875 0.4115101993083954\n",
            "tcost icost 0.04315185546875 0.411714643239975\n",
            "search 0.454833984375\n",
            "tcost icost 0.034393310546875 0.42618492245674133\n",
            "tcost icost 0.031494140625 0.42212456464767456\n",
            "tcost icost 0.031494140625 0.4237384498119354\n",
            "search 0.455322265625\n",
            "tcost icost 0.04095458984375 0.41422006487846375\n",
            "tcost icost 0.0379638671875 0.4007934033870697\n",
            "tcost icost 0.0379638671875 0.39978352189064026\n",
            "search 0.43798828125\n",
            "tcost icost 0.044921875 0.42787569761276245\n",
            "tcost icost 0.037994384765625 0.4254041612148285\n",
            "tcost icost 0.037994384765625 0.42546674609184265\n",
            "search 0.463623046875\n",
            "tcost icost 0.03826904296875 0.4279143214225769\n",
            "tcost icost 0.037200927734375 0.42043226957321167\n",
            "tcost icost 0.037200927734375 0.42192038893699646\n",
            "search 0.458984375\n",
            "tcost icost 0.035980224609375 0.4274657964706421\n",
            "tcost icost 0.03271484375 0.4247276186943054\n",
            "tcost icost 0.03271484375 0.4264044761657715\n",
            "search 0.459228515625\n",
            "tcost icost 0.04779052734375 0.42175814509391785\n",
            "tcost icost 0.039947509765625 0.4274871051311493\n",
            "tcost icost 0.039947509765625 0.4265446662902832\n",
            "search 0.466552734375\n",
            "tcost icost 0.045501708984375 0.42121216654777527\n",
            "tcost icost 0.045501708984375 0.42417600750923157\n",
            "tcost icost 0.045501708984375 0.42401793599128723\n",
            "search 0.469482421875\n",
            "tcost icost 0.037689208984375 0.42626267671585083\n",
            "tcost icost 0.039154052734375 0.4216446876525879\n",
            "tcost icost 0.039154052734375 0.4214501678943634\n",
            "search 0.46044921875\n",
            "tcost icost 0.041229248046875 0.42408958077430725\n",
            "tcost icost 0.03094482421875 0.4282057285308838\n",
            "tcost icost 0.03094482421875 0.4290258288383484\n",
            "search 0.4599609375\n",
            "tcost icost 0.045684814453125 0.42818889021873474\n",
            "tcost icost 0.0390625 0.43297746777534485\n",
            "tcost icost 0.0390625 0.43297746777534485\n",
            "search 0.471923828125\n",
            "tcost icost 0.033721923828125 0.4304886758327484\n",
            "tcost icost 0.0300140380859375 0.43015459179878235\n",
            "tcost icost 0.0300140380859375 0.4307038187980652\n",
            "search 0.460693359375\n",
            "tcost icost 0.04156494140625 0.42742589116096497\n",
            "tcost icost 0.04156494140625 0.42770934104919434\n",
            "tcost icost 0.04156494140625 0.4274882376194\n",
            "search 0.468994140625\n",
            "tcost icost 0.041259765625 0.42909398674964905\n",
            "tcost icost 0.041259765625 0.42800283432006836\n",
            "tcost icost 0.041259765625 0.42710167169570923\n",
            "search 0.46826171875\n",
            "tcost icost 0.042388916015625 0.4147058427333832\n",
            "tcost icost 0.0443115234375 0.4093678891658783\n",
            "tcost icost 0.0443115234375 0.4108268618583679\n",
            "search 0.455078125\n",
            "tcost icost 0.04656982421875 0.42122769355773926\n",
            "tcost icost 0.047271728515625 0.411771297454834\n",
            "tcost icost 0.047271728515625 0.41420862078666687\n",
            "search 0.461669921875\n",
            "tcost icost 0.04486083984375 0.4163099229335785\n",
            "tcost icost 0.047149658203125 0.41072267293930054\n",
            "tcost icost 0.047149658203125 0.41104280948638916\n",
            "search 0.458251953125\n",
            "tcost icost 0.049041748046875 0.4178493618965149\n",
            "tcost icost 0.0462646484375 0.41457390785217285\n",
            "tcost icost 0.0462646484375 0.4165019690990448\n",
            "search 0.462890625\n",
            "tcost icost 0.041778564453125 0.42477309703826904\n",
            "tcost icost 0.038604736328125 0.4219215512275696\n",
            "tcost icost 0.038604736328125 0.4233655035495758\n",
            "search 0.4619140625\n",
            "tcost icost 0.041961669921875 0.4202532470226288\n",
            "tcost icost 0.038299560546875 0.4187018573284149\n",
            "tcost icost 0.038299560546875 0.41929441690444946\n",
            "search 0.45751953125\n",
            "tcost icost 0.04632568359375 0.41708001494407654\n",
            "tcost icost 0.04632568359375 0.4166127145290375\n",
            "tcost icost 0.04632568359375 0.41883188486099243\n",
            "search 0.46533203125\n",
            "tcost icost 0.041015625 0.42024412751197815\n",
            "tcost icost 0.0426025390625 0.41901251673698425\n",
            "tcost icost 0.0426025390625 0.4150536358356476\n",
            "search 0.45751953125\n",
            "tcost icost 0.040924072265625 0.4133807122707367\n",
            "tcost icost 0.035247802734375 0.42345497012138367\n",
            "tcost icost 0.035247802734375 0.4216199219226837\n",
            "search 0.456787109375\n",
            "tcost icost 0.043243408203125 0.41307592391967773\n",
            "tcost icost 0.036102294921875 0.422024130821228\n",
            "tcost icost 0.036102294921875 0.4219457507133484\n",
            "search 0.4580078125\n",
            "tcost icost 0.038421630859375 0.4161045551300049\n",
            "tcost icost 0.041961669921875 0.41096141934394836\n",
            "tcost icost 0.041961669921875 0.4106769859790802\n",
            "search 0.45263671875\n",
            "tcost icost 0.042022705078125 0.41344520449638367\n",
            "tcost icost 0.0399169921875 0.4119916260242462\n",
            "tcost icost 0.0399169921875 0.4151856303215027\n",
            "search 0.455078125\n",
            "tcost icost 0.03948974609375 0.4138226807117462\n",
            "tcost icost 0.036529541015625 0.41192421317100525\n",
            "tcost icost 0.036529541015625 0.4116361737251282\n",
            "search 0.4482421875\n",
            "tcost icost 0.04376220703125 0.4109203517436981\n",
            "tcost icost 0.03948974609375 0.4045552611351013\n",
            "tcost icost 0.03948974609375 0.4074955880641937\n",
            "search 0.447021484375\n",
            "tcost icost 0.04144287109375 0.40334567427635193\n",
            "tcost icost 0.036224365234375 0.4171258211135864\n",
            "tcost icost 0.036224365234375 0.41207805275917053\n",
            "search 0.4482421875\n",
            "tcost icost 0.040283203125 0.40820828080177307\n",
            "tcost icost 0.03924560546875 0.41147467494010925\n",
            "tcost icost 0.03924560546875 0.4109361469745636\n",
            "search 0.4501953125\n",
            "tcost icost 0.041259765625 0.40287595987319946\n",
            "tcost icost 0.04022216796875 0.4068915545940399\n",
            "tcost icost 0.04022216796875 0.40513190627098083\n",
            "search 0.4453125\n",
            "tcost icost 0.0467529296875 0.40610185265541077\n",
            "tcost icost 0.038726806640625 0.4082188606262207\n",
            "tcost icost 0.038726806640625 0.41062530875205994\n",
            "search 0.449462890625\n",
            "tcost icost 0.050079345703125 0.39788395166397095\n",
            "tcost icost 0.038116455078125 0.4019831717014313\n",
            "tcost icost 0.038116455078125 0.4018460810184479\n",
            "search 0.43994140625\n",
            "tcost icost 0.037017822265625 0.4005524516105652\n",
            "tcost icost 0.04315185546875 0.3966032862663269\n",
            "tcost icost 0.04315185546875 0.3952065706253052\n",
            "search 0.4384765625\n",
            "tcost icost 0.040740966796875 0.40121379494667053\n",
            "tcost icost 0.039398193359375 0.40228959918022156\n",
            "tcost icost 0.039398193359375 0.3999791145324707\n",
            "search 0.439208984375\n",
            "tcost icost 0.050079345703125 0.392850399017334\n",
            "tcost icost 0.038116455078125 0.39427676796913147\n",
            "tcost icost 0.038116455078125 0.39519038796424866\n",
            "search 0.433349609375\n",
            "tcost icost 0.05072021484375 0.3918522000312805\n",
            "tcost icost 0.04022216796875 0.3911646008491516\n",
            "tcost icost 0.04022216796875 0.38789254426956177\n",
            "search 0.42822265625\n",
            "tcost icost 0.037445068359375 0.39014574885368347\n",
            "tcost icost 0.041900634765625 0.38113951683044434\n",
            "tcost icost 0.041900634765625 0.38472771644592285\n",
            "search 0.4267578125\n",
            "tcost icost 0.036468505859375 0.39345431327819824\n",
            "tcost icost 0.03912353515625 0.3795797824859619\n",
            "tcost icost 0.03912353515625 0.3824249505996704\n",
            "search 0.42138671875\n",
            "tcost icost 0.03363037109375 0.3921476900577545\n",
            "tcost icost 0.03118896484375 0.3925389051437378\n",
            "tcost icost 0.03118896484375 0.3914807140827179\n",
            "search 0.4228515625\n",
            "tcost icost 0.040069580078125 0.37648987770080566\n",
            "tcost icost 0.03497314453125 0.38853979110717773\n",
            "tcost icost 0.03497314453125 0.3899554908275604\n",
            "search 0.4248046875\n",
            "tcost icost 0.0347900390625 0.38573163747787476\n",
            "tcost icost 0.03765869140625 0.37324875593185425\n",
            "tcost icost 0.03765869140625 0.37046948075294495\n",
            "search 0.407958984375\n",
            "tcost icost 0.0299530029296875 0.39528048038482666\n",
            "tcost icost 0.037689208984375 0.37860116362571716\n",
            "tcost icost 0.037689208984375 0.37824997305870056\n",
            "search 0.415771484375\n",
            "tcost icost 0.03900146484375 0.3709520995616913\n",
            "tcost icost 0.038299560546875 0.37340980768203735\n",
            "tcost icost 0.038299560546875 0.37340980768203735\n",
            "search 0.41162109375\n",
            "tcost icost 0.043212890625 0.3632482588291168\n",
            "tcost icost 0.035186767578125 0.37484508752822876\n",
            "tcost icost 0.035186767578125 0.37843069434165955\n",
            "search 0.41357421875\n",
            "tcost icost 0.0350341796875 0.3786373436450958\n",
            "tcost icost 0.038055419921875 0.36432722210884094\n",
            "tcost icost 0.038055419921875 0.3617120087146759\n",
            "search 0.39990234375\n",
            "tcost icost 0.03167724609375 0.38408756256103516\n",
            "tcost icost 0.03167724609375 0.3838883936405182\n",
            "tcost icost 0.03167724609375 0.3854333162307739\n",
            "search 0.417236328125\n",
            "tcost icost 0.035919189453125 0.3717322051525116\n",
            "tcost icost 0.0391845703125 0.36177462339401245\n",
            "tcost icost 0.0391845703125 0.3583812117576599\n",
            "search 0.3974609375\n",
            "tcost icost 0.034210205078125 0.3793618679046631\n",
            "tcost icost 0.037628173828125 0.3641873896121979\n",
            "tcost icost 0.037628173828125 0.3688619136810303\n",
            "search 0.406494140625\n",
            "tcost icost 0.038726806640625 0.3709357678890228\n",
            "tcost icost 0.040374755859375 0.3662145733833313\n",
            "tcost icost 0.040374755859375 0.3624516427516937\n",
            "search 0.40283203125\n",
            "tcost icost 0.04290771484375 0.36353880167007446\n",
            "tcost icost 0.04107666015625 0.3545268177986145\n",
            "tcost icost 0.04107666015625 0.3555229604244232\n",
            "search 0.396484375\n",
            "tcost icost 0.045318603515625 0.35312584042549133\n",
            "tcost icost 0.038116455078125 0.36231985688209534\n",
            "tcost icost 0.038116455078125 0.3660339117050171\n",
            "search 0.404052734375\n",
            "tcost icost 0.038909912109375 0.371502161026001\n",
            "tcost icost 0.041595458984375 0.3586454391479492\n",
            "tcost icost 0.041595458984375 0.357254296541214\n",
            "search 0.398681640625\n",
            "tcost icost 0.041748046875 0.3670242726802826\n",
            "tcost icost 0.0440673828125 0.3544498682022095\n",
            "tcost icost 0.0440673828125 0.35550621151924133\n",
            "search 0.3994140625\n",
            "tcost icost 0.04400634765625 0.3510293662548065\n",
            "tcost icost 0.03814697265625 0.36046338081359863\n",
            "tcost icost 0.03814697265625 0.35566946864128113\n",
            "search 0.393798828125\n",
            "tcost icost 0.048614501953125 0.35234567523002625\n",
            "tcost icost 0.036895751953125 0.37973782420158386\n",
            "tcost icost 0.036895751953125 0.3730905055999756\n",
            "search 0.409912109375\n",
            "tcost icost 0.045501708984375 0.3592071235179901\n",
            "tcost icost 0.0421142578125 0.35468044877052307\n",
            "tcost icost 0.0421142578125 0.3579002618789673\n",
            "search 0.39990234375\n",
            "tcost icost 0.040008544921875 0.37261098623275757\n",
            "tcost icost 0.04193115234375 0.3570248782634735\n",
            "tcost icost 0.04193115234375 0.3570132851600647\n",
            "search 0.39892578125\n",
            "tcost icost 0.044281005859375 0.3724926710128784\n",
            "tcost icost 0.04425048828125 0.36055970191955566\n",
            "tcost icost 0.04425048828125 0.36001911759376526\n",
            "search 0.404296875\n",
            "tcost icost 0.04132080078125 0.3775162398815155\n",
            "tcost icost 0.0426025390625 0.36087486147880554\n",
            "tcost icost 0.0426025390625 0.35858142375946045\n",
            "search 0.4013671875\n",
            "tcost icost 0.0382080078125 0.3833329975605011\n",
            "tcost icost 0.03485107421875 0.38685235381126404\n",
            "tcost icost 0.03485107421875 0.38380002975463867\n",
            "search 0.418701171875\n",
            "tcost icost 0.03826904296875 0.36771100759506226\n",
            "tcost icost 0.043121337890625 0.3638753294944763\n",
            "tcost icost 0.043121337890625 0.35871008038520813\n",
            "search 0.40185546875\n",
            "tcost icost 0.0380859375 0.3791455328464508\n",
            "tcost icost 0.041748046875 0.36536267399787903\n",
            "tcost icost 0.041748046875 0.36601534485816956\n",
            "search 0.40771484375\n",
            "tcost icost 0.038482666015625 0.38330376148223877\n",
            "tcost icost 0.0433349609375 0.37393805384635925\n",
            "tcost icost 0.0433349609375 0.3740200400352478\n",
            "search 0.41748046875\n",
            "tcost icost 0.0391845703125 0.37838470935821533\n",
            "tcost icost 0.0413818359375 0.3660472631454468\n",
            "tcost icost 0.0413818359375 0.36276036500930786\n",
            "search 0.404296875\n",
            "tcost icost 0.051422119140625 0.3704972565174103\n",
            "tcost icost 0.048248291015625 0.36956802010536194\n",
            "tcost icost 0.048248291015625 0.36638009548187256\n",
            "search 0.414794921875\n",
            "tcost icost 0.040679931640625 0.3770851492881775\n",
            "tcost icost 0.0421142578125 0.3658234477043152\n",
            "tcost icost 0.0421142578125 0.3612893223762512\n",
            "search 0.4033203125\n",
            "tcost icost 0.04388427734375 0.3751010596752167\n",
            "tcost icost 0.04351806640625 0.3640816807746887\n",
            "tcost icost 0.04351806640625 0.3650280237197876\n",
            "search 0.408447265625\n",
            "tcost icost 0.051239013671875 0.3730027675628662\n",
            "tcost icost 0.051239013671875 0.37279632687568665\n",
            "tcost icost 0.051239013671875 0.37408629059791565\n",
            "search 0.42529296875\n",
            "tcost icost 0.04278564453125 0.37458279728889465\n",
            "tcost icost 0.042755126953125 0.36575549840927124\n",
            "tcost icost 0.042755126953125 0.36571651697158813\n",
            "search 0.408447265625\n",
            "tcost icost 0.0390625 0.38587141036987305\n",
            "tcost icost 0.044677734375 0.37041613459587097\n",
            "tcost icost 0.044677734375 0.368240088224411\n",
            "search 0.412841796875\n",
            "tcost icost 0.042327880859375 0.37226659059524536\n",
            "tcost icost 0.042572021484375 0.36732715368270874\n",
            "tcost icost 0.042572021484375 0.3664250671863556\n",
            "search 0.408935546875\n",
            "tcost icost 0.0355224609375 0.3654317259788513\n",
            "tcost icost 0.0386962890625 0.35865575075149536\n",
            "tcost icost 0.0386962890625 0.35707974433898926\n",
            "search 0.39599609375\n",
            "tcost icost 0.040008544921875 0.38054245710372925\n",
            "tcost icost 0.043731689453125 0.3643572926521301\n",
            "tcost icost 0.043731689453125 0.3679516613483429\n",
            "search 0.41162109375\n",
            "tcost icost 0.04254150390625 0.3723156154155731\n",
            "tcost icost 0.0418701171875 0.3629743158817291\n",
            "tcost icost 0.0418701171875 0.3629245460033417\n",
            "search 0.40478515625\n",
            "tcost icost 0.043243408203125 0.3840833604335785\n",
            "tcost icost 0.051727294921875 0.3701861500740051\n",
            "tcost icost 0.051727294921875 0.37130609154701233\n",
            "search 0.423095703125\n",
            "tcost icost 0.03216552734375 0.3822133243083954\n",
            "tcost icost 0.03668212890625 0.3717923164367676\n",
            "tcost icost 0.03668212890625 0.36885470151901245\n",
            "search 0.405517578125\n",
            "tcost icost 0.037139892578125 0.3593238592147827\n",
            "tcost icost 0.042083740234375 0.3559016287326813\n",
            "tcost icost 0.042083740234375 0.35586217045783997\n",
            "search 0.39794921875\n",
            "tcost icost 0.042724609375 0.37813514471054077\n",
            "tcost icost 0.0426025390625 0.3599645495414734\n",
            "tcost icost 0.0426025390625 0.3600900173187256\n",
            "search 0.40283203125\n",
            "tcost icost 0.0399169921875 0.37471985816955566\n",
            "tcost icost 0.041900634765625 0.36503005027770996\n",
            "tcost icost 0.041900634765625 0.36005324125289917\n",
            "search 0.402099609375\n",
            "tcost icost 0.040618896484375 0.3640572428703308\n",
            "tcost icost 0.041656494140625 0.3598763048648834\n",
            "tcost icost 0.041656494140625 0.3598763048648834\n",
            "search 0.401611328125\n",
            "tcost icost 0.042816162109375 0.37235137820243835\n",
            "tcost icost 0.043853759765625 0.362354576587677\n",
            "tcost icost 0.043853759765625 0.36675357818603516\n",
            "search 0.41064453125\n",
            "tcost icost 0.03826904296875 0.36679068207740784\n",
            "tcost icost 0.041168212890625 0.3654426038265228\n",
            "tcost icost 0.041168212890625 0.3649806082248688\n",
            "search 0.40625\n",
            "tcost icost 0.041900634765625 0.3666943609714508\n",
            "tcost icost 0.043487548828125 0.36272522807121277\n",
            "tcost icost 0.043487548828125 0.3602338433265686\n",
            "search 0.40380859375\n",
            "tcost icost 0.04205322265625 0.3670954406261444\n",
            "tcost icost 0.042694091796875 0.3624684512615204\n",
            "tcost icost 0.042694091796875 0.3604353964328766\n",
            "search 0.403076171875\n",
            "tcost icost 0.042266845703125 0.3801419734954834\n",
            "tcost icost 0.045074462890625 0.3727934956550598\n",
            "tcost icost 0.045074462890625 0.37091079354286194\n",
            "search 0.416015625\n",
            "tcost icost 0.04351806640625 0.3820027709007263\n",
            "tcost icost 0.041229248046875 0.37515440583229065\n",
            "tcost icost 0.041229248046875 0.3754724860191345\n",
            "search 0.416748046875\n",
            "tcost icost 0.037322998046875 0.3742881417274475\n",
            "tcost icost 0.041290283203125 0.3660917282104492\n",
            "tcost icost 0.041290283203125 0.3670545518398285\n",
            "search 0.408203125\n",
            "tcost icost 0.036468505859375 0.3726925253868103\n",
            "tcost icost 0.04010009765625 0.3591725528240204\n",
            "tcost icost 0.04010009765625 0.36765336990356445\n",
            "search 0.40771484375\n",
            "tcost icost 0.045440673828125 0.365247905254364\n",
            "tcost icost 0.042510986328125 0.3642460107803345\n",
            "tcost icost 0.042510986328125 0.3604956269264221\n",
            "search 0.403076171875\n",
            "tcost icost 0.043975830078125 0.380460262298584\n",
            "tcost icost 0.044219970703125 0.3676477372646332\n",
            "tcost icost 0.044219970703125 0.3702346980571747\n",
            "search 0.414306640625\n",
            "tcost icost 0.040191650390625 0.3822963237762451\n",
            "tcost icost 0.042694091796875 0.3695550262928009\n",
            "tcost icost 0.042694091796875 0.374385803937912\n",
            "search 0.4169921875\n",
            "tcost icost 0.0357666015625 0.36313164234161377\n",
            "tcost icost 0.040069580078125 0.3573298156261444\n",
            "tcost icost 0.040069580078125 0.3610169291496277\n",
            "search 0.401123046875\n",
            "tcost icost 0.038604736328125 0.38032546639442444\n",
            "tcost icost 0.041839599609375 0.36644428968429565\n",
            "tcost icost 0.041839599609375 0.37297573685646057\n",
            "search 0.414794921875\n",
            "tcost icost 0.03204345703125 0.38694262504577637\n",
            "tcost icost 0.02935791015625 0.3879823684692383\n",
            "tcost icost 0.02935791015625 0.38539424538612366\n",
            "search 0.414794921875\n",
            "tcost icost 0.029266357421875 0.390675812959671\n",
            "tcost icost 0.0261077880859375 0.38980889320373535\n",
            "tcost icost 0.0261077880859375 0.39064928889274597\n",
            "search 0.416748046875\n",
            "tcost icost 0.0304107666015625 0.3858388364315033\n",
            "tcost icost 0.0278167724609375 0.3837323486804962\n",
            "tcost icost 0.0278167724609375 0.3827684223651886\n",
            "search 0.41064453125\n",
            "ded\n",
            "time\n",
            "27 #### train ####\n",
            "repr, std, cov, conv, closs 0.04233389347791672 0.322265625 0.3475404977798462 0.05670011788606644 0.009024860337376595\n",
            "53.70432722164768 6.899986091363442 1.0\n",
            "repr, std, cov, conv, closs 0.03897339850664139 0.32373046875 0.3374171853065491 0.056633248925209045 0.021178768947720528\n",
            "53.59707946563695 6.824539676930682 1.0\n",
            "repr, std, cov, conv, closs 0.04719869792461395 0.3271484375 0.3036932945251465 0.06378911435604095 0.0010955188190564513\n",
            "53.490045883823434 6.7634248014441125 1.0\n",
            "repr, std, cov, conv, closs 0.04529614374041557 0.328857421875 0.30099985003471375 0.06375471502542496 0.024014225229620934\n",
            "54.0273598247783 6.817721954975707 1.0\n",
            "repr, std, cov, conv, closs 0.04386688023805618 0.32861328125 0.2914009690284729 0.07611584663391113 0.002561361063271761\n",
            "54.13546857178767 6.948431135452057 1.0\n",
            "repr, std, cov, conv, closs 0.04212183505296707 0.33349609375 0.31254875659942627 0.06068272888660431 0.029479146003723145\n",
            "54.57007114886069 7.039304710069875 1.0\n",
            "repr, std, cov, conv, closs 0.046524420380592346 0.331787109375 0.2889711856842041 0.06116523593664169 0.0027800777461379766\n",
            "55.39437697759879 7.239089304718693 1.0\n",
            "repr, std, cov, conv, closs 0.041444696485996246 0.3369140625 0.26762655377388 0.066674143075943 0.02349202334880829\n",
            "55.56072634705688 7.355787491407577 1.0\n",
            "repr, std, cov, conv, closs 0.033313412219285965 0.338134765625 0.24746164679527283 0.07564299553632736 0.0067652324214577675\n",
            "56.23113432206681 7.579690950843743 1.0\n",
            "repr, std, cov, conv, closs 0.04852690547704697 0.33349609375 0.2563703656196594 0.08123201131820679 0.015644090250134468\n",
            "56.343652821845254 7.701879827426469 1.0\n",
            "repr, std, cov, conv, closs 0.05523834377527237 0.3291015625 0.2893785238265991 0.06536852568387985 0.015048978850245476\n",
            "56.62593508620097 7.717291288961148 1.0\n",
            "repr, std, cov, conv, closs 0.06075087934732437 0.3291015625 0.3132830262184143 0.06578322499990463 0.02828093431890011\n",
            "56.682561021287164 7.648181675925595 1.0\n",
            "repr, std, cov, conv, closs 0.055681999772787094 0.32568359375 0.30568188428878784 0.060193877667188644 0.0007408890523947775\n",
            "56.56936572048049 7.466900018411363 1.0\n",
            "repr, std, cov, conv, closs 0.04920557513833046 0.322021484375 0.3438680171966553 0.06520342826843262 0.0040269955061376095\n",
            "56.343652821845254 7.341097954400822 1.0\n",
            "repr, std, cov, conv, closs 0.06287132203578949 0.32568359375 0.3139086961746216 0.060186080634593964 0.016250086948275566\n",
            "56.17495936270411 7.138498122106832 1.0\n",
            "repr, std, cov, conv, closs 0.051759421825408936 0.327392578125 0.3334943652153015 0.06188482046127319 0.0008692772826179862\n",
            "56.00677097346404 7.039304710069875 1.0\n",
            "repr, std, cov, conv, closs 0.05944503843784332 0.318359375 0.3781883716583252 0.06136581301689148 0.016086256131529808\n",
            "55.17335230750636 6.831364216607612 1.0\n",
            "repr, std, cov, conv, closs 0.04688824713230133 0.327880859375 0.3173423707485199 0.06349069625139236 0.0004769470542669296\n",
            "55.28375418547367 6.783735372886271 1.0\n",
            "repr, std, cov, conv, closs 0.03712940961122513 0.330810546875 0.31631696224212646 0.055834006518125534 0.01641666889190674\n",
            "55.339037939659136 6.709560076941027 1.0\n",
            "repr, std, cov, conv, closs 0.056460633873939514 0.330810546875 0.30442100763320923 0.06576785445213318 0.03099701553583145\n",
            "55.22852565981386 6.7634248014441125 1.0\n",
            "repr, std, cov, conv, closs 0.03261128440499306 0.333251953125 0.2988917827606201 0.0622870996594429 0.001021758303977549\n",
            "55.28375418547367 6.913792963532259 1.0\n",
            "repr, std, cov, conv, closs 0.051556363701820374 0.330322265625 0.29539164900779724 0.0545617938041687 0.0283232219517231\n",
            "55.449771354576384 7.032272437632244 1.0\n",
            "repr, std, cov, conv, closs 0.04823387414216995 0.331298828125 0.29334092140197754 0.05220816656947136 0.012135491706430912\n",
            "55.78330283910163 7.2030021916723745 1.0\n",
            "repr, std, cov, conv, closs 0.039009831845760345 0.332275390625 0.265789270401001 0.053941190242767334 0.0406569167971611\n",
            "55.839086141940726 7.2972051195531105 1.0\n",
            "repr, std, cov, conv, closs 0.03478381037712097 0.33544921875 0.25895604491233826 0.05004071444272995 0.00037324681761674583\n",
            "56.00677097346404 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.05048711225390434 0.33154296875 0.26169270277023315 0.06105493754148483 0.025735262781381607\n",
            "56.00677097346404 7.610055223119162 1.0\n",
            "repr, std, cov, conv, closs 0.04469866678118706 0.331298828125 0.2515122592449188 0.06752853095531464 0.03038160316646099\n",
            "55.78330283910163 7.787025382274013 1.0\n",
            "repr, std, cov, conv, closs 0.052212901413440704 0.329345703125 0.30352556705474854 0.06574074178934097 0.04058528691530228\n",
            "55.39437697759879 7.7714746614764 1.0\n",
            "repr, std, cov, conv, closs 0.046586908400058746 0.32763671875 0.3102768659591675 0.06083244830369949 0.0562618188560009\n",
            "55.008162739790635 7.725008580250108 1.0\n",
            "repr, std, cov, conv, closs 0.04715065658092499 0.322998046875 0.33651667833328247 0.06756412982940674 0.00022723022266291082\n",
            "54.40668781095771 7.6024527703488145 1.0\n",
            "repr, std, cov, conv, closs 0.03895575553178787 0.325439453125 0.351252019405365 0.06295575201511383 0.0002607525675557554\n",
            "53.973386438339965 7.437106938260827 1.0\n",
            "repr, std, cov, conv, closs 0.042481619864702225 0.325927734375 0.3323860764503479 0.06318515539169312 0.0022541910875588655\n",
            "53.490045883823434 7.326437752458155 1.0\n",
            "repr, std, cov, conv, closs 0.04539696127176285 0.323974609375 0.3541546165943146 0.06970348209142685 0.0012239206116646528\n",
            "52.53631119584325 7.16709497414512 1.0\n",
            "repr, std, cov, conv, closs 0.038246989250183105 0.330810546875 0.32579535245895386 0.07452090084552765 0.01583302579820156\n",
            "52.588847507039084 7.09581664297652 1.0\n",
            "repr, std, cov, conv, closs 0.04222918301820755 0.328369140625 0.3354089856147766 0.06003739684820175 0.01649709790945053\n",
            "53.11710880196585 7.060443749153518 1.0\n",
            "repr, std, cov, conv, closs 0.03868556767702103 0.33251953125 0.25420916080474854 0.05615539476275444 0.015798961743712425\n",
            "53.43660927454889 7.145636620228938 1.0\n",
            "tcost icost 0.021148681640625 0.3585366904735565\n",
            "tcost icost 0.01023101806640625 0.35931921005249023\n",
            "tcost icost 0.01023101806640625 0.3627336919307709\n",
            "search 0.373046875\n",
            "tcost icost 0.02105712890625 0.35781002044677734\n",
            "tcost icost 0.006061553955078125 0.38000866770744324\n",
            "tcost icost 0.006061553955078125 0.3775373101234436\n",
            "search 0.383544921875\n",
            "tcost icost 0.01183319091796875 0.36710450053215027\n",
            "tcost icost 0.01482391357421875 0.36251142621040344\n",
            "tcost icost 0.01482391357421875 0.36189836263656616\n",
            "search 0.376708984375\n",
            "tcost icost 0.01273345947265625 0.3663869798183441\n",
            "tcost icost 0.01023101806640625 0.36911141872406006\n",
            "tcost icost 0.01023101806640625 0.37079131603240967\n",
            "search 0.381103515625\n",
            "tcost icost 0.00832366943359375 0.37686416506767273\n",
            "tcost icost 0.021148681640625 0.3701857030391693\n",
            "tcost icost 0.021148681640625 0.36527374386787415\n",
            "search 0.386474609375\n",
            "tcost icost 0.01482391357421875 0.36548829078674316\n",
            "tcost icost 0.006061553955078125 0.3827873766422272\n",
            "tcost icost 0.006061553955078125 0.3824455142021179\n",
            "search 0.388427734375\n",
            "tcost icost 0.021148681640625 0.364802747964859\n",
            "tcost icost 0.01023101806640625 0.3777914345264435\n",
            "tcost icost 0.01023101806640625 0.37294769287109375\n",
            "search 0.38330078125\n",
            "tcost icost 0.01273345947265625 0.37514638900756836\n",
            "tcost icost 0.01023101806640625 0.3762001693248749\n",
            "tcost icost 0.01023101806640625 0.3728030323982239\n",
            "search 0.383056640625\n",
            "tcost icost 0.00832366943359375 0.37691158056259155\n",
            "tcost icost 0.021148681640625 0.36878636479377747\n",
            "tcost icost 0.021148681640625 0.36972615122795105\n",
            "search 0.390869140625\n",
            "tcost icost 0.00832366943359375 0.3770913779735565\n",
            "tcost icost 0.021148681640625 0.3731831908226013\n",
            "tcost icost 0.021148681640625 0.374347448348999\n",
            "search 0.3955078125\n",
            "tcost icost 0.00832366943359375 0.38024359941482544\n",
            "tcost icost 0.021148681640625 0.36828866600990295\n",
            "tcost icost 0.021148681640625 0.37558838725090027\n",
            "search 0.396728515625\n",
            "tcost icost 0.01183319091796875 0.3736860752105713\n",
            "tcost icost 0.006061553955078125 0.38508790731430054\n",
            "tcost icost 0.006061553955078125 0.3892727494239807\n",
            "search 0.395263671875\n",
            "tcost icost 0.01273345947265625 0.37732431292533875\n",
            "tcost icost 0.01023101806640625 0.37381845712661743\n",
            "tcost icost 0.01023101806640625 0.3729616403579712\n",
            "search 0.38330078125\n",
            "tcost icost 0.00841522216796875 0.37688907980918884\n",
            "tcost icost 0.0216064453125 0.368960976600647\n",
            "tcost icost 0.0216064453125 0.373706191778183\n",
            "search 0.3955078125\n",
            "tcost icost 0.01177978515625 0.37615805864334106\n",
            "tcost icost 0.00603485107421875 0.3845962882041931\n",
            "tcost icost 0.00603485107421875 0.3842025399208069\n",
            "search 0.390380859375\n",
            "tcost icost 0.0079345703125 0.38111549615859985\n",
            "tcost icost 0.0186614990234375 0.3775179386138916\n",
            "tcost icost 0.0186614990234375 0.3754142224788666\n",
            "search 0.39404296875\n",
            "tcost icost 0.01861572265625 0.3799280822277069\n",
            "tcost icost 0.00978851318359375 0.3815906345844269\n",
            "tcost icost 0.00978851318359375 0.3865665793418884\n",
            "search 0.396240234375\n",
            "tcost icost 0.01031494140625 0.38124045729637146\n",
            "tcost icost 0.015777587890625 0.3824334442615509\n",
            "tcost icost 0.015777587890625 0.3801698088645935\n",
            "search 0.39599609375\n",
            "tcost icost 0.010528564453125 0.3852372467517853\n",
            "tcost icost 0.016693115234375 0.38202551007270813\n",
            "tcost icost 0.016693115234375 0.3807390630245209\n",
            "search 0.3974609375\n",
            "tcost icost 0.01560211181640625 0.37921690940856934\n",
            "tcost icost 0.005748748779296875 0.39592042565345764\n",
            "tcost icost 0.005748748779296875 0.39367979764938354\n",
            "search 0.399658203125\n",
            "tcost icost 0.01151275634765625 0.388019323348999\n",
            "tcost icost 0.00949859619140625 0.38709399104118347\n",
            "tcost icost 0.00949859619140625 0.38709399104118347\n",
            "search 0.396728515625\n",
            "tcost icost 0.01081085205078125 0.3889332115650177\n",
            "tcost icost 0.0181884765625 0.38689470291137695\n",
            "tcost icost 0.0181884765625 0.38646483421325684\n",
            "search 0.40478515625\n",
            "tcost icost 0.0192108154296875 0.38590872287750244\n",
            "tcost icost 0.006008148193359375 0.39768117666244507\n",
            "tcost icost 0.006008148193359375 0.39691361784935\n",
            "search 0.403076171875\n",
            "tcost icost 0.00595855712890625 0.3994961380958557\n",
            "tcost icost 0.0134735107421875 0.39163869619369507\n",
            "tcost icost 0.0134735107421875 0.3880465626716614\n",
            "search 0.4013671875\n",
            "tcost icost 0.007724761962890625 0.39860787987709045\n",
            "tcost icost 0.0172576904296875 0.3929716944694519\n",
            "tcost icost 0.0172576904296875 0.38935354351997375\n",
            "search 0.40673828125\n",
            "tcost icost 0.01068115234375 0.3976342976093292\n",
            "tcost icost 0.0173492431640625 0.3980497121810913\n",
            "tcost icost 0.0173492431640625 0.394777774810791\n",
            "search 0.412109375\n",
            "tcost icost 0.0106964111328125 0.39775848388671875\n",
            "tcost icost 0.0176849365234375 0.3947872519493103\n",
            "tcost icost 0.0176849365234375 0.3942978084087372\n",
            "search 0.411865234375\n",
            "tcost icost 0.010528564453125 0.40469232201576233\n",
            "tcost icost 0.01654052734375 0.3978081941604614\n",
            "tcost icost 0.01654052734375 0.3978081941604614\n",
            "search 0.414306640625\n",
            "tcost icost 0.01097869873046875 0.39984825253486633\n",
            "tcost icost 0.00909423828125 0.4024636745452881\n",
            "tcost icost 0.00909423828125 0.40232864022254944\n",
            "search 0.411376953125\n",
            "tcost icost 0.0125732421875 0.4013589322566986\n",
            "tcost icost 0.00905609130859375 0.4035976529121399\n",
            "tcost icost 0.00905609130859375 0.40259575843811035\n",
            "search 0.41162109375\n",
            "tcost icost 0.0153961181640625 0.4020000398159027\n",
            "tcost icost 0.005710601806640625 0.4053382873535156\n",
            "tcost icost 0.005710601806640625 0.40589064359664917\n",
            "search 0.41162109375\n",
            "tcost icost 0.007106781005859375 0.4081364572048187\n",
            "tcost icost 0.005584716796875 0.4048655331134796\n",
            "tcost icost 0.005584716796875 0.40721553564071655\n",
            "search 0.412841796875\n",
            "tcost icost 0.00962066650390625 0.40630197525024414\n",
            "tcost icost 0.005496978759765625 0.4048694372177124\n",
            "tcost icost 0.005496978759765625 0.4046366512775421\n",
            "search 0.41015625\n",
            "tcost icost 0.00653839111328125 0.40880441665649414\n",
            "tcost icost 0.005428314208984375 0.4066329598426819\n",
            "tcost icost 0.005428314208984375 0.40437108278274536\n",
            "search 0.40966796875\n",
            "tcost icost 0.00782012939453125 0.40462949872016907\n",
            "tcost icost 0.01361083984375 0.40118855237960815\n",
            "tcost icost 0.01361083984375 0.4056223928928375\n",
            "search 0.419189453125\n",
            "tcost icost 0.010894775390625 0.40352392196655273\n",
            "tcost icost 0.005977630615234375 0.40534722805023193\n",
            "tcost icost 0.005977630615234375 0.4054422080516815\n",
            "search 0.411376953125\n",
            "tcost icost 0.01213836669921875 0.4023374617099762\n",
            "tcost icost 0.0055389404296875 0.4042282998561859\n",
            "tcost icost 0.0055389404296875 0.40652135014533997\n",
            "search 0.412109375\n",
            "tcost icost 0.01171875 0.4042718708515167\n",
            "tcost icost 0.00966644287109375 0.40205302834510803\n",
            "tcost icost 0.00966644287109375 0.4028666019439697\n",
            "search 0.41259765625\n",
            "tcost icost 0.006805419921875 0.40816015005111694\n",
            "tcost icost 0.0054473876953125 0.40415048599243164\n",
            "tcost icost 0.0054473876953125 0.40564486384391785\n",
            "search 0.4111328125\n",
            "tcost icost 0.00612640380859375 0.40802234411239624\n",
            "tcost icost 0.005199432373046875 0.40670081973075867\n",
            "tcost icost 0.005199432373046875 0.40669411420822144\n",
            "search 0.411865234375\n",
            "tcost icost 0.01023101806640625 0.4057716727256775\n",
            "tcost icost 0.005741119384765625 0.4064830541610718\n",
            "tcost icost 0.005741119384765625 0.40681934356689453\n",
            "search 0.41259765625\n",
            "tcost icost 0.0070953369140625 0.4076859951019287\n",
            "tcost icost 0.00559234619140625 0.40833625197410583\n",
            "tcost icost 0.00559234619140625 0.4079038202762604\n",
            "search 0.41357421875\n",
            "tcost icost 0.006885528564453125 0.41158127784729004\n",
            "tcost icost 0.005565643310546875 0.4122353792190552\n",
            "tcost icost 0.005565643310546875 0.40776771306991577\n",
            "search 0.413330078125\n",
            "tcost icost 0.0102386474609375 0.41029757261276245\n",
            "tcost icost 0.005725860595703125 0.41060182452201843\n",
            "tcost icost 0.005725860595703125 0.40987348556518555\n",
            "search 0.41552734375\n",
            "tcost icost 0.00598907470703125 0.4093239903450012\n",
            "tcost icost 0.005191802978515625 0.41120603680610657\n",
            "tcost icost 0.005191802978515625 0.408890962600708\n",
            "search 0.4140625\n",
            "tcost icost 0.00732421875 0.4090464115142822\n",
            "tcost icost 0.0048828125 0.40680524706840515\n",
            "tcost icost 0.0048828125 0.4062076210975647\n",
            "search 0.4111328125\n",
            "tcost icost 0.00609588623046875 0.41441118717193604\n",
            "tcost icost 0.0050811767578125 0.4121217131614685\n",
            "tcost icost 0.0050811767578125 0.4106517434120178\n",
            "search 0.415771484375\n",
            "tcost icost 0.006969451904296875 0.41009193658828735\n",
            "tcost icost 0.00487518310546875 0.40865403413772583\n",
            "tcost icost 0.00487518310546875 0.40813249349594116\n",
            "search 0.4130859375\n",
            "tcost icost 0.00815582275390625 0.4183277189731598\n",
            "tcost icost 0.006015777587890625 0.41378551721572876\n",
            "tcost icost 0.006015777587890625 0.41353893280029297\n",
            "search 0.419677734375\n",
            "tcost icost 0.0156097412109375 0.41292309761047363\n",
            "tcost icost 0.006381988525390625 0.414704293012619\n",
            "tcost icost 0.006381988525390625 0.414352148771286\n",
            "search 0.420654296875\n",
            "tcost icost 0.0136260986328125 0.41515418887138367\n",
            "tcost icost 0.006175994873046875 0.4173373579978943\n",
            "tcost icost 0.006175994873046875 0.4192398488521576\n",
            "search 0.42529296875\n",
            "tcost icost 0.01546478271484375 0.41818422079086304\n",
            "tcost icost 0.00609588623046875 0.41547641158103943\n",
            "tcost icost 0.00609588623046875 0.4198998212814331\n",
            "search 0.426025390625\n",
            "tcost icost 0.016845703125 0.4159092903137207\n",
            "tcost icost 0.006519317626953125 0.4166717529296875\n",
            "tcost icost 0.006519317626953125 0.4166717529296875\n",
            "search 0.42333984375\n",
            "tcost icost 0.005390167236328125 0.41805097460746765\n",
            "tcost icost 0.00423431396484375 0.39978891611099243\n",
            "tcost icost 0.00423431396484375 0.40076878666877747\n",
            "search 0.405029296875\n",
            "tcost icost 0.010498046875 0.41953620314598083\n",
            "tcost icost 0.00795745849609375 0.4220431447029114\n",
            "tcost icost 0.00795745849609375 0.41737985610961914\n",
            "search 0.425537109375\n",
            "tcost icost 0.004970550537109375 0.4162784516811371\n",
            "tcost icost 0.004131317138671875 0.39460593461990356\n",
            "tcost icost 0.004131317138671875 0.3950621485710144\n",
            "search 0.399169921875\n",
            "tcost icost 0.006816864013671875 0.4181455075740814\n",
            "tcost icost 0.004100799560546875 0.39591607451438904\n",
            "tcost icost 0.004100799560546875 0.39653870463371277\n",
            "search 0.400634765625\n",
            "tcost icost 0.0037078857421875 0.39305391907691956\n",
            "tcost icost 0.004398345947265625 0.3639649748802185\n",
            "tcost icost 0.004398345947265625 0.36385777592658997\n",
            "search 0.3681640625\n",
            "tcost icost 0.0035152435302734375 0.38762933015823364\n",
            "tcost icost 0.0040283203125 0.3575730323791504\n",
            "tcost icost 0.0040283203125 0.35940495133399963\n",
            "search 0.36328125\n",
            "tcost icost 0.00377655029296875 0.41091853380203247\n",
            "tcost icost 0.00432586669921875 0.3710744082927704\n",
            "tcost icost 0.00432586669921875 0.3726750910282135\n",
            "search 0.376953125\n",
            "tcost icost 0.00414276123046875 0.4096333980560303\n",
            "tcost icost 0.004276275634765625 0.3796581029891968\n",
            "tcost icost 0.004276275634765625 0.38102829456329346\n",
            "search 0.385498046875\n",
            "tcost icost 0.0093536376953125 0.4191303551197052\n",
            "tcost icost 0.0164794921875 0.41658058762550354\n",
            "tcost icost 0.0164794921875 0.41658055782318115\n",
            "search 0.43310546875\n",
            "tcost icost 0.011474609375 0.42260757088661194\n",
            "tcost icost 0.00949859619140625 0.41887742280960083\n",
            "tcost icost 0.00949859619140625 0.41887742280960083\n",
            "search 0.428466796875\n",
            "tcost icost 0.012115478515625 0.4235548675060272\n",
            "tcost icost 0.005523681640625 0.4166108965873718\n",
            "tcost icost 0.005523681640625 0.41653743386268616\n",
            "search 0.422119140625\n",
            "tcost icost 0.007427215576171875 0.4229053556919098\n",
            "tcost icost 0.005748748779296875 0.419508695602417\n",
            "tcost icost 0.005748748779296875 0.4195306897163391\n",
            "search 0.42529296875\n",
            "tcost icost 0.0106658935546875 0.42162230610847473\n",
            "tcost icost 0.005931854248046875 0.42008548974990845\n",
            "tcost icost 0.005931854248046875 0.4201766550540924\n",
            "search 0.426025390625\n",
            "tcost icost 0.0105743408203125 0.42318278551101685\n",
            "tcost icost 0.0059051513671875 0.4203866422176361\n",
            "tcost icost 0.0059051513671875 0.42492783069610596\n",
            "search 0.430908203125\n",
            "tcost icost 0.00991058349609375 0.4222703278064728\n",
            "tcost icost 0.00559234619140625 0.41827183961868286\n",
            "tcost icost 0.00559234619140625 0.4200283885002136\n",
            "search 0.425537109375\n",
            "tcost icost 0.009490966796875 0.4236585199832916\n",
            "tcost icost 0.0171356201171875 0.4256514012813568\n",
            "tcost icost 0.0171356201171875 0.4302073121070862\n",
            "search 0.447265625\n",
            "tcost icost 0.01122283935546875 0.4328247606754303\n",
            "tcost icost 0.00937652587890625 0.4317386746406555\n",
            "tcost icost 0.00937652587890625 0.4292600154876709\n",
            "search 0.4384765625\n",
            "tcost icost 0.0108642578125 0.4314296245574951\n",
            "tcost icost 0.0059814453125 0.42805957794189453\n",
            "tcost icost 0.0059814453125 0.42563867568969727\n",
            "search 0.431640625\n",
            "tcost icost 0.021820068359375 0.42884713411331177\n",
            "tcost icost 0.006072998046875 0.4291601777076721\n",
            "tcost icost 0.006072998046875 0.42804354429244995\n",
            "search 0.43408203125\n",
            "tcost icost 0.0114898681640625 0.42921486496925354\n",
            "tcost icost 0.006015777587890625 0.42615750432014465\n",
            "tcost icost 0.006015777587890625 0.42615750432014465\n",
            "search 0.432373046875\n",
            "tcost icost 0.0134124755859375 0.43138718605041504\n",
            "tcost icost 0.00616455078125 0.42804577946662903\n",
            "tcost icost 0.00616455078125 0.42708519101142883\n",
            "search 0.43310546875\n",
            "tcost icost 0.011474609375 0.4286729693412781\n",
            "tcost icost 0.00949859619140625 0.4330579936504364\n",
            "tcost icost 0.00949859619140625 0.4282802939414978\n",
            "search 0.437744140625\n",
            "tcost icost 0.01502227783203125 0.4278976321220398\n",
            "tcost icost 0.01163482666015625 0.43788987398147583\n",
            "tcost icost 0.01163482666015625 0.4283377230167389\n",
            "search 0.43994140625\n",
            "tcost icost 0.01007843017578125 0.42894792556762695\n",
            "tcost icost 0.006473541259765625 0.42813950777053833\n",
            "tcost icost 0.006473541259765625 0.42813950777053833\n",
            "search 0.434814453125\n",
            "tcost icost 0.01052093505859375 0.429935485124588\n",
            "tcost icost 0.00661468505859375 0.4279111921787262\n",
            "tcost icost 0.00661468505859375 0.4281039834022522\n",
            "search 0.434814453125\n",
            "tcost icost 0.018829345703125 0.4280894994735718\n",
            "tcost icost 0.00635528564453125 0.4303441643714905\n",
            "tcost icost 0.00635528564453125 0.42747482657432556\n",
            "search 0.433837890625\n",
            "tcost icost 0.014495849609375 0.42873188853263855\n",
            "tcost icost 0.00624847412109375 0.4271761476993561\n",
            "tcost icost 0.00624847412109375 0.4276552200317383\n",
            "search 0.43408203125\n",
            "tcost icost 0.00907135009765625 0.4286291003227234\n",
            "tcost icost 0.0061492919921875 0.4279187023639679\n",
            "tcost icost 0.0061492919921875 0.4267072081565857\n",
            "search 0.432861328125\n",
            "tcost icost 0.01261138916015625 0.43188923597335815\n",
            "tcost icost 0.0101776123046875 0.4290076494216919\n",
            "tcost icost 0.0101776123046875 0.4297741949558258\n",
            "search 0.43994140625\n",
            "tcost icost 0.0135650634765625 0.4289133846759796\n",
            "tcost icost 0.0061798095703125 0.42706719040870667\n",
            "tcost icost 0.0061798095703125 0.4263475239276886\n",
            "search 0.432373046875\n",
            "tcost icost 0.00624847412109375 0.42702507972717285\n",
            "tcost icost 0.00624847412109375 0.42702507972717285\n",
            "tcost icost 0.00624847412109375 0.431691974401474\n",
            "search 0.43798828125\n",
            "tcost icost 0.017425537109375 0.42838433384895325\n",
            "tcost icost 0.00592803955078125 0.4263416528701782\n",
            "tcost icost 0.00592803955078125 0.4235021471977234\n",
            "search 0.429443359375\n",
            "tcost icost 0.0078582763671875 0.43563657999038696\n",
            "tcost icost 0.00598907470703125 0.42710578441619873\n",
            "tcost icost 0.00598907470703125 0.4284336268901825\n",
            "search 0.4345703125\n",
            "tcost icost 0.0174713134765625 0.43228772282600403\n",
            "tcost icost 0.00618743896484375 0.4302200973033905\n",
            "tcost icost 0.00618743896484375 0.42952436208724976\n",
            "search 0.435546875\n",
            "tcost icost 0.020172119140625 0.432159960269928\n",
            "tcost icost 0.006519317626953125 0.4302578270435333\n",
            "tcost icost 0.006519317626953125 0.4327854514122009\n",
            "search 0.439453125\n",
            "tcost icost 0.0093841552734375 0.4322172701358795\n",
            "tcost icost 0.005863189697265625 0.42761892080307007\n",
            "tcost icost 0.005863189697265625 0.42531293630599976\n",
            "search 0.43115234375\n",
            "tcost icost 0.005863189697265625 0.42529061436653137\n",
            "tcost icost 0.005863189697265625 0.42538967728614807\n",
            "tcost icost 0.005863189697265625 0.42538967728614807\n",
            "search 0.43115234375\n",
            "tcost icost 0.01096343994140625 0.43314269185066223\n",
            "tcost icost 0.005985260009765625 0.42946937680244446\n",
            "tcost icost 0.005985260009765625 0.42702922224998474\n",
            "search 0.43310546875\n",
            "tcost icost 0.00833892822265625 0.43259167671203613\n",
            "tcost icost 0.006092071533203125 0.42859187722206116\n",
            "tcost icost 0.006092071533203125 0.4286811649799347\n",
            "search 0.434814453125\n",
            "tcost icost 0.0114288330078125 0.4368637502193451\n",
            "tcost icost 0.00945281982421875 0.4330872893333435\n",
            "tcost icost 0.00945281982421875 0.4365357756614685\n",
            "search 0.446044921875\n",
            "tcost icost 0.0251007080078125 0.4343322217464447\n",
            "tcost icost 0.006183624267578125 0.4294266402721405\n",
            "tcost icost 0.006183624267578125 0.4291493594646454\n",
            "search 0.435302734375\n",
            "tcost icost 0.01776123046875 0.43376970291137695\n",
            "tcost icost 0.0062255859375 0.4298061728477478\n",
            "tcost icost 0.0062255859375 0.42938387393951416\n",
            "search 0.435546875\n",
            "tcost icost 0.019775390625 0.4332408010959625\n",
            "tcost icost 0.006011962890625 0.42668160796165466\n",
            "tcost icost 0.006011962890625 0.4271523356437683\n",
            "search 0.433349609375\n",
            "tcost icost 0.011932373046875 0.43326184153556824\n",
            "tcost icost 0.006053924560546875 0.4275747835636139\n",
            "tcost icost 0.006053924560546875 0.42772889137268066\n",
            "search 0.433837890625\n",
            "tcost icost 0.0101165771484375 0.43306663632392883\n",
            "tcost icost 0.005649566650390625 0.42281433939933777\n",
            "tcost icost 0.005649566650390625 0.4229629337787628\n",
            "search 0.428466796875\n",
            "tcost icost 0.010589599609375 0.43320396542549133\n",
            "tcost icost 0.005889892578125 0.4250052869319916\n",
            "tcost icost 0.005889892578125 0.4252513647079468\n",
            "search 0.43115234375\n",
            "tcost icost 0.0030956268310546875 0.40215903520584106\n",
            "tcost icost 0.0040435791015625 0.34668484330177307\n",
            "tcost icost 0.0040435791015625 0.3447054326534271\n",
            "search 0.348876953125\n",
            "tcost icost 0.003910064697265625 0.40521711111068726\n",
            "tcost icost 0.004489898681640625 0.34871605038642883\n",
            "tcost icost 0.004489898681640625 0.34871605038642883\n",
            "search 0.35302734375\n",
            "ded\n",
            "time\n",
            "28 #### train ####\n",
            "repr, std, cov, conv, closs 0.034366969019174576 0.33251953125 0.27992236614227295 0.056417398154735565 0.0295957550406456\n",
            "53.973386438339965 7.195806385287089 1.0\n",
            "repr, std, cov, conv, closs 0.049728501588106155 0.33251953125 0.2713014483451843 0.06608691811561584 0.031083140522241592\n",
            "54.0273598247783 7.275357214562424 1.0\n",
            "repr, std, cov, conv, closs 0.047672465443611145 0.328857421875 0.3002670705318451 0.06970488280057907 0.0003767026064451784\n",
            "54.51555559326743 7.422255005993835 1.0\n",
            "repr, std, cov, conv, closs 0.03799225389957428 0.33203125 0.3004509508609772 0.069289930164814 0.041181862354278564\n",
            "54.62464122000954 7.429677260999828 1.0\n",
            "repr, std, cov, conv, closs 0.04838591814041138 0.331298828125 0.3253890573978424 0.056253354996442795 0.00033169396920129657\n",
            "54.62464122000954 7.451988589244286 1.0\n",
            "repr, std, cov, conv, closs 0.04181808605790138 0.3349609375 0.25377631187438965 0.06206851825118065 0.0005138638662174344\n",
            "54.95320953026038 7.414840165828007 1.0\n",
            "repr, std, cov, conv, closs 0.04558667913079262 0.332763671875 0.28837019205093384 0.06219363212585449 0.0038585944566875696\n",
            "54.78867907221785 7.341097954400822 1.0\n",
            "repr, std, cov, conv, closs 0.038791559636592865 0.326904296875 0.35585129261016846 0.06356730312108994 0.0028920115437358618\n",
            "54.57007114886069 7.2899152043487625 1.0\n",
            "repr, std, cov, conv, closs 0.046995438635349274 0.32421875 0.32737451791763306 0.05770398676395416 0.00045417415094561875\n",
            "54.46109449876867 7.110015372079115 1.0\n",
            "repr, std, cov, conv, closs 0.04929538071155548 0.32861328125 0.29019027948379517 0.06427042186260223 0.0024931947700679302\n",
            "54.2980374380442 7.011217743736587 1.0\n",
            "repr, std, cov, conv, closs 0.045087218284606934 0.32470703125 0.31951096653938293 0.05544772744178772 0.01582196168601513\n",
            "54.13546857178767 6.872455009100297 1.0\n",
            "repr, std, cov, conv, closs 0.045094557106494904 0.325927734375 0.3031066656112671 0.06065046042203903 0.002069072797894478\n",
            "54.13546857178767 6.858730688991627 1.0\n",
            "repr, std, cov, conv, closs 0.06109971925616264 0.32861328125 0.324063241481781 0.05616679787635803 0.058109089732170105\n",
            "54.2980374380442 6.824539676930682 1.0\n",
            "repr, std, cov, conv, closs 0.04627900570631027 0.329345703125 0.30673396587371826 0.05432386323809624 0.00029975592042319477\n",
            "54.679265861229545 6.906886077454805 1.0\n",
            "repr, std, cov, conv, closs 0.04944483935832977 0.3291015625 0.3093864917755127 0.06823086738586426 0.0009504329646006227\n",
            "54.84346775129006 7.060443749153518 1.0\n",
            "repr, std, cov, conv, closs 0.03608406335115433 0.33203125 0.2687170207500458 0.07063926756381989 0.010081194341182709\n",
            "55.17335230750636 7.1886177675195695 1.0\n",
            "repr, std, cov, conv, closs 0.034852299839258194 0.3330078125 0.2787500321865082 0.07077615708112717 0.016394853591918945\n",
            "55.61628707340393 7.333764190210612 1.0\n",
            "repr, std, cov, conv, closs 0.04535556584596634 0.3369140625 0.27130958437919617 0.060377418994903564 0.03119168058037758\n",
            "55.89492522808266 7.429677260999828 1.0\n",
            "repr, std, cov, conv, closs 0.029621277004480362 0.337890625 0.25579380989074707 0.06989458203315735 0.0007103648968040943\n",
            "56.23113432206681 7.610055223119162 1.0\n",
            "repr, std, cov, conv, closs 0.037588585168123245 0.33251953125 0.26111435890197754 0.07364635914564133 0.000573265366256237\n",
            "56.28736545638887 7.732733588830357 1.0\n",
            "repr, std, cov, conv, closs 0.050712116062641144 0.326171875 0.3149458169937134 0.06129613518714905 0.0008721958729438484\n",
            "56.17495936270411 7.857389598720513 1.0\n",
            "repr, std, cov, conv, closs 0.04871206730604172 0.326171875 0.31052160263061523 0.06365596503019333 0.015682844445109367\n",
            "55.839086141940726 7.794812407656286 1.0\n",
            "repr, std, cov, conv, closs 0.044539641588926315 0.324951171875 0.33307987451553345 0.06152721494436264 0.02369391731917858\n",
            "55.11823407343294 7.572118832011732 1.0\n",
            "repr, std, cov, conv, closs 0.05054573714733124 0.32861328125 0.3298078179359436 0.06410162895917892 0.0010633125202730298\n",
            "54.73394512709077 7.451988589244286 1.0\n",
            "repr, std, cov, conv, closs 0.04274262860417366 0.31982421875 0.3811899721622467 0.0651426836848259 0.014659276232123375\n",
            "54.13546857178767 7.217415399057909 1.0\n",
            "repr, std, cov, conv, closs 0.03710787743330002 0.321044921875 0.38627398014068604 0.061299920082092285 0.028665687888860703\n",
            "53.650676545102584 7.09581664297652 1.0\n",
            "repr, std, cov, conv, closs 0.0416598916053772 0.3212890625 0.3297443091869354 0.057829223573207855 0.022280842065811157\n",
            "52.85231815920079 6.893092998365078 1.0\n",
            "repr, std, cov, conv, closs 0.04985349625349045 0.318603515625 0.3831838369369507 0.057981424033641815 0.003817595075815916\n",
            "52.588847507039084 6.810911043931776 1.0\n",
            "repr, std, cov, conv, closs 0.04125995934009552 0.327880859375 0.3113926351070404 0.06513191759586334 0.007951367646455765\n",
            "52.37901695554674 6.736438601454199 1.0\n",
            "repr, std, cov, conv, closs 0.035113975405693054 0.328857421875 0.31081050634384155 0.0627094954252243 0.013100966811180115\n",
            "52.69407779090066 6.729708892561638 1.0\n",
            "repr, std, cov, conv, closs 0.04271731898188591 0.32763671875 0.2818841338157654 0.06439090520143509 0.0006017228006385267\n",
            "53.81178958041819 6.838195580824219 1.0\n",
            "repr, std, cov, conv, closs 0.04860306531190872 0.33154296875 0.3215867877006531 0.06646893918514252 0.0004910877905786037\n",
            "54.2437936443998 6.858730688991627 1.0\n",
            "repr, std, cov, conv, closs 0.034833088517189026 0.3330078125 0.29207897186279297 0.06849254667758942 0.0011158108245581388\n",
            "54.84346775129006 7.053390358794724 1.0\n",
            "repr, std, cov, conv, closs 0.04394655302166939 0.32958984375 0.3230159878730774 0.07047653943300247 0.0005447104922495782\n",
            "55.22852565981386 7.16709497414512 1.0\n",
            "repr, std, cov, conv, closs 0.035342611372470856 0.338134765625 0.24010193347930908 0.06311117112636566 0.015383497811853886\n",
            "56.343652821845254 7.370506422177882 1.0\n",
            "repr, std, cov, conv, closs 0.04152405261993408 0.338134765625 0.2565256953239441 0.06877033412456512 0.000947131309658289\n",
            "56.56936572048049 7.481841285348203 1.0\n",
            "tcost icost 0.0151824951171875 0.4235573709011078\n",
            "tcost icost 0.0106353759765625 0.4196932315826416\n",
            "tcost icost 0.0106353759765625 0.4196931719779968\n",
            "search 0.430419921875\n",
            "tcost icost 0.0270538330078125 0.41868266463279724\n",
            "tcost icost 0.0106353759765625 0.417079359292984\n",
            "tcost icost 0.0106353759765625 0.41873496770858765\n",
            "search 0.429443359375\n",
            "tcost icost 0.0151824951171875 0.41621553897857666\n",
            "tcost icost 0.0106353759765625 0.4144790768623352\n",
            "tcost icost 0.0106353759765625 0.41470152139663696\n",
            "search 0.425537109375\n",
            "tcost icost 0.0106353759765625 0.41326475143432617\n",
            "tcost icost 0.0106353759765625 0.4124191999435425\n",
            "tcost icost 0.0106353759765625 0.41216006875038147\n",
            "search 0.4228515625\n",
            "tcost icost 0.0162506103515625 0.4158695936203003\n",
            "tcost icost 0.0106353759765625 0.4101369380950928\n",
            "tcost icost 0.0106353759765625 0.4128463566303253\n",
            "search 0.423583984375\n",
            "tcost icost 0.0132293701171875 0.4105730950832367\n",
            "tcost icost 0.0106353759765625 0.40862953662872314\n",
            "tcost icost 0.0106353759765625 0.4086550176143646\n",
            "search 0.41943359375\n",
            "tcost icost 0.0132293701171875 0.4108532965183258\n",
            "tcost icost 0.0106353759765625 0.4059995114803314\n",
            "tcost icost 0.0106353759765625 0.4105640649795532\n",
            "search 0.42138671875\n",
            "tcost icost 0.02423095703125 0.40452930331230164\n",
            "tcost icost 0.01490020751953125 0.40621331334114075\n",
            "tcost icost 0.01490020751953125 0.40423494577407837\n",
            "search 0.419189453125\n",
            "tcost icost 0.0132293701171875 0.40381351113319397\n",
            "tcost icost 0.0106353759765625 0.40371719002723694\n",
            "tcost icost 0.0106353759765625 0.4037172198295593\n",
            "search 0.41455078125\n",
            "tcost icost 0.0270538330078125 0.40398284792900085\n",
            "tcost icost 0.0106353759765625 0.40564480423927307\n",
            "tcost icost 0.0106353759765625 0.40336254239082336\n",
            "search 0.4140625\n",
            "tcost icost 0.0132293701171875 0.40107160806655884\n",
            "tcost icost 0.0106353759765625 0.40235522389411926\n",
            "tcost icost 0.0106353759765625 0.40078112483024597\n",
            "search 0.41162109375\n",
            "tcost icost 0.02423095703125 0.39918532967567444\n",
            "tcost icost 0.01490020751953125 0.4007066786289215\n",
            "tcost icost 0.01490020751953125 0.40110617876052856\n",
            "search 0.416015625\n",
            "tcost icost 0.0151824951171875 0.4001830816268921\n",
            "tcost icost 0.0106353759765625 0.4004206657409668\n",
            "tcost icost 0.0106353759765625 0.3973635137081146\n",
            "search 0.408203125\n",
            "tcost icost 0.01490020751953125 0.39618802070617676\n",
            "tcost icost 0.01490020751953125 0.39552581310272217\n",
            "tcost icost 0.01490020751953125 0.39546269178390503\n",
            "search 0.410400390625\n",
            "tcost icost 0.0132293701171875 0.3930160403251648\n",
            "tcost icost 0.0106353759765625 0.3928714394569397\n",
            "tcost icost 0.0106353759765625 0.39772915840148926\n",
            "search 0.408447265625\n",
            "tcost icost 0.0162506103515625 0.39300528168678284\n",
            "tcost icost 0.0106353759765625 0.3954232633113861\n",
            "tcost icost 0.0106353759765625 0.395508348941803\n",
            "search 0.40625\n",
            "tcost icost 0.0132293701171875 0.3906310796737671\n",
            "tcost icost 0.0106353759765625 0.3912915587425232\n",
            "tcost icost 0.0106353759765625 0.39094382524490356\n",
            "search 0.401611328125\n",
            "tcost icost 0.0106353759765625 0.39016100764274597\n",
            "tcost icost 0.0106353759765625 0.38903477787971497\n",
            "tcost icost 0.0106353759765625 0.3908899426460266\n",
            "search 0.401611328125\n",
            "tcost icost 0.0151824951171875 0.3859978914260864\n",
            "tcost icost 0.0106353759765625 0.38675251603126526\n",
            "tcost icost 0.0106353759765625 0.38903477787971497\n",
            "search 0.399658203125\n",
            "tcost icost 0.0162506103515625 0.39085015654563904\n",
            "tcost icost 0.0106353759765625 0.3886893689632416\n",
            "tcost icost 0.0106353759765625 0.39355969429016113\n",
            "search 0.404296875\n",
            "tcost icost 0.02423095703125 0.38599130511283875\n",
            "tcost icost 0.01490020751953125 0.386383593082428\n",
            "tcost icost 0.01490020751953125 0.38638362288475037\n",
            "search 0.4013671875\n",
            "tcost icost 0.0106353759765625 0.38671284914016724\n",
            "tcost icost 0.020721435546875 0.39022520184516907\n",
            "tcost icost 0.020721435546875 0.3877117335796356\n",
            "search 0.408447265625\n",
            "tcost icost 0.0132293701171875 0.38572958111763\n",
            "tcost icost 0.0106353759765625 0.38760077953338623\n",
            "tcost icost 0.0106353759765625 0.3912774324417114\n",
            "search 0.402099609375\n",
            "tcost icost 0.0162506103515625 0.3860699534416199\n",
            "tcost icost 0.0106353759765625 0.38443055748939514\n",
            "tcost icost 0.0106353759765625 0.38443055748939514\n",
            "search 0.395263671875\n",
            "tcost icost 0.0151824951171875 0.3806578516960144\n",
            "tcost icost 0.0106353759765625 0.3816942870616913\n",
            "tcost icost 0.0106353759765625 0.3808547556400299\n",
            "search 0.3916015625\n",
            "tcost icost 0.030426025390625 0.38068342208862305\n",
            "tcost icost 0.01085662841796875 0.3861808478832245\n",
            "tcost icost 0.01085662841796875 0.38113170862197876\n",
            "search 0.391845703125\n",
            "tcost icost 0.01085662841796875 0.37707245349884033\n",
            "tcost icost 0.0232086181640625 0.37491554021835327\n",
            "tcost icost 0.0232086181640625 0.37972840666770935\n",
            "search 0.40283203125\n",
            "tcost icost 0.0140228271484375 0.3756391108036041\n",
            "tcost icost 0.0111846923828125 0.3770328164100647\n",
            "tcost icost 0.0111846923828125 0.3744391202926636\n",
            "search 0.3857421875\n",
            "tcost icost 0.0215911865234375 0.3749571144580841\n",
            "tcost icost 0.017181396484375 0.3728009760379791\n",
            "tcost icost 0.017181396484375 0.37227076292037964\n",
            "search 0.389404296875\n",
            "tcost icost 0.0157012939453125 0.37091904878616333\n",
            "tcost icost 0.0107574462890625 0.37483125925064087\n",
            "tcost icost 0.0107574462890625 0.3752332329750061\n",
            "search 0.385986328125\n",
            "tcost icost 0.0171356201171875 0.3691503405570984\n",
            "tcost icost 0.0107574462890625 0.37483125925064087\n",
            "tcost icost 0.0107574462890625 0.3729666471481323\n",
            "search 0.3837890625\n",
            "tcost icost 0.0126190185546875 0.3691171705722809\n",
            "tcost icost 0.0107574462890625 0.3704231381416321\n",
            "tcost icost 0.0107574462890625 0.3727916479110718\n",
            "search 0.383544921875\n",
            "tcost icost 0.0215606689453125 0.365144282579422\n",
            "tcost icost 0.0107574462890625 0.3707468807697296\n",
            "tcost icost 0.0107574462890625 0.37020373344421387\n",
            "search 0.380859375\n",
            "tcost icost 0.02252197265625 0.36993473768234253\n",
            "tcost icost 0.0113525390625 0.37327247858047485\n",
            "tcost icost 0.0113525390625 0.3709944486618042\n",
            "search 0.38232421875\n",
            "tcost icost 0.0193328857421875 0.37297746539115906\n",
            "tcost icost 0.0193328857421875 0.3746916651725769\n",
            "tcost icost 0.0193328857421875 0.3706320524215698\n",
            "search 0.389892578125\n",
            "tcost icost 0.01219940185546875 0.3666818141937256\n",
            "tcost icost 0.013824462890625 0.3676041066646576\n",
            "tcost icost 0.013824462890625 0.3649185597896576\n",
            "search 0.37890625\n",
            "tcost icost 0.0123748779296875 0.3641780614852905\n",
            "tcost icost 0.0182342529296875 0.3611851632595062\n",
            "tcost icost 0.0182342529296875 0.36422520875930786\n",
            "search 0.382568359375\n",
            "tcost icost 0.01102447509765625 0.366031676530838\n",
            "tcost icost 0.027679443359375 0.3625072240829468\n",
            "tcost icost 0.027679443359375 0.36760005354881287\n",
            "search 0.395263671875\n",
            "tcost icost 0.0202178955078125 0.3636939227581024\n",
            "tcost icost 0.0165252685546875 0.3661123812198639\n",
            "tcost icost 0.0165252685546875 0.36643412709236145\n",
            "search 0.383056640625\n",
            "tcost icost 0.028900146484375 0.371249794960022\n",
            "tcost icost 0.01312255859375 0.3687269389629364\n",
            "tcost icost 0.01312255859375 0.3709949254989624\n",
            "search 0.38427734375\n",
            "tcost icost 0.028778076171875 0.3730708062648773\n",
            "tcost icost 0.01290130615234375 0.3731021285057068\n",
            "tcost icost 0.01290130615234375 0.3708309531211853\n",
            "search 0.3837890625\n",
            "tcost icost 0.0229644775390625 0.3722861707210541\n",
            "tcost icost 0.01141357421875 0.3706313967704773\n",
            "tcost icost 0.01141357421875 0.37302032113075256\n",
            "search 0.384521484375\n",
            "tcost icost 0.0217742919921875 0.3710513710975647\n",
            "tcost icost 0.011322021484375 0.3714407682418823\n",
            "tcost icost 0.011322021484375 0.3691461682319641\n",
            "search 0.38037109375\n",
            "tcost icost 0.021453857421875 0.3723314702510834\n",
            "tcost icost 0.017486572265625 0.37272194027900696\n",
            "tcost icost 0.017486572265625 0.37041354179382324\n",
            "search 0.387939453125\n",
            "tcost icost 0.028228759765625 0.3667439818382263\n",
            "tcost icost 0.01099395751953125 0.37173107266426086\n",
            "tcost icost 0.01099395751953125 0.36943578720092773\n",
            "search 0.38037109375\n",
            "tcost icost 0.0165252685546875 0.36768069863319397\n",
            "tcost icost 0.01117706298828125 0.37074241042137146\n",
            "tcost icost 0.01117706298828125 0.3736012876033783\n",
            "search 0.384765625\n",
            "tcost icost 0.01108551025390625 0.36863380670547485\n",
            "tcost icost 0.0271148681640625 0.3688794672489166\n",
            "tcost icost 0.0271148681640625 0.36675316095352173\n",
            "search 0.393798828125\n",
            "tcost icost 0.01495361328125 0.3686177134513855\n",
            "tcost icost 0.01189422607421875 0.37235668301582336\n",
            "tcost icost 0.01189422607421875 0.3696838617324829\n",
            "search 0.381591796875\n",
            "tcost icost 0.0189361572265625 0.36493757367134094\n",
            "tcost icost 0.0147552490234375 0.3676583170890808\n",
            "tcost icost 0.0147552490234375 0.3676583170890808\n",
            "search 0.38232421875\n",
            "tcost icost 0.011444091796875 0.37340015172958374\n",
            "tcost icost 0.01509857177734375 0.36596325039863586\n",
            "tcost icost 0.01509857177734375 0.3682907521724701\n",
            "search 0.383544921875\n",
            "tcost icost 0.0126190185546875 0.3699672818183899\n",
            "tcost icost 0.0162811279296875 0.36625298857688904\n",
            "tcost icost 0.0162811279296875 0.3686964213848114\n",
            "search 0.385009765625\n",
            "tcost icost 0.0179443359375 0.36404719948768616\n",
            "tcost icost 0.0110931396484375 0.3724652826786041\n",
            "tcost icost 0.0110931396484375 0.37053748965263367\n",
            "search 0.381591796875\n",
            "tcost icost 0.01418304443359375 0.3687479794025421\n",
            "tcost icost 0.0138092041015625 0.3702239692211151\n",
            "tcost icost 0.0138092041015625 0.3699702322483063\n",
            "search 0.3837890625\n",
            "tcost icost 0.0135040283203125 0.3739526569843292\n",
            "tcost icost 0.0179901123046875 0.3707832992076874\n",
            "tcost icost 0.0179901123046875 0.3672879934310913\n",
            "search 0.38525390625\n",
            "tcost icost 0.022125244140625 0.37270593643188477\n",
            "tcost icost 0.01165771484375 0.3753133714199066\n",
            "tcost icost 0.01165771484375 0.3745283782482147\n",
            "search 0.38623046875\n",
            "tcost icost 0.020172119140625 0.3764035105705261\n",
            "tcost icost 0.013763427734375 0.3806160092353821\n",
            "tcost icost 0.013763427734375 0.3804799020290375\n",
            "search 0.39404296875\n",
            "tcost icost 0.01552581787109375 0.378788024187088\n",
            "tcost icost 0.0261077880859375 0.37500083446502686\n",
            "tcost icost 0.0261077880859375 0.3720218241214752\n",
            "search 0.398193359375\n",
            "tcost icost 0.0135040283203125 0.3769700527191162\n",
            "tcost icost 0.0176849365234375 0.37329524755477905\n",
            "tcost icost 0.0176849365234375 0.37349987030029297\n",
            "search 0.39111328125\n",
            "tcost icost 0.0223846435546875 0.3720940947532654\n",
            "tcost icost 0.01244354248046875 0.37969455122947693\n",
            "tcost icost 0.01244354248046875 0.37859752774238586\n",
            "search 0.39111328125\n",
            "tcost icost 0.01532745361328125 0.3742848336696625\n",
            "tcost icost 0.0200958251953125 0.37308788299560547\n",
            "tcost icost 0.0200958251953125 0.3758573532104492\n",
            "search 0.39599609375\n",
            "tcost icost 0.02264404296875 0.37350139021873474\n",
            "tcost icost 0.0135040283203125 0.38046103715896606\n",
            "tcost icost 0.0135040283203125 0.3816659450531006\n",
            "search 0.39501953125\n",
            "tcost icost 0.0156097412109375 0.3749873638153076\n",
            "tcost icost 0.0257568359375 0.37127596139907837\n",
            "tcost icost 0.0257568359375 0.3715116083621979\n",
            "search 0.3974609375\n",
            "tcost icost 0.0197601318359375 0.37725675106048584\n",
            "tcost icost 0.01528167724609375 0.3792942762374878\n",
            "tcost icost 0.01528167724609375 0.3792942762374878\n",
            "search 0.394775390625\n",
            "tcost icost 0.0263519287109375 0.3749401271343231\n",
            "tcost icost 0.0224609375 0.37805986404418945\n",
            "tcost icost 0.0224609375 0.3778983950614929\n",
            "search 0.400390625\n",
            "tcost icost 0.01558685302734375 0.3815140426158905\n",
            "tcost icost 0.0214385986328125 0.37928926944732666\n",
            "tcost icost 0.0214385986328125 0.3798908591270447\n",
            "search 0.4013671875\n",
            "tcost icost 0.0267486572265625 0.3770856261253357\n",
            "tcost icost 0.0130615234375 0.38546761870384216\n",
            "tcost icost 0.0130615234375 0.3851448893547058\n",
            "search 0.3984375\n",
            "tcost icost 0.0243377685546875 0.37906092405319214\n",
            "tcost icost 0.017242431640625 0.3840493857860565\n",
            "tcost icost 0.017242431640625 0.38101187348365784\n",
            "search 0.3984375\n",
            "tcost icost 0.0159912109375 0.3803253173828125\n",
            "tcost icost 0.022735595703125 0.37814855575561523\n",
            "tcost icost 0.022735595703125 0.3807605803012848\n",
            "search 0.403564453125\n",
            "tcost icost 0.0264892578125 0.37957239151000977\n",
            "tcost icost 0.01358795166015625 0.38800477981567383\n",
            "tcost icost 0.01358795166015625 0.3856331706047058\n",
            "search 0.3994140625\n",
            "tcost icost 0.0159149169921875 0.3835211992263794\n",
            "tcost icost 0.0226287841796875 0.3818667232990265\n",
            "tcost icost 0.0226287841796875 0.3819565773010254\n",
            "search 0.404541015625\n",
            "tcost icost 0.01386260986328125 0.38478440046310425\n",
            "tcost icost 0.017181396484375 0.3831162750720978\n",
            "tcost icost 0.017181396484375 0.380764365196228\n",
            "search 0.39794921875\n",
            "tcost icost 0.0244140625 0.3854861259460449\n",
            "tcost icost 0.01496124267578125 0.39265599846839905\n",
            "tcost icost 0.01496124267578125 0.3914976418018341\n",
            "search 0.406494140625\n",
            "tcost icost 0.0220184326171875 0.38697630167007446\n",
            "tcost icost 0.01453399658203125 0.39136743545532227\n",
            "tcost icost 0.01453399658203125 0.3891632854938507\n",
            "search 0.40380859375\n",
            "tcost icost 0.01535797119140625 0.38983723521232605\n",
            "tcost icost 0.021881103515625 0.3863893747329712\n",
            "tcost icost 0.021881103515625 0.3878025412559509\n",
            "search 0.40966796875\n",
            "tcost icost 0.02008056640625 0.38435524702072144\n",
            "tcost icost 0.01374053955078125 0.38920193910598755\n",
            "tcost icost 0.01374053955078125 0.39191359281539917\n",
            "search 0.405517578125\n",
            "tcost icost 0.01258087158203125 0.38942858576774597\n",
            "tcost icost 0.0151214599609375 0.3861214220523834\n",
            "tcost icost 0.0151214599609375 0.38686710596084595\n",
            "search 0.402099609375\n",
            "tcost icost 0.0164031982421875 0.392591655254364\n",
            "tcost icost 0.0202484130859375 0.38743120431900024\n",
            "tcost icost 0.0202484130859375 0.3890754282474518\n",
            "search 0.409423828125\n",
            "tcost icost 0.01537322998046875 0.38864442706108093\n",
            "tcost icost 0.0119781494140625 0.3937319815158844\n",
            "tcost icost 0.0119781494140625 0.39406818151474\n",
            "search 0.406005859375\n",
            "tcost icost 0.01387786865234375 0.391200989484787\n",
            "tcost icost 0.01654052734375 0.3924018144607544\n",
            "tcost icost 0.01654052734375 0.3895193934440613\n",
            "search 0.406005859375\n",
            "tcost icost 0.01480865478515625 0.38830527663230896\n",
            "tcost icost 0.01561737060546875 0.3883329927921295\n",
            "tcost icost 0.01561737060546875 0.3887816071510315\n",
            "search 0.404296875\n",
            "tcost icost 0.0211334228515625 0.3884199261665344\n",
            "tcost icost 0.01259613037109375 0.3963678479194641\n",
            "tcost icost 0.01259613037109375 0.39746102690696716\n",
            "search 0.41015625\n",
            "tcost icost 0.0163116455078125 0.3932898938655853\n",
            "tcost icost 0.0154266357421875 0.39379462599754333\n",
            "tcost icost 0.0154266357421875 0.3919118344783783\n",
            "search 0.4072265625\n",
            "tcost icost 0.01323699951171875 0.3935997784137726\n",
            "tcost icost 0.0186309814453125 0.38881969451904297\n",
            "tcost icost 0.0186309814453125 0.3908856213092804\n",
            "search 0.409423828125\n",
            "tcost icost 0.0169830322265625 0.3913302421569824\n",
            "tcost icost 0.01314544677734375 0.3985864520072937\n",
            "tcost icost 0.01314544677734375 0.3964976370334625\n",
            "search 0.40966796875\n",
            "tcost icost 0.0155181884765625 0.39627063274383545\n",
            "tcost icost 0.024932861328125 0.3906272351741791\n",
            "tcost icost 0.024932861328125 0.39541757106781006\n",
            "search 0.42041015625\n",
            "tcost icost 0.018096923828125 0.392551451921463\n",
            "tcost icost 0.0131988525390625 0.39821502566337585\n",
            "tcost icost 0.0131988525390625 0.39821240305900574\n",
            "search 0.411376953125\n",
            "tcost icost 0.022552490234375 0.3919602334499359\n",
            "tcost icost 0.0189971923828125 0.39623144268989563\n",
            "tcost icost 0.0189971923828125 0.3934248387813568\n",
            "search 0.412353515625\n",
            "tcost icost 0.01546478271484375 0.39434710144996643\n",
            "tcost icost 0.0201568603515625 0.39026010036468506\n",
            "tcost icost 0.0201568603515625 0.3908022344112396\n",
            "search 0.4111328125\n",
            "tcost icost 0.01485443115234375 0.3925561308860779\n",
            "tcost icost 0.01220703125 0.40011516213417053\n",
            "tcost icost 0.01220703125 0.397809237241745\n",
            "search 0.409912109375\n",
            "tcost icost 0.01500701904296875 0.3942858874797821\n",
            "tcost icost 0.01357269287109375 0.3986787796020508\n",
            "tcost icost 0.01357269287109375 0.39851388335227966\n",
            "search 0.412109375\n",
            "tcost icost 0.01409149169921875 0.39501383900642395\n",
            "tcost icost 0.021087646484375 0.39269953966140747\n",
            "tcost icost 0.021087646484375 0.3953758478164673\n",
            "search 0.416259765625\n",
            "tcost icost 0.0266571044921875 0.3909228444099426\n",
            "tcost icost 0.018768310546875 0.39864426851272583\n",
            "tcost icost 0.018768310546875 0.39264562726020813\n",
            "search 0.411376953125\n",
            "tcost icost 0.022003173828125 0.3922857344150543\n",
            "tcost icost 0.0139312744140625 0.3991750180721283\n",
            "tcost icost 0.0139312744140625 0.39635714888572693\n",
            "search 0.41015625\n",
            "tcost icost 0.0181884765625 0.3967602252960205\n",
            "tcost icost 0.014495849609375 0.4010120630264282\n",
            "tcost icost 0.014495849609375 0.40114831924438477\n",
            "search 0.41552734375\n",
            "tcost icost 0.01482391357421875 0.3933805227279663\n",
            "tcost icost 0.0126495361328125 0.4010271728038788\n",
            "tcost icost 0.0126495361328125 0.3990177512168884\n",
            "search 0.41162109375\n",
            "tcost icost 0.017547607421875 0.3945225477218628\n",
            "tcost icost 0.01629638671875 0.3964318633079529\n",
            "tcost icost 0.01629638671875 0.39494451880455017\n",
            "search 0.411376953125\n",
            "tcost icost 0.0306243896484375 0.3940954804420471\n",
            "tcost icost 0.0147705078125 0.40148770809173584\n",
            "tcost icost 0.0147705078125 0.3983723819255829\n",
            "search 0.4130859375\n",
            "tcost icost 0.0173797607421875 0.3981778621673584\n",
            "tcost icost 0.013458251953125 0.40224504470825195\n",
            "tcost icost 0.013458251953125 0.39976274967193604\n",
            "search 0.4130859375\n",
            "tcost icost 0.026153564453125 0.3972116708755493\n",
            "tcost icost 0.0136566162109375 0.40297746658325195\n",
            "tcost icost 0.0136566162109375 0.3993237018585205\n",
            "search 0.4130859375\n",
            "tcost icost 0.0238037109375 0.3983657658100128\n",
            "tcost icost 0.0148162841796875 0.4008365869522095\n",
            "tcost icost 0.0148162841796875 0.39907366037368774\n",
            "search 0.4140625\n",
            "tcost icost 0.019775390625 0.39813661575317383\n",
            "tcost icost 0.0131683349609375 0.4045850932598114\n",
            "tcost icost 0.0131683349609375 0.40213915705680847\n",
            "search 0.415283203125\n",
            "tcost icost 0.0189208984375 0.4012332558631897\n",
            "tcost icost 0.013397216796875 0.40530750155448914\n",
            "tcost icost 0.013397216796875 0.40529000759124756\n",
            "search 0.418701171875\n",
            "tcost icost 0.02117919921875 0.4042900800704956\n",
            "tcost icost 0.0137939453125 0.40590882301330566\n",
            "tcost icost 0.0137939453125 0.4081551134586334\n",
            "search 0.421875\n",
            "tcost icost 0.024169921875 0.4046841263771057\n",
            "tcost icost 0.0158233642578125 0.4084770083427429\n",
            "tcost icost 0.0158233642578125 0.4060126543045044\n",
            "search 0.421875\n",
            "tcost icost 0.01506805419921875 0.40438181161880493\n",
            "tcost icost 0.01300811767578125 0.4072969853878021\n",
            "tcost icost 0.01300811767578125 0.40779513120651245\n",
            "search 0.420654296875\n",
            "tcost icost 0.0115966796875 0.404845654964447\n",
            "tcost icost 0.013031005859375 0.40324047207832336\n",
            "tcost icost 0.013031005859375 0.4036446809768677\n",
            "search 0.41650390625\n",
            "tcost icost 0.0174560546875 0.40854236483573914\n",
            "tcost icost 0.022064208984375 0.40817975997924805\n",
            "tcost icost 0.022064208984375 0.40697911381721497\n",
            "search 0.428955078125\n",
            "tcost icost 0.0156707763671875 0.4111534655094147\n",
            "tcost icost 0.0219268798828125 0.40302222967147827\n",
            "tcost icost 0.0219268798828125 0.4024859368801117\n",
            "search 0.424560546875\n",
            "tcost icost 0.014068603515625 0.40438684821128845\n",
            "tcost icost 0.0163726806640625 0.40181973576545715\n",
            "tcost icost 0.0163726806640625 0.40361031889915466\n",
            "search 0.419921875\n",
            "tcost icost 0.01177978515625 0.4093434810638428\n",
            "tcost icost 0.0149078369140625 0.4058922529220581\n",
            "tcost icost 0.0149078369140625 0.40525540709495544\n",
            "search 0.420166015625\n",
            "ded\n",
            "time\n",
            "29 #### train ####\n",
            "repr, std, cov, conv, closs 0.038466427475214005 0.333740234375 0.2771410048007965 0.055798422545194626 0.014948442578315735\n",
            "57.423871806136994 7.640541134790805 1.0\n",
            "repr, std, cov, conv, closs 0.03947566822171211 0.33251953125 0.27670687437057495 0.056040894240140915 0.015966692939400673\n",
            "57.76927754439001 7.6864991426420435 1.0\n",
            "repr, std, cov, conv, closs 0.05233405530452728 0.327392578125 0.28999876976013184 0.05559363216161728 0.030051395297050476\n",
            "57.653912066345264 7.579690950843743 1.0\n",
            "repr, std, cov, conv, closs 0.049305375665426254 0.322998046875 0.3609405755996704 0.06676924228668213 0.02156335487961769\n",
            "57.30919610473144 7.496812449760183 1.0\n",
            "repr, std, cov, conv, closs 0.041969411075115204 0.323974609375 0.3275294005870819 0.06284819543361664 0.01565452665090561\n",
            "56.062777744437504 7.282632571776986 1.0\n",
            "repr, std, cov, conv, closs 0.04145583510398865 0.3251953125 0.3154817223548889 0.06594832986593246 0.02220655046403408\n",
            "55.56072634705688 7.159935039106014 1.0\n",
            "repr, std, cov, conv, closs 0.05543459951877594 0.3203125 0.40407079458236694 0.07302896678447723 0.024990368634462357\n",
            "54.46109449876867 6.941489645806252 1.0\n",
            "repr, std, cov, conv, closs 0.041874125599861145 0.322021484375 0.3274407386779785 0.07544147968292236 0.0308917798101902\n",
            "53.973386438339965 6.838195580824219 1.0\n",
            "repr, std, cov, conv, closs 0.05234936624765396 0.324462890625 0.33975541591644287 0.06012018769979477 0.0160643570125103\n",
            "53.650676545102584 6.676112685591701 1.0\n",
            "repr, std, cov, conv, closs 0.04205527901649475 0.32568359375 0.3486916422843933 0.06364671885967255 0.016674213111400604\n",
            "53.650676545102584 6.669443242349352 1.0\n",
            "repr, std, cov, conv, closs 0.04298825562000275 0.32958984375 0.32107463479042053 0.06604930758476257 0.00038949644658714533\n",
            "54.352335475482235 6.702857219721306 1.0\n",
            "repr, std, cov, conv, closs 0.03959781304001808 0.330810546875 0.28346312046051025 0.06395573914051056 0.014473567716777325\n",
            "54.62464122000954 6.804106936994782 1.0\n",
            "repr, std, cov, conv, closs 0.032914940267801285 0.33837890625 0.28052425384521484 0.0635933130979538 0.010639924556016922\n",
            "55.449771354576384 7.011217743736587 1.0\n",
            "repr, std, cov, conv, closs 0.045385174453258514 0.337158203125 0.2333976924419403 0.0644875168800354 0.015224638395011425\n",
            "56.062777744437504 7.138498122106832 1.0\n",
            "repr, std, cov, conv, closs 0.046458806842565536 0.334228515625 0.24983787536621094 0.08085410296916962 0.015452447347342968\n",
            "56.73924358230845 7.363143278898984 1.0\n",
            "repr, std, cov, conv, closs 0.04541816562414169 0.33544921875 0.26863613724708557 0.07011272758245468 0.00019646402506623417\n",
            "57.13761179936037 7.481841285348203 1.0\n",
            "repr, std, cov, conv, closs 0.04371538758277893 0.3330078125 0.2901577949523926 0.0618644654750824 0.020372778177261353\n",
            "57.13761179936037 7.610055223119162 1.0\n",
            "repr, std, cov, conv, closs 0.05778367444872856 0.330078125 0.31413519382476807 0.0588088184595108 0.0004246005555614829\n",
            "57.08053126809229 7.640541134790805 1.0\n",
            "repr, std, cov, conv, closs 0.037828389555215836 0.32861328125 0.3749591112136841 0.06306900084018707 0.05781244486570358\n",
            "56.343652821845254 7.504309262209943 1.0\n",
            "repr, std, cov, conv, closs 0.04253200441598892 0.332275390625 0.31250426173210144 0.06016213446855545 0.03452644869685173\n",
            "56.118840522181934 7.385254805528658 1.0\n",
            "repr, std, cov, conv, closs 0.05379801243543625 0.322509765625 0.3555344343185425 0.06519730389118195 0.019858412444591522\n",
            "55.78330283910163 7.174262069119264 1.0\n",
            "repr, std, cov, conv, closs 0.04595215618610382 0.32373046875 0.3577454090118408 0.0626865029335022 0.015999816358089447\n",
            "55.7275752638378 7.074571697095573 1.0\n",
            "repr, std, cov, conv, closs 0.04386918991804123 0.326416015625 0.32242971658706665 0.062057703733444214 0.01540603581815958\n",
            "54.73394512709077 6.906886077454805 1.0\n",
            "repr, std, cov, conv, closs 0.04321541637182236 0.3251953125 0.3218126893043518 0.06177627295255661 0.0003104759380221367\n",
            "54.40668781095771 6.824539676930682 1.0\n",
            "repr, std, cov, conv, closs 0.04184165596961975 0.326171875 0.3091692328453064 0.058581724762916565 0.00023691933893132955\n",
            "54.13546857178767 6.722985906654984 1.0\n",
            "repr, std, cov, conv, closs 0.04589574411511421 0.32861328125 0.3148902654647827 0.05734734982252121 0.0016037593595683575\n",
            "54.51555559326743 6.709560076941027 1.0\n",
            "repr, std, cov, conv, closs 0.04385332018136978 0.3291015625 0.3042728006839752 0.056313008069992065 0.011259949766099453\n",
            "54.95320953026038 6.7634248014441125 1.0\n",
            "repr, std, cov, conv, closs 0.03989563137292862 0.331298828125 0.25826090574264526 0.06474914401769638 0.02594936080276966\n",
            "55.008162739790635 6.831364216607612 1.0\n",
            "repr, std, cov, conv, closs 0.03693719953298569 0.331787109375 0.28294751048088074 0.056142158806324005 0.015999173745512962\n",
            "55.17335230750636 6.962334946154095 1.0\n",
            "repr, std, cov, conv, closs 0.030375724658370018 0.33447265625 0.2471417933702469 0.06770750880241394 0.02560495026409626\n",
            "55.11823407343294 7.053390358794724 1.0\n",
            "repr, std, cov, conv, closs 0.03598549962043762 0.330322265625 0.3115161657333374 0.04970850050449371 0.0005920643452554941\n",
            "55.95082015331074 7.174262069119264 1.0\n",
            "repr, std, cov, conv, closs 0.039021000266075134 0.336181640625 0.2735431492328644 0.06309972703456879 0.002677932847291231\n",
            "56.062777744437504 7.304502324672662 1.0\n",
            "repr, std, cov, conv, closs 0.031682707369327545 0.337890625 0.2518002986907959 0.057945773005485535 0.0019612987525761127\n",
            "56.85277880871663 7.5118135714721515 1.0\n",
            "repr, std, cov, conv, closs 0.048278652131557465 0.33544921875 0.2547282874584198 0.061261288821697235 0.0006822954164817929\n",
            "57.08053126809229 7.6024527703488145 1.0\n",
            "repr, std, cov, conv, closs 0.04510435461997986 0.333251953125 0.24040432274341583 0.07031062990427017 0.0580255426466465\n",
            "57.02350776033196 7.748206788741605 1.0\n",
            "repr, std, cov, conv, closs 0.04327746853232384 0.3291015625 0.30191919207572937 0.06429348140954971 0.0005810436559841037\n",
            "57.02350776033196 7.725008580250108 1.0\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "for i in range(10):\n",
        "    # # buffer=[]\n",
        "    # print(\"#### simulate ####\")\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n",
        "\n",
        "    # state = buffer[7][80][0]\n",
        "    # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    # out= agent.deconv(sx_).squeeze(0)\n",
        "    # # print(out.shape)\n",
        "    # imshow(state.detach().cpu())\n",
        "    # imshow(out.detach().cpu())\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "    c_loader = make_weighted(buffer)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    # train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8zxYU9jpE8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "faec43a5-432f-4e98-a491-885e2b331c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*4 -2\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*3 -1.5\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "4ad29030-4c15-4a86-902d-ecce152091f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240823_103908-3o415bps</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/3o415bps' target=\"_blank\">frosty-armadillo-21</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/3o415bps' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/3o415bps</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(\n",
        "    project=\"procgen\",\n",
        "    config={\n",
        "        \"model\": \"res18\",\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.cuda.amp.autocast():\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.cuda.amp.autocast():\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjm2kV3H7ZVR",
        "outputId": "d4040132-28f1-4347-8028-2e951476da85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6872065\n"
          ]
        }
      ],
      "source": [
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad))\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.cuda.amp.autocast(): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ],
      "metadata": {
        "id": "gJ3X_hQelW2x",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi4ODp-XlZoU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "QYbOgNoZn6JL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kcajtpjr7Io",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.cuda.amp.autocast(): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wUhKd009Qvk3"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}