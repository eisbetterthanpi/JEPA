{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "6c1fc2b9-a369-4661-eff2-b79573940d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -qq procgen\n",
        "# !pip install -qq procgen faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEY9MmwZhA8a",
        "outputId": "0ce2a9ed-129e-4f94-e46f-a0df50df4d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1278976\n",
            "torch.Size([4, 256])\n",
            "1278979\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278976\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278979\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "conv = Conv().to(device)\n",
        "print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = conv(input)\n",
        "print(out.shape)\n",
        "\n",
        "deconv = Deconv(256).to(device)\n",
        "print(sum(p.numel() for p in deconv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,256), device=device)\n",
        "out = deconv(input)\n",
        "print(out.shape)\n",
        "\n",
        "# print(conv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuA25qQknUAX",
        "outputId": "23603762-43a8-4373-b8d1-7b0a04120610",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2ce37b725f67>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model) # pixel\n",
        "        # self.enc = ConvEnc(d_model) #\n",
        "        # self.enc = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.enc.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "        # self.pred = nn.Sequential(\n",
        "        #     nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=3e3, h0=None): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95))\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        for i in range(5): # 10\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sy_ = self.pred(sxaz)\n",
        "                sy_, _ = self.pred(sxaz, h0)\n",
        "                loss = lossfn(sy_, sy)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"argm\",i,loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TCost\n",
        "class TCost(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=256): # in_dim=(1+self.jepa.pred.num_layers)*d_model\n",
        "        super().__init__()\n",
        "        self.tc = torch.tensor([-1., 0.], device=device).T\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(in_dim, 2), nn.Softmax(),\n",
        "            nn.Linear(in_dim, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 2), nn.Softmax(),\n",
        "            )\n",
        "        # self.update_loss_weight(train_data)\n",
        "\n",
        "    def update_loss_weight(self, train_data):\n",
        "        a = len(train_data.buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "        # self.data = [step for episode in buffer for step in episode]\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tcost(x)@self.tc\n",
        "\n",
        "    def loss(self, x, y):\n",
        "        out = self.tcost(x)\n",
        "        # print(\"ctost loss\", out, y)\n",
        "        y = torch.where(y < -0.5, 0, 1)\n",
        "        return self.loss_fn(out, y)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AfjFbveH64Io"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkI44ygzfxu",
        "outputId": "a5b3e078-4ee5-44ea-b4b0-bb855c58f6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2727983\n",
            "1278976\n",
            "397824\n",
            "197634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-2b5c5daed39c>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        # self.tcost = nn.Sequential( # trained cost\n",
        "        #     # nn.Linear((1+self.jepa.pred.num_layers)*d_model, 1),\n",
        "        #     nn.Linear((1+self.jepa.pred.num_layers)*d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, 1),\n",
        "        #     )\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=2. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        # 0.0083 0.06 1.0 = 1, 7, 120.5\n",
        "        self.sim_coeff, self.std_coeff, self.cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # e = d_model**-0.5\n",
        "        # self.h0 = torch.empty((self.jepa.pred.num_layers, 1, d_model), device=device).uniform_(-e, e) # [num_layers, batch, d_model]\n",
        "        # self.h0 = torch.normal(mean=0, std=e, size=(self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # torch.nn.init.xavier_uniform_(self.h0)\n",
        "        # torch.nn.init.kaiming_normal_(self.h0)\n",
        "\n",
        "        # self.lx, self.lz = torch.empty(1,0,dim_a), torch.empty(1,0,dim_z)\n",
        "        self.lx, self.lz = None, None\n",
        "\n",
        "    def forward(self, state, k=1): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.h0=lh0[k].unsqueeze(1) # [num_layers, 1, d_model]\n",
        "        # self.lx, self.lz = lx[:,k:], lz[:,k:] # [batch, T, dim_a], [batch, T, dim_z]\n",
        "        self.lx, self.lz = lx[k:], lz[k:] # [T, dim_a], [T, dim_z]\n",
        "        return act\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 16\n",
        "        lr = 1e-1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                # x[:,:self.lx.shape[1]], z[:,:self.lz.shape[1]] = self.lx[:,:T], self.lz[:,:T]\n",
        "                x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].repeat(batch,1,1), self.lz[:T].repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            # print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            # print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i, loss.squeeze().data)\n",
        "            # print(x.shape,torch.argmax(-dist,dim=-1).shape,z.shape,loss.shape) # [16, 6, 3], [16, 6], [16, 6, 1], [16, 1]\n",
        "            # print(i, torch.cat([x,torch.argmax(-dist,dim=-1),z,loss],dim=-1).squeeze().data)\n",
        "            # print(i, torch.cat([x[0],torch.argmax(-dist,dim=-1)[0].unsqueeze(-1),z[0]],dim=-1).squeeze().data)\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, t, dim_a], [batch, t, dim_z]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                # tcost = -self.tcost(sx)\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # cost += tcost + icost\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        # trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            # loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0)\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    print(\"norm\", torch.norm(sy, dim=-1))\n",
        "                    # imshow(state[0])\n",
        "                    # print(\"norm\", torch.norm(sy[0]-sy_[0], dim=-1))\n",
        "                    # # if torch.norm(sy[0]-sy_[0], dim=-1) > 1:\n",
        "                    # print(i, reward[0])\n",
        "                    # print(sy)\n",
        "                    # print(sy_)\n",
        "                    # print(sy[0]-sy_[0])\n",
        "\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # # balance jepa coeffs\n",
        "                    # decay=0.99\n",
        "                    # sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    # step=0.001\n",
        "                    # if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    # if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    # if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    # self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    # self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    # reward_ = self.tcost(syh0).squeeze(-1)\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "\n",
        "                    # try: st, r = next(trainiter)\n",
        "                    # except StopIteration:\n",
        "                    #     st, r = next(trainiter)\n",
        "                    #     trainiter = iter(c_loader)\n",
        "                    # st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    # # _, st = self.get(st, world_state=world_zero)\n",
        "                    # # print(\"stt\",st.shape)\n",
        "                    # # stt = self.tcost(self.jepa.enc(st.unsqueeze(1))).squeeze(-1)\n",
        "                    # # stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    # h00 = torch.randn((self.jepa.pred.num_layers, batch_size, self.d_model), device=device)\n",
        "                    # syy = self.jepa.enc(st) # [batch_size, d_model]\n",
        "                    # syh0 = torch.cat([syy,h00.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    # stt = self.tcost(syh0).squeeze(-1)\n",
        "                    # clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossl #+ clossb\n",
        "\n",
        "                    # loss = loss + jloss + closs\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    # print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    # loss=0\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_b7ZSW6IF1-",
        "outputId": "e9a8e867-7cff-48c6-93e7-1a6228ff1256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB\n",
            "From (redirected): https://drive.google.com/uc?id=1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB&confirm=t&uuid=69494701-b44e-4c7e-878c-99a5565e8e47\n",
            "To: /content/buffergo.pkl\n",
            "100% 786M/786M [00:09<00:00, 81.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "# !gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3 convenc4\n",
        "# !gdown 1bGWBbcKUgHESkbD3NfYt1WWikScVSFOj -O agentoptim.pkl # M1\n",
        "# !gdown 1zoZ52jctM0jed6TgD7kAwrtnuDMeA5II -O agentoptim.pkl # T4\n",
        "# !gdown 1XBDhD2efIFW9lnewGRLrb362w47a8b1q -O agentoptim.pkl # B2\n",
        "# !gdown 1UDgNtFsWGAhvqR9lwA0QbMLhUtmip4ne -O agentoptim.pkl # M1 agentoptimgru3tcost1\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# agent.load_state_dict(modelsd, strict=False)\n",
        "# optim.load_state_dict(optimsd)\n",
        "\n",
        "import pickle\n",
        "# !gdown 19VQp7UjXqH8kJjEPABOTHDV8reg8r7Zn -O buffer512down.pkl # B\n",
        "# with open('buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1HRwU4u7Y6YjQWmC8xlKrDe4YGcNUWxvQ -O buffer512.pkl # B\n",
        "# with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "!gdown 1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB -O buffergo.pkl # S3\n",
        "with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "25f49b1c-9205-4dce-a54e-4f8044a6ade2",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-24614322ca12>:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "def save(folder, name='agent.pth'):\n",
        "    torch.save(agent.state_dict(), folder+name)\n",
        "    # agent.mem.save(file=folder+name)\n",
        "    with open(folder+'buffer.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "def load(folder, name='agent.pth'):\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=torch.device(device)), strict=False)\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=device), strict=False)\n",
        "    # torch.load(folder+name, map_location=torch.device('cpu'))\n",
        "    # agent.mem.load(file=folder+name)\n",
        "    with open(folder+'buffer512.pkl', 'rb') as f: return pickle.load(f)\n",
        "\n",
        "# save(folder)\n",
        "# save(folder, name='agent_jepa753333256.pth')\n",
        "# buffer = load(folder)\n",
        "# save('/content/')\n",
        "# buffer = load('/content/')\n",
        "\n",
        "# name='agent.pth'\n",
        "# print(folder+name)\n",
        "# torch.load(folder+name, map_location='o')\n",
        "# with open(folder+'buffer512down.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "# with open(folder+'buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open('buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open(folder+'buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptimgru3tcost1.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "agent.load_state_dict(modelsd, strict=False)\n",
        "optim.load_state_dict(optimsd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG4Wn3c8IN4V"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = buffer[7][80][0]\n",
        "state = transform(state).unsqueeze(0).to(device)#[0]\n",
        "act = agent(state).cpu()[:1].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# # torch.save(checkpoint, folder+'agentoptimgru3tcost1.pkl')\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "# # torch.save(checkpoint, 'agentoptim.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NVcknabHMxH6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.buffer = self.process(buffer)\n",
        "        self.data = [step for episode in self.buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def process(self, buffer):\n",
        "        cleaned = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "        cleaned = [episode[-random.randint(20, 80):] for episode in cleaned]\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 25 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 64 #512\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1e3fpbtNOiz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2aa87a-8a33-4903-eac0-f5d167f327ea",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1., -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.])\n",
            "tensor([ 0., -1.,  0., -1., -1., -1., -1., -1., -1.,  0.])\n",
            "tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0., -1., -1., -1.])\n",
            "tensor([-1.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "tensor([ 0., -1.,  0.,  0.,  0.,  0., -1.,  0., -1., -1.])\n",
            "tensor([ 0., -1.,  0.,  0.])\n",
            "tensor([-0.4765, -0.4761, -0.4856, -0.4728, -0.4715, -0.4804, -0.4725, -0.4727,\n",
            "        -0.4802, -0.4731])\n",
            "tensor([-0.4886, -0.4807, -0.4787, -0.4822, -0.4734, -0.4751, -0.4791, -0.4765,\n",
            "        -0.4840, -0.4792])\n",
            "tensor([-0.4808, -0.4770, -0.4779, -0.4803, -0.4787, -0.4807, -0.4732, -0.4756,\n",
            "        -0.4774, -0.4760])\n",
            "tensor([-0.4778, -0.4775, -0.4756, -0.4811, -0.4784, -0.4777, -0.4804, -0.4759,\n",
            "        -0.4781, -0.4782])\n",
            "tensor([-0.4800, -0.4714, -0.4727, -0.4722, -0.4697, -0.4779, -0.4813, -0.4750,\n",
            "        -0.4773, -0.4808])\n",
            "tensor([-0.4817, -0.4746, -0.4707, -0.4741, -0.4744, -0.4749, -0.4776, -0.4731,\n",
            "        -0.4736, -0.4834])\n",
            "tensor([-0.4729, -0.4703, -0.4769, -0.4753])\n",
            "tensor(0.2442)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "ctrain_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    ctrain_data=list(zip(state,reward))\n",
        "    ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "trainiter = iter(c_loader)\n",
        "images, labels = next(trainiter)\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# print(labels)\n",
        "for x in range((len(labels)//10)+1):\n",
        "    print(labels[10*x:10*x+10])\n",
        "\n",
        "# # try:\n",
        "with torch.no_grad():\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "    # _, world_state = agent.get(images.to(device))\n",
        "    # pred = agent.tcost(agent.jepa.enc(world_state.unsqueeze(1))).squeeze(-1).cpu()\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device)\n",
        "    torch.nn.init.xavier_normal_(h0)\n",
        "    sy = agent.jepa.enc(images.to(device)) # [batch_size, d_model]\n",
        "    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "    pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "    # print(pred)\n",
        "    for x in range((len(pred)//10)+1):\n",
        "        print(pred[10*x:10*x+10])\n",
        "    # print((labels==pred).sum())\n",
        "# except: pass\n",
        "print(F.mse_loss(labels, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "cellView": "form",
        "id": "OksdjCeJYpYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "000e8dae-f74f-46a0-a828-f45badbf607a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-2b5c5daed39c>:191: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(2.8746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "0 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[ 0.0658,  0.0513,  0.0054,  ..., -0.0189, -0.0091,  0.0112],\n",
            "        [ 0.0562,  0.0585,  0.0097,  ..., -0.0164, -0.0098,  0.0027],\n",
            "        [ 0.0640,  0.0537,  0.0093,  ..., -0.0207, -0.0174,  0.0033],\n",
            "        ...,\n",
            "        [ 0.0611,  0.0506,  0.0127,  ..., -0.0170, -0.0149,  0.0009],\n",
            "        [ 0.0663,  0.0381, -0.0003,  ..., -0.0132, -0.0126,  0.0170],\n",
            "        [ 0.0643,  0.0452,  0.0226,  ..., -0.0229, -0.0167,  0.0017]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-6.5776e-02, -5.1272e-02, -5.3662e-03, -5.2323e-03,  3.2896e-02,\n",
            "        -4.0771e-02, -7.4604e-02,  3.5754e-02,  2.7267e-02, -1.6688e-02,\n",
            "        -2.1099e-02,  6.7518e-02, -3.7877e-02, -7.6879e-03, -1.4862e-02,\n",
            "        -2.5097e-02, -5.6777e-02,  5.5291e-02, -6.8069e-02,  2.8876e-02,\n",
            "         1.7907e-02, -1.6793e-02,  2.1493e-02, -3.4346e-02, -2.7345e-02,\n",
            "        -1.2247e-01,  7.6262e-02, -4.4530e-02, -5.1411e-02, -4.1773e-03,\n",
            "        -4.9992e-03, -7.2899e-02, -3.2064e-02, -1.5828e-02,  4.0909e-02,\n",
            "        -4.9852e-02, -4.6224e-02, -1.6499e+00,  1.2608e-02,  9.9828e-02,\n",
            "        -3.0614e-02, -2.7344e-04, -2.6611e-02,  3.5432e-02, -7.4262e-02,\n",
            "         8.2483e-02, -5.0296e-02,  2.9592e-03, -7.4720e-02, -2.6459e-02,\n",
            "        -4.5152e-02, -9.8911e-02, -5.6612e-02,  5.4093e-02,  2.0311e-03,\n",
            "         5.4198e-03,  2.2510e-02,  1.0043e-01,  2.4456e-02, -1.1587e-02,\n",
            "        -3.5044e-02,  7.1501e-02,  1.0241e-01, -1.4985e+00,  2.6989e-02,\n",
            "         5.3318e-02, -6.2644e-02,  7.9789e-02,  9.0053e-02,  4.1180e-02,\n",
            "         8.1390e-02, -3.1561e-02, -7.5736e-02,  2.9873e-01, -5.2086e-02,\n",
            "         5.1372e-02, -4.6423e-02,  3.4411e-02, -3.6543e-02,  2.8673e-02,\n",
            "        -1.7322e-02, -1.2778e-02, -1.0536e-02,  6.8113e-02, -5.0754e-02,\n",
            "         1.0219e-01, -8.1541e-02,  9.0152e-02,  2.0941e-02,  1.1065e-02,\n",
            "         2.4959e-03,  5.1419e-03, -4.2550e-02,  5.7315e-02,  4.3565e-02,\n",
            "         4.2920e-02,  7.6932e-02, -2.8655e-03, -2.0175e-02, -6.4325e-02,\n",
            "        -2.8255e-03,  5.8173e-02,  2.8825e-02,  1.6805e-01, -5.1471e-01,\n",
            "        -7.3410e-02,  2.3312e-02,  5.3172e-02,  4.9227e-02, -5.1568e-02,\n",
            "        -1.0111e-01,  3.5472e-02, -3.7349e-04, -6.1945e-02, -2.6380e-03,\n",
            "        -1.6296e-01, -3.8888e-02,  1.7941e-01, -1.7631e-02,  3.5174e-02,\n",
            "         2.1725e-02, -1.1636e-01,  8.7594e-02, -1.7309e-02, -7.1565e-02,\n",
            "        -2.7522e-03, -2.2901e-02, -2.9536e-02,  3.8625e-02,  8.0609e-02,\n",
            "         6.7303e-02,  1.4933e-01,  1.2310e-01,  8.0835e-02,  3.1440e-02,\n",
            "        -5.6562e-02, -3.1269e-02, -2.6769e-02, -1.3124e-03,  4.8230e-02,\n",
            "        -4.2184e-02,  9.2183e-02,  1.2587e-02,  3.8076e-02,  1.5126e-02,\n",
            "        -8.7899e-02, -6.5874e-02, -5.0573e-02, -3.2298e-02,  2.4200e-02,\n",
            "        -6.2259e-02, -4.7687e-03, -1.1180e-02,  3.4744e-02, -4.9826e-02,\n",
            "        -1.0635e-02,  1.2016e-01,  3.7523e-02,  1.1332e-01, -3.2296e-02,\n",
            "         3.4372e-02, -2.0970e-02,  4.7490e-02, -3.1864e-02,  6.1208e-02,\n",
            "         3.4669e-02, -5.5249e-02, -2.7105e-02, -1.3271e-01, -4.1538e-02,\n",
            "         5.6477e-02, -3.7828e-03, -8.8921e-02,  9.0660e-02,  2.9015e-02,\n",
            "        -7.3570e-02, -7.1696e-02, -1.0448e-03, -1.5840e-01,  7.6497e-02,\n",
            "        -8.4521e-02,  5.0418e-02,  8.7975e-02,  3.0026e-02, -4.6674e-02,\n",
            "         3.1920e-02,  3.7513e-04,  5.1341e-03, -1.1379e-02, -2.0167e-02,\n",
            "         1.8896e-02, -4.9125e-02,  1.6023e-01,  2.3128e-02,  5.3972e-03,\n",
            "        -1.2022e-01,  4.4296e-02, -2.0826e-02,  1.4719e-01,  4.6987e-02,\n",
            "         3.2060e-02, -6.0425e-03, -6.0510e-02,  6.3749e-02,  3.4755e-02,\n",
            "         3.2435e-02, -7.0034e-02, -8.2374e-04, -2.5173e-02,  8.3003e-02,\n",
            "        -3.8498e-02,  6.9561e-02,  1.6310e-03,  4.7090e-02,  2.9973e-02,\n",
            "        -4.3312e-02, -6.9811e-03, -5.6304e-02, -4.4687e-02,  6.3731e-03,\n",
            "         9.9216e-02, -1.4315e-02, -9.7506e-01, -7.5810e-03, -6.4351e-02,\n",
            "         3.6654e-02, -1.8462e-02, -8.5704e-05,  2.6805e-02,  8.8883e-02,\n",
            "        -4.1637e-02,  2.5068e-02, -5.0855e-03, -8.3587e-02, -1.4700e-02,\n",
            "        -1.1483e-01, -7.4966e-02, -6.5048e-02, -2.9974e-02, -1.0658e+00,\n",
            "        -3.3245e-02,  1.6280e-02, -2.8496e-02, -6.4698e-02,  1.9086e-02,\n",
            "         2.7143e-02, -6.9147e-02, -1.7169e-02, -2.5232e-03, -2.6001e-02,\n",
            "        -7.3489e-02, -5.1453e-02, -8.2680e-02,  1.8908e-02,  9.1006e-03,\n",
            "        -1.1194e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(3.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "1 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[ 5.7803e-02,  4.5633e-02,  1.6344e-02,  ..., -2.3286e-03,\n",
            "         -5.8321e-02, -8.7665e-03],\n",
            "        [ 4.5673e-02,  5.8494e-02,  2.4725e-02,  ...,  2.6427e-03,\n",
            "         -6.1614e-02, -2.1728e-02],\n",
            "        [ 6.1645e-02,  4.9686e-02,  2.6120e-02,  ..., -7.2977e-03,\n",
            "         -5.7957e-02, -1.5297e-02],\n",
            "        ...,\n",
            "        [ 5.7609e-02,  5.0219e-02,  3.1312e-02,  ..., -3.1490e-05,\n",
            "         -6.4075e-02, -2.5663e-02],\n",
            "        [ 5.5649e-02,  3.1364e-02,  2.4422e-03,  ...,  2.4324e-03,\n",
            "         -5.6696e-02, -1.0381e-04],\n",
            "        [ 6.3346e-02,  4.8387e-02,  4.1037e-02,  ..., -1.2944e-02,\n",
            "         -6.1123e-02, -2.5078e-02]], grad_fn=<AddBackward0>)\n",
            "tensor([-5.7803e-02, -4.5633e-02, -1.6344e-02,  1.0322e-01,  9.7413e-02,\n",
            "        -3.6676e-02, -6.9051e-02,  6.7532e-02, -1.1630e-02, -4.8505e-02,\n",
            "        -2.9753e-02,  1.5665e-01, -5.7002e-02, -8.3552e-03, -6.3327e-02,\n",
            "        -3.1614e-02, -1.6084e-01,  1.3488e-01, -9.4605e-02,  1.4771e-02,\n",
            "         5.1797e-02, -4.8116e-02, -1.2455e-02, -1.0612e-01, -1.1128e-02,\n",
            "        -1.5759e-01,  9.5630e-02,  4.8087e-04, -1.2356e-01,  1.6426e-02,\n",
            "        -8.2066e-02, -1.0822e-01, -6.8010e-02, -5.4505e-02,  8.5814e-02,\n",
            "        -3.7324e-02, -3.2192e-02, -1.7814e+00,  1.5615e-02,  1.1693e-01,\n",
            "        -3.5801e-02, -2.3355e-02, -2.6260e-02,  4.4263e-02, -7.3984e-02,\n",
            "         1.5637e-01, -9.0324e-02, -3.0617e-02, -6.6421e-02, -8.9303e-02,\n",
            "         1.7433e-02, -1.3368e-01, -1.2292e-01,  1.4926e-01, -1.2760e-02,\n",
            "         2.6309e-02,  8.7763e-02,  1.6339e-01, -1.6589e-02,  3.6846e-02,\n",
            "        -5.9594e-03,  5.6154e-02,  4.9140e-02, -1.0643e+00,  4.1463e-02,\n",
            "         8.9285e-02, -8.9923e-02,  1.8695e-01,  7.1999e-02,  6.0701e-02,\n",
            "         8.7971e-02, -4.7043e-02, -5.8759e-02,  3.1010e-01, -8.8313e-02,\n",
            "         6.7254e-02, -1.0282e-01,  5.2619e-03, -6.9458e-03,  3.2028e-02,\n",
            "         2.5945e-02, -2.5657e-02,  2.4607e-02,  6.7777e-02, -1.4860e-03,\n",
            "         1.3433e-01, -8.8395e-02,  1.1220e-01,  2.5110e-02, -2.8977e-02,\n",
            "         3.1673e-02, -2.8173e-02, -5.5348e-02,  9.6282e-02,  6.8140e-02,\n",
            "         7.0492e-02,  4.3344e-02,  2.4140e-02, -6.1557e-02, -8.8659e-02,\n",
            "         1.5001e-02,  5.0648e-02,  1.7223e-02,  1.4529e-01, -2.5453e-01,\n",
            "        -8.7941e-02,  3.0361e-02,  3.6647e-03,  1.1312e-01, -8.8475e-02,\n",
            "        -8.5541e-02,  7.1298e-02, -7.3287e-03, -1.1022e-01, -9.6978e-02,\n",
            "        -3.3290e-01, -6.0396e-02,  3.6870e-01, -5.3680e-02,  5.0409e-03,\n",
            "         9.2129e-03, -1.2931e-01,  8.2267e-02,  8.7505e-03, -3.7024e-02,\n",
            "         4.4614e-02, -3.3520e-02,  1.9894e-02,  1.0053e-01,  1.3052e-01,\n",
            "         1.0047e-01,  1.6701e-01,  1.5882e-01,  1.6976e-01,  6.8636e-02,\n",
            "        -1.7023e-02, -7.1482e-02, -4.5713e-03, -7.3403e-02,  6.1105e-02,\n",
            "        -6.3077e-02,  1.6252e-01, -1.5683e-02,  1.1718e-01, -5.6804e-03,\n",
            "        -1.2081e-01, -1.1065e-01, -4.0079e-02,  2.5399e-03,  4.4430e-02,\n",
            "        -6.2176e-02, -1.2436e-02,  2.5696e-02,  5.3368e-02, -9.2502e-02,\n",
            "        -6.1938e-02,  1.6165e-01,  4.6311e-02,  8.8245e-02,  8.2835e-03,\n",
            "         3.2474e-02,  3.8425e-02,  8.5651e-02,  2.3557e-03,  6.4995e-02,\n",
            "         9.9185e-02, -2.1448e-02,  1.3284e-02, -1.6231e-01, -3.9310e-02,\n",
            "         1.4085e-01,  6.2295e-03, -1.2656e-01,  8.2220e-02,  5.0135e-02,\n",
            "        -6.7507e-02, -1.0172e-01,  9.2765e-02, -1.4321e-01,  1.1009e-01,\n",
            "        -7.2840e-02,  4.0409e-02,  1.3649e-01,  8.2989e-03, -3.6257e-02,\n",
            "         5.4648e-02, -2.2347e-02,  2.3821e-03,  3.5648e-02, -6.7834e-02,\n",
            "         4.4684e-02, -3.2967e-02,  2.5748e-01,  2.8862e-03,  4.3043e-02,\n",
            "        -6.1835e-02, -4.1020e-03, -2.3820e-02,  2.7078e-01,  6.1453e-02,\n",
            "         3.7502e-02, -3.9186e-02, -8.5012e-02,  1.2871e-01,  8.3740e-02,\n",
            "        -1.2051e-02,  1.6336e-03, -3.6471e-02,  1.7517e-02,  1.4373e-01,\n",
            "        -7.7687e-02,  8.3365e-02, -5.5681e-03,  2.8933e-02,  1.1055e-02,\n",
            "         2.1196e-02,  2.0431e-02, -7.1658e-02, -3.9270e-02, -2.1156e-02,\n",
            "         4.2397e-02,  1.3339e-02, -1.4901e+00, -4.1352e-02, -1.1202e-01,\n",
            "         5.3509e-02, -2.2672e-02, -2.4906e-02,  8.5345e-02,  1.6498e-01,\n",
            "        -1.1774e-01,  8.7030e-02,  4.4234e-02, -3.1290e-02, -6.4078e-02,\n",
            "        -1.7150e-01, -7.2495e-02, -1.0110e-01, -2.2981e-02, -1.1168e+00,\n",
            "        -6.0053e-02,  1.8253e-02, -2.6944e-03, -1.2273e-01, -1.4006e-02,\n",
            "         4.4303e-02, -7.4641e-02,  2.5551e-02,  3.6920e-02,  3.6043e-02,\n",
            "        -7.4302e-02,  5.2561e-02, -9.0444e-02,  2.3286e-03,  5.8321e-02,\n",
            "         8.7665e-03], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(3.4363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "2 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[ 0.0324,  0.0797, -0.0073,  ..., -0.0454, -0.0465,  0.0183],\n",
            "        [ 0.0215,  0.0985, -0.0033,  ..., -0.0427, -0.0311,  0.0105],\n",
            "        [ 0.0375,  0.0783,  0.0070,  ..., -0.0468, -0.0352,  0.0152],\n",
            "        ...,\n",
            "        [ 0.0292,  0.0907,  0.0008,  ..., -0.0400, -0.0318,  0.0015],\n",
            "        [ 0.0266,  0.0649, -0.0224,  ..., -0.0461, -0.0342,  0.0319],\n",
            "        [ 0.0312,  0.0765,  0.0147,  ..., -0.0415, -0.0427, -0.0125]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-3.2398e-02, -7.9681e-02,  7.3122e-03,  1.6554e-01,  1.3317e-01,\n",
            "        -1.4012e-02, -2.0736e-02,  7.7483e-02, -4.0481e-02, -2.6868e-02,\n",
            "        -5.0439e-02,  1.7179e-01, -2.5269e-02, -3.5458e-02, -1.0338e-01,\n",
            "         1.9665e-02, -2.2161e-01,  1.4371e-01, -9.2701e-02, -5.3470e-03,\n",
            "         3.8873e-02, -8.7074e-02, -3.0188e-02, -1.7652e-01,  1.2582e-02,\n",
            "        -1.4937e-01,  9.0695e-02,  3.1003e-02, -1.6797e-01,  8.0350e-02,\n",
            "        -1.5782e-01, -1.4533e-01, -7.2789e-02, -6.6643e-02,  1.2887e-01,\n",
            "        -1.5406e-02, -6.3151e-03, -2.0003e+00,  4.4840e-02,  1.2157e-01,\n",
            "        -2.0704e-02, -7.7885e-03, -4.1072e-02,  6.1614e-02, -7.8243e-02,\n",
            "         1.5534e-01, -9.8972e-02, -5.3846e-02, -6.6623e-02, -1.6227e-01,\n",
            "         6.4423e-02, -1.2554e-01, -1.7997e-01,  2.0539e-01,  3.8718e-03,\n",
            "         5.2550e-02,  1.0244e-01,  1.6554e-01, -1.6461e-03,  3.6818e-02,\n",
            "         1.0535e-02,  2.2109e-02,  1.2241e-02, -5.9343e-01,  3.1656e-02,\n",
            "         7.6360e-02, -3.8041e-02,  3.1320e-01,  9.9352e-03,  8.8830e-02,\n",
            "         2.6410e-02, -4.4664e-02, -4.3845e-02,  1.6345e-01, -6.3951e-02,\n",
            "         3.4946e-02, -9.0318e-02, -3.1113e-02,  4.9936e-02, -9.2761e-04,\n",
            "         4.2053e-02, -2.7932e-02,  2.4843e-02,  3.7429e-02,  4.1888e-02,\n",
            "         1.0142e-01, -7.2526e-02,  1.2324e-01, -2.0066e-02, -2.5875e-02,\n",
            "         7.0366e-02, -2.9621e-02, -9.5630e-02,  1.4831e-01,  2.0714e-02,\n",
            "         6.2462e-02,  7.4687e-02,  9.5652e-02, -1.2290e-01, -4.5385e-02,\n",
            "         5.6519e-02,  2.9106e-02, -7.0799e-03,  9.8558e-02,  4.5636e-02,\n",
            "        -7.9695e-02,  1.1461e-02, -1.4173e-02,  1.5370e-01, -1.0377e-01,\n",
            "        -4.7883e-02,  6.9374e-02, -4.7613e-02, -6.4365e-02, -1.5375e-01,\n",
            "        -4.7094e-01, -7.3301e-02,  4.9177e-01, -6.6757e-02, -1.1225e-02,\n",
            "        -5.7462e-02, -1.0398e-01, -8.8428e-03,  5.4224e-03,  2.4660e-02,\n",
            "         7.0748e-02, -1.8260e-02,  4.7176e-02,  1.5135e-01,  1.1532e-01,\n",
            "         8.9175e-02,  1.2828e-01,  1.4044e-01,  2.2415e-01,  5.4933e-02,\n",
            "         6.9528e-02, -3.3858e-02, -4.0192e-03, -1.3033e-01,  6.6161e-02,\n",
            "        -2.6791e-02,  1.4530e-01, -2.5766e-02,  1.9100e-01, -4.0097e-02,\n",
            "        -9.9834e-02, -1.2020e-01, -1.7890e-02, -6.1281e-03,  4.6515e-02,\n",
            "        -5.7618e-02, -2.8134e-02,  1.8301e-02,  6.8699e-02, -1.1840e-01,\n",
            "        -7.5898e-02,  1.2781e-01,  4.4069e-03,  4.4933e-02,  1.0115e-02,\n",
            "        -3.2858e-03,  1.1894e-01,  1.4162e-01,  1.1970e-02,  2.7233e-02,\n",
            "         1.1291e-01, -6.7307e-03,  6.1580e-02, -1.5595e-01, -6.9792e-03,\n",
            "         1.1839e-01,  4.9967e-02, -1.1126e-01,  5.6524e-02,  3.0422e-03,\n",
            "        -1.1046e-02, -1.0212e-01,  1.2193e-01, -9.2129e-02,  7.5762e-02,\n",
            "        -3.5659e-02,  2.7224e-02,  8.5103e-02, -1.1196e-03, -1.8360e-02,\n",
            "         3.5679e-02,  4.9627e-03, -5.5064e-02,  5.4694e-02, -9.5823e-02,\n",
            "         6.4950e-02,  5.9494e-03,  3.1022e-01, -1.5311e-02,  1.0095e-01,\n",
            "         8.5025e-02, -9.4164e-02, -2.1198e-02,  2.6826e-01,  2.6086e-02,\n",
            "         3.0266e-02,  1.0695e-02, -4.8390e-02,  1.8468e-01,  2.9112e-02,\n",
            "         1.1794e-02,  3.5636e-02, -8.4703e-02,  1.7256e-02,  1.5482e-01,\n",
            "        -1.5619e-01,  1.0758e-01, -4.7065e-02, -2.7935e-02, -1.0320e-02,\n",
            "         8.8552e-02,  3.5769e-02, -5.8285e-02, -2.5158e-02, -1.2482e-01,\n",
            "         3.2209e-02,  5.3920e-02, -1.9255e+00, -3.2413e-02, -9.5195e-02,\n",
            "         7.6253e-02, -1.6486e-02, -2.1689e-02,  1.2568e-01,  2.2285e-01,\n",
            "        -1.4071e-01,  1.1731e-01,  4.5967e-02,  1.9145e-02, -3.5709e-02,\n",
            "        -1.2099e-01, -1.6441e-02, -1.2131e-01, -1.2263e-02, -1.1174e+00,\n",
            "        -3.0559e-02,  2.3666e-02,  3.3398e-02, -1.0946e-01, -6.5677e-03,\n",
            "         2.1294e-02, -1.7530e-02,  5.7182e-02,  1.2547e-01,  1.0479e-01,\n",
            "        -4.0595e-02,  1.3758e-01, -5.4712e-02,  4.5353e-02,  4.6514e-02,\n",
            "        -1.8349e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(3.9909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "3 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[-0.0124,  0.1158, -0.0412,  ..., -0.0635,  0.0182,  0.0442],\n",
            "        [-0.0187,  0.1356, -0.0351,  ..., -0.0606,  0.0395,  0.0470],\n",
            "        [-0.0112,  0.1089, -0.0265,  ..., -0.0647,  0.0303,  0.0437],\n",
            "        ...,\n",
            "        [-0.0171,  0.1233, -0.0346,  ..., -0.0566,  0.0395,  0.0398],\n",
            "        [-0.0120,  0.0995, -0.0424,  ..., -0.0717,  0.0191,  0.0673],\n",
            "        [-0.0164,  0.1106, -0.0294,  ..., -0.0576,  0.0253,  0.0199]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 1.2381e-02, -1.1584e-01,  4.1177e-02,  2.0257e-01,  1.4377e-01,\n",
            "        -8.5136e-03,  2.6786e-02,  5.8446e-02, -5.4864e-02, -2.5997e-02,\n",
            "        -6.4221e-02,  1.5203e-01, -4.6598e-04, -7.0602e-02, -1.1023e-01,\n",
            "         9.3994e-02, -2.5388e-01,  1.1584e-01, -9.4568e-02, -9.3672e-03,\n",
            "         2.7561e-02, -1.4055e-01, -6.8703e-02, -2.5426e-01,  2.3602e-02,\n",
            "        -1.3614e-01,  9.6228e-02,  6.2914e-02, -2.1948e-01,  1.5481e-01,\n",
            "        -2.1129e-01, -1.7108e-01, -9.4584e-02, -3.0478e-02,  1.5039e-01,\n",
            "         5.0870e-02,  2.0323e-02, -2.2132e+00,  5.4679e-02,  1.3603e-01,\n",
            "        -1.3842e-02, -4.6056e-04, -4.5080e-02,  1.1707e-01, -9.4194e-02,\n",
            "         1.3189e-01, -9.0592e-02, -7.8266e-02, -7.8307e-02, -2.2628e-01,\n",
            "         6.4150e-02, -1.1585e-01, -2.5422e-01,  2.2514e-01, -1.7091e-02,\n",
            "         7.5140e-02,  8.8912e-02,  1.2742e-01,  5.5913e-02,  3.5576e-02,\n",
            "         9.7411e-03, -8.1983e-03,  4.0593e-04,  9.7752e-03,  3.9291e-02,\n",
            "         4.8104e-02, -1.2661e-02,  4.5816e-01,  2.8376e-03,  9.9166e-02,\n",
            "        -4.5829e-02, -2.9319e-02, -4.8009e-02,  1.7851e-01, -2.5817e-02,\n",
            "         3.6177e-02, -9.8397e-02, -1.8737e-02,  1.2958e-01, -4.2235e-02,\n",
            "         1.0781e-02, -1.1088e-02, -2.0444e-02,  4.4391e-03,  6.5125e-02,\n",
            "         4.6160e-02, -6.9677e-02,  1.4665e-01, -7.3722e-02, -7.8701e-03,\n",
            "         1.0374e-01, -1.6709e-02, -1.2488e-01,  1.9284e-01, -3.6481e-02,\n",
            "         4.6357e-02,  1.3674e-01,  1.9357e-01, -1.4922e-01,  1.8331e-03,\n",
            "         8.5055e-02,  2.0239e-02, -1.3916e-02,  7.4893e-02,  3.8423e-01,\n",
            "        -8.2682e-02,  2.6050e-02,  8.9894e-03,  1.6724e-01, -1.0362e-01,\n",
            "        -2.6670e-02,  4.6141e-02, -1.0225e-01,  2.7547e-03, -1.5809e-01,\n",
            "        -5.7031e-01, -8.3790e-02,  6.3084e-01, -6.4552e-02, -7.7270e-03,\n",
            "        -1.0524e-01, -8.5242e-02, -1.1342e-01, -4.5309e-03,  8.5634e-02,\n",
            "         1.2145e-01, -7.2610e-04,  5.7830e-02,  1.8407e-01,  7.2009e-02,\n",
            "         3.9982e-02,  7.5844e-02,  8.5252e-02,  2.4894e-01,  4.9181e-02,\n",
            "         1.5684e-01,  3.2662e-02, -2.6588e-02, -1.2832e-01,  6.7793e-02,\n",
            "        -3.2576e-03,  1.1749e-01, -6.0375e-03,  2.4249e-01, -4.8769e-02,\n",
            "        -5.3223e-02, -7.6796e-02, -2.9682e-03, -2.8341e-02,  1.9201e-02,\n",
            "        -5.9969e-02, -3.6290e-02, -9.7637e-04,  1.0097e-01, -1.5233e-01,\n",
            "        -7.2474e-02,  7.5248e-02, -2.9422e-02,  4.7044e-02, -9.7976e-03,\n",
            "        -4.5457e-02,  1.5901e-01,  2.1825e-01,  1.4538e-02, -1.9976e-03,\n",
            "         1.2756e-01, -3.4674e-03,  9.8199e-02, -1.1568e-01,  2.4295e-02,\n",
            "         5.7339e-02,  1.0504e-01, -1.0353e-01,  6.1051e-02, -8.3661e-02,\n",
            "         3.7829e-02, -9.6029e-02,  7.3422e-02, -4.1959e-02,  6.7906e-03,\n",
            "        -4.0773e-04,  3.5177e-02, -1.5041e-02, -4.7818e-02,  5.2561e-03,\n",
            "        -2.2641e-02,  1.8796e-02, -1.5776e-01,  5.1949e-02, -1.1438e-01,\n",
            "         7.6134e-02,  4.1297e-02,  3.6430e-01,  1.0888e-02,  1.2499e-01,\n",
            "         2.1798e-01, -1.7403e-01, -1.6744e-02,  2.3659e-01, -1.0927e-03,\n",
            "         4.0332e-02,  8.1238e-02,  5.4475e-03,  2.3118e-01, -2.3994e-02,\n",
            "         5.5673e-02,  3.2404e-02, -1.3781e-01,  1.3827e-03,  1.3071e-01,\n",
            "        -2.4098e-01,  1.2050e-01, -5.5677e-02, -8.8519e-02, -2.8305e-02,\n",
            "         1.1232e-01,  2.5126e-02, -2.5622e-02, -1.2012e-02, -2.8960e-01,\n",
            "         6.6014e-02,  5.2961e-02, -2.4449e+00, -6.2031e-03, -4.6172e-02,\n",
            "         1.0332e-01,  1.9155e-02, -2.0775e-02,  1.5160e-01,  2.5135e-01,\n",
            "        -1.3740e-01,  1.3979e-01,  1.6047e-02,  7.6404e-02,  1.3839e-02,\n",
            "        -6.5745e-03,  4.7200e-02, -1.6293e-01, -2.9417e-02, -1.1490e+00,\n",
            "         1.0083e-02, -1.0108e-02,  4.9589e-02, -4.3341e-02, -1.5132e-03,\n",
            "        -5.7703e-03,  2.8428e-02,  8.5806e-02,  1.9516e-01,  1.7703e-01,\n",
            "        -2.1989e-02,  1.5551e-01, -2.3418e-02,  6.3528e-02, -1.8162e-02,\n",
            "        -4.4154e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(4.4588, grad_fn=<LinalgVectorNormBackward0>)\n",
            "4 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[-0.0633,  0.1443, -0.0549,  ..., -0.0433,  0.0904,  0.0509],\n",
            "        [-0.0733,  0.1556, -0.0481,  ..., -0.0333,  0.1026,  0.0460],\n",
            "        [-0.0694,  0.1340, -0.0449,  ..., -0.0430,  0.0912,  0.0468],\n",
            "        ...,\n",
            "        [-0.0686,  0.1408, -0.0459,  ..., -0.0382,  0.0999,  0.0521],\n",
            "        [-0.0609,  0.1265, -0.0450,  ..., -0.0549,  0.0804,  0.0690],\n",
            "        [-0.0704,  0.1376, -0.0605,  ..., -0.0360,  0.0944,  0.0355]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 6.3342e-02, -1.4428e-01,  5.4911e-02,  2.2220e-01,  1.2305e-01,\n",
            "        -2.9636e-02,  4.0390e-02,  2.9331e-02, -7.4750e-02, -3.7123e-02,\n",
            "        -6.7978e-02,  1.1770e-01,  9.5722e-03, -1.0109e-01, -1.1812e-01,\n",
            "         1.5370e-01, -2.8286e-01,  9.8298e-02, -1.0494e-01, -9.2416e-03,\n",
            "        -3.5424e-04, -2.0265e-01, -1.3883e-01, -3.2320e-01,  1.8669e-02,\n",
            "        -1.1511e-01,  1.0801e-01,  1.0820e-01, -2.7009e-01,  2.1193e-01,\n",
            "        -2.3116e-01, -1.8543e-01, -1.3573e-01,  3.3881e-02,  1.7018e-01,\n",
            "         1.2620e-01,  4.2570e-02, -2.1659e+00,  3.9768e-02,  1.3289e-01,\n",
            "        -1.7995e-02, -4.2699e-03, -2.6023e-02,  1.8835e-01, -1.0482e-01,\n",
            "         1.0602e-01, -5.6643e-02, -1.0747e-01, -8.5364e-02, -2.8798e-01,\n",
            "         5.9993e-02, -9.4911e-02, -3.2737e-01,  2.3680e-01, -4.3949e-02,\n",
            "         1.0088e-01,  8.0249e-02,  7.5903e-02,  1.1656e-01,  6.0035e-02,\n",
            "         1.8878e-02, -3.9882e-02, -4.5170e-02,  3.5362e-01,  6.2557e-02,\n",
            "         3.4122e-02, -6.8538e-03,  5.8279e-01,  3.3969e-03,  7.9709e-02,\n",
            "        -1.1647e-01,  6.8167e-03, -4.3193e-02,  2.7003e-01, -1.0416e-02,\n",
            "         5.0395e-02, -1.4299e-01,  3.0063e-02,  1.9662e-01, -6.2834e-02,\n",
            "        -1.8492e-02, -1.8543e-02, -6.9153e-02, -3.2291e-02,  7.9797e-02,\n",
            "        -5.3938e-03, -7.2346e-02,  1.6741e-01, -9.1615e-02, -1.1302e-02,\n",
            "         1.4500e-01, -1.1543e-02, -1.3298e-01,  2.0997e-01, -6.9483e-02,\n",
            "         3.4487e-02,  1.7319e-01,  2.8737e-01, -1.5161e-01,  2.2199e-02,\n",
            "         8.9240e-02,  3.6061e-02, -1.0292e-02,  6.2232e-02,  7.3683e-01,\n",
            "        -8.2141e-02,  6.9016e-02,  3.2996e-02,  1.6787e-01, -8.3543e-02,\n",
            "        -1.5930e-02,  1.0353e-02, -1.2699e-01,  5.0148e-02, -1.5024e-01,\n",
            "        -6.2066e-01, -7.3335e-02,  7.5694e-01, -6.5418e-02, -7.5639e-03,\n",
            "        -1.2805e-01, -8.0991e-02, -2.0631e-01, -1.4978e-03,  1.5920e-01,\n",
            "         1.9116e-01, -6.8768e-03,  8.1491e-02,  2.0679e-01,  2.9152e-02,\n",
            "        -3.7448e-03,  1.9741e-02,  1.6719e-02,  2.4523e-01,  5.0608e-02,\n",
            "         2.2662e-01,  8.4574e-02, -4.1998e-02, -9.0021e-02,  5.5979e-02,\n",
            "        -2.0917e-03,  1.1502e-01,  2.9463e-04,  2.6793e-01, -4.4708e-02,\n",
            "         9.8284e-03, -3.4063e-02, -1.6859e-03, -3.4209e-02, -2.8256e-02,\n",
            "        -6.1440e-02, -4.5497e-02,  7.3318e-04,  1.2638e-01, -1.7196e-01,\n",
            "        -7.2966e-02,  1.9365e-02, -5.3045e-02,  5.3166e-02,  2.2950e-05,\n",
            "        -7.7947e-02,  1.6585e-01,  2.8087e-01,  1.3445e-02, -2.5284e-02,\n",
            "         1.6292e-01,  8.4231e-03,  1.2295e-01, -5.7852e-02,  2.9700e-02,\n",
            "         2.5564e-02,  1.6560e-01, -1.1402e-01,  6.4687e-02, -1.7695e-01,\n",
            "         8.1523e-02, -1.0181e-01,  2.2507e-02,  1.4805e-02, -6.4358e-02,\n",
            "         2.3125e-02,  5.6624e-02, -1.1907e-01, -8.5956e-02,  4.7369e-02,\n",
            "        -6.4452e-02, -2.5393e-02, -2.4242e-01,  3.6541e-02, -1.2386e-01,\n",
            "         9.9689e-02,  6.1199e-02,  4.3675e-01,  6.0053e-02,  1.3375e-01,\n",
            "         3.2639e-01, -2.3342e-01, -3.7034e-02,  2.1828e-01, -1.2433e-02,\n",
            "         8.5403e-02,  1.3879e-01,  6.3665e-02,  2.1898e-01, -3.7921e-02,\n",
            "         8.4717e-02,  2.8528e-02, -1.9501e-01, -1.1111e-02,  8.5852e-02,\n",
            "        -3.1827e-01,  1.1107e-01, -4.3058e-02, -1.3678e-01, -2.9733e-02,\n",
            "         1.2440e-01,  1.6502e-02,  6.0280e-03, -4.6028e-04, -4.3688e-01,\n",
            "         9.6400e-02,  3.8853e-02, -2.8624e+00,  7.5349e-03,  1.1750e-02,\n",
            "         1.2907e-01,  9.8685e-02, -1.9429e-02,  1.7229e-01,  2.5394e-01,\n",
            "        -1.4598e-01,  1.5703e-01, -1.5958e-03,  1.3507e-01,  4.3965e-02,\n",
            "         1.3074e-01,  8.8145e-02, -1.9258e-01, -3.9057e-02, -1.0683e+00,\n",
            "         3.3903e-02, -7.4131e-02,  6.8519e-02,  3.2743e-02, -1.3404e-02,\n",
            "        -1.0075e-02,  5.0361e-02,  1.1452e-01,  2.2458e-01,  2.5166e-01,\n",
            "        -5.8807e-03,  1.5456e-01,  2.1496e-02,  4.3345e-02, -9.0361e-02,\n",
            "        -5.0918e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(4.9714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "5 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[-0.1136,  0.1844, -0.0591,  ..., -0.0040,  0.1573,  0.0389],\n",
            "        [-0.1215,  0.1916, -0.0523,  ..., -0.0027,  0.1803,  0.0360],\n",
            "        [-0.1159,  0.1791, -0.0546,  ..., -0.0111,  0.1628,  0.0433],\n",
            "        ...,\n",
            "        [-0.1131,  0.1829, -0.0473,  ..., -0.0115,  0.1647,  0.0473],\n",
            "        [-0.1113,  0.1666, -0.0436,  ..., -0.0168,  0.1476,  0.0484],\n",
            "        [-0.1147,  0.1694, -0.0699,  ..., -0.0011,  0.1586,  0.0363]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 1.1361e-01, -1.8444e-01,  5.9129e-02,  2.2967e-01,  9.8399e-02,\n",
            "        -4.8394e-02,  3.4618e-02,  1.0678e-02, -9.0716e-02, -3.4081e-02,\n",
            "        -6.6017e-02,  9.6840e-02,  3.1211e-03, -1.4092e-01, -1.4695e-01,\n",
            "         1.8582e-01, -3.1264e-01,  9.8062e-02, -1.1034e-01, -1.9703e-02,\n",
            "        -3.9936e-02, -2.5639e-01, -2.0495e-01, -3.7123e-01,  1.1662e-02,\n",
            "        -1.0006e-01,  1.1518e-01,  1.4387e-01, -3.0685e-01,  2.3777e-01,\n",
            "        -2.2762e-01, -2.1279e-01, -1.8250e-01,  1.0116e-01,  1.9070e-01,\n",
            "         1.9335e-01,  6.4437e-02, -2.1400e+00,  2.8633e-02,  1.1443e-01,\n",
            "        -2.2466e-02, -4.1010e-03, -1.0576e-02,  2.4526e-01, -1.0918e-01,\n",
            "         9.6466e-02, -2.0340e-02, -1.4316e-01, -8.3464e-02, -3.5069e-01,\n",
            "         7.6177e-02, -7.9875e-02, -3.7184e-01,  2.4758e-01, -5.6204e-02,\n",
            "         1.2516e-01,  6.5459e-02,  3.8742e-02,  1.6240e-01,  9.7452e-02,\n",
            "         2.9543e-02, -6.7765e-02, -1.1178e-01,  8.8050e-01,  7.2648e-02,\n",
            "         2.0584e-02,  1.0398e-03,  6.6511e-01, -1.1086e-02,  4.4884e-02,\n",
            "        -1.9359e-01,  2.8000e-02, -2.4949e-02,  3.5208e-01, -2.4968e-02,\n",
            "         3.9880e-02, -1.8451e-01,  6.9277e-02,  2.4860e-01, -6.6488e-02,\n",
            "        -4.3044e-02, -3.4220e-02, -1.1417e-01, -5.2460e-02,  8.4812e-02,\n",
            "        -5.1699e-02, -7.1350e-02,  1.7803e-01, -7.8924e-02, -2.2727e-02,\n",
            "         1.8386e-01, -1.4600e-02, -1.3264e-01,  1.9503e-01, -7.9709e-02,\n",
            "         1.9844e-02,  1.6237e-01,  3.4835e-01, -1.4653e-01,  3.9632e-02,\n",
            "         8.3513e-02,  6.3946e-02, -1.3590e-02,  5.4685e-02,  1.0445e+00,\n",
            "        -6.5886e-02,  1.0437e-01,  3.0702e-02,  1.6577e-01, -4.4569e-02,\n",
            "        -1.5680e-03, -2.1306e-02, -1.2759e-01,  9.1166e-02, -1.4557e-01,\n",
            "        -6.4003e-01, -7.0696e-02,  8.2005e-01, -7.7810e-02, -1.5750e-02,\n",
            "        -1.5126e-01, -6.5788e-02, -2.9121e-01,  8.5153e-03,  2.4561e-01,\n",
            "         2.4806e-01, -2.7208e-03,  1.2748e-01,  2.3737e-01, -2.3544e-03,\n",
            "        -2.9732e-02, -3.1345e-02, -5.0671e-02,  2.2969e-01,  5.5330e-02,\n",
            "         2.7707e-01,  1.2544e-01, -5.0262e-02, -6.8415e-02,  3.9503e-02,\n",
            "         7.0866e-03,  1.1642e-01, -2.6837e-02,  2.6577e-01, -3.8801e-02,\n",
            "         6.0122e-02, -1.1976e-02, -1.4312e-02, -2.4280e-02, -6.2748e-02,\n",
            "        -7.4336e-02, -6.1630e-02,  2.0058e-02,  1.3842e-01, -1.7772e-01,\n",
            "        -6.9489e-02, -4.0410e-02, -7.1619e-02,  5.4408e-02,  2.4112e-02,\n",
            "        -1.1302e-01,  1.6684e-01,  3.1182e-01,  1.7558e-02, -4.3812e-02,\n",
            "         1.9567e-01,  2.1424e-02,  1.4905e-01, -2.4261e-02,  3.1882e-02,\n",
            "         1.9078e-02,  2.3215e-01, -1.3162e-01,  6.4527e-02, -2.5409e-01,\n",
            "         1.2209e-01, -1.0670e-01, -2.0597e-03,  7.0130e-02, -1.3498e-01,\n",
            "         4.9673e-02,  6.4712e-02, -2.1314e-01, -9.1293e-02,  8.9916e-02,\n",
            "        -7.9518e-02, -9.8522e-02, -2.9108e-01,  1.7626e-03, -1.2722e-01,\n",
            "         1.3453e-01,  6.3139e-02,  4.9976e-01,  1.0521e-01,  1.5182e-01,\n",
            "         4.1912e-01, -2.7911e-01, -6.4503e-02,  2.3446e-01, -2.9911e-02,\n",
            "         1.4366e-01,  1.8193e-01,  1.1896e-01,  1.8650e-01, -4.5531e-02,\n",
            "         1.0978e-01,  2.2732e-02, -2.4391e-01, -1.9958e-02,  3.5012e-02,\n",
            "        -3.8396e-01,  1.0981e-01, -3.5860e-02, -1.6951e-01, -1.9233e-02,\n",
            "         1.3239e-01,  2.0091e-02,  2.6182e-02,  6.5580e-03, -5.3083e-01,\n",
            "         1.1136e-01,  3.2441e-02, -3.2247e+00,  1.1134e-03,  4.8618e-02,\n",
            "         1.4472e-01,  1.8509e-01, -2.0257e-02,  1.9556e-01,  2.5517e-01,\n",
            "        -1.8295e-01,  1.7150e-01,  5.7613e-03,  1.8245e-01,  5.7220e-02,\n",
            "         2.5041e-01,  1.2030e-01, -1.9545e-01, -3.1131e-02, -9.5176e-01,\n",
            "         4.9373e-02, -1.2021e-01,  7.6697e-02,  9.9549e-02, -3.6996e-02,\n",
            "         3.6142e-03,  4.7357e-02,  1.3984e-01,  2.3816e-01,  3.2909e-01,\n",
            "         1.6684e-02,  1.5587e-01,  6.8660e-02,  3.9760e-03, -1.5731e-01,\n",
            "        -3.8907e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCoAAAQoCAYAAADMnT/BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAC4jAAAuIwF4pT92AACpIElEQVR4nOz9ebglZXko7D+11h57oJupG6GBNGAYNEpE5SdoCwJ6RAWSnI7Dly9oMFFJcpKTqInhOHRijho1Tl+IUcEhMXEWopgoKASFiMYpAg3a2A00g930AD3sYQ31+6PjltX0sPdTm72r0/d9XV6XtahnPW9VvfW+1c+uVVWUZVkGAAAAQA00ZrsBAAAAAD+jUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANRG32w3oE7uuOOO+Na3vhVr166N8fHxOPDAA+OEE06I0047LYaGhma7eQAAAPDfnkJFRFxxxRXxF3/xF/Hd7353l/993rx58dKXvjTe+MY3xiGHHDLDrQMAAID9R1GWZTnbjZgtY2NjcdFFF8XHP/7xSa1/6KGHxmc+85lYtmzZo9wyAAAA2D/tt4WKbrcbv/qrvxpXXnllz+fNZjOOOuqoWLBgQaxevToefPDBnv8+Z86cuOaaa+JpT3vaTDYXAAAA9gv77cM03/72tz+iSPHKV74y7rrrrvjJT34S3/ve92Ljxo3xuc99Lo466qiJdbZv3x6//uu//ogCBgAAAFDdfnlHxYYNG2Lp0qWxZcuWic/e8pa3xJ/+6Z/ucv177rknnv70p8eaNWsmPnvDG94QK1aseLSbCgAAAPuV/bJQ8Sd/8ifxV3/1VxPLy5Yti+uuuy6KothtzFe/+tU4++yzJ5bnz58fq1evjoMPPvhRbevubN68Of7t3/5tYvnII4+MwcHBWWkLAAAA/32MjY3F3XffPbH8zGc+MxYuXDhj+fe7QkW3243DDjss1q9fP/HZ1772tTjzzDP3Grts2bL4+te/PrF86aWXxqte9apHpZ17c+WVV8YFF1wwK7kBAADYf1xxxRVx/vnnz1i+/e4ZFTfeeGNPkeKYY46JM844Y1KxF110Uc/yFVdcMY0tAwAAAPa7QsVVV13Vs3zOOefs8ScfO6/7cNddd11s27Zt2toGAAAA+7u+2W7ATPv+97/fs3zaaadNOvbwww+PX/iFX5h4qOb4+Hjceuut8ZSnPGUaWzg5Rx55ZM/y33/mc3HMscdNOr5vcrWZXWo2csEVUqYrao1JFqF2pVmlwTNsNn6/NRu7J7udVX7g1s3GVUjaToa2uvmc6X2bzpiXzVmlMr8v7Z8qsv29yobmz+tc5OyMl/kRMznlVprD+pJzZzOfclYmlWzKbB/qVBij0+dmBfvQZVCl8X0webL0ZU/OiOgku8J4MvChdr4HPTCei92QjIuI2JbczvkVBr5DB3O96MCBfO+b38zFZvvsVLOtWrUqfuVXLphY3vnfn4+2/a5QsXLlyp7lk046aUrxJ510Us/bP1auXDkrhYqdH5x5zLHHxYmPe9yk46sUKrID82wUKpoKFY8ahYo968xCoWK8ykVwMlSh4tGJmy2zUajI5lSo2LMq83x/MmmVQkWF6TqfMxmX7UPtCmN0JxlXZbfuQ5dBlcb3oeQFX/Y8icgXKkaTgZtb+aLBgrFc7LyxbK+N2JK8EFpQYeA7fCg3gh2SLHBERCzoy8UOz1ChYmcz/eKG/eqnHyMjI3HXXXf1fDbVytDO699+++2V2wUAAADssF/dUfHAAw/0/AWmv78/Fi1aNKXvOOKII3qW161bV7ld69at63nA52SsWrWqcl4AAACom/2qULF169ae5Tlz5kz6QZo/M3fu3D1+Z8all14aK1asqPw9AAAAsK/br376sXNRYWhoaMrfMTw8vMfvBAAAAPL2q0LF6Ohoz/LAwMCUv2Pnh4iMjIxUahMAAADwc/vVTz92voNifHx8yt8xNja2x+/MuPjii2P58uVTilm1alVccMEFlXMDAABAnexXhYp58+b1LO98h8Vk7HwHxc7fmbFo0aIpP9QTAAAA/jvar376sXNRYfv27VN+D/u2bdv2+J0AAABA3n5VqDjkkEN63vLRarWm/HrRe+65p2fZnRAAAAAwffarn34MDw/HUUcdFXfeeefEZ3fddVcsXrx40t9x11139SyfcMIJ09a+Kn461o35I91Jrz/Ft7L2aCRj+yrkHEwm7a+QcyCbM7uDIt/e7L5tVugI2cgqfS+rwiFJV3P7Kmzo1B/zu8NQhQ3tTPHusp/JRVWTzZncxEo5q3T32ThXsvuoSj+Y/My1c9KZ30HZY9Jf4WD2JQehKn+Jmo3zOqtKL8j2vW5yB1U5JuPJnGPZxkbEeDK2U6EDZY9n9potIqKb7PGDFbYz2955yQu+uX3NVFxExGFDudjRTv6fme3kZFSlH1T5d8pMS1+zTXEu6qSyTJ/96o6KiEcWFm699dYpxa9cuXKP3wcAAADk7XeFipNPPrln+cYbb5x07H333Rdr1qyZWO7v74+TTjppmloGAAAA7HeFiuc///k9y9dcc82kH6j5la98pWf5zDPP9DBNAAAAmEb7XaHitNNOi0MOOWRi+Sc/+Ulcd911k4q97LLLepbPP//86WwaAAAA7Pf2u0JFo9GIl770pT2frVixYq93VXz1q1+Nr3/96xPL8+fPj1//9V9/NJoIAAAA+639rlAREfEnf/InPT/Z+Ld/+7d429vettv177nnnnj5y1/e89kf/MEf9NyZAQAAAFS3XxYqDjnkkPizP/uzns9e97rXxcUXXxz33nvvxGfdbjeuuOKKOO2003oeonn44YfHH//xH89UcwEAAGC/sV8WKiJ23FWx84M1//Zv/zaOOuqoOPbYY+NJT3pSHHzwwfErv/Ircdddd02sMzw8HJ/61Kdi4cKFM9xiAAAA+O9vvy1UNBqN+PSnPx0vetGLej7vdDrxk5/8JL73ve/F5s2be/7bwQcfHF/60pfi9NNPn8GWAgAAwP5jvy1UREQMDQ3FP/3TP8VnPvOZOPnkk3e73ty5c+Piiy+OW2+9Nc4444wZax8AAADsb/pmuwF18Gu/9mvxa7/2a7Fq1aq46aab4p577onx8fFYuHBhnHjiiXH66afH0NDQbDcTAAAA/ttTqHiY4447Lo477rjZbgYAAADst/brn34AAAAA9aJQAQAAANSGn378NzHcLGJuXzHp9RuTX/URsqFVcvYVueBmhZxZ3bJMx44nQ8fSGfNt7SRDs3ER+dbOQjeIZJfdETt9zXjUc2a3s0qVfH/YPxER3W4ubjbOsQop0+N0tg81KxyUKUyzPfpn4c9C7QoHpZOcx6rkbCf7e7dC78v2hP7kBU2Va5LhZOxwhYuvbnIPdSv1vVxcsvvskOzvrSpjbXIn9ScPZ7NCP8iGDjbTKaPRzSWtMv+NJ49JlXEv22/z/9SYWuDmVqUzqzJ3VAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC10TfbDWB6bGl3Y3OrO+n1iwq5stWtRoWk5QzHVYmttG+Twc1k1maFxqbbWilnlb2b0+rmekKnQueb/Jk8fbJ7NntIqhzJYhb6eza2Un/Ph6bNxlib3UXNZOfrL/KtzZ7XU5ieHyHd9/Ipo5nsfP1Vxuh0h8/nnOn+XmXcq3KOZaX7UIXBq0xuaJX9Mxvn9Wjy2mJrMud4mW9sO50zf1TaydDkbv2v2FxwpX9rzPCJPdVr9w3jnUenIZPkjgoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNrom+0GMD0WDTXjiOHm5APKfK5saLvMJ213c3Hj3XzOsWTseLKtERGt5D5qJdvartAPsm1tVzgmnWRchZTRKJJx+ZTpnH1FMjAisqHNyAU2Kuyg/mRbByrsn8FmLnaw0nbmcvblNzP6k51voMJ2DmZzJvdP9vyqGpuVnTorTEXpnK0KFxfZyE6F8T07N3STO6hCU9PHs8r8l72GGq9ybTEL117Z69MqOUeSHTd73TYLQ1f6uiIiP6dUmeeHkvP8UIX5byCZM3sdNNXrxAcHp/Bvy0eBOyoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2uib7QYwPYaLIuY0ikmvX0aZztVNhrbLybfvETmTJbXhCjmLZGg+Yz42ezTzvSCiTAZ3K+TsJpN2KmxoK5lzvMKGjiYbnG1rRH4fZVNmz6+IiL5k8BSGyEdoJwe+ToV+0Emeoe0q/SDZ3irHcyB5YJrJfJXGvQqxWdl+W6Wt2X5QZaztzsLenel5LHv9VCW2XeV6L9sPZuFYZseRiIjmLMwpM93f27MwePVXmBhm4y/p2Xl+rMKVf3a+zh7OzhTzbahyMTsN3FEBAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbfbPdAKbHQKOIwUYx6fUbxeTXfWRsLi6fsVrsTOuW+dh2mQse6eTybe90c4ERkY+ceX0VOtBgI1fPLZr5nMVALq5K39vWyQVn+9B4hQ6UPU9Gk+dJRMRYsr3jybZG5Me97BgdEVEkm1uh68WWZHQ72eGTXX1HzmRsq8LJmW1vlWOSja0yV2fH6f4KHX4w+ee64WYusK/CnweHkrF9RT7pUHIeG27mj0l/8vq0yriXHaarXAfN9HldYSpKz7lV9k92fK9yHZQNHa+SNCn7z7ipjgbdKh1nGrijAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKiNvtluANPjti2tGH+wNen15/cX6VxzmrnYucm4KrEDjXzOrE6Zj20lY9tlLrBR5PdPNrLC7ons4azSC7LV3CpdL3k40/0gIqLVzcVuaefixpL5IiLGu7m4Kvunk8yZDNsRm2xut8J2zsaJnQ2tsplZ6bZWyNlMDkJVLvDm9OU6wry+/N+/hpKD5mCFP7kNJnfuQPaYVJgX+pPzdYVLr9np7/vQPN9X4Roqe6o0k1taoamzch3EnmWvD1pTnDg7c2a3VOCOCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2uib7QYwPY6a04zj5jUnvX5Z5nN1k3GtCknXjedix7v5nOPJDe1W2M7svs0aKPKxC/tzdc5sXETEYCPX4Cr7dSzZh6r090aR2845zfwBPWQwF/vYZMrZqJJX6QfZoaRToR+0kg2u0vfayZztdMa8bG+vMOxF8tSslDN7WlcYDmIguaF92R0U+fYmp4WIiMieKdnxoD0L40F2DouIGO3kYrcm4yIitidjq2xn8hIz2rOwb7NxYxUmwCrzWFb2GmGgwoAwlByEquQcSG5odrwspjgbrX5oNmb3n3NHBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbfbPdAKbHWLeM0U45+YAin6uvyAUPNvJJ5zZzcc0iX4trJptbpfrXTO7bbFun0GMeGZsMrpKzk0xaVujwA8ljMlShv2eNd/N7d2u7m4rbNpVx52G2tPNtzeac0hi5k1Zy31bp79ke1Ej22Yj8+FUhZXo7s/u2yjHJBmfHroiIsdypWam/Z8eSCinTObPnZkTE+AzPKX0VzpP+5JySvHzaEZvM2V9hOweTFzT9FS6+svN19no4ImJBcict6M/lqzAEpcf37LVpldhGheu97Pk5UOF6byi5oYPJ/t4/xYNZzqkyglTnjgoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2vB60v8yOjoaN954Y9x2222xadOmGBgYiCVLlsSpp54axxxzzGw3DwAAAPYLtS1U3HPPPfGtb30rbrrppvjWt74V//Ef/xFbtmyZ+O9HH310rFmzpnKe9evXx4oVK+IjH/lIbNu2bZfrnHLKKfH6178+zj///Mr5AAAAgN2rVaHihhtuiHe+851x0003xb333vuo57vuuuti+fLl8cADD+xxve985ztxwQUXxG/+5m/GBz/4wRgYGHjU2wYAAAD7o1oVKr797W/H5z//+RnJ9Y1vfCPOPffcGBkZ6fl84cKFsXTp0ti0aVPcfffd0el0Jv7bxz72sdi6dWt85jOfiaIoZqSdAAAAsD/ZZx6mOW/evGn7rk2bNsULX/jCniLF0UcfHVdccUVs3Lgxvvvd78bq1atjzZo18YpXvKIn9nOf+1y8613vmra2AAAAAD9Xy0LF/Pnz44wzzojXvOY18elPfzrWrFkTX/jCF6bt+9/+9rf3/LRk6dKlceONN8b555/fc6fEkiVL4v3vf3/85V/+ZU/8n//5n8emTZumrT0AAADADrX66ccLXvCCePaznx0nnHBCNBq9NZTVq1dPS47169fH+973vp7PPvjBD8bhhx++25jXve518eUvfzmuv/76iIh48MEH4x3veMcjChgAAABANbW6o+LYY4+Nk0466RFFiun0iU98IrZu3TqxvGzZsjjrrLP2GFMURbzxjW/s+ezyyy+PsiwflTYCAADA/qpWd1TMhCuvvLJn+aKLLppU3JlnnhlLly6duLPj/vvvj29+85vxtKc9bdrbmDG/rxEL+ydf4Nnc6qZzbenkCjSzUdfpRn4728n2trr5DZ3pnJWOSfKBskXkk44k+97m8Xw/2NRK7tsK2znUzBVr5zTzD/kdaubi2slduy15LCMiRpOx27MnWERsS25otq0REePJ87qT7+7RTQ4KFYa9yO6iboVzLCvb1vEK/SAbWeWR381GLrrCEBT9ydgFA8nBKyIOGcqNtYcM5uIOmMJ12s7m9uV20AHJuIiIucm5qMJmxlCy71XZzqEqHTcpO2Zmr9uqjJbZ65kKw96szAvZY1Jhyk3L9tjGFK/dB5Ln43Sp1R0Vj7atW7dO/HzjZ5797GdPKrYoijj77LN7PvviF784bW0DAAAA9rNCxS233BKtVmtieenSpXHYYYdNOv7000/vWf7+978/XU0DAAAAYj8rVKxcubJn+aSTTppS/M7r7/x9AAAAQDX7VaHi9ttv71k+8sgjpxS/8/p33nlnjI6OVm4XAAAAsMN+9TDNdevW9SwvWbJkSvGLFy+Ovr6+aLfbERHR7XZjw4YNccQRR1Ru1/r166cUs2rVqko5AQAAoI72q0LFw19LGhExd+7cKcUXRRHDw8OxZcuW3X5nxqWXXhorVqyo/D0AAACwr9uvfvqxc1FhaGhoyt8xPDy8x+8EAAAA8varQsXOz5MYGBiY8ncMDg72LI+MjFRqEwAAAPBz+9VPP3a+g2J8fHzK3zE2NrbH78y4+OKLY/ny5VOKWbVqVVxwwQWVcwMAAECd7FeFinnz5vUsZ97YsfMdFDt/Z8aiRYti0aJFlb8HAAAA9nX71U8/di4qbNu2bUrxZVk+KoUKAAAAYIf9qlCx810La9eunVL8T3/604lXk0ZENBqNOOSQQ6albQAAAMB+Vqg4/vjje5bvuuuuKcXvvP7RRx89Lc+oAAAAAHbYr55RccIJJ/Qs33rrrVOKX7ly5R6/bzbduHEs1q6b/DM31m7rpHNtbnVTcSOdMp1zPBk73p2FnBW2s0yGdpOBndyhjIiI7FYW+ZTRTJZWiyKfNRvaqLChzWTS7P6JiJjTl8u5YKCZipuXzBcRMZzc0KFmPue8vtx2Vuh60U6en60K495ocvzakpwXIiIeSsZua2fH6FRYRER0kvs2f0Ty43tRYbTtS44lBwzkcx40mDvH5vfnB76yzLV301iuz2avnyLy80J/hTEoO04fPSf/z4slwzM/1s6G7PVe9rSu8pfpRnLntitcD29OToAbxvPnWDb2geR4EBHxwGhuQvppMm7jFNu64Y6HUnmmy351R8XjHve46O/vn1hes2ZN3HfffZOOv+GGG3qWTz755OlqGgAAABD7WaFi/vz5sWzZsp7Prr766knFlmUZ11xzTc9nL3jBC6atbQAAAMB+VqiIiDjvvPN6li+77LJJxV177bWxevXqieXFixfHqaeeOq1tAwAAgP3dfleoeNGLXhRz586dWL7++uvja1/72h5jyrKMFStW9Hz2spe9LBqN/W73AQAAwKNqv/uX9qJFi+L3fu/3ej57+ctfHvfee+9uY97ylrfE9ddfP7G8YMGCeM1rXvOotREAAAD2V7V768cNN9wQIyMjj/j8Bz/4Qc/y6OjoI54Z8TOHH354nHTSSbvN8drXvjY++tGPxv333x8REatXr47TTjst3vve98YLXvCCiTcErF27Nt785jfH3/3d3/XEX3LJJXHQQQdNabsAAACAvatdoeL/+X/+n7jzzjv3ut5Pf/rTOOecc3b53y688ML4yEc+stvYgw46KD75yU/Gc57znBgd3fFKzzvvvDPOP//8WLhwYSxdujQ2b94cd911V3Q6va9/Of/88+PVr3715DcIAAAAmLT97qcfP7Ns2bK46qqrHnFnxObNm+N73/terF69+hFFipe85CXxyU9+cuKOCwAAAGB67beFioiIZz3rWXHrrbfGq171qpgzZ85u1/vlX/7l+OxnPxsf//jHY3BwcAZbCAAAAPuX2v30Y82aNTOab/HixXHppZfGO9/5zrjxxhtj5cqVsXnz5hgYGIgjjjgiTj311DjuuONmtE0AAACwv6pdoWK2DA8Px1lnnRVnnXXWbDcFAAAA9lv79U8/AAAAgHpRqAAAAABqw08//ptY+WArNmwcn/T6Y50ynWusm4ut8q6U7JtWBpr5rMN9udhuN50y2sl920nmLCPfD7JdqELXy++fCjmzoVXeDlQmQ6ts59ZWLnh7q52Ka1YokzeS+7avkT8m/cn29lfIOZQcv+b25XfucDLn/P785cSRyV2U7UPNCrNR9rSucm6OJ4O3V0g6moxtVZgAW8nQzeMVcpa57Rxt5+LGk3NYREQn2dY5FQbbkxYOpOKqXFsMJJs7UGHOzV4T52a/HZrJuP7kdla5Bt+UPMfu2J7fQ3ds7ex9pV3ItjUiYiTZD8ayF+GRnxuy1zOHDk+t55WD2Z46PdxRAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQG32z3QCmx2/d/D/jpE0Dk17/K8+5JZ1re7tMxY10cnFVYtvddMrolrmcRVGkc/YlQ5uNXGAzly4iIpIpoy8bGBHDzVzsUDIuIqIvWc7t5rt7jCTPsW0VzrHRZM7tndxJNlahrdl9W2E4iIhc0v5Z6O/9Fcag7F8vKqRMj5ntZEfoFPm+1yhzbc3OJxERyZQxNzuhRMSC/lxPaBT5WSV7Xm+rMNE/1MrFzktePTcr/HlwuJELPmAg3w8OGUjmzE6cETE3uZOqjEHZcbo/nzJ9DZUd99Yn+3pExB3bOqm4VVvb6Zybx3PtHa1w8ZW9LqlwOZM+ntm2TjVu01ju2E8Xd1QAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtdE32w1geow/eE+MDk9+/WX/NCed69O/sjUVt3m8m8450s7FjnXKdM52mYttFEU659y+XOz8/mYqbk4yX0R+Oyvsnhjp5o7JWDIuIiLbhapUgfuSwVVylpHb0HZy31Y4JGnNCn1voJELbiTjIiKK5MkylBsOIiLioMFcLxqqsnOTtrZycT8d6aRz3j+ai900ls850s6dLJ0KJ1m27w1U6AcLk31vwUB+5MtOgRVmznRkK3lNsr2dThkbk/NCUeSTZue/IwbzA9/gLIxfWc3kuTk/u2Mj4sgp/PtiutyfHDM3j+fHve3JsTb774WIiE4ydqauofrnzG6pwB0VAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC10TfbDWB6jP7SK2Jk6aJJr3/f41+fzvXkZFyRzhhRJIObFZI2k0mr5CzLXNx4Nxe4vZNMGBEPtbsznnN7Oxc7WiHnaCcX10oek4iIdrIjZOMiIpKHM7Kb2ah0bs5sXEREIzkeZOMi8n9JyPbZiIh1o7mOMFBh5x7Ql4ud35/bQ4cM5v9Gc3JjIBXXV6Ef9M3Cn5S6ybFkPDmO7IjN5RyrMNZmz5XtndyGbkvOYRERY8l5bKTC/Lel3U7F3TuaThlrtuUOymOGmumchybHhLnJsSsiYjg5Cc5JjrVDFcbo+cntfNwB/emcv9jN/RN1W5VrzGRs9to0ImJrMufW5EXbltYU81U4r6aDOyoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2uib7QYwPb6w8GXxrUNOnPT6jZ+OVMhWpKJa3TKdcSwZ2+6mU2Y3M/qTcRERQ81c8Ly+XM1xwUC+VpltazYuIuKggVxsfyOfM9vcokI/iOSpMp4/xWKsnQve1smdZKOdfGOz21mhG8RgI3euDDXzOQeSnai/wp8gyuS+7eRTRieZ9KFWru8lu3pERIwn56KxCv19JBm7vcIEuC0Zu3ksn/OhZOy2sXzva7dzcd3siZKNi4giO6lUGPeyY2ZfhXl+MHk9M9A38zkPqHANlY09INnW+RXaOmcWrveyzZ2T3D8REcPJ0MEKFxeHJDf08OTFxVRPkwMX9KfyTBd3VAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1EbfbDeA6XHgUDMOHZ784eyvUKLqK4pUXJlPGWWZi06G7YjNbWalDe0kY8tk0my+iIjt7Vzw1mRcRMS28U4qbu22djrnnQ+1UnFbRnJtjYhot7qpuLFkXETE+GiuvZ1OLme3SudL6qsw8DX7crEDA/mc/cmcVbZzzmAzFTd3MJ9zbrK9Q8m4uX3ZwT1ifvKYHNCfz7l4KJdzTjN/iZftQsnLg4jIz0cVppQYSQY/kBwv7xvJz0UPJOeULWP5eWF0PBc73soflJHx3D4qu/mc2dAqObOazdxJ1l9hXuhr5HJm21olZzYuImI4OU4PNvP7diC5jwaTcfOmuI0/vW8klWe6uKMCAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqI2+2W4A0+Pz398Yczasm/T6zWa+RjU0mIsdHGymcw705XL29+e3c7C/yMVV2Lf9yV3UKHJt7cuFRUREfyOZs0J5tC+5nXMq9IOTDhpMxbXLMp1ztJ2L3d7u5nN2cnHj3VxbuxX2TxEVOu4Mq9LS7B5KnpqVYpsVkvYlY+c1c3HzK4wHQ8mcyVM6IiLWbs+dnKOddjpnO31ep1Om+8HByWuSiIjHDOcm3ZMPHEjFnbFoKBUXETGQ3MyRCgflgbHcnHLntnzfW/VQKxW3ZvN4Oue6ZOzoWHLijIgyGVpWmDuziuS5mbxki4iI7GZ2OvnroNZ47qB0Kgzw7WQf6iTbWnam1tax++9L5Zku7qgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKiNvtluANPjScfOj0OOWzjp9Q8abKZzHTqUq28dPJDPefBALmenLNM5N7VysetGO+mc921vz2jODaPdVFxExPaxXM6RsXzOsfFcznY33w8G+nJ9b+5wfngdTvb3wf4inbOIXGw2Y4VTM1qdXB9qd/JJs7GdCn0vq8q+7Wvmjmi2z0ZEHDSYi/3FA/pTcUfMyc9Fc5PjQf7MjGglD+iW5BwWEbFqaysVt3Zrbg6LiBhLnmMj7fycsiE5Hw00cvtnXn/+PDkweY4dVOHcHEkek4da+WPSTnbbeUP587px0GAqbmS8wvVMst9mp5SiwrwwkLy2aBb5kS/b3FaF8aCTnufTKaOdDG4lO0J3itu4vW9e3JnKND3cUQEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANRGLd/6UZZlrFmzJn74wx/G2rVrY/PmzTE4OBgHHnhgPPaxj42nPOUpMTQ0NK05t2zZEjfccEP86Ec/ioceeiiGh4fj6KOPjtNOOy0OP/zwac0FAAAA7FptChWbNm2KK664Iv71X/81vva1r8UDDzyw23X7+/vjec97XvzhH/5hPPOZz6yUd/Xq1fGGN7whPvWpT8X4+Pgj/ntRFPHMZz4zVqxYEcuWLauUCwAAANizWvz043d/93fjsMMOi9/6rd+KT33qU3ssUkREtFqtuOKKK+KMM86ICy+8MB566KFU3k996lPx+Mc/Pv7hH/5hl0WKiB13d1x33XVxxhlnxJ/+6Z9GWeUF9QAAAMAe1eKOiptuummXhYJmsxmPecxjYvHixdFqteLOO++MBx98sGedj33sY3HbbbfFV7/61Zg3b96kc37605+OF7/4xdHtdns+P/TQQ+PII4+MdevWxT333DNRmCjLMt72trfF2NhYvOtd70psJQAAALA3tbij4uEWLlwYF198cVx11VWxadOmuPvuu+M//uM/4gc/+EFs2LAhrr322njGM57RE/Otb30rXvrSl046xx133BEve9nLeooUT3ziE+NrX/tarFu3Lr7zne/E3XffHStXroxf/dVf7Yl997vfHZ/73OcqbSMAAACwa7UpVPzCL/xCfOhDH4p77703/uZv/ibOPffcmD9/fs86zWYzzjjjjLj22mvjd37nd3r+22c/+9m49tprJ5Xr9a9/fWzbtm1i+SlPeUpcf/31ceaZZ/asd/zxx8dnPvOZR+R67WtfG+12eyqbBwAAAExCLQoVK1asiNtvvz0uuuiiGB4e3uv6zWYzLr300njyk5/c8/mHPvShvcbecsst8clPfnJieWBgID760Y/GAQccsMv1i6KI97znPfHYxz524rM77rgjPvzhD+81FwAAADA1tShUPO95z4uBgYEpxTSbzXjta1/b89mXv/zlvcZdfvnlPT/5eNGLXhQnnnjiHmOGhobiT//0T3s+m0xRBAAAAJiaWjxMM2vnZ1Vs2LAhtm/fHnPmzNltzD//8z/3LF900UWTyvXCF74w/tf/+l8TPxn59re/Hffee28cfvjhU2z1o+OBbZ1ob5n8z1FG2929r7Qb7W6u23TyKaNIxi0eytfijhnIxR5RIefSebl9O9rJvY1mLBkXEbE9GZuNi4jY3sp1oq3tfM7sPiqynTYimsnYRoWc2RcaZfdslRcotZPBFYa9dD9od/Mbmo1tVOh8/clONHcgn3NBf27M3Jo8JveM5DtCo8jFjlfoBw+O53Lesy3/E9X7krHtCuN7J3lelxXO624yZ/Z6plPhQigb2q3Q99JvuqswF/U1c+PBUPKaLSLi0OS11+MPGUznPHpuLudhQ81U3LzkOBsRMSd5UdJfaS7KxVW69krG9VXp78k5t0rOqbjtlgfj9JlJtUu1uKMi68ADD3zEZzu/FeThbr/99li1atXE8ty5c+O0006bVK6d1y3LMq666qoptBYAAADYm326UHHPPfc84rODDz54t+t///vf71l+6lOfGn19k69onn56b01p5+8DAAAAqtmnCxVf//rXe5aPPvroPT7rYuXKlT3LJ5100pTy7bz+zt8HAAAAVLNPFyouv/zynuVzzz13j+vffvvtPctHHnnklPLtvP7O3wcAAABUs88WKr70pS/F9ddf3/PZS1/60j3GrFu3rmd5yZIlU8p5xBFH9CyvX79+SvEAAADAnu2Tb/3YuHFjvOIVr+j57IILLoinPvWpe4zbunVrz/LcuXOnlHfn9VutVoyNjcXgYP6pvxE7CihTLXo8/KGgAAAA8N/FPleo6Ha78Ru/8Ruxdu3aic8WLFgQ733ve/cau3OhYmhoaEq5h4eHd/mdVQsVl156aaxYsaLSdwAAAMB/B/vcTz9e85rXxL/8y7/0fPZ3f/d3k3rexOjoaM/ynh68uSu7KkiMjIxM6TsAAACA3dunChXvfe9746//+q97Pnvta18bL3zhCycVv/MdFOPj41PKPzY2ttfvBAAAAPL2mZ9+/OM//mP84R/+Yc9nL33pS+Otb33rpL9j3rx5Pcs732GxN7u6e2Ln78y4+OKLY/ny5VOKWbVqVVxwwQWVcwMAAECd7BOFii9+8Ytx4YUXRlmWE5/96q/+anzoQx+Koigm/T07FxW2bds2pXbsvH5fX9+03FGxaNGiWLRoUeXvAQAAgH1d7X/6ce2118by5cuj3W5PfHbOOefEP/3TP0Wz2ZzSd+1cDHj4Azkn45577ulZPvTQQ6cUDwAAAOxZrQsVN910U5x33nk9P9E47bTT4vOf//yUH4QZEXH88cf3LN91111Tit95/RNOOGHKbQAAAAB2r7Y//fjP//zPeO5zn9vzStFf/uVfji996Usxd+7c1HfuXFi49dZbpxS/cuXKPX7fbOqUZbS75d5X/C8PbOukc63b2t77SrvQ6ky+fTsba3VzOVv5nK1OLmclU/gp08MNDuZqjsP9+Vrl8EAudqivQs6+5P6pkPOA5D46KHlMIiLmJXP253ZPRERMYfiYFn3Jvh4RUUause0K27hlPDcebE7GRURsHMuN01uT42VExKbRXM51W/M7dzx5YNrJMbpTYS4qk6HdbGBEdJOHs0rOMhlbIWU0GrkxIRsXERHJ0Ozw1agw7vU1c7HDA1O7+/jh5g3lYg8czuecn5z/stcHERHjyTGhyvi+bvSRD+ifjNHkeFlh2EvLztUR+XFvKv8W2ln2sr9TYeBrZ8f35L6d6jY+tHpTKs90qeUdFbfffnucc845sWnTz3fOiSeeGF/+8pdjwYIF6e89+eSTe5a//e1v9/ykZG9uuOGGPX4fAAAAUE3tChV33nlnnH322bFu3bqJz5YuXRpXX3115WdCnHDCCXHsscdOLG/bti1uvPHGScVu27Yt/v3f/31iuSiKeP7zn1+pPQAAAECvWhUq7rvvvjjrrLN6HnJ5xBFHxFe/+tU44ogjpiXHeeed17N82WWXTSruk5/8ZM/PUJ785CfH4YcfPi1tAgAAAHaoTaFi48aNcc4558Qdd9wx8dmhhx4aV199dSxdunTa8vzWb/1WzytNP/GJTzzi2RM7Gx0djbe+9a09n1100UXT1iYAAABgh1oUKrZs2RL/43/8j7jlllsmPlu4cGF85StfiRNPPHFacz3+8Y+PX//1X59YHh8fjwsvvDAeeuihXa5flmX84R/+Yfz4xz+e+OyYY46J3/qt35rWdgEAAAA1eevHeeedF9/+9rd7PvujP/qjeOCBB+Kaa66Z0nedcsopceCBB+5xnTe/+c3xhS98IbZv3x4ROx6quWzZsnj3u98dZ5xxxsR6P/rRj+J1r3tdfO5zn+uJf+tb3xr9/f1TahcAAACwd7UoVFx33XWP+OwNb3hD6ruuvfbanmLDrhx33HFx2WWXxUte8pKJV3D94Ac/iDPPPDMOPfTQOOqoo2LdunWxdu3aR7yi6/d///dj+fLlqbYBAAAAe1aLQsVseNGLXhRlWcZFF10UIyMjE5+vX78+1q9fv8uYV7/61fFXf/VXM9VEAAAA2O/U4hkVs+XFL35x3HzzzfGSl7xkjz/lWLZsWVx33XXx9re/vedBnAAAAMD0qsUdFTv/vGImHXPMMfHxj388/vZv/za+8Y1vxI9//OPYsmVLDA0NxVFHHRWnn376tL0aFQAAANizWhQq6uCAAw6Ic889d7abAQAAAPu1/fqnHwAAAEC9KFQAAAAAtaFQAQAAANSGZ1T8N7FxSyvGN49Pev15w810rmzswXPy3a2/mXvbSjedMWKsnXvI61g7n3W0lcvZ6uRyVnmO7chYLufYeD7pQ8mX7vQl+09ExE+T5dxGhTcEZR8wPJ7sPxERrc7M9r1ON9/WbGyjQn8f6Msdz4G+/N8DikYuZ7vCvt0+2pnRuIiI8fFcbDc5Rld5fHeRHEuqvC+skewHjQrjXjMZ29/I9/fsOD1Y4Rwb7M/F9iXHg74Kbc1GVunv48l5Ye3mVjrnWCs3Howmx5GIiJHR3DzWqpAzO351k+N7Nq6KKhkbyXNl7pz8v28Omr/7N0DuySHzB9I5F8zLtXcouX+m2g3WbxqIa1OZpoc7KgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDa6JvtBjA9Hlg3Elv7tk16/W6nm87VaeVii3TGiKLIRTf68lkHhpqpuP6h/Gk1MJDLmd7OMhcWEVF2c8GdTj5pJ9lvq+RsJ/v7+Eg7n3Okk4rLHpOI/JhQ5poaZVmh82VVyDkbzW00k+d1cryMiCjbuX7QqtDfu2O52G575s+T2VA0cn9Tagzk/xbVHMzNY82B/PzXHMzNf33JuToiYnBufyqufzC3bweS+zUiopkcD9LjSOT/mtmpcI5l5+tKZ3XykrjCUBuNZFcoylzSIn/ZH512bu92k3EREe2xVipu5MGxdM51dyWvg6rMKcmLi6KR7Ad9Uzurx+5bl8ozXdxRAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQG32z3QCmR/9gIwaGJl93ao0X6VzdVjcV1xrt5HOO5XJ22hVytnKxZadM54zkYSkauZpjoy9fq8zGFs183ysa+disbH/vtnNxERHd8Vzf61bo72Un194y2d3LboXzpJvctxVSplXpskUuuGjmz+tkykqy41dzIHcJU1QY94q+3A5qNJvpnI3kmFlprE32oWpzSq69zWRcREQnOU53kuPlts1jqbiIiHbyGiobF1FxnE5qZPveQL7vDR3Qn4ubl4uLiBgczI1fA8ntrHL9NJ68JnmoQn8f3TKeimttaaVzdsfbqbhOcv9ERJTZ65lk2FTH9taGLblE08QdFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBt9M12A5gefX2N6O9vTnr9/oEinas9mKtvtca7+ZytXGxrWyudc3xrLrbbzm9n2cnFlsmcnWS+iIhuK9eHima+Plo08v02q9vq5OLGc3EREd3scemW6ZxlN5kzm7LCscz2oSr9Z1ZyZmMr5Gykt7PC3z2SzS2KZODkp8pH5kzGlRXOzU5yDIrxdMqIMtfebie/nVmV5oVkaJmdOrPjbOTnlCrXJNlTrMo83xzInaD98wbSOTtjufaOV9jO7NzZbudyDgzmB76BKfz74uHmHTCYztnsy23n2HB+O0cfzF33Nytc76UvoZozcw3e6Ayl8kwXd1QAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANRG32w3gOmx7aHx6Gwem/T6/YPNdK6BZOzgcD5no1mk4opcWERE9PXn6njtVjedszOei+1m47r5tkaZDCuTgRFRdnLtrZIzkn2oUeEcazb6U3FFpdJz8hxrzGxcRESjL5mzmd9BjeR40DeQz9lM9qFGhX2bjSy7Fc7r5PlZJAf4KudJkT1PknNYREQzeTyz82aV2P7keRIR0d/IxQ5WOMfmDOZih5Pn5lCV/ZM8Jn0Vxr1mchrL9tmIiEbyvC6zFyURkby0iPFOPudoKxe7daydixvtpOIiIrZtz+Vst/PXmGU2NDmOROTn3Oy1aUREZyS5b8dzx7Oc4nV/a/NIKs90cUcFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBt9s90Apsem2x+IvvXzJ71+0SjSuYoiGZuNi4iikaupld1uOmeV9uZzJuPSm1lmAyuFplOW2aT71nZm+16V8zqbs9FM1rurnF8zPwTNktkYa9OR6ZyR7LdFM9ln+/J/oymS/b3SuZndPxX+FJVt7WwMl5V0cy3uJuPKTn4PlcmclYa97JybbGtERLed3bf5671sbLc9Gzk7M5ovouK1dDppMix9nVjh/CxnYf9kTfH6oLN526PUkMlxRwUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG30zXYDmCZFseN/U1k/m6rZzMX15etiRSPX3qJRoYtX2EdZZaebiuu2Orl87Vy+iIhusq3ZbYyIKLtlOnZfUnZy21l28/s2svu2TLa1Sj9I5iyqnNPN3PhVJOMiIhrJMbPoy43RO3LmYrNxERFFMzm+J/dtdzQVVkm1vpeLvfMZ/yefM+no69884zmrKNu5ubOTnHO7rXYqLiKim2xremyP/Jw7K3N1levaZGil8zobmsxZ5Yq2aMzC37Wzx6RK19uX/lWc3D9TPTe7/bO7U9xRAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANRG32w3gGlSljv+N+n186m6rXYubrSbzzmWzJlsa0REmYwtO518zk42ZysZlz8mlTpRVlHkwhrNfMq+/lRcY2CgQs7c0Fw0KtSeG8l9W+RyFn0zXyefyhA5vcHZnNm4fFu7rdz4lY2rJrudub4eEXHbSc9Kx2YdPC8ZeF8+54atubgPzrs/nfPFN785FVe2Z2HO7SbnzirjSDo2nzO7nWWF7UyfnRXmv6KZnHOT1wcREY3sPN9MXs9U2T/J64Mql4npPpQ9N6NCf+9WmP+6ue1Mj0FTbGtny+ZcnmnijgoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2qjl60nHx8fjtttuizVr1sQ999wTW7ZsiVarFQcccEAcfPDB8YQnPCFOPPHEaGZf0bOTdrsdN910U9x8882xYcOGaDab8ZjHPCZOOeWUeNzjHjctOQAAAIC9q02h4jOf+Uxcc801ccMNN8Rtt90W7fae3229YMGCePGLXxx/8Ad/ECeccEIq59atW+Otb31r/O3f/m1s3Lhxl+scf/zx8Sd/8ifx0pe+NIoi/+51AAAAYO9q89OPP/zDP4y/+7u/i5tvvnmvRYqIiAcffDDe//73xxOe8IR405veFGVZTinfD3/4w3jCE54Qf/mXf7nbIkVExO233x6/9Vu/Fc997nPjwQcfnFIOAAAAYGpqc0fFrgwNDcVRRx0VCxYsiG63Gw888EDcddddPUWJVqsVK1asiLvvvjsuu+yySX3v7bffHs961rPigQce6Pl83rx5ccwxx8TIyEisWbMmWq3WxH/78pe/HM997nPja1/7WgwNDU3PBgIAAAA9anNHRUTE4YcfHr/9278df//3fx+rVq2Kbdu2xe233x7f+ta34j/+4z9izZo1sWHDhvjABz4QS5Ys6Ym9/PLL48Mf/vBec7Tb7Vi+fHlPkeKggw6Kj370o7Fx48b4wQ9+ED/60Y/i/vvvj0suuSQajZ/von//93+P1772tdO3wQAAAECP2hQqvvSlL8XatWvjAx/4QPzGb/xGHHvssT1Fgp858MAD47d/+7fjP//zP+NJT3pSz3+75JJLotvt7jHP5ZdfHj/84Q97vu/rX/96/OZv/mb09/dPfH7QQQfFm9/85vj7v//7nvi//du/jR//+MeZTQQAAAD2ojaFiic84QlTeljlgQceGP/wD//QE3PffffFDTfcsNuY8fHxePOb39zz2Tve8Y446aSTdhvzkpe8JH7jN35jYrndbseb3vSmSbcTAAAAmLzaFCoyTjzxxDjllFN6Plu5cuVu1//yl78cd99998TyL/zCL8TLXvayveZ505ve1FMQ+fSnP+3BmgAAAPAoqPXDNCfj2GOPjf/4j/+YWN75AZkPd+WVV/Ysv+xlL5vUXRzHHntsPPOZz4zrrrsuInY8wPNLX/pSvPjFL841+lHQ3joaZXP75AOm+JaUfVXZzW/nVN8kM6HCW2yLXfzcaXJxg6m4sq/C/olkbJW+l43tdtIpu2MjqbjOyLZ0zij3/BO23cflU6ZlX9tc5TwpsufJzNfm0+PIjuBsYD7nbLyGOz2UzPx5ctq6d6Tibjzj1emcm6cwtT9cJ7l7qvi1r/1+heifTls7Hn3ZTlTl/MrF3n3+b6czHjwvF7dhazplHPXFyT0Yf2eVpr9iLBdW4Xh20nNnLm4qd63vLD+PzcL8V2HOzf+boUrvm+E5dy+PSHjE6tsqnMzTYJ++oyIiYnR0tGd54cKFu133qquu6ll+9rOfPek855xzTs/yF7/4xUnHAgAAAJOzTxcqyrKMb3/72z2f7fxTkJ/56U9/Gvfff//E8uDg4CMexrknp59+es/y97///ck3FAAAAJiUfbpQcfnll8e99947sXzCCSfEU5/61F2uu/OzK4477rgYGBiYdK6dH7i5atWqaLfbU2gtAAAAsDf7bKHiox/9aFx88cUTy41GI/6//+//2+1vsG6//fae5SOPPHJK+Q499NAYGhqaWB4fH4/Vq1dP6TsAAACAPavtwzR/9KMfxV133TWx3Gq1YtOmTXHzzTfHlVdeGbfeeuvEfxsYGIgPfOADcdZZZ+32+9atW9ezvGTJkim36fDDD4+f/OQnPd/52Mc+dsrfs6u2rV+/fkoxq1atqpwXAAAA6qa2hYpLL7003vOe9+xxnaIo4n/8j/8Rb3nLW+KJT3ziHtfdurX3qaVz586dcpt2jtn5O7MuvfTSWLFixbR8FwAAAOzLaluomIzly5fH//pf/2uvRYqIRxYVHv4zjskaHh7e43cCAAAA1eyzz6iIiPjUpz4VT3/602PZsmV7/SnEzq8xncqDNH9mcHCwZ3lkZGTK3wEAAADsXm3vqHj3u98d7373uyeWR0ZGYsOGDfGDH/wgPv/5z8c//uM/ThQKvv71r8dTnvKUuPrqq+PJT37yLr9v5zsoxsfHp9ymsbGxPX5n1sUXXxzLly+fUsyqVaviggsumJb8AAAAUBe1LVTsbHh4OJYsWRJLliyJ5z3vefGnf/qnsXz58vj+978fERGbN2+OCy64IG6++eZYuHDhI+LnzZvXs7zzHRaTsfMdFDt/Z9aiRYti0aJF0/JdAAAAsC/bZ3/6cdxxx8XVV1/d85rRe+65J97+9rfvcv2diwrbtm2bcs6dY6arUAEAAADssM8WKiIiDjnkkEe8LeMjH/nILtfd+Y6FtWvXTjnfvffeu8fvBAAAAKrZpwsVERG/8iu/EkVRTCzfe++9ceeddz5iveOPP75n+a677ppSnnXr1vX8XGRgYCCOOeaYKbYWAAAA2JN95hkVu7Nw4cI46KCDYsOGDROf3X///XH00Uf3rHfCCSf0LN9xxx0xPj4+6bd/rFy5smf52GOPjb6++uy+otGIojGFulMzX6MqGsXeV5rGuB2xM19TK7Nx7U6FpMmsRfKY9DVz+SKiOZDr/43+fM58P8gezYgye0zyKaPsdFNx3Qp9rzuei+222qm4stVKxe3ImYst27m2VootK4wHWUX+HIv0MF1hfC+yJ8vMzwv3tA5PxR199cfzSZNjUHboisgfzebcKn0v34eyym7y/OzmxuiyzMXtCM7FHvUvH87nnA3pab7Kvk2eY/mM1U7QTLoZzbbDLJzSlRTZfxtVOJbpMWGG+89s2efvqNiV/v7+R3x22GGHxWGHHTaxPDY2Ft/5zncm/Z033HBDz/LJJ5+cbh8AAACwa/t8oWLLli2xcePGns8WL168y3Wf97zn9SxfffXVk86z87oveMELJh0LAAAATM4+X6i46qqrem7NPvTQQ+Mxj3nMLtc977zzepY//OEPT+q27jvuuCP+7d/+bWK5v78/zj333GSLAQAAgN3ZpwsVIyMj8cY3vrHns+c///nR2M3v2J/znOfEkiVLJpbXrFkTH/7w3n+796Y3vamnoPFrv/ZrsWDBgmSrAQAAgN2pRaHita99bXz729+eUszGjRvjvPPOix/96EcTnzWbzfjf//t/7zZmcHAwLrnkkp7PXv3qV8ett96625h//Md/jH/4h3/oybHzK1EBAACA6VGLQsVXvvKVeOpTnxqnnnpq/PVf/3V8//vfj9YunupelmXcdttt8Rd/8Rdx/PHHxzXXXNPz3//3//7f8Uu/9Et7zHXRRRfF4x73uInlTZs2xTOe8Yz42Mc+Fu2HPdV948aN8frXvz7+3//3/+2Jf8UrXhG/+Iu/mNlMAAAAYC/q837NiPjWt74V3/rWtyIiYmBgII444ohYuHBhDAwMxJYtW+Luu++OLVu27DL2wgsvjLe97W17zdHf3x+f/vSn4+lPf/rEQzg3btwYF154Yfzu7/5uHHvssTEyMhKrV69+RLHkqU99arzjHe+ouJUAAADA7tSqUPFw4+PjsXr16r2ud8ABB8Rb3/rWeOUrXxnFJF/Ye+KJJ8bXvva1OP/88+POO++c+Hzr1q3xgx/8YJcxZ599dnz605+O4eHhyW0AAAAAMGW1+OnHP/3TP8Xb3va2OPvss+OAAw7Y6/pFUcQTnvCEePvb3x6rVq2KV73qVZMuUvzME5/4xPjhD38Yr3vd6+LAAw/c7XqPfexj44Mf/GB85StfiYULF04pBwAAADA1RTmZ93POoG63Gz/+8Y9j1apVcdddd8VDDz0UrVYr5s+fHwsWLIhf+IVfiCc96UmTKmhMVqvViptuuiluvvnm2LBhQzSbzXjMYx4TT3rSk/b6zIvZcsstt8TjH//4ieUDzn1/NBccPfkvaOZrVEVjakWhqnE7Yme+ppY9Mcp2p0LSZNYpFuomwvqauXwR0RzI3ZDV6M/nzPeD/DCXHiIrjKxlp5uK61boe93xXGy31d77SrtQ7uI5RJPPmYst27m2Voktu7MxHlQYL9PDdIXxPXmyzM7Fy8yPQdl+UOXqLns0i2Z+fM/OY1Wkz89ubowuy1zcjuAKsfuS7JRbad9mT5aZ77P7klk4pavJNrjCYJvut9mcU0zX3XZvjH3nTRPLN998c8+zHh9ttfvpR6PRiOOPPz6OP/74GcvZ398fT3/60+PpT3/6jOUEAAAAHqkWP/0AAAAAiFCoAAAAAGqkdj/9IKfbakUxPj7p9Ss9mST9m/387wdn+neklVT5UV7yGQxFI/e74Cq/J24nf5tZ5bE4+9TPHSv0g/TzXGbjB6HZ56Mk+2xERKMvl7NboTafbW+3k38uRl6VAT63jxp9+cuJopmLLdLPyanQ1uwzmiqMtY2+5LxQ4RlE2WcJNSo8iyo9flUZ9tLPQ0g+NyT5/KGIiG47+eyiVv45OdlnbmXbGpHfR2WV673k8azy/LR0bDZlleuD9OOSZv46qErO/DX4vnO9N9WXT7Q2DMXYd1KppoU7KgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAaqNvthvA9CgazSiakz+cRZTpXGWnm4vLhe1Q5NpbFhWSdtq5uG5+30aZi+0m4yopsnH5+mjRSMY2mvmcUziveuIqbGeZ3M7GQH86Z3MoF9sczMV970lPSMVFRDzpP29JxZVVzpNOcgyqkjM5llQZDYr+3LnSPzff9wbmDeRyzsn22fylT/Z4dsY66Zydsdw81m3l579OKzf/le18zjLZ34siOxlFFI1cbHYuKgbyc1F2KMnu14iIbivXb7NxERHd8Vzf64yOp3N2RnKx3fZYOmfZze6j7HlS4W/Ts3C9F8nzukg3tkLO5DgSEVEkr9uaw9l5c2pxVQ7hdHBHBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbfbPdAKZHZ3Qkon/bpNcvu510rrLdSsV1W2P5nOO5nFHmtzOtLCsEF7mwRq7mWPT35/JFRNE/mIvrS25jRESjmQvrq7KdudhGf354LZq57Sz68rXnRt/M5nzqj3+UiouIGDpkbi5uwUA+5wG52KE5+X7Q3587Jn1VzrHk8NXu5Me91lg7Fbf9ofFU3Mjm/Fw0unk0FTf+4Eg6Z2trLmdnWz5nt507JtHN94Oy7KZjs4oid64UyTmlMZCfi/rmDuXi5g+nczYHc+3tH8qPe42+bHvz415nLHeN2dqaH0va23Kx2fO6M55va2T/zdCtcE4nx4MyeU5HRBTNXH8vmvn+npvlI7L/uumOT21sb2/JzT/TxR0VAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC10TfbDWB6dLZvibLYPPmAbplP1pfrNo3+oXTKYs78XFyzQhcvimRYLu6/onNhjVzNsWg2c/kiomjmcr7p6IPSOZ92QK4PPfu7d6Zzlu12Kq49PlYhZysX18m1tZpkny3ydfIiGVth1EtHF9n9ExFRdpNhnXzObjJnWSFnmdu3ZTIumy8iomwlz7F2hfEge15X6AdlmWxvss9GRHrOjaI/nzN9fiavD6r8fTC7f5LXBxERRTa2wrVXYyA3zxf9A+mc2diiWaHvZa/bkudYpWvTvuR2Vhhr07EVroPK1ngqrju6PZ2z/VBynE7v26nFdbfdm8wzPdxRAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANRG32w3gOnRmDMvmvMWTD6gLNO5ynZrRuMiIrqj23KBnXY6Z3o7y246Z3SzsbnjefmznpbMF3HcgvmpuCWHHJXOmXXTMxamY0/+5D/nAosinTOKXA25aOaH9GKgPxfXN5CLq7J/kiX2RnK/7ghupsKKRj5n2c2d10WVca/byQVWypkb94rsWJuf/qIYyp1jRTEnn7MveV4n+2xEfixpZNsaEUV/MmcyrkpsYzA3XjaT42xERHM419a+ubkxOiKiP5mzOZjve30Dudi+gfyc0mhUmI+Sspfh2XmhM54c2yOiM54ba9utfM72aC62yna2R3LX/Z3R/L9vOiPjqbj2yFgy3+jU1u/bHrlM08MdFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtdE32w1geoyt/lYUg6smH1AW+WRFmQ3MpyyyNbUKtbiimYtr5k+rIpuzkcv5qdt/lMsXEX/21FPSsfuSxpz5qbiiL3ksIyKS/b3CWR1lt5uLa42n4jqjo6m4iIhybGsurjOSz9lpZSPTOaObjG1UGPfKZM6iQu9LtrcokmNtdpyNiKLoz8X15eIiIqJvIJezwlwUyfErP1dXbG9arr9nx8vIxkVEWeZi0+dJRJTJc6XKsSz6crFFo8Kcm+0HnU4+Yzs3p5Sddi5hlb6XnovSKaOR7Qf9+bG2OZAbaxuDubiISF/vZa/4Gs2ptbVsVJi7poE7KgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDa6JvtBjA9+g5+bDTmHD4zybrtVFjZ7eRzlsm4Ip8yrcw2duZz/svaDemU/3rP1am4ollh2Gn253L25XPmY/M5v7j1HenYmXbB4hWpuKLZzCdt5GrsRTKuSs7odNMpO6MjubhtW9I5u6OjucAyv51RJAfqbB+qMEQXzWQ/yG5jRJTd5L5ttfI5t29LxXWrzPPJ7SzLCjmjQr9NqdD5yuS1VzvfDyJ7PCv09/Q+qpKzqDAfZWXHzOQxKTtV+kGu78WsnJsV+kEjed3WyF2bRkQUzcFcXF8ybmjBlNbvbr8vlWe6uKMCAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2+ma7AUyPb1/0tXjcUfNmuxl7tPjzr03HDiyYk4rrnzuQztmc05+L62+mc3Za3VRca9t4Lm7zSCouImL0vgdScWP3r03n7Gy+MxXXbW1N57xm8b/nAnOHZNackDzH7u28MxV34B1npeIiIhpzD07FNecekM7ZnDM3Fde3IJ9zzsGHpOKaw4enc/YN5y4LmkP5y4nOSDsV1x5tJfPl4iIixh/KjZmd7WPpnJ2R3PjVKbelc0Ynt4+KMjeHRUR0y1w/KNtVtrOTDCxzYUX++iAaub8tFs3ctUxERPQN5nIW+WuvKJJ/Q23k923RTMZm2xoR0c31vbKbO08iG1cpZ348SJ9jZfacrrCdybErIiI6ubmhm4wrWtuntH45uj6VZ7q4owIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNb/2IiNHR0bjxxhvjtttui02bNsXAwEAsWbIkTj311DjmmGNmu3kAAACw39jnChUvfvGL4xOf+ETPZ0cffXSsWbNmyt+1fv36WLFiRXzkIx+Jbdt2/XqrU045JV7/+tfH+eefn2kuAAAAMAX71E8/vvCFLzyiSJF13XXXxUknnRR/8zd/s9siRUTEd77znbjgggviwgsvjPHx8WnJDQAAAOzaPnNHxYMPPhivetWrpuW7vvGNb8S5554bIyMjPZ8vXLgwli5dGps2bYq77747Op3OxH/72Mc+Flu3bo3PfOYzURTFtLQDAAAA6LXP3FHxmte8Ju65556IiJg7d276ezZt2hQvfOELe4oURx99dFxxxRWxcePG+O53vxurV6+ONWvWxCte8Yqe2M997nPxrne9K50bAAAA2LN9olBx3XXXxYc+9KGIiGg0GvHGN74x/V1vf/vb4957751YXrp0adx4441x/vnn99wpsWTJknj/+98ff/mXf9kT/+d//uexadOmdH4AAABg92pfqBgZGYmXv/zlUZZlRET8/u//fjzlKU9Jfdf69evjfe97X89nH/zgB+Pwww/fbczrXve6WLZs2cTygw8+GO94xztS+QEAAIA9q32h4vWvf33ccccdERFx1FFHxZvf/Ob0d33iE5+IrVu3TiwvW7YszjrrrD3GFEXxiDs4Lr/88onCCQAAADB9av0wzW9/+9vx7ne/e2L5b/7mb2LevHnp77vyyit7li+66KJJxZ155pmxdOnSWL16dURE3H///fHNb34znva0p6XbMt223PnvsXls8uvPHcznGurPxT3w/7s6nXPBl69Ixf3k9AvSObNeuPSudOwRi4dTcQfOaeYSVqi3bRzp7H2lXXjgofzbc177l89Lxf3uC/8xnXPRP38nFXfQYPJEmSUH9CX7UNIXDv9BOvb8B89OxZXdXJ+NiOiMjux9pV3l7FTIuS03UBf9A+mcfcPZ2Pxgkq37F81cny2KfFuLZu7vO42h/DGJInfdUzTzY1A5PCcXV6G/N9qtXM4Kb2QrW1O4cHp4XKedjBtNxUVElO3tubjx3DZGRJSd5L7t5o7lfyXNhSXjdgR3k3H5lFEk/wlW5M7roqjwt+lsbKPKdcXM/0E4vY8qvWMhlzP9Xoep9vXsuTFNantHRavViosuumjizRvLly+P5z//+env27p1a1x//fU9nz372c+eVGxRFHH22b0Xxl/84hfTbQEAAAB2rbaFire85S3xwx/+MCJ2vDb0ve99b6Xvu+WWW6LV+nmFd+nSpXHYYYdNOv7000/vWf7+979fqT0AAADAI9WyUHHrrbf2vG3jbW9725SKCruycuXKnuWTTjppSvE7r7/z9wEAAADV1a5Q0e1246KLLorx//rN4TOe8Yz47d/+7crfe/vtt/csH3nkkVOK33n9O++8M0ZH8781BAAAAB6pdoWK9773vfHNb34zIiIGBgbiAx/4QBTpJ4b83Lp163qWlyxZMqX4xYsXR1/fzx980+12Y8OGDZXbBQAAAPxcrd76sXr16vg//+f/TCy/7nWvixNOOGFavvvhryWNiJg7d+6U4ouiiOHh4diyZctuvzNr3bp1sX79+inFrFq1alpyAwAAQJ3UqlDxO7/zO7Ft27aIiDjhhBPiz/7sz6btu3cuKgwNDU35Ox6tQsWll14aK1asmJbvAgAAgH1ZbX76cdlll8U111wTETvuXvjABz4QAwMV3ju+k52fJ5H57sHB3nfaj4yMVGoTAAAA0KsWhYr77rsvXv3qV08sv/zlL49nPOMZ05pj5zsofvawzqkYGxvb43cCAAAA1dTipx+/+7u/G5s3b46IiMMOOyz+6q/+atpzzJs3r2c588aOne+g2Pk7sy6++OJYvnz5lGJWrVoVF1xwwbTkBwAAgLqY9ULFpz/96fj85z8/sfye97wnFi5cOO15di4q/OxZGJNVluWjVqhYtGhRLFq0aFq+CwAAAPZls/7Tj9e85jUT//95z3te/Pqv//qjkmfnQsDatWunFP/Tn/402u32xHKj0YhDDjlkWtoGAAAA7DDrd1T87CcfERFXXXVVFEUx5e+48847HxH3ve99L04++eSJ5eOPP77nv991111TyrHz+kcffbRnVAAAAMA0m/U7KmbKCSec0LN86623Til+5cqVe/w+AAAAoLpZv6NipjzucY+L/v7+aLVaERGxZs2auO++++Ixj3nMpOJvuOGGnuWH362xLxrqn+0WTM2Dz7kgFbdh6/S2YzI+ufqofPDqXNiJt341FTd8+IJcwoiY95i5qbi/+ccXp3NmffXLv50PHtzHTpZ9xNMHHkjHdrbcl4vbmq/NT/1evx3KdGREdFu5uM7Y3tfZjbLT3vtKu06azhmN3KvIi4Hcc6IaA/NTcRERjXkLU3F983NxERH9B+S2c2BhboyOiIjE3a0REWWnm07ZGcv1vc7W7RVyJmPbubaWZZnLFxFFIzd+Fc1mPmdf7txsDAymczaHc3crFwP5f9I0+pP7NnlMItKnWFqVc7Ps5mK77fy8UGabm2xrRETZyZ2fZYXt7LZz83zZysV1W1N762V3y9po35FKNS1mvVBx5ZVXThQPJusHP/hBz+tMFy9eHP/wD//Qs85xxx3Xszx//vxYtmxZfPWrP/8H3dVXXx2/+Zu/udd8ZVnGNddc0/PZC17wgim1GQAAANi7WS9UPPOZz5xyTF9fb7OHhobi7LPP3mvceeed11OouOyyyyZVqLj22mtj9eqf/6l78eLFceqpp06hxQAAAMBk7DfPqIiIeNGLXhRz5/78Vsjrr78+vva1r+0xpizLWLFiRc9nL3vZy6JR4XYvAAAAYNf2q39tL1q0KH7v936v57OXv/zlce+99+425i1veUtcf/31E8sLFizoeaUqAAAAMH32q0JFRMRrX/vaOOywwyaWV69eHaeddlr88z//c89DjtauXRuvfOUr45JLLumJv+SSS+Kggw6asfYCAADA/mTWn1Ex0w466KD45Cc/Gc95znNidHQ0IiLuvPPOOP/882PhwoWxdOnS2Lx5c9x1113R6fQ+xfX888/veYgnAAAAML32uzsqIiKWLVsWV1111SPujNi8eXN873vfi9WrVz+iSPGSl7wkPvnJT0Yx0+8TAgAAgP3IflmoiIh41rOeFbfeemu86lWvijlz5ux2vV/+5V+Oz372s/Hxj388Bgfz74UGAAAA9m6f/OnHGWec0fM8iazFixfHpZdeGu985zvjxhtvjJUrV8bmzZtjYGAgjjjiiDj11FPjuOOOm4YWAwAAAJOxTxYqptvw8HCcddZZcdZZZ812UwAAAGC/tt/+9AMAAACoH4UKAAAAoDYUKgAAAIDa8IwKpmzD1pnPefC8mc85G4760odzgY27U2Gj6zbk8kXER6/9v+nYfcltm7fNdhMm7YSFc2e7CTOi++Cdqbiy7OaTlp29r7PLuHY+Z7eVzJlsa1TcRzOtaObCGv35nI2BVNj4QH4SK/rnp+IaQwfmcw7m2lv0VbmszP3trGyNpjOW49uzkbmwRq7PRuT7bdGX67MRkW9vM3+OFUWuHxT9+e1sDA2l4vrm7f6tgXvTPz83X/fNS7Z1znAqLiKiOTDz/1zMTkXdVn7+64zl5uvOeD5ndyw3z3eScVPN14mHUnmmizsqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNrom+0GMD0Wzok4eN7M5JqpPA/Xecw5qbij3vPidM7uyLZUXDk+ms5Zdu7OxbXHUnHjnfFUXETEOd1npuKuPuTf0jlnwwkL56bibtuc6z/sXdkZyQUWzXzSokgGVsnZzcWVZYWcydgqOSMZ223lsiXjIiKiyI3vZXtLPmXxQCquu3VtOmc0+lNhRd9QOmXRnxtri/45+ZyDC1JxjcHchVBjOLeNERHNObmczXn5i7a+ObnjWTSz42VEt50b97pj+fO6M5I7r1sP5c/r0XvvScV1t23OxY1sSsVFRJSjuTGoHN2Qzzmea2/Z2ZrOGWU7GZjv71Fk7xnI5pxivuz11jRxRwUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG30zXYDmB5PvvovozHviEmv/6ULrk7nevqSdam4A971wnTOaCRramU+ZdHsz6VstvNJOzNdO6ywgzqdVNjZ9zwpnfKXmg+k4v7zjnTK+NX5G1Nx7/vFufmk+4Ej/j0fW3Y25AKLZj5pIzceFH1D+ZzNObmcQ7m4iIhGM9neRoV9m1bMaFil4LKbT5nct0XfcDplNrYYqND3hnNjZnMoP9YWAwO5uOTf+coq/SAZ23ogN29GRIyObEvFdbdvSufsjuZiy7GH0jnLsWTO8XzOaG3O5eyO5/KVFa5Ny+y1YpX+nsyZbmtEvr0VtjOrymZORXdshhLtmjsqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNrom+0GMD3KdifKVmfS65/7mbMqJOumwrqtVj7l+EgurrW9Qs4tM5+zndvO6Izn8pXtXL6IyNY5i2Z/OuMPu4fmcg6V6ZxfHpubirtt88p0zn3JmT9MTiNV+l45+bFu2hRFKqws8tNsUeTOlbJ/fj7n4EG5uOFF6ZzN+Yel4hpzDs7lG56TiouIKAYHU3F9w7lxZEfOgVRcd2wsnbNs5c7P7ng+Z2d7bs5tb1qXzlm2cu3ttrfl8o3n4iIiyvZoLrBVIef45lxccv9EREQ3Ob5Xup7JXyOkNXLndZGMy16775CLLbv56/70PN/NXQ/viE32g7JC/8n223TOKV7LdKucV9W5owIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDb6ZrsBTI+y1YqyNT75gP7+Csm62cAZz1m2t+dTjm9NxXVHN+RztrbkArvtbMZkXEQ0kn2ob246ZTEwPxfXN5TOOdKYl4o7Z/3idM4oO8mw0XzK1rZUXDEn2WdbufMrIiKy25keuyLy50qRT5k9xyqc12VnLBdY4Xh2t2/MBWY3s53cxoiIkYFUWGfrQ+mUjYHk+NVopnOW47lzbErXITvpjo/kAtv5nOn+np1zu7mxPSLy416Veb4/O+fm5/ns/FdpO9MqjO8z/bfiKk0tcmNJIxm3I2d2/1T5t0YutqxwbZE+LMnAcorbWI5vjvK+e3PJpoE7KgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDa6JvtBjA9yvZolK3tk16/u30sn6szmgtsV8mZiy074+mc0W2nwoq+4XzORn8+NqWsEFvkoopmPmW3mwory8mfG4/M2cnl7LbyObP9tsznLJPbme5DzaFkvojom5MKK6qcX42BXM7++emUxUAutuivMAb1JbezyI0HERFlJzfWdse35OK2r0vFRcSU5tmeuHaFMai1beZzZsevCmNQeqyNXP/ZEZydA7Nx+fOkKJLj12yMtZWug3JjUBRV/klT5VooK3c9k+6z6Tk+ouwkx71u/ro/ktf90RnJ5yxzY0m1K+nkNXEj2d+Lqd2jULZz8890cUcFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBt9M12A5gerXv/PYq++ZMPKPKHvmg0k4HJuArKzng+uDOSjBvL5yzbybgyn3OGlVHkg7N9rzEw8zmrHJOym4vrtmY+ZyNZ7y76c3ER+eNZoR8UfcO5uIF5+ZxDB6TiGn1z0jmjyB3Psr0tnbIc25qM25SLG8/li4goW5tzge3t+ZxlJxuZzjkrc0qRnRvyc0qRzFlm922F/VqWyWuL1mg6Z4xvTIWVkZxPqqhwjVk0hnKBfXPTOSM5ThfZ8b05mIuLiEb/FP590RuYzpm9Hi7b+f6enVOK1oPpnNnrtrKb3c4pjkHd5L+Fpok7KgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDa6JvtBjBNxjZG2R6ZQkCZTpWOLPM504pmPrTYl+p4ybbOxjaW7QqhU+nj05Mzym4yrjPzOSspkmEzHBcR2f5eVurvydhGfpotGoO5wP756ZzR6M/FVRlr04HJY9IcymaMYvDoVFxjIH9Miv45ubi+/Ham+22V87rTSoWV7bF0yrKTm1PSOdvbc3ERUba25eLGt6RzRjuZszuezxm5+a/IjyQVxr0Kc0pyns/22aKTPyZldtdWuJYps7Hd3DiyIzZ7rTjz1zNF+l6Dqf1brIz83D4d9qV/iQEAAAD/zSlUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBteOtHRIyOjsaNN94Yt912W2zatCkGBgZiyZIlceqpp8Yxxxwz280DAACA/UZtChVvetObYsWKFen4Cy+8MD7ykY9MKWb9+vWxYsWK+MhHPhLbtu36FUynnHJKvP71r4/zzz8/3TYAAABgcvbbn35cd911cdJJJ8Xf/M3f7LZIERHxne98Jy644IK48MILY3y8ynuhAQAAgL2pzR0VM+kb3/hGnHvuuTEyMtLz+cKFC2Pp0qWxadOmuPvuu6PT6Uz8t4997GOxdevW+MxnPhNFUcx0kwEAAGC/UNtCxTve8Y544hOfOOn1Dz/88Emtt2nTpnjhC1/YU6Q4+uij4z3veU+cd955E0WItWvXxpvf/Ob4u7/7u4n1Pve5z8W73vWu+KM/+qNJtwsAAACYvNoWKk455ZQ444wzpv173/72t8e99947sbx06dL4xje+8YhCx5IlS+L9739/HHXUUXHJJZdMfP7nf/7n8bKXvSwOPPDAaW8bAAAA7O/2q2dUrF+/Pt73vvf1fPbBD35wj3djvO51r4tly5ZNLD/44IPxjne841FrIwAAAOzP9qtCxSc+8YnYunXrxPKyZcvirLPO2mNMURTxxje+seezyy+/PMqyfFTaCAAAAPuz/apQceWVV/YsX3TRRZOKO/PMM2Pp0qUTy/fff39885vfnNa2AQAAADV+RsV027p1a1x//fU9nz372c+eVGxRFHH22WfHBz/4wYnPvvjFL8bTnva0aW1jJZ3Rqa3fGEqnKvrn5QL75+dz9s3JBWbjIqLoG07GDaZzRpE7JYtmMmeVF9iU3VxYJ/+a37LTSsUVVXJ2c7Fl2dn7SruTbW97ezpl2dq695V2FdfekkvYGdn7OrvTzfWDSB7LiEj394hsXOTv3BttpnOmVXgbVpn9m0kjeQlTVNg/ydhucmyPiCgaA7nARn86ZxTZv2NVmVSSsem2RkQjN3cW/XNzcQP566DG3Mk9NP4RORfmr4Oimet7s/F2vLJdYZ4fz81j3bHN6Zzp+Tp9bVHhmDSSY2aRH4OKbN9rVsiZHWurjEGVxsyEKfafcmxjdLb88FFqzN7tN3dU3HLLLdFq/fzidunSpXHYYYdNOv7000/vWf7+978/XU0DAAAA/kut76gYGxuLn/zkJ7Fhw4bo7++Pgw8+OA4//PCYM2fq1eGVK1f2LJ900klTit95/Z2/DwAAAKiutoWK3/3d342f/OQnMTra+5OGvr6+OOWUU+K5z31uXHzxxXHooYdO6vtuv/32nuUjjzxySu3Zef0777wzRkdHY2go/xMKAAAAoFdtf/px6623PqJIERHRbrfjpptuije96U1x9NFHxxve8IbodPb+e5t169b1LC9ZsmRK7Vm8eHH09f28rtPtdmPDhg1T+g4AAABgz2p7R8VkjIyMxF/8xV/E17/+9fjCF74Q8+bt/iGPD38taUTE3LlTexBSURQxPDwcW7b8/IE7O39n1rp162L9+vVTilm1atW05AYAAIA6qVWhoiiKeNrTnhbPe97z4qlPfWqceOKJcdBBB0Wj0YgNGzbEd7/73fjiF78YH/3oR3vutrjuuuviRS96UVx55ZXRbO76ybQ7FxUyP9l4tAoVl156aaxYsWJavgsAAAD2ZbX56cezn/3suO222+KGG26IP/uzP4uzzz47jjjiiBgeHo7BwcE4/PDD4/nPf368//3vjx//+MePeAvHVVddFZdeeuluv3/nn5EMDEz9FTSDg72vsRoZqfB6PQAAAOARalOoOO200+IXf/EXJ7XukiVL4pprromnPe1pPZ+/+c1vju3bd/1e4p3voBgfn/r7lsfGxvb4nQAAAEA1tfrpx1QMDQ3Fxz72sTjxxBOj3W5HxI5nPXzlK1+JCy644BHr7/z8il09qHNvdr6DYk/PxJiKiy++OJYvXz6lmFWrVu1yOwEAAGBfts8WKiIijjvuuDjvvPPic5/73MRnky1UbNu2bUq5yrJ81AoVixYtikWLFk3LdwEAAMC+rDY//cg666yzepZvv/32Xa63cyFg7dq1U8rz05/+dOLOjYiIRqMRhxxyyJS+AwAAANizfb5QceSRR/Ys7+41n8cff3zP8l133TWlPDuvf/TRR3tGBQAAAEyzfb5Q0d/f37PcarV2ud4JJ5zQs3zrrbdOKc/KlSv3+H0AAABAdfv0MyoiIu6///6e5UMPPXSX6z3ucY+L/v7+iULGmjVr4r777ovHPOYxk8pzww039CyffPLJU2/so2ju034/mgccNfmAYhZqVGWZDu3upgC115TtXFxERNka2/tKu4pLvFFmIraTzNlp732lXQbmj0k0ZqEPFUUurJkf6hqDw7m4ofwzbLI5i74K29nXzAVmj0kuLCIiup1OKq5s5c/NzmjuddSdbQ+lc3a3P5iLG92SzlmObc3FjefauiM2196yM/WHYv9XYC4uosKYWWGsTcdWOMmyJ2hR4bIyO5ZUmMfKTm5MKLffk4rrbs2PQVF2k4HZuAqqdPdscJVJpUjOf1WuobLjUJm93puFftBI7teI9DEpisF8zkYytjknn7N/biqs6Mvd1V80p7aN2X+XTJd9/o6Kb3zjGz3LO/8U5Gfmz58fy5Yt6/ns6quvnlSOsizjmmuu6fnsBS94wRRaCQAAAEzGPl2o2Lx5c3z2s5/t+Wznh2s+3HnnndezfNlll00qz7XXXhurV6+eWF68eHGceuqpU2gpAAAAMBn7dKHi1a9+dWzevHlieWBgIJ773Ofudv0XvehFMXfuz2+xuf766+NrX/vaHnOUZRkrVqzo+exlL3tZNGbjtncAAAD4b64W/9p+61vfGt/5zncmvX673Y4//uM/fsQdEa985Sv3+MyJRYsWxe/93u/1fPbyl7887r333t3GvOUtb4nrr79+YnnBggXxmte8ZtJtBQAAACavFoWKf/3Xf40nP/nJcfrpp8d73vOeuPnmm6PdfuTDYh588MH4p3/6p3jKU54Sf/3Xf93z34499th4wxvesNdcr33ta+Owww6bWF69enWcdtpp8c///M9RPuyhOGvXro1XvvKVcckll/TEX3LJJXHQQQdNdRMBAACASajVWz9uvPHGuPHGGyMiYnBwMJYsWRILFiyIZrMZGzZsiDVr1kS3+8in1h522GHxL//yL3HwwQfvNcdBBx0Un/zkJ+M5z3lOjI7ueGL4nXfeGeeff34sXLgwli5dGps3b4677rorOjs9Wf7888+PV7/61dOwpQAAAMCu1KpQ8XBjY2Nxxx137HW9c889Nz784Q/HokWLJv3dy5Yti6uuuiqWL18eGzdunPh88+bN8b3vfW+XMS95yUvi8ssvj6LK648AAACAParFTz8uueSSeOUrXxmPe9zjotnc+3tz582bF8uXL49/+7d/i6uuumpKRYqfedaznhW33nprvOpVr4o5c3b//ttf/uVfjs9+9rPx8Y9/PAYHK7ybFwAAANirWtxRcc4558Q555wTERHbt2+PW2+9NdasWRP33XdfbN26NbrdbixcuDAOPPDAOOmkk+KXfumXJlXQ2JvFixfHpZdeGu985zvjxhtvjJUrV8bmzZtjYGAgjjjiiDj11FPjuOOOq5wHAAAAmJxaFCoebs6cOfHkJz85nvzkJ89YzuHh4TjrrLPirLPOmrGcAAAAwCPV4qcfAAAAABEKFQAAAECNKFQAAAAAtaFQAQAAANRG7R6mSc62b38oojk86fWLspPOVc5CZD5lhZzp2Co5uzMbF9m4iMj2oXRbK+Ss1PeKZNhs1IFnYd8WA7m4/oW5uIgoBg/KxfUfkM85MD8X2D8vn7Nv8mN6T1yjP5+zf/ev63404iIiYs7iVFjZbefyZeMiouyOJ3Pm59x8eyuMe+nxKzleRkQk923Z2pbPmZ7Hcq+rL2bj+qDK3ySLWZj/knNKUWGsjYGFqbDG8MHplI3hA3Nxcxam4ppDFeai/uQ836jQD5L9vWznx/duazSXczQ/BnXHcrHd8S2puHJ869QCOrmxbrq4owIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACojb7ZbgDTZOSeiGLyh7OM4lFszO6z7lM5y2Rs2cnnnGnFbPSDKvXRZHsrbWe2D83Gvq2QM72PWrmwzrZkvohydG0ubjZq80WFnEUzGbiPbWdWdoyuMh5kj0ljMJ+zb14qrBhYmE6ZjS0GDsjnHMzlbMxdnM4ZzdxxKZoDyXzJuIgo+oZycc3+fM5m8p8JjQrnWDd3DVV2knNRRJTjo6m47thD6ZydretSce0Hbs0lHNuUi4uIbmtzLnA8v3+i/WAurjuWz1nm+1A+Z/a6NptwioGz/G8ad1QAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtdE32w1gejSPPC+KwUMmH9DI16iKaOYCK+SM5kAqrEjGRUQUfYO5uEZy/0RENHOxRTN3Khd9/am4iIiikRw+iiKdsyzLZGAnnTOyOSO/nRHZ7ayQMbudnW4uX7uVyxcRZWt7Kq7b2lYh50gusD2Wz9kdzwV2K/T3bjsVVnbzxzM6ozMaV62tuX5QJuN25Mz193Lb5nTKckuuH0SZjIuIKJPHpdL4PsPbWWn/ZAf43Bg9e7LXilXm3NlQYcKe6XzZvlfpkGSDKyStcH0648oZ2j9Vxtdp4I4KAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDa6JvtBjA9Ohu+H0VzzuQDimY+WTa2Us5kTa2o0MUbyfaWRT5nJGPLZLoyGxgR3XYuZTJuR85WLq4zms9ZjiUDK2xnmY2tkrObDUyGVeh7WdlxJGKWxr3k+NUYqJByCvPIw/UdkM85mIsthh6Tims0h1NxERFlNzcelGMP5XOOb84Fjm2skHNTLrCzJZ0zOttycVXmlEiOe+nxaxbGvVlR5TpoFqTnhgrbWWRjZzou8tfDlczCtUU6dhb6ezrlVLdxdscsd1QAAAAAtaFQAQAAANSGQgUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtdE32w1gmrQeirIzNvn1iwqHvmjObFxE5Gtqs1CLK2Y+ZUSZDEvGRUSU7WxghZzdfGxWkW3vLLS1rNL5srHZ/VOhH2SVnSrBubBiNsagKjmTsc3+dMaiOZyLG1iQi2vk2xrjufO6rNL3Wg/lcibjIiKiszUX1x3P50yP7/vSnFJl3JvpMbqK2chZQZVroXTO5FhbZPtBleuD7HlSIWd2Hqv075tZ2LfZrjdjbW1HxEgyV3XuqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqI2+2W4A06P/sb8ejTmHTSGirJAtGdtp5TO2x3NxrdF0zujkYrvJtkZERNlOxnXzObPSXahC3yuKfGxWWeVcycpuZ4W2Zrez7OTCuhXOk05yPEie0xER0R7JxXWScRHpfVtJ8riUIz9Np+yM3JsL3Jz8W0uV/Zoeo6ucm9mcybiIiMZAMrDCGN0YzMVV2c7s3JmNqzSHzcK8UOV4piXPz26VfjAb117ZOTebs8oYlA/dt2T7+yycJ+mxZIpxs/Hvi4dxRwUAAABQGwoVAAAAQG0oVAAAAAC1oVABAAAA1IZCBQAAAFAbChUAAABAbShUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtaFQAQAAANSGQgUAAABQG32z3QCmR+tHn4hoDE4+oOxWyFZWiJ3pnFXamqzjFVXqf9nYfemYVFEkw2ajJptsa0TMzr7Nyh6TKvsnGVtW2a/JMbPs5FNmx+kqOWej7xXNmc1X6ZhkY6vs11kY97LnSqVhLzvn9udzFvvQWFtp/EpKH88KHSHbb5tV5vnkvq1yLd0dS8aN5+LKdi5uR3CF2BnOORvnyWyYjTF6FrijAgAAAKgNhQoAAACgNhQqAAAAgNpQqAAAAABqQ6ECAAAAqA2FCgAAAKA2FCoAAACA2lCoAAAAAGpDoQIAAACoDYUKAAAAoDYUKgAAAIDaUKgAAAAAakOhAgAAAKgNhQoAAACgNvpmuwFMk4EDo2jOmUJAN52q7IzlAttb0jkjm7Ns53OW2X2U37dRlvnYXMIZzrcPKopsYIWkyRpyUWFIbyRji/6ZzVclZzMZtyNpLiw9jkR+/Co7FXImYyttZzZndv9UmRdm45hk922V8X0Wxr30WFvhb25Fdqxtzmy+SrFV5qJk36vS37vZ83NfuvaqoJGcx8oKfa9sJeMqHJNsv02PI7MkPZYk46a6X8tOhXOyOndUAAAAALWhUAEAAADUhkIFAAAAUBsKFQAAAEBtKFQAAAAAtbFPvfXj9ttvjx/84Aexdu3a2L59ewwPD8fixYvjF3/xF+OJT3xiDA4Opr97dHQ0brzxxrjtttti06ZNMTAwEEuWLIlTTz01jjnmmGncCgAAAGB3al+o2LJlS7zvfe+LD33oQ7F69erdrjcwMBBPfepT43/+z/8Zf/AHfzDp71+/fn2sWLEiPvKRj8S2bdt2uc4pp5wSr3/96+P888+fcvsBAACAySvKsr4vD/7iF78YL3/5y+OnP/3ppGMWL14c999//6TWve6662L58uXxwAMPTGr93/zN34wPfvCDMTAwMOn2PFpuueWWePzjH//zDw54YhTNOVP4hvy7jcvOWC6wvSWdMzqjubjsO+8jKrz/eV96l3dtT//6SL+Tu8q7vJO/yisq1J4bydgi+U73bL7Zypk9nlXeI58dv8pOhZzJ2Erbmc2Z3T9V5oXZOCbZfVtlfJ+FcS891lb4FXORHWubM5svIvLbWWUuSva9Wenv+9K1V0T+/EzGVTomrWRchWOyv0iPJcm4qY4HZSeiu31i8eabb47HPe5xydxTV9s7Kt71rnfFH//xH8fOdZShoaE4/PDD45BDDomRkZG47777Jl1oeLhvfOMbce6558bIyEjP5wsXLoylS5fGpk2b4u67745O5+cn9sc+9rHYunVrfOYzn4kiPaECAAAAu1PLh2ledtll8Ud/9Ec9RYrnPve58S//8i+xefPmuOOOO+Kmm26K//zP/4z169fHPffcE3//938fv/Zrvzapux02bdoUL3zhC3uKFEcffXRcccUVsXHjxvjud78bq1evjjVr1sQrXvGKntjPfe5z8a53vWv6NhYAAACYULuffqxatSp+6Zd+KUZHd9zq39/fHx/96EfjxS9+8aTiN23aFAceeOAe1/mzP/uzeMtb3jKxvHTp0vjGN74Rhx9++C7X/7//9//GJZdcMrG8YMGCWL169V7zPJr89GOS/PRjbwlnON8+yE8/9pLTTz/2yE8/HsWcfvqxl8B8Tj/92Eucn37skZ9+TCbpzMb56Uc9+enHHtXujorf+Z3fmShSRER8/OMfn3SRIiL2WjxYv359vO997+v57IMf/OBuixQREa973eti2bJlE8sPPvhgvOMd75h0mwAAAIDJqVWh4sorr4xrr712Ynn58uWxfPnyac3xiU98IrZu3TqxvGzZsjjrrLP2GFMURbzxjW/s+ezyyy9/xPMzAAAAgGpq9TDND3zgAz3LOxcHpsOVV17Zs3zRRRdNKu7MM8+MpUuXTrwi9f77749vfvOb8bSnPW3a25gytjHKxq5fr7pr+8ntyJXMxi2PM3wr4GzcGlzpQbSzUFtN35Y+vc2YlKLKLe0zfAt0ZxZu147srZKR/9lIY2jmc1aSPa+r5EyOtZ3sz3GqzCez8fOEZFylP6bMwpwy4/Nf5PtCdqydjV/jVDs59xP70h8eZ2MMSr7tsNiX9mvEPnVdO1M/Gem2e376MdNqc0fFPffcE1/+8pcnlk8++eRp/w3M1q1b4/rrr+/57NnPfvakYouiiLPPPrvnsy9+8YvT1jYAAACgRoWKf/3Xf+15FeiZZ5457TluueWWaLV+/kCYpf//9u49OsryTuD4bzK5kysBEkkgFxKuiyGJwCmUAGuoF6hQeyiU5XgpWhArdbugFTzl2C3GC1pht1hROKusuGK5qditiUYUaSm2sagJgchFE+4JIYHcJpln/+Awm3cuycz7TpI3w/dzzpyT583zvM8zeX95n3l/817S0yUpKcnr9pMnT9aUP//8c38NDQAAAAAAiIkSFQcPHtSUs7OzHT+XlpbKsmXLJDs7W+Lj4yUyMlLS0tJkxowZsnbtWqmurvaqj/Lyck159OjRPo3Rub7z+gAAAAAAgDGmTVRkZGTI5cuXZdGiRZKbmyv/8R//IYcOHZK6ujppamqSkydPSnFxsaxYsUKysrJk5cqVmrMl3KmoqNCUhwwZ4tMYneufPHlS84QSAAAAAABgjGlupllZWakpBwUFSX5+vpSWlnbZtqmpSQoLC+XgwYOyY8cOiY6Odlvv3LlzmnJKSopPY0xMTJTg4GBpa7t6EyW73S41NTWSnJzs03rcjev8+fM+tXH+ewEAAAAAEAhMkaiw2+3S0NCgWbZs2TJHksJiscisWbPk9ttvl5SUFLly5YqUlpbKli1b5NSpU442xcXFcs8998j27dvd9tPxsaQiIv369fNpnBaLRSIiIjRjdV6nHhs2bJAnnnjC8HoAAAAAAOjrTJGouHTpkiinx1L9/e9/FxGRhIQE2blzp0yZMkXz+3nz5snjjz8uixcvlq1btzqW79ixQ1577TW56667XPpxTiqEh/v+2LjuSFQAAAAAAICrTHGPCk8H+1arVfbs2eOSpLgmKipKtmzZ4vKI0SeffNIl8SEiLveTCA31/bnAYWFhmnJTU5PP6wAAAAAAAO6Z4owKT2c23HfffTJx4sRO2wYFBcmLL74oWVlZYrfbReTqTTP37t0r06ZN67Sf1tZWn8fa0tLS6Tr1WLp0qcydO9enNpWVlTJnzhzDfQMAAAAAYCamSFRERUW5XX7//fd71T4jI0MKCgrk/fffdyxzl6hw7kfPEzucz6DwNHZfDBo0SAYNGmR4PQAAAAAA9HWmuPQjIiJCrFarZll0dLTk5OR4vY6pU6dqyp999plLHeekwpUrV3wYpYhSqlsSFQAAAAAA4CpTJCpExOWMgszMTAkK8n54I0aM0JSdH0Xqro+qqiofRihy9uxZx6NJRa5edjJgwACf1gEAAAAAADwzTaJi1KhRmnJMTIxP7Z3rX7x40aWOczLjm2++8akP5/qpqal+uUcFAAAAAAC4yjSJitGjR2vKzjet7Irz/SYiIyNd6owcOVJTLisr86mP8vLyTtcHAAAAAACMMcXNNEVEcnNzNeWzZ8/61N75Uo+EhASXOmPGjJGQkBCx2WwiInLixAk5ffq03HDDDV718emnn2rK48aN82mM3UrZRFyfyOpZkO+PZnUIjtbXzkifenNqqq3rOp7YbTrb+f40GYd232/werVPve0MjFXs+pr5Eqcu2nW2s+jv0qIz9vS2u9pYZzNr13U8CQrR2S5CX7tg/ff3sQS7JqK9YtXZTkTEqnO6bNe5HxGRrI1DdbU78pOvdPcptgad7er192nX+Zhv3fsvvfsREVE693uG6N1pGtjv6WZgB29obtDJ0sN/IyPzgtI7L/TCXNQrsWfgfeqOAyPvsy/Fnt79Xm/EgQG6P+/p/Pwkov+zl95493mT9O42NM0ZFTNnztTck+L48eNSW1vrdfu//e1vmrLzZR4iV2/QmZ+fr1lWVFTk1fqVUlJcXKxZ9v3vf9/r8QEAAAAAgK6ZJlExaNAgmTx5smbZjh07vGrb1tYmO3fu1CxzfjTpNXfccYemvGnTJq/6KCkpkePHjzvKiYmJMnHiRK/aAgAAAAAA75gmUSEisnjxYk352Wef9epeFS+//LKcOXPGUY6JiZFbbrnFbd358+dLv379HOWPP/5YPvzww07Xr5SSJ554QrPs3nvv9empJAAAAAAAoGumOtL+8Y9/LGPHjnWUjxw5IosXLxa73fO1UQcOHJBHHnlEs2zp0qUSGxvrtv6gQYPkZz/7mWbZfffdJ6dOnfLYR2FhoXz88ceOcmxsrKxYsaLT9wIAAAAAAHxnqkRFUFCQ/Pa3vxVLh5vavPrqq3LLLbe43IPi0qVL8vzzz0tBQYFcvnzZsXz48OGycuXKTvt55JFHJCkpyVE+fvy4TJo0Sd5++21R6v/v5lRVVSVLliyRVatWadqvWrVK+vfvr+s9AgAAAAAAz0zz1I9rbr75ZiksLJRf/vKXjmXFxcVy0003SVJSkqSkpMiVK1fk66+/ltZW7R2/ExIS5A9/+INER3f+VIr+/fvLm2++KbfccovjsaYnT56U2bNnS1xcnKSnp0tdXZ1888030t6uvTv47NmzZfny5X56twAAAAAAoCNTnVFxzaOPPirr16+XkBDtI1vOnDkjn332mZSXl7skKUaMGCF//vOfNZeOdCY/P1/27NnjcmZEXV2dlJaWyvHjx12SFAsWLJA333xTc8YHAAAAAADwH1MmKkREHnroITl06JDMmzfPJWHRUXp6uqxbt04OHTokWVlZPvXxz//8z1JWViYPPPCAREZGeqyXk5Mj27dvl9dff13CwsJ86gMAAAAAAHjPdJd+dDRy5Ej5n//5H6mvr5f9+/fL0aNH5dKlSxIVFSWJiYmSm5srI0aMMNRHYmKibNiwQZ577jnZv3+/lJeXS11dnYSGhkpycrJMnDhRMjMz/fSOAAAAAABAZ0ydqLgmJiZGbr31Vrn11lu7rY+IiAi5+eab5eabb+62PgAAAAAAQOdMe+kHAAAAAAC4/pCoAAAAAAAApkGiAgAAAAAAmEafuEcFvBAUIhIU6kN9A08v0dnWYu2nv8/QOH19WvTn4lR7s76Gtsv6+2xr0NewvUlfO3uLvnZG2tpbu67jiWrvuo77hgb6tOtsqLediFisOhvqbSeiO2+t+2nNerel9E4c6JwuszbeoLtHe2ubrnaZG4br7vPYCn3/18rIvqRdZ9s2fftaZWAfLe0627bpnE9ERJTefa3NQJ96/8eM7Pf0/n8aeWS83rY62/XK0+0NdKp7/uuNObc3GNmgev9GRuYxvXolcPWxGIl3vf/XRva1np9s2SlrlL52Ro7/egFnVAAAAAAAANMgUQEAAAAAAEyDRAUAAAAAADANEhUAAAAAAMA0SFQAAAAAAADTIFEBAAAAAABMg0QFAAAAAAAwDRIVAAAAAADANEhUAAAAAAAA0yBRAQAAAAAATINEBQAAAAAAMA0SFQAAAAAAwDRIVAAAAAAAANMgUQEAAAAAAEwjuLcHAD8JChOxhntfX9n199XerKuZ0tlORERsdfr6tBjIxen9G6l2A33qbKv3fQaF6WsnImLRufsw0qey6WvX3trzfaq2XuizSX+fonS2sxjoUx+9IzXEou99Hpmrf5odVbRQV7vyW3fr7lOsOv8/e2Nfors/AzEbFKGvXajOdiL6/8XsBvZB9hZ97Yz8c1qsOtv1xjyv829raF7Q26eBz3t6P5MoA3Ou3iAy8j5199krs5FOfWmsBvS5t6nz2Ki9UV+7oFDf6hs5pvEDzqgAAAAAAACmQaICAAAAAACYBokKAAAAAABgGiQqAAAAAACAaZCoAAAAAAAApkGiAgAAAAAAmAaJCgAAAAAAYBokKgAAAAAAgGmQqAAAAAAAAKZBogIAAAAAAJgGiQoAAAAAAGAawb09AOjT0tKiXWBvcV/RE2X332B6gsWqs52BXJzev5Fq19+n9PB2MRIHuv8+bQb61NnWUJ86t6eh/zG9f1tloE+9bS0G+uxL9L5P/fuDluO1+hrabbr7FEtvbE8D/596GHmPhv7HdNI7XCNzkb1VZ5/6u9Q/z/fC9tQ9FxnYJrrbGpnn9c5/Rt6n3vmvNz7X9sL+QLe+NFZ0qaeOUZz6cTn+7GYkKvqob7/9Vrug+Vv3FQEAxun9jGfgs+GxRdv0N9arh3MGAADAVzqTgUa+yJCrx5+5ubmG1uELLv0AAAAAAACmQaICAAAAAACYhkWp3rjgEkbV1dXJ3r17HeUhQ4ZIWFiYo1xZWSlz5sxxlHft2iWZmZk9OUT0YcQPjCB+YBQxBCOIHxhB/MCoQImhlpYWze0Gpk6dKnFxcT3WP/eo6KPi4uJk9uzZXtfPzMyUMWPGdOOIEMiIHxhB/MAoYghGED8wgviBUX05hnrynhTOuPQDAAAAAACYBokKAAAAAABgGiQqAAAAAACAaZCoAAAAAAAApkGiAgAAAAAAmAaJCgAAAAAAYBokKgAAAAAAgGmQqAAAAAAAAKZBogIAAAAAAJgGiQoAAAAAAGAaJCoAAAAAAIBpBPf2ANA9Bg4cKKtXr9aUAW8RPzCC+IFRxBCMIH5gBPEDo4gh/7AopVRvDwIAAAAAAECESz8AAAAAAICJkKgAAAAAAACmQaICAAAAAACYBokKAAAAAABgGiQqAAAAAACAaZCoAAAAAAAApkGiAgAAAAAAmAaJCgAAAAAAYBokKgAAAAAAgGmQqAAAAAAAAKZBogIAAAAAAJgGiQoAAAAAAGAaJCoAAAAAAIBpBPf2AOB/X3/9tfz1r3+VqqoqaW1tlfj4eBk5cqRMmjRJwsPDe3t4CDDNzc2yf/9+OXz4sFy8eFFCQ0MlJSVFJk6cKBkZGb09PPhIKSUnTpyQL774QqqqqqSurk7CwsIkPj5esrKyZPz48X7fjzQ0NMinn34qR44ckfr6eomIiJDU1FSZNGmSDB482K99oXu1trbK4cOH5cSJE1JdXS0NDQ1is9kkJiZGEhIS5MYbb5RRo0aJ1Wr1S39tbW1y4MAB+fLLL6WmpkasVqvccMMNkpeXJ2PGjPFLHwhszGEwgvi5PlRUVMg//vEPqaqqksbGRomIiJDExEQZPny4ZGdnS1hYmO51E0OdUAgYO3fuVLm5uUpE3L6ioqLUz372M3X+/PneHiq6UVVVldqxY4d69NFH1fTp01V0dLQmDlJTU/3Sz7lz59SDDz6o+vXr5zHm8vLy1K5du/zSH7pPbW2t2rx5s/rRj36kBgwY4HF7iogKCQlRc+bMUR999JHhfo8dO6YWLlyoQkND3fZlsVjUtGnT1N69e/3wLtFd3nrrLbV48WL1T//0Tyo4OLjT+BERFRsbq5YsWaLKy8t199nQ0KBWrVql+vfv77GfESNGqM2bNyu73e7Hd4veNH/+fJftrHdOYw4LHKtXr+5yv9PZ6+677/a5T+In8NXX16s1a9ao9PT0TuMnNDRUffe731UvvPCCT+snhrpGoiIANDc3q3/5l3/xeoc8cOBAPvgHmH379qkf/OAHavDgwV1uf38kKkpKSro8oO34uuuuu1RLS4vxNwq/W7p0qcdEgTfb9dKlS7r6ffPNN1VkZKRX/VgsFvXoo49ywGlSycnJuuInJCRErV692ufteujQoS4/OHZ83XLLLaqurq6b3j16yttvv+23OY05LLD0dKKC+Al877zzjkpMTPQpjhITE71ePzHkHRIVfVx7e7uaPXu2S0BbrVaVnp6uxo0bp2JjY11+HxkZqfbv39/bw4ef/Pa3v/V6Z2c0UfHJJ5+oiIgIl/XGxcWpnJwclZaWpqxWq8vv77zzTg40TSgvL89tnFitVpWSkqLy8vLUjTfe6HY/IiJqwoQJqqGhwac+t23bpoKCglzWNXDgQJWbm6tSUlKUxWJx+f3DDz/cTX8FGOEuUREeHq6GDx+uxo8fr/Ly8lRqaqrbbSoi6ic/+YnXfR0+fNjth7uoqCh14403qqysLBUSEuLy++985zuqqampG/8K6E51dXUeE2K+zmnMYYGnJxMVxE/ge/75593OV+Hh4SojI0NNmDBBjR071mUu8jZRQQx5j0RFH/fUU0+5BPKSJUtUdXW1o057e7vasWOHGjp0qKZeSkoK3zIFiM4SFVFRUX5LVNTW1rqctZGamqp27dql2Xl+++23avHixS5jee655/zwbuFPHRMVcXFxaunSpWrPnj2qvr5eU6+trU2VlJSoKVOmuGzXH/7wh173V1lZ6XKaY3Z2tvrwww819Q4fPqzuvPNOl762b9/ul/cN/0lOTlaDBw9W999/v9qyZYuqrKxU7e3tLvVqa2vVxo0bVUpKist23bx5c5f92Gw2NXbsWE27/v37q1dffVW1trY66tXU1KhVq1a5JMMeeughv75v9Jz777/fsR2d9x++zGnMYYHJOVGxdu1aVVRU5PXrq6++8qof4ifwvfLKKy7b7bbbblN//OMfVXNzs0v96upqtWXLFvXDH/5QDRkypMv1E0O+IVHRh124cMHl/gOFhYUe61dVVam0tDRN/V/96lc9OGJ0l2uJiujoaDVt2jS1YsUK9dZbb6kTJ06okpISvyUqHnvsMc260tPTNUkxZ2vWrNHUj42NVbW1tbr7h//l5eWptLQ09corr6jGxsYu67e1tamf/vSnLpOnc6LBkx//+MeaduPHj/d4+Yjdbnfpa9iwYcpms/n0HtG9/vGPf/j0LU9tba3L/ZRuuOEGt8mNjl566SVNm/j4+E4PMF5//XVN/eDgYHXkyBGvxwlzKCkpcXy7GRQUpJ555hndcxpzWGByTlSUlJR0Sz/ET2A7evSoCg8Pd2yvkJAQtXXrVq/be7NtiSHfkKjowx555BFN8Obn53f5YbG4uFjTJjo6Wl24cKGHRozuUllZqb766iu3H/T9lag4d+6cy9kZxcXFnbax2+0qPz9f02blypW6+kf3ePfdd32+7rGtrU3ddNNNmu26YMGCLtt9+eWXmm+5Q0NDVVlZWadtmpqaVFZWlqavjRs3+jRemE9ZWZnLqbUff/yxx/otLS1qyJAhmvqbNm3qsp+FCxf6HKcwj8bGRjVs2DDH9vv5z3+ue05jDgtcPZGoIH4C3/Tp0zXbatu2bX5dPzHkOxIVfVR7e7saOHCgrm80nU/d3rBhQzePFr3JX4mK9evXuyTGvPHBBx9o2iUlJV1319gFom3btmm2a0JCQpdtfvGLX2ja3HXXXV71tWnTJk27CRMmGB0+TMA52fXSSy95rOt8I8W0tDSv9iOVlZWahEhISAiXPPYh//Zv/+bYdkOHDlUNDQ265zTmsMDVE4kK4iew7dq1S7Od5s6d6/c+iCHfBQn6pP3798v58+cd5YyMDJk2bZpXbRctWqQp79q1y48jQ6DavXu3puwcR55Mnz5d0tPTHeUzZ87IX/7yF7+ODT1vypQpmnJNTY00NjZ22ubtt9/WlL2NoXnz5km/fv0c5YMHD8qpU6e8HCnMatiwYZryhQsXPNZ13v/ce++9YrFYvOpj6tSpjrLNZpP33nvPx5GiNxw8eFBeeOEFR/l3v/udREVF6V4fcxiMIH4C28aNGzXl1atX+70PYsh3JCr6qD179mjKM2bM8OpD27W6HX300Udy5coVv40Ngefy5cvy8ccfa5Z973vf86qtxWKRgoICzbJ3333Xb2ND74iPj3dZdunSJY/1KyoqpLKy0lHu16+fTJo0yau+nOsqpVz2geh7mpubNeW4uDiPdZ23t7f7HxHXOY/9j/nZbDZZtGiRtLe3i4jI3LlzZdasWbrXxxwGI4ifwFZdXS1/+tOfHOVx48bJmDFj/NoHMaQPiYo+6vPPP9eUvf3ALyIyePBgSUtLc5RbW1ulrKzMTyNDIPrqq6/EZrM5yunp6ZKUlOR1+8mTJ2vKzvGLvqe6utplWUJCgsf6ztt8woQJEhwc7HV/xFBgUUrJwYMHNcvy8vLc1j179qycOXPGUQ4LC5Pc3Fyv+yJ2+p7CwkL54osvRORqAmv9+vWG1sccBiOIn8D2v//7v46kqMjVMxj8jRjSh0RFH1VeXq4pjx492qf2zvWd1wd0RLzB2SeffKIpp6amSmhoqMf6xBA62rx5s+bynZEjR8qECRPc1nXe1pmZmZ3GmjPn2KmsrJS2tjYfRoueVFZWJmvWrHGUn376aZ8+0LvD/uf609LSIuXl5bJv3z45cOCAVFZWdnl5oifET2BzTppnZ2c7fi4tLZVly5ZJdna2xMfHS2RkpKSlpcmMGTNk7dq1br+0cYcY0sf7r7NgGk1NTfLNN99olg0ZMsSndTjXr6ioMDwuBC7n+DAabydPnpTm5mYJDw83PDb0js2bN2vKt99+e6f1/R1D7LP6rldffVWWLl3qKAcFBcl//ud/erx80WjsDBw4UMLDwx2XmrS2tsrx48clKyvLx5Gju9ntdlm0aJG0traKyNV74dx///2G18scdn158MEH5dixYy6XlwUHB0teXp7cdtttsnTpUhk4cKBX6yN+AptzoiIjI0MuX74sP//5z10+64hc3X4nT56U4uJi+dWvfiUPP/ywPPHEExISEuKxD2JIHxIVfdCFCxdEKeUoh4SEyKBBg3xaR3JysqZ87tw5v4wNgck5PlJSUnxqn5iYKMHBwY5vMe12u9TU1LjEIfqG9957z+Vay3vuuafTNkZjyDlWOt5MGOZy5MgRTTLdZrPJxYsX5csvv5Tdu3drLjUMDQ2VjRs3ys033+xxfUZjR+TqJY/Hjh3TrJNEhfmsX7/ecZO4a7Hh7f23OsMcdn3xdDlzW1ubHDhwQA4cOCBPP/20LF++XFavXi1Wq7XT9RE/ga3j/bNEribP8/PzpbS0tMu2TU1NUlhYKAcPHpQdO3ZIdHS023rEkD4kKvqgy5cva8qRkZE+T+Qd76Dvbp1AR87x4Rw/XbFYLBIRESENDQ0e14m+oba2VhYvXqxZNmfOHI+n7V9jNIac69tsNmlpaZGwsDCf1oPut2HDBlm3bl2ndSwWi9x6661SWFioOc3WHaOx464N+x/zOX78uDz++OOO8mOPPSYjR470y7qZw+CsqalJ/v3f/10++eQTeeeddzp9ogzxE7jsdrtmu4iILFu2zJGksFgsMmvWLLn99tslJSVFrly5IqWlpbJlyxbN5YvFxcVyzz33yPbt2932Qwzpwz0q+iDnwNRz2k9ERESn6wQ6IuYgcnVCX7hwoVRVVTmWxcbGenWjO6Mx5Bw/7taJvmPu3LmyatWqLpMUIux/rhc//elPHU8gGzlypKxcudJv6yaGAp/FYpFJkybJmjVrpKioSKqqqqSxsVGam5ulurpa3nnnHVm8eLHLtv/oo49k/vz5mpspOiN+AtelS5c0Z6mLiPz9738Xkas3CN+7d6+8/fbbsmTJEpk1a5bMmzdPnnrqKamoqJAFCxZo2u3YsUNee+01t/0QQ/qQqOiDnK+58+WmYtc4fwvZ1NRkaEwIbMQcRERWrFghf/zjHzXLXnrpJa+utTQaQ+7OnCCG+q5t27bJd7/7XcnPz3c57dYZ+5/At2nTJikuLhaRqwecGzdu1LWdPSGGAtv3vvc9OXz4sHz66aeycuVKKSgokOTkZImIiJCwsDAZPHiwzJo1S37/+9/L0aNHXZ6gsGfPHtmwYYPH9RM/gcvTwb7VapU9e/bIlClT3P4+KipKtmzZ4vKI0SeffNIl8SFCDOlFoqIPcs7CXbvplC9aWlo6XSfQETGH9evXy/PPP69Z9sgjj8i8efO8am80hpzjx906YQ4vvPCCKKUcr8bGRvn222/l3XfflUWLFmm+Ffrkk09k/Pjx8tlnn3lcH/ufwHb69GlZvny5o3zfffd5PDjQixgKbJMmTZLhw4d7VTclJUWKi4vlO9/5jmb5b37zG49PBSF+Apen7XDffffJxIkTO20bFBQkL774ogQF/f/hdEVFhezdu7fLfogh75Co6IOcr6NzztJ5wzkL19m1eQAxd33bunWrPPzww5pl99xzjzz11FNer8NoDLn75oAY6hsiIiIkJSVFZs6cKa+88oocOnRIxo0b5/h9XV2dzJkzR+rq6ty2Z/8T2B588EHHtk9KSpJnnnnG730QQ+goPDxcXnvtNQkO/v9b9Z07d07ef/99t/WJn8DlaTt4+7ShjIwMKSgo0Cxzl6gghvQhUdEHOQdmY2Oj29OMOnPtOlBP6wQ6co4P5/jpilLqutzBBoJ3331X7r77bs0+5s4775RXXnnFp5v4Go0h5/rBwcHXxbcJgSgzM1OKioo0lwxVV1fLs88+67a+0dhx14b9jzm89dZbsnPnTkd53bp1EhcX5/d+mMPgLDMzU+644w7NMm8TFcRP4IiIiHB56kt0dLTk5OR4vY6pU6dqyu7OECSG9CFR0QcNGDBAc4Bgs9l8frxodXW1puzr401xfXGOj443U/TG2bNnHY9UErl6utyAAQP8MjZ0n5KSEpk7d65m282YMUPeeOONLh/n5sxoDDnvswYOHOhTe5jLgAED5IknntAs+6//+i+3dY3Gjoho7s7ubp3oHStWrHD8PHPmTPnRj37ULf0wh8Ed58ciV1RUuK1H/AQ25+2bmZmpuZyjKyNGjNCU3R2TEUP6kKjogyIiImTo0KGaZR2fWe8N5/r+egQYApPzTthovKWmpvJtuMkdOHBA7rjjDs3piZMmTZKdO3fqugmUv2OIfVbf94Mf/ECTdD916pScPHnSpZ7R2Dl37pwmjkNDQyUjI8PH0aI7dLzcZ8+ePWKxWLp8TZ8+XbOOkydPutT5/PPPNXWYw+CO842gz58/77Ye8RPYRo0apSnHxMT41N65/sWLF13qEEP6kKjoo5w/pJeVlfnUvry8vNP1AR0Rb9eXQ4cOyW233aa5G3ZOTo689957Pj/7+xpiCM7i4uKkf//+mmVnzpxxqee8rb/++mufbkTmHDvDhg3TXJuOwMf+B+6EhIRoyjabzW094iewjR49WlN2d/PuzjjfbyIyMtKlDjGkD4mKPqrjjchERPbv3+9129OnT8uJEycc5ZCQEJd/UqCjMWPGaCb0EydOyOnTp71u/+mnn2rKzvEL86ioqJAZM2ZovhEYNWqU/OlPf5LY2Fjd63Xe5gcPHtScxtgVYuj64HzgIHL1BotJSUmOcktLi/ztb3/zep3EDpjD4I5zYtTTJYXET2DLzc3VlM+ePetTe+dLPRISElzqEEP6kKjoo2bNmqUpFxcXe31DTeebBU2fPv26uCEL9IuOjpb8/HzNsqKiIq/aKqWkuLhYs+z73/++38YG/zl58qQUFBRoJt309HQpKioyfE+IkSNHyrBhwxzlK1eueJ1gvXLlivz5z392lC0Wi8s+EH1PQ0OD1NbWapYlJia6rTtz5kxN2dv9j7u67H/MY/fu3VJUVOTTa+3atZp1JCYmutTJzMzU1GEOgzv79u3TlJ0vBbmG+AlsM2fO1NyT4vjx4y5zU2ecE+fOl3mIEEO6KfRJ7e3tasCAAUpEHK8PP/zQq7ZTpkzRtPvd737XzaNFbyopKdFs79TUVF3rWbdunWY9+fn5XrX74IMPNO0SExNVe3u7rjGg+5w6dUoNGzZMs62Sk5PVsWPH/NbHv/7rv2rWf9ddd3nVbtOmTZp248eP99uY0HveeOMNzXYdOHCgx33D7t27NXXT0tKU3W7vso/KykplsVgc7UJCQlRdXZ2/3wp6kN45jTkMHV28eFHFxcVptu2mTZs81id+ApvzsdHLL7/sVTubzaaSkpI0bd988023dYkh35Go6MOWL1+uCdypU6d2+cGtuLhY0yY6OlqdP3++h0aM3uCvRMXZs2dVv379NOv64IMPOm1jt9tVfn6+ps0vf/lLXf2j+9TU1KgxY8a4HDSWlZX5tZ8vvvhCc9AYGhraZR9NTU0qKytLM7bf//73fh0Xel5jY6MaPny4Zrvee++9Hus3NzerlJQUrw8qrlm4cKGmzfz58/35NtAL9M5pzGHoaNGiRZrtGhoaqk6dOuWxPvET2P77v/9bs52GDx+umpubu2y3YcMGTbuYmBiPyXBiyHckKvqw8+fPq6ioKE3wFhYWeqxfVVWl0tLSNPUff/zxHhwxeoO/EhVKKfXoo49q1pWenq6qq6s91l+zZo2mfmxsrKqpqdHdP/yvvr5ejR8/XrOd4uLiVGlpabf0N2/ePJezIy5duuS2rt1uV4sXL9bUz8jIUK2trd0yNvhuxYoV6q9//atPbWpqalRBQYFmu1qtVnXo0KFO27344ouaNvHx8eqrr77yWP/111936aOiosKnscJ8jMxpzGGBp7CwUH322Wde17fZbOoXv/iFZruKiFq2bFmXbYmfwNXe3q7Gjh2r2V533313p2cu/OUvf3E5DusqiUAM+YZERR/35JNPuuxsH3jgAU3Qt7e3q507d6qhQ4dq6g0ePFhdvHix9wYPv9q3b58qKipyea1du1az3RMTE93WKyoq6vRDv1JXDzCcT3FLTU1Vu3fv1pzN8+2337ocYIqIeuaZZ7r7zwAfTZs2zWU7/frXv/YYI529amtru+zv6NGjKjIyUtNfdna2Kikp0dSrqKhQd955p8vYtm3b1k1/CeiRnZ2tRERNmDBBPffcc6q0tNRtIslut6vy8nL161//2uWyRRFRy5cv77Kv1tZWlzN/+vfvr1599VVls9kc9WpqatTjjz+ugoKCNHWXLl3q1/eO3mEkUcEcFnimTp2qRERNmjRJvfDCC+qLL77Q7A+uqaurU1u3blXjxo1z2a7Dhg1TFy5c6LIv4iewFRcXa876FBFVUFDgkgirq6tTzz33nEuSYvjw4aq+vr7TPogh35Co6OPa29vVrFmzXALZarWqjIwMlZOT43INnoioiIgItW/fvt4ePvwoNTXVZTv7+rr77ru77Gfv3r0qPDzcpW1cXJzKyclR6enpymq1uvx+9uzZXl1Tjp5lNGY6vpyTDZ688cYbLh8GRK5ebpKXl6eGDBni9vcPPfRQ9/4x4LNriYqOr9DQUJWenq5ycnLUxIkT1ejRo1V0dHSn+x1vr7ctKytT/fv3d1lHVFSUys7OVsOHD1chISEuv58wYYJqbGzs5r8GeoLRswSZwwLLtURFx1dYWJgaNmyYys3NVePHj1cZGRkuictrr6SkJHXkyBGv+yN+AttTTz3lMU5uuukmNWrUKBUaGury+4SEhC7PCryGGPIeiYoA0NTUpObPn+/1wURCQoLXBxToO3oqUaHU1Rv7uDtY8PRasGCBV9f6oef1RqJCKaW2bt2qIiIivF738uXLr7sJui9wl6jw9hUTE6M2bNjg83b9/PPPfdrfFRQUcPZgAPHH5YzMYYHDXaLC29ftt9+uzp4963OfxE9gW79+vduEt6fXiBEjfEp2KUUMeYtERQD5wx/+4PaUtmuvfv36qaVLl+raKcP8ejJRoZRSZ86cUQ888IDLafwdXzk5OWr79u3d96ZhmNGY6fjyNQH69ddfqwULFnT6gSA/P1999NFH3fPmYVhZWZl6+umnVUFBgYqJiekyRiwWi7rxxhvVs88+q86dO6e73/r6evXYY4+p+Ph4j31lZWWpl19+mQRXgPHXfZeYwwLD+++/r5YsWaLGjBnj9lto51dUVJSaO3eu2rt3r6F+iZ/AVl5erubNm9fp55P09HS1bt061dLSoqsPYqhrFqWUEgSUyspKOXDggFRXV0tra6vExcXJqFGjZPLkyRIeHt7bw0OAaWpqkv3790t5ebnU1dVJaGioJCcny8SJE12eZQ+4U19fL/v27ZOjR49KQ0ODhIeHy9ChQ2Xy5MmSnJzc28ODl+x2uxw9elQqKyvlm2++kfr6erHZbBIdHS2xsbGSlpYmubm5EhMT47c+bTabHDhwQL788kupqakRq9UqN9xwg+Tm5srYsWP91g8CF3NY4GhsbJSysjI5ceKEnD59Wi5fvix2u13i4uIkPj5eRo8eLWPHjhWr1eq3PomfwFZfXy/79++Xo0ePyqVLlyQqKkoSExMlNzdXRowY4Zc+iCHPSFQAAAAAAADTCOrtAQAAAAAAAFxDogIAAAAAAJgGiQoAAAAAAGAaJCoAAAAAAIBpkKgAAAAAAACmQaICAAAAAACYBokKAAAAAABgGiQqAAAAAACAaZCoAAAAAAAApkGiAgAAAAAAmAaJCgAAAAAAYBokKgAAAAAAgGmQqAAAAAAAAKZBogIAAAAAAJgGiQoAAAAAAGAaJCoAAAAAAIBpkKgAAAAAAACmQaICAAAAAACYBokKAAAAAABgGiQqAAAAAACAaZCoAAAAAAAApkGiAgAAAAAAmAaJCgAAAAAAYBokKgAAAAAAgGmQqAAAAAAAAKZBogIAAAAAAJgGiQoAAAAAAGAaJCoAAAAAAIBpkKgAAAAAAACmQaICAAAAAACYBokKAAAAAABgGiQqAAAAAACAaZCoAAAAAAAApkGiAgAAAAAAmAaJCgAAAAAAYBokKgAAAAAAgGmQqAAAAAAAAKbxf+XAdEs4cS3qAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(5.2393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "6 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[-0.1499,  0.2320, -0.0649,  ...,  0.0284,  0.2300,  0.0320],\n",
            "        [-0.1530,  0.2295, -0.0561,  ...,  0.0218,  0.2520,  0.0359],\n",
            "        [-0.1461,  0.2198, -0.0585,  ...,  0.0217,  0.2289,  0.0412],\n",
            "        ...,\n",
            "        [-0.1457,  0.2305, -0.0514,  ...,  0.0161,  0.2325,  0.0435],\n",
            "        [-0.1477,  0.2122, -0.0511,  ...,  0.0173,  0.2194,  0.0330],\n",
            "        [-0.1409,  0.2122, -0.0736,  ...,  0.0233,  0.2281,  0.0404]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 1.4993e-01, -2.3197e-01,  6.4861e-02,  2.1488e-01,  7.9782e-02,\n",
            "        -5.4579e-02,  4.2745e-02, -4.5254e-03, -8.9191e-02, -1.2713e-02,\n",
            "        -5.7773e-02,  8.6163e-02,  7.3048e-05, -1.8037e-01, -1.7549e-01,\n",
            "         2.1579e-01, -3.3579e-01,  1.0413e-01, -1.0193e-01, -4.3858e-02,\n",
            "        -5.6649e-02, -2.9890e-01, -2.4463e-01, -3.8459e-01,  2.0926e-02,\n",
            "        -9.6066e-02,  1.1045e-01,  1.5770e-01, -3.0564e-01,  2.3870e-01,\n",
            "        -2.0539e-01, -2.4058e-01, -2.2359e-01,  1.6538e-01,  2.0025e-01,\n",
            "         2.4792e-01,  7.8993e-02, -1.9483e+00,  2.9269e-02,  9.3304e-02,\n",
            "        -2.0563e-02,  2.2646e-02, -1.5970e-02,  2.8681e-01, -1.0714e-01,\n",
            "         7.8841e-02,  1.6806e-02, -1.6491e-01, -7.5917e-02, -4.0222e-01,\n",
            "         9.9452e-02, -6.7388e-02, -3.9663e-01,  2.3568e-01, -5.0413e-02,\n",
            "         1.4244e-01,  2.7883e-02,  8.5444e-03,  2.1072e-01,  1.2343e-01,\n",
            "         4.1234e-02, -8.4776e-02, -1.6303e-01,  1.1245e+00,  6.4786e-02,\n",
            "        -4.9664e-03,  2.4815e-02,  7.1993e-01, -2.0628e-02,  1.7882e-02,\n",
            "        -2.6990e-01,  3.1790e-02,  1.3781e-02,  4.2728e-01, -3.9765e-02,\n",
            "         1.1332e-02, -1.9161e-01,  8.3477e-02,  2.8739e-01, -7.1123e-02,\n",
            "        -6.6656e-02, -3.1243e-02, -1.5335e-01, -7.0837e-02,  7.7667e-02,\n",
            "        -1.0036e-01, -6.4794e-02,  1.8967e-01, -5.9262e-02, -2.7214e-02,\n",
            "         2.1053e-01, -2.4230e-03, -1.2664e-01,  1.7334e-01, -8.5423e-02,\n",
            "         4.0851e-03,  1.4945e-01,  3.7933e-01, -1.3115e-01,  5.8024e-02,\n",
            "         7.4959e-02,  8.8361e-02, -2.1489e-02,  5.6398e-02,  1.2924e+00,\n",
            "        -4.7689e-02,  1.2482e-01,  2.1589e-02,  1.5159e-01,  7.0574e-03,\n",
            "         1.3150e-02, -4.0067e-02, -1.2455e-01,  1.4618e-01, -1.3439e-01,\n",
            "        -6.2715e-01, -7.3288e-02,  8.5367e-01, -9.8176e-02, -3.2006e-02,\n",
            "        -1.8257e-01, -4.2107e-02, -3.5953e-01,  9.8615e-03,  3.2149e-01,\n",
            "         2.7985e-01,  2.1216e-02,  1.5584e-01,  2.6105e-01, -2.2426e-02,\n",
            "        -4.6393e-02, -7.7256e-02, -1.0198e-01,  2.0217e-01,  6.2982e-02,\n",
            "         3.0814e-01,  1.5995e-01, -5.5157e-02, -6.0439e-02,  1.8988e-02,\n",
            "         3.0234e-02,  9.4986e-02, -5.0911e-02,  2.3641e-01, -3.3942e-02,\n",
            "         9.3420e-02,  6.0139e-03, -1.6479e-02, -2.3187e-02, -6.7576e-02,\n",
            "        -1.0362e-01, -7.5475e-02,  3.2033e-02,  1.3453e-01, -1.7078e-01,\n",
            "        -4.6139e-02, -9.1083e-02, -7.5880e-02,  5.4838e-02,  3.3221e-02,\n",
            "        -1.4324e-01,  1.7078e-01,  3.2330e-01,  1.6576e-02, -5.6093e-02,\n",
            "         1.8911e-01,  2.4475e-02,  1.7323e-01, -1.0659e-02,  3.4034e-02,\n",
            "         2.1682e-03,  2.8785e-01, -1.3343e-01,  4.9929e-02, -3.1246e-01,\n",
            "         1.6326e-01, -1.0020e-01, -1.8330e-02,  1.1775e-01, -2.1303e-01,\n",
            "         8.5128e-02,  4.9035e-02, -2.9103e-01, -8.2767e-02,  1.1726e-01,\n",
            "        -9.1694e-02, -1.5102e-01, -3.2444e-01, -4.4480e-02, -1.2339e-01,\n",
            "         1.6762e-01,  5.6782e-02,  5.4880e-01,  1.3044e-01,  1.7457e-01,\n",
            "         4.7853e-01, -3.0665e-01, -7.2715e-02,  2.6059e-01, -6.5715e-02,\n",
            "         1.9745e-01,  2.2294e-01,  1.7218e-01,  1.6383e-01, -6.0138e-02,\n",
            "         1.3779e-01,  7.0657e-03, -2.7852e-01, -3.2835e-02, -1.1348e-02,\n",
            "        -4.3568e-01,  1.2897e-01, -4.1674e-02, -1.8538e-01, -9.7839e-03,\n",
            "         1.3683e-01,  2.8740e-02,  5.3737e-02,  1.8360e-02, -5.9899e-01,\n",
            "         1.1346e-01,  3.6062e-02, -3.3835e+00, -2.5886e-03,  9.1516e-02,\n",
            "         1.6262e-01,  2.5072e-01, -7.0188e-03,  2.0514e-01,  2.5904e-01,\n",
            "        -2.1372e-01,  1.7388e-01,  1.4030e-02,  2.0878e-01,  8.1196e-02,\n",
            "         3.7320e-01,  1.5573e-01, -1.8439e-01, -1.9469e-02, -8.4515e-01,\n",
            "         7.2473e-02, -1.3475e-01,  7.1568e-02,  1.5618e-01, -6.0213e-02,\n",
            "         2.0725e-02,  3.9441e-02,  1.5017e-01,  2.5001e-01,  3.9302e-01,\n",
            "         4.7482e-02,  1.4664e-01,  1.0804e-01, -2.8393e-02, -2.2997e-01,\n",
            "        -3.1970e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(5.4718, grad_fn=<LinalgVectorNormBackward0>)\n",
            "7 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[-0.1698,  0.2593, -0.0663,  ...,  0.0525,  0.2885,  0.0322],\n",
            "        [-0.1743,  0.2511, -0.0658,  ...,  0.0425,  0.3017,  0.0340],\n",
            "        [-0.1653,  0.2463, -0.0643,  ...,  0.0448,  0.2831,  0.0375],\n",
            "        ...,\n",
            "        [-0.1698,  0.2465, -0.0563,  ...,  0.0425,  0.2821,  0.0357],\n",
            "        [-0.1663,  0.2375, -0.0599,  ...,  0.0419,  0.2828,  0.0294],\n",
            "        [-0.1583,  0.2381, -0.0751,  ...,  0.0456,  0.2783,  0.0409]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 1.6984e-01, -2.5930e-01,  6.6309e-02,  1.9747e-01,  7.4466e-02,\n",
            "        -5.3876e-02,  4.4976e-02, -1.9661e-02, -8.3621e-02,  9.4065e-04,\n",
            "        -4.1893e-02,  8.0849e-02,  2.1956e-03, -2.0298e-01, -1.8226e-01,\n",
            "         2.4410e-01, -3.3443e-01,  9.9978e-02, -8.1797e-02, -5.4364e-02,\n",
            "        -4.9440e-02, -3.2525e-01, -2.6788e-01, -3.6847e-01,  2.3344e-02,\n",
            "        -9.2771e-02,  9.4563e-02,  1.5631e-01, -2.7603e-01,  2.2700e-01,\n",
            "        -1.9211e-01, -2.5484e-01, -2.4742e-01,  2.2173e-01,  1.9355e-01,\n",
            "         2.9325e-01,  7.2934e-02, -1.7909e+00,  2.4865e-02,  7.8981e-02,\n",
            "        -2.1637e-02,  4.1830e-02, -1.9332e-02,  3.2714e-01, -9.9288e-02,\n",
            "         6.3516e-02,  5.6385e-02, -1.7320e-01, -6.3909e-02, -4.2394e-01,\n",
            "         1.1524e-01, -4.4643e-02, -4.1110e-01,  2.0145e-01, -5.5392e-02,\n",
            "         1.5570e-01,  1.0544e-02, -1.9603e-02,  2.5735e-01,  1.3960e-01,\n",
            "         3.2993e-02, -8.8870e-02, -1.8556e-01,  1.3824e+00,  5.1726e-02,\n",
            "        -2.4634e-02,  3.8276e-02,  7.5240e-01, -1.9515e-03,  7.4255e-03,\n",
            "        -3.3831e-01,  2.9241e-02,  5.8759e-02,  4.8231e-01, -5.0582e-02,\n",
            "         1.1394e-03, -1.8537e-01,  7.8589e-02,  3.3038e-01, -6.4225e-02,\n",
            "        -7.7311e-02, -1.0773e-02, -1.9573e-01, -8.0261e-02,  7.5780e-02,\n",
            "        -1.3478e-01, -6.0248e-02,  2.0352e-01, -4.0723e-02, -2.2503e-02,\n",
            "         2.2083e-01,  9.3425e-03, -1.1570e-01,  1.5288e-01, -9.3066e-02,\n",
            "        -7.4155e-03,  1.2685e-01,  3.9585e-01, -1.0528e-01,  7.3147e-02,\n",
            "         6.5653e-02,  1.0227e-01, -2.9672e-02,  5.7710e-02,  1.5021e+00,\n",
            "        -3.0953e-02,  1.3373e-01,  1.1166e-02,  1.2373e-01,  5.0867e-02,\n",
            "         2.3474e-02, -4.2893e-02, -1.1694e-01,  1.9008e-01, -1.1895e-01,\n",
            "        -5.9934e-01, -6.6142e-02,  8.8769e-01, -1.2278e-01, -4.7079e-02,\n",
            "        -2.0339e-01, -1.5053e-02, -3.9469e-01,  8.4665e-03,  3.8143e-01,\n",
            "         2.8305e-01,  5.7453e-02,  1.5318e-01,  2.6738e-01, -3.2615e-02,\n",
            "        -5.5481e-02, -1.0950e-01, -1.3812e-01,  1.6874e-01,  8.3716e-02,\n",
            "         3.3134e-01,  1.8641e-01, -6.0980e-02, -4.9898e-02,  2.9780e-03,\n",
            "         4.7637e-02,  7.1358e-02, -5.1689e-02,  1.9235e-01, -2.9908e-02,\n",
            "         1.3482e-01,  1.6309e-02, -1.0376e-02, -2.7358e-02, -6.3854e-02,\n",
            "        -1.2102e-01, -8.9338e-02,  4.3267e-02,  1.2537e-01, -1.7060e-01,\n",
            "        -3.0167e-02, -1.3085e-01, -7.7358e-02,  5.7015e-02,  4.0492e-02,\n",
            "        -1.5508e-01,  1.6639e-01,  3.3401e-01,  1.4771e-02, -6.9781e-02,\n",
            "         1.5583e-01,  1.2126e-02,  1.8617e-01,  3.1490e-03,  3.3044e-02,\n",
            "        -1.2516e-02,  3.2732e-01, -1.2471e-01,  3.5517e-02, -3.5196e-01,\n",
            "         1.9634e-01, -1.0660e-01, -3.4712e-02,  1.4950e-01, -2.8459e-01,\n",
            "         1.1992e-01,  4.1169e-02, -3.4850e-01, -9.0029e-02,  1.3863e-01,\n",
            "        -9.6243e-02, -1.7969e-01, -3.3457e-01, -8.4781e-02, -1.2138e-01,\n",
            "         1.8684e-01,  5.1079e-02,  6.0931e-01,  1.3083e-01,  1.8679e-01,\n",
            "         5.0769e-01, -3.2359e-01, -6.4613e-02,  3.0771e-01, -8.2644e-02,\n",
            "         2.3862e-01,  2.4459e-01,  2.1437e-01,  1.4919e-01, -7.5972e-02,\n",
            "         1.4794e-01, -6.6190e-03, -2.9484e-01, -4.1124e-02, -3.7375e-02,\n",
            "        -4.5675e-01,  1.4598e-01, -3.7293e-02, -1.9053e-01, -7.7833e-03,\n",
            "         1.2997e-01,  2.6119e-02,  7.4510e-02,  3.6440e-02, -6.6074e-01,\n",
            "         1.1452e-01,  2.5992e-02, -3.4910e+00, -2.1477e-03,  1.3377e-01,\n",
            "         1.8437e-01,  2.8198e-01,  1.2710e-02,  2.0316e-01,  2.5958e-01,\n",
            "        -2.3377e-01,  1.6491e-01,  8.4138e-03,  2.1428e-01,  1.1050e-01,\n",
            "         4.9970e-01,  1.8239e-01, -1.7501e-01, -8.3107e-03, -7.6384e-01,\n",
            "         9.4640e-02, -1.3744e-01,  4.8571e-02,  2.0348e-01, -7.3217e-02,\n",
            "         1.7146e-02,  3.1663e-02,  1.5680e-01,  2.5297e-01,  4.3802e-01,\n",
            "         7.1347e-02,  1.1591e-01,  1.2747e-01, -5.2483e-02, -2.8847e-01,\n",
            "        -3.2235e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm tensor(5.3905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "8 tensor(0.)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n",
            "tensor([[-0.1843,  0.2654, -0.0666,  ...,  0.0710,  0.3254,  0.0221],\n",
            "        [-0.1884,  0.2532, -0.0700,  ...,  0.0617,  0.3308,  0.0258],\n",
            "        [-0.1813,  0.2554, -0.0670,  ...,  0.0642,  0.3185,  0.0257],\n",
            "        ...,\n",
            "        [-0.1843,  0.2472, -0.0615,  ...,  0.0591,  0.3167,  0.0252],\n",
            "        [-0.1799,  0.2410, -0.0656,  ...,  0.0628,  0.3200,  0.0191],\n",
            "        [-0.1744,  0.2371, -0.0735,  ...,  0.0649,  0.3069,  0.0281]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 1.8430e-01, -2.6542e-01,  6.6580e-02,  1.8594e-01,  6.8824e-02,\n",
            "        -5.6152e-02,  4.0466e-02, -3.3558e-02, -7.5242e-02,  3.6837e-03,\n",
            "        -1.7352e-02,  7.1790e-02,  5.6898e-03, -2.0884e-01, -1.7495e-01,\n",
            "         2.4646e-01, -3.2268e-01,  9.0005e-02, -5.5525e-02, -6.0275e-02,\n",
            "        -3.7454e-02, -3.3591e-01, -2.9535e-01, -3.3149e-01,  1.3330e-02,\n",
            "        -8.9377e-02,  6.7355e-02,  1.6103e-01, -2.4708e-01,  2.0797e-01,\n",
            "        -1.7198e-01, -2.5877e-01, -2.5478e-01,  2.5749e-01,  1.7977e-01,\n",
            "         3.1644e-01,  6.4308e-02, -1.3783e+00,  2.1505e-02,  6.8540e-02,\n",
            "        -3.1827e-02,  5.4707e-02, -2.0356e-02,  3.6066e-01, -8.9048e-02,\n",
            "         5.6272e-02,  9.2604e-02, -1.6921e-01, -4.3392e-02, -4.3316e-01,\n",
            "         1.2558e-01, -2.2485e-02, -4.0737e-01,  1.5527e-01, -6.3198e-02,\n",
            "         1.7033e-01,  1.1095e-02, -4.8406e-02,  2.9384e-01,  1.4387e-01,\n",
            "         2.2544e-02, -9.4637e-02, -2.1074e-01,  1.6495e+00,  4.6435e-02,\n",
            "        -4.0658e-02,  3.5766e-02,  7.5478e-01,  9.5940e-03, -8.1268e-04,\n",
            "        -3.8468e-01,  3.6125e-02,  9.4842e-02,  5.1718e-01, -5.4274e-02,\n",
            "        -1.9735e-02, -1.7968e-01,  7.2877e-02,  3.5397e-01, -5.1649e-02,\n",
            "        -7.7446e-02, -1.2031e-04, -2.2794e-01, -7.4922e-02,  7.8774e-02,\n",
            "        -1.6030e-01, -6.4177e-02,  2.0339e-01, -1.5200e-02, -1.9592e-02,\n",
            "         2.2755e-01,  8.0100e-03, -1.0875e-01,  1.3090e-01, -9.3006e-02,\n",
            "        -1.6884e-02,  1.0188e-01,  3.9960e-01, -7.8452e-02,  7.8174e-02,\n",
            "         4.7949e-02,  1.1733e-01, -4.5563e-02,  4.6704e-02,  1.6534e+00,\n",
            "        -1.6568e-02,  1.3951e-01,  1.2477e-02,  9.7448e-02,  9.0646e-02,\n",
            "         2.8851e-02, -3.8030e-02, -1.0727e-01,  2.0779e-01, -9.8761e-02,\n",
            "        -5.4707e-01, -5.4616e-02,  9.1569e-01, -1.3857e-01, -5.7937e-02,\n",
            "        -2.1431e-01,  2.8153e-03, -4.0100e-01,  1.2361e-03,  4.2951e-01,\n",
            "         2.7197e-01,  8.4159e-02,  1.5034e-01,  2.5677e-01, -4.6068e-02,\n",
            "        -5.4033e-02, -1.2880e-01, -1.7498e-01,  1.3640e-01,  1.0913e-01,\n",
            "         3.5916e-01,  1.9555e-01, -5.7986e-02, -4.6547e-02, -1.0386e-02,\n",
            "         5.2954e-02,  6.0683e-02, -4.6932e-02,  1.6388e-01, -3.3505e-02,\n",
            "         1.7019e-01,  2.1299e-02, -1.5979e-02, -2.0478e-02, -6.6993e-02,\n",
            "        -1.1671e-01, -9.3516e-02,  5.6229e-02,  1.0556e-01, -1.6589e-01,\n",
            "        -2.4464e-02, -1.6907e-01, -7.8350e-02,  4.9989e-02,  6.2844e-02,\n",
            "        -1.6699e-01,  1.5252e-01,  3.3151e-01,  7.4590e-03, -9.3066e-02,\n",
            "         1.3612e-01,  7.5133e-03,  1.9130e-01,  1.6407e-02,  2.8929e-02,\n",
            "        -6.8933e-03,  3.5919e-01, -1.1401e-01,  2.2402e-02, -3.7095e-01,\n",
            "         2.3367e-01, -1.2486e-01, -4.2911e-02,  1.7964e-01, -3.4685e-01,\n",
            "         1.4407e-01,  3.2339e-02, -4.0007e-01, -8.0852e-02,  1.6095e-01,\n",
            "        -9.5905e-02, -1.9848e-01, -3.2272e-01, -1.1471e-01, -1.1172e-01,\n",
            "         1.9732e-01,  4.6634e-02,  6.4347e-01,  1.2557e-01,  1.9412e-01,\n",
            "         5.2011e-01, -3.3391e-01, -4.8802e-02,  3.3815e-01, -9.8417e-02,\n",
            "         2.5430e-01,  2.5293e-01,  2.3819e-01,  1.2608e-01, -8.5224e-02,\n",
            "         1.5325e-01,  1.8731e-03, -2.9451e-01, -3.6432e-02, -5.1598e-02,\n",
            "        -4.6156e-01,  1.4097e-01, -2.3100e-02, -1.8632e-01,  2.1900e-03,\n",
            "         1.2173e-01,  1.9233e-02,  7.8284e-02,  4.5587e-02, -6.9974e-01,\n",
            "         1.1748e-01,  2.1844e-02, -3.3133e+00, -7.5850e-03,  1.6080e-01,\n",
            "         1.9892e-01,  3.0176e-01,  2.6966e-02,  1.9520e-01,  2.4702e-01,\n",
            "        -2.4330e-01,  1.5503e-01,  9.5799e-03,  2.0551e-01,  1.2451e-01,\n",
            "         6.0189e-01,  1.9991e-01, -1.6179e-01,  4.3745e-03, -4.6877e-01,\n",
            "         1.1253e-01, -1.3580e-01,  2.6407e-02,  2.2672e-01, -8.6067e-02,\n",
            "         1.1400e-02,  2.9127e-02,  1.6383e-01,  2.3603e-01,  4.6235e-01,\n",
            "         9.3420e-02,  9.0429e-02,  1.4418e-01, -7.0984e-02, -3.2542e-01,\n",
            "        -2.2096e-02], grad_fn=<SubBackward0>)\n",
            "(3, 64, 64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-41daf5871243>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# agent.train_ae(train_loader, optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# agent.train_jepa(train_loader, optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_jepa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# state = buffer[7][80][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-2b5c5daed39c>\u001b[0m in \u001b[0;36mtrain_jepa\u001b[0;34m(self, dataloader, c_loader, optim, bptt)\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mstd_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_creg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"norm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msy_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0;31m# if torch.norm(sy[0]-sy_[0], dim=-1) > 1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-41daf5871243>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# plt.imshow(np.transpose(npimg, (1, 2, 0)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[1;32m    445\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m                 )\n\u001b[1;32m   2341\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_draw_disabled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3141\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0m_draw_rasterized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3064\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3065\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;31m# Shift label away from axes to avoid overlapping ticklabels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    299\u001b[0m         for artist in [self.gridline, self.tick1line, self.tick2line,\n\u001b[1;32m    300\u001b[0m                        self.label1, self.label2]:\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cm_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_wrapped_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[1;32m    747\u001b[0m         no_ops = {\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mmeth_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmeth_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRendererBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             if (meth_name.startswith(\"draw_\")\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "\n",
        "for i in range(30):\n",
        "    print(i)\n",
        "    # agent.train_ae(train_loader, optim)\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "    # state = buffer[7][80][0]\n",
        "    # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    # out= agent.deconv(sx_).squeeze(0)\n",
        "    # print(out.shape)\n",
        "    # imshow(state.detach().cpu())\n",
        "    # imshow(out.detach().cpu())\n",
        "\n",
        "# 10 epochs 15m23s\n",
        "\n",
        "\n",
        "\n",
        "# loss 0.00027325598057359457\n",
        "# loss 0.00027538512949831784\n",
        "# loss 0.000279315427178517\n",
        "# loss 0.00028544830274768174\n",
        "# loss 0.00029633755912072957\n",
        "# loss 0.0002964686427731067\n",
        "# loss 0.00030574199627153575\n",
        "# loss 0.00031030713580548763\n",
        "# loss 0.00011697990703396499\n",
        "# loss 0.00012466282350942492\n",
        "\n",
        "# loss 0.0002805441035889089\n",
        "# loss 0.0002813159371726215\n",
        "# loss 0.00028616547933779657\n",
        "# loss 0.00029815093148499727\n",
        "# loss 0.0003055527340620756\n",
        "# loss 0.0002878434315789491\n",
        "# loss 0.0002965773455798626\n",
        "# loss 0.00030164531199261546\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "ad2bf88e-91ab-4fc8-8c87-2007d9df537d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "\n",
        "ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PraFUAPB3j7v",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dd3a6d-14a7-44d8-a7c4-08c7cc03c7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "dided\n",
            "time\n",
            "[8, 7, 3, 12, 14, 12, 9, 2, 14, 12, 2, 12, 7, 12, 9, 9, 9, 9, 2, 2, 9, 13, 14, 3, 12, 9, 0, 12, 3, 12, 8, 12, 13, 7, 2, 8, 2, 9, 12, 14, 9, 13, 0, 12, 13, 14, 8, 13, 12, 3, 13, 13, 14, 14, 14, 7, 14, 2, 9, 0, 8, 9, 9, 2, 2, 8, 13, 2, 2, 14, 13, 12, 3, 12, 13, 9, 9, 14, 11, 13, 12, 9, 7, 9, 2, 9, 13, 12, 7, 2, 2, 13, 12, 11, 11, 14, 12, 2, 13, 7, 9, 9, 13, 2, 2, 2, 12, 3, 9, 13, 12, 2, 12, 12, 2, 7, 13, 2, 3, 7, 14, 9, 11, 2, 14, 11, 13, 9, 14, 2, 11, 12, 14, 14, 14, 12, 14]\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "# from gymnasium.wrappers import TimeLimit\n",
        "from gym.wrappers import TimeLimit\n",
        "\n",
        "env = TimeLimit(env, max_episode_steps=600)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# print(env.action_space) # 15\n",
        "\n",
        "def simulate(agent, buffer=[], k=4):\n",
        "    # agent.eval()\n",
        "    out=None\n",
        "    writer = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # writer = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    act_list=[]\n",
        "    # h0 = torch.randn((agent.jepa.pred.num_layers, agent.d_model), device=device)\n",
        "    while True:\n",
        "    # for i in range(400):\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        # if len(act)<=0: act = agent(state).cpu()[0,:4].tolist()\n",
        "        # print(act.shape, h0.shape) # [1, 6], [1, 256]\n",
        "        if len(act)<=0:\n",
        "            # lact, lh0, lx, lz = agent(state, h0)\n",
        "            # act = lact.cpu()[0,:k].tolist()\n",
        "            # out = agent(state, zip(*out)[k:])\n",
        "            act = agent(state, k)\n",
        "            # act = zip(*out)[0].cpu()[0,:k].tolist()\n",
        "            # act = out[0].cpu()[0,:k].tolist()\n",
        "            # h0=lh0[k-1].unsqueeze(0)\n",
        "            # , lx, lz\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        # print(i, 'act: ',action, 'reward: ',reward)\n",
        "        act_list.append(action)\n",
        "        writer.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"dided\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    print(act_list)\n",
        "    env.close()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff7c3c3-b781-46f9-dcd4-bb4a672e96ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "dided\n",
            "time\n",
            "[13, 3, 13, 12, 9, 14, 11, 9, 12, 9, 13, 14, 14, 0, 12, 9, 7, 8, 13, 12, 9, 3, 8, 9, 13, 8, 13, 12, 2, 9, 11, 9, 12, 14, 9, 10, 9, 2, 11, 12, 9, 7, 0, 2, 12, 14, 14, 13, 2, 9, 3, 12, 13, 2, 12, 3, 2, 0, 11, 14, 13, 12, 8, 12, 14, 13, 9, 11, 12, 14, 14, 14, 0, 12, 0, 3, 13, 12, 13, 2, 8, 12, 11, 11, 7, 12, 2, 13, 12, 14, 2, 12, 3, 8, 13, 2, 14, 11, 9, 3, 8, 11, 13, 9, 12, 3, 11, 13, 9, 13, 9, 2, 13, 12, 12, 2, 12, 9, 3, 8, 12, 8, 9, 13, 8, 3, 3, 12, 12, 8, 12, 12, 11, 13, 7, 9, 12, 2, 9, 9, 14, 12, 12, 12, 3, 2, 12, 9, 12, 14, 12, 9, 13, 12, 9, 0, 13, 7, 8, 12, 9, 7, 0, 10, 14, 12, 2, 9, 12, 12, 9, 2, 13, 11, 7, 3, 13, 0, 13, 3, 2, 2, 9, 13, 2, 9, 2, 3, 13, 14]\n",
            "0 #### train ####\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-5710a487b32e>:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0012, 0.0013, 0.0012, 0.0011, 0.0011, 0.0012, 0.0011, 0.0010, 0.0011,\n",
            "        0.0014, 0.0012, 0.0016, 0.0013, 0.0011, 0.0011, 0.0012],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0012, 0.0013, 0.0015, 0.0014, 0.0011, 0.0013, 0.0012, 0.0011, 0.0013,\n",
            "        0.0014, 0.0012, 0.0020, 0.0015, 0.0012, 0.0012, 0.0012],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0012, 0.0013, 0.0015, 0.0013, 0.0012, 0.0012, 0.0013, 0.0011, 0.0013,\n",
            "        0.0012, 0.0013, 0.0014, 0.0013, 0.0012, 0.0012, 0.0012],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0013, 0.0013, 0.0013, 0.0013, 0.0011, 0.0012, 0.0013, 0.0011, 0.0013,\n",
            "        0.0012, 0.0012, 0.0013, 0.0012, 0.0011, 0.0012, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0013, 0.0012, 0.0012, 0.0013, 0.0011, 0.0013, 0.0013, 0.0011, 0.0013,\n",
            "        0.0011, 0.0011, 0.0013, 0.0012, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0013, 0.0012, 0.0012, 0.0013, 0.0011, 0.0013, 0.0013, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0012, 0.0012, 0.0013, 0.0013, 0.0011, 0.0013, 0.0013, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0013, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0013, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0013, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0013, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0013, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0013, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0011, 0.0012,\n",
            "        0.0011, 0.0011, 0.0012, 0.0011, 0.0011, 0.0011, 0.0011],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0052, 0.0052, 0.0051, 0.0050, 0.0054, 0.0051, 0.0054, 0.0053, 0.0053,\n",
            "        0.0051, 0.0050, 0.0052, 0.0051, 0.0052, 0.0051, 0.0051],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0053, 0.0052, 0.0053, 0.0053, 0.0056, 0.0051, 0.0056, 0.0056, 0.0051,\n",
            "        0.0051, 0.0051, 0.0052, 0.0052, 0.0052, 0.0050, 0.0051],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0054, 0.0055, 0.0055, 0.0055, 0.0056, 0.0052, 0.0056, 0.0055, 0.0054,\n",
            "        0.0053, 0.0054, 0.0054, 0.0054, 0.0053, 0.0052, 0.0054],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0056, 0.0055, 0.0054, 0.0055, 0.0053, 0.0051, 0.0055, 0.0055, 0.0053,\n",
            "        0.0053, 0.0053, 0.0052, 0.0055, 0.0053, 0.0053, 0.0053],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0054, 0.0054, 0.0055, 0.0052, 0.0052, 0.0052, 0.0054, 0.0054, 0.0053,\n",
            "        0.0053, 0.0052, 0.0052, 0.0052, 0.0053, 0.0053, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0053, 0.0054, 0.0052,\n",
            "        0.0053, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0054, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0054, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0053, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0053, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0053, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0053, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0053, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0053, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0054, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0054, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0054, 0.0054, 0.0054, 0.0052, 0.0052, 0.0052, 0.0052, 0.0054, 0.0052,\n",
            "        0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052, 0.0052],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0045, 0.0041, 0.0048, 0.0040, 0.0042, 0.0044, 0.0043, 0.0043, 0.0045,\n",
            "        0.0041, 0.0040, 0.0042, 0.0042, 0.0044, 0.0040, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0044, 0.0042, 0.0046, 0.0039, 0.0042, 0.0042, 0.0042, 0.0041, 0.0043,\n",
            "        0.0043, 0.0041, 0.0042, 0.0042, 0.0042, 0.0041, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0043, 0.0044, 0.0045, 0.0040, 0.0044, 0.0043, 0.0042, 0.0043, 0.0044,\n",
            "        0.0044, 0.0043, 0.0041, 0.0043, 0.0045, 0.0041, 0.0044],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0044, 0.0044, 0.0044, 0.0041, 0.0044, 0.0043, 0.0043, 0.0043, 0.0044,\n",
            "        0.0044, 0.0043, 0.0041, 0.0043, 0.0046, 0.0042, 0.0046],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0045, 0.0043, 0.0044, 0.0041, 0.0045, 0.0044, 0.0042, 0.0042, 0.0044,\n",
            "        0.0044, 0.0043, 0.0043, 0.0044, 0.0046, 0.0042, 0.0046],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0042, 0.0042, 0.0043, 0.0042, 0.0044, 0.0043, 0.0042, 0.0042, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0043, 0.0042, 0.0044],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0042, 0.0042, 0.0042, 0.0042, 0.0043, 0.0042, 0.0042, 0.0042, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0041, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0041, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042,\n",
            "        0.0043, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042,\n",
            "        0.0043, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0042, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0042, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0042, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0042, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0042, 0.0042, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0041, 0.0042,\n",
            "        0.0043, 0.0042, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0060, 0.0061, 0.0069, 0.0058, 0.0060, 0.0063, 0.0058, 0.0059, 0.0060,\n",
            "        0.0060, 0.0060, 0.0059, 0.0060, 0.0065, 0.0061, 0.0064],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0058, 0.0058, 0.0065, 0.0058, 0.0060, 0.0062, 0.0058, 0.0059, 0.0059,\n",
            "        0.0059, 0.0060, 0.0058, 0.0058, 0.0061, 0.0062, 0.0062],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0059, 0.0060, 0.0064, 0.0060, 0.0061, 0.0060, 0.0058, 0.0059, 0.0059,\n",
            "        0.0059, 0.0061, 0.0060, 0.0059, 0.0062, 0.0062, 0.0063],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0059, 0.0060, 0.0063, 0.0061, 0.0059, 0.0058, 0.0059, 0.0058, 0.0059,\n",
            "        0.0060, 0.0063, 0.0062, 0.0058, 0.0065, 0.0064, 0.0063],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0060, 0.0059, 0.0063, 0.0061, 0.0059, 0.0058, 0.0058, 0.0058, 0.0059,\n",
            "        0.0058, 0.0063, 0.0062, 0.0058, 0.0063, 0.0063, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0060, 0.0058, 0.0062, 0.0058, 0.0059, 0.0058, 0.0058, 0.0058, 0.0059,\n",
            "        0.0059, 0.0060, 0.0061, 0.0059, 0.0063, 0.0061, 0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0060, 0.0058, 0.0061, 0.0058, 0.0059, 0.0058, 0.0058, 0.0058, 0.0059,\n",
            "        0.0058, 0.0060, 0.0060, 0.0059, 0.0060, 0.0061, 0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0060, 0.0060, 0.0060, 0.0060, 0.0059, 0.0059, 0.0059, 0.0059, 0.0059,\n",
            "        0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0061, 0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0058, 0.0059, 0.0058, 0.0058,\n",
            "        0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0061, 0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0060, 0.0059, 0.0060, 0.0058, 0.0059, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0061, 0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0060, 0.0059, 0.0060, 0.0058, 0.0059, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0061, 0.0061],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0060, 0.0059, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0061, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0060, 0.0059, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0061, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0060, 0.0058, 0.0060, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058, 0.0058,\n",
            "        0.0058, 0.0060, 0.0060, 0.0058, 0.0060, 0.0060, 0.0060],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0071, 0.0069, 0.0070, 0.0074, 0.0071, 0.0070, 0.0068, 0.0075, 0.0071,\n",
            "        0.0070, 0.0072, 0.0073, 0.0078, 0.0070, 0.0071, 0.0072],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0071, 0.0070, 0.0069, 0.0073, 0.0069, 0.0071, 0.0069, 0.0075, 0.0074,\n",
            "        0.0069, 0.0071, 0.0071, 0.0077, 0.0070, 0.0073, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0072, 0.0072, 0.0073, 0.0075, 0.0073, 0.0073, 0.0072, 0.0074, 0.0075,\n",
            "        0.0072, 0.0074, 0.0077, 0.0083, 0.0073, 0.0074, 0.0074],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0072, 0.0072, 0.0074, 0.0075, 0.0073, 0.0074, 0.0074, 0.0074, 0.0073,\n",
            "        0.0073, 0.0072, 0.0074, 0.0081, 0.0073, 0.0075, 0.0072],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0071, 0.0070, 0.0073, 0.0072, 0.0072, 0.0072, 0.0071, 0.0073, 0.0072,\n",
            "        0.0072, 0.0071, 0.0074, 0.0079, 0.0072, 0.0073, 0.0074],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0071, 0.0070, 0.0072, 0.0071, 0.0072, 0.0071, 0.0071, 0.0072, 0.0071,\n",
            "        0.0072, 0.0071, 0.0071, 0.0077, 0.0071, 0.0072, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0070, 0.0070, 0.0071, 0.0071, 0.0071, 0.0071, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0071, 0.0072, 0.0074, 0.0071, 0.0072, 0.0072],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0070, 0.0070, 0.0071, 0.0071, 0.0071, 0.0071, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0071, 0.0072, 0.0073, 0.0071, 0.0071, 0.0072],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0070, 0.0070, 0.0071, 0.0071, 0.0071, 0.0070, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0071, 0.0072, 0.0073, 0.0071, 0.0071, 0.0072],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0070, 0.0070, 0.0071, 0.0071, 0.0071, 0.0070, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0071, 0.0072, 0.0073, 0.0071, 0.0071, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0070, 0.0070, 0.0071, 0.0071, 0.0071, 0.0070, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0071, 0.0071, 0.0073, 0.0071, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0070, 0.0070, 0.0071, 0.0071, 0.0071, 0.0070, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0071, 0.0071, 0.0073, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0071, 0.0070, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0070, 0.0070, 0.0071, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0071,\n",
            "        0.0070, 0.0070, 0.0071, 0.0072, 0.0070, 0.0070, 0.0071],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0039, 0.0031, 0.0034, 0.0033, 0.0032, 0.0033, 0.0032, 0.0033, 0.0031,\n",
            "        0.0032, 0.0035, 0.0032, 0.0033, 0.0032, 0.0034, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0038, 0.0031, 0.0033, 0.0033, 0.0032, 0.0032, 0.0032, 0.0034, 0.0031,\n",
            "        0.0031, 0.0033, 0.0033, 0.0035, 0.0033, 0.0031, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0036, 0.0030, 0.0032, 0.0034, 0.0033, 0.0034, 0.0033, 0.0033, 0.0031,\n",
            "        0.0031, 0.0034, 0.0033, 0.0035, 0.0035, 0.0033, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0036, 0.0031, 0.0031, 0.0034, 0.0033, 0.0035, 0.0031, 0.0035, 0.0033,\n",
            "        0.0032, 0.0033, 0.0035, 0.0034, 0.0033, 0.0032, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0036, 0.0032, 0.0032, 0.0032, 0.0032, 0.0035, 0.0032, 0.0035, 0.0034,\n",
            "        0.0032, 0.0033, 0.0035, 0.0033, 0.0033, 0.0032, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0034, 0.0031, 0.0032, 0.0032, 0.0032, 0.0034, 0.0032, 0.0035, 0.0034,\n",
            "        0.0031, 0.0032, 0.0035, 0.0034, 0.0034, 0.0032, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0034, 0.0031, 0.0031, 0.0032, 0.0032, 0.0034, 0.0032, 0.0034, 0.0033,\n",
            "        0.0032, 0.0032, 0.0034, 0.0034, 0.0034, 0.0032, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0034, 0.0031, 0.0031, 0.0032, 0.0032, 0.0033, 0.0032, 0.0033, 0.0033,\n",
            "        0.0031, 0.0032, 0.0033, 0.0033, 0.0034, 0.0032, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0034, 0.0031, 0.0031, 0.0031, 0.0032, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0034, 0.0031, 0.0031, 0.0031, 0.0032, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0034, 0.0031, 0.0031, 0.0031, 0.0032, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0032, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0034, 0.0031, 0.0031, 0.0031, 0.0032, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0034, 0.0031, 0.0031, 0.0031, 0.0032, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0032, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0032, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0033, 0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0033, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0033, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0026, 0.0028, 0.0027, 0.0027, 0.0027, 0.0029, 0.0033, 0.0028, 0.0029,\n",
            "        0.0027, 0.0027, 0.0029, 0.0026, 0.0030, 0.0029, 0.0026],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0027, 0.0029, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0027, 0.0028,\n",
            "        0.0027, 0.0029, 0.0030, 0.0027, 0.0030, 0.0028, 0.0028],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0027, 0.0029, 0.0027, 0.0028, 0.0028, 0.0029, 0.0031, 0.0028, 0.0028,\n",
            "        0.0030, 0.0029, 0.0029, 0.0028, 0.0032, 0.0032, 0.0029],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0027, 0.0029, 0.0028, 0.0028, 0.0028, 0.0028, 0.0032, 0.0028, 0.0027,\n",
            "        0.0031, 0.0030, 0.0028, 0.0028, 0.0031, 0.0032, 0.0028],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0027, 0.0028, 0.0027, 0.0027, 0.0027, 0.0028, 0.0032, 0.0027, 0.0027,\n",
            "        0.0031, 0.0028, 0.0027, 0.0029, 0.0029, 0.0029, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0032, 0.0027, 0.0027,\n",
            "        0.0029, 0.0029, 0.0027, 0.0029, 0.0029, 0.0029, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0029, 0.0027, 0.0027,\n",
            "        0.0029, 0.0029, 0.0027, 0.0029, 0.0029, 0.0029, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0029, 0.0027, 0.0027,\n",
            "        0.0029, 0.0029, 0.0027, 0.0029, 0.0029, 0.0029, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0029, 0.0027, 0.0027,\n",
            "        0.0029, 0.0029, 0.0027, 0.0029, 0.0029, 0.0029, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0029, 0.0027, 0.0027,\n",
            "        0.0029, 0.0028, 0.0027, 0.0028, 0.0029, 0.0029, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0029, 0.0029, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0029, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0029, 0.0029, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0029, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0029, 0.0029, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0029, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0029, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0027, 0.0027,\n",
            "        0.0028, 0.0028, 0.0027, 0.0028, 0.0028, 0.0028, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0021, 0.0020, 0.0021, 0.0021, 0.0023, 0.0021, 0.0022, 0.0020, 0.0020,\n",
            "        0.0021, 0.0021, 0.0020, 0.0022, 0.0025, 0.0023, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0020, 0.0021, 0.0022, 0.0022, 0.0021, 0.0022, 0.0022, 0.0020, 0.0019,\n",
            "        0.0022, 0.0021, 0.0020, 0.0021, 0.0024, 0.0022, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0021, 0.0022, 0.0024, 0.0024, 0.0022, 0.0022, 0.0022, 0.0022, 0.0020,\n",
            "        0.0022, 0.0022, 0.0022, 0.0023, 0.0024, 0.0021, 0.0023],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0023, 0.0025, 0.0024, 0.0024, 0.0023, 0.0021, 0.0022, 0.0023, 0.0022,\n",
            "        0.0021, 0.0023, 0.0025, 0.0022, 0.0023, 0.0021, 0.0023],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0022, 0.0023, 0.0023, 0.0022, 0.0023, 0.0021, 0.0021, 0.0023, 0.0021,\n",
            "        0.0021, 0.0023, 0.0025, 0.0022, 0.0022, 0.0021, 0.0023],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0021, 0.0024, 0.0023, 0.0023, 0.0021, 0.0021, 0.0021, 0.0023, 0.0021,\n",
            "        0.0021, 0.0021, 0.0025, 0.0022, 0.0021, 0.0021, 0.0023],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0021, 0.0023, 0.0023, 0.0023, 0.0021, 0.0021, 0.0021, 0.0023, 0.0021,\n",
            "        0.0021, 0.0021, 0.0023, 0.0021, 0.0021, 0.0021, 0.0022],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0021, 0.0023, 0.0022, 0.0023, 0.0021, 0.0021, 0.0021, 0.0023, 0.0021,\n",
            "        0.0021, 0.0021, 0.0023, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0021, 0.0023, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0023, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0021, 0.0023, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0023, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0021, 0.0023, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0023, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0021, 0.0023, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0023, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0021, 0.0022, 0.0022, 0.0022, 0.0021, 0.0021, 0.0021, 0.0022, 0.0021,\n",
            "        0.0021, 0.0021, 0.0022, 0.0021, 0.0021, 0.0021, 0.0021],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0024, 0.0025, 0.0026, 0.0025, 0.0024, 0.0028, 0.0026, 0.0023, 0.0024,\n",
            "        0.0028, 0.0023, 0.0027, 0.0027, 0.0024, 0.0024, 0.0027],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0024, 0.0023, 0.0025, 0.0024, 0.0024, 0.0027, 0.0025, 0.0024, 0.0026,\n",
            "        0.0033, 0.0024, 0.0024, 0.0028, 0.0024, 0.0025, 0.0028],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0025, 0.0025, 0.0027, 0.0026, 0.0025, 0.0026, 0.0028, 0.0025, 0.0026,\n",
            "        0.0029, 0.0025, 0.0026, 0.0026, 0.0025, 0.0027, 0.0026],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0026, 0.0025, 0.0026, 0.0026, 0.0025, 0.0027, 0.0026, 0.0025, 0.0027,\n",
            "        0.0029, 0.0025, 0.0026, 0.0026, 0.0025, 0.0026, 0.0026],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0025, 0.0024, 0.0026, 0.0026, 0.0024, 0.0026, 0.0025, 0.0025, 0.0025,\n",
            "        0.0027, 0.0026, 0.0025, 0.0025, 0.0025, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0025, 0.0024, 0.0025, 0.0025, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025,\n",
            "        0.0027, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0025, 0.0024, 0.0025, 0.0025, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025,\n",
            "        0.0027, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0025],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0025, 0.0024, 0.0025, 0.0025, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025,\n",
            "        0.0026, 0.0025, 0.0025, 0.0025, 0.0025, 0.0026, 0.0025],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0024, 0.0024, 0.0025, 0.0025, 0.0024, 0.0025, 0.0025, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0025, 0.0025, 0.0024, 0.0026, 0.0025],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0025, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0025, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0025, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0025, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0025, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0025, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0024, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0024, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0024, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0024, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0024, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
            "        0.0026, 0.0024, 0.0024, 0.0024, 0.0024, 0.0026, 0.0024],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0030, 0.0031, 0.0032, 0.0034, 0.0031, 0.0029, 0.0030, 0.0033, 0.0030,\n",
            "        0.0030, 0.0035, 0.0029, 0.0031, 0.0031, 0.0031, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0031, 0.0031, 0.0033, 0.0034, 0.0033, 0.0030, 0.0032, 0.0032, 0.0029,\n",
            "        0.0032, 0.0035, 0.0030, 0.0029, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0029, 0.0030, 0.0035, 0.0031, 0.0032, 0.0031, 0.0032, 0.0033, 0.0031,\n",
            "        0.0031, 0.0036, 0.0031, 0.0031, 0.0032, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0030, 0.0030, 0.0034, 0.0030, 0.0035, 0.0032, 0.0031, 0.0032, 0.0030,\n",
            "        0.0031, 0.0036, 0.0030, 0.0030, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0035, 0.0032, 0.0030, 0.0032, 0.0030,\n",
            "        0.0031, 0.0033, 0.0030, 0.0030, 0.0031, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0033, 0.0031, 0.0030, 0.0032, 0.0030,\n",
            "        0.0031, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0032, 0.0030,\n",
            "        0.0030, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0033, 0.0030, 0.0030, 0.0030, 0.0032, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0032, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0030, 0.0030, 0.0032, 0.0030, 0.0031, 0.0030, 0.0030, 0.0031, 0.0030,\n",
            "        0.0030, 0.0032, 0.0030, 0.0030, 0.0030, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0031, 0.0038, 0.0032, 0.0030, 0.0031, 0.0029, 0.0032, 0.0030, 0.0029,\n",
            "        0.0030, 0.0032, 0.0034, 0.0034, 0.0034, 0.0031, 0.0030],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0030, 0.0033, 0.0033, 0.0030, 0.0033, 0.0030, 0.0031, 0.0031, 0.0029,\n",
            "        0.0032, 0.0034, 0.0034, 0.0034, 0.0035, 0.0031, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0030, 0.0033, 0.0031, 0.0030, 0.0035, 0.0031, 0.0032, 0.0031, 0.0031,\n",
            "        0.0033, 0.0032, 0.0037, 0.0037, 0.0031, 0.0031, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0031, 0.0033, 0.0031, 0.0031, 0.0035, 0.0033, 0.0032, 0.0032, 0.0034,\n",
            "        0.0033, 0.0032, 0.0033, 0.0037, 0.0032, 0.0033, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0031, 0.0032, 0.0032, 0.0031, 0.0034, 0.0033, 0.0033, 0.0032, 0.0033,\n",
            "        0.0033, 0.0032, 0.0034, 0.0036, 0.0033, 0.0035, 0.0033],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0031, 0.0032, 0.0032, 0.0031, 0.0034, 0.0032, 0.0032, 0.0032, 0.0033,\n",
            "        0.0032, 0.0032, 0.0033, 0.0036, 0.0033, 0.0034, 0.0032],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0032, 0.0031, 0.0033,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0031, 0.0031, 0.0033,\n",
            "        0.0031, 0.0031, 0.0034, 0.0033, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0034, 0.0033, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0033, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0034, 0.0033, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0031, 0.0033, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0033, 0.0033, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0033, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0031, 0.0031, 0.0031, 0.0032,\n",
            "        0.0031, 0.0031, 0.0032, 0.0032, 0.0031, 0.0032, 0.0031],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0044, 0.0043, 0.0047, 0.0043, 0.0044, 0.0047, 0.0046, 0.0045, 0.0044,\n",
            "        0.0045, 0.0044, 0.0042, 0.0046, 0.0045, 0.0047, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0045, 0.0043, 0.0048, 0.0045, 0.0042, 0.0046, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0042, 0.0043, 0.0044, 0.0044, 0.0047, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0044, 0.0044, 0.0049, 0.0044, 0.0043, 0.0045, 0.0045, 0.0044, 0.0048,\n",
            "        0.0045, 0.0044, 0.0044, 0.0045, 0.0045, 0.0045, 0.0046],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0044, 0.0045, 0.0046, 0.0045, 0.0044, 0.0047, 0.0045, 0.0044, 0.0045,\n",
            "        0.0044, 0.0044, 0.0043, 0.0047, 0.0046, 0.0045, 0.0047],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0043, 0.0045, 0.0046, 0.0045, 0.0044, 0.0048, 0.0046, 0.0043, 0.0045,\n",
            "        0.0045, 0.0044, 0.0043, 0.0047, 0.0046, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0043, 0.0045, 0.0046, 0.0045, 0.0043, 0.0046, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0044, 0.0043, 0.0047, 0.0046, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0043, 0.0045, 0.0046, 0.0045, 0.0043, 0.0046, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0045, 0.0045, 0.0044, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0044, 0.0045, 0.0045, 0.0045, 0.0044, 0.0046, 0.0045, 0.0044, 0.0045,\n",
            "        0.0045, 0.0044, 0.0044, 0.0045, 0.0045, 0.0044, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0044, 0.0045, 0.0045, 0.0045, 0.0044, 0.0047, 0.0046, 0.0044, 0.0046,\n",
            "        0.0045, 0.0044, 0.0044, 0.0046, 0.0045, 0.0044, 0.0046],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0043, 0.0045, 0.0045, 0.0045, 0.0044, 0.0045, 0.0045, 0.0044, 0.0045,\n",
            "        0.0045, 0.0044, 0.0044, 0.0045, 0.0045, 0.0044, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0043, 0.0045, 0.0044, 0.0045, 0.0043, 0.0045, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0045, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0043, 0.0045, 0.0044, 0.0045, 0.0043, 0.0045, 0.0044, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0043, 0.0045, 0.0044, 0.0044, 0.0043, 0.0044, 0.0044, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0043, 0.0045, 0.0044, 0.0044, 0.0043, 0.0044, 0.0044, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0043, 0.0045, 0.0044, 0.0044, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0043, 0.0045, 0.0044, 0.0044, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0043, 0.0045, 0.0044, 0.0044, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0043, 0.0045, 0.0044, 0.0045, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0043, 0.0045, 0.0044, 0.0045, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0043, 0.0045, 0.0044, 0.0045, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045,\n",
            "        0.0045, 0.0043, 0.0043, 0.0044, 0.0045, 0.0043, 0.0045],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "dided\n",
            "time\n",
            "[7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 6, 4, 7, 7, 7, 4, 4, 4, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 6, 4, 4, 7, 6, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7]\n",
            "18 #### train ####\n",
            "repr, std, cov, closs 0.006621013395488262 0.47412109375 0.0007647608872503042 0.33305156230926514\n",
            "0.06515158099130984 0.09587351296168657 1.0\n",
            "repr, std, cov, closs 0.006829024292528629 0.47314453125 0.000854662386700511 0.7196159362792969\n",
            "0.0654779910639179 0.09492002985146797 1.0\n",
            "repr, std, cov, closs 0.006623061839491129 0.474365234375 0.0007216131780296564 0.6821219325065613\n",
            "0.06633433100465831 0.09473047417264853 1.0\n",
            "repr, std, cov, closs 0.006781477015465498 0.476318359375 0.0007049513515084982 0.7245012521743774\n",
            "0.06726907227507502 0.09530027987082794 1.0\n",
            "repr, std, cov, closs 0.007171778008341789 0.477783203125 0.0004937860649079084 0.8180166482925415\n",
            "0.06760609100020025 0.09463583833431423 1.0\n",
            "repr, std, cov, closs 0.007529481779783964 0.475341796875 0.0008324023801833391 0.3915747106075287\n",
            "0.06876463510904313 0.09520507479603192 1.0\n",
            "repr, std, cov, closs 0.007790037430822849 0.4765625 0.0005246768705546856 0.5676451325416565\n",
            "0.06994303282030964 0.09722450162694986 1.0\n",
            "repr, std, cov, closs 0.007448828313499689 0.47607421875 0.0006090439856052399 0.6561471223831177\n",
            "0.07085776785734035 0.09820113343317433 1.0\n",
            "repr, std, cov, closs 0.007705920375883579 0.474609375 0.0007082221563905478 0.6517778635025024\n",
            "0.07192810677804372 0.09810303040277156 1.0\n",
            "repr, std, cov, closs 0.0067165568470954895 0.475341796875 0.0005855932831764221 0.7019190788269043\n",
            "0.07301461365661277 0.09948543601207777 1.0\n",
            "repr, std, cov, closs 0.005936697591096163 0.476806640625 0.0004565734416246414 0.6895862221717834\n",
            "0.07411753271742956 0.10149416086211166 1.0\n",
            "repr, std, cov, closs 0.004966613836586475 0.4765625 0.00045489799231290817 0.7437503933906555\n",
            "0.07523711187399698 0.10302727648062172 1.0\n",
            "repr, std, cov, closs 0.004643409512937069 0.476806640625 0.0005085724405944347 0.6416232585906982\n",
            "0.07637360278466444 0.1054231531177157 1.0\n",
            "repr, std, cov, closs 0.004979141987860203 0.478515625 0.00037415907718241215 0.3836606442928314\n",
            "0.07714078480552634 0.107015617957313 1.0\n",
            "repr, std, cov, closs 0.005795701872557402 0.47607421875 0.0005488598253577948 0.7914455533027649\n",
            "0.07683299153403225 0.10595132416959414 1.0\n",
            "repr, std, cov, closs 0.007360995747148991 0.474853515625 0.0007632183842360973 0.8898858428001404\n",
            "0.07622108439479049 0.10416626005566212 1.0\n",
            "repr, std, cov, closs 0.008368415758013725 0.476318359375 0.0007179402746260166 0.35901060700416565\n",
            "0.07584111962667044 0.10323343406085943 1.0\n",
            "repr, std, cov, closs 0.007306803949177265 0.477294921875 0.0005489147733896971 0.5582184195518494\n",
            "0.07584111962667044 0.10416626005566212 1.0\n",
            "repr, std, cov, closs 0.008747521787881851 0.475341796875 0.0008079127874225378 0.3517409563064575\n",
            "0.07501185120980212 0.10200264762347996 1.0\n",
            "repr, std, cov, closs 0.007921749725937843 0.4755859375 0.0010270422790199518 0.7300407290458679\n",
            "0.07396951970849287 0.10068584921911945 1.0\n",
            "0 tensor([0.0346, 0.0375, 0.0365, 0.0334, 0.0347, 0.0342, 0.0342, 0.0338, 0.0363,\n",
            "        0.0343, 0.0349, 0.0358, 0.0358, 0.0343, 0.0345, 0.0359],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0349, 0.0370, 0.0365, 0.0342, 0.0346, 0.0351, 0.0342, 0.0343, 0.0352,\n",
            "        0.0345, 0.0344, 0.0351, 0.0358, 0.0352, 0.0345, 0.0354],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0352, 0.0365, 0.0356, 0.0343, 0.0343, 0.0346, 0.0349, 0.0351, 0.0357,\n",
            "        0.0347, 0.0342, 0.0351, 0.0353, 0.0348, 0.0353, 0.0361],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0345, 0.0364, 0.0356, 0.0345, 0.0345, 0.0350, 0.0355, 0.0354, 0.0353,\n",
            "        0.0345, 0.0345, 0.0356, 0.0360, 0.0354, 0.0354, 0.0354],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0347, 0.0355, 0.0349, 0.0345, 0.0345, 0.0344, 0.0345, 0.0345, 0.0349,\n",
            "        0.0345, 0.0345, 0.0341, 0.0356, 0.0354, 0.0346, 0.0355],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0342, 0.0348, 0.0348, 0.0339, 0.0339, 0.0340, 0.0340, 0.0340, 0.0344,\n",
            "        0.0339, 0.0340, 0.0341, 0.0352, 0.0345, 0.0341, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0339, 0.0343, 0.0342, 0.0339, 0.0339, 0.0340, 0.0339, 0.0340, 0.0344,\n",
            "        0.0340, 0.0340, 0.0341, 0.0342, 0.0341, 0.0341, 0.0343],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0339, 0.0343, 0.0342, 0.0339, 0.0339, 0.0340, 0.0339, 0.0340, 0.0344,\n",
            "        0.0340, 0.0340, 0.0341, 0.0342, 0.0341, 0.0341, 0.0343],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0339, 0.0343, 0.0342, 0.0339, 0.0339, 0.0340, 0.0339, 0.0339, 0.0344,\n",
            "        0.0340, 0.0340, 0.0341, 0.0342, 0.0341, 0.0341, 0.0343],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0339, 0.0343, 0.0342, 0.0345, 0.0339, 0.0345, 0.0345, 0.0345, 0.0341,\n",
            "        0.0345, 0.0345, 0.0341, 0.0342, 0.0341, 0.0341, 0.0340],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0345, 0.0348, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0346,\n",
            "        0.0345, 0.0345, 0.0341, 0.0348, 0.0345, 0.0341, 0.0346],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0345, 0.0347, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0346,\n",
            "        0.0345, 0.0345, 0.0341, 0.0345, 0.0345, 0.0346, 0.0346],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
            "        0.0345, 0.0345, 0.0346, 0.0345, 0.0345, 0.0346, 0.0346],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
            "        0.0345, 0.0345, 0.0346, 0.0345, 0.0345, 0.0341, 0.0346],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
            "        0.0345, 0.0345, 0.0341, 0.0345, 0.0345, 0.0341, 0.0345],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0340, 0.0339, 0.0340, 0.0340, 0.0340, 0.0339, 0.0340, 0.0340, 0.0340,\n",
            "        0.0340, 0.0340, 0.0341, 0.0340, 0.0340, 0.0341, 0.0340],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0340, 0.0340, 0.0340, 0.0342, 0.0342, 0.0339, 0.0340, 0.0340, 0.0340,\n",
            "        0.0342, 0.0340, 0.0341, 0.0340, 0.0340, 0.0341, 0.0340],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0342, 0.0340, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
            "        0.0342, 0.0342, 0.0341, 0.0340, 0.0342, 0.0341, 0.0340],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0348, 0.0340, 0.0347, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0347,\n",
            "        0.0348, 0.0348, 0.0341, 0.0342, 0.0348, 0.0341, 0.0342],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0348, 0.0345, 0.0347, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0347,\n",
            "        0.0348, 0.0348, 0.0341, 0.0348, 0.0348, 0.0341, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0230, 0.0238, 0.0223, 0.0236, 0.0245, 0.0234, 0.0231, 0.0223, 0.0228,\n",
            "        0.0229, 0.0232, 0.0225, 0.0248, 0.0231, 0.0237, 0.0233],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0231, 0.0234, 0.0221, 0.0235, 0.0234, 0.0240, 0.0237, 0.0222, 0.0226,\n",
            "        0.0230, 0.0232, 0.0222, 0.0247, 0.0225, 0.0236, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0230, 0.0231, 0.0226, 0.0233, 0.0237, 0.0236, 0.0230, 0.0227, 0.0231,\n",
            "        0.0232, 0.0244, 0.0229, 0.0236, 0.0231, 0.0225, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0233, 0.0233, 0.0229, 0.0230, 0.0236, 0.0229, 0.0236, 0.0227, 0.0234,\n",
            "        0.0234, 0.0237, 0.0231, 0.0236, 0.0231, 0.0228, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0238, 0.0229, 0.0234, 0.0233, 0.0234, 0.0230, 0.0234, 0.0234, 0.0234,\n",
            "        0.0235, 0.0235, 0.0231, 0.0233, 0.0231, 0.0230, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0233, 0.0227, 0.0226, 0.0227, 0.0234, 0.0225, 0.0225, 0.0227, 0.0228,\n",
            "        0.0226, 0.0231, 0.0227, 0.0229, 0.0225, 0.0227, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0230, 0.0228, 0.0225, 0.0227, 0.0229, 0.0225, 0.0226, 0.0227, 0.0228,\n",
            "        0.0226, 0.0229, 0.0227, 0.0228, 0.0225, 0.0227, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0230, 0.0228, 0.0225, 0.0227, 0.0227, 0.0225, 0.0226, 0.0227, 0.0225,\n",
            "        0.0226, 0.0229, 0.0227, 0.0228, 0.0225, 0.0227, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0228, 0.0229, 0.0224, 0.0227, 0.0227, 0.0225, 0.0226, 0.0226, 0.0225,\n",
            "        0.0225, 0.0227, 0.0227, 0.0226, 0.0224, 0.0227, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0228, 0.0224, 0.0224, 0.0226, 0.0225, 0.0223, 0.0223, 0.0226, 0.0224,\n",
            "        0.0224, 0.0227, 0.0226, 0.0226, 0.0224, 0.0225, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0225, 0.0224, 0.0224, 0.0224, 0.0225, 0.0223, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0227, 0.0226, 0.0224, 0.0224, 0.0225, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0223, 0.0224, 0.0224, 0.0224,\n",
            "        0.0223, 0.0227, 0.0226, 0.0224, 0.0224, 0.0225, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0223, 0.0227, 0.0226, 0.0224, 0.0224, 0.0224, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0227, 0.0226, 0.0224, 0.0224, 0.0224, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0226, 0.0226, 0.0224, 0.0224, 0.0224, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0226, 0.0226, 0.0224, 0.0224, 0.0224, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0226, 0.0226, 0.0224, 0.0224, 0.0224, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0223,\n",
            "        0.0224, 0.0226, 0.0226, 0.0224, 0.0223, 0.0224, 0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0223, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0226, 0.0226, 0.0224, 0.0223, 0.0224, 0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0223, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224, 0.0224,\n",
            "        0.0224, 0.0226, 0.0226, 0.0224, 0.0223, 0.0224, 0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0309, 0.0301, 0.0318, 0.0304, 0.0302, 0.0327, 0.0318, 0.0295, 0.0327,\n",
            "        0.0294, 0.0299, 0.0321, 0.0305, 0.0305, 0.0306, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0311, 0.0313, 0.0320, 0.0311, 0.0312, 0.0312, 0.0324, 0.0307, 0.0338,\n",
            "        0.0305, 0.0298, 0.0313, 0.0311, 0.0305, 0.0311, 0.0301],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0312, 0.0303, 0.0310, 0.0309, 0.0308, 0.0305, 0.0316, 0.0301, 0.0315,\n",
            "        0.0302, 0.0298, 0.0309, 0.0314, 0.0311, 0.0305, 0.0304],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0304, 0.0306, 0.0308, 0.0305, 0.0305, 0.0309, 0.0314, 0.0300, 0.0311,\n",
            "        0.0299, 0.0297, 0.0306, 0.0313, 0.0305, 0.0305, 0.0304],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0306, 0.0309, 0.0305, 0.0307, 0.0307, 0.0304, 0.0302, 0.0303, 0.0307,\n",
            "        0.0302, 0.0301, 0.0310, 0.0308, 0.0306, 0.0306, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0300, 0.0309, 0.0304, 0.0300, 0.0302, 0.0308, 0.0302, 0.0303, 0.0304,\n",
            "        0.0302, 0.0304, 0.0305, 0.0302, 0.0303, 0.0303, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0300, 0.0306, 0.0304, 0.0300, 0.0302, 0.0305, 0.0303, 0.0303, 0.0304,\n",
            "        0.0302, 0.0305, 0.0303, 0.0302, 0.0300, 0.0302, 0.0308],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0300, 0.0302, 0.0304, 0.0300, 0.0302, 0.0305, 0.0303, 0.0301, 0.0304,\n",
            "        0.0300, 0.0303, 0.0303, 0.0302, 0.0300, 0.0302, 0.0308],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0298, 0.0300, 0.0298, 0.0298, 0.0300, 0.0298, 0.0300, 0.0298, 0.0298,\n",
            "        0.0298, 0.0307, 0.0300, 0.0298, 0.0300, 0.0300, 0.0309],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0298, 0.0304, 0.0302, 0.0302,\n",
            "        0.0302, 0.0307, 0.0304, 0.0302, 0.0304, 0.0302, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0299, 0.0304, 0.0302, 0.0302,\n",
            "        0.0302, 0.0306, 0.0304, 0.0302, 0.0303, 0.0302, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0299, 0.0302, 0.0302, 0.0302,\n",
            "        0.0302, 0.0306, 0.0304, 0.0302, 0.0303, 0.0302, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0298, 0.0302, 0.0302, 0.0302,\n",
            "        0.0302, 0.0307, 0.0302, 0.0302, 0.0303, 0.0302, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0307, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0303, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0303, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0303, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0303, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0303, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
            "        0.0298, 0.0303, 0.0298, 0.0298, 0.0299, 0.0298, 0.0305],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0289, 0.0280, 0.0280, 0.0282, 0.0303, 0.0296, 0.0285, 0.0285, 0.0304,\n",
            "        0.0288, 0.0289, 0.0289, 0.0316, 0.0286, 0.0288, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0301, 0.0287, 0.0287, 0.0287, 0.0314, 0.0302, 0.0291, 0.0291, 0.0317,\n",
            "        0.0297, 0.0300, 0.0303, 0.0302, 0.0298, 0.0287, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0300, 0.0293, 0.0293, 0.0290, 0.0306, 0.0308, 0.0294, 0.0293, 0.0302,\n",
            "        0.0304, 0.0297, 0.0298, 0.0307, 0.0305, 0.0291, 0.0290],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0295, 0.0298, 0.0294, 0.0289, 0.0298, 0.0301, 0.0297, 0.0293, 0.0297,\n",
            "        0.0297, 0.0296, 0.0298, 0.0296, 0.0305, 0.0290, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0291, 0.0287, 0.0289, 0.0286, 0.0287, 0.0292, 0.0293, 0.0289, 0.0293,\n",
            "        0.0287, 0.0291, 0.0289, 0.0291, 0.0301, 0.0286, 0.0288],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0291, 0.0290, 0.0288, 0.0286, 0.0287, 0.0291, 0.0293, 0.0289, 0.0293,\n",
            "        0.0287, 0.0289, 0.0288, 0.0287, 0.0290, 0.0286, 0.0288],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0288, 0.0298, 0.0288, 0.0288, 0.0289, 0.0291, 0.0294, 0.0289, 0.0289,\n",
            "        0.0289, 0.0298, 0.0288, 0.0289, 0.0291, 0.0289, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0292, 0.0298, 0.0288, 0.0293, 0.0288, 0.0291, 0.0295, 0.0293, 0.0288,\n",
            "        0.0293, 0.0298, 0.0288, 0.0289, 0.0291, 0.0293, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0292, 0.0298, 0.0293, 0.0293, 0.0292, 0.0295, 0.0295, 0.0293, 0.0292,\n",
            "        0.0293, 0.0298, 0.0292, 0.0293, 0.0293, 0.0293, 0.0292],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0291, 0.0298, 0.0293, 0.0291, 0.0292, 0.0295, 0.0295, 0.0291, 0.0292,\n",
            "        0.0291, 0.0298, 0.0292, 0.0293, 0.0293, 0.0291, 0.0292],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0291, 0.0295, 0.0288, 0.0291, 0.0290, 0.0293, 0.0291, 0.0291, 0.0292,\n",
            "        0.0291, 0.0295, 0.0292, 0.0291, 0.0292, 0.0291, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0291, 0.0295, 0.0288, 0.0291, 0.0290, 0.0287, 0.0291, 0.0286, 0.0288,\n",
            "        0.0291, 0.0295, 0.0287, 0.0291, 0.0288, 0.0291, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0286, 0.0296, 0.0288, 0.0287, 0.0286, 0.0287, 0.0286, 0.0286, 0.0288,\n",
            "        0.0287, 0.0295, 0.0287, 0.0291, 0.0287, 0.0286, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0286, 0.0295, 0.0287, 0.0287, 0.0286, 0.0287, 0.0286, 0.0286, 0.0288,\n",
            "        0.0287, 0.0294, 0.0287, 0.0286, 0.0287, 0.0286, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0286, 0.0295, 0.0287, 0.0287, 0.0286, 0.0287, 0.0286, 0.0291, 0.0287,\n",
            "        0.0286, 0.0295, 0.0287, 0.0287, 0.0287, 0.0287, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0291, 0.0295, 0.0287, 0.0291, 0.0287, 0.0287, 0.0290, 0.0291, 0.0287,\n",
            "        0.0290, 0.0295, 0.0288, 0.0287, 0.0287, 0.0291, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0290, 0.0295, 0.0292, 0.0291, 0.0291, 0.0292, 0.0290, 0.0291, 0.0292,\n",
            "        0.0290, 0.0295, 0.0292, 0.0291, 0.0292, 0.0291, 0.0292],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0290, 0.0295, 0.0287, 0.0291, 0.0291, 0.0292, 0.0290, 0.0291, 0.0288,\n",
            "        0.0290, 0.0295, 0.0292, 0.0291, 0.0287, 0.0291, 0.0288],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0290, 0.0295, 0.0287, 0.0291, 0.0291, 0.0287, 0.0290, 0.0291, 0.0288,\n",
            "        0.0290, 0.0295, 0.0287, 0.0290, 0.0287, 0.0291, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0286, 0.0295, 0.0287, 0.0286, 0.0291, 0.0287, 0.0286, 0.0287, 0.0288,\n",
            "        0.0286, 0.0295, 0.0287, 0.0290, 0.0287, 0.0286, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0297, 0.0282, 0.0303, 0.0276, 0.0289, 0.0285, 0.0295, 0.0301, 0.0283,\n",
            "        0.0294, 0.0303, 0.0289, 0.0301, 0.0300, 0.0296, 0.0300],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0297, 0.0285, 0.0297, 0.0278, 0.0285, 0.0286, 0.0298, 0.0288, 0.0278,\n",
            "        0.0294, 0.0299, 0.0291, 0.0287, 0.0301, 0.0300, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0306, 0.0296, 0.0303, 0.0287, 0.0298, 0.0297, 0.0297, 0.0295, 0.0289,\n",
            "        0.0295, 0.0297, 0.0304, 0.0288, 0.0306, 0.0290, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0309, 0.0291, 0.0301, 0.0289, 0.0298, 0.0300, 0.0292, 0.0292, 0.0298,\n",
            "        0.0299, 0.0296, 0.0311, 0.0289, 0.0293, 0.0294, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0309, 0.0291, 0.0303, 0.0291, 0.0301, 0.0303, 0.0294, 0.0296, 0.0293,\n",
            "        0.0295, 0.0298, 0.0298, 0.0291, 0.0296, 0.0296, 0.0297],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0290, 0.0287, 0.0296, 0.0287, 0.0297, 0.0293, 0.0290, 0.0288, 0.0286,\n",
            "        0.0287, 0.0292, 0.0289, 0.0287, 0.0290, 0.0289, 0.0290],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0290, 0.0287, 0.0291, 0.0285, 0.0289, 0.0290, 0.0288, 0.0288, 0.0286,\n",
            "        0.0287, 0.0292, 0.0289, 0.0287, 0.0287, 0.0289, 0.0288],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0290, 0.0285, 0.0291, 0.0285, 0.0289, 0.0287, 0.0287, 0.0286, 0.0286,\n",
            "        0.0285, 0.0290, 0.0287, 0.0285, 0.0287, 0.0287, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0288, 0.0285, 0.0289, 0.0285, 0.0289, 0.0286, 0.0287, 0.0286, 0.0286,\n",
            "        0.0285, 0.0290, 0.0285, 0.0285, 0.0287, 0.0287, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0288, 0.0285, 0.0289, 0.0285, 0.0289, 0.0286, 0.0287, 0.0286, 0.0286,\n",
            "        0.0285, 0.0290, 0.0285, 0.0285, 0.0287, 0.0285, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0286, 0.0285, 0.0285, 0.0285, 0.0289, 0.0286, 0.0286, 0.0286, 0.0286,\n",
            "        0.0285, 0.0288, 0.0285, 0.0285, 0.0287, 0.0285, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0286, 0.0285, 0.0285, 0.0285, 0.0289, 0.0286, 0.0286, 0.0286, 0.0286,\n",
            "        0.0285, 0.0285, 0.0285, 0.0285, 0.0287, 0.0285, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0289, 0.0289, 0.0289, 0.0289, 0.0286, 0.0286, 0.0287, 0.0289, 0.0286,\n",
            "        0.0289, 0.0289, 0.0289, 0.0289, 0.0287, 0.0289, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0289, 0.0289, 0.0289, 0.0285, 0.0286, 0.0286, 0.0287, 0.0289, 0.0286,\n",
            "        0.0289, 0.0289, 0.0289, 0.0289, 0.0287, 0.0289, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0286, 0.0285, 0.0285, 0.0285, 0.0286, 0.0287, 0.0287, 0.0285, 0.0286,\n",
            "        0.0289, 0.0289, 0.0285, 0.0285, 0.0287, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0285, 0.0285, 0.0285, 0.0285, 0.0286, 0.0287, 0.0287, 0.0285, 0.0286,\n",
            "        0.0285, 0.0285, 0.0285, 0.0285, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0285, 0.0286, 0.0285, 0.0285, 0.0286, 0.0286, 0.0286, 0.0285, 0.0286,\n",
            "        0.0285, 0.0285, 0.0285, 0.0285, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0285, 0.0286, 0.0285, 0.0285, 0.0286, 0.0286, 0.0286, 0.0285, 0.0286,\n",
            "        0.0285, 0.0285, 0.0285, 0.0285, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0285, 0.0286, 0.0285, 0.0285, 0.0286, 0.0286, 0.0286, 0.0285, 0.0286,\n",
            "        0.0285, 0.0285, 0.0285, 0.0285, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0285, 0.0286, 0.0285, 0.0285, 0.0286, 0.0286, 0.0286, 0.0285, 0.0286,\n",
            "        0.0285, 0.0285, 0.0285, 0.0285, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0336, 0.0322, 0.0322, 0.0316, 0.0330, 0.0327, 0.0321, 0.0329, 0.0325,\n",
            "        0.0319, 0.0342, 0.0320, 0.0318, 0.0316, 0.0355, 0.0333],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0327, 0.0321, 0.0336, 0.0319, 0.0324, 0.0332, 0.0333, 0.0338, 0.0334,\n",
            "        0.0321, 0.0345, 0.0323, 0.0328, 0.0323, 0.0346, 0.0337],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0329, 0.0323, 0.0323, 0.0318, 0.0323, 0.0325, 0.0335, 0.0324, 0.0336,\n",
            "        0.0316, 0.0338, 0.0322, 0.0326, 0.0327, 0.0345, 0.0332],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0325, 0.0328, 0.0327, 0.0322, 0.0327, 0.0332, 0.0334, 0.0329, 0.0334,\n",
            "        0.0320, 0.0334, 0.0325, 0.0327, 0.0328, 0.0345, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0327, 0.0322, 0.0322, 0.0325, 0.0325, 0.0316, 0.0321, 0.0321, 0.0320,\n",
            "        0.0316, 0.0323, 0.0322, 0.0329, 0.0323, 0.0342, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0336, 0.0318, 0.0322, 0.0329, 0.0319, 0.0316, 0.0321, 0.0321, 0.0320,\n",
            "        0.0316, 0.0318, 0.0321, 0.0325, 0.0316, 0.0320, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0334, 0.0318, 0.0320, 0.0327, 0.0319, 0.0316, 0.0319, 0.0319, 0.0320,\n",
            "        0.0316, 0.0318, 0.0320, 0.0320, 0.0316, 0.0320, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0327, 0.0318, 0.0316, 0.0327, 0.0319, 0.0316, 0.0316, 0.0319, 0.0318,\n",
            "        0.0316, 0.0318, 0.0320, 0.0320, 0.0316, 0.0318, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0327, 0.0316, 0.0314, 0.0327, 0.0317, 0.0314, 0.0316, 0.0316, 0.0318,\n",
            "        0.0313, 0.0318, 0.0322, 0.0314, 0.0314, 0.0318, 0.0316],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0330, 0.0316, 0.0314, 0.0324, 0.0317, 0.0314, 0.0315, 0.0316, 0.0315,\n",
            "        0.0313, 0.0316, 0.0326, 0.0314, 0.0314, 0.0318, 0.0316],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0330, 0.0318, 0.0319, 0.0324, 0.0322, 0.0319, 0.0320, 0.0321, 0.0320,\n",
            "        0.0318, 0.0321, 0.0326, 0.0319, 0.0319, 0.0321, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0330, 0.0318, 0.0319, 0.0324, 0.0322, 0.0319, 0.0320, 0.0319, 0.0320,\n",
            "        0.0318, 0.0321, 0.0326, 0.0319, 0.0319, 0.0321, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0329, 0.0318, 0.0319, 0.0324, 0.0318, 0.0318, 0.0320, 0.0319, 0.0320,\n",
            "        0.0318, 0.0321, 0.0326, 0.0319, 0.0318, 0.0321, 0.0319],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0329, 0.0318, 0.0318, 0.0324, 0.0318, 0.0318, 0.0315, 0.0319, 0.0315,\n",
            "        0.0318, 0.0318, 0.0326, 0.0319, 0.0318, 0.0315, 0.0319],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0324, 0.0313, 0.0313, 0.0319, 0.0313, 0.0313, 0.0315, 0.0313, 0.0315,\n",
            "        0.0313, 0.0313, 0.0321, 0.0313, 0.0313, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0324, 0.0313, 0.0313, 0.0319, 0.0314, 0.0313, 0.0315, 0.0313, 0.0315,\n",
            "        0.0313, 0.0313, 0.0321, 0.0313, 0.0313, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0324, 0.0313, 0.0313, 0.0319, 0.0314, 0.0313, 0.0315, 0.0313, 0.0315,\n",
            "        0.0313, 0.0313, 0.0321, 0.0313, 0.0314, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0324, 0.0313, 0.0313, 0.0319, 0.0314, 0.0313, 0.0315, 0.0313, 0.0315,\n",
            "        0.0313, 0.0313, 0.0321, 0.0313, 0.0314, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0324, 0.0313, 0.0313, 0.0319, 0.0314, 0.0314, 0.0315, 0.0313, 0.0315,\n",
            "        0.0313, 0.0313, 0.0321, 0.0313, 0.0314, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0324, 0.0313, 0.0313, 0.0323, 0.0314, 0.0314, 0.0315, 0.0313, 0.0315,\n",
            "        0.0314, 0.0313, 0.0321, 0.0313, 0.0314, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0333, 0.0305, 0.0326, 0.0316, 0.0327, 0.0318, 0.0313, 0.0340, 0.0327,\n",
            "        0.0327, 0.0345, 0.0310, 0.0341, 0.0318, 0.0323, 0.0328],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0326, 0.0309, 0.0326, 0.0319, 0.0322, 0.0327, 0.0313, 0.0323, 0.0330,\n",
            "        0.0326, 0.0326, 0.0313, 0.0326, 0.0313, 0.0337, 0.0326],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0325, 0.0316, 0.0325, 0.0323, 0.0324, 0.0325, 0.0321, 0.0329, 0.0340,\n",
            "        0.0331, 0.0331, 0.0317, 0.0331, 0.0319, 0.0330, 0.0323],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0320, 0.0317, 0.0324, 0.0318, 0.0327, 0.0326, 0.0320, 0.0339, 0.0321,\n",
            "        0.0320, 0.0328, 0.0320, 0.0334, 0.0320, 0.0327, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0322, 0.0320, 0.0327, 0.0320, 0.0327, 0.0321, 0.0317, 0.0325, 0.0318,\n",
            "        0.0322, 0.0330, 0.0324, 0.0334, 0.0320, 0.0319, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0317, 0.0315, 0.0322, 0.0315, 0.0321, 0.0315, 0.0317, 0.0321, 0.0318,\n",
            "        0.0317, 0.0325, 0.0319, 0.0319, 0.0315, 0.0319, 0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0317, 0.0315, 0.0317, 0.0315, 0.0317, 0.0315, 0.0315, 0.0318, 0.0315,\n",
            "        0.0317, 0.0318, 0.0319, 0.0319, 0.0315, 0.0317, 0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0317, 0.0312, 0.0317, 0.0312, 0.0317, 0.0313, 0.0315, 0.0318, 0.0315,\n",
            "        0.0317, 0.0318, 0.0316, 0.0319, 0.0313, 0.0317, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0312, 0.0312, 0.0313, 0.0312, 0.0315, 0.0313, 0.0315, 0.0318, 0.0315,\n",
            "        0.0312, 0.0316, 0.0312, 0.0316, 0.0313, 0.0317, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0312, 0.0312, 0.0313, 0.0312, 0.0315, 0.0313, 0.0315, 0.0318, 0.0315,\n",
            "        0.0312, 0.0316, 0.0312, 0.0316, 0.0313, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0313, 0.0312, 0.0313, 0.0312, 0.0315, 0.0313, 0.0315, 0.0316, 0.0315,\n",
            "        0.0313, 0.0316, 0.0312, 0.0316, 0.0313, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0313, 0.0312, 0.0313, 0.0312, 0.0313, 0.0313, 0.0314, 0.0316, 0.0315,\n",
            "        0.0313, 0.0316, 0.0312, 0.0314, 0.0313, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0313, 0.0313, 0.0313, 0.0312, 0.0313, 0.0313, 0.0314, 0.0315, 0.0314,\n",
            "        0.0313, 0.0315, 0.0312, 0.0314, 0.0312, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0314, 0.0315, 0.0314,\n",
            "        0.0313, 0.0312, 0.0313, 0.0313, 0.0312, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0314, 0.0315, 0.0314,\n",
            "        0.0313, 0.0312, 0.0313, 0.0313, 0.0312, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0315, 0.0315, 0.0315,\n",
            "        0.0313, 0.0312, 0.0313, 0.0313, 0.0313, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0315, 0.0315, 0.0315,\n",
            "        0.0313, 0.0313, 0.0313, 0.0312, 0.0313, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0315, 0.0315, 0.0315,\n",
            "        0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0314, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0315, 0.0315, 0.0314,\n",
            "        0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0314, 0.0315, 0.0314,\n",
            "        0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0315, 0.0313],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0229, 0.0246, 0.0237, 0.0233, 0.0231, 0.0258, 0.0245, 0.0236, 0.0237,\n",
            "        0.0244, 0.0227, 0.0239, 0.0242, 0.0235, 0.0239, 0.0235],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0226, 0.0233, 0.0234, 0.0226, 0.0234, 0.0243, 0.0230, 0.0229, 0.0232,\n",
            "        0.0254, 0.0231, 0.0241, 0.0228, 0.0229, 0.0232, 0.0240],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0236, 0.0239, 0.0234, 0.0237, 0.0240, 0.0242, 0.0235, 0.0235, 0.0244,\n",
            "        0.0254, 0.0239, 0.0255, 0.0235, 0.0233, 0.0240, 0.0246],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0239, 0.0242, 0.0236, 0.0231, 0.0228, 0.0244, 0.0230, 0.0231, 0.0248,\n",
            "        0.0240, 0.0231, 0.0243, 0.0242, 0.0231, 0.0242, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0234, 0.0230, 0.0231, 0.0231, 0.0231, 0.0245, 0.0228, 0.0230, 0.0235,\n",
            "        0.0230, 0.0229, 0.0243, 0.0242, 0.0233, 0.0233, 0.0231],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0230, 0.0230, 0.0233, 0.0228, 0.0228, 0.0233, 0.0228, 0.0228, 0.0235,\n",
            "        0.0230, 0.0228, 0.0228, 0.0235, 0.0230, 0.0233, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0230, 0.0230, 0.0231, 0.0228, 0.0228, 0.0233, 0.0228, 0.0228, 0.0230,\n",
            "        0.0228, 0.0228, 0.0228, 0.0230, 0.0228, 0.0233, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0228, 0.0228, 0.0230, 0.0228, 0.0228, 0.0230, 0.0226, 0.0228, 0.0230,\n",
            "        0.0228, 0.0228, 0.0230, 0.0230, 0.0228, 0.0233, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0226, 0.0228, 0.0230, 0.0228, 0.0228, 0.0230, 0.0230, 0.0228, 0.0232,\n",
            "        0.0228, 0.0228, 0.0228, 0.0230, 0.0228, 0.0230, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0226, 0.0232, 0.0230, 0.0228, 0.0228, 0.0232, 0.0230, 0.0228, 0.0232,\n",
            "        0.0228, 0.0228, 0.0226, 0.0230, 0.0228, 0.0230, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0226, 0.0228, 0.0227, 0.0228, 0.0228, 0.0232, 0.0227, 0.0228, 0.0228,\n",
            "        0.0228, 0.0228, 0.0226, 0.0230, 0.0228, 0.0227, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0226, 0.0226, 0.0227, 0.0228, 0.0228, 0.0228, 0.0227, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0230, 0.0228, 0.0227, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0226, 0.0227, 0.0227, 0.0228, 0.0228, 0.0226, 0.0226, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0227, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0226, 0.0227, 0.0227, 0.0228, 0.0228, 0.0226, 0.0226, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0227, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0226, 0.0227, 0.0227, 0.0228, 0.0228, 0.0227, 0.0226, 0.0228, 0.0227,\n",
            "        0.0228, 0.0228, 0.0227, 0.0228, 0.0228, 0.0227, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0226, 0.0227, 0.0226, 0.0228, 0.0228, 0.0226, 0.0226, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0226, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0226, 0.0227, 0.0226, 0.0228, 0.0228, 0.0226, 0.0226, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0226, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0226, 0.0226, 0.0226, 0.0228, 0.0228, 0.0226, 0.0230, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0226, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0226, 0.0226, 0.0226, 0.0228, 0.0228, 0.0226, 0.0226, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0226, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0226, 0.0226, 0.0226, 0.0228, 0.0228, 0.0226, 0.0226, 0.0228, 0.0226,\n",
            "        0.0228, 0.0228, 0.0226, 0.0228, 0.0228, 0.0226, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0357, 0.0366, 0.0353, 0.0350, 0.0350, 0.0357, 0.0344, 0.0349, 0.0345,\n",
            "        0.0361, 0.0346, 0.0356, 0.0363, 0.0359, 0.0348, 0.0352],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0352, 0.0367, 0.0345, 0.0350, 0.0354, 0.0354, 0.0341, 0.0347, 0.0343,\n",
            "        0.0350, 0.0355, 0.0363, 0.0356, 0.0351, 0.0352, 0.0358],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0362, 0.0356, 0.0352, 0.0361, 0.0349, 0.0350, 0.0346, 0.0357, 0.0344,\n",
            "        0.0356, 0.0360, 0.0361, 0.0356, 0.0357, 0.0367, 0.0354],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0361, 0.0361, 0.0359, 0.0363, 0.0356, 0.0359, 0.0353, 0.0372, 0.0356,\n",
            "        0.0371, 0.0365, 0.0361, 0.0360, 0.0364, 0.0361, 0.0354],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0358, 0.0360, 0.0357, 0.0365, 0.0356, 0.0361, 0.0353, 0.0357, 0.0355,\n",
            "        0.0366, 0.0365, 0.0363, 0.0363, 0.0357, 0.0358, 0.0356],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0353, 0.0350, 0.0357, 0.0352, 0.0355, 0.0361, 0.0356, 0.0352, 0.0356,\n",
            "        0.0364, 0.0359, 0.0357, 0.0355, 0.0357, 0.0353, 0.0355],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0350, 0.0350, 0.0352, 0.0352, 0.0350, 0.0353, 0.0348, 0.0351, 0.0348,\n",
            "        0.0353, 0.0353, 0.0353, 0.0350, 0.0352, 0.0350, 0.0349],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0350, 0.0350, 0.0350, 0.0352, 0.0348, 0.0350, 0.0348, 0.0351, 0.0348,\n",
            "        0.0353, 0.0353, 0.0353, 0.0348, 0.0352, 0.0350, 0.0347],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0350, 0.0350, 0.0350, 0.0352, 0.0348, 0.0348, 0.0348, 0.0351, 0.0348,\n",
            "        0.0351, 0.0353, 0.0348, 0.0348, 0.0350, 0.0350, 0.0347],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0350, 0.0350, 0.0350, 0.0352, 0.0348, 0.0348, 0.0348, 0.0351, 0.0348,\n",
            "        0.0350, 0.0350, 0.0348, 0.0348, 0.0350, 0.0351, 0.0347],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0350, 0.0350, 0.0348, 0.0352, 0.0348, 0.0348, 0.0348, 0.0350, 0.0348,\n",
            "        0.0350, 0.0350, 0.0348, 0.0348, 0.0348, 0.0351, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0350, 0.0350, 0.0348, 0.0351, 0.0348, 0.0348, 0.0348, 0.0350, 0.0348,\n",
            "        0.0350, 0.0349, 0.0348, 0.0347, 0.0348, 0.0351, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0350, 0.0350, 0.0353, 0.0350, 0.0353, 0.0353, 0.0353, 0.0350, 0.0353,\n",
            "        0.0353, 0.0349, 0.0348, 0.0347, 0.0348, 0.0350, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0350, 0.0349, 0.0348, 0.0349, 0.0353, 0.0348, 0.0348, 0.0350, 0.0353,\n",
            "        0.0353, 0.0349, 0.0353, 0.0353, 0.0348, 0.0349, 0.0353],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0350, 0.0349, 0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0350, 0.0348,\n",
            "        0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0349, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0349, 0.0349, 0.0348, 0.0349, 0.0348, 0.0347, 0.0348, 0.0349, 0.0347,\n",
            "        0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0349, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0349, 0.0350, 0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0349, 0.0347,\n",
            "        0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0349, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0349, 0.0350, 0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0349, 0.0348,\n",
            "        0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0350, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0349, 0.0350, 0.0348, 0.0350, 0.0348, 0.0348, 0.0348, 0.0349, 0.0348,\n",
            "        0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0350, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0349, 0.0350, 0.0348, 0.0350, 0.0348, 0.0348, 0.0348, 0.0349, 0.0348,\n",
            "        0.0348, 0.0349, 0.0348, 0.0348, 0.0348, 0.0350, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0249, 0.0241, 0.0236, 0.0231, 0.0237, 0.0235, 0.0239, 0.0235, 0.0251,\n",
            "        0.0237, 0.0236, 0.0234, 0.0253, 0.0235, 0.0235, 0.0248],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0243, 0.0232, 0.0243, 0.0239, 0.0235, 0.0241, 0.0247, 0.0239, 0.0246,\n",
            "        0.0232, 0.0238, 0.0237, 0.0243, 0.0241, 0.0233, 0.0245],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0243, 0.0237, 0.0234, 0.0239, 0.0237, 0.0247, 0.0240, 0.0238, 0.0243,\n",
            "        0.0237, 0.0245, 0.0235, 0.0245, 0.0235, 0.0237, 0.0242],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0237, 0.0238, 0.0233, 0.0240, 0.0234, 0.0247, 0.0237, 0.0241, 0.0242,\n",
            "        0.0238, 0.0237, 0.0236, 0.0237, 0.0238, 0.0234, 0.0235],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0231, 0.0235, 0.0235, 0.0234, 0.0232, 0.0234, 0.0238, 0.0240, 0.0241,\n",
            "        0.0239, 0.0231, 0.0236, 0.0237, 0.0241, 0.0234, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0231, 0.0232, 0.0231, 0.0232, 0.0232, 0.0234, 0.0238, 0.0235, 0.0234,\n",
            "        0.0240, 0.0231, 0.0234, 0.0237, 0.0235, 0.0234, 0.0234],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0231, 0.0234, 0.0229, 0.0229, 0.0232, 0.0234, 0.0233, 0.0234, 0.0236,\n",
            "        0.0240, 0.0229, 0.0234, 0.0231, 0.0235, 0.0232, 0.0234],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0231, 0.0232, 0.0230, 0.0229, 0.0232, 0.0230, 0.0231, 0.0232, 0.0234,\n",
            "        0.0240, 0.0229, 0.0231, 0.0229, 0.0230, 0.0230, 0.0230],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0231, 0.0230, 0.0229, 0.0229, 0.0232, 0.0230, 0.0231, 0.0233, 0.0232,\n",
            "        0.0237, 0.0229, 0.0231, 0.0229, 0.0229, 0.0230, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0234, 0.0233, 0.0233, 0.0232, 0.0236, 0.0233, 0.0235, 0.0233, 0.0233,\n",
            "        0.0237, 0.0233, 0.0235, 0.0233, 0.0233, 0.0233, 0.0233],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0234, 0.0233, 0.0233, 0.0232, 0.0235, 0.0232, 0.0235, 0.0233, 0.0233,\n",
            "        0.0237, 0.0233, 0.0235, 0.0233, 0.0233, 0.0233, 0.0233],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0234, 0.0233, 0.0233, 0.0232, 0.0235, 0.0232, 0.0235, 0.0233, 0.0233,\n",
            "        0.0237, 0.0233, 0.0235, 0.0233, 0.0233, 0.0233, 0.0233],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0234, 0.0233, 0.0233, 0.0232, 0.0235, 0.0232, 0.0235, 0.0233, 0.0233,\n",
            "        0.0237, 0.0232, 0.0235, 0.0233, 0.0233, 0.0233, 0.0233],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0234, 0.0233, 0.0233, 0.0232, 0.0234, 0.0233, 0.0233, 0.0233, 0.0233,\n",
            "        0.0237, 0.0232, 0.0235, 0.0233, 0.0233, 0.0233, 0.0233],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0231, 0.0229, 0.0230, 0.0230, 0.0231, 0.0229, 0.0230, 0.0229, 0.0230,\n",
            "        0.0234, 0.0229, 0.0231, 0.0230, 0.0230, 0.0229, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0231, 0.0229, 0.0230, 0.0230, 0.0231, 0.0230, 0.0230, 0.0229, 0.0230,\n",
            "        0.0234, 0.0229, 0.0231, 0.0230, 0.0230, 0.0229, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0231, 0.0229, 0.0230, 0.0230, 0.0231, 0.0230, 0.0230, 0.0230, 0.0229,\n",
            "        0.0234, 0.0229, 0.0231, 0.0230, 0.0230, 0.0229, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0231, 0.0229, 0.0230, 0.0230, 0.0231, 0.0230, 0.0230, 0.0230, 0.0229,\n",
            "        0.0234, 0.0229, 0.0231, 0.0230, 0.0230, 0.0230, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0231, 0.0229, 0.0230, 0.0230, 0.0231, 0.0230, 0.0230, 0.0230, 0.0229,\n",
            "        0.0234, 0.0229, 0.0231, 0.0230, 0.0230, 0.0230, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0231, 0.0229, 0.0230, 0.0230, 0.0231, 0.0230, 0.0230, 0.0230, 0.0229,\n",
            "        0.0237, 0.0229, 0.0231, 0.0229, 0.0229, 0.0230, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0147, 0.0147, 0.0169, 0.0144, 0.0151, 0.0154, 0.0171, 0.0139, 0.0147,\n",
            "        0.0151, 0.0149, 0.0164, 0.0156, 0.0151, 0.0150, 0.0150],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0143, 0.0150, 0.0145, 0.0146, 0.0147, 0.0149, 0.0166, 0.0139, 0.0152,\n",
            "        0.0152, 0.0151, 0.0171, 0.0145, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0147, 0.0147, 0.0148, 0.0142, 0.0148, 0.0146, 0.0155, 0.0143, 0.0160,\n",
            "        0.0150, 0.0158, 0.0161, 0.0147, 0.0147, 0.0140, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0147, 0.0145, 0.0152, 0.0143, 0.0146, 0.0143, 0.0155, 0.0143, 0.0153,\n",
            "        0.0152, 0.0154, 0.0156, 0.0151, 0.0148, 0.0142, 0.0152],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0147, 0.0141, 0.0155, 0.0143, 0.0142, 0.0143, 0.0151, 0.0143, 0.0146,\n",
            "        0.0147, 0.0154, 0.0154, 0.0150, 0.0143, 0.0144, 0.0146],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0147, 0.0143, 0.0147, 0.0143, 0.0142, 0.0143, 0.0148, 0.0143, 0.0141,\n",
            "        0.0144, 0.0146, 0.0151, 0.0147, 0.0143, 0.0144, 0.0146],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0143, 0.0143, 0.0144, 0.0141, 0.0142, 0.0143, 0.0148, 0.0143, 0.0141,\n",
            "        0.0144, 0.0144, 0.0146, 0.0143, 0.0143, 0.0144, 0.0143],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0143, 0.0145, 0.0145, 0.0143, 0.0144, 0.0145, 0.0147, 0.0143, 0.0145,\n",
            "        0.0146, 0.0144, 0.0145, 0.0145, 0.0145, 0.0143, 0.0145],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0142, 0.0143, 0.0145, 0.0142, 0.0142, 0.0143, 0.0145, 0.0143, 0.0145,\n",
            "        0.0145, 0.0144, 0.0147, 0.0145, 0.0144, 0.0142, 0.0143],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0142, 0.0142, 0.0143, 0.0142, 0.0142, 0.0142, 0.0145, 0.0142, 0.0142,\n",
            "        0.0142, 0.0143, 0.0147, 0.0143, 0.0142, 0.0142, 0.0143],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0142, 0.0142, 0.0140, 0.0142, 0.0142, 0.0142, 0.0145, 0.0142, 0.0142,\n",
            "        0.0142, 0.0142, 0.0147, 0.0143, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0142, 0.0142, 0.0140, 0.0142, 0.0142, 0.0142, 0.0143, 0.0142, 0.0142,\n",
            "        0.0142, 0.0142, 0.0146, 0.0142, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0142, 0.0142, 0.0140, 0.0142, 0.0142, 0.0142, 0.0143, 0.0142, 0.0142,\n",
            "        0.0142, 0.0142, 0.0146, 0.0142, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0143, 0.0142, 0.0142,\n",
            "        0.0142, 0.0144, 0.0146, 0.0142, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0140, 0.0140, 0.0142, 0.0140, 0.0140, 0.0140, 0.0145, 0.0140, 0.0140,\n",
            "        0.0140, 0.0144, 0.0143, 0.0140, 0.0140, 0.0140, 0.0140],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0140, 0.0140, 0.0142, 0.0140, 0.0140, 0.0140, 0.0145, 0.0140, 0.0140,\n",
            "        0.0140, 0.0144, 0.0142, 0.0140, 0.0140, 0.0140, 0.0140],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0140, 0.0140, 0.0142, 0.0140, 0.0140, 0.0140, 0.0142, 0.0140, 0.0140,\n",
            "        0.0140, 0.0144, 0.0142, 0.0140, 0.0140, 0.0140, 0.0140],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
            "        0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
            "        0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
            "        0.0142, 0.0142, 0.0144, 0.0142, 0.0142, 0.0142, 0.0142],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0176, 0.0172, 0.0177, 0.0173, 0.0178, 0.0180, 0.0172, 0.0180, 0.0188,\n",
            "        0.0186, 0.0175, 0.0186, 0.0183, 0.0169, 0.0179, 0.0175],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0187, 0.0181, 0.0178, 0.0177, 0.0177, 0.0186, 0.0182, 0.0181, 0.0190,\n",
            "        0.0182, 0.0183, 0.0187, 0.0182, 0.0173, 0.0184, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0186, 0.0179, 0.0178, 0.0181, 0.0182, 0.0177, 0.0184, 0.0180, 0.0181,\n",
            "        0.0182, 0.0185, 0.0178, 0.0173, 0.0175, 0.0179, 0.0179],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0185, 0.0181, 0.0174, 0.0181, 0.0180, 0.0177, 0.0185, 0.0184, 0.0180,\n",
            "        0.0178, 0.0180, 0.0180, 0.0180, 0.0174, 0.0189, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0182, 0.0181, 0.0175, 0.0183, 0.0174, 0.0175, 0.0181, 0.0184, 0.0176,\n",
            "        0.0179, 0.0177, 0.0174, 0.0179, 0.0171, 0.0182, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0183, 0.0177, 0.0179, 0.0178, 0.0175, 0.0176, 0.0179, 0.0183, 0.0177,\n",
            "        0.0177, 0.0174, 0.0173, 0.0180, 0.0172, 0.0178, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0178, 0.0177, 0.0182, 0.0178, 0.0175, 0.0175, 0.0174, 0.0178, 0.0175,\n",
            "        0.0177, 0.0174, 0.0173, 0.0180, 0.0172, 0.0178, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0176, 0.0176, 0.0182, 0.0175, 0.0174, 0.0177, 0.0174, 0.0176, 0.0175,\n",
            "        0.0174, 0.0174, 0.0172, 0.0179, 0.0172, 0.0179, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0178, 0.0178, 0.0182, 0.0177, 0.0176, 0.0176, 0.0176, 0.0178, 0.0177,\n",
            "        0.0174, 0.0174, 0.0174, 0.0178, 0.0174, 0.0178, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0178, 0.0177, 0.0182, 0.0177, 0.0175, 0.0176, 0.0176, 0.0177, 0.0175,\n",
            "        0.0174, 0.0174, 0.0173, 0.0176, 0.0173, 0.0178, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0176, 0.0175, 0.0181, 0.0177, 0.0175, 0.0174, 0.0176, 0.0177, 0.0174,\n",
            "        0.0174, 0.0172, 0.0173, 0.0174, 0.0173, 0.0176, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0176, 0.0175, 0.0181, 0.0176, 0.0175, 0.0174, 0.0172, 0.0177, 0.0173,\n",
            "        0.0173, 0.0172, 0.0173, 0.0174, 0.0173, 0.0174, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0176, 0.0175, 0.0179, 0.0176, 0.0176, 0.0174, 0.0172, 0.0175, 0.0173,\n",
            "        0.0173, 0.0172, 0.0172, 0.0174, 0.0173, 0.0173, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0176, 0.0175, 0.0179, 0.0176, 0.0176, 0.0173, 0.0172, 0.0175, 0.0173,\n",
            "        0.0173, 0.0173, 0.0172, 0.0174, 0.0173, 0.0173, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0173, 0.0173, 0.0179, 0.0173, 0.0173, 0.0173, 0.0171, 0.0173, 0.0171,\n",
            "        0.0171, 0.0171, 0.0171, 0.0173, 0.0171, 0.0173, 0.0171],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0173, 0.0173, 0.0181, 0.0173, 0.0173, 0.0173, 0.0171, 0.0173, 0.0171,\n",
            "        0.0171, 0.0171, 0.0171, 0.0173, 0.0171, 0.0173, 0.0171],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0173, 0.0173, 0.0181, 0.0173, 0.0173, 0.0173, 0.0171, 0.0173, 0.0171,\n",
            "        0.0171, 0.0171, 0.0171, 0.0173, 0.0171, 0.0173, 0.0171],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0173, 0.0173, 0.0181, 0.0173, 0.0173, 0.0175, 0.0171, 0.0174, 0.0171,\n",
            "        0.0171, 0.0171, 0.0171, 0.0175, 0.0171, 0.0176, 0.0171],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0173, 0.0173, 0.0181, 0.0173, 0.0173, 0.0175, 0.0171, 0.0174, 0.0171,\n",
            "        0.0171, 0.0171, 0.0171, 0.0175, 0.0171, 0.0176, 0.0171],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0173, 0.0173, 0.0181, 0.0173, 0.0173, 0.0174, 0.0173, 0.0174, 0.0173,\n",
            "        0.0172, 0.0173, 0.0173, 0.0173, 0.0173, 0.0174, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0308, 0.0315, 0.0331, 0.0314, 0.0310, 0.0319, 0.0322, 0.0328, 0.0316,\n",
            "        0.0333, 0.0322, 0.0315, 0.0313, 0.0328, 0.0327, 0.0319],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0317, 0.0317, 0.0321, 0.0330, 0.0312, 0.0320, 0.0326, 0.0326, 0.0320,\n",
            "        0.0330, 0.0327, 0.0317, 0.0325, 0.0319, 0.0331, 0.0325],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0306, 0.0317, 0.0317, 0.0317, 0.0316, 0.0315, 0.0323, 0.0323, 0.0321,\n",
            "        0.0329, 0.0318, 0.0318, 0.0315, 0.0313, 0.0317, 0.0328],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0310, 0.0327, 0.0312, 0.0313, 0.0319, 0.0318, 0.0325, 0.0322, 0.0316,\n",
            "        0.0326, 0.0320, 0.0312, 0.0315, 0.0309, 0.0313, 0.0329],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0311, 0.0321, 0.0313, 0.0314, 0.0316, 0.0316, 0.0326, 0.0314, 0.0313,\n",
            "        0.0312, 0.0319, 0.0312, 0.0314, 0.0310, 0.0313, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0313, 0.0321, 0.0316, 0.0314, 0.0323, 0.0317, 0.0321, 0.0317, 0.0316,\n",
            "        0.0312, 0.0320, 0.0316, 0.0314, 0.0312, 0.0316, 0.0317],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0313, 0.0315, 0.0316, 0.0314, 0.0327, 0.0317, 0.0314, 0.0316, 0.0316,\n",
            "        0.0312, 0.0316, 0.0316, 0.0314, 0.0312, 0.0315, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0315, 0.0320, 0.0320, 0.0317, 0.0327, 0.0321, 0.0320, 0.0320, 0.0320,\n",
            "        0.0312, 0.0320, 0.0320, 0.0316, 0.0314, 0.0319, 0.0318],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0315, 0.0320, 0.0315, 0.0317, 0.0327, 0.0315, 0.0320, 0.0315, 0.0317,\n",
            "        0.0316, 0.0320, 0.0317, 0.0316, 0.0315, 0.0316, 0.0316],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0315, 0.0319, 0.0315, 0.0317, 0.0327, 0.0315, 0.0320, 0.0315, 0.0317,\n",
            "        0.0316, 0.0315, 0.0315, 0.0316, 0.0315, 0.0316, 0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0315, 0.0314, 0.0311, 0.0312, 0.0320, 0.0310, 0.0314, 0.0310, 0.0315,\n",
            "        0.0312, 0.0310, 0.0310, 0.0312, 0.0310, 0.0312, 0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0311, 0.0315, 0.0311, 0.0312, 0.0320, 0.0310, 0.0312, 0.0310, 0.0311,\n",
            "        0.0312, 0.0310, 0.0310, 0.0312, 0.0310, 0.0310, 0.0310],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0310, 0.0312, 0.0310, 0.0312, 0.0316, 0.0311, 0.0312, 0.0310, 0.0311,\n",
            "        0.0312, 0.0310, 0.0310, 0.0312, 0.0310, 0.0310, 0.0310],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0310, 0.0312, 0.0310, 0.0312, 0.0316, 0.0311, 0.0312, 0.0311, 0.0310,\n",
            "        0.0312, 0.0311, 0.0310, 0.0312, 0.0310, 0.0311, 0.0310],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0310, 0.0312, 0.0310, 0.0312, 0.0316, 0.0311, 0.0312, 0.0311, 0.0310,\n",
            "        0.0312, 0.0311, 0.0310, 0.0312, 0.0310, 0.0311, 0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0310, 0.0312, 0.0311, 0.0312, 0.0315, 0.0310, 0.0312, 0.0310, 0.0310,\n",
            "        0.0312, 0.0311, 0.0310, 0.0312, 0.0310, 0.0311, 0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0310, 0.0312, 0.0311, 0.0312, 0.0320, 0.0310, 0.0312, 0.0310, 0.0310,\n",
            "        0.0312, 0.0311, 0.0310, 0.0312, 0.0310, 0.0311, 0.0310],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0315, 0.0312, 0.0311, 0.0312, 0.0320, 0.0314, 0.0312, 0.0314, 0.0315,\n",
            "        0.0312, 0.0310, 0.0310, 0.0312, 0.0310, 0.0311, 0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0315, 0.0312, 0.0315, 0.0312, 0.0320, 0.0314, 0.0312, 0.0314, 0.0315,\n",
            "        0.0312, 0.0315, 0.0315, 0.0312, 0.0315, 0.0315, 0.0315],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0310, 0.0312, 0.0311, 0.0312, 0.0320, 0.0310, 0.0312, 0.0310, 0.0311,\n",
            "        0.0312, 0.0310, 0.0311, 0.0312, 0.0315, 0.0310, 0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0480, 0.0479, 0.0485, 0.0492, 0.0486, 0.0481, 0.0495, 0.0477, 0.0490,\n",
            "        0.0478, 0.0469, 0.0482, 0.0481, 0.0482, 0.0468, 0.0474],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0473, 0.0481, 0.0486, 0.0472, 0.0469, 0.0473, 0.0507, 0.0472, 0.0469,\n",
            "        0.0470, 0.0459, 0.0474, 0.0468, 0.0483, 0.0463, 0.0467],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0479, 0.0489, 0.0481, 0.0479, 0.0475, 0.0475, 0.0487, 0.0476, 0.0471,\n",
            "        0.0471, 0.0466, 0.0481, 0.0471, 0.0477, 0.0467, 0.0468],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0478, 0.0481, 0.0489, 0.0471, 0.0478, 0.0476, 0.0482, 0.0483, 0.0473,\n",
            "        0.0476, 0.0474, 0.0471, 0.0470, 0.0476, 0.0470, 0.0471],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0478, 0.0473, 0.0475, 0.0475, 0.0481, 0.0471, 0.0479, 0.0476, 0.0473,\n",
            "        0.0478, 0.0478, 0.0475, 0.0473, 0.0473, 0.0472, 0.0475],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0472, 0.0470, 0.0470, 0.0471, 0.0478, 0.0471, 0.0472, 0.0472, 0.0472,\n",
            "        0.0470, 0.0484, 0.0471, 0.0470, 0.0469, 0.0476, 0.0477],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0480, 0.0477, 0.0479, 0.0479, 0.0479, 0.0479, 0.0480, 0.0480, 0.0480,\n",
            "        0.0478, 0.0493, 0.0479, 0.0477, 0.0477, 0.0485, 0.0486],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0480, 0.0477, 0.0479, 0.0479, 0.0479, 0.0470, 0.0472, 0.0480, 0.0480,\n",
            "        0.0478, 0.0493, 0.0479, 0.0477, 0.0477, 0.0485, 0.0486],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0471, 0.0470, 0.0470, 0.0469, 0.0471, 0.0470, 0.0472, 0.0469, 0.0472,\n",
            "        0.0470, 0.0493, 0.0468, 0.0470, 0.0470, 0.0485, 0.0486],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0471, 0.0470, 0.0470, 0.0469, 0.0471, 0.0470, 0.0472, 0.0469, 0.0469,\n",
            "        0.0469, 0.0479, 0.0468, 0.0470, 0.0469, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0469, 0.0470, 0.0470, 0.0469, 0.0471, 0.0470, 0.0472, 0.0469, 0.0469,\n",
            "        0.0469, 0.0479, 0.0468, 0.0470, 0.0469, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0468, 0.0469, 0.0468, 0.0469, 0.0471, 0.0470, 0.0472, 0.0468, 0.0469,\n",
            "        0.0469, 0.0479, 0.0468, 0.0469, 0.0468, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0468, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0469,\n",
            "        0.0469, 0.0479, 0.0468, 0.0469, 0.0469, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0469,\n",
            "        0.0469, 0.0479, 0.0469, 0.0469, 0.0469, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0469,\n",
            "        0.0469, 0.0478, 0.0469, 0.0470, 0.0469, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0468, 0.0469, 0.0469,\n",
            "        0.0469, 0.0478, 0.0469, 0.0469, 0.0469, 0.0479, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0468, 0.0469, 0.0469,\n",
            "        0.0469, 0.0478, 0.0469, 0.0469, 0.0469, 0.0479, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0468, 0.0469, 0.0469,\n",
            "        0.0469, 0.0478, 0.0469, 0.0469, 0.0469, 0.0479, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0468, 0.0469, 0.0469,\n",
            "        0.0469, 0.0478, 0.0469, 0.0469, 0.0469, 0.0479, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0469, 0.0469, 0.0468, 0.0469, 0.0469, 0.0468, 0.0468, 0.0469, 0.0469,\n",
            "        0.0469, 0.0478, 0.0469, 0.0469, 0.0469, 0.0478, 0.0478],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0233, 0.0226, 0.0214, 0.0221, 0.0221, 0.0236, 0.0225, 0.0221, 0.0222,\n",
            "        0.0216, 0.0219, 0.0220, 0.0222, 0.0224, 0.0233, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0235, 0.0231, 0.0215, 0.0222, 0.0218, 0.0226, 0.0228, 0.0218, 0.0218,\n",
            "        0.0218, 0.0223, 0.0218, 0.0222, 0.0221, 0.0234, 0.0219],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0237, 0.0230, 0.0220, 0.0228, 0.0221, 0.0239, 0.0220, 0.0223, 0.0228,\n",
            "        0.0223, 0.0226, 0.0218, 0.0226, 0.0223, 0.0227, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0228, 0.0234, 0.0225, 0.0227, 0.0221, 0.0227, 0.0226, 0.0223, 0.0227,\n",
            "        0.0227, 0.0229, 0.0221, 0.0230, 0.0228, 0.0231, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0229, 0.0235, 0.0222, 0.0224, 0.0222, 0.0226, 0.0226, 0.0224, 0.0223,\n",
            "        0.0222, 0.0229, 0.0221, 0.0227, 0.0229, 0.0231, 0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0225, 0.0226, 0.0220, 0.0221, 0.0221, 0.0221, 0.0222, 0.0220, 0.0222,\n",
            "        0.0219, 0.0222, 0.0220, 0.0219, 0.0227, 0.0225, 0.0220],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0223, 0.0224, 0.0220, 0.0221, 0.0221, 0.0221, 0.0219, 0.0220, 0.0222,\n",
            "        0.0219, 0.0221, 0.0220, 0.0220, 0.0222, 0.0221, 0.0220],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0223, 0.0224, 0.0220, 0.0221, 0.0221, 0.0221, 0.0219, 0.0220, 0.0222,\n",
            "        0.0219, 0.0221, 0.0220, 0.0220, 0.0222, 0.0221, 0.0220],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0223, 0.0221, 0.0220, 0.0221, 0.0221, 0.0221, 0.0219, 0.0220, 0.0220,\n",
            "        0.0219, 0.0221, 0.0220, 0.0220, 0.0222, 0.0221, 0.0220],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0223, 0.0219, 0.0219, 0.0219, 0.0220, 0.0221, 0.0219, 0.0220, 0.0220,\n",
            "        0.0218, 0.0219, 0.0220, 0.0219, 0.0220, 0.0221, 0.0220],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0223, 0.0219, 0.0218, 0.0218, 0.0220, 0.0221, 0.0218, 0.0220, 0.0220,\n",
            "        0.0218, 0.0218, 0.0220, 0.0218, 0.0220, 0.0221, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0221, 0.0218, 0.0218, 0.0218, 0.0220, 0.0221, 0.0218, 0.0220, 0.0220,\n",
            "        0.0218, 0.0218, 0.0220, 0.0218, 0.0218, 0.0220, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0221, 0.0218, 0.0218, 0.0218, 0.0220, 0.0221, 0.0218, 0.0220, 0.0220,\n",
            "        0.0217, 0.0218, 0.0220, 0.0218, 0.0218, 0.0218, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0221, 0.0218, 0.0218, 0.0218, 0.0220, 0.0221, 0.0218, 0.0220, 0.0220,\n",
            "        0.0217, 0.0218, 0.0220, 0.0218, 0.0218, 0.0218, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0220, 0.0217, 0.0218, 0.0218, 0.0220, 0.0221, 0.0218, 0.0220, 0.0220,\n",
            "        0.0217, 0.0218, 0.0220, 0.0218, 0.0218, 0.0218, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0220, 0.0217, 0.0218, 0.0218, 0.0220, 0.0221, 0.0218, 0.0220, 0.0220,\n",
            "        0.0217, 0.0218, 0.0220, 0.0218, 0.0218, 0.0218, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0220, 0.0217, 0.0218, 0.0218, 0.0220, 0.0220, 0.0218, 0.0220, 0.0220,\n",
            "        0.0218, 0.0218, 0.0220, 0.0217, 0.0218, 0.0218, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0220, 0.0217, 0.0218, 0.0218, 0.0220, 0.0220, 0.0218, 0.0220, 0.0220,\n",
            "        0.0218, 0.0218, 0.0220, 0.0217, 0.0218, 0.0217, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0220, 0.0217, 0.0218, 0.0218, 0.0220, 0.0220, 0.0218, 0.0220, 0.0220,\n",
            "        0.0218, 0.0218, 0.0220, 0.0217, 0.0218, 0.0217, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0220, 0.0217, 0.0218, 0.0218, 0.0220, 0.0220, 0.0218, 0.0220, 0.0220,\n",
            "        0.0218, 0.0218, 0.0220, 0.0217, 0.0218, 0.0217, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0169, 0.0158, 0.0159, 0.0156, 0.0144, 0.0167, 0.0153, 0.0150, 0.0158,\n",
            "        0.0148, 0.0159, 0.0161, 0.0149, 0.0151, 0.0156, 0.0154],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0170, 0.0166, 0.0154, 0.0166, 0.0145, 0.0166, 0.0161, 0.0151, 0.0158,\n",
            "        0.0150, 0.0150, 0.0164, 0.0157, 0.0149, 0.0150, 0.0154],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0160, 0.0162, 0.0153, 0.0165, 0.0151, 0.0166, 0.0157, 0.0156, 0.0162,\n",
            "        0.0155, 0.0157, 0.0158, 0.0165, 0.0155, 0.0154, 0.0159],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0161, 0.0157, 0.0156, 0.0158, 0.0155, 0.0160, 0.0153, 0.0151, 0.0163,\n",
            "        0.0151, 0.0154, 0.0162, 0.0166, 0.0158, 0.0154, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0156, 0.0156, 0.0157, 0.0158, 0.0152, 0.0160, 0.0150, 0.0150, 0.0163,\n",
            "        0.0153, 0.0155, 0.0159, 0.0155, 0.0158, 0.0152, 0.0156],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0152, 0.0156, 0.0153, 0.0155, 0.0150, 0.0159, 0.0150, 0.0150, 0.0157,\n",
            "        0.0153, 0.0155, 0.0152, 0.0153, 0.0153, 0.0150, 0.0153],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0151, 0.0148, 0.0150, 0.0150, 0.0148, 0.0153, 0.0150, 0.0148, 0.0153,\n",
            "        0.0152, 0.0150, 0.0150, 0.0153, 0.0151, 0.0150, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0151, 0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0153,\n",
            "        0.0150, 0.0150, 0.0150, 0.0152, 0.0151, 0.0150, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0151, 0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0149, 0.0148, 0.0151,\n",
            "        0.0150, 0.0150, 0.0150, 0.0152, 0.0149, 0.0150, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0151, 0.0148, 0.0148, 0.0150, 0.0147, 0.0150, 0.0149, 0.0147, 0.0151,\n",
            "        0.0147, 0.0148, 0.0150, 0.0150, 0.0149, 0.0150, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0151, 0.0149, 0.0149, 0.0150, 0.0149, 0.0150, 0.0149, 0.0149, 0.0149,\n",
            "        0.0149, 0.0149, 0.0149, 0.0150, 0.0149, 0.0149, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0149, 0.0149, 0.0149, 0.0151, 0.0149, 0.0150, 0.0149, 0.0149, 0.0151,\n",
            "        0.0149, 0.0149, 0.0149, 0.0151, 0.0151, 0.0151, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0149, 0.0149, 0.0149, 0.0151, 0.0149, 0.0152, 0.0149, 0.0149, 0.0151,\n",
            "        0.0149, 0.0149, 0.0149, 0.0151, 0.0151, 0.0151, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0149, 0.0149, 0.0149, 0.0151, 0.0149, 0.0152, 0.0149, 0.0149, 0.0151,\n",
            "        0.0149, 0.0149, 0.0149, 0.0151, 0.0151, 0.0151, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0149, 0.0149, 0.0149, 0.0150, 0.0149, 0.0151, 0.0149, 0.0149, 0.0149,\n",
            "        0.0149, 0.0149, 0.0149, 0.0149, 0.0151, 0.0151, 0.0151],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149,\n",
            "        0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0149, 0.0149, 0.0147, 0.0149, 0.0147, 0.0149, 0.0147, 0.0147, 0.0149,\n",
            "        0.0147, 0.0147, 0.0147, 0.0149, 0.0149, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0147, 0.0147, 0.0147, 0.0149, 0.0147, 0.0149, 0.0147, 0.0147, 0.0149,\n",
            "        0.0147, 0.0147, 0.0147, 0.0149, 0.0149, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0147, 0.0147, 0.0147, 0.0149, 0.0149, 0.0149, 0.0147, 0.0147, 0.0149,\n",
            "        0.0147, 0.0147, 0.0147, 0.0149, 0.0149, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0147, 0.0147, 0.0149, 0.0149, 0.0149, 0.0149, 0.0147, 0.0149, 0.0149,\n",
            "        0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0275, 0.0262, 0.0298, 0.0267, 0.0286, 0.0269, 0.0291, 0.0270, 0.0267,\n",
            "        0.0267, 0.0278, 0.0268, 0.0284, 0.0263, 0.0294, 0.0275],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0275, 0.0262, 0.0281, 0.0267, 0.0283, 0.0268, 0.0275, 0.0262, 0.0268,\n",
            "        0.0269, 0.0266, 0.0263, 0.0268, 0.0265, 0.0285, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0274, 0.0269, 0.0277, 0.0276, 0.0277, 0.0267, 0.0278, 0.0269, 0.0272,\n",
            "        0.0274, 0.0269, 0.0269, 0.0277, 0.0268, 0.0278, 0.0272],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0272, 0.0270, 0.0280, 0.0283, 0.0280, 0.0266, 0.0278, 0.0274, 0.0267,\n",
            "        0.0269, 0.0277, 0.0270, 0.0283, 0.0267, 0.0276, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0270, 0.0270, 0.0284, 0.0270, 0.0271, 0.0269, 0.0282, 0.0278, 0.0270,\n",
            "        0.0270, 0.0279, 0.0273, 0.0280, 0.0269, 0.0277, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0270, 0.0270, 0.0284, 0.0271, 0.0270, 0.0269, 0.0287, 0.0271, 0.0270,\n",
            "        0.0270, 0.0279, 0.0272, 0.0274, 0.0269, 0.0272, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0270, 0.0270, 0.0272, 0.0271, 0.0270, 0.0269, 0.0284, 0.0275, 0.0270,\n",
            "        0.0270, 0.0272, 0.0272, 0.0273, 0.0269, 0.0272, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0271, 0.0270, 0.0276, 0.0271, 0.0272, 0.0271, 0.0284, 0.0275, 0.0272,\n",
            "        0.0272, 0.0272, 0.0272, 0.0273, 0.0271, 0.0276, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0268, 0.0270, 0.0276, 0.0271, 0.0272, 0.0271, 0.0279, 0.0268, 0.0268,\n",
            "        0.0268, 0.0272, 0.0268, 0.0273, 0.0267, 0.0272, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0268, 0.0270, 0.0272, 0.0271, 0.0270, 0.0268, 0.0279, 0.0268, 0.0268,\n",
            "        0.0268, 0.0272, 0.0268, 0.0273, 0.0267, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0268, 0.0270, 0.0270, 0.0270, 0.0270, 0.0268, 0.0275, 0.0268, 0.0267,\n",
            "        0.0268, 0.0272, 0.0267, 0.0271, 0.0268, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0268, 0.0270, 0.0270, 0.0270, 0.0270, 0.0268, 0.0275, 0.0268, 0.0267,\n",
            "        0.0268, 0.0272, 0.0268, 0.0271, 0.0268, 0.0267, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0268, 0.0270, 0.0270, 0.0270, 0.0270, 0.0267, 0.0275, 0.0268, 0.0267,\n",
            "        0.0268, 0.0270, 0.0268, 0.0271, 0.0268, 0.0267, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0268, 0.0270, 0.0268, 0.0270, 0.0270, 0.0267, 0.0274, 0.0268, 0.0268,\n",
            "        0.0267, 0.0270, 0.0268, 0.0271, 0.0268, 0.0267, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0268, 0.0270, 0.0267, 0.0270, 0.0270, 0.0267, 0.0277, 0.0267, 0.0268,\n",
            "        0.0267, 0.0270, 0.0268, 0.0271, 0.0268, 0.0267, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0268, 0.0270, 0.0267, 0.0270, 0.0270, 0.0267, 0.0277, 0.0267, 0.0268,\n",
            "        0.0267, 0.0270, 0.0268, 0.0270, 0.0267, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0267, 0.0270, 0.0267, 0.0270, 0.0270, 0.0267, 0.0277, 0.0267, 0.0268,\n",
            "        0.0267, 0.0270, 0.0268, 0.0270, 0.0267, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0267, 0.0270, 0.0267, 0.0270, 0.0270, 0.0267, 0.0273, 0.0267, 0.0268,\n",
            "        0.0267, 0.0270, 0.0268, 0.0270, 0.0267, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0267, 0.0270, 0.0267, 0.0270, 0.0270, 0.0267, 0.0273, 0.0267, 0.0268,\n",
            "        0.0267, 0.0270, 0.0268, 0.0270, 0.0267, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0267, 0.0270, 0.0267, 0.0270, 0.0270, 0.0267, 0.0273, 0.0267, 0.0268,\n",
            "        0.0267, 0.0270, 0.0267, 0.0270, 0.0267, 0.0268, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0279, 0.0277, 0.0265, 0.0299, 0.0283, 0.0280, 0.0267, 0.0295, 0.0273,\n",
            "        0.0276, 0.0271, 0.0283, 0.0288, 0.0278, 0.0285, 0.0262],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0271, 0.0284, 0.0265, 0.0291, 0.0280, 0.0283, 0.0270, 0.0290, 0.0268,\n",
            "        0.0276, 0.0267, 0.0271, 0.0271, 0.0271, 0.0275, 0.0265],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0273, 0.0275, 0.0272, 0.0286, 0.0280, 0.0272, 0.0273, 0.0296, 0.0273,\n",
            "        0.0276, 0.0274, 0.0275, 0.0277, 0.0276, 0.0277, 0.0272],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0275, 0.0273, 0.0274, 0.0278, 0.0282, 0.0273, 0.0276, 0.0281, 0.0272,\n",
            "        0.0278, 0.0281, 0.0272, 0.0276, 0.0272, 0.0276, 0.0276],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0271, 0.0270, 0.0271, 0.0280, 0.0274, 0.0270, 0.0269, 0.0275, 0.0274,\n",
            "        0.0271, 0.0283, 0.0268, 0.0275, 0.0274, 0.0280, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0271, 0.0270, 0.0271, 0.0280, 0.0274, 0.0270, 0.0269, 0.0269, 0.0271,\n",
            "        0.0272, 0.0277, 0.0268, 0.0274, 0.0274, 0.0278, 0.0271],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0271, 0.0270, 0.0271, 0.0270, 0.0271, 0.0270, 0.0269, 0.0269, 0.0271,\n",
            "        0.0270, 0.0270, 0.0268, 0.0268, 0.0270, 0.0274, 0.0271],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0271, 0.0268, 0.0267, 0.0270, 0.0268, 0.0270, 0.0269, 0.0271, 0.0271,\n",
            "        0.0270, 0.0270, 0.0268, 0.0271, 0.0270, 0.0272, 0.0271],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0271, 0.0266, 0.0267, 0.0270, 0.0268, 0.0269, 0.0269, 0.0271, 0.0269,\n",
            "        0.0269, 0.0270, 0.0266, 0.0270, 0.0266, 0.0272, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0271, 0.0270, 0.0267, 0.0274, 0.0270, 0.0269, 0.0269, 0.0270, 0.0270,\n",
            "        0.0269, 0.0271, 0.0270, 0.0266, 0.0270, 0.0273, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0272, 0.0270, 0.0270, 0.0272, 0.0270, 0.0269, 0.0273, 0.0270, 0.0270,\n",
            "        0.0272, 0.0271, 0.0270, 0.0266, 0.0270, 0.0270, 0.0272],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0272, 0.0270, 0.0270, 0.0270, 0.0270, 0.0269, 0.0273, 0.0270, 0.0270,\n",
            "        0.0272, 0.0269, 0.0270, 0.0266, 0.0270, 0.0270, 0.0272],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0272, 0.0269, 0.0270, 0.0270, 0.0270, 0.0269, 0.0272, 0.0269, 0.0270,\n",
            "        0.0272, 0.0269, 0.0270, 0.0266, 0.0270, 0.0270, 0.0272],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0272, 0.0269, 0.0270, 0.0270, 0.0270, 0.0269, 0.0272, 0.0270, 0.0270,\n",
            "        0.0272, 0.0269, 0.0270, 0.0266, 0.0270, 0.0270, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268, 0.0268, 0.0266, 0.0266,\n",
            "        0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0266, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268, 0.0269, 0.0266, 0.0266,\n",
            "        0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0266, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268, 0.0269, 0.0266, 0.0266,\n",
            "        0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268, 0.0269, 0.0266, 0.0266,\n",
            "        0.0269, 0.0266, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268, 0.0269, 0.0266, 0.0266,\n",
            "        0.0269, 0.0266, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0268, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268, 0.0269, 0.0266, 0.0266,\n",
            "        0.0269, 0.0266, 0.0266, 0.0266, 0.0266, 0.0266, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0266, 0.0264, 0.0263, 0.0266, 0.0268, 0.0267, 0.0258, 0.0273, 0.0283,\n",
            "        0.0286, 0.0262, 0.0282, 0.0277, 0.0264, 0.0270, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0270, 0.0271, 0.0268, 0.0267, 0.0271, 0.0273, 0.0264, 0.0285, 0.0277,\n",
            "        0.0306, 0.0262, 0.0290, 0.0294, 0.0276, 0.0273, 0.0275],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0275, 0.0276, 0.0273, 0.0268, 0.0275, 0.0269, 0.0267, 0.0284, 0.0282,\n",
            "        0.0302, 0.0263, 0.0279, 0.0286, 0.0273, 0.0274, 0.0289],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0273, 0.0278, 0.0268, 0.0272, 0.0276, 0.0269, 0.0271, 0.0275, 0.0278,\n",
            "        0.0283, 0.0263, 0.0279, 0.0272, 0.0271, 0.0276, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0270, 0.0270, 0.0271, 0.0269, 0.0270, 0.0265, 0.0269, 0.0270, 0.0269,\n",
            "        0.0281, 0.0266, 0.0277, 0.0268, 0.0271, 0.0275, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0272, 0.0270, 0.0271, 0.0267, 0.0270, 0.0267, 0.0269, 0.0270, 0.0269,\n",
            "        0.0277, 0.0271, 0.0273, 0.0268, 0.0268, 0.0274, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0268, 0.0270, 0.0271, 0.0267, 0.0270, 0.0267, 0.0269, 0.0269, 0.0269,\n",
            "        0.0268, 0.0273, 0.0271, 0.0267, 0.0266, 0.0271, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0268, 0.0267, 0.0267, 0.0265, 0.0270, 0.0265, 0.0267, 0.0269, 0.0269,\n",
            "        0.0270, 0.0273, 0.0271, 0.0267, 0.0266, 0.0271, 0.0269],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0266, 0.0265, 0.0265, 0.0265, 0.0268, 0.0265, 0.0267, 0.0268, 0.0269,\n",
            "        0.0270, 0.0274, 0.0271, 0.0267, 0.0266, 0.0269, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0269, 0.0269, 0.0269, 0.0269, 0.0272, 0.0269, 0.0269, 0.0268, 0.0268,\n",
            "        0.0270, 0.0273, 0.0273, 0.0270, 0.0266, 0.0269, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0272, 0.0270,\n",
            "        0.0271, 0.0273, 0.0269, 0.0270, 0.0270, 0.0269, 0.0271],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0270, 0.0270,\n",
            "        0.0271, 0.0273, 0.0269, 0.0270, 0.0270, 0.0269, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0270, 0.0270,\n",
            "        0.0270, 0.0273, 0.0269, 0.0270, 0.0270, 0.0269, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0270, 0.0270,\n",
            "        0.0270, 0.0274, 0.0269, 0.0270, 0.0270, 0.0269, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0265, 0.0266, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0266, 0.0266,\n",
            "        0.0266, 0.0271, 0.0266, 0.0266, 0.0266, 0.0265, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0265, 0.0266, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0266, 0.0266,\n",
            "        0.0266, 0.0271, 0.0266, 0.0266, 0.0266, 0.0265, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0266, 0.0266,\n",
            "        0.0266, 0.0271, 0.0266, 0.0266, 0.0266, 0.0265, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0266, 0.0266,\n",
            "        0.0266, 0.0271, 0.0266, 0.0266, 0.0266, 0.0265, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0266, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0265, 0.0266, 0.0266,\n",
            "        0.0266, 0.0274, 0.0266, 0.0266, 0.0266, 0.0265, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0269, 0.0266, 0.0266,\n",
            "        0.0266, 0.0276, 0.0265, 0.0266, 0.0266, 0.0269, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0174, 0.0179, 0.0176, 0.0208, 0.0188, 0.0180, 0.0184, 0.0194, 0.0189,\n",
            "        0.0177, 0.0176, 0.0186, 0.0180, 0.0187, 0.0183, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0179, 0.0181, 0.0180, 0.0194, 0.0191, 0.0186, 0.0187, 0.0196, 0.0203,\n",
            "        0.0182, 0.0177, 0.0199, 0.0189, 0.0188, 0.0193, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0186, 0.0186, 0.0178, 0.0200, 0.0199, 0.0191, 0.0198, 0.0204, 0.0198,\n",
            "        0.0185, 0.0182, 0.0197, 0.0189, 0.0185, 0.0189, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0187, 0.0185, 0.0182, 0.0199, 0.0201, 0.0190, 0.0195, 0.0201, 0.0200,\n",
            "        0.0181, 0.0183, 0.0201, 0.0184, 0.0190, 0.0189, 0.0193],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0189, 0.0183, 0.0182, 0.0197, 0.0189, 0.0188, 0.0188, 0.0189, 0.0187,\n",
            "        0.0182, 0.0184, 0.0189, 0.0186, 0.0189, 0.0190, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0185, 0.0183, 0.0182, 0.0196, 0.0191, 0.0185, 0.0188, 0.0189, 0.0187,\n",
            "        0.0183, 0.0184, 0.0189, 0.0186, 0.0185, 0.0184, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0185, 0.0183, 0.0185, 0.0184, 0.0183, 0.0185, 0.0184, 0.0183, 0.0185,\n",
            "        0.0183, 0.0184, 0.0187, 0.0186, 0.0185, 0.0184, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0185, 0.0183, 0.0185, 0.0184, 0.0186, 0.0183, 0.0187, 0.0186, 0.0188,\n",
            "        0.0183, 0.0184, 0.0187, 0.0186, 0.0185, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0185, 0.0182, 0.0185, 0.0187, 0.0186, 0.0183, 0.0187, 0.0186, 0.0188,\n",
            "        0.0182, 0.0182, 0.0187, 0.0184, 0.0185, 0.0185, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0183, 0.0182, 0.0185, 0.0187, 0.0186, 0.0181, 0.0185, 0.0186, 0.0188,\n",
            "        0.0182, 0.0182, 0.0187, 0.0182, 0.0185, 0.0185, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0182, 0.0182, 0.0184, 0.0187, 0.0186, 0.0181, 0.0185, 0.0186, 0.0187,\n",
            "        0.0182, 0.0182, 0.0187, 0.0181, 0.0183, 0.0183, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0182, 0.0182, 0.0182, 0.0184, 0.0183, 0.0181, 0.0182, 0.0186, 0.0184,\n",
            "        0.0182, 0.0182, 0.0185, 0.0181, 0.0181, 0.0181, 0.0182],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0182, 0.0182, 0.0182, 0.0182, 0.0183, 0.0181, 0.0182, 0.0183, 0.0182,\n",
            "        0.0182, 0.0181, 0.0182, 0.0181, 0.0181, 0.0181, 0.0182],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0182, 0.0181, 0.0184, 0.0182, 0.0185, 0.0181, 0.0184, 0.0182, 0.0184,\n",
            "        0.0181, 0.0181, 0.0185, 0.0181, 0.0182, 0.0181, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0182, 0.0181, 0.0184, 0.0182, 0.0185, 0.0181, 0.0184, 0.0184, 0.0184,\n",
            "        0.0181, 0.0182, 0.0185, 0.0181, 0.0182, 0.0181, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0181, 0.0181, 0.0184, 0.0184, 0.0184, 0.0181, 0.0185, 0.0184, 0.0184,\n",
            "        0.0181, 0.0182, 0.0184, 0.0182, 0.0182, 0.0182, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0181, 0.0181, 0.0184, 0.0184, 0.0184, 0.0181, 0.0185, 0.0184, 0.0185,\n",
            "        0.0181, 0.0182, 0.0184, 0.0181, 0.0181, 0.0182, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0181, 0.0181, 0.0184, 0.0184, 0.0184, 0.0181, 0.0185, 0.0184, 0.0185,\n",
            "        0.0181, 0.0182, 0.0184, 0.0181, 0.0181, 0.0181, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0181, 0.0181, 0.0184, 0.0184, 0.0184, 0.0181, 0.0185, 0.0184, 0.0185,\n",
            "        0.0181, 0.0182, 0.0184, 0.0181, 0.0181, 0.0181, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0181, 0.0181, 0.0184, 0.0184, 0.0182, 0.0181, 0.0182, 0.0184, 0.0185,\n",
            "        0.0181, 0.0182, 0.0184, 0.0182, 0.0181, 0.0181, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0285, 0.0303, 0.0297, 0.0286, 0.0298, 0.0289, 0.0293, 0.0300, 0.0303,\n",
            "        0.0283, 0.0323, 0.0310, 0.0295, 0.0288, 0.0288, 0.0284],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0280, 0.0293, 0.0286, 0.0286, 0.0287, 0.0284, 0.0293, 0.0291, 0.0296,\n",
            "        0.0288, 0.0315, 0.0299, 0.0296, 0.0286, 0.0289, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0281, 0.0297, 0.0288, 0.0288, 0.0291, 0.0293, 0.0300, 0.0289, 0.0295,\n",
            "        0.0297, 0.0309, 0.0299, 0.0298, 0.0288, 0.0285, 0.0282],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0287, 0.0300, 0.0296, 0.0290, 0.0297, 0.0297, 0.0297, 0.0292, 0.0304,\n",
            "        0.0300, 0.0298, 0.0309, 0.0297, 0.0291, 0.0295, 0.0289],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0291, 0.0298, 0.0299, 0.0294, 0.0294, 0.0292, 0.0297, 0.0293, 0.0306,\n",
            "        0.0299, 0.0294, 0.0299, 0.0296, 0.0294, 0.0297, 0.0291],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0294, 0.0298, 0.0299, 0.0294, 0.0294, 0.0292, 0.0293, 0.0293, 0.0299,\n",
            "        0.0294, 0.0296, 0.0295, 0.0292, 0.0294, 0.0296, 0.0291],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0292, 0.0294, 0.0294, 0.0297, 0.0294, 0.0292, 0.0293, 0.0292, 0.0294,\n",
            "        0.0294, 0.0289, 0.0289, 0.0292, 0.0294, 0.0292, 0.0288],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0286, 0.0290, 0.0290, 0.0296, 0.0290, 0.0286, 0.0289, 0.0286, 0.0290,\n",
            "        0.0288, 0.0289, 0.0288, 0.0288, 0.0290, 0.0288, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0286, 0.0288, 0.0288, 0.0290, 0.0288, 0.0285, 0.0287, 0.0286, 0.0290,\n",
            "        0.0286, 0.0288, 0.0288, 0.0286, 0.0288, 0.0286, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0285, 0.0288, 0.0288, 0.0290, 0.0285, 0.0285, 0.0287, 0.0286, 0.0288,\n",
            "        0.0286, 0.0287, 0.0288, 0.0286, 0.0288, 0.0286, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0285, 0.0286, 0.0288, 0.0294, 0.0285, 0.0285, 0.0287, 0.0285, 0.0288,\n",
            "        0.0286, 0.0287, 0.0288, 0.0286, 0.0286, 0.0286, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0285, 0.0290, 0.0292, 0.0294, 0.0285, 0.0285, 0.0286, 0.0286, 0.0290,\n",
            "        0.0286, 0.0287, 0.0288, 0.0285, 0.0286, 0.0286, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0289, 0.0289, 0.0290, 0.0294, 0.0289, 0.0289, 0.0290, 0.0290, 0.0290,\n",
            "        0.0289, 0.0291, 0.0292, 0.0289, 0.0290, 0.0290, 0.0290],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0289, 0.0290, 0.0290, 0.0294, 0.0289, 0.0289, 0.0290, 0.0290, 0.0290,\n",
            "        0.0289, 0.0291, 0.0292, 0.0289, 0.0290, 0.0290, 0.0290],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0289, 0.0290, 0.0290, 0.0294, 0.0290, 0.0289, 0.0289, 0.0290, 0.0290,\n",
            "        0.0289, 0.0287, 0.0288, 0.0290, 0.0289, 0.0290, 0.0290],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0285, 0.0286, 0.0286, 0.0294, 0.0286, 0.0286, 0.0286, 0.0286, 0.0286,\n",
            "        0.0286, 0.0287, 0.0287, 0.0286, 0.0285, 0.0286, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0286, 0.0286, 0.0286, 0.0294, 0.0286, 0.0286, 0.0286, 0.0286, 0.0286,\n",
            "        0.0286, 0.0287, 0.0287, 0.0286, 0.0285, 0.0286, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0286, 0.0286, 0.0286, 0.0294, 0.0286, 0.0286, 0.0286, 0.0286, 0.0286,\n",
            "        0.0286, 0.0288, 0.0287, 0.0286, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0286, 0.0286, 0.0286, 0.0294, 0.0286, 0.0286, 0.0286, 0.0286, 0.0285,\n",
            "        0.0286, 0.0288, 0.0287, 0.0286, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0286, 0.0285, 0.0285, 0.0294, 0.0286, 0.0286, 0.0286, 0.0286, 0.0285,\n",
            "        0.0286, 0.0288, 0.0287, 0.0286, 0.0286, 0.0285, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0297, 0.0291, 0.0285, 0.0286, 0.0289, 0.0275, 0.0288, 0.0300, 0.0281,\n",
            "        0.0297, 0.0286, 0.0279, 0.0284, 0.0290, 0.0290, 0.0282],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0285, 0.0293, 0.0290, 0.0289, 0.0286, 0.0278, 0.0282, 0.0300, 0.0289,\n",
            "        0.0301, 0.0281, 0.0279, 0.0292, 0.0287, 0.0286, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0283, 0.0300, 0.0289, 0.0296, 0.0291, 0.0283, 0.0288, 0.0297, 0.0286,\n",
            "        0.0298, 0.0287, 0.0286, 0.0291, 0.0288, 0.0293, 0.0293],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0285, 0.0301, 0.0289, 0.0291, 0.0296, 0.0284, 0.0289, 0.0287, 0.0285,\n",
            "        0.0294, 0.0289, 0.0289, 0.0283, 0.0283, 0.0294, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0280, 0.0286, 0.0289, 0.0284, 0.0293, 0.0285, 0.0286, 0.0289, 0.0284,\n",
            "        0.0290, 0.0289, 0.0286, 0.0281, 0.0281, 0.0289, 0.0284],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0280, 0.0284, 0.0284, 0.0284, 0.0281, 0.0289, 0.0281, 0.0283, 0.0284,\n",
            "        0.0283, 0.0283, 0.0285, 0.0281, 0.0281, 0.0284, 0.0284],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0280, 0.0283, 0.0284, 0.0281, 0.0283, 0.0293, 0.0281, 0.0281, 0.0281,\n",
            "        0.0283, 0.0283, 0.0283, 0.0278, 0.0278, 0.0284, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0280, 0.0283, 0.0285, 0.0281, 0.0283, 0.0288, 0.0283, 0.0278, 0.0279,\n",
            "        0.0281, 0.0281, 0.0284, 0.0279, 0.0278, 0.0284, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0280, 0.0287, 0.0285, 0.0281, 0.0281, 0.0288, 0.0283, 0.0283, 0.0283,\n",
            "        0.0285, 0.0285, 0.0284, 0.0283, 0.0283, 0.0288, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0285, 0.0285, 0.0285, 0.0286, 0.0285, 0.0288, 0.0283, 0.0283, 0.0283,\n",
            "        0.0285, 0.0283, 0.0284, 0.0283, 0.0283, 0.0287, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0284, 0.0285, 0.0285, 0.0286, 0.0285, 0.0288, 0.0283, 0.0283, 0.0283,\n",
            "        0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0287, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0284, 0.0280, 0.0283, 0.0280, 0.0281, 0.0288, 0.0283, 0.0283, 0.0283,\n",
            "        0.0283, 0.0283, 0.0279, 0.0283, 0.0283, 0.0280, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0280, 0.0280, 0.0278, 0.0280, 0.0281, 0.0288, 0.0279, 0.0283, 0.0279,\n",
            "        0.0283, 0.0279, 0.0279, 0.0279, 0.0279, 0.0280, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0280, 0.0280, 0.0278, 0.0280, 0.0281, 0.0287, 0.0278, 0.0278, 0.0279,\n",
            "        0.0279, 0.0279, 0.0278, 0.0279, 0.0279, 0.0280, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0280, 0.0280, 0.0278, 0.0280, 0.0280, 0.0287, 0.0278, 0.0278, 0.0279,\n",
            "        0.0279, 0.0279, 0.0283, 0.0279, 0.0279, 0.0280, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0280, 0.0281, 0.0283, 0.0280, 0.0280, 0.0287, 0.0283, 0.0278, 0.0279,\n",
            "        0.0279, 0.0283, 0.0283, 0.0283, 0.0283, 0.0280, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0280, 0.0280, 0.0283, 0.0280, 0.0280, 0.0287, 0.0283, 0.0283, 0.0283,\n",
            "        0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0280, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0280, 0.0284, 0.0283, 0.0280, 0.0280, 0.0287, 0.0283, 0.0283, 0.0283,\n",
            "        0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0284, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0284, 0.0280, 0.0283, 0.0284, 0.0285, 0.0287, 0.0283, 0.0283, 0.0283,\n",
            "        0.0283, 0.0283, 0.0278, 0.0283, 0.0283, 0.0280, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0280, 0.0280, 0.0283, 0.0280, 0.0280, 0.0287, 0.0279, 0.0283, 0.0278,\n",
            "        0.0283, 0.0279, 0.0278, 0.0279, 0.0283, 0.0280, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0302, 0.0311, 0.0322, 0.0302, 0.0302, 0.0303, 0.0313, 0.0316, 0.0317,\n",
            "        0.0304, 0.0296, 0.0306, 0.0311, 0.0302, 0.0302, 0.0312],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0316, 0.0308, 0.0313, 0.0309, 0.0310, 0.0317, 0.0335, 0.0321, 0.0317,\n",
            "        0.0312, 0.0311, 0.0307, 0.0318, 0.0309, 0.0315, 0.0316],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0310, 0.0320, 0.0316, 0.0308, 0.0313, 0.0312, 0.0322, 0.0326, 0.0323,\n",
            "        0.0324, 0.0309, 0.0311, 0.0310, 0.0310, 0.0323, 0.0314],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0306, 0.0315, 0.0316, 0.0306, 0.0312, 0.0305, 0.0316, 0.0317, 0.0324,\n",
            "        0.0317, 0.0305, 0.0308, 0.0304, 0.0308, 0.0314, 0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0305, 0.0308, 0.0316, 0.0309, 0.0307, 0.0308, 0.0312, 0.0318, 0.0312,\n",
            "        0.0314, 0.0305, 0.0311, 0.0304, 0.0307, 0.0315, 0.0312],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0305, 0.0308, 0.0316, 0.0309, 0.0307, 0.0308, 0.0307, 0.0309, 0.0308,\n",
            "        0.0311, 0.0305, 0.0313, 0.0304, 0.0307, 0.0308, 0.0312],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0305, 0.0308, 0.0317, 0.0307, 0.0305, 0.0308, 0.0305, 0.0305, 0.0308,\n",
            "        0.0307, 0.0305, 0.0316, 0.0304, 0.0307, 0.0305, 0.0309],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0305, 0.0307, 0.0312, 0.0305, 0.0305, 0.0306, 0.0305, 0.0305, 0.0305,\n",
            "        0.0304, 0.0305, 0.0310, 0.0304, 0.0305, 0.0305, 0.0309],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0305, 0.0307, 0.0312, 0.0303, 0.0304, 0.0303, 0.0305, 0.0303, 0.0305,\n",
            "        0.0302, 0.0305, 0.0312, 0.0304, 0.0305, 0.0303, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0311, 0.0312, 0.0312, 0.0308, 0.0310, 0.0308, 0.0309, 0.0308, 0.0305,\n",
            "        0.0307, 0.0310, 0.0312, 0.0309, 0.0310, 0.0308, 0.0308],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0311, 0.0309, 0.0312, 0.0308, 0.0310, 0.0309, 0.0309, 0.0308, 0.0305,\n",
            "        0.0307, 0.0310, 0.0312, 0.0309, 0.0307, 0.0308, 0.0308],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0309, 0.0309, 0.0311, 0.0308, 0.0310, 0.0307, 0.0309, 0.0308, 0.0305,\n",
            "        0.0307, 0.0309, 0.0312, 0.0309, 0.0307, 0.0308, 0.0308],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0304, 0.0304, 0.0310, 0.0303, 0.0304, 0.0302, 0.0304, 0.0303, 0.0305,\n",
            "        0.0302, 0.0304, 0.0312, 0.0304, 0.0302, 0.0302, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0304, 0.0305, 0.0310, 0.0303, 0.0304, 0.0302, 0.0304, 0.0303, 0.0310,\n",
            "        0.0302, 0.0304, 0.0307, 0.0304, 0.0303, 0.0302, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0304, 0.0304, 0.0310, 0.0303, 0.0304, 0.0302, 0.0304, 0.0303, 0.0305,\n",
            "        0.0302, 0.0304, 0.0307, 0.0304, 0.0303, 0.0302, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0305, 0.0304, 0.0310, 0.0303, 0.0304, 0.0303, 0.0304, 0.0303, 0.0304,\n",
            "        0.0302, 0.0304, 0.0307, 0.0304, 0.0303, 0.0302, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0305, 0.0304, 0.0310, 0.0303, 0.0304, 0.0303, 0.0305, 0.0302, 0.0304,\n",
            "        0.0302, 0.0304, 0.0307, 0.0304, 0.0303, 0.0303, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0305, 0.0304, 0.0310, 0.0303, 0.0304, 0.0303, 0.0305, 0.0302, 0.0304,\n",
            "        0.0302, 0.0304, 0.0307, 0.0304, 0.0303, 0.0303, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0304, 0.0304, 0.0310, 0.0303, 0.0304, 0.0303, 0.0305, 0.0302, 0.0304,\n",
            "        0.0303, 0.0304, 0.0307, 0.0304, 0.0303, 0.0303, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0304, 0.0304, 0.0310, 0.0302, 0.0304, 0.0303, 0.0305, 0.0303, 0.0304,\n",
            "        0.0303, 0.0304, 0.0312, 0.0304, 0.0303, 0.0303, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0191, 0.0195, 0.0216, 0.0197, 0.0196, 0.0210, 0.0196, 0.0203, 0.0198,\n",
            "        0.0195, 0.0210, 0.0200, 0.0198, 0.0194, 0.0197, 0.0204],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0195, 0.0204, 0.0207, 0.0205, 0.0199, 0.0208, 0.0201, 0.0203, 0.0207,\n",
            "        0.0203, 0.0197, 0.0204, 0.0206, 0.0201, 0.0201, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0197, 0.0209, 0.0210, 0.0204, 0.0199, 0.0207, 0.0205, 0.0209, 0.0208,\n",
            "        0.0205, 0.0202, 0.0201, 0.0200, 0.0200, 0.0205, 0.0212],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0199, 0.0201, 0.0213, 0.0201, 0.0199, 0.0200, 0.0204, 0.0210, 0.0201,\n",
            "        0.0202, 0.0205, 0.0205, 0.0200, 0.0198, 0.0207, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0204, 0.0202, 0.0205, 0.0201, 0.0199, 0.0198, 0.0200, 0.0202, 0.0202,\n",
            "        0.0200, 0.0204, 0.0199, 0.0198, 0.0199, 0.0202, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0204, 0.0202, 0.0200, 0.0197, 0.0199, 0.0200, 0.0200, 0.0203, 0.0202,\n",
            "        0.0197, 0.0199, 0.0199, 0.0199, 0.0199, 0.0201, 0.0204],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0200, 0.0202, 0.0200, 0.0197, 0.0199, 0.0200, 0.0200, 0.0202, 0.0202,\n",
            "        0.0200, 0.0201, 0.0197, 0.0200, 0.0199, 0.0201, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0200, 0.0202, 0.0202, 0.0200, 0.0201, 0.0202, 0.0200, 0.0202, 0.0202,\n",
            "        0.0200, 0.0201, 0.0200, 0.0202, 0.0200, 0.0201, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0203, 0.0201, 0.0202, 0.0200, 0.0201, 0.0201, 0.0202, 0.0200, 0.0205,\n",
            "        0.0200, 0.0201, 0.0200, 0.0204, 0.0200, 0.0201, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0199, 0.0198, 0.0202, 0.0199, 0.0202, 0.0200, 0.0198, 0.0200, 0.0201,\n",
            "        0.0198, 0.0201, 0.0199, 0.0204, 0.0198, 0.0200, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0199, 0.0198, 0.0202, 0.0199, 0.0198, 0.0198, 0.0198, 0.0199, 0.0200,\n",
            "        0.0195, 0.0200, 0.0199, 0.0204, 0.0195, 0.0198, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0198, 0.0198, 0.0199, 0.0196, 0.0195, 0.0195, 0.0198, 0.0196, 0.0198,\n",
            "        0.0195, 0.0195, 0.0195, 0.0204, 0.0196, 0.0198, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0196, 0.0198, 0.0195, 0.0198,\n",
            "        0.0195, 0.0195, 0.0195, 0.0204, 0.0196, 0.0198, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0196, 0.0199, 0.0195, 0.0198,\n",
            "        0.0195, 0.0195, 0.0196, 0.0204, 0.0196, 0.0198, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0198, 0.0198, 0.0195, 0.0198, 0.0196, 0.0196, 0.0199, 0.0198, 0.0198,\n",
            "        0.0199, 0.0198, 0.0199, 0.0204, 0.0198, 0.0198, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0198, 0.0198, 0.0199, 0.0198, 0.0199, 0.0199, 0.0199, 0.0198, 0.0198,\n",
            "        0.0199, 0.0199, 0.0199, 0.0204, 0.0198, 0.0198, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0198, 0.0198, 0.0199, 0.0198, 0.0199, 0.0199, 0.0199, 0.0198, 0.0198,\n",
            "        0.0199, 0.0199, 0.0199, 0.0204, 0.0198, 0.0198, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0198, 0.0198, 0.0199, 0.0198, 0.0199, 0.0199, 0.0199, 0.0198, 0.0198,\n",
            "        0.0199, 0.0199, 0.0199, 0.0204, 0.0195, 0.0198, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0198, 0.0198, 0.0199, 0.0195, 0.0196, 0.0199, 0.0198, 0.0195, 0.0198,\n",
            "        0.0196, 0.0196, 0.0199, 0.0204, 0.0195, 0.0199, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0198, 0.0198, 0.0195, 0.0195, 0.0196, 0.0196, 0.0198, 0.0195, 0.0198,\n",
            "        0.0196, 0.0196, 0.0196, 0.0204, 0.0195, 0.0199, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0395, 0.0391, 0.0379, 0.0388, 0.0375, 0.0377, 0.0396, 0.0393, 0.0387,\n",
            "        0.0381, 0.0388, 0.0381, 0.0369, 0.0388, 0.0388, 0.0383],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0387, 0.0391, 0.0387, 0.0392, 0.0375, 0.0376, 0.0381, 0.0399, 0.0391,\n",
            "        0.0384, 0.0386, 0.0385, 0.0375, 0.0400, 0.0373, 0.0388],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0387, 0.0385, 0.0381, 0.0371, 0.0378, 0.0373, 0.0384, 0.0391, 0.0398,\n",
            "        0.0391, 0.0384, 0.0385, 0.0377, 0.0387, 0.0376, 0.0382],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0384, 0.0381, 0.0380, 0.0377, 0.0376, 0.0378, 0.0385, 0.0386, 0.0389,\n",
            "        0.0385, 0.0382, 0.0378, 0.0376, 0.0376, 0.0381, 0.0380],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0378, 0.0384, 0.0381, 0.0385, 0.0383, 0.0384, 0.0383, 0.0384, 0.0381,\n",
            "        0.0384, 0.0385, 0.0379, 0.0383, 0.0378, 0.0384, 0.0384],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0378, 0.0378, 0.0383, 0.0378, 0.0393, 0.0379, 0.0388, 0.0378, 0.0380,\n",
            "        0.0381, 0.0382, 0.0381, 0.0387, 0.0379, 0.0383, 0.0384],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0383, 0.0378, 0.0383, 0.0382, 0.0395, 0.0382, 0.0388, 0.0378, 0.0378,\n",
            "        0.0377, 0.0382, 0.0381, 0.0389, 0.0379, 0.0383, 0.0378],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0381, 0.0376, 0.0378, 0.0379, 0.0392, 0.0379, 0.0384, 0.0378, 0.0376,\n",
            "        0.0375, 0.0379, 0.0379, 0.0386, 0.0376, 0.0381, 0.0375],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0375, 0.0376, 0.0373, 0.0374, 0.0386, 0.0373, 0.0376, 0.0375, 0.0373,\n",
            "        0.0375, 0.0373, 0.0373, 0.0385, 0.0376, 0.0375, 0.0375],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0375, 0.0382, 0.0373, 0.0374, 0.0381, 0.0373, 0.0373, 0.0375, 0.0373,\n",
            "        0.0375, 0.0373, 0.0373, 0.0381, 0.0382, 0.0373, 0.0381],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0373, 0.0382, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0375, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0380, 0.0382, 0.0373, 0.0381],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0373, 0.0379, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0375, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0380, 0.0379, 0.0373, 0.0379],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0373, 0.0379, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0380, 0.0379, 0.0373, 0.0379],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0382, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0380, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0385, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0385, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0380, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0373, 0.0373, 0.0373, 0.0373, 0.0380, 0.0373, 0.0373, 0.0373, 0.0373,\n",
            "        0.0373, 0.0373, 0.0373, 0.0381, 0.0373, 0.0373, 0.0373],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0220, 0.0243, 0.0236, 0.0225, 0.0220, 0.0229, 0.0221, 0.0223, 0.0238,\n",
            "        0.0226, 0.0218, 0.0223, 0.0217, 0.0227, 0.0224, 0.0219],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0233, 0.0230, 0.0225, 0.0219, 0.0226, 0.0235, 0.0228, 0.0232, 0.0231,\n",
            "        0.0226, 0.0219, 0.0245, 0.0228, 0.0230, 0.0223, 0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0228, 0.0231, 0.0226, 0.0219, 0.0223, 0.0231, 0.0223, 0.0231, 0.0218,\n",
            "        0.0222, 0.0220, 0.0229, 0.0228, 0.0222, 0.0226, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0221, 0.0231, 0.0224, 0.0220, 0.0229, 0.0226, 0.0225, 0.0229, 0.0225,\n",
            "        0.0229, 0.0222, 0.0218, 0.0231, 0.0222, 0.0222, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0217, 0.0227, 0.0221, 0.0222, 0.0219, 0.0220, 0.0222, 0.0220, 0.0226,\n",
            "        0.0217, 0.0223, 0.0218, 0.0227, 0.0223, 0.0218, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0217, 0.0222, 0.0221, 0.0214, 0.0216, 0.0220, 0.0219, 0.0220, 0.0225,\n",
            "        0.0216, 0.0216, 0.0218, 0.0222, 0.0220, 0.0216, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0216, 0.0216, 0.0217, 0.0214, 0.0216, 0.0220, 0.0219, 0.0219, 0.0223,\n",
            "        0.0216, 0.0216, 0.0218, 0.0219, 0.0216, 0.0216, 0.0216],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0215, 0.0216, 0.0217, 0.0214, 0.0216, 0.0218, 0.0216, 0.0219, 0.0225,\n",
            "        0.0216, 0.0214, 0.0217, 0.0219, 0.0216, 0.0216, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0215, 0.0218, 0.0217, 0.0215, 0.0218, 0.0218, 0.0215, 0.0219, 0.0225,\n",
            "        0.0216, 0.0215, 0.0216, 0.0217, 0.0217, 0.0217, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0218, 0.0217, 0.0220, 0.0215, 0.0217, 0.0221, 0.0215, 0.0222, 0.0225,\n",
            "        0.0215, 0.0215, 0.0216, 0.0215, 0.0217, 0.0215, 0.0219],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0218, 0.0217, 0.0220, 0.0215, 0.0217, 0.0221, 0.0215, 0.0222, 0.0225,\n",
            "        0.0215, 0.0215, 0.0216, 0.0215, 0.0217, 0.0215, 0.0219],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0218, 0.0217, 0.0220, 0.0215, 0.0215, 0.0219, 0.0215, 0.0222, 0.0225,\n",
            "        0.0215, 0.0215, 0.0216, 0.0215, 0.0217, 0.0215, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0215, 0.0215, 0.0219, 0.0215, 0.0215, 0.0216, 0.0215, 0.0216, 0.0225,\n",
            "        0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0215, 0.0215, 0.0216, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0225,\n",
            "        0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0215, 0.0215, 0.0215, 0.0212, 0.0212, 0.0215, 0.0212, 0.0215, 0.0225,\n",
            "        0.0212, 0.0212, 0.0215, 0.0212, 0.0212, 0.0212, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0215, 0.0212, 0.0215, 0.0212, 0.0212, 0.0215, 0.0212, 0.0215, 0.0222,\n",
            "        0.0212, 0.0215, 0.0215, 0.0212, 0.0212, 0.0212, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0215, 0.0212, 0.0215, 0.0215, 0.0215, 0.0216, 0.0215, 0.0215, 0.0225,\n",
            "        0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0216, 0.0215, 0.0215, 0.0225,\n",
            "        0.0215, 0.0215, 0.0216, 0.0215, 0.0215, 0.0215, 0.0218],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0215, 0.0215, 0.0218, 0.0215, 0.0215, 0.0216, 0.0215, 0.0219, 0.0225,\n",
            "        0.0215, 0.0215, 0.0216, 0.0215, 0.0215, 0.0215, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0218, 0.0215, 0.0218, 0.0215, 0.0215, 0.0216, 0.0215, 0.0216, 0.0225,\n",
            "        0.0215, 0.0215, 0.0216, 0.0215, 0.0215, 0.0215, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0429, 0.0415, 0.0422, 0.0412, 0.0419, 0.0426, 0.0422, 0.0417, 0.0416,\n",
            "        0.0440, 0.0439, 0.0439, 0.0442, 0.0429, 0.0413, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0426, 0.0417, 0.0427, 0.0415, 0.0419, 0.0422, 0.0421, 0.0415, 0.0418,\n",
            "        0.0423, 0.0435, 0.0432, 0.0428, 0.0427, 0.0415, 0.0459],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0426, 0.0422, 0.0427, 0.0424, 0.0431, 0.0429, 0.0425, 0.0420, 0.0424,\n",
            "        0.0431, 0.0441, 0.0434, 0.0440, 0.0435, 0.0424, 0.0438],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0421, 0.0418, 0.0422, 0.0422, 0.0430, 0.0428, 0.0418, 0.0418, 0.0427,\n",
            "        0.0426, 0.0435, 0.0434, 0.0438, 0.0425, 0.0425, 0.0431],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0421, 0.0421, 0.0422, 0.0423, 0.0427, 0.0422, 0.0418, 0.0418, 0.0421,\n",
            "        0.0424, 0.0430, 0.0429, 0.0438, 0.0425, 0.0429, 0.0428],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0424, 0.0424, 0.0425, 0.0426, 0.0427, 0.0422, 0.0421, 0.0421, 0.0424,\n",
            "        0.0427, 0.0425, 0.0435, 0.0424, 0.0428, 0.0429, 0.0423],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0424, 0.0421, 0.0425, 0.0429, 0.0427, 0.0422, 0.0421, 0.0419, 0.0424,\n",
            "        0.0427, 0.0425, 0.0438, 0.0424, 0.0421, 0.0431, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0421, 0.0421, 0.0422, 0.0429, 0.0424, 0.0422, 0.0418, 0.0419, 0.0421,\n",
            "        0.0427, 0.0424, 0.0438, 0.0424, 0.0421, 0.0429, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0421, 0.0421, 0.0419, 0.0428, 0.0421, 0.0422, 0.0419, 0.0419, 0.0421,\n",
            "        0.0424, 0.0422, 0.0444, 0.0424, 0.0418, 0.0428, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0421, 0.0419, 0.0418, 0.0428, 0.0419, 0.0422, 0.0419, 0.0419, 0.0418,\n",
            "        0.0422, 0.0422, 0.0435, 0.0421, 0.0419, 0.0427, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0418, 0.0419, 0.0418, 0.0427, 0.0419, 0.0422, 0.0419, 0.0419, 0.0418,\n",
            "        0.0419, 0.0419, 0.0429, 0.0419, 0.0419, 0.0427, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0418, 0.0419, 0.0418, 0.0427, 0.0419, 0.0421, 0.0419, 0.0419, 0.0418,\n",
            "        0.0419, 0.0419, 0.0429, 0.0419, 0.0419, 0.0427, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0419, 0.0419, 0.0418, 0.0427, 0.0419, 0.0421, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0428, 0.0419, 0.0419, 0.0427, 0.0421],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0419, 0.0419, 0.0418, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0428, 0.0419, 0.0419, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0419, 0.0419, 0.0419, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0427, 0.0418, 0.0418, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0419, 0.0419, 0.0419, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0427, 0.0418, 0.0419, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0419, 0.0419, 0.0419, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0427, 0.0418, 0.0419, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0419, 0.0419, 0.0419, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0427, 0.0418, 0.0419, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0419, 0.0419, 0.0419, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0427, 0.0419, 0.0419, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0419, 0.0419, 0.0419, 0.0427, 0.0419, 0.0420, 0.0419, 0.0419, 0.0419,\n",
            "        0.0419, 0.0419, 0.0427, 0.0419, 0.0419, 0.0427, 0.0420],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0364, 0.0343, 0.0341, 0.0360, 0.0339, 0.0339, 0.0355, 0.0340, 0.0347,\n",
            "        0.0356, 0.0357, 0.0329, 0.0362, 0.0346, 0.0339, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0359, 0.0343, 0.0350, 0.0379, 0.0337, 0.0340, 0.0350, 0.0334, 0.0345,\n",
            "        0.0348, 0.0349, 0.0334, 0.0382, 0.0353, 0.0347, 0.0349],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0351, 0.0345, 0.0339, 0.0350, 0.0344, 0.0344, 0.0350, 0.0340, 0.0353,\n",
            "        0.0351, 0.0345, 0.0336, 0.0361, 0.0355, 0.0347, 0.0346],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0350, 0.0340, 0.0338, 0.0347, 0.0344, 0.0341, 0.0342, 0.0345, 0.0357,\n",
            "        0.0344, 0.0346, 0.0337, 0.0350, 0.0357, 0.0335, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0341, 0.0335, 0.0341, 0.0346, 0.0344, 0.0338, 0.0335, 0.0334, 0.0355,\n",
            "        0.0341, 0.0344, 0.0337, 0.0346, 0.0347, 0.0337, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0340, 0.0338, 0.0343, 0.0349, 0.0343, 0.0338, 0.0338, 0.0337, 0.0345,\n",
            "        0.0344, 0.0341, 0.0337, 0.0349, 0.0340, 0.0337, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0338, 0.0338, 0.0337, 0.0340, 0.0343, 0.0338, 0.0338, 0.0337, 0.0339,\n",
            "        0.0344, 0.0340, 0.0337, 0.0340, 0.0340, 0.0337, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0338, 0.0335, 0.0335, 0.0340, 0.0349, 0.0335, 0.0335, 0.0335, 0.0339,\n",
            "        0.0344, 0.0339, 0.0337, 0.0340, 0.0340, 0.0335, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0335, 0.0335, 0.0340, 0.0340, 0.0343, 0.0340, 0.0335, 0.0340, 0.0342,\n",
            "        0.0347, 0.0339, 0.0337, 0.0340, 0.0343, 0.0340, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0342,\n",
            "        0.0340, 0.0337, 0.0337, 0.0340, 0.0343, 0.0340, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0340, 0.0335, 0.0335, 0.0339, 0.0335, 0.0334, 0.0340, 0.0339, 0.0337,\n",
            "        0.0335, 0.0337, 0.0337, 0.0340, 0.0342, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0340, 0.0335, 0.0335, 0.0337, 0.0335, 0.0334, 0.0340, 0.0334, 0.0337,\n",
            "        0.0335, 0.0337, 0.0336, 0.0340, 0.0339, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0335, 0.0335, 0.0335, 0.0337, 0.0335, 0.0334, 0.0335, 0.0334, 0.0335,\n",
            "        0.0335, 0.0336, 0.0336, 0.0339, 0.0334, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0334, 0.0335, 0.0335, 0.0337, 0.0335, 0.0334, 0.0334, 0.0334, 0.0335,\n",
            "        0.0335, 0.0336, 0.0336, 0.0339, 0.0334, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0334, 0.0335, 0.0335, 0.0336, 0.0334, 0.0335, 0.0335, 0.0334, 0.0335,\n",
            "        0.0335, 0.0336, 0.0336, 0.0336, 0.0334, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0335, 0.0335, 0.0335, 0.0336, 0.0334, 0.0335, 0.0335, 0.0335, 0.0335,\n",
            "        0.0335, 0.0336, 0.0337, 0.0336, 0.0335, 0.0335, 0.0337],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0335, 0.0335, 0.0335, 0.0336, 0.0334, 0.0335, 0.0335, 0.0340, 0.0334,\n",
            "        0.0335, 0.0336, 0.0337, 0.0336, 0.0340, 0.0335, 0.0337],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0335, 0.0335, 0.0335, 0.0337, 0.0334, 0.0335, 0.0335, 0.0335, 0.0335,\n",
            "        0.0335, 0.0336, 0.0337, 0.0336, 0.0335, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0340, 0.0335, 0.0334, 0.0337, 0.0334, 0.0335, 0.0340, 0.0335, 0.0335,\n",
            "        0.0334, 0.0336, 0.0337, 0.0336, 0.0335, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0335, 0.0335, 0.0334, 0.0337, 0.0334, 0.0335, 0.0335, 0.0335, 0.0335,\n",
            "        0.0334, 0.0336, 0.0337, 0.0336, 0.0340, 0.0335, 0.0336],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0197, 0.0198, 0.0195, 0.0194, 0.0200, 0.0206, 0.0202, 0.0193, 0.0197,\n",
            "        0.0189, 0.0197, 0.0195, 0.0192, 0.0188, 0.0205, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0193, 0.0188, 0.0187, 0.0191, 0.0199, 0.0200, 0.0198, 0.0196, 0.0193,\n",
            "        0.0188, 0.0199, 0.0203, 0.0194, 0.0187, 0.0190, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0195, 0.0196, 0.0190, 0.0193, 0.0212, 0.0194, 0.0209, 0.0193, 0.0192,\n",
            "        0.0189, 0.0209, 0.0194, 0.0194, 0.0195, 0.0196, 0.0194],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0200, 0.0196, 0.0194, 0.0196, 0.0199, 0.0195, 0.0199, 0.0190, 0.0195,\n",
            "        0.0194, 0.0207, 0.0195, 0.0196, 0.0188, 0.0193, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0204, 0.0192, 0.0195, 0.0193, 0.0200, 0.0193, 0.0189, 0.0190, 0.0195,\n",
            "        0.0193, 0.0193, 0.0198, 0.0193, 0.0188, 0.0195, 0.0194],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0194, 0.0192, 0.0187, 0.0189, 0.0192, 0.0190, 0.0191, 0.0189, 0.0190,\n",
            "        0.0193, 0.0193, 0.0197, 0.0189, 0.0188, 0.0193, 0.0189],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0188, 0.0191, 0.0191, 0.0191, 0.0190, 0.0189, 0.0190, 0.0190, 0.0191,\n",
            "        0.0192, 0.0190, 0.0190, 0.0191, 0.0190, 0.0189, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0188, 0.0191, 0.0191, 0.0191, 0.0190, 0.0192, 0.0190, 0.0190, 0.0189,\n",
            "        0.0191, 0.0190, 0.0190, 0.0191, 0.0188, 0.0189, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0188, 0.0190, 0.0188, 0.0190, 0.0188, 0.0190, 0.0190, 0.0188, 0.0189,\n",
            "        0.0190, 0.0188, 0.0190, 0.0188, 0.0188, 0.0191, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0188, 0.0190, 0.0188, 0.0190, 0.0188, 0.0190, 0.0187, 0.0188, 0.0188,\n",
            "        0.0188, 0.0187, 0.0190, 0.0188, 0.0188, 0.0190, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0187, 0.0188, 0.0186, 0.0185, 0.0188, 0.0188, 0.0187, 0.0187, 0.0185,\n",
            "        0.0185, 0.0187, 0.0189, 0.0185, 0.0186, 0.0190, 0.0186],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0187, 0.0186, 0.0186, 0.0185, 0.0188, 0.0186, 0.0187, 0.0187, 0.0185,\n",
            "        0.0185, 0.0187, 0.0189, 0.0185, 0.0186, 0.0187, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0187, 0.0186, 0.0186, 0.0185, 0.0187, 0.0186, 0.0187, 0.0187, 0.0185,\n",
            "        0.0186, 0.0187, 0.0187, 0.0185, 0.0186, 0.0186, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0187, 0.0185, 0.0185, 0.0185, 0.0187, 0.0186, 0.0187, 0.0187, 0.0185,\n",
            "        0.0186, 0.0187, 0.0187, 0.0185, 0.0185, 0.0186, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0187, 0.0185, 0.0185, 0.0188, 0.0187, 0.0186, 0.0187, 0.0187, 0.0188,\n",
            "        0.0186, 0.0187, 0.0187, 0.0188, 0.0188, 0.0186, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0187, 0.0188, 0.0188, 0.0188, 0.0187, 0.0188, 0.0187, 0.0187, 0.0188,\n",
            "        0.0188, 0.0187, 0.0187, 0.0188, 0.0188, 0.0186, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0187, 0.0188, 0.0188, 0.0188, 0.0187, 0.0188, 0.0187, 0.0188, 0.0188,\n",
            "        0.0188, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0187, 0.0188, 0.0188, 0.0188, 0.0187, 0.0188, 0.0187, 0.0188, 0.0188,\n",
            "        0.0188, 0.0188, 0.0188, 0.0186, 0.0186, 0.0188, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0187, 0.0185, 0.0186, 0.0185, 0.0187, 0.0186, 0.0188, 0.0188, 0.0185,\n",
            "        0.0185, 0.0188, 0.0188, 0.0186, 0.0186, 0.0185, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0188, 0.0185, 0.0186, 0.0185, 0.0187, 0.0186, 0.0188, 0.0188, 0.0185,\n",
            "        0.0185, 0.0188, 0.0188, 0.0186, 0.0186, 0.0185, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0245, 0.0229, 0.0241, 0.0219, 0.0236, 0.0222, 0.0227, 0.0224, 0.0233,\n",
            "        0.0227, 0.0221, 0.0228, 0.0238, 0.0229, 0.0230, 0.0231],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0239, 0.0226, 0.0242, 0.0226, 0.0223, 0.0222, 0.0223, 0.0224, 0.0231,\n",
            "        0.0236, 0.0225, 0.0236, 0.0236, 0.0233, 0.0233, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0237, 0.0230, 0.0232, 0.0229, 0.0229, 0.0222, 0.0224, 0.0228, 0.0225,\n",
            "        0.0234, 0.0229, 0.0244, 0.0233, 0.0232, 0.0235, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0230, 0.0231, 0.0233, 0.0227, 0.0233, 0.0227, 0.0224, 0.0226, 0.0229,\n",
            "        0.0237, 0.0226, 0.0228, 0.0234, 0.0237, 0.0227, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0229, 0.0227, 0.0228, 0.0224, 0.0228, 0.0228, 0.0227, 0.0224, 0.0228,\n",
            "        0.0236, 0.0224, 0.0228, 0.0232, 0.0236, 0.0225, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0225, 0.0227, 0.0228, 0.0224, 0.0228, 0.0226, 0.0227, 0.0224, 0.0224,\n",
            "        0.0226, 0.0224, 0.0226, 0.0231, 0.0227, 0.0225, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0225, 0.0227, 0.0228, 0.0224, 0.0226, 0.0229, 0.0230, 0.0224, 0.0224,\n",
            "        0.0226, 0.0224, 0.0226, 0.0226, 0.0227, 0.0225, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0225, 0.0227, 0.0231, 0.0225, 0.0229, 0.0227, 0.0228, 0.0225, 0.0227,\n",
            "        0.0229, 0.0225, 0.0226, 0.0229, 0.0227, 0.0225, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0227, 0.0225, 0.0226, 0.0225, 0.0228, 0.0227, 0.0225, 0.0225, 0.0225,\n",
            "        0.0229, 0.0225, 0.0227, 0.0229, 0.0227, 0.0224, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0227, 0.0225, 0.0225, 0.0225, 0.0226, 0.0225, 0.0225, 0.0225, 0.0225,\n",
            "        0.0227, 0.0225, 0.0227, 0.0227, 0.0229, 0.0228, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0227, 0.0222, 0.0225, 0.0222, 0.0225, 0.0222, 0.0225, 0.0222, 0.0225,\n",
            "        0.0225, 0.0222, 0.0224, 0.0227, 0.0224, 0.0224, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222,\n",
            "        0.0222, 0.0222, 0.0224, 0.0224, 0.0224, 0.0224, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222,\n",
            "        0.0222, 0.0222, 0.0224, 0.0224, 0.0224, 0.0224, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222,\n",
            "        0.0222, 0.0222, 0.0224, 0.0222, 0.0224, 0.0224, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0222, 0.0222, 0.0222, 0.0225, 0.0222, 0.0225, 0.0225, 0.0225, 0.0222,\n",
            "        0.0222, 0.0225, 0.0224, 0.0222, 0.0224, 0.0224, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0222, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225,\n",
            "        0.0225, 0.0225, 0.0224, 0.0225, 0.0224, 0.0224, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225,\n",
            "        0.0225, 0.0225, 0.0224, 0.0225, 0.0224, 0.0224, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0225, 0.0225, 0.0225, 0.0222, 0.0225, 0.0225, 0.0225, 0.0222, 0.0225,\n",
            "        0.0225, 0.0222, 0.0224, 0.0225, 0.0224, 0.0224, 0.0225],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222,\n",
            "        0.0222, 0.0222, 0.0224, 0.0222, 0.0224, 0.0224, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222, 0.0222,\n",
            "        0.0222, 0.0222, 0.0224, 0.0222, 0.0224, 0.0224, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0171, 0.0181, 0.0178, 0.0181, 0.0180, 0.0177, 0.0175, 0.0201, 0.0182,\n",
            "        0.0176, 0.0179, 0.0177, 0.0179, 0.0170, 0.0168, 0.0186],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0173, 0.0172, 0.0183, 0.0179, 0.0184, 0.0168, 0.0172, 0.0194, 0.0180,\n",
            "        0.0169, 0.0178, 0.0173, 0.0180, 0.0172, 0.0167, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0181, 0.0179, 0.0180, 0.0176, 0.0176, 0.0174, 0.0172, 0.0189, 0.0175,\n",
            "        0.0172, 0.0182, 0.0182, 0.0182, 0.0177, 0.0172, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0180, 0.0186, 0.0180, 0.0181, 0.0183, 0.0178, 0.0173, 0.0190, 0.0180,\n",
            "        0.0173, 0.0178, 0.0188, 0.0184, 0.0177, 0.0176, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0176, 0.0187, 0.0175, 0.0184, 0.0182, 0.0180, 0.0174, 0.0188, 0.0180,\n",
            "        0.0174, 0.0178, 0.0180, 0.0180, 0.0177, 0.0178, 0.0176],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0178, 0.0181, 0.0178, 0.0176, 0.0180, 0.0182, 0.0175, 0.0187, 0.0177,\n",
            "        0.0176, 0.0177, 0.0175, 0.0181, 0.0178, 0.0176, 0.0177],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0175, 0.0175, 0.0178, 0.0175, 0.0175, 0.0175, 0.0173, 0.0178, 0.0175,\n",
            "        0.0173, 0.0175, 0.0173, 0.0175, 0.0175, 0.0174, 0.0175],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0175, 0.0175, 0.0178, 0.0175, 0.0175, 0.0175, 0.0173, 0.0176, 0.0175,\n",
            "        0.0173, 0.0175, 0.0173, 0.0175, 0.0173, 0.0174, 0.0175],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0173, 0.0175, 0.0180, 0.0175, 0.0175, 0.0175, 0.0172, 0.0176, 0.0175,\n",
            "        0.0172, 0.0175, 0.0173, 0.0173, 0.0172, 0.0172, 0.0175],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0172, 0.0175, 0.0179, 0.0175, 0.0175, 0.0177, 0.0172, 0.0176, 0.0175,\n",
            "        0.0172, 0.0175, 0.0172, 0.0173, 0.0172, 0.0172, 0.0175],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0174, 0.0173, 0.0179, 0.0175, 0.0176, 0.0175, 0.0174, 0.0176, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0176],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0174, 0.0175, 0.0179, 0.0175, 0.0174, 0.0175, 0.0174, 0.0179, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0174, 0.0175, 0.0179, 0.0175, 0.0174, 0.0174, 0.0174, 0.0177, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0174, 0.0175, 0.0179, 0.0175, 0.0174, 0.0174, 0.0174, 0.0177, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0174, 0.0173, 0.0179, 0.0173, 0.0174, 0.0174, 0.0174, 0.0176, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0172, 0.0173, 0.0179, 0.0173, 0.0174, 0.0172, 0.0174, 0.0174, 0.0172,\n",
            "        0.0174, 0.0172, 0.0174, 0.0172, 0.0174, 0.0172, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0172, 0.0173, 0.0179, 0.0173, 0.0172, 0.0172, 0.0172, 0.0173, 0.0172,\n",
            "        0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0172, 0.0173, 0.0179, 0.0173, 0.0172, 0.0172, 0.0172, 0.0173, 0.0172,\n",
            "        0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0174, 0.0173, 0.0179, 0.0173, 0.0172, 0.0174, 0.0172, 0.0173, 0.0174,\n",
            "        0.0172, 0.0172, 0.0174, 0.0174, 0.0172, 0.0174, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0174, 0.0173, 0.0179, 0.0173, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0215, 0.0198, 0.0207, 0.0218, 0.0196, 0.0199, 0.0204, 0.0197, 0.0190,\n",
            "        0.0199, 0.0204, 0.0201, 0.0195, 0.0208, 0.0193, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0220, 0.0199, 0.0214, 0.0201, 0.0187, 0.0205, 0.0194, 0.0196, 0.0194,\n",
            "        0.0201, 0.0195, 0.0199, 0.0199, 0.0200, 0.0199, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0208, 0.0213, 0.0206, 0.0210, 0.0193, 0.0203, 0.0202, 0.0204, 0.0197,\n",
            "        0.0210, 0.0203, 0.0208, 0.0202, 0.0206, 0.0203, 0.0204],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0208, 0.0207, 0.0204, 0.0215, 0.0195, 0.0205, 0.0204, 0.0200, 0.0200,\n",
            "        0.0209, 0.0206, 0.0210, 0.0203, 0.0208, 0.0207, 0.0206],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0207, 0.0207, 0.0206, 0.0212, 0.0198, 0.0204, 0.0201, 0.0202, 0.0202,\n",
            "        0.0210, 0.0201, 0.0201, 0.0206, 0.0211, 0.0204, 0.0203],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0200, 0.0206, 0.0204, 0.0199, 0.0196, 0.0198, 0.0196, 0.0198, 0.0198,\n",
            "        0.0205, 0.0197, 0.0201, 0.0201, 0.0200, 0.0198, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0201, 0.0200, 0.0201, 0.0199, 0.0196, 0.0198, 0.0196, 0.0198, 0.0198,\n",
            "        0.0199, 0.0198, 0.0201, 0.0201, 0.0198, 0.0198, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0201, 0.0200, 0.0201, 0.0199, 0.0196, 0.0198, 0.0196, 0.0198, 0.0198,\n",
            "        0.0199, 0.0200, 0.0201, 0.0198, 0.0198, 0.0198, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0201, 0.0200, 0.0201, 0.0199, 0.0196, 0.0198, 0.0196, 0.0198, 0.0196,\n",
            "        0.0198, 0.0201, 0.0201, 0.0198, 0.0198, 0.0198, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0198, 0.0200, 0.0201, 0.0199, 0.0196, 0.0198, 0.0196, 0.0198, 0.0196,\n",
            "        0.0198, 0.0198, 0.0201, 0.0196, 0.0198, 0.0196, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0198, 0.0198, 0.0198, 0.0199, 0.0195, 0.0198, 0.0195, 0.0197, 0.0195,\n",
            "        0.0198, 0.0198, 0.0198, 0.0196, 0.0198, 0.0196, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0198, 0.0198, 0.0201, 0.0199, 0.0195, 0.0196, 0.0195, 0.0196, 0.0195,\n",
            "        0.0196, 0.0198, 0.0198, 0.0195, 0.0198, 0.0195, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0198, 0.0198, 0.0199, 0.0199, 0.0195, 0.0195, 0.0195, 0.0196, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0198, 0.0198, 0.0199, 0.0199, 0.0195, 0.0197, 0.0195, 0.0195, 0.0195,\n",
            "        0.0198, 0.0198, 0.0198, 0.0195, 0.0197, 0.0195, 0.0197],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0198, 0.0198, 0.0196, 0.0199, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0198, 0.0198, 0.0196, 0.0199, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0198, 0.0198, 0.0196, 0.0199, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0198, 0.0198, 0.0196, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0199, 0.0198, 0.0196, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0199, 0.0198, 0.0196, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
            "        0.0195, 0.0198, 0.0198, 0.0195, 0.0195, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0354, 0.0346, 0.0338, 0.0335, 0.0344, 0.0331, 0.0331, 0.0341, 0.0334,\n",
            "        0.0331, 0.0334, 0.0334, 0.0339, 0.0334, 0.0342, 0.0359],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0352, 0.0353, 0.0338, 0.0343, 0.0342, 0.0339, 0.0335, 0.0348, 0.0337,\n",
            "        0.0338, 0.0341, 0.0340, 0.0339, 0.0341, 0.0351, 0.0347],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0353, 0.0360, 0.0342, 0.0342, 0.0350, 0.0345, 0.0339, 0.0343, 0.0339,\n",
            "        0.0344, 0.0349, 0.0347, 0.0344, 0.0336, 0.0358, 0.0358],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0337, 0.0351, 0.0339, 0.0333, 0.0349, 0.0339, 0.0334, 0.0336, 0.0339,\n",
            "        0.0337, 0.0341, 0.0338, 0.0341, 0.0334, 0.0337, 0.0351],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0337, 0.0342, 0.0337, 0.0335, 0.0347, 0.0334, 0.0334, 0.0335, 0.0339,\n",
            "        0.0334, 0.0342, 0.0341, 0.0337, 0.0334, 0.0337, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0338, 0.0335, 0.0337, 0.0337, 0.0347, 0.0334, 0.0334, 0.0335, 0.0338,\n",
            "        0.0334, 0.0342, 0.0337, 0.0337, 0.0337, 0.0337, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0335, 0.0338, 0.0337, 0.0337, 0.0341, 0.0334, 0.0334, 0.0335, 0.0338,\n",
            "        0.0334, 0.0337, 0.0337, 0.0337, 0.0337, 0.0334, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0335, 0.0337, 0.0337, 0.0335, 0.0341, 0.0332, 0.0334, 0.0335, 0.0334,\n",
            "        0.0332, 0.0337, 0.0337, 0.0337, 0.0333, 0.0334, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0332, 0.0334, 0.0335, 0.0335, 0.0337, 0.0332, 0.0334, 0.0335, 0.0332,\n",
            "        0.0332, 0.0334, 0.0335, 0.0335, 0.0333, 0.0334, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0337, 0.0339, 0.0339, 0.0337, 0.0338, 0.0337, 0.0334, 0.0335, 0.0337,\n",
            "        0.0337, 0.0337, 0.0337, 0.0337, 0.0338, 0.0334, 0.0338],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0337, 0.0337, 0.0337, 0.0337, 0.0338, 0.0337, 0.0339, 0.0340, 0.0337,\n",
            "        0.0337, 0.0337, 0.0337, 0.0338, 0.0338, 0.0339, 0.0343],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0337, 0.0337, 0.0337, 0.0337, 0.0338, 0.0337, 0.0339, 0.0339, 0.0337,\n",
            "        0.0337, 0.0337, 0.0337, 0.0338, 0.0337, 0.0339, 0.0340],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0339, 0.0339, 0.0337,\n",
            "        0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0339, 0.0339],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0332, 0.0332, 0.0333, 0.0332, 0.0332, 0.0333, 0.0334, 0.0334, 0.0332,\n",
            "        0.0332, 0.0332, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0332, 0.0332, 0.0333, 0.0332, 0.0332, 0.0333, 0.0334, 0.0334, 0.0332,\n",
            "        0.0332, 0.0332, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0332, 0.0332, 0.0333, 0.0332, 0.0332, 0.0333, 0.0334, 0.0334, 0.0332,\n",
            "        0.0332, 0.0332, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0332, 0.0332, 0.0333, 0.0332, 0.0332, 0.0333, 0.0334, 0.0334, 0.0332,\n",
            "        0.0332, 0.0332, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0332, 0.0332, 0.0333, 0.0332, 0.0332, 0.0333, 0.0334, 0.0334, 0.0332,\n",
            "        0.0332, 0.0332, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0332, 0.0333, 0.0333, 0.0332, 0.0332, 0.0333, 0.0334, 0.0334, 0.0333,\n",
            "        0.0332, 0.0333, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0332, 0.0333, 0.0332, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334, 0.0332,\n",
            "        0.0332, 0.0333, 0.0332, 0.0332, 0.0332, 0.0334, 0.0334],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0243, 0.0246, 0.0245, 0.0250, 0.0264, 0.0257, 0.0243, 0.0239, 0.0235,\n",
            "        0.0252, 0.0247, 0.0238, 0.0245, 0.0245, 0.0259, 0.0255],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0246, 0.0254, 0.0238, 0.0248, 0.0251, 0.0257, 0.0251, 0.0246, 0.0233,\n",
            "        0.0260, 0.0248, 0.0237, 0.0245, 0.0251, 0.0256, 0.0263],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0240, 0.0246, 0.0241, 0.0248, 0.0253, 0.0264, 0.0249, 0.0244, 0.0234,\n",
            "        0.0246, 0.0246, 0.0236, 0.0247, 0.0244, 0.0254, 0.0250],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0244, 0.0254, 0.0249, 0.0245, 0.0255, 0.0254, 0.0245, 0.0246, 0.0242,\n",
            "        0.0255, 0.0249, 0.0241, 0.0254, 0.0252, 0.0252, 0.0258],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0245, 0.0257, 0.0245, 0.0250, 0.0257, 0.0249, 0.0249, 0.0244, 0.0244,\n",
            "        0.0256, 0.0248, 0.0244, 0.0252, 0.0246, 0.0254, 0.0249],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0246, 0.0257, 0.0246, 0.0248, 0.0250, 0.0249, 0.0249, 0.0244, 0.0244,\n",
            "        0.0256, 0.0244, 0.0244, 0.0249, 0.0249, 0.0247, 0.0249],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0242, 0.0246, 0.0242, 0.0248, 0.0246, 0.0246, 0.0245, 0.0240, 0.0241,\n",
            "        0.0246, 0.0244, 0.0240, 0.0246, 0.0246, 0.0246, 0.0245],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0242, 0.0244, 0.0242, 0.0245, 0.0244, 0.0242, 0.0241, 0.0240, 0.0239,\n",
            "        0.0242, 0.0241, 0.0238, 0.0241, 0.0241, 0.0244, 0.0243],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0238, 0.0244, 0.0241, 0.0243, 0.0244, 0.0242, 0.0241, 0.0239, 0.0239,\n",
            "        0.0242, 0.0239, 0.0238, 0.0239, 0.0239, 0.0244, 0.0243],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0238, 0.0244, 0.0239, 0.0243, 0.0244, 0.0241, 0.0241, 0.0239, 0.0239,\n",
            "        0.0240, 0.0239, 0.0238, 0.0238, 0.0239, 0.0242, 0.0243],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0239, 0.0244, 0.0239, 0.0243, 0.0244, 0.0241, 0.0241, 0.0239, 0.0239,\n",
            "        0.0240, 0.0239, 0.0238, 0.0238, 0.0239, 0.0242, 0.0243],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0239, 0.0244, 0.0239, 0.0243, 0.0243, 0.0241, 0.0241, 0.0238, 0.0239,\n",
            "        0.0239, 0.0239, 0.0238, 0.0238, 0.0239, 0.0242, 0.0243],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0239, 0.0242, 0.0239, 0.0243, 0.0241, 0.0241, 0.0241, 0.0238, 0.0239,\n",
            "        0.0239, 0.0238, 0.0238, 0.0238, 0.0239, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0239, 0.0241, 0.0239, 0.0246, 0.0241, 0.0241, 0.0241, 0.0238, 0.0239,\n",
            "        0.0239, 0.0238, 0.0239, 0.0238, 0.0239, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0242, 0.0241, 0.0242, 0.0246, 0.0241, 0.0241, 0.0241, 0.0242, 0.0242,\n",
            "        0.0242, 0.0242, 0.0242, 0.0242, 0.0242, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0242, 0.0241, 0.0242, 0.0246, 0.0241, 0.0241, 0.0241, 0.0242, 0.0242,\n",
            "        0.0242, 0.0242, 0.0242, 0.0242, 0.0242, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0242, 0.0241, 0.0239, 0.0246, 0.0242, 0.0241, 0.0241, 0.0238, 0.0239,\n",
            "        0.0242, 0.0242, 0.0239, 0.0242, 0.0242, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0239, 0.0241, 0.0239, 0.0243, 0.0242, 0.0241, 0.0241, 0.0239, 0.0239,\n",
            "        0.0238, 0.0239, 0.0239, 0.0239, 0.0239, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0239, 0.0241, 0.0239, 0.0243, 0.0242, 0.0241, 0.0241, 0.0239, 0.0239,\n",
            "        0.0238, 0.0239, 0.0239, 0.0239, 0.0239, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0239, 0.0241, 0.0239, 0.0243, 0.0242, 0.0241, 0.0241, 0.0239, 0.0239,\n",
            "        0.0238, 0.0239, 0.0239, 0.0239, 0.0239, 0.0241, 0.0241],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0179, 0.0185, 0.0172, 0.0178, 0.0165, 0.0171, 0.0173, 0.0176, 0.0181,\n",
            "        0.0180, 0.0171, 0.0169, 0.0182, 0.0174, 0.0176, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0182, 0.0164, 0.0172, 0.0172, 0.0162, 0.0165, 0.0167, 0.0170, 0.0171,\n",
            "        0.0177, 0.0166, 0.0168, 0.0172, 0.0171, 0.0165, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0188, 0.0176, 0.0174, 0.0166, 0.0162, 0.0167, 0.0170, 0.0177, 0.0176,\n",
            "        0.0176, 0.0170, 0.0172, 0.0184, 0.0167, 0.0170, 0.0169],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0167, 0.0173, 0.0165, 0.0169, 0.0164, 0.0172, 0.0173, 0.0172, 0.0173,\n",
            "        0.0170, 0.0170, 0.0172, 0.0178, 0.0168, 0.0168, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0169, 0.0172, 0.0165, 0.0168, 0.0165, 0.0172, 0.0175, 0.0171, 0.0175,\n",
            "        0.0171, 0.0166, 0.0165, 0.0180, 0.0165, 0.0170, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0170, 0.0173, 0.0165, 0.0165, 0.0165, 0.0171, 0.0173, 0.0172, 0.0177,\n",
            "        0.0168, 0.0167, 0.0165, 0.0175, 0.0165, 0.0166, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0170, 0.0173, 0.0167, 0.0167, 0.0167, 0.0170, 0.0170, 0.0170, 0.0177,\n",
            "        0.0168, 0.0169, 0.0167, 0.0173, 0.0167, 0.0169, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0169, 0.0171, 0.0167, 0.0167, 0.0167, 0.0170, 0.0170, 0.0168, 0.0170,\n",
            "        0.0168, 0.0168, 0.0167, 0.0171, 0.0167, 0.0169, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0167, 0.0166, 0.0167, 0.0167, 0.0167, 0.0168, 0.0167, 0.0166, 0.0166,\n",
            "        0.0168, 0.0168, 0.0167, 0.0169, 0.0167, 0.0169, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0167, 0.0166, 0.0166, 0.0167, 0.0165, 0.0167, 0.0165, 0.0166, 0.0166,\n",
            "        0.0168, 0.0166, 0.0166, 0.0169, 0.0166, 0.0167, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0166, 0.0166, 0.0166, 0.0166, 0.0166, 0.0167, 0.0165, 0.0166, 0.0166,\n",
            "        0.0166, 0.0166, 0.0166, 0.0169, 0.0166, 0.0166, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0166, 0.0166, 0.0166, 0.0164, 0.0164, 0.0167, 0.0164, 0.0166, 0.0166,\n",
            "        0.0164, 0.0163, 0.0164, 0.0167, 0.0164, 0.0164, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0166, 0.0166, 0.0166, 0.0164, 0.0164, 0.0166, 0.0164, 0.0166, 0.0166,\n",
            "        0.0164, 0.0163, 0.0164, 0.0167, 0.0164, 0.0164, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0166, 0.0166, 0.0166, 0.0164, 0.0164, 0.0166, 0.0163, 0.0166, 0.0166,\n",
            "        0.0164, 0.0164, 0.0163, 0.0166, 0.0164, 0.0164, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0166, 0.0166, 0.0166, 0.0164, 0.0164, 0.0166, 0.0165, 0.0166, 0.0166,\n",
            "        0.0164, 0.0164, 0.0163, 0.0166, 0.0164, 0.0163, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0166, 0.0166, 0.0166, 0.0163, 0.0164, 0.0166, 0.0165, 0.0166, 0.0169,\n",
            "        0.0164, 0.0164, 0.0164, 0.0166, 0.0164, 0.0163, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0168, 0.0168, 0.0166, 0.0166, 0.0166, 0.0168, 0.0165, 0.0168, 0.0169,\n",
            "        0.0166, 0.0166, 0.0166, 0.0168, 0.0166, 0.0165, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0169, 0.0168, 0.0166, 0.0166, 0.0166, 0.0168, 0.0165, 0.0168, 0.0169,\n",
            "        0.0166, 0.0166, 0.0166, 0.0168, 0.0166, 0.0165, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0166, 0.0166, 0.0166, 0.0166, 0.0166, 0.0169, 0.0165, 0.0166, 0.0166,\n",
            "        0.0166, 0.0166, 0.0166, 0.0166, 0.0166, 0.0165, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0166, 0.0166, 0.0166, 0.0166, 0.0166, 0.0166, 0.0165, 0.0166, 0.0166,\n",
            "        0.0166, 0.0166, 0.0166, 0.0166, 0.0166, 0.0165, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0204, 0.0192, 0.0185, 0.0214, 0.0202, 0.0185, 0.0184, 0.0191, 0.0182,\n",
            "        0.0182, 0.0196, 0.0176, 0.0209, 0.0182, 0.0194, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0198, 0.0200, 0.0186, 0.0200, 0.0209, 0.0193, 0.0188, 0.0199, 0.0181,\n",
            "        0.0188, 0.0189, 0.0182, 0.0220, 0.0183, 0.0194, 0.0196],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0195, 0.0189, 0.0189, 0.0200, 0.0200, 0.0190, 0.0187, 0.0193, 0.0188,\n",
            "        0.0184, 0.0188, 0.0181, 0.0201, 0.0184, 0.0190, 0.0197],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0190, 0.0190, 0.0191, 0.0196, 0.0198, 0.0192, 0.0192, 0.0196, 0.0187,\n",
            "        0.0187, 0.0190, 0.0186, 0.0193, 0.0191, 0.0185, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0192, 0.0185, 0.0189, 0.0197, 0.0193, 0.0190, 0.0194, 0.0188, 0.0187,\n",
            "        0.0189, 0.0185, 0.0189, 0.0192, 0.0186, 0.0187, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0187, 0.0185, 0.0185, 0.0193, 0.0193, 0.0188, 0.0191, 0.0189, 0.0188,\n",
            "        0.0186, 0.0185, 0.0185, 0.0190, 0.0187, 0.0187, 0.0186],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0187, 0.0187, 0.0185, 0.0190, 0.0188, 0.0188, 0.0187, 0.0189, 0.0187,\n",
            "        0.0186, 0.0185, 0.0185, 0.0190, 0.0186, 0.0187, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0183, 0.0187, 0.0185, 0.0190, 0.0185, 0.0184, 0.0187, 0.0185, 0.0184,\n",
            "        0.0184, 0.0185, 0.0183, 0.0187, 0.0183, 0.0187, 0.0185],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0183, 0.0185, 0.0183, 0.0188, 0.0183, 0.0184, 0.0185, 0.0185, 0.0184,\n",
            "        0.0184, 0.0183, 0.0181, 0.0186, 0.0183, 0.0185, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0183, 0.0182, 0.0181, 0.0185, 0.0183, 0.0183, 0.0181, 0.0185, 0.0184,\n",
            "        0.0183, 0.0181, 0.0181, 0.0186, 0.0183, 0.0184, 0.0182],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0183, 0.0182, 0.0181, 0.0183, 0.0181, 0.0183, 0.0181, 0.0185, 0.0183,\n",
            "        0.0181, 0.0181, 0.0181, 0.0186, 0.0183, 0.0182, 0.0182],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0183, 0.0184, 0.0184, 0.0184, 0.0183, 0.0183, 0.0184, 0.0185, 0.0185,\n",
            "        0.0183, 0.0184, 0.0184, 0.0183, 0.0186, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0185, 0.0184, 0.0184, 0.0184, 0.0183, 0.0185, 0.0184, 0.0185, 0.0185,\n",
            "        0.0184, 0.0184, 0.0184, 0.0186, 0.0186, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0185, 0.0184, 0.0184, 0.0184, 0.0183, 0.0185, 0.0184, 0.0185, 0.0185,\n",
            "        0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0185, 0.0184, 0.0184, 0.0183, 0.0184, 0.0185, 0.0184, 0.0185, 0.0186,\n",
            "        0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0185, 0.0184, 0.0184, 0.0183, 0.0184, 0.0185, 0.0184, 0.0185, 0.0186,\n",
            "        0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0185, 0.0184, 0.0184, 0.0184, 0.0184, 0.0185, 0.0184, 0.0185, 0.0186,\n",
            "        0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0186, 0.0184, 0.0184, 0.0184, 0.0184, 0.0185, 0.0184, 0.0185, 0.0186,\n",
            "        0.0184, 0.0184, 0.0184, 0.0185, 0.0185, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0186, 0.0184, 0.0184, 0.0184, 0.0184, 0.0183, 0.0184, 0.0185, 0.0183,\n",
            "        0.0184, 0.0184, 0.0184, 0.0186, 0.0183, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0184, 0.0184, 0.0183, 0.0184, 0.0184, 0.0183, 0.0184, 0.0183, 0.0183,\n",
            "        0.0184, 0.0184, 0.0184, 0.0184, 0.0183, 0.0184, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0149, 0.0159, 0.0146, 0.0153, 0.0147, 0.0153, 0.0161, 0.0154, 0.0159,\n",
            "        0.0150, 0.0154, 0.0153, 0.0156, 0.0146, 0.0160, 0.0150],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0156, 0.0159, 0.0151, 0.0154, 0.0146, 0.0163, 0.0159, 0.0160, 0.0156,\n",
            "        0.0150, 0.0153, 0.0153, 0.0152, 0.0146, 0.0150, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0165, 0.0156, 0.0151, 0.0159, 0.0147, 0.0160, 0.0159, 0.0154, 0.0155,\n",
            "        0.0152, 0.0156, 0.0155, 0.0146, 0.0150, 0.0156, 0.0153],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0157, 0.0153, 0.0155, 0.0157, 0.0150, 0.0163, 0.0160, 0.0160, 0.0158,\n",
            "        0.0155, 0.0156, 0.0157, 0.0152, 0.0148, 0.0158, 0.0155],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0154, 0.0152, 0.0151, 0.0154, 0.0150, 0.0160, 0.0155, 0.0163, 0.0160,\n",
            "        0.0151, 0.0155, 0.0160, 0.0152, 0.0151, 0.0154, 0.0156],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0153, 0.0152, 0.0152, 0.0151, 0.0151, 0.0154, 0.0156, 0.0154, 0.0160,\n",
            "        0.0152, 0.0154, 0.0157, 0.0153, 0.0152, 0.0154, 0.0154],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0153, 0.0149, 0.0149, 0.0151, 0.0149, 0.0154, 0.0153, 0.0156, 0.0151,\n",
            "        0.0149, 0.0152, 0.0153, 0.0151, 0.0151, 0.0151, 0.0152],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0150, 0.0149, 0.0149, 0.0151, 0.0149, 0.0154, 0.0152, 0.0154, 0.0151,\n",
            "        0.0149, 0.0150, 0.0152, 0.0151, 0.0150, 0.0151, 0.0152],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0150, 0.0149, 0.0149, 0.0150, 0.0149, 0.0153, 0.0152, 0.0154, 0.0151,\n",
            "        0.0149, 0.0150, 0.0152, 0.0151, 0.0150, 0.0151, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0150, 0.0149, 0.0149, 0.0150, 0.0149, 0.0152, 0.0150, 0.0152, 0.0151,\n",
            "        0.0149, 0.0150, 0.0152, 0.0151, 0.0150, 0.0151, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0150, 0.0149, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0149, 0.0151,\n",
            "        0.0148, 0.0150, 0.0150, 0.0149, 0.0150, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0149, 0.0151,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0151, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0150,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0151, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0151, 0.0151,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0148,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0148,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0148,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0148,\n",
            "        0.0148, 0.0150, 0.0150, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0148,\n",
            "        0.0148, 0.0150, 0.0151, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0150, 0.0148, 0.0148, 0.0150, 0.0148, 0.0150, 0.0150, 0.0148, 0.0148,\n",
            "        0.0148, 0.0150, 0.0151, 0.0148, 0.0150, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0252, 0.0236, 0.0257, 0.0231, 0.0229, 0.0217, 0.0235, 0.0230, 0.0229,\n",
            "        0.0226, 0.0234, 0.0226, 0.0230, 0.0237, 0.0224, 0.0216],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0249, 0.0230, 0.0235, 0.0221, 0.0232, 0.0221, 0.0240, 0.0225, 0.0221,\n",
            "        0.0222, 0.0229, 0.0230, 0.0230, 0.0236, 0.0225, 0.0214],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0255, 0.0233, 0.0241, 0.0231, 0.0231, 0.0231, 0.0236, 0.0234, 0.0226,\n",
            "        0.0227, 0.0236, 0.0239, 0.0231, 0.0239, 0.0232, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0240, 0.0231, 0.0232, 0.0233, 0.0231, 0.0229, 0.0232, 0.0232, 0.0227,\n",
            "        0.0228, 0.0238, 0.0241, 0.0227, 0.0233, 0.0238, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0238, 0.0232, 0.0230, 0.0231, 0.0233, 0.0227, 0.0226, 0.0229, 0.0226,\n",
            "        0.0227, 0.0238, 0.0228, 0.0229, 0.0234, 0.0234, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0223, 0.0223, 0.0226, 0.0229, 0.0225, 0.0225, 0.0223, 0.0224, 0.0223,\n",
            "        0.0230, 0.0227, 0.0228, 0.0226, 0.0225, 0.0225, 0.0223],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0225, 0.0225, 0.0225, 0.0224, 0.0225, 0.0225, 0.0223, 0.0224, 0.0223,\n",
            "        0.0230, 0.0227, 0.0224, 0.0224, 0.0225, 0.0225, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0225, 0.0225, 0.0225, 0.0224, 0.0225, 0.0225, 0.0223, 0.0224, 0.0223,\n",
            "        0.0230, 0.0223, 0.0224, 0.0224, 0.0225, 0.0225, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0225, 0.0221, 0.0225, 0.0224, 0.0223, 0.0223, 0.0221, 0.0222, 0.0223,\n",
            "        0.0229, 0.0221, 0.0224, 0.0222, 0.0224, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0223, 0.0221, 0.0225, 0.0224, 0.0223, 0.0223, 0.0221, 0.0221, 0.0223,\n",
            "        0.0230, 0.0221, 0.0224, 0.0222, 0.0224, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0223, 0.0221, 0.0225, 0.0224, 0.0223, 0.0222, 0.0221, 0.0221, 0.0223,\n",
            "        0.0230, 0.0221, 0.0224, 0.0221, 0.0224, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0224, 0.0221, 0.0225, 0.0224, 0.0221, 0.0222, 0.0222, 0.0221, 0.0223,\n",
            "        0.0230, 0.0222, 0.0224, 0.0221, 0.0221, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0224, 0.0221, 0.0224, 0.0224, 0.0221, 0.0222, 0.0222, 0.0222, 0.0223,\n",
            "        0.0227, 0.0222, 0.0224, 0.0221, 0.0221, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0222, 0.0221, 0.0224, 0.0224, 0.0221, 0.0221, 0.0222, 0.0222, 0.0223,\n",
            "        0.0227, 0.0222, 0.0224, 0.0222, 0.0221, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0222, 0.0221, 0.0223, 0.0224, 0.0221, 0.0221, 0.0222, 0.0222, 0.0223,\n",
            "        0.0226, 0.0221, 0.0223, 0.0222, 0.0221, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0222, 0.0221, 0.0223, 0.0224, 0.0221, 0.0221, 0.0222, 0.0222, 0.0223,\n",
            "        0.0226, 0.0221, 0.0223, 0.0222, 0.0221, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0222, 0.0221, 0.0223, 0.0224, 0.0221, 0.0221, 0.0221, 0.0222, 0.0223,\n",
            "        0.0226, 0.0221, 0.0223, 0.0222, 0.0222, 0.0221, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0222, 0.0221, 0.0223, 0.0224, 0.0221, 0.0221, 0.0221, 0.0222, 0.0223,\n",
            "        0.0229, 0.0221, 0.0223, 0.0222, 0.0222, 0.0221, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0221, 0.0221, 0.0223, 0.0224, 0.0221, 0.0221, 0.0221, 0.0222, 0.0223,\n",
            "        0.0229, 0.0222, 0.0223, 0.0222, 0.0222, 0.0221, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0221, 0.0221, 0.0223, 0.0224, 0.0221, 0.0221, 0.0221, 0.0222, 0.0223,\n",
            "        0.0226, 0.0221, 0.0223, 0.0222, 0.0222, 0.0221, 0.0222],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0143, 0.0138, 0.0150, 0.0130, 0.0130, 0.0148, 0.0137, 0.0147, 0.0133,\n",
            "        0.0129, 0.0148, 0.0127, 0.0130, 0.0132, 0.0133, 0.0137],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0137, 0.0137, 0.0135, 0.0126, 0.0129, 0.0139, 0.0131, 0.0136, 0.0133,\n",
            "        0.0126, 0.0140, 0.0131, 0.0126, 0.0129, 0.0134, 0.0133],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0137, 0.0146, 0.0142, 0.0131, 0.0133, 0.0138, 0.0138, 0.0141, 0.0137,\n",
            "        0.0130, 0.0147, 0.0131, 0.0132, 0.0135, 0.0141, 0.0146],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0137, 0.0135, 0.0142, 0.0133, 0.0134, 0.0137, 0.0132, 0.0132, 0.0136,\n",
            "        0.0133, 0.0145, 0.0137, 0.0130, 0.0129, 0.0138, 0.0141],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0134, 0.0135, 0.0136, 0.0131, 0.0136, 0.0132, 0.0132, 0.0132, 0.0130,\n",
            "        0.0133, 0.0142, 0.0134, 0.0130, 0.0131, 0.0132, 0.0137],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0134, 0.0135, 0.0137, 0.0132, 0.0137, 0.0133, 0.0133, 0.0133, 0.0131,\n",
            "        0.0132, 0.0136, 0.0133, 0.0132, 0.0132, 0.0133, 0.0136],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0133, 0.0134, 0.0136, 0.0130, 0.0133, 0.0133, 0.0133, 0.0133, 0.0131,\n",
            "        0.0132, 0.0136, 0.0133, 0.0130, 0.0132, 0.0131, 0.0136],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0133, 0.0134, 0.0134, 0.0130, 0.0133, 0.0132, 0.0132, 0.0132, 0.0130,\n",
            "        0.0130, 0.0136, 0.0133, 0.0130, 0.0130, 0.0130, 0.0136],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0132, 0.0132, 0.0132, 0.0130, 0.0133, 0.0132, 0.0132, 0.0132, 0.0130,\n",
            "        0.0132, 0.0136, 0.0133, 0.0130, 0.0130, 0.0130, 0.0134],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0132, 0.0132, 0.0134, 0.0131, 0.0133, 0.0133, 0.0133, 0.0133, 0.0131,\n",
            "        0.0132, 0.0135, 0.0133, 0.0132, 0.0131, 0.0131, 0.0133],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0134, 0.0134, 0.0134, 0.0131, 0.0131, 0.0133, 0.0131, 0.0132, 0.0131,\n",
            "        0.0131, 0.0134, 0.0134, 0.0132, 0.0131, 0.0131, 0.0134],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0133, 0.0134, 0.0132, 0.0130, 0.0131, 0.0131, 0.0131, 0.0132, 0.0131,\n",
            "        0.0130, 0.0134, 0.0134, 0.0130, 0.0130, 0.0131, 0.0134],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0134, 0.0134, 0.0131, 0.0131, 0.0130, 0.0131, 0.0130, 0.0132, 0.0130,\n",
            "        0.0130, 0.0134, 0.0134, 0.0130, 0.0130, 0.0130, 0.0134],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0134, 0.0134, 0.0130, 0.0131, 0.0130, 0.0130, 0.0130, 0.0131, 0.0130,\n",
            "        0.0130, 0.0134, 0.0133, 0.0131, 0.0130, 0.0130, 0.0133],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0134, 0.0133, 0.0131, 0.0131, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
            "        0.0130, 0.0134, 0.0134, 0.0131, 0.0130, 0.0131, 0.0133],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0133, 0.0132, 0.0131, 0.0131, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
            "        0.0130, 0.0134, 0.0132, 0.0131, 0.0130, 0.0131, 0.0132],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0132, 0.0132, 0.0131, 0.0131, 0.0131, 0.0130, 0.0130, 0.0130, 0.0130,\n",
            "        0.0130, 0.0132, 0.0132, 0.0131, 0.0130, 0.0131, 0.0132],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0132, 0.0132, 0.0131, 0.0131, 0.0131, 0.0131, 0.0130, 0.0130, 0.0131,\n",
            "        0.0130, 0.0132, 0.0132, 0.0131, 0.0130, 0.0131, 0.0132],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0132, 0.0132, 0.0131, 0.0130, 0.0131, 0.0131, 0.0130, 0.0130, 0.0131,\n",
            "        0.0130, 0.0132, 0.0132, 0.0131, 0.0130, 0.0130, 0.0132],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0133, 0.0133, 0.0130, 0.0130, 0.0131, 0.0131, 0.0130, 0.0130, 0.0131,\n",
            "        0.0130, 0.0134, 0.0133, 0.0131, 0.0130, 0.0130, 0.0133],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0131, 0.0127, 0.0124, 0.0143, 0.0140, 0.0140, 0.0125, 0.0134, 0.0125,\n",
            "        0.0128, 0.0126, 0.0132, 0.0138, 0.0123, 0.0130, 0.0134],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0135, 0.0135, 0.0124, 0.0138, 0.0131, 0.0143, 0.0130, 0.0134, 0.0131,\n",
            "        0.0132, 0.0127, 0.0131, 0.0131, 0.0123, 0.0134, 0.0137],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0139, 0.0144, 0.0125, 0.0143, 0.0140, 0.0133, 0.0132, 0.0134, 0.0130,\n",
            "        0.0136, 0.0130, 0.0140, 0.0136, 0.0130, 0.0144, 0.0132],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0129, 0.0138, 0.0128, 0.0145, 0.0141, 0.0136, 0.0133, 0.0133, 0.0129,\n",
            "        0.0139, 0.0129, 0.0137, 0.0136, 0.0129, 0.0143, 0.0136],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0130, 0.0132, 0.0128, 0.0144, 0.0141, 0.0136, 0.0134, 0.0135, 0.0129,\n",
            "        0.0135, 0.0130, 0.0136, 0.0136, 0.0133, 0.0131, 0.0133],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0130, 0.0132, 0.0128, 0.0134, 0.0134, 0.0136, 0.0130, 0.0134, 0.0129,\n",
            "        0.0132, 0.0130, 0.0130, 0.0132, 0.0128, 0.0133, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0130, 0.0130, 0.0128, 0.0132, 0.0133, 0.0134, 0.0130, 0.0130, 0.0129,\n",
            "        0.0132, 0.0129, 0.0130, 0.0130, 0.0128, 0.0129, 0.0129],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0130, 0.0128, 0.0128, 0.0133, 0.0132, 0.0130, 0.0130, 0.0129, 0.0128,\n",
            "        0.0130, 0.0129, 0.0130, 0.0129, 0.0128, 0.0129, 0.0129],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0129, 0.0130, 0.0128, 0.0131, 0.0131, 0.0129, 0.0130, 0.0129, 0.0128,\n",
            "        0.0130, 0.0128, 0.0129, 0.0129, 0.0128, 0.0128, 0.0129],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0128, 0.0130, 0.0128, 0.0131, 0.0132, 0.0130, 0.0130, 0.0129, 0.0128,\n",
            "        0.0130, 0.0128, 0.0130, 0.0130, 0.0128, 0.0130, 0.0131],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0128, 0.0130, 0.0127, 0.0131, 0.0131, 0.0130, 0.0128, 0.0129, 0.0127,\n",
            "        0.0128, 0.0127, 0.0128, 0.0130, 0.0127, 0.0130, 0.0131],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0127, 0.0130, 0.0127, 0.0131, 0.0131, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0131],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0127, 0.0130, 0.0127, 0.0131, 0.0131, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0131],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0127, 0.0130, 0.0127, 0.0131, 0.0131, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0127, 0.0130, 0.0127, 0.0131, 0.0130, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0127, 0.0130, 0.0127, 0.0131, 0.0130, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0127, 0.0130, 0.0127, 0.0130, 0.0130, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0127, 0.0130, 0.0127, 0.0130, 0.0130, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0127, 0.0130, 0.0127, 0.0130, 0.0130, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0127, 0.0130, 0.0128, 0.0130, 0.0130, 0.0130, 0.0127, 0.0127, 0.0127,\n",
            "        0.0127, 0.0127, 0.0127, 0.0130, 0.0127, 0.0130, 0.0130],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0206, 0.0193, 0.0190, 0.0193, 0.0184, 0.0199, 0.0201, 0.0196, 0.0194,\n",
            "        0.0200, 0.0204, 0.0188, 0.0210, 0.0204, 0.0195, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0212, 0.0189, 0.0195, 0.0196, 0.0182, 0.0188, 0.0193, 0.0190, 0.0181,\n",
            "        0.0190, 0.0186, 0.0187, 0.0199, 0.0193, 0.0198, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0200, 0.0196, 0.0190, 0.0197, 0.0187, 0.0193, 0.0196, 0.0185, 0.0184,\n",
            "        0.0190, 0.0188, 0.0190, 0.0195, 0.0187, 0.0202, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0197, 0.0191, 0.0189, 0.0203, 0.0189, 0.0194, 0.0190, 0.0184, 0.0186,\n",
            "        0.0192, 0.0193, 0.0184, 0.0193, 0.0190, 0.0192, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0197, 0.0186, 0.0189, 0.0196, 0.0186, 0.0195, 0.0188, 0.0186, 0.0185,\n",
            "        0.0192, 0.0191, 0.0187, 0.0194, 0.0187, 0.0194, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0191, 0.0186, 0.0190, 0.0191, 0.0186, 0.0199, 0.0188, 0.0188, 0.0186,\n",
            "        0.0189, 0.0193, 0.0189, 0.0186, 0.0189, 0.0191, 0.0192],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0190, 0.0186, 0.0189, 0.0188, 0.0186, 0.0192, 0.0188, 0.0188, 0.0186,\n",
            "        0.0189, 0.0189, 0.0186, 0.0186, 0.0189, 0.0189, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0189, 0.0186, 0.0190, 0.0188, 0.0186, 0.0190, 0.0188, 0.0188, 0.0186,\n",
            "        0.0189, 0.0189, 0.0186, 0.0186, 0.0189, 0.0189, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0189, 0.0186, 0.0187, 0.0188, 0.0186, 0.0190, 0.0187, 0.0188, 0.0186,\n",
            "        0.0189, 0.0189, 0.0186, 0.0186, 0.0189, 0.0186, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0186, 0.0185, 0.0187, 0.0188, 0.0184, 0.0188, 0.0188, 0.0186, 0.0184,\n",
            "        0.0189, 0.0186, 0.0185, 0.0186, 0.0187, 0.0186, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0186, 0.0185, 0.0187, 0.0186, 0.0184, 0.0188, 0.0185, 0.0186, 0.0185,\n",
            "        0.0189, 0.0186, 0.0185, 0.0184, 0.0187, 0.0186, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0186, 0.0184, 0.0185, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185,\n",
            "        0.0184, 0.0185, 0.0185, 0.0185, 0.0187, 0.0184, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0185, 0.0184, 0.0185, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185,\n",
            "        0.0184, 0.0185, 0.0185, 0.0185, 0.0185, 0.0185, 0.0186],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0185, 0.0184, 0.0185, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185,\n",
            "        0.0184, 0.0185, 0.0185, 0.0185, 0.0186, 0.0184, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0185, 0.0184, 0.0186, 0.0184, 0.0184, 0.0185, 0.0185, 0.0185, 0.0185,\n",
            "        0.0184, 0.0185, 0.0184, 0.0185, 0.0186, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0185, 0.0184, 0.0186, 0.0184, 0.0184, 0.0186, 0.0185, 0.0185, 0.0185,\n",
            "        0.0184, 0.0185, 0.0184, 0.0185, 0.0186, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0187, 0.0185, 0.0185, 0.0184, 0.0184, 0.0187, 0.0185, 0.0187, 0.0185,\n",
            "        0.0184, 0.0187, 0.0184, 0.0185, 0.0188, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0187, 0.0185, 0.0185, 0.0184, 0.0184, 0.0187, 0.0185, 0.0187, 0.0185,\n",
            "        0.0184, 0.0187, 0.0184, 0.0185, 0.0188, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0185, 0.0185, 0.0187, 0.0184, 0.0184, 0.0185, 0.0184, 0.0185, 0.0184,\n",
            "        0.0184, 0.0185, 0.0184, 0.0185, 0.0186, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0185, 0.0185, 0.0187, 0.0185, 0.0184, 0.0185, 0.0184, 0.0185, 0.0184,\n",
            "        0.0184, 0.0185, 0.0184, 0.0185, 0.0186, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0278, 0.0282, 0.0296, 0.0282, 0.0292, 0.0280, 0.0297, 0.0285, 0.0280,\n",
            "        0.0285, 0.0282, 0.0296, 0.0297, 0.0279, 0.0289, 0.0290],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0274, 0.0278, 0.0301, 0.0279, 0.0289, 0.0278, 0.0285, 0.0289, 0.0285,\n",
            "        0.0281, 0.0286, 0.0290, 0.0285, 0.0278, 0.0289, 0.0294],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0275, 0.0287, 0.0290, 0.0287, 0.0293, 0.0284, 0.0290, 0.0293, 0.0295,\n",
            "        0.0288, 0.0278, 0.0285, 0.0284, 0.0278, 0.0283, 0.0291],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0284, 0.0287, 0.0289, 0.0292, 0.0301, 0.0278, 0.0296, 0.0284, 0.0307,\n",
            "        0.0288, 0.0285, 0.0282, 0.0292, 0.0284, 0.0288, 0.0286],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0287, 0.0285, 0.0292, 0.0285, 0.0294, 0.0281, 0.0294, 0.0286, 0.0296,\n",
            "        0.0291, 0.0288, 0.0285, 0.0292, 0.0286, 0.0294, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0283, 0.0286, 0.0292, 0.0285, 0.0294, 0.0282, 0.0289, 0.0286, 0.0289,\n",
            "        0.0285, 0.0285, 0.0283, 0.0289, 0.0286, 0.0289, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0283, 0.0280, 0.0279, 0.0285, 0.0282, 0.0277, 0.0289, 0.0283, 0.0282,\n",
            "        0.0285, 0.0285, 0.0283, 0.0282, 0.0284, 0.0289, 0.0283],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0277, 0.0280, 0.0279, 0.0281, 0.0282, 0.0279, 0.0285, 0.0279, 0.0279,\n",
            "        0.0281, 0.0279, 0.0277, 0.0282, 0.0278, 0.0285, 0.0279],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0277, 0.0280, 0.0279, 0.0279, 0.0282, 0.0278, 0.0279, 0.0277, 0.0278,\n",
            "        0.0279, 0.0279, 0.0277, 0.0280, 0.0278, 0.0285, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0277, 0.0280, 0.0279, 0.0279, 0.0280, 0.0278, 0.0279, 0.0277, 0.0278,\n",
            "        0.0279, 0.0279, 0.0277, 0.0280, 0.0278, 0.0285, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0277, 0.0279, 0.0280, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278,\n",
            "        0.0279, 0.0277, 0.0277, 0.0280, 0.0277, 0.0285, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0277, 0.0279, 0.0280, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278,\n",
            "        0.0277, 0.0277, 0.0277, 0.0280, 0.0277, 0.0289, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0281, 0.0278, 0.0280, 0.0280, 0.0279, 0.0278, 0.0281, 0.0280, 0.0278,\n",
            "        0.0281, 0.0281, 0.0280, 0.0280, 0.0281, 0.0287, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0281, 0.0283, 0.0283, 0.0280, 0.0283, 0.0283, 0.0281, 0.0281, 0.0283,\n",
            "        0.0281, 0.0281, 0.0280, 0.0284, 0.0281, 0.0287, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0280, 0.0283, 0.0283, 0.0281, 0.0283, 0.0283, 0.0281, 0.0281, 0.0283,\n",
            "        0.0281, 0.0281, 0.0281, 0.0283, 0.0281, 0.0287, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0280, 0.0278, 0.0278, 0.0281, 0.0279, 0.0279, 0.0281, 0.0281, 0.0278,\n",
            "        0.0281, 0.0281, 0.0281, 0.0278, 0.0281, 0.0287, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0277, 0.0279, 0.0278, 0.0277, 0.0279, 0.0279, 0.0277, 0.0277, 0.0278,\n",
            "        0.0277, 0.0277, 0.0277, 0.0278, 0.0277, 0.0287, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0277, 0.0279, 0.0278, 0.0277, 0.0279, 0.0279, 0.0277, 0.0277, 0.0278,\n",
            "        0.0277, 0.0277, 0.0277, 0.0278, 0.0277, 0.0287, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0277, 0.0279, 0.0278, 0.0277, 0.0279, 0.0279, 0.0277, 0.0277, 0.0278,\n",
            "        0.0277, 0.0277, 0.0277, 0.0278, 0.0277, 0.0287, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0277, 0.0279, 0.0278, 0.0277, 0.0279, 0.0279, 0.0277, 0.0277, 0.0278,\n",
            "        0.0277, 0.0277, 0.0277, 0.0278, 0.0277, 0.0288, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0165, 0.0149, 0.0165, 0.0158, 0.0175, 0.0156, 0.0149, 0.0161, 0.0164,\n",
            "        0.0162, 0.0158, 0.0153, 0.0161, 0.0163, 0.0153, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0164, 0.0150, 0.0169, 0.0164, 0.0160, 0.0154, 0.0153, 0.0164, 0.0157,\n",
            "        0.0157, 0.0159, 0.0154, 0.0163, 0.0161, 0.0158, 0.0170],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0166, 0.0155, 0.0162, 0.0167, 0.0157, 0.0159, 0.0162, 0.0169, 0.0164,\n",
            "        0.0164, 0.0161, 0.0158, 0.0169, 0.0165, 0.0164, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0158, 0.0159, 0.0162, 0.0164, 0.0162, 0.0158, 0.0157, 0.0162, 0.0167,\n",
            "        0.0167, 0.0160, 0.0161, 0.0169, 0.0165, 0.0158, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0158, 0.0165, 0.0162, 0.0165, 0.0162, 0.0158, 0.0158, 0.0163, 0.0163,\n",
            "        0.0170, 0.0158, 0.0159, 0.0161, 0.0164, 0.0157, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0158, 0.0164, 0.0159, 0.0161, 0.0160, 0.0158, 0.0158, 0.0159, 0.0163,\n",
            "        0.0163, 0.0158, 0.0161, 0.0158, 0.0160, 0.0157, 0.0161],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0158, 0.0161, 0.0159, 0.0161, 0.0158, 0.0158, 0.0158, 0.0159, 0.0160,\n",
            "        0.0163, 0.0158, 0.0161, 0.0158, 0.0158, 0.0157, 0.0159],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0158, 0.0158, 0.0159, 0.0161, 0.0158, 0.0159, 0.0157, 0.0159, 0.0160,\n",
            "        0.0163, 0.0160, 0.0158, 0.0158, 0.0158, 0.0159, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0157, 0.0157, 0.0159, 0.0161, 0.0158, 0.0158, 0.0157, 0.0159, 0.0160,\n",
            "        0.0160, 0.0160, 0.0157, 0.0158, 0.0160, 0.0157, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0157, 0.0157, 0.0159, 0.0158, 0.0158, 0.0158, 0.0157, 0.0157, 0.0158,\n",
            "        0.0160, 0.0157, 0.0157, 0.0158, 0.0158, 0.0157, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0157, 0.0155, 0.0157, 0.0158, 0.0157, 0.0157, 0.0155, 0.0157, 0.0157,\n",
            "        0.0160, 0.0157, 0.0155, 0.0157, 0.0158, 0.0157, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0157, 0.0155, 0.0157, 0.0157, 0.0157, 0.0157, 0.0155, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0155, 0.0157, 0.0157, 0.0157, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0155, 0.0157, 0.0157, 0.0157, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0212, 0.0218, 0.0199, 0.0202, 0.0206, 0.0208, 0.0209, 0.0213, 0.0207,\n",
            "        0.0198, 0.0212, 0.0218, 0.0201, 0.0204, 0.0208, 0.0214],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0208, 0.0219, 0.0206, 0.0213, 0.0214, 0.0211, 0.0212, 0.0218, 0.0208,\n",
            "        0.0202, 0.0222, 0.0215, 0.0212, 0.0214, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0209, 0.0212, 0.0206, 0.0215, 0.0215, 0.0209, 0.0213, 0.0219, 0.0208,\n",
            "        0.0202, 0.0210, 0.0224, 0.0209, 0.0207, 0.0212, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0209, 0.0214, 0.0212, 0.0211, 0.0216, 0.0217, 0.0213, 0.0215, 0.0209,\n",
            "        0.0208, 0.0210, 0.0211, 0.0204, 0.0208, 0.0209, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0210, 0.0215, 0.0208, 0.0208, 0.0210, 0.0216, 0.0214, 0.0209, 0.0208,\n",
            "        0.0212, 0.0211, 0.0211, 0.0206, 0.0206, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0208, 0.0206, 0.0208, 0.0208, 0.0211, 0.0212, 0.0208, 0.0211, 0.0208,\n",
            "        0.0208, 0.0211, 0.0211, 0.0206, 0.0206, 0.0206, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0211, 0.0211, 0.0208, 0.0211, 0.0212, 0.0212, 0.0211, 0.0209, 0.0211,\n",
            "        0.0211, 0.0212, 0.0209, 0.0206, 0.0210, 0.0209, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0211, 0.0211, 0.0211, 0.0211, 0.0210, 0.0212, 0.0211, 0.0209, 0.0211,\n",
            "        0.0210, 0.0212, 0.0209, 0.0206, 0.0210, 0.0209, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0208, 0.0208, 0.0206, 0.0208, 0.0207, 0.0211, 0.0208, 0.0209, 0.0208,\n",
            "        0.0206, 0.0209, 0.0209, 0.0206, 0.0206, 0.0206, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0208, 0.0208, 0.0205, 0.0206, 0.0207, 0.0208, 0.0208, 0.0208, 0.0206,\n",
            "        0.0205, 0.0206, 0.0209, 0.0205, 0.0205, 0.0205, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0209, 0.0205, 0.0205, 0.0205, 0.0207],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0209, 0.0205, 0.0205, 0.0205, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0209, 0.0205, 0.0205, 0.0205, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0209, 0.0205, 0.0205, 0.0205, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0209, 0.0205, 0.0205, 0.0205, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0209, 0.0205, 0.0205, 0.0205, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0205, 0.0205, 0.0205, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0205, 0.0205, 0.0208, 0.0205, 0.0205, 0.0208, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208,\n",
            "        0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0205, 0.0208, 0.0205, 0.0205, 0.0205, 0.0208, 0.0208, 0.0208, 0.0208,\n",
            "        0.0205, 0.0208, 0.0208, 0.0205, 0.0208, 0.0205, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0205, 0.0205, 0.0206, 0.0205, 0.0205, 0.0208, 0.0205, 0.0208, 0.0205,\n",
            "        0.0206, 0.0205, 0.0208, 0.0205, 0.0205, 0.0205, 0.0205],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0169, 0.0164, 0.0163, 0.0178, 0.0171, 0.0178, 0.0173, 0.0175, 0.0173,\n",
            "        0.0169, 0.0189, 0.0167, 0.0170, 0.0173, 0.0172, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0168, 0.0169, 0.0163, 0.0184, 0.0181, 0.0175, 0.0169, 0.0185, 0.0179,\n",
            "        0.0176, 0.0179, 0.0168, 0.0177, 0.0179, 0.0174, 0.0176],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0171, 0.0168, 0.0167, 0.0177, 0.0174, 0.0173, 0.0170, 0.0184, 0.0172,\n",
            "        0.0171, 0.0177, 0.0170, 0.0173, 0.0174, 0.0169, 0.0169],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0171, 0.0167, 0.0167, 0.0175, 0.0173, 0.0177, 0.0170, 0.0183, 0.0169,\n",
            "        0.0167, 0.0180, 0.0167, 0.0171, 0.0170, 0.0174, 0.0168],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0171, 0.0167, 0.0169, 0.0170, 0.0172, 0.0171, 0.0170, 0.0182, 0.0174,\n",
            "        0.0170, 0.0178, 0.0169, 0.0167, 0.0170, 0.0175, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0168, 0.0167, 0.0168, 0.0170, 0.0167, 0.0171, 0.0168, 0.0177, 0.0172,\n",
            "        0.0172, 0.0175, 0.0168, 0.0167, 0.0167, 0.0166, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0168, 0.0166, 0.0167, 0.0170, 0.0167, 0.0168, 0.0167, 0.0171, 0.0168,\n",
            "        0.0174, 0.0171, 0.0167, 0.0167, 0.0167, 0.0166, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0168, 0.0166, 0.0167, 0.0168, 0.0167, 0.0167, 0.0167, 0.0169, 0.0168,\n",
            "        0.0172, 0.0171, 0.0167, 0.0167, 0.0167, 0.0166, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0169, 0.0167, 0.0167, 0.0167, 0.0170, 0.0170, 0.0167, 0.0170, 0.0168,\n",
            "        0.0171, 0.0170, 0.0167, 0.0167, 0.0168, 0.0167, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0169, 0.0167, 0.0169, 0.0170, 0.0168, 0.0167, 0.0169, 0.0170, 0.0170,\n",
            "        0.0171, 0.0170, 0.0169, 0.0167, 0.0167, 0.0167, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0167, 0.0166, 0.0169, 0.0170, 0.0167, 0.0167, 0.0169, 0.0169, 0.0170,\n",
            "        0.0171, 0.0169, 0.0169, 0.0167, 0.0167, 0.0167, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0167, 0.0166, 0.0170, 0.0170, 0.0167, 0.0166, 0.0169, 0.0169, 0.0170,\n",
            "        0.0171, 0.0169, 0.0169, 0.0167, 0.0166, 0.0167, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0167, 0.0167, 0.0170, 0.0170, 0.0167, 0.0166, 0.0169, 0.0169, 0.0169,\n",
            "        0.0171, 0.0169, 0.0169, 0.0167, 0.0166, 0.0167, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0164, 0.0164, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167,\n",
            "        0.0171, 0.0167, 0.0167, 0.0164, 0.0164, 0.0167, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0165, 0.0164, 0.0167, 0.0167, 0.0164, 0.0164, 0.0167, 0.0167, 0.0167,\n",
            "        0.0169, 0.0165, 0.0167, 0.0164, 0.0164, 0.0164, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0165, 0.0164, 0.0167, 0.0167, 0.0165, 0.0164, 0.0167, 0.0167, 0.0167,\n",
            "        0.0169, 0.0164, 0.0167, 0.0165, 0.0164, 0.0164, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0164, 0.0165, 0.0167, 0.0167, 0.0165, 0.0164, 0.0167, 0.0167, 0.0167,\n",
            "        0.0169, 0.0164, 0.0167, 0.0164, 0.0164, 0.0164, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0164, 0.0165, 0.0167, 0.0167, 0.0165, 0.0165, 0.0167, 0.0167, 0.0167,\n",
            "        0.0169, 0.0164, 0.0167, 0.0164, 0.0164, 0.0164, 0.0165],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167,\n",
            "        0.0171, 0.0166, 0.0167, 0.0167, 0.0167, 0.0164, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167,\n",
            "        0.0171, 0.0166, 0.0167, 0.0167, 0.0167, 0.0167, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0211, 0.0212, 0.0209, 0.0225, 0.0205, 0.0217, 0.0221, 0.0222, 0.0216,\n",
            "        0.0230, 0.0201, 0.0224, 0.0214, 0.0219, 0.0200, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0209, 0.0217, 0.0209, 0.0220, 0.0204, 0.0213, 0.0214, 0.0221, 0.0212,\n",
            "        0.0229, 0.0211, 0.0212, 0.0214, 0.0217, 0.0207, 0.0219],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0215, 0.0215, 0.0211, 0.0214, 0.0210, 0.0224, 0.0222, 0.0213, 0.0212,\n",
            "        0.0224, 0.0208, 0.0212, 0.0217, 0.0222, 0.0208, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0219, 0.0220, 0.0216, 0.0209, 0.0218, 0.0221, 0.0214, 0.0214, 0.0208,\n",
            "        0.0228, 0.0217, 0.0211, 0.0211, 0.0225, 0.0212, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0224, 0.0220, 0.0212, 0.0211, 0.0215, 0.0217, 0.0213, 0.0216, 0.0210,\n",
            "        0.0213, 0.0220, 0.0211, 0.0214, 0.0218, 0.0211, 0.0214],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0211, 0.0222, 0.0212, 0.0211, 0.0212, 0.0215, 0.0213, 0.0216, 0.0210,\n",
            "        0.0215, 0.0222, 0.0210, 0.0210, 0.0214, 0.0211, 0.0216],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0214, 0.0215, 0.0215, 0.0214, 0.0212, 0.0215, 0.0212, 0.0214, 0.0212,\n",
            "        0.0215, 0.0215, 0.0210, 0.0213, 0.0216, 0.0211, 0.0214],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0214, 0.0213, 0.0215, 0.0214, 0.0212, 0.0213, 0.0212, 0.0214, 0.0212,\n",
            "        0.0215, 0.0216, 0.0213, 0.0213, 0.0214, 0.0211, 0.0212],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0214, 0.0213, 0.0213, 0.0214, 0.0212, 0.0214, 0.0209, 0.0214, 0.0212,\n",
            "        0.0213, 0.0211, 0.0213, 0.0213, 0.0214, 0.0211, 0.0212],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0209, 0.0213, 0.0208, 0.0209, 0.0212, 0.0214, 0.0208, 0.0211, 0.0208,\n",
            "        0.0213, 0.0211, 0.0208, 0.0208, 0.0212, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0207, 0.0213, 0.0208, 0.0207, 0.0211, 0.0211, 0.0208, 0.0207, 0.0208,\n",
            "        0.0213, 0.0211, 0.0208, 0.0208, 0.0212, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0207, 0.0213, 0.0208, 0.0208, 0.0211, 0.0211, 0.0208, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0208, 0.0212, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0207, 0.0213, 0.0208, 0.0208, 0.0211, 0.0211, 0.0208, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0208, 0.0212, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0207, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0207, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0208, 0.0212, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0207, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0207, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0207, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0207, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0208, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0208, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0208, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0208, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0207, 0.0211, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0208, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0208, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0207, 0.0211, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0208, 0.0211, 0.0208, 0.0208, 0.0211, 0.0211, 0.0208, 0.0208, 0.0208,\n",
            "        0.0211, 0.0211, 0.0208, 0.0207, 0.0211, 0.0211, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0240, 0.0257, 0.0235, 0.0252, 0.0258, 0.0240, 0.0246, 0.0237, 0.0242,\n",
            "        0.0242, 0.0238, 0.0244, 0.0254, 0.0247, 0.0261, 0.0234],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0248, 0.0250, 0.0242, 0.0244, 0.0244, 0.0245, 0.0246, 0.0243, 0.0251,\n",
            "        0.0244, 0.0243, 0.0244, 0.0249, 0.0253, 0.0251, 0.0240],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0240, 0.0264, 0.0242, 0.0244, 0.0255, 0.0243, 0.0254, 0.0242, 0.0254,\n",
            "        0.0245, 0.0251, 0.0245, 0.0256, 0.0256, 0.0249, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0237, 0.0246, 0.0241, 0.0241, 0.0253, 0.0239, 0.0252, 0.0241, 0.0251,\n",
            "        0.0242, 0.0242, 0.0240, 0.0244, 0.0245, 0.0252, 0.0237],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0239, 0.0245, 0.0243, 0.0241, 0.0243, 0.0241, 0.0240, 0.0244, 0.0246,\n",
            "        0.0237, 0.0239, 0.0237, 0.0238, 0.0238, 0.0253, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0239, 0.0240, 0.0240, 0.0240, 0.0245, 0.0241, 0.0242, 0.0239, 0.0239,\n",
            "        0.0237, 0.0239, 0.0237, 0.0240, 0.0240, 0.0246, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0239, 0.0240, 0.0240, 0.0240, 0.0242, 0.0240, 0.0242, 0.0239, 0.0239,\n",
            "        0.0237, 0.0239, 0.0237, 0.0238, 0.0238, 0.0240, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0239, 0.0238, 0.0237, 0.0238, 0.0240, 0.0240, 0.0240, 0.0239, 0.0239,\n",
            "        0.0237, 0.0237, 0.0237, 0.0238, 0.0238, 0.0240, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0243, 0.0238, 0.0240, 0.0238, 0.0240, 0.0239, 0.0238, 0.0242, 0.0240,\n",
            "        0.0238, 0.0240, 0.0238, 0.0237, 0.0237, 0.0243, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0239, 0.0242, 0.0239, 0.0242, 0.0244, 0.0239, 0.0241, 0.0238, 0.0238,\n",
            "        0.0238, 0.0238, 0.0238, 0.0241, 0.0241, 0.0243, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0238, 0.0241, 0.0239, 0.0241, 0.0244, 0.0239, 0.0241, 0.0238, 0.0238,\n",
            "        0.0238, 0.0238, 0.0238, 0.0241, 0.0241, 0.0241, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0238, 0.0241, 0.0238, 0.0241, 0.0241, 0.0239, 0.0241, 0.0238, 0.0238,\n",
            "        0.0238, 0.0238, 0.0238, 0.0241, 0.0241, 0.0239, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0238, 0.0241, 0.0238, 0.0241, 0.0241, 0.0238, 0.0241, 0.0238, 0.0238,\n",
            "        0.0238, 0.0238, 0.0238, 0.0241, 0.0241, 0.0238, 0.0238],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0235, 0.0237, 0.0235, 0.0237, 0.0237, 0.0235, 0.0237, 0.0235, 0.0235,\n",
            "        0.0235, 0.0235, 0.0236, 0.0237, 0.0237, 0.0235, 0.0235],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0235, 0.0237, 0.0235, 0.0237, 0.0237, 0.0235, 0.0237, 0.0235, 0.0235,\n",
            "        0.0235, 0.0235, 0.0236, 0.0237, 0.0237, 0.0235, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0235, 0.0237, 0.0235, 0.0237, 0.0237, 0.0235, 0.0237, 0.0235, 0.0235,\n",
            "        0.0236, 0.0235, 0.0235, 0.0237, 0.0237, 0.0235, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0235, 0.0237, 0.0235, 0.0237, 0.0237, 0.0235, 0.0237, 0.0235, 0.0235,\n",
            "        0.0236, 0.0235, 0.0235, 0.0237, 0.0237, 0.0236, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0235, 0.0237, 0.0235, 0.0237, 0.0237, 0.0235, 0.0237, 0.0235, 0.0236,\n",
            "        0.0235, 0.0235, 0.0235, 0.0238, 0.0238, 0.0235, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0235, 0.0237, 0.0235, 0.0237, 0.0237, 0.0235, 0.0237, 0.0235, 0.0236,\n",
            "        0.0235, 0.0235, 0.0235, 0.0238, 0.0238, 0.0235, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0238, 0.0237, 0.0238, 0.0237, 0.0237, 0.0238, 0.0237, 0.0238, 0.0239,\n",
            "        0.0238, 0.0238, 0.0238, 0.0238, 0.0238, 0.0238, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0201, 0.0211, 0.0216, 0.0206, 0.0186, 0.0191, 0.0214, 0.0194, 0.0195,\n",
            "        0.0190, 0.0202, 0.0193, 0.0192, 0.0191, 0.0196, 0.0194],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0196, 0.0197, 0.0203, 0.0196, 0.0188, 0.0190, 0.0211, 0.0194, 0.0194,\n",
            "        0.0188, 0.0194, 0.0190, 0.0195, 0.0186, 0.0189, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0205, 0.0206, 0.0213, 0.0190, 0.0189, 0.0197, 0.0211, 0.0197, 0.0193,\n",
            "        0.0188, 0.0193, 0.0189, 0.0192, 0.0189, 0.0191, 0.0186],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0203, 0.0210, 0.0216, 0.0192, 0.0197, 0.0204, 0.0210, 0.0200, 0.0198,\n",
            "        0.0187, 0.0191, 0.0189, 0.0194, 0.0189, 0.0193, 0.0192],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0197, 0.0202, 0.0203, 0.0195, 0.0193, 0.0199, 0.0202, 0.0194, 0.0199,\n",
            "        0.0189, 0.0190, 0.0191, 0.0190, 0.0198, 0.0195, 0.0195],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0196, 0.0196, 0.0197, 0.0190, 0.0193, 0.0199, 0.0196, 0.0194, 0.0191,\n",
            "        0.0190, 0.0190, 0.0193, 0.0189, 0.0194, 0.0191, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0195, 0.0196, 0.0197, 0.0190, 0.0191, 0.0195, 0.0196, 0.0194, 0.0191,\n",
            "        0.0189, 0.0188, 0.0194, 0.0191, 0.0191, 0.0191, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0195, 0.0195, 0.0195, 0.0189, 0.0189, 0.0194, 0.0195, 0.0194, 0.0191,\n",
            "        0.0189, 0.0187, 0.0194, 0.0189, 0.0189, 0.0191, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0195, 0.0195, 0.0195, 0.0189, 0.0189, 0.0193, 0.0195, 0.0194, 0.0194,\n",
            "        0.0192, 0.0187, 0.0189, 0.0192, 0.0189, 0.0193, 0.0194],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0195, 0.0195, 0.0195, 0.0189, 0.0188, 0.0193, 0.0195, 0.0192, 0.0192,\n",
            "        0.0191, 0.0187, 0.0189, 0.0191, 0.0189, 0.0193, 0.0194],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0193, 0.0195, 0.0195, 0.0188, 0.0188, 0.0193, 0.0195, 0.0192, 0.0192,\n",
            "        0.0191, 0.0187, 0.0188, 0.0191, 0.0188, 0.0194, 0.0192],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0188, 0.0193, 0.0193, 0.0189, 0.0189,\n",
            "        0.0188, 0.0187, 0.0188, 0.0189, 0.0188, 0.0189, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0188, 0.0193, 0.0193, 0.0189, 0.0189,\n",
            "        0.0188, 0.0186, 0.0188, 0.0189, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0191, 0.0193, 0.0193, 0.0188, 0.0189,\n",
            "        0.0189, 0.0186, 0.0188, 0.0189, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0188, 0.0193, 0.0193, 0.0188, 0.0189,\n",
            "        0.0189, 0.0186, 0.0188, 0.0189, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0188, 0.0193, 0.0193, 0.0188, 0.0189,\n",
            "        0.0189, 0.0186, 0.0188, 0.0189, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0189, 0.0193, 0.0193, 0.0188, 0.0189,\n",
            "        0.0189, 0.0186, 0.0188, 0.0188, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0189, 0.0193, 0.0193, 0.0188, 0.0189,\n",
            "        0.0189, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0189, 0.0193, 0.0193, 0.0188, 0.0188,\n",
            "        0.0189, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0193, 0.0193, 0.0193, 0.0188, 0.0189, 0.0193, 0.0193, 0.0188, 0.0188,\n",
            "        0.0189, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0188],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0208, 0.0203, 0.0206, 0.0215, 0.0206, 0.0207, 0.0219, 0.0209, 0.0223,\n",
            "        0.0215, 0.0222, 0.0203, 0.0206, 0.0211, 0.0207, 0.0212],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0214, 0.0206, 0.0205, 0.0208, 0.0206, 0.0210, 0.0227, 0.0207, 0.0224,\n",
            "        0.0213, 0.0215, 0.0200, 0.0203, 0.0204, 0.0204, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0219, 0.0206, 0.0209, 0.0215, 0.0208, 0.0212, 0.0217, 0.0207, 0.0209,\n",
            "        0.0211, 0.0215, 0.0205, 0.0205, 0.0208, 0.0209, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0222, 0.0210, 0.0206, 0.0216, 0.0213, 0.0213, 0.0217, 0.0207, 0.0218,\n",
            "        0.0215, 0.0217, 0.0208, 0.0208, 0.0212, 0.0213, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0222, 0.0210, 0.0208, 0.0217, 0.0213, 0.0210, 0.0211, 0.0209, 0.0213,\n",
            "        0.0211, 0.0218, 0.0211, 0.0210, 0.0208, 0.0210, 0.0216],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0216, 0.0210, 0.0207, 0.0212, 0.0209, 0.0210, 0.0211, 0.0208, 0.0213,\n",
            "        0.0208, 0.0218, 0.0213, 0.0213, 0.0209, 0.0208, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0212, 0.0210, 0.0207, 0.0213, 0.0209, 0.0208, 0.0211, 0.0208, 0.0213,\n",
            "        0.0208, 0.0213, 0.0213, 0.0215, 0.0209, 0.0208, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0211, 0.0210, 0.0207, 0.0213, 0.0208, 0.0208, 0.0211, 0.0208, 0.0212,\n",
            "        0.0208, 0.0212, 0.0213, 0.0211, 0.0209, 0.0208, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0211, 0.0210, 0.0207, 0.0213, 0.0208, 0.0208, 0.0211, 0.0208, 0.0212,\n",
            "        0.0208, 0.0212, 0.0213, 0.0211, 0.0208, 0.0208, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0211, 0.0210, 0.0207, 0.0213, 0.0208, 0.0208, 0.0211, 0.0208, 0.0212,\n",
            "        0.0208, 0.0212, 0.0213, 0.0211, 0.0208, 0.0208, 0.0211],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0211, 0.0210, 0.0207, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0212,\n",
            "        0.0208, 0.0212, 0.0213, 0.0211, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0208, 0.0208, 0.0207, 0.0213, 0.0208, 0.0208, 0.0208, 0.0208, 0.0209,\n",
            "        0.0208, 0.0210, 0.0213, 0.0211, 0.0208, 0.0208, 0.0208],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0210, 0.0210, 0.0207, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0210, 0.0213, 0.0211, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0210, 0.0210, 0.0207, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0210, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0211, 0.0211, 0.0208, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0210, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0211, 0.0211, 0.0208, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0210, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0210, 0.0210, 0.0208, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0211, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0210, 0.0210, 0.0208, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0211, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0210, 0.0210, 0.0208, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0211, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0210, 0.0210, 0.0208, 0.0213, 0.0208, 0.0208, 0.0210, 0.0208, 0.0210,\n",
            "        0.0208, 0.0210, 0.0213, 0.0210, 0.0208, 0.0208, 0.0210],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0169, 0.0162, 0.0173, 0.0156, 0.0163, 0.0169, 0.0168, 0.0166, 0.0171,\n",
            "        0.0173, 0.0188, 0.0173, 0.0170, 0.0172, 0.0173, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0168, 0.0156, 0.0164, 0.0153, 0.0158, 0.0168, 0.0166, 0.0165, 0.0166,\n",
            "        0.0163, 0.0180, 0.0176, 0.0169, 0.0160, 0.0174, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0170, 0.0157, 0.0168, 0.0157, 0.0162, 0.0174, 0.0167, 0.0164, 0.0168,\n",
            "        0.0166, 0.0184, 0.0171, 0.0169, 0.0166, 0.0170, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0171, 0.0159, 0.0167, 0.0160, 0.0163, 0.0173, 0.0164, 0.0166, 0.0166,\n",
            "        0.0164, 0.0167, 0.0170, 0.0173, 0.0165, 0.0164, 0.0170],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0168, 0.0164, 0.0170, 0.0163, 0.0164, 0.0173, 0.0172, 0.0171, 0.0168,\n",
            "        0.0166, 0.0166, 0.0167, 0.0165, 0.0165, 0.0165, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0166, 0.0166, 0.0167, 0.0161, 0.0163, 0.0168, 0.0165, 0.0166, 0.0164,\n",
            "        0.0164, 0.0167, 0.0162, 0.0165, 0.0165, 0.0163, 0.0168],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0165, 0.0166, 0.0167, 0.0163, 0.0163, 0.0164, 0.0165, 0.0166, 0.0164,\n",
            "        0.0164, 0.0166, 0.0163, 0.0164, 0.0165, 0.0163, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0165, 0.0166, 0.0167, 0.0162, 0.0163, 0.0164, 0.0166, 0.0163, 0.0163,\n",
            "        0.0164, 0.0166, 0.0163, 0.0164, 0.0165, 0.0163, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0165, 0.0166, 0.0167, 0.0162, 0.0162, 0.0164, 0.0166, 0.0163, 0.0163,\n",
            "        0.0164, 0.0166, 0.0162, 0.0164, 0.0165, 0.0163, 0.0166],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0163, 0.0166, 0.0167, 0.0162, 0.0162, 0.0164, 0.0162, 0.0161, 0.0163,\n",
            "        0.0162, 0.0164, 0.0161, 0.0164, 0.0164, 0.0162, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0162, 0.0164, 0.0164, 0.0162, 0.0162, 0.0163, 0.0162, 0.0160, 0.0162,\n",
            "        0.0162, 0.0164, 0.0161, 0.0162, 0.0162, 0.0162, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0162, 0.0164, 0.0164, 0.0161, 0.0162, 0.0162, 0.0162, 0.0159, 0.0162,\n",
            "        0.0162, 0.0164, 0.0161, 0.0162, 0.0162, 0.0162, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0162, 0.0164, 0.0164, 0.0162, 0.0162, 0.0162, 0.0162, 0.0159, 0.0162,\n",
            "        0.0162, 0.0163, 0.0161, 0.0162, 0.0162, 0.0162, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0162, 0.0164, 0.0164, 0.0162, 0.0162, 0.0162, 0.0162, 0.0159, 0.0162,\n",
            "        0.0162, 0.0163, 0.0162, 0.0162, 0.0162, 0.0162, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0162, 0.0166, 0.0166, 0.0162, 0.0162, 0.0162, 0.0162, 0.0161, 0.0162,\n",
            "        0.0162, 0.0163, 0.0162, 0.0162, 0.0162, 0.0162, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0164, 0.0166, 0.0166, 0.0162, 0.0162, 0.0162, 0.0164, 0.0161, 0.0162,\n",
            "        0.0164, 0.0165, 0.0162, 0.0161, 0.0162, 0.0162, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0164, 0.0166, 0.0166, 0.0162, 0.0162, 0.0162, 0.0164, 0.0161, 0.0162,\n",
            "        0.0165, 0.0165, 0.0162, 0.0161, 0.0162, 0.0162, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0164, 0.0166, 0.0166, 0.0162, 0.0162, 0.0162, 0.0164, 0.0161, 0.0162,\n",
            "        0.0165, 0.0165, 0.0162, 0.0161, 0.0162, 0.0162, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0164, 0.0166, 0.0166, 0.0162, 0.0162, 0.0162, 0.0164, 0.0161, 0.0162,\n",
            "        0.0165, 0.0165, 0.0162, 0.0161, 0.0162, 0.0162, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0162, 0.0166, 0.0166, 0.0162, 0.0162, 0.0161, 0.0162, 0.0162, 0.0162,\n",
            "        0.0162, 0.0163, 0.0162, 0.0161, 0.0162, 0.0162, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0358, 0.0363, 0.0388, 0.0385, 0.0357, 0.0361, 0.0341, 0.0354, 0.0359,\n",
            "        0.0351, 0.0368, 0.0352, 0.0362, 0.0353, 0.0345, 0.0354],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0359, 0.0361, 0.0363, 0.0363, 0.0360, 0.0357, 0.0343, 0.0350, 0.0354,\n",
            "        0.0352, 0.0365, 0.0346, 0.0371, 0.0349, 0.0349, 0.0353],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0354, 0.0355, 0.0369, 0.0369, 0.0356, 0.0356, 0.0338, 0.0350, 0.0352,\n",
            "        0.0352, 0.0364, 0.0348, 0.0369, 0.0341, 0.0351, 0.0356],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0358, 0.0358, 0.0352, 0.0360, 0.0356, 0.0363, 0.0345, 0.0355, 0.0352,\n",
            "        0.0346, 0.0357, 0.0351, 0.0363, 0.0347, 0.0357, 0.0352],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0350, 0.0356, 0.0349, 0.0354, 0.0359, 0.0359, 0.0348, 0.0355, 0.0354,\n",
            "        0.0347, 0.0351, 0.0347, 0.0366, 0.0349, 0.0357, 0.0350],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0349, 0.0356, 0.0349, 0.0357, 0.0356, 0.0352, 0.0348, 0.0357, 0.0354,\n",
            "        0.0350, 0.0351, 0.0350, 0.0352, 0.0348, 0.0357, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0349, 0.0350, 0.0349, 0.0352, 0.0352, 0.0348, 0.0348, 0.0353, 0.0352,\n",
            "        0.0350, 0.0351, 0.0350, 0.0352, 0.0348, 0.0351, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0349, 0.0350, 0.0349, 0.0356, 0.0353, 0.0356, 0.0351, 0.0358, 0.0352,\n",
            "        0.0352, 0.0351, 0.0352, 0.0352, 0.0348, 0.0356, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0349, 0.0349, 0.0349, 0.0354, 0.0352, 0.0352, 0.0351, 0.0356, 0.0352,\n",
            "        0.0352, 0.0354, 0.0352, 0.0354, 0.0348, 0.0351, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0349, 0.0349, 0.0349, 0.0354, 0.0352, 0.0352, 0.0352, 0.0352, 0.0349,\n",
            "        0.0352, 0.0354, 0.0352, 0.0352, 0.0348, 0.0351, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0349, 0.0348, 0.0349, 0.0354, 0.0346, 0.0346, 0.0346, 0.0347, 0.0349,\n",
            "        0.0346, 0.0354, 0.0347, 0.0346, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0347, 0.0348,\n",
            "        0.0347, 0.0346, 0.0347, 0.0346, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0347, 0.0346, 0.0347, 0.0346, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0347, 0.0346, 0.0347, 0.0346, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0347, 0.0346, 0.0347, 0.0346, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0347, 0.0346, 0.0346, 0.0346, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0348, 0.0348, 0.0348, 0.0352, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0347, 0.0346, 0.0346, 0.0346, 0.0348, 0.0347, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0352, 0.0352, 0.0346, 0.0346, 0.0348, 0.0352, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0346, 0.0352, 0.0346, 0.0346, 0.0348, 0.0347, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0348, 0.0348, 0.0348, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0348,\n",
            "        0.0346, 0.0346, 0.0346, 0.0347, 0.0348, 0.0346, 0.0348],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0244, 0.0233, 0.0248, 0.0219, 0.0224, 0.0226, 0.0230, 0.0230, 0.0235,\n",
            "        0.0248, 0.0234, 0.0225, 0.0221, 0.0241, 0.0227, 0.0224],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0238, 0.0230, 0.0243, 0.0223, 0.0232, 0.0236, 0.0240, 0.0241, 0.0233,\n",
            "        0.0249, 0.0246, 0.0233, 0.0226, 0.0246, 0.0226, 0.0231],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0232, 0.0235, 0.0245, 0.0227, 0.0227, 0.0230, 0.0236, 0.0244, 0.0235,\n",
            "        0.0236, 0.0241, 0.0240, 0.0231, 0.0240, 0.0230, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0230, 0.0226, 0.0231, 0.0226, 0.0226, 0.0229, 0.0234, 0.0240, 0.0233,\n",
            "        0.0235, 0.0236, 0.0227, 0.0230, 0.0239, 0.0227, 0.0228],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0231, 0.0226, 0.0231, 0.0227, 0.0226, 0.0233, 0.0234, 0.0238, 0.0234,\n",
            "        0.0235, 0.0230, 0.0228, 0.0227, 0.0238, 0.0229, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0228, 0.0226, 0.0227, 0.0227, 0.0226, 0.0233, 0.0228, 0.0232, 0.0234,\n",
            "        0.0234, 0.0232, 0.0228, 0.0226, 0.0230, 0.0229, 0.0227],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0230, 0.0228, 0.0231, 0.0229, 0.0228, 0.0230, 0.0230, 0.0234, 0.0231,\n",
            "        0.0231, 0.0231, 0.0228, 0.0228, 0.0232, 0.0231, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0230, 0.0228, 0.0230, 0.0229, 0.0228, 0.0230, 0.0230, 0.0234, 0.0231,\n",
            "        0.0231, 0.0233, 0.0228, 0.0228, 0.0234, 0.0231, 0.0229],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0233, 0.0228, 0.0228, 0.0229, 0.0228, 0.0233, 0.0233, 0.0231, 0.0229,\n",
            "        0.0231, 0.0233, 0.0228, 0.0228, 0.0234, 0.0234, 0.0232],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0231, 0.0231, 0.0231, 0.0231, 0.0231, 0.0233, 0.0231, 0.0233, 0.0232,\n",
            "        0.0233, 0.0234, 0.0232, 0.0231, 0.0232, 0.0231, 0.0232],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0231, 0.0230, 0.0231, 0.0230, 0.0229, 0.0229, 0.0230, 0.0232, 0.0232,\n",
            "        0.0233, 0.0232, 0.0232, 0.0230, 0.0232, 0.0229, 0.0230],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0229, 0.0230, 0.0230, 0.0230, 0.0229, 0.0229, 0.0230, 0.0232, 0.0232,\n",
            "        0.0229, 0.0232, 0.0232, 0.0230, 0.0232, 0.0229, 0.0230],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0229, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0232, 0.0232,\n",
            "        0.0229, 0.0232, 0.0232, 0.0230, 0.0232, 0.0229, 0.0230],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0228, 0.0228,\n",
            "        0.0230, 0.0228, 0.0228, 0.0230, 0.0228, 0.0229, 0.0230],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0226, 0.0226, 0.0226, 0.0227, 0.0227, 0.0227, 0.0227, 0.0228, 0.0228,\n",
            "        0.0226, 0.0228, 0.0228, 0.0227, 0.0228, 0.0226, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0226, 0.0226, 0.0226, 0.0227, 0.0227, 0.0227, 0.0226, 0.0228, 0.0229,\n",
            "        0.0227, 0.0229, 0.0228, 0.0227, 0.0229, 0.0226, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0226, 0.0227, 0.0226, 0.0227, 0.0227, 0.0227, 0.0226, 0.0228, 0.0229,\n",
            "        0.0227, 0.0228, 0.0228, 0.0227, 0.0229, 0.0226, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0226, 0.0227, 0.0226, 0.0226, 0.0227, 0.0227, 0.0226, 0.0228, 0.0229,\n",
            "        0.0227, 0.0228, 0.0228, 0.0226, 0.0229, 0.0226, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0226, 0.0226, 0.0226, 0.0226, 0.0227, 0.0227, 0.0226, 0.0228, 0.0228,\n",
            "        0.0227, 0.0228, 0.0229, 0.0226, 0.0229, 0.0226, 0.0226],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0230, 0.0230, 0.0226, 0.0230, 0.0230, 0.0230, 0.0230, 0.0228, 0.0228,\n",
            "        0.0227, 0.0228, 0.0229, 0.0230, 0.0229, 0.0230, 0.0230],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0226, 0.0225, 0.0231, 0.0231, 0.0242, 0.0215, 0.0226, 0.0227, 0.0214,\n",
            "        0.0223, 0.0230, 0.0236, 0.0217, 0.0229, 0.0219, 0.0215],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0222, 0.0222, 0.0220, 0.0219, 0.0226, 0.0212, 0.0215, 0.0229, 0.0211,\n",
            "        0.0215, 0.0221, 0.0237, 0.0216, 0.0230, 0.0215, 0.0216],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0212, 0.0217, 0.0215, 0.0220, 0.0223, 0.0217, 0.0222, 0.0226, 0.0213,\n",
            "        0.0212, 0.0220, 0.0224, 0.0212, 0.0219, 0.0216, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0216, 0.0220, 0.0218, 0.0218, 0.0219, 0.0222, 0.0217, 0.0222, 0.0216,\n",
            "        0.0210, 0.0219, 0.0223, 0.0215, 0.0217, 0.0212, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0221, 0.0221, 0.0219, 0.0216, 0.0221, 0.0223, 0.0214, 0.0219, 0.0215,\n",
            "        0.0213, 0.0223, 0.0220, 0.0219, 0.0213, 0.0215, 0.0216],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0222, 0.0221, 0.0219, 0.0218, 0.0219, 0.0220, 0.0218, 0.0220, 0.0216,\n",
            "        0.0215, 0.0217, 0.0222, 0.0215, 0.0216, 0.0215, 0.0221],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0221, 0.0221, 0.0220, 0.0218, 0.0219, 0.0220, 0.0218, 0.0220, 0.0216,\n",
            "        0.0215, 0.0217, 0.0217, 0.0215, 0.0216, 0.0215, 0.0219],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0219, 0.0219, 0.0218, 0.0218, 0.0216, 0.0218, 0.0218, 0.0218, 0.0215,\n",
            "        0.0215, 0.0217, 0.0217, 0.0215, 0.0215, 0.0215, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0216, 0.0219, 0.0214, 0.0215, 0.0213, 0.0215, 0.0213, 0.0215, 0.0215,\n",
            "        0.0215, 0.0217, 0.0217, 0.0215, 0.0215, 0.0215, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0213, 0.0212, 0.0214, 0.0212, 0.0213, 0.0215, 0.0213, 0.0215, 0.0211,\n",
            "        0.0211, 0.0214, 0.0214, 0.0211, 0.0208, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0211, 0.0212, 0.0214, 0.0210, 0.0211, 0.0215, 0.0213, 0.0214, 0.0211,\n",
            "        0.0211, 0.0214, 0.0214, 0.0211, 0.0208, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0211, 0.0211, 0.0214, 0.0211, 0.0211, 0.0213, 0.0213, 0.0214, 0.0211,\n",
            "        0.0211, 0.0213, 0.0213, 0.0211, 0.0208, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0211, 0.0211, 0.0214, 0.0211, 0.0211, 0.0213, 0.0214, 0.0213, 0.0211,\n",
            "        0.0211, 0.0211, 0.0211, 0.0211, 0.0208, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0211, 0.0211, 0.0214, 0.0211, 0.0211, 0.0213, 0.0214, 0.0213, 0.0211,\n",
            "        0.0211, 0.0211, 0.0211, 0.0211, 0.0208, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0211, 0.0211, 0.0214, 0.0211, 0.0211, 0.0213, 0.0214, 0.0213, 0.0211,\n",
            "        0.0211, 0.0211, 0.0211, 0.0211, 0.0208, 0.0211, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0211, 0.0210, 0.0213, 0.0211, 0.0211, 0.0213, 0.0214, 0.0214, 0.0214,\n",
            "        0.0211, 0.0211, 0.0211, 0.0213, 0.0208, 0.0214, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0214, 0.0213, 0.0213, 0.0214, 0.0214, 0.0213, 0.0214, 0.0214, 0.0214,\n",
            "        0.0214, 0.0214, 0.0214, 0.0214, 0.0211, 0.0214, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0214, 0.0213, 0.0213, 0.0214, 0.0214, 0.0213, 0.0213, 0.0214, 0.0213,\n",
            "        0.0214, 0.0214, 0.0213, 0.0214, 0.0211, 0.0214, 0.0217],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0214, 0.0213, 0.0213, 0.0214, 0.0214, 0.0213, 0.0213, 0.0214, 0.0213,\n",
            "        0.0214, 0.0214, 0.0213, 0.0214, 0.0211, 0.0214, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0214, 0.0210, 0.0213, 0.0211, 0.0211, 0.0213, 0.0213, 0.0214, 0.0210,\n",
            "        0.0211, 0.0211, 0.0210, 0.0211, 0.0208, 0.0210, 0.0213],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0483, 0.0487, 0.0497, 0.0496, 0.0506, 0.0489, 0.0488, 0.0501, 0.0506,\n",
            "        0.0482, 0.0495, 0.0493, 0.0492, 0.0496, 0.0486, 0.0499],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0478, 0.0492, 0.0484, 0.0487, 0.0489, 0.0485, 0.0492, 0.0493, 0.0501,\n",
            "        0.0485, 0.0502, 0.0483, 0.0493, 0.0501, 0.0485, 0.0497],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0485, 0.0491, 0.0489, 0.0490, 0.0488, 0.0492, 0.0496, 0.0494, 0.0494,\n",
            "        0.0485, 0.0499, 0.0480, 0.0496, 0.0491, 0.0488, 0.0505],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0486, 0.0494, 0.0492, 0.0489, 0.0490, 0.0486, 0.0490, 0.0490, 0.0487,\n",
            "        0.0493, 0.0500, 0.0487, 0.0493, 0.0492, 0.0486, 0.0497],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0486, 0.0493, 0.0496, 0.0493, 0.0494, 0.0490, 0.0495, 0.0491, 0.0491,\n",
            "        0.0499, 0.0501, 0.0491, 0.0494, 0.0486, 0.0491, 0.0494],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0490, 0.0494, 0.0495, 0.0502, 0.0494, 0.0490, 0.0493, 0.0494, 0.0491,\n",
            "        0.0493, 0.0494, 0.0490, 0.0494, 0.0491, 0.0491, 0.0494],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0490, 0.0491, 0.0490, 0.0507, 0.0493, 0.0490, 0.0490, 0.0491, 0.0491,\n",
            "        0.0493, 0.0494, 0.0490, 0.0491, 0.0491, 0.0490, 0.0494],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0490, 0.0491, 0.0490, 0.0500, 0.0493, 0.0490, 0.0490, 0.0491, 0.0491,\n",
            "        0.0493, 0.0494, 0.0490, 0.0491, 0.0490, 0.0490, 0.0494],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0490, 0.0490, 0.0490, 0.0500, 0.0493, 0.0490, 0.0490, 0.0491, 0.0491,\n",
            "        0.0493, 0.0494, 0.0490, 0.0491, 0.0490, 0.0490, 0.0494],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0490, 0.0490, 0.0490, 0.0500, 0.0493, 0.0490, 0.0490, 0.0491, 0.0491,\n",
            "        0.0490, 0.0494, 0.0490, 0.0490, 0.0490, 0.0490, 0.0494],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0490, 0.0490, 0.0490, 0.0500, 0.0490, 0.0490, 0.0490, 0.0491, 0.0490,\n",
            "        0.0490, 0.0491, 0.0490, 0.0490, 0.0490, 0.0490, 0.0491],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0490, 0.0486, 0.0490, 0.0500, 0.0490, 0.0490, 0.0486, 0.0490, 0.0490,\n",
            "        0.0486, 0.0485, 0.0490, 0.0486, 0.0485, 0.0490, 0.0486],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0486, 0.0486, 0.0486, 0.0496, 0.0486, 0.0486, 0.0486, 0.0486, 0.0486,\n",
            "        0.0486, 0.0485, 0.0486, 0.0486, 0.0485, 0.0486, 0.0486],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0490, 0.0491, 0.0490, 0.0499, 0.0490, 0.0490, 0.0490, 0.0490, 0.0491,\n",
            "        0.0490, 0.0485, 0.0491, 0.0490, 0.0485, 0.0490, 0.0490],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0491, 0.0491, 0.0490, 0.0499, 0.0491, 0.0490, 0.0490, 0.0490, 0.0490,\n",
            "        0.0490, 0.0490, 0.0491, 0.0490, 0.0490, 0.0490, 0.0490],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0491, 0.0491, 0.0490, 0.0499, 0.0491, 0.0490, 0.0490, 0.0490, 0.0491,\n",
            "        0.0490, 0.0490, 0.0491, 0.0490, 0.0490, 0.0490, 0.0490],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0491, 0.0491, 0.0490, 0.0499, 0.0491, 0.0491, 0.0491, 0.0490, 0.0491,\n",
            "        0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0491],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0491, 0.0490, 0.0490, 0.0499, 0.0490, 0.0491, 0.0490, 0.0490, 0.0491,\n",
            "        0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0491],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0490, 0.0490, 0.0490, 0.0499, 0.0490, 0.0491, 0.0490, 0.0490, 0.0491,\n",
            "        0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0491],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0490, 0.0490, 0.0490, 0.0499, 0.0490, 0.0491, 0.0490, 0.0490, 0.0491,\n",
            "        0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0490, 0.0491],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0290, 0.0285, 0.0286, 0.0278, 0.0284, 0.0293, 0.0297, 0.0294, 0.0279,\n",
            "        0.0285, 0.0285, 0.0284, 0.0288, 0.0292, 0.0294, 0.0287],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0291, 0.0282, 0.0277, 0.0277, 0.0283, 0.0288, 0.0296, 0.0287, 0.0276,\n",
            "        0.0283, 0.0277, 0.0277, 0.0282, 0.0285, 0.0284, 0.0282],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0281, 0.0289, 0.0283, 0.0284, 0.0290, 0.0283, 0.0286, 0.0297, 0.0282,\n",
            "        0.0279, 0.0279, 0.0285, 0.0289, 0.0291, 0.0283, 0.0285],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0284, 0.0291, 0.0281, 0.0281, 0.0282, 0.0284, 0.0287, 0.0294, 0.0281,\n",
            "        0.0282, 0.0284, 0.0281, 0.0284, 0.0294, 0.0283, 0.0285],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0279, 0.0285, 0.0281, 0.0277, 0.0282, 0.0284, 0.0283, 0.0289, 0.0285,\n",
            "        0.0278, 0.0282, 0.0281, 0.0282, 0.0285, 0.0280, 0.0280],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0280, 0.0285, 0.0279, 0.0279, 0.0280, 0.0283, 0.0285, 0.0283, 0.0287,\n",
            "        0.0281, 0.0283, 0.0280, 0.0282, 0.0280, 0.0282, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0281, 0.0280, 0.0279, 0.0279, 0.0280, 0.0283, 0.0281, 0.0283, 0.0280,\n",
            "        0.0281, 0.0281, 0.0280, 0.0279, 0.0280, 0.0279, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0281, 0.0280, 0.0279, 0.0279, 0.0280, 0.0283, 0.0281, 0.0283, 0.0279,\n",
            "        0.0281, 0.0281, 0.0280, 0.0279, 0.0280, 0.0279, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0281, 0.0280, 0.0279, 0.0277, 0.0280, 0.0280, 0.0281, 0.0280, 0.0279,\n",
            "        0.0281, 0.0281, 0.0280, 0.0279, 0.0280, 0.0279, 0.0281],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0279, 0.0280, 0.0278, 0.0277, 0.0278, 0.0280, 0.0281, 0.0280, 0.0277,\n",
            "        0.0277, 0.0279, 0.0281, 0.0278, 0.0280, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0279, 0.0280, 0.0278, 0.0277, 0.0278, 0.0278, 0.0281, 0.0280, 0.0277,\n",
            "        0.0277, 0.0278, 0.0281, 0.0277, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0278, 0.0280, 0.0278, 0.0277, 0.0278, 0.0277, 0.0279, 0.0280, 0.0277,\n",
            "        0.0277, 0.0278, 0.0281, 0.0277, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0278, 0.0280, 0.0278, 0.0277, 0.0278, 0.0277, 0.0279, 0.0280, 0.0277,\n",
            "        0.0277, 0.0278, 0.0281, 0.0277, 0.0277, 0.0277, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0278, 0.0280, 0.0277, 0.0277, 0.0278, 0.0277, 0.0277, 0.0280, 0.0277,\n",
            "        0.0277, 0.0278, 0.0280, 0.0278, 0.0277, 0.0277, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0278, 0.0280, 0.0277, 0.0277, 0.0278, 0.0277, 0.0277, 0.0280, 0.0277,\n",
            "        0.0277, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0277, 0.0280, 0.0277, 0.0277, 0.0278, 0.0278, 0.0277, 0.0280, 0.0277,\n",
            "        0.0277, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0277, 0.0280, 0.0277, 0.0278, 0.0277, 0.0277, 0.0278, 0.0280, 0.0278,\n",
            "        0.0277, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0277, 0.0280, 0.0277, 0.0278, 0.0277, 0.0277, 0.0278, 0.0280, 0.0278,\n",
            "        0.0277, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0277, 0.0280, 0.0277, 0.0278, 0.0277, 0.0277, 0.0278, 0.0280, 0.0278,\n",
            "        0.0277, 0.0277, 0.0280, 0.0278, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0277, 0.0281, 0.0277, 0.0278, 0.0277, 0.0277, 0.0278, 0.0280, 0.0278,\n",
            "        0.0277, 0.0277, 0.0280, 0.0277, 0.0277, 0.0277, 0.0278],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0336, 0.0325, 0.0341, 0.0328, 0.0329, 0.0315, 0.0341, 0.0323, 0.0331,\n",
            "        0.0327, 0.0324, 0.0328, 0.0338, 0.0317, 0.0330, 0.0316],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0321, 0.0327, 0.0343, 0.0332, 0.0333, 0.0312, 0.0345, 0.0325, 0.0325,\n",
            "        0.0317, 0.0315, 0.0332, 0.0327, 0.0321, 0.0334, 0.0316],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0317, 0.0326, 0.0335, 0.0331, 0.0325, 0.0317, 0.0353, 0.0327, 0.0323,\n",
            "        0.0322, 0.0318, 0.0338, 0.0339, 0.0319, 0.0339, 0.0323],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0322, 0.0323, 0.0331, 0.0330, 0.0329, 0.0323, 0.0332, 0.0327, 0.0322,\n",
            "        0.0327, 0.0320, 0.0332, 0.0341, 0.0323, 0.0323, 0.0325],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0322, 0.0326, 0.0331, 0.0330, 0.0322, 0.0320, 0.0331, 0.0325, 0.0327,\n",
            "        0.0327, 0.0323, 0.0330, 0.0331, 0.0328, 0.0323, 0.0327],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0322, 0.0327, 0.0326, 0.0326, 0.0324, 0.0322, 0.0328, 0.0325, 0.0326,\n",
            "        0.0327, 0.0328, 0.0325, 0.0334, 0.0328, 0.0323, 0.0323],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0322, 0.0327, 0.0325, 0.0324, 0.0322, 0.0322, 0.0325, 0.0323, 0.0326,\n",
            "        0.0327, 0.0327, 0.0325, 0.0325, 0.0324, 0.0323, 0.0323],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0322, 0.0327, 0.0325, 0.0324, 0.0320, 0.0320, 0.0325, 0.0323, 0.0326,\n",
            "        0.0327, 0.0325, 0.0325, 0.0325, 0.0320, 0.0323, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0322, 0.0327, 0.0323, 0.0324, 0.0320, 0.0320, 0.0325, 0.0320, 0.0323,\n",
            "        0.0325, 0.0325, 0.0323, 0.0325, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0322, 0.0327, 0.0323, 0.0322, 0.0320, 0.0320, 0.0325, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0325, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0325, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0322, 0.0327, 0.0320, 0.0322, 0.0320, 0.0320, 0.0322, 0.0320, 0.0320,\n",
            "        0.0325, 0.0325, 0.0320, 0.0322, 0.0320, 0.0322, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0188, 0.0162, 0.0171, 0.0168, 0.0159, 0.0163, 0.0161, 0.0170, 0.0158,\n",
            "        0.0178, 0.0164, 0.0171, 0.0171, 0.0167, 0.0165, 0.0169],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0178, 0.0161, 0.0170, 0.0174, 0.0160, 0.0158, 0.0156, 0.0163, 0.0164,\n",
            "        0.0169, 0.0167, 0.0167, 0.0173, 0.0166, 0.0169, 0.0163],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0172, 0.0166, 0.0168, 0.0172, 0.0161, 0.0163, 0.0158, 0.0168, 0.0167,\n",
            "        0.0165, 0.0166, 0.0168, 0.0171, 0.0170, 0.0168, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0172, 0.0163, 0.0162, 0.0166, 0.0164, 0.0164, 0.0160, 0.0164, 0.0163,\n",
            "        0.0164, 0.0164, 0.0165, 0.0171, 0.0161, 0.0163, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0173, 0.0160, 0.0163, 0.0164, 0.0165, 0.0161, 0.0160, 0.0164, 0.0165,\n",
            "        0.0160, 0.0161, 0.0164, 0.0167, 0.0161, 0.0165, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0165, 0.0162, 0.0161, 0.0165, 0.0163, 0.0161, 0.0162, 0.0161, 0.0161,\n",
            "        0.0161, 0.0163, 0.0165, 0.0166, 0.0163, 0.0167, 0.0162],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0165, 0.0164, 0.0161, 0.0165, 0.0163, 0.0161, 0.0164, 0.0163, 0.0161,\n",
            "        0.0163, 0.0161, 0.0164, 0.0161, 0.0163, 0.0161, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0164, 0.0163, 0.0161, 0.0166, 0.0163, 0.0163, 0.0164, 0.0163, 0.0161,\n",
            "        0.0163, 0.0161, 0.0164, 0.0161, 0.0163, 0.0161, 0.0163],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0166, 0.0163, 0.0161, 0.0166, 0.0163, 0.0163, 0.0164, 0.0163, 0.0161,\n",
            "        0.0163, 0.0161, 0.0163, 0.0161, 0.0163, 0.0161, 0.0163],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0166, 0.0163, 0.0161, 0.0163, 0.0161, 0.0161, 0.0161, 0.0161, 0.0159,\n",
            "        0.0163, 0.0161, 0.0162, 0.0161, 0.0161, 0.0162, 0.0161],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0163, 0.0158, 0.0158, 0.0161, 0.0158, 0.0161, 0.0160, 0.0161, 0.0158,\n",
            "        0.0163, 0.0158, 0.0160, 0.0159, 0.0161, 0.0158, 0.0160],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0163, 0.0158, 0.0158, 0.0161, 0.0158, 0.0161, 0.0158, 0.0158, 0.0158,\n",
            "        0.0158, 0.0158, 0.0158, 0.0158, 0.0161, 0.0158, 0.0160],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0161, 0.0158, 0.0158, 0.0161, 0.0158, 0.0161, 0.0158, 0.0158, 0.0158,\n",
            "        0.0158, 0.0158, 0.0158, 0.0158, 0.0161, 0.0158, 0.0160],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0160, 0.0160, 0.0160, 0.0160, 0.0158, 0.0160, 0.0160, 0.0158, 0.0160,\n",
            "        0.0158, 0.0160, 0.0160, 0.0160, 0.0161, 0.0160, 0.0160],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
            "        0.0160, 0.0160, 0.0160, 0.0160, 0.0163, 0.0160, 0.0163],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0160, 0.0160, 0.0160, 0.0163, 0.0160, 0.0163, 0.0160, 0.0160, 0.0160,\n",
            "        0.0160, 0.0160, 0.0160, 0.0160, 0.0163, 0.0160, 0.0163],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0161, 0.0160, 0.0160, 0.0163, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
            "        0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0161],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0161, 0.0158, 0.0160, 0.0161, 0.0160, 0.0160, 0.0160, 0.0160, 0.0158,\n",
            "        0.0160, 0.0160, 0.0160, 0.0158, 0.0160, 0.0160, 0.0161],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0161, 0.0158, 0.0160, 0.0161, 0.0158, 0.0160, 0.0160, 0.0160, 0.0158,\n",
            "        0.0158, 0.0158, 0.0158, 0.0158, 0.0160, 0.0158, 0.0161],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0161, 0.0160, 0.0160, 0.0161, 0.0158, 0.0160, 0.0160, 0.0158, 0.0160,\n",
            "        0.0158, 0.0158, 0.0158, 0.0160, 0.0160, 0.0158, 0.0160],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0184, 0.0182, 0.0188, 0.0177, 0.0181, 0.0179, 0.0176, 0.0183, 0.0213,\n",
            "        0.0193, 0.0189, 0.0175, 0.0173, 0.0174, 0.0183, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0185, 0.0180, 0.0180, 0.0178, 0.0175, 0.0185, 0.0175, 0.0182, 0.0190,\n",
            "        0.0185, 0.0179, 0.0171, 0.0172, 0.0177, 0.0183, 0.0167],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0183, 0.0175, 0.0181, 0.0182, 0.0174, 0.0180, 0.0178, 0.0184, 0.0185,\n",
            "        0.0180, 0.0182, 0.0169, 0.0173, 0.0182, 0.0184, 0.0169],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0174, 0.0176, 0.0182, 0.0183, 0.0179, 0.0172, 0.0181, 0.0180, 0.0188,\n",
            "        0.0182, 0.0185, 0.0171, 0.0174, 0.0187, 0.0189, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0175, 0.0175, 0.0181, 0.0173, 0.0179, 0.0174, 0.0177, 0.0181, 0.0189,\n",
            "        0.0182, 0.0180, 0.0173, 0.0177, 0.0179, 0.0181, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0175, 0.0175, 0.0174, 0.0177, 0.0177, 0.0176, 0.0177, 0.0177, 0.0188,\n",
            "        0.0178, 0.0182, 0.0175, 0.0175, 0.0179, 0.0175, 0.0173],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0175, 0.0175, 0.0174, 0.0177, 0.0179, 0.0176, 0.0180, 0.0177, 0.0177,\n",
            "        0.0178, 0.0177, 0.0175, 0.0175, 0.0180, 0.0177, 0.0175],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0175, 0.0177, 0.0177, 0.0175, 0.0179, 0.0176, 0.0180, 0.0177, 0.0177,\n",
            "        0.0178, 0.0177, 0.0175, 0.0175, 0.0179, 0.0177, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0175, 0.0176, 0.0176, 0.0175, 0.0179, 0.0174, 0.0179, 0.0177, 0.0179,\n",
            "        0.0178, 0.0177, 0.0174, 0.0174, 0.0179, 0.0177, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0174, 0.0174, 0.0174, 0.0172, 0.0179, 0.0172, 0.0174, 0.0176, 0.0177,\n",
            "        0.0176, 0.0175, 0.0174, 0.0174, 0.0174, 0.0175, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0172, 0.0172, 0.0174, 0.0172, 0.0177,\n",
            "        0.0173, 0.0173, 0.0172, 0.0172, 0.0174, 0.0175, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0172, 0.0172, 0.0174, 0.0172, 0.0175,\n",
            "        0.0172, 0.0174, 0.0172, 0.0172, 0.0174, 0.0175, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0172, 0.0172, 0.0174, 0.0172, 0.0175,\n",
            "        0.0172, 0.0174, 0.0172, 0.0172, 0.0174, 0.0174, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0172, 0.0172, 0.0174, 0.0172, 0.0175,\n",
            "        0.0172, 0.0172, 0.0172, 0.0172, 0.0174, 0.0174, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0174, 0.0175, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0175,\n",
            "        0.0172, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0174, 0.0175, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174,\n",
            "        0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0177, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0174, 0.0175, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174,\n",
            "        0.0173, 0.0174, 0.0174, 0.0174, 0.0176, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0174, 0.0172, 0.0174, 0.0172, 0.0174,\n",
            "        0.0173, 0.0172, 0.0174, 0.0174, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0172, 0.0172, 0.0174, 0.0172, 0.0174,\n",
            "        0.0172, 0.0172, 0.0172, 0.0172, 0.0174, 0.0174, 0.0174],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0172, 0.0174, 0.0174, 0.0172, 0.0172, 0.0172, 0.0174, 0.0172, 0.0174,\n",
            "        0.0172, 0.0172, 0.0172, 0.0172, 0.0174, 0.0174, 0.0172],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0219, 0.0203, 0.0200, 0.0210, 0.0213, 0.0213, 0.0204, 0.0207, 0.0199,\n",
            "        0.0225, 0.0201, 0.0207, 0.0208, 0.0204, 0.0207, 0.0203],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0219, 0.0210, 0.0204, 0.0203, 0.0208, 0.0212, 0.0202, 0.0210, 0.0207,\n",
            "        0.0208, 0.0206, 0.0204, 0.0221, 0.0215, 0.0200, 0.0207],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0206, 0.0217, 0.0202, 0.0206, 0.0206, 0.0211, 0.0205, 0.0214, 0.0213,\n",
            "        0.0208, 0.0212, 0.0200, 0.0226, 0.0222, 0.0205, 0.0209],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0208, 0.0212, 0.0207, 0.0210, 0.0211, 0.0211, 0.0201, 0.0209, 0.0209,\n",
            "        0.0210, 0.0204, 0.0202, 0.0214, 0.0215, 0.0206, 0.0214],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0201, 0.0212, 0.0203, 0.0208, 0.0210, 0.0210, 0.0202, 0.0208, 0.0201,\n",
            "        0.0210, 0.0204, 0.0203, 0.0202, 0.0217, 0.0203, 0.0212],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0202, 0.0208, 0.0204, 0.0205, 0.0205, 0.0206, 0.0203, 0.0209, 0.0203,\n",
            "        0.0207, 0.0205, 0.0203, 0.0203, 0.0207, 0.0204, 0.0206],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0202, 0.0205, 0.0202, 0.0202, 0.0203, 0.0202, 0.0200, 0.0206, 0.0200,\n",
            "        0.0204, 0.0202, 0.0200, 0.0202, 0.0204, 0.0202, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0202, 0.0205, 0.0200, 0.0202, 0.0203, 0.0202, 0.0200, 0.0206, 0.0200,\n",
            "        0.0201, 0.0200, 0.0200, 0.0202, 0.0204, 0.0202, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0202, 0.0204, 0.0200, 0.0202, 0.0203, 0.0202, 0.0200, 0.0204, 0.0200,\n",
            "        0.0201, 0.0200, 0.0200, 0.0202, 0.0202, 0.0202, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0200, 0.0201, 0.0198, 0.0202, 0.0203, 0.0202, 0.0198, 0.0204, 0.0198,\n",
            "        0.0201, 0.0200, 0.0199, 0.0202, 0.0202, 0.0200, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0198, 0.0201, 0.0198, 0.0198, 0.0201, 0.0198, 0.0198, 0.0201, 0.0198,\n",
            "        0.0201, 0.0198, 0.0199, 0.0198, 0.0202, 0.0198, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0201, 0.0201, 0.0201, 0.0201, 0.0202, 0.0201, 0.0201, 0.0201, 0.0201,\n",
            "        0.0201, 0.0201, 0.0202, 0.0198, 0.0202, 0.0201, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0201, 0.0204, 0.0201, 0.0201, 0.0202, 0.0201, 0.0201, 0.0204, 0.0201,\n",
            "        0.0204, 0.0201, 0.0202, 0.0201, 0.0205, 0.0201, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0201, 0.0204, 0.0201, 0.0201, 0.0202, 0.0201, 0.0201, 0.0204, 0.0202,\n",
            "        0.0204, 0.0201, 0.0202, 0.0201, 0.0205, 0.0201, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0201, 0.0204, 0.0201, 0.0201, 0.0202, 0.0202, 0.0201, 0.0204, 0.0202,\n",
            "        0.0205, 0.0201, 0.0202, 0.0201, 0.0204, 0.0201, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0201, 0.0201, 0.0201, 0.0201, 0.0202, 0.0201, 0.0202, 0.0201, 0.0202,\n",
            "        0.0205, 0.0202, 0.0201, 0.0201, 0.0201, 0.0202, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0201, 0.0201, 0.0198, 0.0198, 0.0198, 0.0201, 0.0199, 0.0202, 0.0199,\n",
            "        0.0202, 0.0199, 0.0198, 0.0201, 0.0201, 0.0199, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0198, 0.0201, 0.0198, 0.0198, 0.0198, 0.0198, 0.0199, 0.0202, 0.0199,\n",
            "        0.0202, 0.0199, 0.0198, 0.0198, 0.0201, 0.0199, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0198, 0.0201, 0.0199, 0.0198, 0.0198, 0.0198, 0.0199, 0.0202, 0.0198,\n",
            "        0.0201, 0.0198, 0.0198, 0.0198, 0.0201, 0.0199, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0198, 0.0202, 0.0199, 0.0199, 0.0198, 0.0198, 0.0199, 0.0201, 0.0198,\n",
            "        0.0201, 0.0198, 0.0198, 0.0198, 0.0201, 0.0199, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0146, 0.0157, 0.0147, 0.0148, 0.0166, 0.0142, 0.0150, 0.0149, 0.0144,\n",
            "        0.0154, 0.0167, 0.0166, 0.0139, 0.0151, 0.0152, 0.0164],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0156, 0.0152, 0.0148, 0.0146, 0.0158, 0.0146, 0.0150, 0.0149, 0.0147,\n",
            "        0.0152, 0.0167, 0.0176, 0.0143, 0.0154, 0.0149, 0.0159],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0148, 0.0150, 0.0149, 0.0145, 0.0152, 0.0144, 0.0152, 0.0152, 0.0148,\n",
            "        0.0154, 0.0160, 0.0164, 0.0144, 0.0150, 0.0151, 0.0158],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0148, 0.0148, 0.0151, 0.0145, 0.0154, 0.0145, 0.0152, 0.0155, 0.0149,\n",
            "        0.0156, 0.0153, 0.0158, 0.0144, 0.0151, 0.0150, 0.0146],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0152, 0.0146, 0.0155, 0.0148, 0.0157, 0.0147, 0.0150, 0.0149, 0.0153,\n",
            "        0.0155, 0.0154, 0.0152, 0.0147, 0.0155, 0.0153, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0159, 0.0149, 0.0150, 0.0149, 0.0153, 0.0149, 0.0150, 0.0153, 0.0150,\n",
            "        0.0154, 0.0151, 0.0151, 0.0149, 0.0159, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0156, 0.0149, 0.0150, 0.0149, 0.0152, 0.0149, 0.0150, 0.0153, 0.0151,\n",
            "        0.0152, 0.0151, 0.0153, 0.0149, 0.0154, 0.0149, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0155, 0.0149, 0.0150, 0.0149, 0.0152, 0.0149, 0.0150, 0.0152, 0.0149,\n",
            "        0.0149, 0.0151, 0.0152, 0.0149, 0.0154, 0.0150, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0155, 0.0149, 0.0150, 0.0147, 0.0150, 0.0147, 0.0150, 0.0149, 0.0148,\n",
            "        0.0149, 0.0149, 0.0152, 0.0147, 0.0154, 0.0150, 0.0149],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0155, 0.0147, 0.0149, 0.0147, 0.0150, 0.0147, 0.0148, 0.0149, 0.0147,\n",
            "        0.0148, 0.0149, 0.0151, 0.0147, 0.0153, 0.0149, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0154, 0.0147, 0.0147, 0.0147, 0.0149, 0.0147, 0.0148, 0.0149, 0.0147,\n",
            "        0.0148, 0.0147, 0.0151, 0.0147, 0.0152, 0.0149, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0154, 0.0147, 0.0148, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0148,\n",
            "        0.0148, 0.0147, 0.0149, 0.0148, 0.0152, 0.0147, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0154, 0.0147, 0.0148, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0148,\n",
            "        0.0147, 0.0147, 0.0149, 0.0148, 0.0152, 0.0147, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0154, 0.0147, 0.0148, 0.0147, 0.0147, 0.0147, 0.0148, 0.0149, 0.0148,\n",
            "        0.0147, 0.0148, 0.0149, 0.0148, 0.0151, 0.0147, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0154, 0.0147, 0.0148, 0.0147, 0.0147, 0.0147, 0.0148, 0.0149, 0.0148,\n",
            "        0.0147, 0.0147, 0.0149, 0.0148, 0.0151, 0.0146, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0154, 0.0147, 0.0148, 0.0147, 0.0147, 0.0147, 0.0148, 0.0149, 0.0148,\n",
            "        0.0147, 0.0147, 0.0149, 0.0147, 0.0151, 0.0146, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0154, 0.0147, 0.0148, 0.0147, 0.0147, 0.0147, 0.0148, 0.0149, 0.0148,\n",
            "        0.0147, 0.0147, 0.0149, 0.0147, 0.0151, 0.0146, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0154, 0.0147, 0.0147, 0.0148, 0.0147, 0.0148, 0.0148, 0.0149, 0.0148,\n",
            "        0.0147, 0.0147, 0.0149, 0.0147, 0.0151, 0.0148, 0.0147],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0154, 0.0147, 0.0147, 0.0148, 0.0147, 0.0147, 0.0148, 0.0149, 0.0147,\n",
            "        0.0148, 0.0147, 0.0149, 0.0147, 0.0151, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0154, 0.0147, 0.0147, 0.0147, 0.0147, 0.0147, 0.0148, 0.0149, 0.0147,\n",
            "        0.0148, 0.0147, 0.0149, 0.0147, 0.0151, 0.0148, 0.0148],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0213, 0.0196, 0.0207, 0.0197, 0.0206, 0.0205, 0.0206, 0.0208, 0.0218,\n",
            "        0.0226, 0.0200, 0.0203, 0.0203, 0.0213, 0.0208, 0.0204],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0216, 0.0199, 0.0209, 0.0191, 0.0209, 0.0211, 0.0205, 0.0202, 0.0200,\n",
            "        0.0207, 0.0196, 0.0204, 0.0201, 0.0208, 0.0204, 0.0200],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0204, 0.0200, 0.0202, 0.0193, 0.0207, 0.0222, 0.0201, 0.0201, 0.0205,\n",
            "        0.0210, 0.0202, 0.0201, 0.0205, 0.0202, 0.0207, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0210, 0.0204, 0.0199, 0.0199, 0.0212, 0.0221, 0.0202, 0.0202, 0.0205,\n",
            "        0.0210, 0.0202, 0.0196, 0.0206, 0.0197, 0.0202, 0.0206],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0208, 0.0206, 0.0202, 0.0200, 0.0206, 0.0210, 0.0206, 0.0204, 0.0211,\n",
            "        0.0210, 0.0206, 0.0201, 0.0202, 0.0198, 0.0207, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0201, 0.0206, 0.0203, 0.0201, 0.0206, 0.0206, 0.0202, 0.0201, 0.0211,\n",
            "        0.0211, 0.0206, 0.0200, 0.0204, 0.0200, 0.0206, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0201, 0.0202, 0.0200, 0.0203, 0.0201, 0.0203, 0.0202, 0.0201, 0.0202,\n",
            "        0.0202, 0.0201, 0.0200, 0.0199, 0.0200, 0.0200, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0199, 0.0199, 0.0197, 0.0204, 0.0199, 0.0201, 0.0199, 0.0198, 0.0202,\n",
            "        0.0200, 0.0199, 0.0197, 0.0199, 0.0197, 0.0197, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0199, 0.0197, 0.0197, 0.0201, 0.0199, 0.0201, 0.0197, 0.0198, 0.0202,\n",
            "        0.0200, 0.0199, 0.0197, 0.0199, 0.0197, 0.0197, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0199, 0.0197, 0.0196, 0.0201, 0.0197, 0.0201, 0.0197, 0.0197, 0.0201,\n",
            "        0.0200, 0.0199, 0.0196, 0.0199, 0.0197, 0.0197, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0199, 0.0196, 0.0196, 0.0201, 0.0197, 0.0199, 0.0196, 0.0197, 0.0199,\n",
            "        0.0200, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0196, 0.0196, 0.0196, 0.0201, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0197, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0196, 0.0196, 0.0196, 0.0203, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0196, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0198, 0.0196, 0.0196, 0.0203, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0199, 0.0196, 0.0198, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0196, 0.0199, 0.0199, 0.0203, 0.0198, 0.0199, 0.0198, 0.0199, 0.0199,\n",
            "        0.0199, 0.0198, 0.0198, 0.0199, 0.0199, 0.0198, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0196, 0.0199, 0.0196, 0.0203, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0196, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0196, 0.0196, 0.0196, 0.0201, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0196, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0196, 0.0196, 0.0196, 0.0201, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0196, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0196, 0.0196, 0.0196, 0.0201, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0196, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0196, 0.0196, 0.0196, 0.0203, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199,\n",
            "        0.0196, 0.0196, 0.0196, 0.0199, 0.0196, 0.0196, 0.0199],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0247, 0.0243, 0.0244, 0.0232, 0.0239, 0.0241, 0.0232, 0.0235, 0.0242,\n",
            "        0.0231, 0.0260, 0.0245, 0.0231, 0.0252, 0.0234, 0.0237],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0244, 0.0253, 0.0244, 0.0237, 0.0247, 0.0249, 0.0240, 0.0239, 0.0241,\n",
            "        0.0237, 0.0261, 0.0246, 0.0245, 0.0247, 0.0239, 0.0242],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0243, 0.0250, 0.0252, 0.0245, 0.0257, 0.0247, 0.0248, 0.0238, 0.0244,\n",
            "        0.0239, 0.0251, 0.0244, 0.0240, 0.0240, 0.0239, 0.0244],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0243, 0.0246, 0.0248, 0.0240, 0.0249, 0.0244, 0.0239, 0.0240, 0.0238,\n",
            "        0.0240, 0.0250, 0.0246, 0.0244, 0.0239, 0.0238, 0.0242],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0243, 0.0243, 0.0245, 0.0238, 0.0245, 0.0244, 0.0241, 0.0238, 0.0242,\n",
            "        0.0243, 0.0245, 0.0249, 0.0245, 0.0238, 0.0235, 0.0244],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0237, 0.0246, 0.0240, 0.0239, 0.0240, 0.0238, 0.0245, 0.0238, 0.0239,\n",
            "        0.0243, 0.0245, 0.0243, 0.0248, 0.0238, 0.0237, 0.0240],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0240, 0.0242, 0.0240, 0.0242, 0.0240, 0.0242, 0.0247, 0.0241, 0.0241,\n",
            "        0.0241, 0.0243, 0.0243, 0.0246, 0.0239, 0.0240, 0.0242],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0240, 0.0240, 0.0244, 0.0241, 0.0243, 0.0242, 0.0245, 0.0239, 0.0241,\n",
            "        0.0241, 0.0243, 0.0242, 0.0243, 0.0242, 0.0238, 0.0240],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0236, 0.0240, 0.0244, 0.0241, 0.0243, 0.0242, 0.0245, 0.0239, 0.0239,\n",
            "        0.0239, 0.0243, 0.0242, 0.0240, 0.0241, 0.0238, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0236, 0.0239, 0.0243, 0.0241, 0.0240, 0.0241, 0.0245, 0.0239, 0.0239,\n",
            "        0.0239, 0.0243, 0.0241, 0.0239, 0.0241, 0.0238, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0236, 0.0239, 0.0237, 0.0238, 0.0237, 0.0238, 0.0245, 0.0239, 0.0239,\n",
            "        0.0239, 0.0239, 0.0241, 0.0239, 0.0237, 0.0238, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0233, 0.0235, 0.0237, 0.0238, 0.0237, 0.0238, 0.0245, 0.0235, 0.0235,\n",
            "        0.0235, 0.0239, 0.0235, 0.0236, 0.0237, 0.0235, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0233, 0.0235, 0.0237, 0.0237, 0.0237, 0.0238, 0.0242, 0.0235, 0.0235,\n",
            "        0.0235, 0.0237, 0.0235, 0.0236, 0.0237, 0.0235, 0.0236],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0233, 0.0235, 0.0237, 0.0237, 0.0237, 0.0238, 0.0245, 0.0235, 0.0235,\n",
            "        0.0235, 0.0237, 0.0235, 0.0235, 0.0237, 0.0235, 0.0235],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0236, 0.0239, 0.0237, 0.0237, 0.0237, 0.0237, 0.0244, 0.0239, 0.0238,\n",
            "        0.0239, 0.0240, 0.0238, 0.0239, 0.0237, 0.0239, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0236, 0.0239, 0.0240, 0.0241, 0.0240, 0.0240, 0.0244, 0.0239, 0.0238,\n",
            "        0.0239, 0.0240, 0.0238, 0.0239, 0.0241, 0.0239, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0236, 0.0239, 0.0241, 0.0241, 0.0240, 0.0240, 0.0244, 0.0239, 0.0238,\n",
            "        0.0239, 0.0240, 0.0238, 0.0239, 0.0241, 0.0239, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0236, 0.0239, 0.0241, 0.0241, 0.0240, 0.0240, 0.0244, 0.0239, 0.0239,\n",
            "        0.0239, 0.0237, 0.0238, 0.0238, 0.0241, 0.0239, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0236, 0.0239, 0.0237, 0.0237, 0.0237, 0.0237, 0.0244, 0.0239, 0.0239,\n",
            "        0.0239, 0.0237, 0.0238, 0.0238, 0.0237, 0.0239, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0237, 0.0239, 0.0237, 0.0237, 0.0237, 0.0237, 0.0244, 0.0239, 0.0239,\n",
            "        0.0239, 0.0241, 0.0238, 0.0239, 0.0237, 0.0239, 0.0239],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0300, 0.0309, 0.0306, 0.0304, 0.0311, 0.0303, 0.0302, 0.0318, 0.0300,\n",
            "        0.0317, 0.0321, 0.0304, 0.0311, 0.0299, 0.0298, 0.0320],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0302, 0.0309, 0.0300, 0.0293, 0.0302, 0.0304, 0.0298, 0.0301, 0.0298,\n",
            "        0.0325, 0.0316, 0.0299, 0.0305, 0.0295, 0.0297, 0.0311],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0308, 0.0305, 0.0306, 0.0296, 0.0307, 0.0306, 0.0303, 0.0302, 0.0295,\n",
            "        0.0309, 0.0310, 0.0297, 0.0313, 0.0295, 0.0299, 0.0309],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0297, 0.0307, 0.0305, 0.0298, 0.0307, 0.0298, 0.0295, 0.0302, 0.0298,\n",
            "        0.0297, 0.0306, 0.0298, 0.0311, 0.0297, 0.0295, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0297, 0.0310, 0.0303, 0.0296, 0.0301, 0.0298, 0.0295, 0.0302, 0.0302,\n",
            "        0.0298, 0.0306, 0.0296, 0.0311, 0.0303, 0.0296, 0.0303],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0300, 0.0319, 0.0302, 0.0298, 0.0298, 0.0301, 0.0298, 0.0303, 0.0308,\n",
            "        0.0301, 0.0305, 0.0298, 0.0314, 0.0305, 0.0298, 0.0301],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0300, 0.0312, 0.0302, 0.0298, 0.0298, 0.0301, 0.0298, 0.0302, 0.0310,\n",
            "        0.0301, 0.0304, 0.0298, 0.0303, 0.0307, 0.0298, 0.0301],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0300, 0.0312, 0.0302, 0.0298, 0.0298, 0.0300, 0.0298, 0.0302, 0.0310,\n",
            "        0.0301, 0.0300, 0.0298, 0.0303, 0.0307, 0.0298, 0.0301],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0298, 0.0312, 0.0302, 0.0298, 0.0298, 0.0300, 0.0298, 0.0301, 0.0304,\n",
            "        0.0300, 0.0300, 0.0298, 0.0303, 0.0307, 0.0298, 0.0300],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0298, 0.0312, 0.0302, 0.0298, 0.0298, 0.0300, 0.0298, 0.0300, 0.0304,\n",
            "        0.0300, 0.0300, 0.0298, 0.0303, 0.0306, 0.0298, 0.0300],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0298, 0.0312, 0.0300, 0.0298, 0.0298, 0.0300, 0.0298, 0.0300, 0.0304,\n",
            "        0.0300, 0.0300, 0.0298, 0.0301, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0298, 0.0312, 0.0297, 0.0298, 0.0298, 0.0300, 0.0298, 0.0300, 0.0304,\n",
            "        0.0300, 0.0300, 0.0298, 0.0301, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0295, 0.0312, 0.0297, 0.0295, 0.0295, 0.0297, 0.0295, 0.0297, 0.0304,\n",
            "        0.0297, 0.0297, 0.0295, 0.0297, 0.0306, 0.0296, 0.0295],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0295, 0.0309, 0.0297, 0.0295, 0.0295, 0.0297, 0.0295, 0.0298, 0.0304,\n",
            "        0.0297, 0.0297, 0.0295, 0.0298, 0.0303, 0.0296, 0.0295],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0298, 0.0310, 0.0297, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0304,\n",
            "        0.0297, 0.0298, 0.0298, 0.0298, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0298, 0.0310, 0.0300, 0.0298, 0.0298, 0.0300, 0.0298, 0.0301, 0.0304,\n",
            "        0.0300, 0.0298, 0.0298, 0.0301, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0298, 0.0310, 0.0301, 0.0298, 0.0298, 0.0300, 0.0298, 0.0301, 0.0304,\n",
            "        0.0300, 0.0298, 0.0298, 0.0301, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0298, 0.0310, 0.0301, 0.0298, 0.0298, 0.0300, 0.0298, 0.0301, 0.0304,\n",
            "        0.0300, 0.0298, 0.0298, 0.0300, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0298, 0.0310, 0.0301, 0.0298, 0.0298, 0.0300, 0.0298, 0.0301, 0.0304,\n",
            "        0.0300, 0.0298, 0.0298, 0.0300, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0298, 0.0310, 0.0301, 0.0298, 0.0298, 0.0300, 0.0298, 0.0300, 0.0304,\n",
            "        0.0300, 0.0298, 0.0298, 0.0300, 0.0306, 0.0298, 0.0298],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0275, 0.0254, 0.0274, 0.0267, 0.0268, 0.0258, 0.0284, 0.0274, 0.0269,\n",
            "        0.0270, 0.0274, 0.0266, 0.0276, 0.0269, 0.0259, 0.0258],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0288, 0.0263, 0.0285, 0.0270, 0.0278, 0.0270, 0.0284, 0.0282, 0.0268,\n",
            "        0.0272, 0.0276, 0.0266, 0.0287, 0.0275, 0.0270, 0.0260],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0276, 0.0264, 0.0280, 0.0272, 0.0275, 0.0289, 0.0282, 0.0284, 0.0279,\n",
            "        0.0274, 0.0279, 0.0274, 0.0281, 0.0282, 0.0271, 0.0263],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0270, 0.0264, 0.0284, 0.0271, 0.0272, 0.0273, 0.0282, 0.0278, 0.0279,\n",
            "        0.0270, 0.0278, 0.0274, 0.0269, 0.0282, 0.0275, 0.0264],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0270, 0.0262, 0.0277, 0.0268, 0.0268, 0.0278, 0.0275, 0.0274, 0.0264,\n",
            "        0.0266, 0.0273, 0.0270, 0.0269, 0.0278, 0.0263, 0.0266],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0268, 0.0264, 0.0265, 0.0264, 0.0264, 0.0274, 0.0263, 0.0265, 0.0264,\n",
            "        0.0264, 0.0265, 0.0271, 0.0262, 0.0271, 0.0262, 0.0271],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0264, 0.0270, 0.0268, 0.0266, 0.0267, 0.0276, 0.0265, 0.0267, 0.0265,\n",
            "        0.0265, 0.0267, 0.0267, 0.0264, 0.0267, 0.0265, 0.0274],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0267, 0.0270, 0.0271, 0.0268, 0.0267, 0.0279, 0.0271, 0.0271, 0.0266,\n",
            "        0.0268, 0.0271, 0.0268, 0.0268, 0.0267, 0.0265, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0267, 0.0270, 0.0267, 0.0268, 0.0267, 0.0276, 0.0266, 0.0269, 0.0266,\n",
            "        0.0265, 0.0269, 0.0268, 0.0266, 0.0267, 0.0265, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0267, 0.0270, 0.0267, 0.0268, 0.0264, 0.0276, 0.0266, 0.0266, 0.0266,\n",
            "        0.0265, 0.0269, 0.0268, 0.0266, 0.0267, 0.0263, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0265, 0.0270, 0.0266, 0.0265, 0.0263, 0.0275, 0.0266, 0.0266, 0.0266,\n",
            "        0.0265, 0.0267, 0.0268, 0.0266, 0.0265, 0.0263, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0263, 0.0270, 0.0266, 0.0265, 0.0263, 0.0275, 0.0266, 0.0266, 0.0266,\n",
            "        0.0265, 0.0262, 0.0261, 0.0262, 0.0263, 0.0264, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0263, 0.0270, 0.0262, 0.0261, 0.0263, 0.0271, 0.0261, 0.0262, 0.0262,\n",
            "        0.0262, 0.0262, 0.0261, 0.0262, 0.0263, 0.0264, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0263, 0.0270, 0.0262, 0.0261, 0.0263, 0.0270, 0.0261, 0.0262, 0.0261,\n",
            "        0.0262, 0.0262, 0.0261, 0.0261, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0260, 0.0270, 0.0261, 0.0261, 0.0263, 0.0274, 0.0261, 0.0266, 0.0266,\n",
            "        0.0262, 0.0266, 0.0266, 0.0261, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0260, 0.0270, 0.0266, 0.0265, 0.0263, 0.0274, 0.0266, 0.0266, 0.0266,\n",
            "        0.0266, 0.0265, 0.0266, 0.0261, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0264, 0.0270, 0.0266, 0.0266, 0.0263, 0.0274, 0.0266, 0.0265, 0.0266,\n",
            "        0.0265, 0.0265, 0.0266, 0.0265, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0263, 0.0270, 0.0266, 0.0266, 0.0263, 0.0274, 0.0266, 0.0265, 0.0266,\n",
            "        0.0265, 0.0265, 0.0266, 0.0265, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0263, 0.0270, 0.0266, 0.0266, 0.0263, 0.0274, 0.0266, 0.0265, 0.0266,\n",
            "        0.0265, 0.0265, 0.0266, 0.0261, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0263, 0.0270, 0.0262, 0.0262, 0.0263, 0.0274, 0.0266, 0.0265, 0.0262,\n",
            "        0.0261, 0.0265, 0.0261, 0.0262, 0.0263, 0.0263, 0.0267],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0471, 0.0463, 0.0464, 0.0468, 0.0468, 0.0464, 0.0464, 0.0459, 0.0501,\n",
            "        0.0464, 0.0481, 0.0472, 0.0460, 0.0486, 0.0463, 0.0459],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0473, 0.0455, 0.0466, 0.0463, 0.0472, 0.0469, 0.0470, 0.0458, 0.0474,\n",
            "        0.0463, 0.0479, 0.0467, 0.0453, 0.0467, 0.0466, 0.0461],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0468, 0.0459, 0.0470, 0.0469, 0.0475, 0.0482, 0.0475, 0.0465, 0.0474,\n",
            "        0.0468, 0.0472, 0.0466, 0.0458, 0.0474, 0.0464, 0.0464],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0461, 0.0465, 0.0475, 0.0463, 0.0477, 0.0480, 0.0475, 0.0463, 0.0471,\n",
            "        0.0472, 0.0468, 0.0469, 0.0466, 0.0472, 0.0462, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0464, 0.0464, 0.0469, 0.0464, 0.0466, 0.0476, 0.0475, 0.0466, 0.0471,\n",
            "        0.0475, 0.0468, 0.0464, 0.0466, 0.0475, 0.0467, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0464, 0.0464, 0.0464, 0.0464, 0.0466, 0.0476, 0.0466, 0.0466, 0.0471,\n",
            "        0.0469, 0.0468, 0.0464, 0.0466, 0.0467, 0.0464, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0464, 0.0464, 0.0464, 0.0464, 0.0466, 0.0469, 0.0466, 0.0466, 0.0466,\n",
            "        0.0466, 0.0468, 0.0464, 0.0465, 0.0467, 0.0464, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0461, 0.0464, 0.0461, 0.0462, 0.0466, 0.0469, 0.0466, 0.0464, 0.0466,\n",
            "        0.0466, 0.0468, 0.0462, 0.0465, 0.0467, 0.0462, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0466, 0.0467, 0.0466, 0.0462, 0.0466,\n",
            "        0.0464, 0.0468, 0.0461, 0.0465, 0.0464, 0.0462, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0466, 0.0467, 0.0465, 0.0462, 0.0466,\n",
            "        0.0464, 0.0468, 0.0461, 0.0465, 0.0464, 0.0462, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0466, 0.0467, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0468, 0.0461, 0.0465, 0.0464, 0.0462, 0.0466],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0466, 0.0466, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0461, 0.0461, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0466, 0.0466, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0461, 0.0461, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0465, 0.0466, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0461, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0461, 0.0461, 0.0461, 0.0462, 0.0465, 0.0466, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0461, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0462, 0.0462, 0.0461, 0.0462, 0.0465, 0.0465, 0.0465, 0.0461, 0.0465,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0461, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0462, 0.0462, 0.0462, 0.0461, 0.0465, 0.0465, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0461, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0462, 0.0462, 0.0462, 0.0461, 0.0465, 0.0465, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0462, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0462, 0.0462, 0.0462, 0.0461, 0.0465, 0.0465, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0462, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0461, 0.0461, 0.0462, 0.0461, 0.0465, 0.0465, 0.0465, 0.0461, 0.0466,\n",
            "        0.0461, 0.0465, 0.0461, 0.0465, 0.0462, 0.0462, 0.0465],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0441, 0.0446, 0.0445, 0.0442, 0.0453, 0.0456, 0.0439, 0.0449, 0.0472,\n",
            "        0.0446, 0.0447, 0.0468, 0.0443, 0.0454, 0.0465, 0.0467],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0443, 0.0464, 0.0455, 0.0458, 0.0470, 0.0460, 0.0450, 0.0458, 0.0466,\n",
            "        0.0458, 0.0457, 0.0472, 0.0454, 0.0461, 0.0463, 0.0460],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0439, 0.0457, 0.0445, 0.0452, 0.0451, 0.0450, 0.0445, 0.0447, 0.0460,\n",
            "        0.0445, 0.0443, 0.0458, 0.0452, 0.0457, 0.0450, 0.0452],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0447, 0.0447, 0.0450, 0.0449, 0.0454, 0.0446, 0.0444, 0.0450, 0.0452,\n",
            "        0.0441, 0.0446, 0.0461, 0.0443, 0.0456, 0.0449, 0.0454],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0447, 0.0440, 0.0449, 0.0449, 0.0455, 0.0448, 0.0445, 0.0443, 0.0450,\n",
            "        0.0444, 0.0447, 0.0447, 0.0443, 0.0456, 0.0449, 0.0446],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0455, 0.0443, 0.0455, 0.0448, 0.0457, 0.0443, 0.0447, 0.0446, 0.0453,\n",
            "        0.0444, 0.0446, 0.0450, 0.0443, 0.0452, 0.0451, 0.0450],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0457, 0.0443, 0.0458, 0.0448, 0.0446, 0.0443, 0.0447, 0.0442, 0.0444,\n",
            "        0.0444, 0.0446, 0.0450, 0.0443, 0.0446, 0.0446, 0.0444],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0464, 0.0440, 0.0462, 0.0448, 0.0446, 0.0443, 0.0444, 0.0442, 0.0444,\n",
            "        0.0441, 0.0443, 0.0450, 0.0443, 0.0446, 0.0446, 0.0444],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0457, 0.0440, 0.0457, 0.0441, 0.0443, 0.0440, 0.0444, 0.0442, 0.0444,\n",
            "        0.0441, 0.0440, 0.0443, 0.0443, 0.0446, 0.0443, 0.0444],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0454, 0.0440, 0.0450, 0.0441, 0.0443, 0.0440, 0.0441, 0.0442, 0.0444,\n",
            "        0.0441, 0.0440, 0.0440, 0.0443, 0.0446, 0.0440, 0.0443],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0448, 0.0440, 0.0450, 0.0440, 0.0443, 0.0440, 0.0440, 0.0442, 0.0444,\n",
            "        0.0441, 0.0440, 0.0440, 0.0443, 0.0443, 0.0440, 0.0443],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0448, 0.0440, 0.0450, 0.0440, 0.0440, 0.0440, 0.0440, 0.0442, 0.0444,\n",
            "        0.0440, 0.0440, 0.0440, 0.0442, 0.0443, 0.0440, 0.0443],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0448, 0.0440, 0.0450, 0.0440, 0.0440, 0.0440, 0.0440, 0.0442, 0.0444,\n",
            "        0.0440, 0.0440, 0.0440, 0.0442, 0.0443, 0.0440, 0.0443],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0448, 0.0440, 0.0449, 0.0440, 0.0440, 0.0440, 0.0440, 0.0442, 0.0444,\n",
            "        0.0440, 0.0441, 0.0440, 0.0442, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0448, 0.0440, 0.0449, 0.0440, 0.0440, 0.0440, 0.0440, 0.0443, 0.0443,\n",
            "        0.0440, 0.0441, 0.0440, 0.0442, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0448, 0.0440, 0.0449, 0.0441, 0.0440, 0.0440, 0.0440, 0.0443, 0.0442,\n",
            "        0.0440, 0.0441, 0.0440, 0.0443, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0448, 0.0441, 0.0449, 0.0441, 0.0440, 0.0440, 0.0440, 0.0443, 0.0442,\n",
            "        0.0440, 0.0441, 0.0441, 0.0443, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0448, 0.0441, 0.0449, 0.0441, 0.0440, 0.0440, 0.0440, 0.0442, 0.0442,\n",
            "        0.0440, 0.0440, 0.0441, 0.0443, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0448, 0.0440, 0.0449, 0.0441, 0.0440, 0.0440, 0.0440, 0.0442, 0.0443,\n",
            "        0.0440, 0.0440, 0.0441, 0.0443, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0448, 0.0440, 0.0449, 0.0440, 0.0440, 0.0440, 0.0440, 0.0442, 0.0443,\n",
            "        0.0440, 0.0440, 0.0441, 0.0443, 0.0442, 0.0440, 0.0442],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0270, 0.0275, 0.0272, 0.0285, 0.0269, 0.0286, 0.0276, 0.0281, 0.0288,\n",
            "        0.0272, 0.0295, 0.0269, 0.0297, 0.0274, 0.0273, 0.0277],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0271, 0.0278, 0.0274, 0.0279, 0.0272, 0.0293, 0.0285, 0.0275, 0.0278,\n",
            "        0.0273, 0.0280, 0.0270, 0.0286, 0.0269, 0.0276, 0.0270],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0267, 0.0274, 0.0275, 0.0273, 0.0268, 0.0279, 0.0280, 0.0269, 0.0278,\n",
            "        0.0269, 0.0273, 0.0270, 0.0279, 0.0269, 0.0270, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0271, 0.0275, 0.0279, 0.0269, 0.0274, 0.0273, 0.0276, 0.0272, 0.0283,\n",
            "        0.0266, 0.0279, 0.0273, 0.0274, 0.0272, 0.0267, 0.0272],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0274, 0.0270, 0.0281, 0.0273, 0.0271, 0.0276, 0.0276, 0.0272, 0.0282,\n",
            "        0.0270, 0.0274, 0.0270, 0.0276, 0.0276, 0.0270, 0.0274],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0273, 0.0272, 0.0276, 0.0272, 0.0273, 0.0276, 0.0276, 0.0272, 0.0273,\n",
            "        0.0273, 0.0274, 0.0274, 0.0279, 0.0283, 0.0273, 0.0273],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0276, 0.0270, 0.0276, 0.0272, 0.0270, 0.0276, 0.0276, 0.0276, 0.0279,\n",
            "        0.0274, 0.0277, 0.0274, 0.0276, 0.0284, 0.0273, 0.0274],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0276, 0.0270, 0.0276, 0.0272, 0.0273, 0.0272, 0.0276, 0.0276, 0.0279,\n",
            "        0.0274, 0.0274, 0.0274, 0.0276, 0.0279, 0.0273, 0.0274],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0272, 0.0270, 0.0272, 0.0268, 0.0270, 0.0270, 0.0270, 0.0274, 0.0274,\n",
            "        0.0268, 0.0268, 0.0268, 0.0272, 0.0279, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0268, 0.0269, 0.0268, 0.0271, 0.0270, 0.0270, 0.0268, 0.0270, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0270, 0.0277, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0268, 0.0269, 0.0268, 0.0271, 0.0270, 0.0270, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0270, 0.0274, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0268, 0.0269, 0.0268, 0.0271, 0.0269, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0274, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0268, 0.0269, 0.0269, 0.0271, 0.0269, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0274, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0268, 0.0269, 0.0269, 0.0268, 0.0269, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0273, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0268, 0.0269, 0.0269, 0.0268, 0.0270, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0273, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0268, 0.0269, 0.0268, 0.0268, 0.0270, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0273, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0268, 0.0270, 0.0268, 0.0268, 0.0270, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0277, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0268, 0.0270, 0.0268, 0.0268, 0.0269, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0277, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0268, 0.0270, 0.0268, 0.0268, 0.0269, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0273, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0268, 0.0270, 0.0268, 0.0268, 0.0269, 0.0268, 0.0268, 0.0268, 0.0268,\n",
            "        0.0268, 0.0268, 0.0268, 0.0268, 0.0273, 0.0268, 0.0268],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0175, 0.0186, 0.0184, 0.0178, 0.0181, 0.0194, 0.0193, 0.0173, 0.0188,\n",
            "        0.0185, 0.0189, 0.0182, 0.0182, 0.0182, 0.0187, 0.0203],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0185, 0.0192, 0.0186, 0.0179, 0.0186, 0.0191, 0.0197, 0.0179, 0.0191,\n",
            "        0.0194, 0.0190, 0.0183, 0.0191, 0.0192, 0.0182, 0.0204],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0188, 0.0192, 0.0197, 0.0187, 0.0185, 0.0193, 0.0201, 0.0185, 0.0190,\n",
            "        0.0194, 0.0195, 0.0188, 0.0195, 0.0191, 0.0190, 0.0201],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0194, 0.0186, 0.0203, 0.0189, 0.0187, 0.0196, 0.0195, 0.0183, 0.0191,\n",
            "        0.0191, 0.0191, 0.0190, 0.0196, 0.0191, 0.0188, 0.0198],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0192, 0.0184, 0.0201, 0.0188, 0.0186, 0.0192, 0.0189, 0.0188, 0.0193,\n",
            "        0.0185, 0.0189, 0.0191, 0.0197, 0.0184, 0.0189, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0192, 0.0184, 0.0188, 0.0185, 0.0186, 0.0189, 0.0190, 0.0184, 0.0187,\n",
            "        0.0185, 0.0186, 0.0193, 0.0194, 0.0186, 0.0186, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0186, 0.0184, 0.0186, 0.0185, 0.0186, 0.0189, 0.0187, 0.0184, 0.0187,\n",
            "        0.0183, 0.0184, 0.0194, 0.0189, 0.0186, 0.0186, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0186, 0.0184, 0.0186, 0.0185, 0.0186, 0.0189, 0.0183, 0.0184, 0.0185,\n",
            "        0.0183, 0.0184, 0.0194, 0.0189, 0.0186, 0.0186, 0.0190],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0186, 0.0184, 0.0189, 0.0188, 0.0186, 0.0186, 0.0183, 0.0183, 0.0185,\n",
            "        0.0183, 0.0184, 0.0189, 0.0188, 0.0186, 0.0186, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0186, 0.0183, 0.0189, 0.0186, 0.0186, 0.0186, 0.0186, 0.0183, 0.0185,\n",
            "        0.0186, 0.0187, 0.0188, 0.0185, 0.0184, 0.0184, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0186, 0.0183, 0.0187, 0.0186, 0.0185, 0.0186, 0.0186, 0.0183, 0.0184,\n",
            "        0.0186, 0.0186, 0.0188, 0.0185, 0.0183, 0.0183, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0186, 0.0183, 0.0187, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0186, 0.0186, 0.0186, 0.0183, 0.0183, 0.0183, 0.0187],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0187, 0.0183, 0.0187, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0186, 0.0186, 0.0186, 0.0183, 0.0183, 0.0182, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0187, 0.0183, 0.0187, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0186, 0.0186, 0.0186, 0.0183, 0.0183, 0.0182, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0184, 0.0183, 0.0186, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0183, 0.0186, 0.0186, 0.0183, 0.0183, 0.0183, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0184, 0.0183, 0.0186, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0183, 0.0183, 0.0186, 0.0182, 0.0183, 0.0183, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0186, 0.0183, 0.0186, 0.0183, 0.0183, 0.0183, 0.0183, 0.0183, 0.0183,\n",
            "        0.0183, 0.0183, 0.0186, 0.0182, 0.0183, 0.0183, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0186, 0.0183, 0.0186, 0.0186, 0.0183, 0.0183, 0.0183, 0.0183, 0.0183,\n",
            "        0.0186, 0.0186, 0.0186, 0.0182, 0.0183, 0.0183, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0186, 0.0183, 0.0186, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0186, 0.0186, 0.0186, 0.0182, 0.0183, 0.0183, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0186, 0.0183, 0.0186, 0.0186, 0.0183, 0.0183, 0.0186, 0.0183, 0.0183,\n",
            "        0.0186, 0.0186, 0.0186, 0.0182, 0.0183, 0.0183, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0183, 0.0183, 0.0181, 0.0173, 0.0186, 0.0177, 0.0188, 0.0188, 0.0204,\n",
            "        0.0177, 0.0177, 0.0193, 0.0183, 0.0192, 0.0179, 0.0202],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0184, 0.0187, 0.0181, 0.0178, 0.0188, 0.0184, 0.0195, 0.0195, 0.0187,\n",
            "        0.0184, 0.0181, 0.0196, 0.0188, 0.0201, 0.0181, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0188, 0.0181, 0.0183, 0.0175, 0.0187, 0.0187, 0.0193, 0.0199, 0.0190,\n",
            "        0.0184, 0.0179, 0.0201, 0.0190, 0.0184, 0.0185, 0.0191],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0187, 0.0183, 0.0186, 0.0177, 0.0189, 0.0191, 0.0192, 0.0198, 0.0190,\n",
            "        0.0187, 0.0181, 0.0194, 0.0183, 0.0183, 0.0181, 0.0193],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0187, 0.0184, 0.0182, 0.0178, 0.0189, 0.0184, 0.0189, 0.0189, 0.0187,\n",
            "        0.0183, 0.0181, 0.0190, 0.0178, 0.0184, 0.0182, 0.0193],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0179, 0.0184, 0.0183, 0.0179, 0.0184, 0.0185, 0.0182, 0.0186, 0.0186,\n",
            "        0.0183, 0.0182, 0.0185, 0.0179, 0.0183, 0.0180, 0.0184],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0179, 0.0180, 0.0179, 0.0180, 0.0183, 0.0185, 0.0182, 0.0186, 0.0186,\n",
            "        0.0183, 0.0179, 0.0185, 0.0179, 0.0183, 0.0180, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0179, 0.0180, 0.0179, 0.0180, 0.0180, 0.0185, 0.0182, 0.0186, 0.0184,\n",
            "        0.0181, 0.0179, 0.0185, 0.0179, 0.0182, 0.0180, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0179, 0.0180, 0.0181, 0.0182, 0.0180, 0.0182, 0.0184, 0.0182, 0.0184,\n",
            "        0.0181, 0.0181, 0.0184, 0.0181, 0.0180, 0.0182, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0179, 0.0180, 0.0181, 0.0181, 0.0179, 0.0182, 0.0182, 0.0182, 0.0182,\n",
            "        0.0181, 0.0180, 0.0183, 0.0180, 0.0180, 0.0181, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0180, 0.0181, 0.0180, 0.0181, 0.0180, 0.0182, 0.0182, 0.0182, 0.0182,\n",
            "        0.0181, 0.0180, 0.0183, 0.0180, 0.0180, 0.0180, 0.0183],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0180, 0.0181, 0.0180, 0.0181, 0.0180, 0.0180, 0.0181, 0.0184, 0.0184,\n",
            "        0.0183, 0.0180, 0.0183, 0.0180, 0.0180, 0.0180, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0180, 0.0181, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0184, 0.0183,\n",
            "        0.0183, 0.0180, 0.0183, 0.0181, 0.0180, 0.0180, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0180, 0.0181, 0.0178, 0.0178, 0.0180, 0.0178, 0.0178, 0.0184, 0.0183,\n",
            "        0.0183, 0.0178, 0.0183, 0.0178, 0.0180, 0.0178, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0180, 0.0181, 0.0178, 0.0178, 0.0180, 0.0178, 0.0178, 0.0184, 0.0183,\n",
            "        0.0183, 0.0178, 0.0183, 0.0178, 0.0180, 0.0178, 0.0181],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0180, 0.0180, 0.0178, 0.0178, 0.0180, 0.0178, 0.0178, 0.0181, 0.0181,\n",
            "        0.0181, 0.0178, 0.0181, 0.0178, 0.0178, 0.0178, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0181, 0.0181,\n",
            "        0.0181, 0.0178, 0.0181, 0.0178, 0.0178, 0.0178, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0181, 0.0181,\n",
            "        0.0181, 0.0178, 0.0181, 0.0178, 0.0178, 0.0178, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0178, 0.0178, 0.0180, 0.0180, 0.0178, 0.0180, 0.0181, 0.0181, 0.0181,\n",
            "        0.0181, 0.0180, 0.0181, 0.0181, 0.0178, 0.0181, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0178, 0.0178, 0.0180, 0.0180, 0.0178, 0.0180, 0.0181, 0.0181, 0.0181,\n",
            "        0.0181, 0.0180, 0.0181, 0.0181, 0.0178, 0.0181, 0.0178],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "0 tensor([0.0654, 0.0645, 0.0667, 0.0629, 0.0651, 0.0651, 0.0645, 0.0650, 0.0654,\n",
            "        0.0643, 0.0659, 0.0633, 0.0649, 0.0666, 0.0656, 0.0662],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "1 tensor([0.0648, 0.0649, 0.0654, 0.0631, 0.0654, 0.0646, 0.0654, 0.0652, 0.0658,\n",
            "        0.0642, 0.0645, 0.0636, 0.0634, 0.0670, 0.0654, 0.0669],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "2 tensor([0.0658, 0.0646, 0.0666, 0.0639, 0.0656, 0.0655, 0.0651, 0.0660, 0.0657,\n",
            "        0.0644, 0.0649, 0.0645, 0.0643, 0.0662, 0.0660, 0.0654],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "3 tensor([0.0649, 0.0650, 0.0663, 0.0648, 0.0654, 0.0663, 0.0645, 0.0656, 0.0661,\n",
            "        0.0651, 0.0645, 0.0651, 0.0649, 0.0656, 0.0656, 0.0656],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "4 tensor([0.0653, 0.0650, 0.0652, 0.0652, 0.0660, 0.0651, 0.0646, 0.0646, 0.0660,\n",
            "        0.0654, 0.0652, 0.0657, 0.0654, 0.0654, 0.0660, 0.0655],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "5 tensor([0.0649, 0.0646, 0.0650, 0.0659, 0.0666, 0.0646, 0.0646, 0.0646, 0.0654,\n",
            "        0.0660, 0.0660, 0.0659, 0.0658, 0.0650, 0.0657, 0.0649],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "6 tensor([0.0649, 0.0646, 0.0650, 0.0659, 0.0660, 0.0646, 0.0646, 0.0646, 0.0650,\n",
            "        0.0661, 0.0660, 0.0659, 0.0659, 0.0646, 0.0652, 0.0649],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "7 tensor([0.0646, 0.0646, 0.0650, 0.0659, 0.0660, 0.0646, 0.0647, 0.0646, 0.0649,\n",
            "        0.0661, 0.0660, 0.0659, 0.0659, 0.0646, 0.0652, 0.0648],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "8 tensor([0.0646, 0.0646, 0.0650, 0.0659, 0.0661, 0.0646, 0.0647, 0.0646, 0.0649,\n",
            "        0.0661, 0.0660, 0.0659, 0.0659, 0.0646, 0.0646, 0.0648],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "9 tensor([0.0646, 0.0646, 0.0648, 0.0659, 0.0661, 0.0646, 0.0647, 0.0646, 0.0649,\n",
            "        0.0661, 0.0660, 0.0659, 0.0659, 0.0646, 0.0647, 0.0648],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "10 tensor([0.0646, 0.0646, 0.0648, 0.0659, 0.0661, 0.0646, 0.0646, 0.0646, 0.0646,\n",
            "        0.0659, 0.0660, 0.0660, 0.0659, 0.0646, 0.0647, 0.0648],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "11 tensor([0.0646, 0.0646, 0.0646, 0.0660, 0.0661, 0.0646, 0.0646, 0.0645, 0.0646,\n",
            "        0.0659, 0.0659, 0.0660, 0.0659, 0.0646, 0.0647, 0.0648],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "12 tensor([0.0646, 0.0646, 0.0645, 0.0660, 0.0660, 0.0646, 0.0646, 0.0645, 0.0646,\n",
            "        0.0659, 0.0659, 0.0660, 0.0659, 0.0646, 0.0647, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "13 tensor([0.0646, 0.0646, 0.0645, 0.0660, 0.0660, 0.0646, 0.0646, 0.0645, 0.0646,\n",
            "        0.0659, 0.0659, 0.0660, 0.0659, 0.0646, 0.0647, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "14 tensor([0.0646, 0.0646, 0.0645, 0.0660, 0.0660, 0.0646, 0.0647, 0.0645, 0.0646,\n",
            "        0.0659, 0.0659, 0.0661, 0.0659, 0.0646, 0.0646, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "15 tensor([0.0646, 0.0646, 0.0645, 0.0659, 0.0660, 0.0646, 0.0647, 0.0645, 0.0646,\n",
            "        0.0660, 0.0659, 0.0661, 0.0659, 0.0647, 0.0646, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "16 tensor([0.0646, 0.0646, 0.0645, 0.0659, 0.0660, 0.0646, 0.0647, 0.0645, 0.0646,\n",
            "        0.0660, 0.0659, 0.0660, 0.0659, 0.0647, 0.0646, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "17 tensor([0.0646, 0.0646, 0.0645, 0.0659, 0.0660, 0.0646, 0.0647, 0.0646, 0.0646,\n",
            "        0.0660, 0.0659, 0.0660, 0.0659, 0.0647, 0.0646, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "18 tensor([0.0646, 0.0646, 0.0645, 0.0659, 0.0660, 0.0646, 0.0646, 0.0646, 0.0647,\n",
            "        0.0660, 0.0659, 0.0660, 0.0661, 0.0647, 0.0646, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "19 tensor([0.0646, 0.0647, 0.0645, 0.0659, 0.0659, 0.0646, 0.0646, 0.0646, 0.0647,\n",
            "        0.0660, 0.0659, 0.0660, 0.0661, 0.0647, 0.0646, 0.0645],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "dided\n",
            "time\n",
            "[7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 4, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 4, 4, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 4, 4, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 4, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 4, 4, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 4, 7, 7, 4, 4, 4, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 4, 4, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 4, 4, 7, 4, 7, 7, 7, 4, 4, 7, 7, 4, 4, 7, 7, 4, 7, 7, 7, 4, 7, 4, 7, 4, 7, 7, 7, 4, 7, 7, 7]\n",
            "19 #### train ####\n",
            "repr, std, cov, closs 0.007134936284273863 0.47705078125 0.0006988130044192076 0.7016483545303345\n",
            "0.07360077906898146 0.1005852639551643 1.0\n",
            "repr, std, cov, closs 0.007611851207911968 0.477294921875 0.0009027230553328991 0.3680996894836426\n",
            "0.07345379801914517 0.10129147661740026 1.0\n",
            "repr, std, cov, closs 0.007879780605435371 0.475830078125 0.0009250105358660221 0.6526530385017395\n",
            "0.07265063325712495 0.10018392674379283 1.0\n",
            "repr, std, cov, closs 0.008323601447045803 0.47509765625 0.0011230658274143934 0.7435885071754456\n",
            "0.07156954265329739 0.09780930895018489 1.0\n",
            "repr, std, cov, closs 0.007853485643863678 0.475341796875 0.0009220156352967024 0.3383273184299469\n",
            "0.0705750439489103 0.09568205317328685 1.0\n",
            "repr, std, cov, closs 0.0076822200790047646 0.4755859375 0.0009364516008645296 0.6711649894714355\n",
            "0.069733622681663 0.09378835883384042 1.0\n",
            "repr, std, cov, closs 0.008360326290130615 0.475830078125 0.0008927553426474333 0.7845474481582642\n",
            "0.06966395872294007 0.09294846865170907 1.0\n",
            "repr, std, cov, closs 0.008342850022017956 0.47607421875 0.0008349872659891844 0.6643778085708618\n",
            "0.07029344811451949 0.09444685018708987 1.0\n",
            "repr, std, cov, closs 0.008276322856545448 0.477294921875 0.0007157174404710531 0.6205463409423828\n",
            "0.07099955425082287 0.09673983409027549 1.0\n",
            "repr, std, cov, closs 0.007236572913825512 0.476318359375 0.000789253506809473 0.744421660900116\n",
            "0.0706456189928592 0.09577773522646012 1.0\n",
            "repr, std, cov, closs 0.007994464598596096 0.4755859375 0.0011135356035083532 0.8479061126708984\n",
            "0.07022322488962986 0.09425823944995053 1.0\n",
            "repr, std, cov, closs 0.007521206513047218 0.474853515625 0.0011182092130184174 0.7625037431716919\n",
            "0.06994303282030964 0.09294846865170907 1.0\n",
            "repr, std, cov, closs 0.006845270749181509 0.478271484375 0.0005925344303250313 0.8469687700271606\n",
            "0.0707869808764639 0.09510996483120072 1.0\n",
            "repr, std, cov, closs 0.006671147886663675 0.47802734375 0.0005503888241946697 0.5483944416046143\n",
            "0.07178446606145476 0.09751646690256006 1.0\n",
            "repr, std, cov, closs 0.006382168736308813 0.477783203125 0.0006563246715813875 0.43113240599632263\n",
            "0.07286880318144671 0.09978419087590745 1.0\n",
            "repr, std, cov, closs 0.0064295819029212 0.47998046875 0.0003763095010071993 0.7867477536201477\n",
            "0.07404348922820136 0.1023089616762959 1.0\n",
            "repr, std, cov, closs 0.007788397371768951 0.478271484375 0.0006024190224707127 0.7165566682815552\n",
            "0.07501185120980212 0.10468813406072446 1.0\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "for i in range(30):\n",
        "    # # buffer=[]\n",
        "    # print(\"#### simulate ####\")\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n",
        "\n",
        "    # state = buffer[7][80][0]\n",
        "    # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    # out= agent.deconv(sx_).squeeze(0)\n",
        "    # # print(out.shape)\n",
        "    # imshow(state.detach().cpu())\n",
        "    # imshow(out.detach().cpu())\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len)\n",
        "    train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    c_loader = make_weighted(buffer)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    # train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksm4ha7XA-BN"
      },
      "outputs": [],
      "source": [
        "# print(optim.param_groups[0][\"lr\"])\n",
        "optim.param_groups[0][\"lr\"] = 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "b8zxYU9jpE8K",
        "outputId": "829c629a-1940-47c5-c470-2b6cc8eb6118"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "256c75e8-e0c1-446e-a588-6de3dee18e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wandb/analytics/sentry.py:90: SentryHubDeprecationWarning: `sentry_sdk.Hub` is deprecated and will be removed in a future major release. Please consult our 1.x to 2.x migration guide for details on how to migrate `Hub` usage to the new API: https://docs.sentry.io/platforms/python/migration/1.x-to-2.x\n",
            "  self.hub = sentry_sdk.Hub(client)\n",
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240902_034119-3gthhome</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/3gthhome' target=\"_blank\">smooth-elevator-27</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/3gthhome' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/3gthhome</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(\n",
        "    project=\"procgen\",\n",
        "    config={\n",
        "        \"model\": \"res18\",\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xLh80kPvEzwX"
      },
      "outputs": [],
      "source": [
        "# @title agent pixel save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.emb = torch.nn.Embedding(15, dim_a) # env.action_space # 15\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        for i in range(20): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "\n",
        "            dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "\n",
        "            # loss, sx_ = self.rnn_pred(sx_, x)\n",
        "            loss, sx_ = self.rnn_pred(sx_, x_)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(syaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb #+ clossl\n",
        "\n",
        "                    loss = loss + jloss + closs #+ conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sy_ = sy_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29O1eyvhnRSD",
        "outputId": "c470e601-d5da-4b94-bb69-928dd9d823af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-77-bbc83a6aed37>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=2. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        # 0.0083 0.06 1.0 = 1, 7, 120.5\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        optim_z = torch.optim.SGD([z], lr=1e2, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.95)) #\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.data)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i,x.data, z.squeeze(), loss.item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        # print(\"search\",loss.item())\n",
        "        return lact#, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        _,T,_ = sx.shape\n",
        "        batch = 1\n",
        "        lr = 1e-1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                x[:,:self.lx.shape[1]] = self.lx[:,:T]\n",
        "                z[:,:self.lz.shape[1]] = self.lz[:,:T]\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            # print(i,x.data, z.squeeze(), loss.item())\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        return lact, lh0, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, gamma=0.9): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sx = self.jepa.pred(sxaz)\n",
        "                sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        # if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            # loss=0\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(syaz)\n",
        "                    sy_ = sy_ + self.jepa.pred(syaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # cost loss\n",
        "                    reward_ = self.tcost(sy_).squeeze(-1) # [batch_size]\n",
        "                    clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    _, st = self.get(st, world_state=world_zero)\n",
        "                    # print(\"stt\",st.shape)\n",
        "                    stt = self.tcost(self.jepa.enc(st.unsqueeze(1))).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb + clossl\n",
        "\n",
        "                    # loss = loss + jloss + closs\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    # loss=0\n",
        "                else:\n",
        "                    scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*4 -2\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*3 -1.5\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "    # def argm(self, sx, a, lr=3e3): # 3e3\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "    #     optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    #     # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    #     sx, a = sx.detach(), a.detach()\n",
        "    #     for i in range(5): # 10\n",
        "    #         sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #         with torch.amp.autocast('cuda'):\n",
        "    #             # sx_ = self.jepa.pred(sxaz)\n",
        "    #             sx_ = sx + self.jepa.pred(sxaz)\n",
        "    #             cost = -self.tcost(sx_)\n",
        "\n",
        "    #         cost.backward()\n",
        "    #         optim.step()\n",
        "    #         # scaler.scale(cost).backward()\n",
        "    #         # scaler.step(optim)\n",
        "    #         # scaler.update()\n",
        "    #         optim.zero_grad()\n",
        "    #         with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "    #         print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def argm(self, sx, lr=3e3): # 3e3\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch_size, T, _ = sx.shape\n",
        "        batch = 16\n",
        "        # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "        z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "        optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "        sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "        # sx = sx.detach()\n",
        "        for i in range(20): # 10\n",
        "            # print(sx.shape,z.shape)\n",
        "            sxz = torch.cat([sx, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                cost = model(sxz)\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "            # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "            # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        # return z.detach()\n",
        "        # print(\"argm z\",z.squeeze().data)\n",
        "        # print(\"cost\",cost.squeeze())\n",
        "        idx = torch.argmax(loss)\n",
        "        # return z[idx].detach().unsqueeze(0)\n",
        "        return z[:,idx].detach()\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch=1\n",
        "        T=1\n",
        "        x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "\n",
        "        lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "        # ratio = 6e0\n",
        "        lr = 1e-1 # adamw 1e-1\n",
        "        ratio = 4\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        # optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze())\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "        for i in range(50):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            z = argm(x)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "            # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "            # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                x.clamp_(min=-1, max=1)\n",
        "            # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "        idx = torch.argmax(loss)\n",
        "        print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "outputs": [],
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.amp.autocast('cuda'):\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjm2kV3H7ZVR"
      },
      "outputs": [],
      "source": [
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad))\n",
        "for name, p in agent.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(name, p.numel())\n",
        "\n",
        "\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcOidvtW9KAH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title from RNN2\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, h0=None, c0=None): # [batch_size, seq_len, input_size]\n",
        "        if h0 is None: h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        if c0 is None: c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        out, h0 = self.rnn(x, h0)\n",
        "        # out, (h0,c0) = self.lstm(x, (h0,c0))\n",
        "        # out:(batch_size, seq_length, hidden_size) (n, 28, 128)\n",
        "        out = out[:, -1, :] # out: (n, 128)\n",
        "        out = self.fc(out) # out: (n, 10)\n",
        "        return out\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "\n",
        "d_model,dim_a,dim_z = 256,3,1\n",
        "pred = nn.Sequential(\n",
        "    nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model),\n",
        "    )\n",
        "gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "\n",
        "print(sum(p.numel() for p in pred.parameters() if p.requires_grad)) # 264192\n",
        "print(sum(p.numel() for p in gru.parameters() if p.requires_grad)) # 397824\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AodVas3L4ZS",
        "outputId": "f1940ab6-b72d-4c8d-f97d-6d876f1b92e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 256])\n",
            "136960\n",
            "136960\n"
          ]
        }
      ],
      "source": [
        "# @title efficientnet\n",
        "# https://arxiv.org/pdf/2207.10318 # visualise kernal\n",
        "\n",
        "# https://pytorch.org/hub/research-models\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/shufflenetv2.py\n",
        "\n",
        "import torch\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py\n",
        "from torchvision.models.efficientnet import *\n",
        "from torchvision.models import efficientnet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # https://arxiv.org/pdf/2104.00298\n",
        "# Stage Operator Stride #Channels #Layers\n",
        "# 0 Conv3x3 2 24 1\n",
        "# 1 Fused-MBConv1, k3x3 1 24 2\n",
        "# 2 Fused-MBConv4, k3x3 2 48 4\n",
        "# 3 Fused-MBConv4, k3x3 2 64 4\n",
        "# 4 MBConv4, k3x3, SE0.25 2 128 6\n",
        "# 5 MBConv6, k3x3, SE0.25 1 160 9\n",
        "# 6 MBConv6, k3x3, SE0.25 2 256 15\n",
        "# 7 Conv1x1 & Pooling & FC - 1280 1\n",
        "\n",
        "# # elif arch.startswith(\"efficientnet_v2_s\"):\n",
        "# inverted_residual_setting = [\n",
        "#     FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
        "#     FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
        "#     FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
        "#     MBConvConfig(4, 3, 2, 64, 128, 6),\n",
        "#     MBConvConfig(6, 3, 1, 128, 160, 9),\n",
        "#     MBConvConfig(6, 3, 2, 160, 256, 15),\n",
        "# ]\n",
        "# last_channel = 1280\n",
        "\n",
        "# d_list=[24, 48, 64, 128, 160, 256] #\n",
        "d_list=[16, 32, 48, 96, 108, 172] #\n",
        "inverted_residual_setting = [\n",
        "    efficientnet.FusedMBConvConfig(1, 3, 1, d_list[0], d_list[0], 2),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[0], d_list[1], 4),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[1], d_list[2], 4),\n",
        "    efficientnet.MBConvConfig(4, 3, 2, d_list[2], d_list[3], 6),\n",
        "    efficientnet.MBConvConfig(6, 3, 1, d_list[3], d_list[4], 9),\n",
        "    efficientnet.MBConvConfig(6, 3, 2, d_list[4], d_list[5], 15),\n",
        "]\n",
        "last_channel = 512\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "\n",
        "effnet = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "effnet.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "\n",
        "#   (features): Sequential(\n",
        "#     (0): Conv2dNormActivation(\n",
        "#       (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "#       (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "#       (2): SiLU(inplace=True)\n",
        "\n",
        "input = torch.rand((1,1,256,256), device=device)\n",
        "out = effnet(input)\n",
        "print(out.shape)\n",
        "# print(effnet)\n",
        "print(sum(p.numel() for p in effnet.parameters() if p.requires_grad)) #\n",
        "print(sum(p.numel() for p in effnet.parameters())) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "# !pip install -qq vector-quantize-pytorch\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LK5u500Vad2P"
      },
      "outputs": [],
      "source": [
        "# @title FSQ jax\n",
        "# https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "Codeword = jax.Array\n",
        "Indices = jax.Array\n",
        "\n",
        "def round_ste(z):\n",
        "  \"\"\"Round with straight through gradients.\"\"\"\n",
        "  zhat = jnp.round(z)\n",
        "  return z + jax.lax.stop_gradient(zhat - z)\n",
        "\n",
        "class FSQ:\n",
        "  \"\"\"Quantizer.\"\"\"\n",
        "  def __init__(self, levels: list[int], eps: float = 1e-3):\n",
        "    self._levels = levels\n",
        "    self._eps = eps\n",
        "    self._levels_np = np.asarray(levels)\n",
        "    self._basis = np.concatenate(([1], np.cumprod(self._levels_np[:-1]))).astype(np.uint32)\n",
        "    self._implicit_codebook = self.indexes_to_codes(np.arange(self.codebook_size))\n",
        "    print(\"self._basis\",self._basis)\n",
        "    print(\"self._implicit_codebook\",self._implicit_codebook)\n",
        "\n",
        "  @property\n",
        "  def num_dimensions(self):\n",
        "    \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
        "    return len(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook_size(self):\n",
        "    \"\"\"Size of the codebook.\"\"\"\n",
        "    return np.prod(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook(self):\n",
        "    \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
        "    return self._implicit_codebook\n",
        "\n",
        "  def bound(self, z: jax.Array) -> jax.Array:\n",
        "    \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "    half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
        "    offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
        "    shift = jnp.tan(offset / half_l)\n",
        "    return jnp.tanh(z + shift) * half_l - offset\n",
        "\n",
        "  def quantize(self, z: jax.Array) -> Codeword:\n",
        "    \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
        "    quantized = round_ste(self.bound(z))\n",
        "\n",
        "    # Renormalize to [-1, 1].\n",
        "    half_width = self._levels_np // 2\n",
        "    return quantized / half_width\n",
        "\n",
        "  def _scale_and_shift(self, zhat_normalized):\n",
        "    # Scale and shift to range [0, ..., L-1]\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "  def _scale_and_shift_inverse(self, zhat):\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat - half_width) / half_width\n",
        "\n",
        "  def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
        "    \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
        "    assert zhat.shape[-1] == self.num_dimensions\n",
        "    zhat = self._scale_and_shift(zhat)\n",
        "    return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
        "\n",
        "  def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
        "    \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
        "    indices = indices[..., jnp.newaxis]\n",
        "    print(indices, self._basis, self._levels_np)\n",
        "    print(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    codes_non_centered = np.mod(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    return self._scale_and_shift_inverse(codes_non_centered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xHxv7ptuwVHX"
      },
      "outputs": [],
      "source": [
        "# @title FSQ torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module): # https://colab.research.google.com/github/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "    def __init__(self, levels, eps = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cat([torch.ones(1, device=device), torch.cumprod(self.levels[:-1], dim=0)]).long()\n",
        "        self.num_dimensions = len(levels)\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        # self.mean = self.codebook.mean(dim=0)\n",
        "        # self.max = self.codebook.max(dim=0).values\n",
        "        # self.min = self.codebook.min(dim=0).values\n",
        "\n",
        "    def bound(self, z):\n",
        "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "        half_l = (self.levels - 1) * (1 - self.eps) / 2 # [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "        # half_l = (self.levels-1)/2 # me ?\n",
        "        offset = torch.where(self.levels % 2 == 1, 0.0, 0.5) # [0.0000, 0.0000, 0.5000] mean?\n",
        "        # print(\"half_l\", half_l)\n",
        "        # shift = torch.tan(offset / half_l) # [0.0000, 0.0000, 1.5608] < tan(1)\n",
        "\n",
        "        # print(\"shift\", shift)\n",
        "        # print(\"bound\", torch.tanh(z + shift) * half_l - offset)\n",
        "\n",
        "        # print(f'half_l {half_l}, shift {shift}, bound {torch.tanh(z + shift) * half_l - offset}')\n",
        "        # return torch.tanh(z + shift) * half_l - offset\n",
        "        # return torch.tanh(z - shift) * half_l + offset\n",
        "        return torch.tanh(z) * half_l + offset\n",
        "\n",
        "    def forward(self, z):\n",
        "        quantized = ste_round(self.bound(z))\n",
        "        # print(\"quantized\", quantized)\n",
        "        half_width = self.levels // 2 # Renormalize to [-1, 1]\n",
        "        return quantized / half_width\n",
        "\n",
        "    def _scale_and_shift(self, zhat_normalized): # Scale and shift to range [0, ..., L-1]\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "    def _scale_and_shift_inverse(self, zhat):\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat - half_width) / half_width\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        assert zhat.shape[-1] == self.num_dimensions\n",
        "        zhat = self._scale_and_shift(zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).long()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes_non_centered = torch.fmod(indices // self.basis, self.levels)\n",
        "        return self._scale_and_shift_inverse(codes_non_centered)\n",
        "\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "# print(fsq.codebook)\n",
        "\n",
        "# batch_size, seq_len = 1, 1\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SnfcKPses5X",
        "outputId": "7c50a3e3-281a-4375-b86f-ece58f6775c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "half_l tensor([0.9990, 0.9990, 0.4995]), shift tensor([0.0000, 0.0000, 1.5608]), bound tensor([-0.4617,  0.5365, -0.0515])\n",
            "quantized tensor([0., 1., 0.])\n",
            "tensor([0., 1., 0.])\n"
          ]
        }
      ],
      "source": [
        "# @title test fsq\n",
        "fsq = FSQ(levels = [4])\n",
        "\n",
        "# 2: 1.6 half_l tensor([0.4995]), shift tensor([1.5608]), bound tensor([-0.5195])\n",
        "# 3: 0.6 # half_l tensor([0.9990]), shift tensor([0.]), bound tensor([-0.9207])\n",
        "# 4: 0.4, 1.3 # half_l tensor([1.4985]), shift tensor([0.3466]), bound tensor([-1.7726])\n",
        "# 5: 0.5, 1 # half_l [1.9980], shift [0.], bound [-1.8415]\n",
        "x = torch.tensor([.9],device=device)\n",
        "# x = torch.tensor([-1.6],device=device)\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.tensor([-0.6,0.6,-1.6],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,-1.5],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,1.6],device=device)\n",
        "x = torch.tensor([-0.5,0.6,-0.1],device=device)\n",
        "\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "round emb\n",
        "\n",
        "# half_l [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "# offset [0.0000, 0.0000, 0.5000] mean?\n",
        "# shift [0.0000, 0.0000, 1.5608] torch.tan(offset / half_l)\n",
        "# bound [-0.5365,  0.5365, -0.4696] tanh(z + shift) * half_l - offset\n",
        "\n",
        "\n",
        "\n",
        "levels = torch.tensor([3,3,2])\n",
        "eps = 1e-3\n",
        "\n",
        "half_l = (levels - 1) * (1 - eps) / 2\n",
        "offset = torch.where(levels % 2 == 1, 0.0, 0.5)\n",
        "# print(\"half_l\", half_l)\n",
        "shift = torch.tan(offset / half_l)\n",
        "# print(\"shift\", shift)\n",
        "# print(\"bound\", torch.tanh(x + shift) * half_l - offset)\n",
        "# return torch.tanh(x + shift) * half_l - offset\n",
        "out = torch.tanh(x) * half_l + offset\n",
        "print(out)\n",
        "\n",
        "shift=torch.tan(torch.tensor([1.]))\n",
        "print(shift)\n",
        "bound = torch.tanh(x - shift)\n",
        "print(bound)\n",
        "\n",
        "print(torch.tanh(torch.tensor([0.])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_VgsenYLpM",
        "outputId": "8c7b23ae-8cdb-4846-dae3-32fd046a4d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[0.0437, 0.3097, 0.4537]]], requires_grad=True)\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n"
          ]
        }
      ],
      "source": [
        "# @title test rnn_pred symlog\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "# fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # xx = fsq(x)\n",
        "    # xx = fsq(x.clone())\n",
        "    # print(xx)\n",
        "    # x = torch.tanh(x)\n",
        "    # loss = x.sum()\n",
        "    # loss = model(xx)\n",
        "    loss = model(x)\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    # x = torch.clamp(x, min=-1, max=1)\n",
        "    # x = torch.clamp(x.clone(), min=-1, max=1)\n",
        "    with torch.no_grad():\n",
        "        # x.clamp_(min=-1, max=1)\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # model = nn.Sequential(nn.Linear(3,1))\n",
        "# model = nn.Sequential(nn.Linear(3*2,1))\n",
        "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# batch_size = 1\n",
        "# seq_len = 3\n",
        "# x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# # torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "\n",
        "# def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "#     batch, seq_len, dim_a = la.shape\n",
        "#     cost = 0\n",
        "#     lsx=sx\n",
        "#     for t in range(seq_len): # simple single layer\n",
        "#         a = la[:,t] # [1, dim_a]\n",
        "#         sxaz = torch.cat([sx, a], dim=-1)\n",
        "#         # with torch.amp.autocast('cuda'):\n",
        "#         cost = cost + model(sxaz)\n",
        "#         lsx = torch.cat([lsx, sx], dim=0)\n",
        "#     return cost, sx\n",
        "\n",
        "\n",
        "# # def ste_clamp(input, min=-1, max=1):\n",
        "# #     clamped_output = torch.clamp(input, min, max)\n",
        "# #     clamp_mask = (input < min) | (input > max)\n",
        "# #     return torch.where(clamp_mask, input, clamped_output)\n",
        "\n",
        "# def ste_clamp(x, min=-1, max=1):\n",
        "#     return torch.clamp(x, min, max).detach() + x - x.detach()\n",
        "\n",
        "# def ste_abs(x): return x.sign() * x\n",
        "# def symlog(x): return torch.sign(x) * torch.log(ste_abs(x) + 1.0)\n",
        "# def symexp(x): return torch.sign(x) * torch.exp(ste_abs(x) - 1.0)\n",
        "\n",
        "\n",
        "# sx = torch.rand((batch_size,3),device=device)\n",
        "# sx_ = sx.detach()\n",
        "# for i in range(10): # num epochs\n",
        "#     # la = fsq(x.clone())\n",
        "#     la = fsq(x)\n",
        "#     print(i)\n",
        "#     print(x,x.requires_grad)\n",
        "#     print(la,la.requires_grad)\n",
        "#     loss, sx_ = rnn_pred(sx_, la)\n",
        "#     # loss.backward()\n",
        "#     loss.backward(retain_graph=True) # retain_graph bec fsq got tanh that creates new graph?\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     # x = torch.tanh(x)\n",
        "#     # x = torch.clamp(x, min=-1, max=1)\n",
        "#     # x = ste_clamp(x.clone(), min=-1, max=1)\n",
        "#     # x = symlog(x.clone())\n",
        "#     # sx_ = sx_.detach()\n",
        "\n",
        "\n",
        "# # print(xx)\n",
        "# print(x)\n",
        "# # print(xhat)\n",
        "# print(la)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YWmwVYhVVh5R"
      },
      "outputs": [],
      "source": [
        "# @title test ste_argmin\n",
        "import torch\n",
        "emb = torch.nn.Embedding(15, 3) # env.action_space # 15\n",
        "x = torch.rand(1,3)\n",
        "\n",
        "# def ste_argmin(x, dim=-1):\n",
        "#     idx = torch.argmin(x, dim)\n",
        "#     # out = torch.zeros_like(x)\n",
        "#     out = torch.zeros_like(idx).unsqueeze(-1)\n",
        "#     print(idx.shape, out.shape)\n",
        "#     out.scatter_(1, idx, 1)\n",
        "#     return out\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# def softargmin(x, beta=10):\n",
        "#     # Apply softmax to the negative of the input to approximate argmin\n",
        "#     weights = F.softmax(-x * beta, dim=-1)\n",
        "#     indices = torch.arange(x.size(-1), dtype=x.dtype, device=x.device)\n",
        "#     soft_argmin = torch.sum(weights * indices, dim=-1)\n",
        "#     return soft_argmin\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "# out = differentiable_argmax(-x)\n",
        "# print(out)\n",
        "\n",
        "\n",
        "# def softargmax1d(input, beta=100): # https://github.com/david-wb/softargmax/blob/master/softargmax.py\n",
        "#     *_, n = input.shape\n",
        "#     input = nn.functional.softmin(beta * input, dim=-1)\n",
        "#     indices = torch.linspace(0, 1, n)\n",
        "#     result = torch.sum((n - 1) * input * indices, dim=-1)\n",
        "#     return result\n",
        "\n",
        "# ste_round\n",
        "\n",
        "# # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "# dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "# print(lact)\n",
        "\n",
        "device='cpu'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "    dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    A=differentiable_argmax(-dist)\n",
        "    # print(A.shape)\n",
        "    print(torch.argmax(A))\n",
        "    x_=A@emb.weight.data\n",
        "    # print(\"dist\", dist.shape)\n",
        "    # lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = ste_argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = softargmin(dist)\n",
        "    # print(lact)\n",
        "    # x = emb.weight.data[lact]\n",
        "\n",
        "    # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "    print(\"x_\",x_)\n",
        "    # x = emb(x_)\n",
        "\n",
        "    loss = model(x_).sum()\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "x_ = torch.tensor([14])\n",
        "x = emb(x_)\n",
        "# print(x)\n",
        "# # print(emb.weight)\n",
        "# pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "pseudo_inverse_weight = torch.linalg.pinv(emb.weight)\n",
        "# weight_inv = torch.pinverse(emb.weight.T)\n",
        "\n",
        "dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "# print(x@pseudo_inverse_weight)\n",
        "# A=differentiable_argmax(-x@pseudo_inverse_weight)\n",
        "A=differentiable_argmax(-dist)\n",
        "print(A)\n",
        "\n",
        "# print(pseudo_inverse_weight.shape, pseudo_inverse_weight)\n",
        "# # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "# x_ = x@ pseudo_inverse_weight\n",
        "# print(\"x_\",x_)\n",
        "\n",
        "# print(emb.weight@ pseudo_inverse_weight)\n",
        "# dist=torch.dist(emb.weight@ pseudo_inverse_weight, torch.eye(15))\n",
        "# print(dist)\n",
        "# print(pseudo_inverse_weight@ emb.weight)\n",
        "\n",
        "# print(emb.weight@ weight_inv.T)\n",
        "# print(weight_inv.T@ emb.weight)\n",
        "\n",
        "# torch.linalg.lstsq(A, B).solution\n",
        "\n",
        "\n",
        "x_ = torch.tensor([4])\n",
        "embx = emb(x_) # emb.weight[x_,:]\n",
        "print(embx)\n",
        "\n",
        "Apinv = torch.linalg.pinv(A)\n",
        "x = embx@Apinv\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pGZld_gLH1RA"
      },
      "outputs": [],
      "source": [
        "# @title test bptt\n",
        "\n",
        "x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    loss=0\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        # loss = loss -stcost(xxx.clone()).sum()\n",
        "        loss = loss -stcost(xxx).sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "# RuntimeError: Output 1 of SplitBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size, T = 1,6\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "# optim = torch.optim.SGD([x], lr=1e-3)\n",
        "# # xx = torch.split(x, bptt, dim=1)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    loss=0\n",
        "    # xx = torch.split(x, bptt, dim=1)\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        loss = loss -stcost(xxx.clone()).sum()\n",
        "        # loss = loss -stcost(xxx).sum()\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jepapred = nn.Sequential(nn.Linear(3*2,3))\n",
        "stcost = nn.Sequential(nn.Linear(3,1))\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    for t in range(seq_len): # simple single layer\n",
        "        # print(la.shape)\n",
        "        a = la[:,t,:].clone() # [1, dim_a]\n",
        "        # sxaz = torch.cat([sx, a], dim=-1)\n",
        "        sxaz = torch.cat([sx.clone(), a.clone()], dim=-1)\n",
        "        # sxaz = torch.cat([sx.clone(), a], dim=-1)\n",
        "        sx = jepapred(sxaz)\n",
        "        tcost = -stcost(sx).sum()\n",
        "        lsx = torch.cat([lsx, sx], dim=0)\n",
        "        # print(lsx.requires_grad, sx.requires_grad)\n",
        "        # icost = 0.5*icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(icost.requires_grad)\n",
        "        cost += tcost# + icost\n",
        "    return cost, sx#, z\n",
        "\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "sx = torch.rand((batch_size,3),device=device)\n",
        "T = 6\n",
        "bptt = 3\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device)) # FSQ 3 levels\n",
        "x = torch.empty((batch_size, T, 3),device=device) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "# optim = torch.optim.SGD([x], lr=1e-3) #, maximize=True)\n",
        "# print(x.shape)\n",
        "# print(len(xx))\n",
        "# print(xx[0].shape)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    sx_ = sx.detach()\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "\n",
        "        # xxx=x\n",
        "        # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        la = fsq(xxx)\n",
        "        # la = xxx\n",
        "        # print(x,x.requires_grad)\n",
        "        # print(la,la.requires_grad)\n",
        "        # loss, sx_ = rnn_pred(sx_, la)\n",
        "        loss = -stcost(la).sum()\n",
        "\n",
        "        print(\"loss\",loss)\n",
        "        loss.backward()\n",
        "        # loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # sx_ = sx_.detach()\n",
        "        # print(loss.item(), lact)\n",
        "\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    x = torch.tanh(x) # clamp\n",
        "    print(x)\n",
        "    # print(x)\n",
        "print(\"search\",loss.item())\n",
        "# print(lact)\n",
        "# return la, lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # def search(self, sx, T=256, bptt=32):\n",
        "    # def search(self, sx, T=None, bptt=None):\n",
        "    #     if T==None: T = 256\n",
        "    #     if bptt==None: bptt = min(T,3)\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "    #     torch.nn.init.xavier_uniform_(x)\n",
        "    #     # optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "    #     # xx = torch.split(x, bptt, dim=1)\n",
        "    #     xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "    #     optim = torch.optim.SGD(xx, lr=1e7) #, maximize=True)\n",
        "\n",
        "    #     for _ in range(10): # num epochs\n",
        "    #         sx_ = sx.detach()\n",
        "    #         for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    #             # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "    #             la = fsq(xxx.clone())\n",
        "    #             # print(x,x.requires_grad)\n",
        "    #             # print(la,la.requires_grad)\n",
        "    #             loss, sx_ = self.rnn_pred(sx_, la)\n",
        "    #             loss.backward(retain_graph=True)\n",
        "    #             optim.step()\n",
        "    #             optim.zero_grad()\n",
        "    #             sx_ = sx_.detach()\n",
        "    #             # print(loss.item(), lact)\n",
        "    #             # xx = torch.tanh(xx) # clamp\n",
        "    #         xx = [torch.tanh(xxx) for xxx in xx]\n",
        "    #         x = torch.cat(xx,dim=1)\n",
        "    #         # x = torch.tanh(x) # clamp\n",
        "    #         print(x)\n",
        "    #     print(\"search\",loss.item())\n",
        "    #     # print(lact)\n",
        "    #     return la, lact # [batch_size, T]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "Jx0k_ndHOEMe",
        "outputId": "b5fb2840-eeb5-45ae-f0e0-e2a15f8e7ccc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-05466a22e258>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# visualise(agent.sense,layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mvisualise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title visualise kernels\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "# https://stackoverflow.com/questions/55594969/how-to-visualise-filters-in-a-cnn-with-pytorch\n",
        "\n",
        "layers = [0,3,6,9]\n",
        "layers = [0,3,6,9,12]\n",
        "layer = 9\n",
        "\n",
        "def visualise(model,layer):\n",
        "    kernels = model.cnn[layer].weight.data.clone()\n",
        "    n,c,w,h = kernels.shape\n",
        "    print(kernels.shape)\n",
        "    if c not in [1,3]:\n",
        "        # kernels = kernels.mean(dim=1, keepdim=True)\n",
        "        kernels = kernels[:,2,:,:].unsqueeze(dim=1)\n",
        "    nrow=10\n",
        "    rows = np.min((kernels.shape[0]//nrow + 1, 64))\n",
        "    grid = utils.make_grid(kernels, nrow=nrow, normalize=True, padding=1)\n",
        "    plt.figure(figsize=(nrow,rows))\n",
        "\n",
        "    kernels = kernels - kernels.min()\n",
        "    kernels = kernels / kernels.max()\n",
        "    filter_img = utils.make_grid(kernels, nrow = 12)\n",
        "    # change ordering since matplotlib requires images to\n",
        "    # be (H, W, C)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0))\n",
        "\n",
        "    # plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "# visualise(agent.sense,layer)\n",
        "visualise(agent.jepa.enc,layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N2TGs69fnrZo"
      },
      "outputs": [],
      "source": [
        "# @title visualise lin\n",
        "# https://matplotlib.org/stable/plot_types/index.html\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for name, param in agent.jepa.pred.named_parameters(): # for param in model.parameters():\n",
        "for name, param in agent.emb.named_parameters():\n",
        "    print(name, param.shape)\n",
        "    if len(param.shape)==1: param=param.unsqueeze(0)\n",
        "    Z=param.detach()#.numpy()\n",
        "\n",
        "    filter_img = utils.make_grid(Z, nrow = 12, normalize=True, padding=1)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0)) # (H, W, C)\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "    # pos=ax.imshow(Z)\n",
        "    # fig.colorbar(pos)\n",
        "    plt.show()\n",
        "\n",
        "print(agent.jepa.pred[0].weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90BTTw0Lr-t",
        "outputId": "a95870e2-bc89-43ba-d40b-febea4ce2382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n",
            "690080\n"
          ]
        }
      ],
      "source": [
        "# @title ConvEnc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ConvEnc(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[5], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[5], d_list[5], 2, 2, 0), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # 2457024\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # 685248\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 4, 2, 2), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 4, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 4, 2, 2), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 4, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # # #\n",
        "\n",
        "\n",
        "            nn.Conv2d(1, d_list[0], 4, 4, 0), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 4, 4, 0), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 4, 4, 0), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 4, 4, 0), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            #\n",
        "\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[5],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "\n",
        "convenc = ConvEnc(256).to(device)\n",
        "input = torch.rand((4,1,256,256), device=device)\n",
        "out = convenc(input)\n",
        "print(out.shape)\n",
        "print(sum(p.numel() for p in convenc.parameters() if p.requires_grad)) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot 3D"
      ],
      "metadata": {
        "id": "Jt_UlGz6Xoq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title sklearn RBF\n",
        "# https://gist.github.com/eljost/2c4e1af652ef02b2989da341c5569af7\n",
        "# from nn_plot.ipynb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import scipy.stats as st\n",
        "\n",
        "# np.random.seed(1)\n",
        "def func(x):\n",
        "    # print(x.shape)\n",
        "    # x= np.sum(x**2, axis=-1)\n",
        "    x=np.random.rand(x.shape[0])\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "res = 50\n",
        "num_pts=15\n",
        "X=np.random.rand(num_pts,2)*res\n",
        "# Y = func(X)\n",
        "Y=np.random.rand(num_pts)\n",
        "# print(X);print(Y)\n",
        "\n",
        "lim = 1\n",
        "# lin = np.linspace(-lim, lim, res)\n",
        "lin = np.linspace(0, res, res)\n",
        "x1, x2 = np.meshgrid(lin, lin)\n",
        "xx = np.vstack((x1.flatten(), x2.flatten())).T\n",
        "\n",
        "kernel = RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X, Y)\n",
        "# print(\"Learned kernel\", gp.kernel_)\n",
        "y_mean, y_cov = gp.predict(xx, return_cov=True)\n",
        "\n",
        "posteriors = st.multivariate_normal.rvs(mean=y_mean, cov=y_cov, size=1)\n",
        "\n",
        "ax = plt.figure().add_subplot(projection='3d')\n",
        "Z=posteriors.reshape(-1, res)\n",
        "# ax.plot_surface(x1, x2, Z)\n",
        "ax.plot_surface(x1, x2, Z, cmap='rainbow', alpha=0.7)\n",
        "\n",
        "# ax.plot_surface(x1, x2, posteriors.reshape(-1, res))\n",
        "ax.contour(x1, x2, Z, zdir='z', offset=-1, cmap='coolwarm') # https://matplotlib.org/stable/gallery/mplot3d/contour3d_3.html#sphx-glr-gallery-mplot3d-contour3d-3-py\n",
        "# ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-0.4, 0.5))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-1, 2))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, c=zdata, cmap='Greens');\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, cmap='Greens');\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VX5IExbRriwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title chatgpt RBFKernelLayer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RBFKernelLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(RBFKernelLayer, self).__init__()\n",
        "        self.centres = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        dists = torch.cdist(x, self.centres, p=2) ** 2\n",
        "        return torch.exp(-dists / (2 * self.sigma ** 2))\n",
        "\n",
        "class SaddlePointNetwork(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(SaddlePointNetwork, self).__init__()\n",
        "        self.rbf_layer = RBFKernelLayer(in_features, out_features, sigma)\n",
        "        self.linear = nn.Linear(out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rbf_output = self.rbf_layer(x)\n",
        "        # Introduce a saddle point structure\n",
        "        linear_output = self.linear(rbf_output)\n",
        "        # Example saddle function: x^2 - y^2\n",
        "        saddle_output = torch.sum(linear_output[:, :1]**2 - linear_output[:, 1:]**2, dim=1, keepdim=True)\n",
        "        return saddle_output\n",
        "\n",
        "# sin(ax)sin(bx)\n",
        "# (x^2 - y^2)\n",
        "import torch\n",
        "\n",
        "def rbf_saddle(x, y, gamma=1.0, a=1.0, b=1.0):\n",
        "    # RBF-like term\n",
        "    rbf_term = torch.exp(-gamma * torch.norm(x - y, p=2)**2)\n",
        "    # Saddle point term\n",
        "    saddle_term = (a * x)**2 - (b * y)**2\n",
        "    return rbf_term + saddle_term\n",
        "\n",
        "# Example usage\n",
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "output = rbf_saddle(x, y)\n",
        "print(output)\n",
        "\n",
        "# Compute gradients\n",
        "output.backward()\n",
        "print(x.grad, y.grad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "SusX7gpzxFNL",
        "outputId": "9f14a9da-e188-49ba-f5f5-70192ff33134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.6321], grad_fn=<AddBackward0>)\n",
            "tensor([2.7358]) tensor([-4.7358])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title plot 3d\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "y = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "X, Y = torch.meshgrid(x, y)\n",
        "Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rTmCo7pm0NxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title shape NN\n",
        "num_pts=1\n",
        "\n",
        "# X=torch.rand(num_pts,4)*2-1\n",
        "# X=torch.cat([torch.tensor([0,0]).unsqueeze(0),torch.rand(num_pts,2)*2-1], dim=-1)\n",
        "X=torch.cat([torch.zeros(1,1),torch.rand(num_pts,2)*2-1,torch.zeros(1,1)], dim=-1)\n",
        "Y=torch.rand(num_pts)\n",
        "print(X,Y)\n",
        "optim = torch.optim.SGD(model.parameters(), 1e-1)\n",
        "\n",
        "# model.train()\n",
        "pred = model(X)\n",
        "# print(Y.shape,pred.shape)\n",
        "# loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "loss = F.mse_loss(Y, pred.squeeze(-1))\n",
        "loss.backward()\n",
        "optim.step()\n",
        "optim.zero_grad()\n",
        "print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7fWZaQTDFg1",
        "outputId": "4c5ced88-54f1-436e-89f9-66f1c8396373",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000, -0.7231,  0.3792,  0.0000]]) tensor([0.3362])\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title plot NN\n",
        "\n",
        "xx = torch.linspace(-1, 1, 100)\n",
        "yy = torch.linspace(-1, 1, 100)\n",
        "X, Y = torch.meshgrid(xx, yy) # [100,100]\n",
        "xy = torch.cat([X.unsqueeze(-1), torch.zeros(X.shape+(2,)), Y.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "with torch.no_grad(): Z = model(xy).squeeze(-1)\n",
        "# print(Z)\n",
        "# print(Z.shape)\n",
        "\n",
        "# Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "boDd__PE2sGy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test optim saddle same time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def f(x, y):\n",
        "    return x ** 2 - y ** 2 + x * y\n",
        "# (x-y)(x+y)+xy\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "dim_x, dim_z = 3, 1\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# xx = torch.empty((1, T, dim_x))\n",
        "# torch.nn.init.xavier_uniform_(xx)\n",
        "# x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "\n",
        "# tensor([[0.6478, 0.0531, 0.0861]]) tensor([[-1.,  1.]]) 0.2974517047405243\n",
        "# tensor([-0.9419, -1.0000,  0.4416, -1.0000,  1.0000,  0.2963])\n",
        "\n",
        "# x = nn.Parameter(torch.tensor([[0.6478, 0.0531, 0.0861]]))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "z = nn.Parameter(torch.empty((batch, T, dim_z)))\n",
        "# z = torch.empty((1, T, 1))\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# z = nn.Parameter(z.repeat(batch,1,1))\n",
        "# z = nn.Parameter(torch.tensor([[-1.,  1.]]))\n",
        "# optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "# optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.95), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "# .95,1e-1,3e-1\n",
        "# .99,\n",
        "\n",
        "d_model = 4\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(50): # num epochs\n",
        "    # loss = f(x,z)\n",
        "    # loss = f(x.sum(-1),z)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step(); optim_z.step()\n",
        "    optim_x.zero_grad(); optim_z.zero_grad()\n",
        "    # print(i,x.squeeze(), z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    print(i,x.squeeze()[0].data, z[0].squeeze().data, loss[0].squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "        z.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "print(loss.squeeze())\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "# idx = torch.argmax(loss)\n",
        "# print(x[idx],z[idx],loss[idx])\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n",
        "\n"
      ],
      "metadata": {
        "id": "qW6BYoXsX57o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dc0e5f-6def-42fd-f829-e227ec94833b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([-0.1000, -0.1000,  0.1000]) tensor(0.4161) -0.0008160677389241755\n",
            "1 tensor([-0.1999, -0.1999,  0.1999]) tensor(0.8145) -0.000763896678108722\n",
            "2 tensor([-0.2997, -0.2997,  0.2997]) tensor(1.2112) -0.0007120760856196284\n",
            "3 tensor([-0.3994, -0.3994,  0.3994]) tensor(1.3960) -0.0007130901212804019\n",
            "4 tensor([-0.4989, -0.4990,  0.4990]) tensor(1.3960) -0.0007601650431752205\n",
            "5 tensor([-0.5885, -0.5989,  0.5981]) tensor(1.3965) -0.0008037001243792474\n",
            "6 tensor([-0.6703, -0.6989,  0.6969]) tensor(1.3969) -0.0008425545529462397\n",
            "7 tensor([-0.7460, -0.7991,  0.7955]) tensor(1.3972) -0.0008812308078631759\n",
            "8 tensor([-0.8166, -0.8994,  0.8938]) tensor(1.3974) -0.000919759797398001\n",
            "9 tensor([-0.8943, -1.0004,  0.9918]) tensor(1.4013) -0.0009680598159320652\n",
            "10 tensor([-0.9786, -1.1017,  1.0897]) tensor(1.4044) -0.0010272095678374171\n",
            "11 tensor([-1.0680, -1.1023,  1.0977]) tensor(1.4068) -0.0010494425659999251\n",
            "12 tensor([-1.0936, -1.1028,  1.0976]) tensor(1.4087) -0.0010546413250267506\n",
            "13 tensor([-1.0968, -1.1032,  1.0976]) tensor(1.4102) -0.0010546413250267506\n",
            "14 tensor([-1.0994, -1.1035,  1.0975]) tensor(1.4113) -0.0010546413250267506\n",
            "15 tensor([-1.1015, -1.1037,  1.0975]) tensor(1.4123) -0.0010546413250267506\n",
            "16 tensor([-1.1032, -1.1039,  1.0975]) tensor(1.4130) -0.0010546413250267506\n",
            "17 tensor([-1.1045, -1.1040,  1.0975]) tensor(1.4135) -0.0010546413250267506\n",
            "18 tensor([-1.1057, -1.1041,  1.0975]) tensor(1.4139) -0.0010546413250267506\n",
            "19 tensor([-1.1066, -1.1041,  1.0975]) tensor(1.4142) -0.0010546413250267506\n",
            "20 tensor([-1.1073, -1.1042,  1.0975]) tensor(1.4144) -0.0010546413250267506\n",
            "21 tensor([-1.1079, -1.1042,  1.0975]) tensor(1.4145) -0.0010546413250267506\n",
            "22 tensor([-1.1084, -1.1042,  1.0975]) tensor(1.4146) -0.0010546413250267506\n",
            "23 tensor([-1.1088, -1.1042,  1.0975]) tensor(1.4146) -0.0010546413250267506\n",
            "24 tensor([-1.1091, -1.1042,  1.0975]) tensor(1.4145) -0.0010546413250267506\n",
            "25 tensor([-1.1093, -1.1041,  1.0975]) tensor(1.4144) -0.0010546413250267506\n",
            "26 tensor([-1.1094, -1.1041,  1.0976]) tensor(1.4143) -0.0010546413250267506\n",
            "27 tensor([-1.1096, -1.1040,  1.0976]) tensor(1.4141) -0.0010546413250267506\n",
            "28 tensor([-1.1096, -1.1040,  1.0976]) tensor(1.4140) -0.0010546413250267506\n",
            "29 tensor([-1.1097, -1.1039,  1.0976]) tensor(1.4138) -0.0010546413250267506\n",
            "30 tensor([-1.1097, -1.1039,  1.0976]) tensor(1.4135) -0.0010546413250267506\n",
            "31 tensor([-1.1096, -1.1038,  1.0976]) tensor(1.4133) -0.0010546413250267506\n",
            "32 tensor([-1.1096, -1.1037,  1.0977]) tensor(1.4131) -0.0010546413250267506\n",
            "33 tensor([-1.1095, -1.1037,  1.0977]) tensor(1.4128) -0.0010546413250267506\n",
            "34 tensor([-1.1094, -1.1036,  1.0977]) tensor(1.4126) -0.0010546413250267506\n",
            "35 tensor([-1.1093, -1.1035,  1.0977]) tensor(1.4123) -0.0010546413250267506\n",
            "36 tensor([-1.1092, -1.1034,  1.0978]) tensor(1.4121) -0.0010546413250267506\n",
            "37 tensor([-1.1091, -1.1034,  1.0978]) tensor(1.4118) -0.0010546413250267506\n",
            "38 tensor([-1.1090, -1.1033,  1.0978]) tensor(1.4116) -0.0010546413250267506\n",
            "39 tensor([-1.1089, -1.1032,  1.0978]) tensor(1.4113) -0.0010546413250267506\n",
            "40 tensor([-1.1087, -1.1032,  1.0978]) tensor(1.4111) -0.0010546413250267506\n",
            "41 tensor([-1.1086, -1.1031,  1.0979]) tensor(1.4108) -0.0010546413250267506\n",
            "42 tensor([-1.1085, -1.1030,  1.0979]) tensor(1.4106) -0.0010546413250267506\n",
            "43 tensor([-1.1083, -1.1030,  1.0979]) tensor(1.4103) -0.0010546413250267506\n",
            "44 tensor([-1.1082, -1.1029,  1.0979]) tensor(1.4101) -0.0010546413250267506\n",
            "45 tensor([-1.1080, -1.1028,  1.0979]) tensor(1.4098) -0.0010546413250267506\n",
            "46 tensor([-1.1079, -1.1027,  1.0979]) tensor(1.4096) -0.0010546413250267506\n",
            "47 tensor([-1.1077, -1.1027,  1.0980]) tensor(1.4094) -0.0010546413250267506\n",
            "48 tensor([-1.1076, -1.1026,  1.0980]) tensor(1.4091) -0.0010546413250267506\n",
            "49 tensor([-1.1075, -1.1026,  1.0980]) tensor(1.4089) -0.0010546413250267506\n",
            "tensor([-0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011,\n",
            "        -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011],\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "tensor([[-1., -1.,  1.]]) tensor([[1.]]) -0.0010546413250267506\n",
            "tensor([[-1., -1.,  1.]]) tensor([[1.]]) -0.0010546413250267506\n",
            "tensor([[-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011],\n",
            "        [-1.0000, -1.0000,  1.0000,  1.0000, -0.0011]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test optim saddle argm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def argm(sx, lr=3e3): # 3e3\n",
        "    # batch=sx.size(dim=0)\n",
        "    batch_size, T, _ = sx.shape\n",
        "    batch = 16\n",
        "    # z = nn.Parameter(torch.zeros((batch,1),device=device))\n",
        "    # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "    z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "    torch.nn.init.xavier_uniform_(z)\n",
        "    # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "    # sx = sx.detach()\n",
        "    for i in range(20): # 10\n",
        "        # print(sx.shape,z.shape)\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            cost = model(sxz)\n",
        "        cost.sum().backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "        # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    # return z.detach()\n",
        "    idx = torch.argmax(cost.squeeze(), dim=1)\n",
        "    return z[torch.arange(z.shape[0]),idx].detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# x = nn.Parameter(xx.clone())\n",
        "x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "# ratio = 6e0\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(50):\n",
        "    z = argm(x)\n",
        "    # print(x.shape,z.shape)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "# print(\"z\",z)\n",
        "# print(loss.squeeze())\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n"
      ],
      "metadata": {
        "id": "GJdFpDr2wIMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff06bd6b-2bec-4392-c749-77cd3f1688ca",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3976, -1.0000, -1.0000]]) tensor([[-1.,  1.]]) 0.29717573523521423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.randn(16, 16)\n",
        "# print((b==torch.max(b)).nonzero())\n",
        "x = torch.randn(10, 3)\n",
        "idx = torch.randint(3,(10,))\n",
        "# print(x[:,idx].shape)\n",
        "print(x[torch.arange(x.shape[0]),idx].shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvjIJP6RlEv2",
        "outputId": "447fdefd-452b-437d-c228-1847492b36f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gJ3X_hQelW2x"
      },
      "outputs": [],
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wi4ODp-XlZoU"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QYbOgNoZn6JL"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_kcajtpjr7Io"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "outputs": [],
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "    def get_down(self, state, world_state=None): # update world_state and mem from state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        return world_state\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    world_state = self.get_down(state, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "                    sy = self.effnet(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "\n",
        "                    world_state_ = self.deconvenc(sy).squeeze(1) # ae\n",
        "                    # loss = F.mse_loss(world_state_, world_state)\n",
        "                    loss = F.mse_loss(world_state_, world_state.detach())\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wUhKd009Qvk3"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}