{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "d8978a30-e218-47f8-9197-f370aa027b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -qq procgen\n",
        "# !pip install -qq procgen faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEY9MmwZhA8a",
        "outputId": "d345a87b-8267-4079-fb6a-37f3d799e422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1278976\n",
            "torch.Size([4, 256])\n",
            "1278979\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model=256, drop=0.5):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278976\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Dropout(p=drop),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278979\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "conv = Conv().to(device)\n",
        "print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = conv(input)\n",
        "print(out.shape)\n",
        "\n",
        "deconv = Deconv(256).to(device)\n",
        "print(sum(p.numel() for p in deconv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,256), device=device)\n",
        "out = deconv(input)\n",
        "print(out.shape)\n",
        "\n",
        "# print(conv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Bos81kQf1dwh"
      },
      "outputs": [],
      "source": [
        "# @title transfer_sd store_sd load_sd\n",
        "\n",
        "def transfer_sd(tgt_sd, src_sd): #\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            # print(wht_name, tgt_wht.shape, src_wht.shape)\n",
        "            if tgt_wht.shape==src_wht.shape:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "                continue\n",
        "            if tgt_wht.shape[0] != src_wht.shape[0]: continue # output dim diff\n",
        "            if len(tgt_wht.shape)==2: tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "    return tgt_sd\n",
        "\n",
        "def store_sd(all_sd, new_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in new_sd.keys():\n",
        "            if not wht_name in all_sd.keys():\n",
        "                # print(wht_name, new_sd[wht_name].shape)\n",
        "                all_sd[wht_name] = (new_sd[wht_name],)\n",
        "                continue\n",
        "            all_tpl, new_wht = all_sd[wht_name], new_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                print(wht_name, all_wht.shape, new_wht.shape)\n",
        "                if all_wht.shape==new_wht.shape:\n",
        "                    all_wht = new_wht\n",
        "                    break\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: continue # diff output shape\n",
        "                if len(all_wht.shape)==2: all_wht[:, :new_wht.shape[1]] = new_wht[:, :all_wht.shape[1]]\n",
        "                break\n",
        "            if len(all_wht.shape)>=2 and len(all_wht.shape)>=2:\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: all_tpl = all_tpl + (new_wht,) # wht not in all_wht\n",
        "    return all_sd\n",
        "\n",
        "def load_sd(tgt_sd, all_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in all_sd.keys(): continue\n",
        "            tgt_wht, all_tpl = tgt_sd[wht_name], all_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                # try: print(wht_name, tgt_wht.shape, all_wht.shape)\n",
        "                # except: print(wht_name, tgt_wht, all_wht)\n",
        "                if tgt_wht.shape==all_wht.shape:\n",
        "                    tgt_wht.copy_(all_wht)\n",
        "                    break\n",
        "                if tgt_wht.shape[0] != all_wht.shape[0]: continue # output dim diff\n",
        "                if len(tgt_wht.shape)==2: tgt_wht[:, :all_wht.shape[1]].copy_(all_wht[:, :tgt_wht.shape[1]])\n",
        "                break\n",
        "    return tgt_sd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# modelsd = torch.load('agent.pkl', map_location=device).values()\n",
        "# tgt_sd = transfer_sd(agent.state_dict(), modelsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = {}\n",
        "# all_sd = store_sd(all_sd, agent1.state_dict())\n",
        "# print(all_sd.keys())\n",
        "# checkpoint = {'model': all_sd}\n",
        "# torch.save(checkpoint, 'all_sd.pkl')\n",
        "\n",
        "# agent3 = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "# agent3.tcost = tcost3\n",
        "# tgt_sd = load_sd(agent3.state_dict(), all_sd)\n",
        "# agent3.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "# for x,y in zip(agent1.state_dict().values(), agent3.state_dict().values()):\n",
        "#     print((x==y).all())\n",
        "\n",
        "# print(agent1.jepa.enc.cnn[1].num_batches_tracked)\n",
        "# jepa.enc.cnn.0.weight\n",
        "# print(agent1.jepa.enc.cnn[0].weight.shape)\n",
        "# print(agent1.jepa.enc.cnn[0].weight[0][0])\n",
        "# print(agent3.jepa.enc.cnn[0].weight[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SFVbGqMDqcDR"
      },
      "outputs": [],
      "source": [
        "# @title rename_sd\n",
        "def rename_sd(agent_sd):\n",
        "    sd_={}\n",
        "    convert={}\n",
        "    na_=''\n",
        "    for wht_name, wht in agent_sd.items():\n",
        "        o=wht_name.split('.')\n",
        "        # print(\"####\", wht_name)\n",
        "        name=wht_name\n",
        "        for i in range(len(o)):\n",
        "            c = o[i]\n",
        "            if c.isnumeric():\n",
        "                na, me = '.'.join(o[:i]), '.'.join(o[i+1:])\n",
        "                c=int(c)\n",
        "                if na!=na_: # param name diff\n",
        "                    j=0 # reset num\n",
        "                    c_=c # track wht_name num\n",
        "                    na_=na # track param name\n",
        "                elif c_<c: # same param name, diff num\n",
        "                    j+=1\n",
        "                    c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "        # print(name)\n",
        "        sd_[name] = wht\n",
        "        convert[name] = wht_name\n",
        "    return sd_, convert\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# # modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, _ = rename_sd(modelsd)\n",
        "\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# agent.load_state_dict(modelsd, strict=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "riBHnAAkkzrd"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim me\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# def transfer_optim(tgt_sd, src_sd, tgt_optim, src_optim): #\n",
        "def transfer_optim(tgt_sd, src_sd, tgt_optim_sd, src_optim_sd): #\n",
        "    non_lst = ['running_mean', 'running_var', 'num_batches_tracked', 'num_batches_tracked', 'loss_fn']\n",
        "    tgt_lst, src_lst = [], []\n",
        "    for i, (k,v) in enumerate(tgt_sd.items()):\n",
        "        # print(i, k, v.shape, any(s in k for s in non_lst))\n",
        "        if not any(s in k for s in non_lst): tgt_lst.append(k)\n",
        "    for i, (k,v) in enumerate(src_sd.items()):\n",
        "        if not any(s in k for s in non_lst): src_lst.append(k)\n",
        "\n",
        "    # tgt_optim_st, src_optim_st = tgt_optim.state_dict()['state'], src_optim.state_dict()['state']\n",
        "    tgt_optim_st, src_optim_st = tgt_optim_sd['state'], src_optim_sd['state']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, wht_name in enumerate(tgt_lst):\n",
        "            if not wht_name in src_lst: continue\n",
        "            tgt_wht, src_wht = tgt_optim_st[tgt_lst.index(wht_name)], src_optim_st[src_lst.index(wht_name)]\n",
        "            # print(wht_name, tgt_wht, src_wht)\n",
        "            tgt_shp, src_shp = tgt_wht['exp_avg'].shape, src_wht['exp_avg'].shape\n",
        "            if tgt_shp==src_shp:\n",
        "                tgt_wht = src_wht\n",
        "                continue\n",
        "            if tgt_shp[0] != src_shp[0]: continue # output dim diff\n",
        "            if len(tgt_shp)==2:\n",
        "                tgt_wht['step'] = src_wht['step']\n",
        "                tgt_wht['exp_avg'][:, :src_shp[1]] = src_wht['exp_avg'][:, :tgt_shp[1]]\n",
        "                tgt_wht['exp_avg_sq'][:, :src_shp[1]] = src_wht['exp_avg_sq'][:, :tgt_shp[1]]\n",
        "    # return tgt_optim.state_dict()\n",
        "    return tgt_optim_sd\n",
        "\n",
        "# model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "# model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "# source_optimizer = optim.AdamW(model_src.parameters())\n",
        "# target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "# dummy_input = torch.randn(3, 10)\n",
        "# dummy_target = torch.randn(3, 5)\n",
        "# criterion = torch.nn.MSELoss()\n",
        "# output = model_src(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# source_optimizer.step()\n",
        "\n",
        "# dummy_input = torch.randn(3, 20)\n",
        "# output = model_tgt(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# target_optimizer.step()\n",
        "\n",
        "\n",
        "# print(source_optimizer.state_dict())\n",
        "# print(target_optimizer.state_dict())\n",
        "\n",
        "# optimsd = transfer_optim(model_tgt.state_dict(), model_src.state_dict(), target_optimizer, source_optimizer)\n",
        "# target_optimizer.load_state_dict(optimsd)\n",
        "# print(target_optimizer.state_dict())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfjFbveH64Io"
      },
      "outputs": [],
      "source": [
        "# @title TCost\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TCost(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=256): # in_dim=(1+self.jepa.pred.num_layers)*d_model\n",
        "        super().__init__()\n",
        "        self.tc = torch.tensor([-1., 0.], device=device).unsqueeze(-1) # unsqueeze(0).T\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Dropout(p=0.),\n",
        "            # nn.Linear(in_dim, 2, bias=False), nn.Softmax(dim=-1),\n",
        "            nn.Linear(in_dim, d_model), nn.ReLU(),\n",
        "            # nn.Dropout(p=0.5),\n",
        "            # nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 2), nn.Softmax(),\n",
        "            )\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def update_loss_weight(self, train_data):\n",
        "        a = len(buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tcost(x)@self.tc\n",
        "\n",
        "    def loss(self, x, y):\n",
        "        out = self.tcost(x)\n",
        "        y = torch.where(y < -0.5, 0, 1)\n",
        "        return self.loss_fn(out, y)\n",
        "\n",
        "\n",
        "# tcost=TCost(1024)\n",
        "# x=torch.rand(256,1024)\n",
        "# import time\n",
        "# start = time.time()\n",
        "# out=tcost(x)\n",
        "# # out=F.gumbel_softmax(out)\n",
        "# print(time.time()-start)\n",
        "# # nn.AdaptiveLogSoftmaxWithLoss(in_features=2, n_classes=2, cutoffs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0UHSueqx9W8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "#     self.train()\n",
        "#     for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "#         h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "#         sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "#         # sx=sy_\n",
        "#         state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "#         with torch.cuda.amp.autocast():\n",
        "#             lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "#             clossl = self.tcost.loss(lsy, rwd.flatten())\n",
        "#             closs = self.closs_coeff * clossl\n",
        "\n",
        "#             pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "#             print(\"pred\",pred[0])\n",
        "#             print(\"rwd\",rwd[0])\n",
        "#             mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "#             # # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "#             # try: imshow(torchvision.utils.make_grid(st[0].cpu(), nrow=10))\n",
        "#             # # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "#             # except ZeroDivisionError: pass\n",
        "\n",
        "#         loss = jloss + closs\n",
        "\n",
        "#         print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "#         # print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "#         scaler.scale(loss).backward()\n",
        "#         # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "#         scaler.step(optim)\n",
        "#         scaler.update()\n",
        "#         optim.zero_grad()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuA25qQknUAX",
        "outputId": "ef7c5c91-2d56-43b3-da14-437059737774"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-9b3493e3f0c0>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model) # pixel\n",
        "        # self.enc = ConvEnc(d_model) #\n",
        "        # self.enc = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.enc.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "        # self.pred = nn.Sequential(\n",
        "        #     nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.3)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=3e3, h0=None): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95))\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        for i in range(5): # 10\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sy_ = self.pred(sxaz)\n",
        "                sy_, _ = self.pred(sxaz, h0)\n",
        "                loss = lossfn(sy_, sy)# + self.z_coeff * torch.norm(z)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"argm\",i,loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "# torch.norm(z, dim=-1)\n",
        "# -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "# in RL, distribution of action, if certainty is high, entropy is low\n",
        "\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkI44ygzfxu",
        "outputId": "d3ca218d-cc9a-4408-dd41-b2d9cdd58bae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-c26d148f32c5>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=8, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 50 # 50 # 10 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=50. # 50 # 20 # 50 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 1 # 0.001 # 1 # ν cov Covariance\n",
        "        self.closs_coeff=100. # 100 # 100 # 100\n",
        "        self.zloss_coeff=1. # 10 # 20 # 1\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        self.lx, self.lz = torch.empty((0,dim_a),device=device), torch.empty((0,dim_z),device=device) # [T,dim_az]\n",
        "        self.sx = self.jepa.enc(torch.zeros((1, 3,64,64)))\n",
        "        self.la = torch.empty(0,device=device)\n",
        "\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        if len(self.la)>1 or laction!=None:\n",
        "            self.update_h0(lstate, laction)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                self.sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(self.sx, T=8, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.la, self.lx, self.lz = lact, lx, lz\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx - torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    self.la = torch.cat([torch.tensor(laction, device=device), self.la[len(laction):]], dim=-1)\n",
        "                la = self.emb(self.la[:seq_len])\n",
        "\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5) # torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        optim_z = torch.optim.SGD([lz], lr=1e1) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e0 ; 3e-2 1e-1\n",
        "        lsx, la = lsx.detach(), la.detach() # [T, d_model], [T, dim_a]\n",
        "        # print(\"update_h0 lz\", lz.data)\n",
        "        self.jepa.pred.train()\n",
        "        for i in range(1): # 1?\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                loss = F.mse_loss(out_, out.squeeze(0))\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            # print(\"update_h0 loss, lz\",i,loss.item(), lz.data)\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1].unsqueeze(0)\n",
        "        # print(\"update_h0\", self.lx.data)\n",
        "        # print(self.la.shape, self.lx.shape, self.lz.shape, self.la[seq_len:].shape, self.lx[seq_len:].shape, self.lz[seq_len:].shape)\n",
        "        self.la, self.lx, self.lz = self.la[seq_len:], self.lx[seq_len:], self.lz[seq_len:] # [T, dim_a], [T, dim_z]\n",
        "        return h0\n",
        "\n",
        "    def argm_s(self, sx, x, h0): # batch argm z for search\n",
        "        T, _ = x.shape\n",
        "        batch = 64 # 16\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        optim_z = torch.optim.SGD([z], lr=1e4, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        with torch.no_grad():\n",
        "            z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_z]\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, seq_len, dim_a]\n",
        "        # print(\"argm\", z[0].squeeze())\n",
        "        for i in range(2): # 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm z loss\", z[0].squeeze().data, loss[0].squeeze().data)\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return z[idx]\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        x = nn.Parameter(torch.empty((T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        optim_x = torch.optim.SGD([x], lr=1e3) # 1e-1,1e-0,1e4 ; 1e2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        with torch.no_grad(): x[:self.lx.shape[0]] = self.lx[:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        # print(\"search x\",x.squeeze().data)\n",
        "        for i in range(2): # 5\n",
        "            dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0) # [T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_.unsqueeze(0), z.unsqueeze(0), h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i, \"search x loss\", x.squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        return lact, lh0, x.data, z # [T], [T, num_layers, batch, d_model], [T, dim_a], [T, dim_z]\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lsx = torch.empty((batch, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1) # [batch, 1, d_model+dim_a/z]\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        syh0 = torch.cat([lsx, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,T,d_model], [T,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "        tcost = -self.tcost(syh0).unflatten(0, (batch, seq_len)).squeeze(-1)\n",
        "        c = (tcost + icost)*gamma**torch.arange(seq_len, device=device)\n",
        "        # if len(c.shape) == 1: print(\"rnn_pred c\", [f'{cc.item():g}' for cc in c.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        if len(tcost.shape) == 1: print(\"rnn_pred tcost\", [f'{cc.item():g}' for cc in tcost.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        return c.sum(), lh0\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd):\n",
        "        self.tcost.eval()\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "            lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "                for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                    syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                    out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                    lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                    lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "                repr_loss = F.mse_loss(lsy, lsy_)\n",
        "                syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "                clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "                # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "                cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            # sx=sy_\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "                lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_, h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    # with torch.no_grad(): lz.mul_(torch.rand_like(lz)).mul_((torch.rand_like(lz)>0.5).bool()) # dropout without scailing\n",
        "\n",
        "                    for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                        syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                        out_, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                        sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                        lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                        lh0 = torch.cat((lh0, h0.unsqueeze(0)), dim=0)\n",
        "\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "\n",
        "                    pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "                    print(\"pred\",pred[0])\n",
        "                    print(\"rwd\",rwd[0])\n",
        "                    mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "                    # # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[0].cpu(), nrow=10))\n",
        "                    # # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "                loss = jloss + closs\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                # norm = torch.norm(lsy, dim=-1)[0][0].item()\n",
        "                # z_norm = torch.norm(z)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                # print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                scaler.scale(loss).backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.999)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "# !pip show torch triton\n",
        "# # !pip install --upgrade torch\n",
        "# !pip install --upgrade triton\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "# print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "# print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "# print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwgWasBjZ04u"
      },
      "outputs": [],
      "source": [
        "# print(agent.tcost._parameters['weight'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RERFWFMgA_",
        "outputId": "7614b6db-c4b7-467a-f4fc-7869ae3f7548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0229, -0.0159, -0.0247,  ...,  0.0336,  0.0319, -0.0009],\n",
            "        [-0.0306, -0.0346, -0.0081,  ..., -0.0064,  0.0082,  0.0179]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# print(agent.jepa.enc.parameters().values()[0].requires_grad)\n",
        "# for name, param in agent.tcost.named_parameters():\n",
        "# # # for name, param in agent.named_parameters():\n",
        "# #     # print(name, param.requires_grad)\n",
        "#     print(name, param)\n",
        "\n",
        "for name, param in agent.tcost.named_parameters(): print(param.data)\n",
        "\n",
        "# print(agent.tcost.1.weight.data)\n",
        "\n",
        "# print(agent.tcost.named_parameters()['tcost.1.weight'])\n",
        "\n",
        "# print(vars(agent.jepa.exp.named_parameters()['exp.1.weight']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "UEH1P802JkHU",
        "outputId": "31b3efd5-1338-4f55-9345-76a8d9371905"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'state' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2eab810ffe5c>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# sx = agent.jepa.enc(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# lact, lh0, lx, lz = agent.search(sx, T=6, h0=h0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# dim_a, dim_z = 3, 8\n",
        "# batch, T = 4,6\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_a),device=device))\n",
        "# torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "# dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# x = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "# z = nn.Parameter(torch.zeros((batch, T, dim_z),device=device))\n",
        "# torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# state = torch.zeros((1, 3,64,64))\n",
        "# # state = torch.rand((1, 3,64,64), device=device)\n",
        "# sx = agent.jepa.enc(state)\n",
        "\n",
        "act = agent([state], k=4)\n",
        "# h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "# lact, lh0, lx, lz = agent.search(sx, T=6, h0=h0)\n",
        "# loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "# print(loss,c)\n",
        "# print(lact, lh0, lx, lz)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_b7ZSW6IF1-",
        "outputId": "0bb9f39d-f329-4f9f-a260-02f2be0aadd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-34fhOMTdMvtuAeHuL28Y4taSINvOejQ\n",
            "From (redirected): https://drive.google.com/uc?id=1-34fhOMTdMvtuAeHuL28Y4taSINvOejQ&confirm=t&uuid=62f7b9c2-dfc6-4a6f-a8e8-74f323c8b8ad\n",
            "To: /content/buffergo.pkl\n",
            "100% 1.80G/1.80G [00:30<00:00, 59.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !gdown 1bGWBbcKUgHESkbD3NfYt1WWikScVSFOj -O agentoptim.pkl # M1 gru3 tcost1\n",
        "# !gdown 1XBDhD2efIFW9lnewGRLrb362w47a8b1q -O agentoptim.pkl # B2 gru3 tcost1\n",
        "# !gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3\n",
        "# !gdown 1zoZ52jctM0jed6TgD7kAwrtnuDMeA5II -O agentoptim.pkl # T4 gru1 tcost1 drop\n",
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "# !gdown 1UDgNtFsWGAhvqR9lwA0QbMLhUtmip4ne -O agentoptim.pkl # M1 agentoptimgru3tcost1\n",
        "# !gdown 1-0oc6yucS5JXLHX1zqbYe3NTVMuhP_5r -O agentoptim.pkl # A2 agentoptim25251c25z3\n",
        "# !gdown 1U1CuCU1FugkrzPXsvTPpIX-wzWz6szl2 -O agentoptim.pkl # T4 agentoptimargm\n",
        "# !gdown 1CWZAtiEwSnglClJbq2LJTYlKhPN10gfo -O agentoptim.pkl # S3 agentoptimargm\n",
        "# !gdown 1XAbr6l1pCmcUCKR6kYlQ_dSDsOBqRg_j -O agentoptim.pkl # B2 argm2search2\n",
        "# !gdown 1UkQuf-IC2LYErSapkF6rZM1dv3svGI5P -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1-4sNf6mINCiD5YsBdQvCrlyqzzfS64si -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1MV9Qj_53Vu6wpe7nOFn47M5vDj7F7-gv -O agentoptim.pkl # S3 agentoptimargm2\n",
        "# !gdown 1--1Vl3337zugQng-j1qbptFY8EvhZA-T -O agentoptim.pkl # T4 agentoptimargm3 online\n",
        "# !gdown 1XHFBVPSH4T4FpUOBKN8X20xDQLNmL7go -O agentoptim.pkl # M1 agentoptimargm4\n",
        "# !gdown 1fFXsee_cSZxhTRewD7ZkGT68NXeq8OcH -O agentoptim.pkl # B2 agentoptimargm4\n",
        "\n",
        "# !gdown 1sCW9uvcdCJkCH5HQDdISLws5rMvmkmFR -O all_sd.pkl # M1 all_sd\n",
        "\n",
        "import pickle\n",
        "# !gdown 1j9hOq8_752duPB0PMYUJqabNvYoGLysX -O buffer512down.pkl # S\n",
        "# with open('buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY -O buffer512.pkl # S\n",
        "# with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB -O buffergo.pkl # S3\n",
        "# !gdown 1egXy0t_kn0M0oL6sbwixoVr7bqMfcB8j -O buffergo.pkl # T4\n",
        "!gdown 1-34fhOMTdMvtuAeHuL28Y4taSINvOejQ -O buffergo.pkl # B2\n",
        "with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "2a50a1b5-61fa-430f-bf93-6785babc7f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "# with open(folder+'buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptimargm4.pkl', map_location=device).values()\n",
        "modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# modelsd = transfer_sd(agent.state_dict(), modelsd)\n",
        "agent.load_state_dict(modelsd, strict=False)\n",
        "# # optimsd = transfer_optim(agent.state_dict(), modelsd, optim.state_dict(), optimsd)\n",
        "optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = torch.load(folder+'all_sd.pkl', map_location=device)\n",
        "# # all_sd = torch.load('all_sd.pkl', map_location=device)\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in all_sd.items())\n",
        "# allsd = {}\n",
        "# for (k, v) in all_sd.items():\n",
        "#     try: allsd[convert[k]] = v\n",
        "#     except Exception as e: print('dict err', e)\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# tgt_sd = load_sd(agent.state_dict(), allsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# for i, (k,v) in enumerate(modelsd.items()):\n",
        "# for i, (k,v) in enumerate(agent.state_dict().items()):\n",
        "#     print(i,k,v.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "# buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# checkpoint = {'model': agentsd, 'optimizer': optim.state_dict(),}\n",
        "checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "torch.save(checkpoint, folder+'agent_grudrop0.3.pkl')\n",
        "# torch.save(checkpoint, 'agentoptim.pkl')\n",
        "\n",
        "# all_sd = {}\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# all_sd = store_sd(all_sd, agentsd)\n",
        "# # torch.save(all_sd, 'all_sd.pkl')\n",
        "# torch.save(all_sd, folder+'all_sd.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NVcknabHMxH6"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in self.process(buffer) for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def process(self, buffer):\n",
        "        cleaned = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "        cleaned = [episode[-random.randint(20, 100):] for episode in cleaned]\n",
        "        random.shuffle(cleaned)\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "\n",
        "    # def pop_unif(self, buffer_, n=3):\n",
        "    #     buffer_.pop(random.randrange(len(buffer_)))\n",
        "    #     return buffer_\n",
        "\n",
        "# while len(train_data.data)>10000:\n",
        "#     buffer.pop(random.randrange(len(buffer)))\n",
        "#     train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 64 #512\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True)\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # # [3,T,batch]\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "1e3fpbtNOiz1",
        "outputId": "1d3b4abb-384d-4bd8-bdf1-a7a6ee8f84bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.,  0., -1., -1., -1.,  0.,  0., -1., -1.,  0.])\n",
            "tensor([ 0., -1., -1., -1., -1., -1., -1.,  0.,  0., -1.])\n",
            "tensor([-1.,  0., -1., -1.,  0., -1.,  0., -1., -1.,  0.])\n",
            "tensor([ 0., -1., -1., -1., -1., -1.,  0., -1., -1., -1.])\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b23656e238b2>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# _, world_state = agent.get(images.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# pred = agent.tcost(agent.jepa.enc(world_state.unsqueeze(1))).squeeze(-1).cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m# h0 = torch.empty((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# torch.nn.init.xavier_normal_(h0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "ctrain_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    ctrain_data=list(zip(state,reward))\n",
        "    ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "trainiter = iter(c_loader)\n",
        "images, labels = next(trainiter)\n",
        "# images, labels = images.to(device), labels.to(device)\n",
        "batch=40\n",
        "images, labels = images[:batch], labels[:batch]\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# print(labels)\n",
        "for x in range(len(labels)//10):\n",
        "    print(labels[10*x:10*x+10])\n",
        "\n",
        "# # try:\n",
        "with torch.no_grad():\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "    # _, world_state = agent.get(images.to(device))\n",
        "    # pred = agent.tcost(agent.jepa.enc(world_state.unsqueeze(1))).squeeze(-1).cpu()\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch, agent.d_model), device=device)\n",
        "    # h0 = torch.empty((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device)\n",
        "    # torch.nn.init.xavier_normal_(h0)\n",
        "    sy = agent.jepa.enc(images.to(device)) # [batch_size, d_model]\n",
        "    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "    pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "\n",
        "    # print(pred)\n",
        "    for x in range(len(pred)//10):\n",
        "        print(pred[10*x:10*x+10])\n",
        "    # print((labels==pred).sum())\n",
        "# except: pass\n",
        "print(agent.tcost.loss(syh0, labels.to(device)).squeeze(-1))\n",
        "print(F.mse_loss(labels, pred))\n",
        "\n",
        "# torch.where(abs(labels- pred)>0.5,1,0)\n",
        "for x in range(len(pred)//10):\n",
        "    print(torch.where(abs(labels- pred)>0.5,1,0)[10*x:10*x+10])\n",
        "\n",
        "mask = torch.where(abs(labels- pred)>0.5,1,0).bool()\n",
        "print(\"reward, pred\", labels[mask].data, pred[mask].data)\n",
        "try: imshow(torchvision.utils.make_grid(images[mask], nrow=10))\n",
        "except ZeroDivisionError: pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viimAIpYSJq_"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels = torch.tensor([0])\n",
        "# pred = torch.tensor([[.999,.001]])\n",
        "pred = torch.tensor([[1.,0.]])\n",
        "pred = torch.tensor([[5.,-5.]])\n",
        "# pred = torch.tensor([[.5,.5]])\n",
        "# pred = torch.tensor([[1/a, 1/(1-a)]])\n",
        "# pred = torch.tensor([[1/(1-a), 1/a]])\n",
        "# print(F.mse_loss(labels, pred))\n",
        "\n",
        "pred = torch.rand(10,2)\n",
        "pred = nn.Softmax(dim=-1)(pred)\n",
        "print(pred)\n",
        "labels = torch.where(torch.rand(10)>0.5,1,0)\n",
        "\n",
        "\n",
        "a=10\n",
        "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)]))\n",
        "print(loss_fn(pred, labels))\n",
        "\n",
        "# print((pred@torch.log(pred).T).sum())\n",
        "# print(pred,torch.log(pred).T)\n",
        "\n",
        "# 0.6931\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksm4ha7XA-BN"
      },
      "outputs": [],
      "source": [
        "# optim = torch.optim.SGD(agent.parameters(), 1e-1, momentum=0.9, dampening=0, weight_decay=0)\n",
        "# print(optim.param_groups[0][\"lr\"])\n",
        "# print(optim)\n",
        "optim.param_groups[0][\"lr\"] = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OksdjCeJYpYh",
        "outputId": "42212de0-f405-498e-8e88-aa150e769c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "<ipython-input-17-c26d148f32c5>:237: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "<ipython-input-17-c26d148f32c5>:203: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred tensor([-0.4847, -0.4535, -0.4575, -0.4638, -0.4787, -0.4668, -0.4271, -0.4408,\n",
            "        -0.4675, -0.4485, -0.4208, -0.4241, -0.4237, -0.4527, -0.4233, -0.4257,\n",
            "        -0.4561, -0.4078, -0.4343, -0.4213, -0.4175, -0.4354, -0.4240, -0.3753,\n",
            "        -0.4402], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 53.724037170410156 0.48714953660964966 1.8375042145635234e-06 0.6917220950126648 176\n",
            "pred tensor([-0.5171, -0.5095, -0.5466, -0.5407, -0.5231, -0.5302, -0.5208, -0.5207,\n",
            "        -0.5541, -0.5397, -0.5333, -0.4882, -0.5085, -0.5319, -0.5390, -0.5231,\n",
            "        -0.5231, -0.5200, -0.5282, -0.5144, -0.5142, -0.4907, -0.5142, -0.4929,\n",
            "        -0.5332], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 595.4003295898438 0.48354417085647583 9.387893442180939e-06 0.6974031925201416 1310\n",
            "pred tensor([-0.5171, -0.4907, -0.4952, -0.4796, -0.5078, -0.4927, -0.4686, -0.4802,\n",
            "        -0.4677, -0.4579, -0.4728, -0.5014, -0.4426, -0.4742, -0.4624, -0.4738,\n",
            "        -0.4377, -0.4453, -0.4578, -0.4371, -0.4525, -0.4541, -0.4586, -0.4573,\n",
            "        -0.4264], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 59.44352722167969 0.47495296597480774 0.00021537617431022227 0.6910675764083862 273\n",
            "pred tensor([-0.5182, -0.5315, -0.5194, -0.4829, -0.5175, -0.5273, -0.4877, -0.5295,\n",
            "        -0.5200, -0.5119, -0.5295, -0.5279, -0.5245, -0.5116, -0.5057, -0.5658,\n",
            "        -0.5113, -0.5285, -0.5313, -0.5085, -0.5112, -0.5310, -0.4963, -0.5032,\n",
            "        -0.4905], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 622.4459228515625 0.464489221572876 0.0038495303597301245 0.6964451670646667 1162\n",
            "pred tensor([-0.5463, -0.4897, -0.4918, -0.5129, -0.4994, -0.5183, -0.4988, -0.5401,\n",
            "        -0.5520, -0.5280, -0.5574, -0.5579, -0.6024, -0.5804, -0.5588, -0.5626,\n",
            "        -0.5648, -0.5310, -0.5438, -0.5507, -0.5169, -0.5515, -0.5642, -0.5311,\n",
            "        -0.5564], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 61.002357482910156 0.4528306722640991 0.0230457354336977 0.6929348111152649 1015\n",
            "pred tensor([-0.5452, -0.5122, -0.5485, -0.5117, -0.5386, -0.5369, -0.5554, -0.5772,\n",
            "        -0.5647, -0.5568, -0.5751, -0.5753, -0.5800, -0.5730, -0.5785, -0.5874,\n",
            "        -0.5554, -0.5493, -0.5866, -0.5571, -0.5707, -0.5518, -0.5910, -0.5784,\n",
            "        -0.5975], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 638.2970581054688 0.4236963987350464 0.28436893224716187 0.6974919438362122 1276\n",
            "pred tensor([-0.5033, -0.4795, -0.4599, -0.4630, -0.4487, -0.4606, -0.4229, -0.4528,\n",
            "        -0.4855, -0.4936, -0.4917, -0.5117, -0.4822, -0.5024, -0.5189, -0.5109,\n",
            "        -0.5106, -0.5070, -0.5048, -0.5145, -0.5506, -0.5045, -0.5191, -0.5151,\n",
            "        -0.5083], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 50.11812973022461 0.3973435163497925 1.0323810577392578 0.6932075619697571 823\n",
            "pred tensor([-0.4649, -0.5006, -0.4883, -0.4681, -0.4564, -0.4947, -0.5044, -0.4839,\n",
            "        -0.4904, -0.4957, -0.4676, -0.4669, -0.4728, -0.4969, -0.5024, -0.4514,\n",
            "        -0.4663, -0.4652, -0.4792, -0.4724, -0.4678, -0.4945, -0.4763, -0.4910,\n",
            "        -0.5172], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 571.6077270507812 0.3694382309913635 2.7003772258758545 0.6946267485618591 873\n",
            "pred tensor([-0.4920, -0.4794, -0.4525, -0.4794, -0.4642, -0.4893, -0.5027, -0.5250,\n",
            "        -0.5449, -0.5736, -0.5792, -0.5730, -0.5937, -0.5956, -0.6165, -0.6229,\n",
            "        -0.6383, -0.6473, -0.6550, -0.6301, -0.6296, -0.6057, -0.6107, -0.6430,\n",
            "        -0.6025], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 36.00614929199219 0.38142454624176025 1.6967236995697021 0.692272424697876 1041\n",
            "pred tensor([-0.5810, -0.5658, -0.5465, -0.5686, -0.5495, -0.5615, -0.5529, -0.5551,\n",
            "        -0.5704, -0.5638, -0.5712, -0.5638, -0.5670, -0.5501, -0.5694, -0.5475,\n",
            "        -0.5715, -0.5537, -0.5498, -0.5261, -0.5441, -0.5383, -0.5386, -0.5347,\n",
            "        -0.5272], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 488.17010498046875 0.42155182361602783 0.27984362840652466 0.6925230622291565 951\n",
            "pred tensor([-0.4825, -0.4751, -0.4785, -0.4543, -0.4694, -0.4667, -0.4764, -0.4711,\n",
            "        -0.4903, -0.4938, -0.4854, -0.5020, -0.4791, -0.5123, -0.4848, -0.4854,\n",
            "        -0.4746, -0.4669, -0.4756, -0.4585, -0.4649, -0.4707, -0.4990, -0.4749,\n",
            "        -0.4441], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 34.121620178222656 0.41166386008262634 0.45083916187286377 0.6821303963661194 374\n",
            "pred tensor([-0.4571, -0.4665, -0.4706, -0.4645, -0.4671, -0.4701, -0.4682, -0.4517,\n",
            "        -0.4554, -0.4678, -0.4544, -0.4415, -0.4548, -0.4782, -0.4503, -0.4699,\n",
            "        -0.4748, -0.4964, -0.5034, -0.4791, -0.4890, -0.4935, -0.4914, -0.5103,\n",
            "        -0.4941], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 479.4482421875 0.3956508934497833 0.9041699767112732 0.6946967244148254 572\n",
            "pred tensor([-0.4929, -0.5003, -0.5006, -0.4997, -0.4899, -0.4958, -0.4949, -0.5083,\n",
            "        -0.5021, -0.5030, -0.5134, -0.4924, -0.4760, -0.4888, -0.4758, -0.4866,\n",
            "        -0.4844, -0.5124, -0.5170, -0.5249, -0.5294, -0.5248, -0.5450, -0.5544,\n",
            "        -0.5605], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 26.844837188720703 0.3771092891693115 1.7799606323242188 0.6925802230834961 968\n",
            "pred tensor([-0.5581, -0.5555, -0.5597, -0.5687, -0.5614, -0.5474, -0.5515, -0.5596,\n",
            "        -0.5656, -0.5747, -0.5814, -0.5934, -0.5815, -0.5638, -0.5708, -0.5629,\n",
            "        -0.5680, -0.5833, -0.5822, -0.5939, -0.5814, -0.5939, -0.5984, -0.6003,\n",
            "        -0.5770], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 414.431396484375 0.36945804953575134 2.2969837188720703 0.6981412768363953 1269\n",
            "pred tensor([-0.5018, -0.5145, -0.5121, -0.5146, -0.5279, -0.5282, -0.5082, -0.5317,\n",
            "        -0.5302, -0.5146, -0.5306, -0.5112, -0.5084, -0.5005, -0.5181, -0.4938,\n",
            "        -0.5124, -0.5282, -0.5263, -0.5503, -0.5239, -0.5459, -0.5326, -0.5326,\n",
            "        -0.5353], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 21.826566696166992 0.3702264428138733 2.2511847019195557 0.6902806758880615 1041\n",
            "pred tensor([-0.5613, -0.5731, -0.5827, -0.5769, -0.5821, -0.5852, -0.5705, -0.5531,\n",
            "        -0.5583, -0.5371, -0.5425, -0.5321, -0.5373, -0.5346, -0.5201, -0.5319,\n",
            "        -0.5280, -0.5483, -0.5318, -0.5308, -0.5312, -0.5494, -0.5351, -0.5391,\n",
            "        -0.5391], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 364.3714599609375 0.3938710689544678 0.991008460521698 0.6976418495178223 1439\n",
            "pred tensor([-0.5010, -0.5076, -0.5078, -0.5105, -0.5154, -0.5240, -0.5400, -0.5059,\n",
            "        -0.5328, -0.5084, -0.4984, -0.4993, -0.4901, -0.5053, -0.5145, -0.5172,\n",
            "        -0.5454, -0.5405, -0.5546, -0.5421, -0.5420, -0.5292, -0.5294, -0.5442,\n",
            "        -0.5365], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 17.939739227294922 0.40535804629325867 0.6177530288696289 0.6899240612983704 1123\n",
            "pred tensor([-0.5379, -0.5424, -0.5260, -0.5338, -0.5305, -0.5233, -0.5475, -0.5398,\n",
            "        -0.5542, -0.5509, -0.5286, -0.5292, -0.5266, -0.5367, -0.5277, -0.5093,\n",
            "        -0.5167, -0.5186, -0.5180, -0.5170, -0.5249, -0.5315, -0.5389, -0.5421,\n",
            "        -0.5478], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 323.7094421386719 0.4134066700935364 0.4275897145271301 0.6897854208946228 1238\n",
            "pred tensor([-0.5099, -0.4992, -0.4975, -0.4969, -0.4942, -0.4957, -0.4770, -0.4784,\n",
            "        -0.4654, -0.4651, -0.4583, -0.4578, -0.4958, -0.5172, -0.5484, -0.5714,\n",
            "        -0.5659, -0.5722, -0.5681, -0.5542, -0.5547, -0.5864, -0.5673, -0.5927,\n",
            "        -0.5671], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 15.006570816040039 0.397976815700531 0.8460109233856201 0.6933401823043823 1029\n",
            "pred tensor([-0.5904, -0.5781, -0.5478, -0.5429, -0.5564, -0.5343, -0.5188, -0.5098,\n",
            "        -0.4850, -0.4724, -0.4621, -0.4487, -0.4440, -0.4392, -0.4284, -0.4410,\n",
            "        -0.4390, -0.4304, -0.4396, -0.4288, -0.4362, -0.4243, -0.4462, -0.4414,\n",
            "        -0.4442], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 293.4190673828125 0.3948787748813629 0.9541270732879639 0.6983731985092163 1012\n",
            "pred tensor([-0.5123, -0.5092, -0.4963, -0.4902, -0.4901, -0.4764, -0.4731, -0.4669,\n",
            "        -0.4630, -0.4730, -0.5268, -0.5635, -0.6125, -0.6540, -0.6979, -0.7037,\n",
            "        -0.7143, -0.6834, -0.6558, -0.6237, -0.6087, -0.5805, -0.5840, -0.5747,\n",
            "        -0.5771], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 12.583357810974121 0.3815332353115082 1.5656697750091553 0.714910089969635 1016\n",
            "pred tensor([-0.5580, -0.5408, -0.5311, -0.5537, -0.5451, -0.5841, -0.5554, -0.5691,\n",
            "        -0.5539, -0.5534, -0.5549, -0.5430, -0.5384, -0.5369, -0.5151, -0.5031,\n",
            "        -0.5118, -0.4976, -0.4985, -0.5118, -0.5166, -0.5080, -0.5029, -0.5087,\n",
            "        -0.5124], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 260.6324157714844 0.3681187033653259 2.4215426445007324 0.6966454982757568 980\n",
            "pred tensor([-0.5107, -0.5133, -0.5049, -0.4858, -0.4912, -0.4914, -0.4702, -0.4448,\n",
            "        -0.4508, -0.4571, -0.4847, -0.5578, -0.5854, -0.6435, -0.6485, -0.6596,\n",
            "        -0.6390, -0.6110, -0.5948, -0.5689, -0.5720, -0.5666, -0.5578, -0.5526,\n",
            "        -0.5202], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 10.318358421325684 0.36684077978134155 2.5201377868652344 0.6929439902305603 1018\n",
            "pred tensor([-0.5315, -0.5453, -0.5479, -0.5528, -0.5575, -0.5438, -0.5620, -0.5524,\n",
            "        -0.5478, -0.5589, -0.5570, -0.5601, -0.5569, -0.5667, -0.5866, -0.5805,\n",
            "        -0.5987, -0.5772, -0.5869, -0.5885, -0.5801, -0.6009, -0.5915, -0.6014,\n",
            "        -0.6042], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 231.25621032714844 0.38676387071609497 1.2919445037841797 0.691936194896698 940\n",
            "pred tensor([-0.5184, -0.5318, -0.5193, -0.5145, -0.5192, -0.5143, -0.5203, -0.5090,\n",
            "        -0.4932, -0.5042, -0.4921, -0.4837, -0.4967, -0.5119, -0.5141, -0.5375,\n",
            "        -0.5348, -0.5222, -0.5434, -0.5155, -0.5019, -0.4925, -0.4914, -0.4813,\n",
            "        -0.4644], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 8.436651229858398 0.3992830812931061 0.789586067199707 0.6965512633323669 1115\n",
            "pred tensor([-0.4952, -0.5061, -0.5130, -0.5368, -0.5720, -0.5633, -0.5489, -0.5567,\n",
            "        -0.5376, -0.5522, -0.5416, -0.5394, -0.5431, -0.5271, -0.5152, -0.5096,\n",
            "        -0.4958, -0.4731, -0.4737, -0.4611, -0.4641, -0.4663, -0.4807, -0.4646,\n",
            "        -0.4683], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 208.38809204101562 0.40242332220077515 0.6877074837684631 0.6960459351539612 1187\n",
            "pred tensor([-0.5250, -0.5250, -0.5252, -0.5182, -0.5355, -0.5313, -0.5240, -0.5204,\n",
            "        -0.5088, -0.4857, -0.4850, -0.4939, -0.5269, -0.5351, -0.5441, -0.5528,\n",
            "        -0.5445, -0.5345, -0.5246, -0.5661, -0.6026, -0.6203, -0.6286, -0.6264,\n",
            "        -0.6396], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 7.432535171508789 0.4019182622432709 0.7036721706390381 0.6957073211669922 1225\n",
            "pred tensor([-0.6290, -0.6356, -0.6127, -0.6125, -0.5890, -0.5961, -0.6050, -0.5831,\n",
            "        -0.6011, -0.5838, -0.5692, -0.5615, -0.5583, -0.5570, -0.5406, -0.5583,\n",
            "        -0.5523, -0.5536, -0.5563, -0.5503, -0.5543, -0.5554, -0.5449, -0.5511,\n",
            "        -0.5447], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 189.87074279785156 0.3870258033275604 1.2510933876037598 0.6966458559036255 1245\n",
            "pred tensor([-0.5226, -0.5254, -0.5218, -0.5292, -0.5288, -0.5279, -0.5132, -0.5056,\n",
            "        -0.4770, -0.4783, -0.4748, -0.4655, -0.4709, -0.4637, -0.4833, -0.5126,\n",
            "        -0.5368, -0.5415, -0.5573, -0.6024, -0.6142, -0.6227, -0.6161, -0.5977,\n",
            "        -0.5941], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 6.583855152130127 0.3768109083175659 1.774075984954834 0.6840346455574036 1335\n",
            "pred tensor([-0.6132, -0.5870, -0.5701, -0.5470, -0.5275, -0.5228, -0.5100, -0.5246,\n",
            "        -0.5221, -0.5277, -0.5372, -0.5310, -0.5309, -0.5127, -0.5290, -0.5091,\n",
            "        -0.5075, -0.5004, -0.5081, -0.4993, -0.5133, -0.5024, -0.5007, -0.4946,\n",
            "        -0.4920], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 172.34230041503906 0.37446296215057373 1.8957946300506592 0.6902617812156677 1258\n",
            "pred tensor([-0.5218, -0.5344, -0.5337, -0.5369, -0.5414, -0.5489, -0.5387, -0.5123,\n",
            "        -0.4981, -0.4734, -0.4555, -0.4556, -0.4542, -0.4624, -0.4487, -0.4800,\n",
            "        -0.5174, -0.5940, -0.6474, -0.6930, -0.7353, -0.7361, -0.7191, -0.6785,\n",
            "        -0.6621], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.70412540435791 0.38293370604515076 1.4042174816131592 0.6910412311553955 1253\n",
            "pred tensor([-0.6576, -0.6291, -0.5998, -0.5777, -0.5548, -0.5463, -0.5582, -0.5717,\n",
            "        -0.5737, -0.5744, -0.5734, -0.5441, -0.5478, -0.5343, -0.5231, -0.5398,\n",
            "        -0.5477, -0.5363, -0.5380, -0.5307, -0.5237, -0.5196, -0.5094, -0.5282,\n",
            "        -0.4962], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 146.1370086669922 0.382515013217926 1.4110380411148071 0.7017040848731995 863\n",
            "pred tensor([-0.5348, -0.5169, -0.5194, -0.5403, -0.5492, -0.5555, -0.5251, -0.5155,\n",
            "        -0.4779, -0.4872, -0.4873, -0.4933, -0.4941, -0.4925, -0.5173, -0.5945,\n",
            "        -0.6996, -0.7441, -0.7660, -0.7519, -0.7408, -0.7049, -0.6737, -0.6427,\n",
            "        -0.6030], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.823947429656982 0.37533965706825256 1.7846381664276123 0.702308177947998 1193\n",
            "pred tensor([-0.5433, -0.5352, -0.5074, -0.4945, -0.4883, -0.4863, -0.4706, -0.4713,\n",
            "        -0.4571, -0.4587, -0.4518, -0.4380, -0.4299, -0.4240, -0.4178, -0.4429,\n",
            "        -0.4405, -0.4447, -0.4444, -0.4395, -0.4233, -0.3993, -0.4063, -0.4126,\n",
            "        -0.4198], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 121.36477661132812 0.3760303556919098 1.7211230993270874 0.7103394865989685 135\n",
            "pred tensor([-0.5257, -0.5308, -0.5292, -0.5393, -0.5495, -0.5362, -0.5257, -0.4884,\n",
            "        -0.4907, -0.4681, -0.4629, -0.4787, -0.4891, -0.5354, -0.6125, -0.6653,\n",
            "        -0.7164, -0.7027, -0.6627, -0.5909, -0.5442, -0.4920, -0.4437, -0.4002,\n",
            "        -0.3782], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.748304843902588 0.38938596844673157 1.0427956581115723 0.6867214441299438 1050\n",
            "pred tensor([-0.3341, -0.2939, -0.2718, -0.2801, -0.2767, -0.2777, -0.2867, -0.3049,\n",
            "        -0.3414, -0.3662, -0.3796, -0.3838, -0.4007, -0.4050, -0.4158, -0.4145,\n",
            "        -0.4360, -0.4543, -0.4749, -0.4950, -0.5110, -0.5222, -0.5157, -0.5164,\n",
            "        -0.5049], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 109.990234375 0.3912261128425598 0.934731125831604 0.6924479603767395 527\n",
            "pred tensor([-0.5160, -0.5203, -0.5222, -0.5373, -0.5457, -0.5344, -0.5070, -0.4848,\n",
            "        -0.4697, -0.4661, -0.4686, -0.4738, -0.5161, -0.5477, -0.6252, -0.6969,\n",
            "        -0.7239, -0.7228, -0.6793, -0.6111, -0.5310, -0.4520, -0.4292, -0.4004,\n",
            "        -0.3560], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.253527641296387 0.38654080033302307 1.0893757343292236 0.7084959149360657 972\n",
            "pred tensor([-0.3306, -0.3309, -0.3509, -0.3563, -0.3439, -0.3313, -0.3505, -0.3594,\n",
            "        -0.4009, -0.4536, -0.4667, -0.4777, -0.4897, -0.4854, -0.4910, -0.4931,\n",
            "        -0.5297, -0.5272, -0.5446, -0.5507, -0.5455, -0.5512, -0.5552, -0.5678,\n",
            "        -0.5704], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 92.65686798095703 0.38494595885276794 1.1057822704315186 0.6902723908424377 853\n",
            "1\n",
            "pred tensor([-0.5361, -0.5437, -0.5524, -0.5577, -0.5623, -0.5527, -0.5416, -0.5046,\n",
            "        -0.5002, -0.4703, -0.4629, -0.5032, -0.5014, -0.5778, -0.6648, -0.7070,\n",
            "        -0.7189, -0.6884, -0.6421, -0.5848, -0.5140, -0.4607, -0.4062, -0.3612,\n",
            "        -0.3620], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.8986704349517822 0.36934149265289307 1.8583482503890991 0.6810070872306824 962\n",
            "pred tensor([-0.3784, -0.4101, -0.4208, -0.4273, -0.4449, -0.4830, -0.5368, -0.6179,\n",
            "        -0.6557, -0.6556, -0.6601, -0.6624, -0.6648, -0.6555, -0.6481, -0.6431,\n",
            "        -0.6160, -0.5945, -0.5703, -0.5469, -0.5197, -0.5136, -0.5109, -0.5056,\n",
            "        -0.5165], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 79.82701873779297 0.3712644875049591 1.5998948812484741 0.6929469108581543 1276\n",
            "pred tensor([-0.5270, -0.5218, -0.5362, -0.5377, -0.5455, -0.5329, -0.5164, -0.5097,\n",
            "        -0.4653, -0.4602, -0.4479, -0.4542, -0.4924, -0.5391, -0.6265, -0.6507,\n",
            "        -0.6534, -0.6158, -0.5531, -0.5019, -0.4983, -0.4582, -0.4255, -0.4185,\n",
            "        -0.4291], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.513641595840454 0.37845733761787415 1.1142868995666504 0.7029269337654114 905\n",
            "pred tensor([-0.4868, -0.4797, -0.4895, -0.5563, -0.6178, -0.6419, -0.6601, -0.6616,\n",
            "        -0.6387, -0.6138, -0.5974, -0.5722, -0.5535, -0.5731, -0.5919, -0.5963,\n",
            "        -0.5909, -0.5824, -0.5781, -0.5504, -0.5468, -0.5267, -0.5043, -0.5088,\n",
            "        -0.4877], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 67.0696029663086 0.380356103181839 0.9839784502983093 0.6965311169624329 1338\n",
            "pred tensor([-0.5399, -0.5319, -0.5424, -0.5445, -0.5270, -0.5152, -0.5018, -0.5076,\n",
            "        -0.4914, -0.5007, -0.5087, -0.5246, -0.5747, -0.6186, -0.6176, -0.5835,\n",
            "        -0.5282, -0.4731, -0.4518, -0.4822, -0.5134, -0.5147, -0.5287, -0.5109,\n",
            "        -0.5213], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.513486862182617 0.3716549575328827 1.2415187358856201 0.6949959993362427 1099\n",
            "pred tensor([-0.5673, -0.5912, -0.5952, -0.5965, -0.6191, -0.6335, -0.6207, -0.6125,\n",
            "        -0.6162, -0.5691, -0.5709, -0.5867, -0.6065, -0.6114, -0.5971, -0.5872,\n",
            "        -0.5824, -0.6049, -0.6101, -0.6093, -0.6137, -0.6123, -0.6461, -0.6386,\n",
            "        -0.6422], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 60.383182525634766 0.3610159158706665 1.6367018222808838 0.6980488896369934 1441\n",
            "pred tensor([-0.5194, -0.5262, -0.5268, -0.5164, -0.5105, -0.4951, -0.5064, -0.5047,\n",
            "        -0.5324, -0.5730, -0.5857, -0.6060, -0.5996, -0.5771, -0.5205, -0.4448,\n",
            "        -0.3861, -0.3849, -0.4030, -0.4686, -0.5301, -0.5729, -0.5629, -0.5772,\n",
            "        -0.5933], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.48988676071167 0.3581015169620514 1.7583189010620117 0.6940204501152039 1112\n",
            "pred tensor([-0.6192, -0.5619, -0.5251, -0.5072, -0.5034, -0.4833, -0.4641, -0.4334,\n",
            "        -0.4005, -0.3964, -0.4434, -0.4872, -0.4891, -0.5162, -0.5032, -0.5009,\n",
            "        -0.5292, -0.5757, -0.6065, -0.6387, -0.6422, -0.6279, -0.6189, -0.6360,\n",
            "        -0.6370], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 50.85356140136719 0.34872618317604065 2.2634973526000977 0.7012467384338379 968\n",
            "pred tensor([-0.5247, -0.5171, -0.5104, -0.5087, -0.4825, -0.4845, -0.4940, -0.5144,\n",
            "        -0.5506, -0.5985, -0.6391, -0.6239, -0.5697, -0.5060, -0.4094, -0.3398,\n",
            "        -0.3063, -0.3212, -0.3638, -0.4264, -0.5277, -0.5974, -0.6053, -0.6076,\n",
            "        -0.6202], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.5014946460723877 0.33691054582595825 3.077056407928467 0.6808213591575623 966\n",
            "pred tensor([-0.6335, -0.5780, -0.4997, -0.4758, -0.4512, -0.3786, -0.3744, -0.4103,\n",
            "        -0.3810, -0.3911, -0.4310, -0.5050, -0.5289, -0.5089, -0.5226, -0.5632,\n",
            "        -0.5711, -0.6139, -0.6380, -0.6755, -0.7026, -0.7158, -0.7284, -0.7391,\n",
            "        -0.7349], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 35.572166442871094 0.34523940086364746 2.515686511993408 0.6982647776603699 925\n",
            "pred tensor([-0.5176, -0.5146, -0.5061, -0.4905, -0.4678, -0.4713, -0.5120, -0.5562,\n",
            "        -0.6134, -0.6524, -0.6654, -0.6127, -0.5098, -0.4245, -0.3310, -0.2719,\n",
            "        -0.2584, -0.2911, -0.3647, -0.5061, -0.6268, -0.7047, -0.7410, -0.7311,\n",
            "        -0.6856], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.5401382446289062 0.3552534580230713 1.9364657402038574 0.7028326392173767 888\n",
            "pred tensor([-0.6259, -0.5513, -0.4375, -0.3905, -0.3437, -0.2795, -0.2662, -0.2658,\n",
            "        -0.2671, -0.2602, -0.3368, -0.4263, -0.5036, -0.5708, -0.5969, -0.6397,\n",
            "        -0.6806, -0.6948, -0.6887, -0.6685, -0.6330, -0.5669, -0.5291, -0.5147,\n",
            "        -0.5032], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 27.876724243164062 0.36283087730407715 1.5035706758499146 0.7088009119033813 930\n",
            "pred tensor([-0.5065, -0.5058, -0.4980, -0.4809, -0.4707, -0.4830, -0.5152, -0.5466,\n",
            "        -0.5908, -0.6199, -0.5714, -0.4442, -0.3374, -0.2595, -0.2271, -0.2488,\n",
            "        -0.2884, -0.3761, -0.5263, -0.6520, -0.6835, -0.7291, -0.7088, -0.6730,\n",
            "        -0.6153], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.560805320739746 0.36904215812683105 1.2277889251708984 0.7006734609603882 841\n",
            "pred tensor([-0.5281, -0.4264, -0.3553, -0.2934, -0.2615, -0.2414, -0.2391, -0.2288,\n",
            "        -0.2625, -0.3213, -0.3896, -0.4757, -0.5201, -0.5962, -0.6566, -0.6764,\n",
            "        -0.7004, -0.6843, -0.6749, -0.6480, -0.6299, -0.5922, -0.5521, -0.5225,\n",
            "        -0.4674], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 24.114398956298828 0.37167519330978394 1.0662944316864014 0.7291289567947388 876\n",
            "pred tensor([-0.5103, -0.5134, -0.4944, -0.4734, -0.4615, -0.4650, -0.5188, -0.5492,\n",
            "        -0.5800, -0.5978, -0.6222, -0.5438, -0.4229, -0.3428, -0.2605, -0.2471,\n",
            "        -0.2514, -0.2843, -0.3316, -0.4527, -0.5718, -0.6617, -0.6877, -0.6824,\n",
            "        -0.6559], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.5121545791625977 0.3650333881378174 1.2873334884643555 0.711873471736908 859\n",
            "pred tensor([-0.6009, -0.5717, -0.5050, -0.4248, -0.3563, -0.3085, -0.2648, -0.2316,\n",
            "        -0.2571, -0.2783, -0.3423, -0.4106, -0.5020, -0.5392, -0.5855, -0.6094,\n",
            "        -0.5969, -0.5311, -0.5246, -0.4882, -0.4284, -0.3925, -0.3614, -0.3290,\n",
            "        -0.2786], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 21.507400512695312 0.3637372851371765 1.3244985342025757 0.7006411552429199 590\n",
            "pred tensor([-0.5121, -0.5130, -0.5115, -0.5109, -0.4950, -0.4928, -0.5145, -0.5063,\n",
            "        -0.5244, -0.5347, -0.5105, -0.4507, -0.3648, -0.3186, -0.3025, -0.3303,\n",
            "        -0.3721, -0.4627, -0.5467, -0.5919, -0.5993, -0.6082, -0.5924, -0.5879,\n",
            "        -0.5526], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.4608330726623535 0.35088473558425903 1.993058443069458 0.7079471349716187 845\n",
            "pred tensor([-0.4948, -0.4580, -0.4045, -0.3983, -0.3714, -0.3437, -0.3687, -0.3641,\n",
            "        -0.3858, -0.4215, -0.4743, -0.5040, -0.5109, -0.4825, -0.4523, -0.4383,\n",
            "        -0.4470, -0.4515, -0.4587, -0.4118, -0.3700, -0.3634, -0.3333, -0.3276,\n",
            "        -0.3281], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 19.514263153076172 0.3553878962993622 1.7517411708831787 0.6949605941772461 169\n",
            "pred tensor([-0.5074, -0.5147, -0.5098, -0.5006, -0.4958, -0.5016, -0.5005, -0.4814,\n",
            "        -0.4576, -0.4841, -0.4836, -0.4598, -0.4384, -0.4057, -0.4053, -0.4113,\n",
            "        -0.4401, -0.4516, -0.5103, -0.5439, -0.5207, -0.4928, -0.4957, -0.4813,\n",
            "        -0.4898], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.348527193069458 0.35722455382347107 1.6003096103668213 0.696517825126648 459\n",
            "pred tensor([-0.4871, -0.4805, -0.4829, -0.4410, -0.4517, -0.4359, -0.4276, -0.4591,\n",
            "        -0.4602, -0.4386, -0.4579, -0.4806, -0.4942, -0.4452, -0.4095, -0.3998,\n",
            "        -0.4092, -0.4038, -0.4041, -0.4126, -0.4103, -0.3686, -0.3477, -0.3662,\n",
            "        -0.3702], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 17.94806480407715 0.34993284940719604 1.92662513256073 0.6875559687614441 61\n",
            "pred tensor([-0.5103, -0.5105, -0.5075, -0.5086, -0.4973, -0.5042, -0.4973, -0.4671,\n",
            "        -0.4360, -0.4542, -0.4764, -0.4698, -0.4432, -0.4400, -0.4583, -0.4685,\n",
            "        -0.4642, -0.4722, -0.5197, -0.5252, -0.4837, -0.4502, -0.4633, -0.4639,\n",
            "        -0.4827], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.2852659225463867 0.356435626745224 1.5175063610076904 0.6945727467536926 422\n",
            "pred tensor([-0.4951, -0.5050, -0.4891, -0.4502, -0.4680, -0.4573, -0.4428, -0.4882,\n",
            "        -0.5084, -0.4791, -0.4561, -0.4550, -0.4768, -0.4367, -0.3823, -0.3709,\n",
            "        -0.4057, -0.3797, -0.4025, -0.4355, -0.4594, -0.4248, -0.3737, -0.3910,\n",
            "        -0.4065], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 18.232816696166992 0.35436540842056274 1.5729690790176392 0.6959426999092102 197\n",
            "pred tensor([-0.5053, -0.5044, -0.4966, -0.5055, -0.5101, -0.5162, -0.4982, -0.4653,\n",
            "        -0.4405, -0.4719, -0.4939, -0.4946, -0.4886, -0.4778, -0.5175, -0.5216,\n",
            "        -0.4790, -0.4712, -0.5391, -0.5155, -0.4929, -0.4537, -0.4357, -0.4420,\n",
            "        -0.4710], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.245870351791382 0.35376960039138794 1.5571566820144653 0.696525514125824 547\n",
            "pred tensor([-0.5310, -0.5565, -0.5210, -0.5081, -0.4821, -0.4822, -0.4843, -0.5171,\n",
            "        -0.5509, -0.5302, -0.5076, -0.5049, -0.5140, -0.4863, -0.4336, -0.3997,\n",
            "        -0.3758, -0.3563, -0.3740, -0.3878, -0.4261, -0.4707, -0.4977, -0.5246,\n",
            "        -0.5577], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 18.383953094482422 0.3510538637638092 1.6398319005966187 0.7017410397529602 866\n",
            "pred tensor([-0.5050, -0.5106, -0.5132, -0.5024, -0.4996, -0.5058, -0.5093, -0.4714,\n",
            "        -0.4570, -0.4646, -0.4904, -0.4812, -0.4542, -0.4476, -0.5025, -0.5250,\n",
            "        -0.5147, -0.5651, -0.6032, -0.5564, -0.5086, -0.4800, -0.4844, -0.4954,\n",
            "        -0.5430], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.110184907913208 0.34396225214004517 1.9218779802322388 0.689935564994812 853\n",
            "pred tensor([-0.5475, -0.5076, -0.4488, -0.4192, -0.4085, -0.4412, -0.4946, -0.5769,\n",
            "        -0.5878, -0.5790, -0.6007, -0.6254, -0.5745, -0.5135, -0.4459, -0.4409,\n",
            "        -0.4632, -0.4811, -0.5173, -0.4936, -0.4454, -0.4343, -0.4412, -0.4463,\n",
            "        -0.4673], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 16.27775764465332 0.3316121995449066 2.5858206748962402 0.6966484785079956 670\n",
            "pred tensor([-0.5070, -0.5102, -0.4995, -0.5045, -0.5046, -0.5161, -0.5106, -0.4706,\n",
            "        -0.4723, -0.4838, -0.4550, -0.3957, -0.4115, -0.4826, -0.5238, -0.5999,\n",
            "        -0.6396, -0.5786, -0.5461, -0.5114, -0.5067, -0.5110, -0.5031, -0.4517,\n",
            "        -0.3974], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.004030466079712 0.3398128151893616 2.01324200630188 0.6997781991958618 919\n",
            "pred tensor([-0.3336, -0.3261, -0.3946, -0.4767, -0.5472, -0.5589, -0.6029, -0.6325,\n",
            "        -0.6009, -0.5419, -0.5058, -0.4768, -0.4778, -0.4907, -0.4634, -0.3920,\n",
            "        -0.3396, -0.3093, -0.3213, -0.4233, -0.4608, -0.5122, -0.5646, -0.6115,\n",
            "        -0.5981], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 14.213665962219238 0.33583739399909973 2.1231014728546143 0.6994023323059082 675\n",
            "pred tensor([-0.5013, -0.5028, -0.4996, -0.4986, -0.5031, -0.5124, -0.5119, -0.4814,\n",
            "        -0.4853, -0.4969, -0.4705, -0.4041, -0.3725, -0.4573, -0.5231, -0.6040,\n",
            "        -0.6272, -0.5740, -0.5479, -0.5153, -0.5214, -0.5433, -0.5134, -0.4553,\n",
            "        -0.3797], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.9793343544006348 0.33037257194519043 2.359821319580078 0.694816529750824 933\n",
            "pred tensor([-0.3452, -0.3437, -0.4013, -0.4938, -0.5523, -0.5652, -0.5972, -0.5990,\n",
            "        -0.5313, -0.4943, -0.4930, -0.4949, -0.5314, -0.5286, -0.4605, -0.3982,\n",
            "        -0.3513, -0.3556, -0.4087, -0.4580, -0.5228, -0.5832, -0.5912, -0.5756,\n",
            "        -0.5384], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 14.010944366455078 0.3306931257247925 2.355064868927002 0.7153058052062988 854\n",
            "pred tensor([-0.5047, -0.5071, -0.5026, -0.4915, -0.4989, -0.5170, -0.5166, -0.4779,\n",
            "        -0.4837, -0.5240, -0.5153, -0.4666, -0.3879, -0.4292, -0.5128, -0.5390,\n",
            "        -0.5752, -0.5704, -0.5184, -0.5019, -0.5079, -0.5260, -0.5664, -0.5765,\n",
            "        -0.5490], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.872229814529419 0.3330249786376953 2.2901132106781006 0.6932145357131958 998\n",
            "pred tensor([-0.5264, -0.4756, -0.4469, -0.4727, -0.5191, -0.5267, -0.5239, -0.5087,\n",
            "        -0.4994, -0.4996, -0.4571, -0.4972, -0.5229, -0.5466, -0.5659, -0.5527,\n",
            "        -0.5387, -0.4838, -0.4225, -0.4248, -0.4495, -0.4926, -0.5106, -0.5065,\n",
            "        -0.5277], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 13.700448989868164 0.33695557713508606 2.120173931121826 0.6949210166931152 767\n",
            "pred tensor([-0.5011, -0.5057, -0.5023, -0.4990, -0.4946, -0.4921, -0.4763, -0.4537,\n",
            "        -0.4699, -0.5368, -0.5626, -0.5115, -0.4321, -0.4249, -0.4628, -0.4492,\n",
            "        -0.4718, -0.4494, -0.4252, -0.4722, -0.5196, -0.5814, -0.6321, -0.6303,\n",
            "        -0.5677], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.708282470703125 0.33830127120018005 1.9760932922363281 0.6844200491905212 643\n",
            "pred tensor([-0.5093, -0.4651, -0.4232, -0.4517, -0.4659, -0.4282, -0.4182, -0.4190,\n",
            "        -0.3876, -0.4251, -0.5098, -0.5697, -0.6301, -0.6364, -0.5944, -0.4901,\n",
            "        -0.4469, -0.4420, -0.4626, -0.4469, -0.4578, -0.4551, -0.4489, -0.4055,\n",
            "        -0.3852], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 13.197391510009766 0.34395262598991394 1.7406301498413086 0.6856182217597961 402\n",
            "pred tensor([-0.5041, -0.5023, -0.5034, -0.5006, -0.4977, -0.4854, -0.4578, -0.4317,\n",
            "        -0.4400, -0.5187, -0.5913, -0.5758, -0.4797, -0.4216, -0.4030, -0.3548,\n",
            "        -0.3631, -0.3500, -0.3543, -0.4491, -0.5289, -0.6122, -0.6808, -0.6747,\n",
            "        -0.5908], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.612908363342285 0.3422900438308716 1.8393003940582275 0.6941077709197998 700\n",
            "pred tensor([-0.5351, -0.4436, -0.4047, -0.3979, -0.3396, -0.3365, -0.3185, -0.2967,\n",
            "        -0.3982, -0.5200, -0.6138, -0.6828, -0.6775, -0.5982, -0.5120, -0.4439,\n",
            "        -0.4174, -0.4067, -0.3479, -0.3531, -0.3351, -0.3340, -0.4151, -0.5020,\n",
            "        -0.5571], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 11.62472915649414 0.33704090118408203 1.9645992517471313 0.7083527445793152 481\n",
            "pred tensor([-0.5016, -0.5074, -0.5024, -0.4994, -0.4917, -0.4784, -0.4501, -0.4209,\n",
            "        -0.4542, -0.5461, -0.5897, -0.5504, -0.4567, -0.4285, -0.3854, -0.3515,\n",
            "        -0.3017, -0.3010, -0.3875, -0.4962, -0.6119, -0.6778, -0.6902, -0.6177,\n",
            "        -0.5494], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.5644381046295166 0.34389522671699524 1.6157619953155518 0.6842528581619263 715\n",
            "pred tensor([-0.5049, -0.4714, -0.4714, -0.3782, -0.3410, -0.3064, -0.2854, -0.3490,\n",
            "        -0.4599, -0.5602, -0.6608, -0.6909, -0.6546, -0.6031, -0.5354, -0.5187,\n",
            "        -0.4799, -0.4005, -0.3661, -0.3419, -0.3081, -0.3213, -0.3734, -0.4606,\n",
            "        -0.5478], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 10.857854843139648 0.3418410122394562 1.6933513879776 0.7200032472610474 531\n",
            "2\n",
            "pred tensor([-0.4987, -0.5032, -0.5000, -0.5024, -0.5015, -0.4911, -0.4645, -0.4148,\n",
            "        -0.4219, -0.5055, -0.5852, -0.5702, -0.5002, -0.4874, -0.4363, -0.3772,\n",
            "        -0.2931, -0.2828, -0.3486, -0.4470, -0.5773, -0.6593, -0.6624, -0.5993,\n",
            "        -0.5303], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.5449440479278564 0.3377560079097748 1.8652592897415161 0.6981179118156433 701\n",
            "pred tensor([-0.5108, -0.5848, -0.5455, -0.4602, -0.3563, -0.2758, -0.2916, -0.3703,\n",
            "        -0.4664, -0.5815, -0.6325, -0.6047, -0.5671, -0.5293, -0.5660, -0.5607,\n",
            "        -0.4976, -0.4285, -0.3576, -0.3219, -0.3387, -0.4003, -0.4945, -0.5629,\n",
            "        -0.6092], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 11.38192367553711 0.3303528130054474 2.235786199569702 0.696415901184082 806\n",
            "pred tensor([-0.4965, -0.5026, -0.5006, -0.5013, -0.5076, -0.5107, -0.4917, -0.4306,\n",
            "        -0.3808, -0.3939, -0.4836, -0.5471, -0.5368, -0.5327, -0.5907, -0.5685,\n",
            "        -0.4985, -0.3384, -0.2762, -0.2850, -0.3170, -0.4279, -0.5274, -0.5967,\n",
            "        -0.5556], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.506500720977783 0.33013248443603516 2.3284683227539062 0.6877174377441406 761\n",
            "pred tensor([-0.5446, -0.5545, -0.6545, -0.7059, -0.6421, -0.5020, -0.3443, -0.2774,\n",
            "        -0.2682, -0.3165, -0.4358, -0.5051, -0.5696, -0.5595, -0.5617, -0.6004,\n",
            "        -0.6873, -0.6657, -0.6112, -0.5172, -0.4109, -0.3230, -0.2974, -0.3432,\n",
            "        -0.3956], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 11.424768447875977 0.32787418365478516 2.4232354164123535 0.7154898047447205 812\n",
            "pred tensor([-0.4945, -0.4940, -0.4959, -0.5000, -0.5036, -0.5046, -0.4828, -0.4328,\n",
            "        -0.4118, -0.4427, -0.4966, -0.5238, -0.5708, -0.6445, -0.6150, -0.4187,\n",
            "        -0.3125, -0.2795, -0.2916, -0.3903, -0.4627, -0.5339, -0.5202, -0.5493,\n",
            "        -0.6059], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.440580368041992 0.33222654461860657 2.1394083499908447 0.6894903779029846 700\n",
            "pred tensor([-0.7305, -0.7561, -0.7007, -0.5206, -0.3592, -0.2862, -0.2829, -0.2922,\n",
            "        -0.3806, -0.4631, -0.4886, -0.5266, -0.5591, -0.6237, -0.7289, -0.7362,\n",
            "        -0.6973, -0.5916, -0.4322, -0.3472, -0.3212, -0.3221, -0.3463, -0.4546,\n",
            "        -0.5289], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 11.321849822998047 0.33804723620414734 1.8469319343566895 0.7202070355415344 763\n",
            "pred tensor([-0.4967, -0.4939, -0.4953, -0.4993, -0.5100, -0.5141, -0.4852, -0.4248,\n",
            "        -0.3891, -0.4048, -0.4659, -0.4884, -0.5446, -0.6703, -0.6952, -0.6182,\n",
            "        -0.4397, -0.3347, -0.2843, -0.2773, -0.3482, -0.3924, -0.4620, -0.4504,\n",
            "        -0.5055], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.374645948410034 0.3386749029159546 1.7968213558197021 0.6858029365539551 495\n",
            "pred tensor([-0.5623, -0.7145, -0.7824, -0.7393, -0.5793, -0.4201, -0.3485, -0.3116,\n",
            "        -0.2877, -0.3551, -0.4165, -0.4482, -0.4886, -0.5340, -0.6102, -0.7536,\n",
            "        -0.7538, -0.7205, -0.5522, -0.4115, -0.3762, -0.3417, -0.3330, -0.4019,\n",
            "        -0.4692], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 10.737927436828613 0.33812665939331055 1.7994861602783203 0.6950616240501404 639\n",
            "pred tensor([-0.4929, -0.4947, -0.4971, -0.4964, -0.5018, -0.5050, -0.4980, -0.4568,\n",
            "        -0.4291, -0.4343, -0.4632, -0.4994, -0.5904, -0.6718, -0.6204, -0.4620,\n",
            "        -0.3823, -0.3039, -0.3213, -0.3634, -0.4319, -0.4491, -0.5060, -0.6121,\n",
            "        -0.7461], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.3184876441955566 0.33549007773399353 1.9297113418579102 0.6827422976493835 541\n",
            "pred tensor([-0.7459, -0.6846, -0.5469, -0.4287, -0.3562, -0.2874, -0.3057, -0.3696,\n",
            "        -0.4266, -0.4603, -0.5108, -0.5979, -0.7351, -0.7333, -0.6915, -0.5384,\n",
            "        -0.4374, -0.3550, -0.2725, -0.2993, -0.4172, -0.4605, -0.4655, -0.4900,\n",
            "        -0.5260], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 10.590628623962402 0.3348045349121094 1.9533629417419434 0.6979373693466187 646\n",
            "pred tensor([-0.4935, -0.4954, -0.4921, -0.4970, -0.5064, -0.5165, -0.5073, -0.4483,\n",
            "        -0.4055, -0.4114, -0.4640, -0.5000, -0.5864, -0.6876, -0.6990, -0.5837,\n",
            "        -0.4563, -0.3419, -0.2899, -0.3119, -0.3749, -0.4457, -0.4846, -0.5289,\n",
            "        -0.6419], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.247842311859131 0.3226592242717743 2.619689464569092 0.6993693113327026 592\n",
            "pred tensor([-0.7287, -0.7264, -0.6546, -0.5393, -0.4297, -0.3312, -0.2938, -0.3336,\n",
            "        -0.3981, -0.4396, -0.4564, -0.5166, -0.6519, -0.7132, -0.7159, -0.5937,\n",
            "        -0.4916, -0.3653, -0.2979, -0.3211, -0.3629, -0.4345, -0.4308, -0.4670,\n",
            "        -0.5344], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 10.6375093460083 0.3254169523715973 2.3864357471466064 0.7303093075752258 597\n",
            "pred tensor([-0.4923, -0.4925, -0.4933, -0.4969, -0.5010, -0.5094, -0.4838, -0.4396,\n",
            "        -0.4343, -0.4690, -0.4835, -0.5051, -0.5939, -0.6606, -0.6329, -0.5219,\n",
            "        -0.4279, -0.3470, -0.3470, -0.3929, -0.4819, -0.4783, -0.4790, -0.5008,\n",
            "        -0.6309], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.1626055240631104 0.33410629630088806 1.9160966873168945 0.6960014700889587 498\n",
            "pred tensor([-0.6303, -0.6387, -0.5781, -0.5069, -0.4358, -0.3662, -0.3853, -0.4310,\n",
            "        -0.4985, -0.4864, -0.4387, -0.4628, -0.5516, -0.6295, -0.6481, -0.6118,\n",
            "        -0.5227, -0.4574, -0.3921, -0.3880, -0.3980, -0.4539, -0.5342, -0.4521,\n",
            "        -0.3899], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 9.509993553161621 0.32891571521759033 2.148395538330078 0.6984261870384216 600\n",
            "pred tensor([-0.4955, -0.4937, -0.4942, -0.4927, -0.4910, -0.4953, -0.5014, -0.4750,\n",
            "        -0.4493, -0.4740, -0.5191, -0.4889, -0.4750, -0.5621, -0.6084, -0.5754,\n",
            "        -0.5161, -0.4418, -0.4189, -0.4693, -0.5426, -0.5340, -0.4741, -0.4305,\n",
            "        -0.5287], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 2.0812177658081055 0.33298400044441223 1.9110355377197266 0.6998240947723389 579\n",
            "pred tensor([-0.5517, -0.5688, -0.5576, -0.5309, -0.4857, -0.4445, -0.4806, -0.5127,\n",
            "        -0.5362, -0.4645, -0.3891, -0.4280, -0.5101, -0.5343, -0.5450, -0.5485,\n",
            "        -0.5030, -0.4640, -0.4383, -0.4467, -0.4751, -0.5271, -0.5126, -0.4330,\n",
            "        -0.3875], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 8.695284843444824 0.3354703187942505 1.77809739112854 0.6987044811248779 800\n",
            "pred tensor([-0.4966, -0.4958, -0.4952, -0.4926, -0.4903, -0.4894, -0.4865, -0.4765,\n",
            "        -0.4790, -0.4903, -0.5067, -0.4459, -0.4504, -0.5200, -0.5226, -0.5152,\n",
            "        -0.5301, -0.5627, -0.6036, -0.4962, -0.4096, -0.4465, -0.5159, -0.5289,\n",
            "        -0.5573], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.962856650352478 0.33690401911735535 1.686129093170166 0.6841217279434204 692\n",
            "pred tensor([-0.5480, -0.5726, -0.5580, -0.5894, -0.5901, -0.6010, -0.4761, -0.3805,\n",
            "        -0.4038, -0.4411, -0.4750, -0.5150, -0.5479, -0.5509, -0.5418, -0.5379,\n",
            "        -0.5236, -0.5116, -0.5306, -0.4508, -0.3092, -0.3098, -0.3660, -0.3583,\n",
            "        -0.3478], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 8.370190620422363 0.3308296203613281 1.9088561534881592 0.7043271660804749 928\n",
            "pred tensor([-0.4990, -0.4987, -0.4991, -0.4979, -0.4910, -0.4807, -0.4907, -0.4895,\n",
            "        -0.4898, -0.5522, -0.5949, -0.5603, -0.4251, -0.4197, -0.4803, -0.5247,\n",
            "        -0.5297, -0.5668, -0.5973, -0.6507, -0.6751, -0.6543, -0.4847, -0.3817,\n",
            "        -0.4044], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.922298789024353 0.3267016112804413 2.091073989868164 0.6957088708877563 684\n",
            "pred tensor([-0.4636, -0.4768, -0.5184, -0.5303, -0.5771, -0.6273, -0.6659, -0.6990,\n",
            "        -0.5652, -0.4233, -0.4053, -0.4455, -0.4491, -0.5063, -0.5080, -0.5391,\n",
            "        -0.5878, -0.6318, -0.6159, -0.5938, -0.5055, -0.4215, -0.4168, -0.4216,\n",
            "        -0.4238], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 9.01016902923584 0.32935774326324463 1.927055835723877 0.69664466381073 912\n",
            "pred tensor([-0.5050, -0.5010, -0.4996, -0.4964, -0.4887, -0.4807, -0.4857, -0.4807,\n",
            "        -0.5128, -0.5783, -0.5918, -0.4743, -0.4319, -0.4861, -0.5207, -0.5252,\n",
            "        -0.5649, -0.6277, -0.7016, -0.7291, -0.6201, -0.4797, -0.4178, -0.4616,\n",
            "        -0.5132], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.8678637742996216 0.32863131165504456 1.8885080814361572 0.6764448285102844 753\n",
            "pred tensor([-0.5133, -0.4889, -0.5410, -0.6308, -0.7150, -0.7578, -0.6491, -0.4665,\n",
            "        -0.4111, -0.4672, -0.4911, -0.5010, -0.4658, -0.5226, -0.6208, -0.6915,\n",
            "        -0.7392, -0.6414, -0.4613, -0.4090, -0.4153, -0.4734, -0.4641, -0.4761,\n",
            "        -0.4852], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 8.919846534729004 0.32568442821502686 1.969303846359253 0.7139802575111389 770\n",
            "pred tensor([-0.4975, -0.4975, -0.4982, -0.4978, -0.4956, -0.4925, -0.4876, -0.5075,\n",
            "        -0.5510, -0.5558, -0.4723, -0.4681, -0.4986, -0.4921, -0.5363, -0.6238,\n",
            "        -0.7004, -0.7382, -0.6582, -0.5088, -0.4444, -0.4746, -0.5126, -0.5075,\n",
            "        -0.4864], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.7890127897262573 0.3211369812488556 2.17205548286438 0.6893983483314514 702\n",
            "pred tensor([-0.5227, -0.6139, -0.7053, -0.7517, -0.7236, -0.5349, -0.4650, -0.4738,\n",
            "        -0.5133, -0.4839, -0.4498, -0.4967, -0.5983, -0.6853, -0.7533, -0.7194,\n",
            "        -0.5115, -0.4376, -0.4616, -0.4749, -0.4512, -0.4357, -0.4192, -0.4735,\n",
            "        -0.5329], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 8.934715270996094 0.31393200159072876 2.5269317626953125 0.7009942531585693 813\n",
            "pred tensor([-0.4967, -0.4980, -0.4993, -0.4994, -0.4914, -0.4850, -0.4811, -0.4763,\n",
            "        -0.5040, -0.5673, -0.6019, -0.5145, -0.4691, -0.4973, -0.4988, -0.4746,\n",
            "        -0.5336, -0.6110, -0.6893, -0.7287, -0.6865, -0.5609, -0.4807, -0.4967,\n",
            "        -0.5110], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.7321146726608276 0.30713343620300293 2.9329774379730225 0.6889567971229553 781\n",
            "pred tensor([-0.5151, -0.4658, -0.4856, -0.5812, -0.6575, -0.7035, -0.7108, -0.6101,\n",
            "        -0.5140, -0.5202, -0.5204, -0.5108, -0.4645, -0.4661, -0.5153, -0.6206,\n",
            "        -0.6733, -0.7107, -0.6777, -0.6061, -0.5148, -0.4623, -0.4690, -0.4639,\n",
            "        -0.4461], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 8.738883018493652 0.3103112578392029 2.776845932006836 0.7110264301300049 988\n",
            "pred tensor([-0.4998, -0.4970, -0.4992, -0.4975, -0.4960, -0.4942, -0.4845, -0.4915,\n",
            "        -0.5226, -0.5300, -0.4911, -0.4855, -0.5017, -0.4681, -0.5122, -0.5881,\n",
            "        -0.6442, -0.6745, -0.5890, -0.5136, -0.5341, -0.5344, -0.5499, -0.4944,\n",
            "        -0.4608], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.6429842710494995 0.3185100257396698 2.3256149291992188 0.6892077922821045 841\n",
            "pred tensor([-0.5244, -0.5982, -0.6372, -0.6528, -0.5666, -0.5017, -0.5590, -0.5622,\n",
            "        -0.5681, -0.4823, -0.4512, -0.5468, -0.6145, -0.6295, -0.6240, -0.4895,\n",
            "        -0.4916, -0.5499, -0.5293, -0.4862, -0.4314, -0.4954, -0.5840, -0.5895,\n",
            "        -0.5886], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 7.681909561157227 0.32866406440734863 1.864816665649414 0.6985296010971069 1163\n",
            "pred tensor([-0.4976, -0.4966, -0.4960, -0.4963, -0.4956, -0.4927, -0.4861, -0.4840,\n",
            "        -0.4917, -0.4905, -0.4780, -0.4968, -0.5056, -0.4677, -0.5095, -0.6014,\n",
            "        -0.5872, -0.5088, -0.4816, -0.5783, -0.6131, -0.5911, -0.4989, -0.4506,\n",
            "        -0.5048], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.586538553237915 0.32951515913009644 1.8623261451721191 0.6874275803565979 728\n",
            "pred tensor([-0.5518, -0.5700, -0.5514, -0.4770, -0.4696, -0.5976, -0.6568, -0.6018,\n",
            "        -0.5055, -0.4289, -0.4903, -0.5650, -0.5560, -0.5252, -0.4376, -0.4622,\n",
            "        -0.5984, -0.6065, -0.5486, -0.4630, -0.4241, -0.5156, -0.5805, -0.5477,\n",
            "        -0.5171], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 7.7106614112854 0.33234694600105286 1.6648783683776855 0.693361222743988 1039\n",
            "pred tensor([-0.4997, -0.4994, -0.4979, -0.4983, -0.4972, -0.4953, -0.4816, -0.4762,\n",
            "        -0.4935, -0.4968, -0.4945, -0.5433, -0.5765, -0.4837, -0.4400, -0.4942,\n",
            "        -0.5568, -0.5452, -0.5240, -0.4958, -0.5758, -0.6685, -0.6313, -0.5664,\n",
            "        -0.4367], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.55277419090271 0.32704561948776245 1.8797025680541992 0.6929445266723633 607\n",
            "pred tensor([-0.4082, -0.4843, -0.5465, -0.5332, -0.5328, -0.5278, -0.6222, -0.6964,\n",
            "        -0.6061, -0.4920, -0.3916, -0.4416, -0.5383, -0.5325, -0.5378, -0.5065,\n",
            "        -0.6026, -0.6757, -0.5841, -0.4718, -0.3948, -0.4189, -0.5150, -0.5279,\n",
            "        -0.4923], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 7.751162528991699 0.3181121349334717 2.2723701000213623 0.6942033171653748 1073\n",
            "pred tensor([-0.4984, -0.4969, -0.4967, -0.4992, -0.5023, -0.5020, -0.4848, -0.4687,\n",
            "        -0.4759, -0.4861, -0.4930, -0.5294, -0.6079, -0.5746, -0.4398, -0.3884,\n",
            "        -0.4477, -0.5017, -0.5210, -0.5166, -0.4709, -0.5491, -0.6746, -0.6926,\n",
            "        -0.6075], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.5117884874343872 0.3059861361980438 2.955404043197632 0.6791374683380127 600\n",
            "pred tensor([-0.4262, -0.3438, -0.4131, -0.4846, -0.5218, -0.4994, -0.4729, -0.5620,\n",
            "        -0.6957, -0.6872, -0.5743, -0.3912, -0.3716, -0.4327, -0.4991, -0.5166,\n",
            "        -0.5073, -0.5194, -0.6353, -0.7016, -0.6093, -0.4886, -0.4262, -0.4109,\n",
            "        -0.4478], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 7.2364726066589355 0.3098009526729584 2.729013681411743 0.6992279887199402 982\n",
            "pred tensor([-0.4954, -0.4972, -0.4965, -0.4978, -0.4955, -0.4926, -0.4842, -0.4813,\n",
            "        -0.4832, -0.4847, -0.4976, -0.5423, -0.5117, -0.3998, -0.4162, -0.4777,\n",
            "        -0.4928, -0.4607, -0.4941, -0.6187, -0.7045, -0.6556, -0.5084, -0.3800,\n",
            "        -0.3603], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.4767391681671143 0.3171151280403137 2.3137011528015137 0.6726253032684326 442\n",
            "pred tensor([-0.3998, -0.4365, -0.4550, -0.4724, -0.4358, -0.5256, -0.6824, -0.7339,\n",
            "        -0.6668, -0.4791, -0.3501, -0.3613, -0.4183, -0.4592, -0.4821, -0.4850,\n",
            "        -0.5081, -0.6448, -0.7338, -0.6959, -0.5767, -0.4022, -0.3685, -0.4032,\n",
            "        -0.4526], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 7.443578720092773 0.3244017958641052 1.9675222635269165 0.7121526598930359 619\n",
            "pred tensor([-0.4948, -0.4961, -0.4939, -0.4977, -0.5022, -0.4978, -0.4809, -0.4669,\n",
            "        -0.4667, -0.4670, -0.4657, -0.5363, -0.6028, -0.5050, -0.3882, -0.4056,\n",
            "        -0.4247, -0.4447, -0.4630, -0.4424, -0.5422, -0.6842, -0.7005, -0.6258,\n",
            "        -0.4401], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.4629101753234863 0.32579025626182556 1.9818381071090698 0.6745187640190125 425\n",
            "pred tensor([-0.3520, -0.3812, -0.3972, -0.4299, -0.4588, -0.4431, -0.5270, -0.6805,\n",
            "        -0.7198, -0.6488, -0.4748, -0.3449, -0.3673, -0.4057, -0.4425, -0.4772,\n",
            "        -0.4837, -0.5250, -0.6590, -0.7033, -0.6616, -0.5706, -0.3807, -0.3556,\n",
            "        -0.3927], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 7.644749164581299 0.32250115275382996 2.095144033432007 0.6929100751876831 607\n",
            "3\n",
            "pred tensor([-0.4947, -0.4964, -0.4967, -0.4975, -0.4969, -0.4891, -0.4818, -0.4838,\n",
            "        -0.4801, -0.4940, -0.5296, -0.5276, -0.4419, -0.4096, -0.4229, -0.4261,\n",
            "        -0.4239, -0.4726, -0.6337, -0.7137, -0.6440, -0.4895, -0.3781, -0.3868,\n",
            "        -0.3989], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.4020837545394897 0.3254763185977936 1.9011880159378052 0.6815590262413025 414\n",
            "pred tensor([-0.4030, -0.3936, -0.4304, -0.4382, -0.6173, -0.7391, -0.6892, -0.5637,\n",
            "        -0.4001, -0.3730, -0.3949, -0.4093, -0.4071, -0.4473, -0.4657, -0.6548,\n",
            "        -0.7366, -0.6686, -0.5334, -0.3928, -0.3745, -0.4045, -0.4316, -0.4091,\n",
            "        -0.4694], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 6.426591396331787 0.3214658200740814 2.105252265930176 0.7060393691062927 526\n",
            "pred tensor([-0.4941, -0.4949, -0.4953, -0.4961, -0.4948, -0.4928, -0.4891, -0.4885,\n",
            "        -0.4891, -0.4923, -0.4978, -0.4912, -0.4733, -0.4607, -0.4289, -0.4183,\n",
            "        -0.5892, -0.6625, -0.5793, -0.4598, -0.4239, -0.4127, -0.4049, -0.3823,\n",
            "        -0.3890], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.3822702169418335 0.31129834055900574 2.6185336112976074 0.6852328181266785 426\n",
            "pred tensor([-0.3657, -0.4180, -0.5844, -0.7032, -0.6562, -0.5908, -0.5051, -0.4236,\n",
            "        -0.4237, -0.4211, -0.4081, -0.3863, -0.4149, -0.4274, -0.4566, -0.5614,\n",
            "        -0.6641, -0.6890, -0.6268, -0.6020, -0.5119, -0.4424, -0.4339, -0.4622,\n",
            "        -0.4714], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 6.30605411529541 0.30598872900009155 2.8939895629882812 0.6851460337638855 492\n",
            "pred tensor([-0.4941, -0.5013, -0.4955, -0.4967, -0.4996, -0.4940, -0.4886, -0.4874,\n",
            "        -0.4851, -0.4875, -0.5124, -0.5224, -0.4776, -0.4681, -0.4471, -0.3956,\n",
            "        -0.3461, -0.4383, -0.6414, -0.6655, -0.5959, -0.4890, -0.4523, -0.4582,\n",
            "        -0.4362], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.331858515739441 0.3127787113189697 2.528815984725952 0.68064945936203 404\n",
            "pred tensor([-0.3877, -0.3770, -0.3242, -0.4175, -0.6349, -0.6856, -0.6328, -0.5097,\n",
            "        -0.4596, -0.4611, -0.4488, -0.3892, -0.3887, -0.3603, -0.5400, -0.6768,\n",
            "        -0.6509, -0.6001, -0.4636, -0.4500, -0.4509, -0.4609, -0.4151, -0.4280,\n",
            "        -0.4640], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 6.261383056640625 0.32654905319213867 1.9040732383728027 0.7020625472068787 486\n",
            "pred tensor([-0.4967, -0.4954, -0.4958, -0.4958, -0.4969, -0.4953, -0.4933, -0.4894,\n",
            "        -0.4855, -0.4822, -0.4919, -0.5255, -0.5166, -0.4658, -0.4705, -0.4560,\n",
            "        -0.3870, -0.3506, -0.4383, -0.6419, -0.6740, -0.5886, -0.4809, -0.4553,\n",
            "        -0.4867], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.2920641899108887 0.33088767528533936 1.696315050125122 0.6709783673286438 383\n",
            "pred tensor([-0.4638, -0.3957, -0.3710, -0.3527, -0.4411, -0.6475, -0.6877, -0.6017,\n",
            "        -0.4832, -0.4483, -0.4668, -0.4520, -0.3805, -0.3995, -0.4012, -0.5709,\n",
            "        -0.6815, -0.6265, -0.5756, -0.4765, -0.4616, -0.4667, -0.4692, -0.4251,\n",
            "        -0.4333], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 6.19228458404541 0.33298859000205994 1.6127231121063232 0.71164470911026 516\n",
            "pred tensor([-0.4983, -0.4950, -0.4971, -0.4974, -0.4964, -0.4941, -0.4924, -0.4943,\n",
            "        -0.4931, -0.4914, -0.4870, -0.4909, -0.4826, -0.4568, -0.4962, -0.5598,\n",
            "        -0.4686, -0.4679, -0.4916, -0.4462, -0.3917, -0.3765, -0.4675, -0.6541,\n",
            "        -0.6974], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.268650770187378 0.3149019479751587 2.398284912109375 0.6827979683876038 379\n",
            "pred tensor([-0.5779, -0.4727, -0.4516, -0.4668, -0.5051, -0.4926, -0.4361, -0.4245,\n",
            "        -0.4560, -0.4578, -0.5788, -0.6797, -0.6359, -0.5623, -0.5113, -0.4627,\n",
            "        -0.4643, -0.4837, -0.4817, -0.4853, -0.4716, -0.5083, -0.5112, -0.5472,\n",
            "        -0.6272], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.9076104164123535 0.3006170094013214 3.255155563354492 0.6970325112342834 603\n",
            "pred tensor([-0.4987, -0.4995, -0.4975, -0.4970, -0.5010, -0.5067, -0.5010, -0.4813,\n",
            "        -0.4887, -0.4880, -0.4426, -0.4615, -0.5942, -0.6029, -0.5035, -0.4441,\n",
            "        -0.4949, -0.5290, -0.5044, -0.4197, -0.4276, -0.4160, -0.5478, -0.6922,\n",
            "        -0.6022], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.2186808586120605 0.30544742941856384 2.9502665996551514 0.6976584196090698 502\n",
            "pred tensor([-0.4810, -0.4210, -0.4730, -0.5369, -0.5125, -0.4506, -0.4580, -0.4485,\n",
            "        -0.6042, -0.6731, -0.5381, -0.4444, -0.4570, -0.5211, -0.5218, -0.4626,\n",
            "        -0.4531, -0.4423, -0.5245, -0.6509, -0.6044, -0.5032, -0.4631, -0.4899,\n",
            "        -0.4985], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.403313636779785 0.31525498628616333 2.3835196495056152 0.6942795515060425 723\n",
            "pred tensor([-0.4951, -0.4972, -0.4987, -0.4989, -0.4950, -0.4911, -0.4942, -0.4907,\n",
            "        -0.5024, -0.5147, -0.4943, -0.4553, -0.4901, -0.5292, -0.4866, -0.4784,\n",
            "        -0.5429, -0.6589, -0.5419, -0.4152, -0.4044, -0.4824, -0.5491, -0.5380,\n",
            "        -0.4769], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.1878913640975952 0.33382728695869446 1.5734885931015015 0.6874093413352966 535\n",
            "pred tensor([-0.5555, -0.5303, -0.6090, -0.6622, -0.4664, -0.3713, -0.3987, -0.5194,\n",
            "        -0.5578, -0.5342, -0.5505, -0.5328, -0.5645, -0.6657, -0.5146, -0.4214,\n",
            "        -0.3877, -0.4423, -0.5274, -0.5701, -0.5258, -0.5619, -0.5543, -0.5674,\n",
            "        -0.6610], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.567091464996338 0.3365703821182251 1.4886391162872314 0.6994257569313049 1137\n",
            "pred tensor([-0.4955, -0.5009, -0.4995, -0.4985, -0.4984, -0.4961, -0.4891, -0.4939,\n",
            "        -0.4918, -0.4979, -0.5040, -0.4778, -0.4649, -0.5182, -0.5279, -0.5197,\n",
            "        -0.5481, -0.6277, -0.4965, -0.3878, -0.3907, -0.4856, -0.5636, -0.5686,\n",
            "        -0.5259], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.1576313972473145 0.32377099990844727 2.003312349319458 0.6807693839073181 683\n",
            "pred tensor([-0.6159, -0.5781, -0.6146, -0.6342, -0.4488, -0.3623, -0.3626, -0.4490,\n",
            "        -0.5547, -0.5796, -0.5480, -0.6192, -0.5916, -0.6018, -0.6507, -0.5282,\n",
            "        -0.3978, -0.3463, -0.3792, -0.4631, -0.5624, -0.5859, -0.5640, -0.5945,\n",
            "        -0.6100], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 5.670981407165527 0.3192802667617798 2.2146880626678467 0.7017417550086975 1107\n",
            "pred tensor([-0.4980, -0.4963, -0.4965, -0.5047, -0.4960, -0.4905, -0.4942, -0.4947,\n",
            "        -0.4972, -0.5056, -0.5157, -0.4999, -0.4322, -0.4596, -0.5217, -0.5257,\n",
            "        -0.5625, -0.5751, -0.6205, -0.6130, -0.4249, -0.3353, -0.3791, -0.4886,\n",
            "        -0.5569], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.1368950605392456 0.30568477511405945 2.949458599090576 0.6892092823982239 674\n",
            "pred tensor([-0.5351, -0.5452, -0.6163, -0.5900, -0.6454, -0.5937, -0.3861, -0.3218,\n",
            "        -0.3970, -0.5111, -0.5585, -0.5384, -0.6146, -0.5924, -0.6421, -0.6079,\n",
            "        -0.3946, -0.3319, -0.3880, -0.4835, -0.5608, -0.5694, -0.5919, -0.6219,\n",
            "        -0.6293], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.9941606521606445 0.3092248737812042 2.705789804458618 0.6936957836151123 1070\n",
            "pred tensor([-0.4952, -0.4971, -0.4993, -0.4960, -0.4957, -0.4930, -0.4939, -0.4962,\n",
            "        -0.4985, -0.4896, -0.4591, -0.4573, -0.5017, -0.5070, -0.5727, -0.5988,\n",
            "        -0.5810, -0.3949, -0.3385, -0.4141, -0.4988, -0.5213, -0.5254, -0.6163,\n",
            "        -0.5950], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.0795626640319824 0.30809539556503296 2.8966779708862305 0.6839791536331177 578\n",
            "pred tensor([-0.6098, -0.6279, -0.4069, -0.3197, -0.3467, -0.4586, -0.5010, -0.5094,\n",
            "        -0.6278, -0.6051, -0.6071, -0.5863, -0.3796, -0.3384, -0.3725, -0.4714,\n",
            "        -0.5086, -0.5295, -0.6178, -0.5794, -0.6113, -0.5200, -0.3791, -0.3718,\n",
            "        -0.3760], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.177361488342285 0.32426804304122925 1.9622163772583008 0.6809359788894653 931\n",
            "pred tensor([-0.4950, -0.4984, -0.4934, -0.4942, -0.4931, -0.4912, -0.4911, -0.4926,\n",
            "        -0.4942, -0.5014, -0.4962, -0.4706, -0.4594, -0.4748, -0.4954, -0.5753,\n",
            "        -0.5766, -0.5289, -0.3452, -0.3103, -0.3879, -0.4735, -0.4884, -0.5389,\n",
            "        -0.6562], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 1.0969845056533813 0.34041234850883484 1.397815227508545 0.6793710589408875 455\n",
            "pred tensor([-0.6604, -0.6234, -0.5737, -0.3526, -0.2781, -0.3399, -0.4211, -0.4779,\n",
            "        -0.5212, -0.6600, -0.6803, -0.6345, -0.5953, -0.3532, -0.2919, -0.3463,\n",
            "        -0.4373, -0.4900, -0.5336, -0.6744, -0.6746, -0.6391, -0.5639, -0.3852,\n",
            "        -0.3250], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.7716755867004395 0.3354288339614868 1.628827452659607 0.7110590934753418 750\n",
            "pred tensor([-0.4950, -0.4953, -0.4943, -0.4941, -0.4897, -0.4924, -0.4960, -0.5032,\n",
            "        -0.5093, -0.4800, -0.4336, -0.4245, -0.4639, -0.5128, -0.6322, -0.6225,\n",
            "        -0.6030, -0.3885, -0.2981, -0.3166, -0.4039, -0.4482, -0.4874, -0.6400,\n",
            "        -0.6666], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.0472902059555054 0.3197605609893799 2.341156482696533 0.6682376265525818 435\n",
            "pred tensor([-0.6350, -0.6152, -0.3770, -0.2846, -0.3055, -0.3896, -0.4102, -0.5359,\n",
            "        -0.6912, -0.6352, -0.6080, -0.4080, -0.2912, -0.3181, -0.3659, -0.3976,\n",
            "        -0.4975, -0.6677, -0.6203, -0.5895, -0.4755, -0.3256, -0.3597, -0.3846,\n",
            "        -0.3968], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.166136264801025 0.31745606660842896 2.370133638381958 0.676834225654602 697\n",
            "pred tensor([-0.4947, -0.4952, -0.4924, -0.4923, -0.4933, -0.4927, -0.4953, -0.4989,\n",
            "        -0.4966, -0.4747, -0.4511, -0.4426, -0.4571, -0.5590, -0.6413, -0.6038,\n",
            "        -0.3949, -0.3079, -0.3180, -0.3759, -0.3984, -0.5199, -0.7310, -0.6986,\n",
            "        -0.6511], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.0278748273849487 0.302633672952652 3.1057324409484863 0.6660364270210266 435\n",
            "pred tensor([-0.5776, -0.3519, -0.2808, -0.2829, -0.3440, -0.3558, -0.5705, -0.7478,\n",
            "        -0.6840, -0.6370, -0.3791, -0.2832, -0.2692, -0.3269, -0.3566, -0.5317,\n",
            "        -0.7292, -0.6838, -0.6354, -0.3957, -0.2959, -0.2841, -0.3245, -0.3606,\n",
            "        -0.4387], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 5.2579450607299805 0.3056457042694092 3.0252246856689453 0.7064718008041382 685\n",
            "pred tensor([-0.4962, -0.4943, -0.4935, -0.4980, -0.4978, -0.4945, -0.4915, -0.4870,\n",
            "        -0.4873, -0.4950, -0.5056, -0.5004, -0.4582, -0.4121, -0.3870, -0.4165,\n",
            "        -0.6192, -0.6799, -0.6214, -0.4540, -0.3390, -0.2881, -0.3030, -0.3333,\n",
            "        -0.3500], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.0206420421600342 0.3189106285572052 2.253279685974121 0.656233549118042 396\n",
            "pred tensor([-0.5319, -0.7547, -0.7239, -0.6419, -0.5385, -0.3472, -0.2806, -0.2713,\n",
            "        -0.3017, -0.3076, -0.4896, -0.7560, -0.7238, -0.6386, -0.4769, -0.3283,\n",
            "        -0.2751, -0.2789, -0.3098, -0.3604, -0.5914, -0.7539, -0.6822, -0.5890,\n",
            "        -0.4166], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.178887844085693 0.3342539668083191 1.6008853912353516 0.7370131015777588 674\n",
            "pred tensor([-0.4918, -0.4962, -0.4936, -0.4955, -0.4945, -0.4981, -0.4945, -0.4837,\n",
            "        -0.4700, -0.4638, -0.4699, -0.5464, -0.6051, -0.5453, -0.4022, -0.3575,\n",
            "        -0.3312, -0.3380, -0.3518, -0.5224, -0.7400, -0.7089, -0.6243, -0.5565,\n",
            "        -0.3725], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.9909428954124451 0.3310396075248718 1.690263032913208 0.6546222567558289 366\n",
            "pred tensor([-0.3268, -0.2964, -0.2896, -0.2992, -0.3199, -0.5545, -0.7512, -0.6812,\n",
            "        -0.5767, -0.4789, -0.3519, -0.3003, -0.2764, -0.2995, -0.2963, -0.5122,\n",
            "        -0.7183, -0.6527, -0.5487, -0.4436, -0.3540, -0.3085, -0.3037, -0.3056,\n",
            "        -0.3495], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.979525566101074 0.3328598439693451 1.629622220993042 0.6957908272743225 654\n",
            "pred tensor([-0.4965, -0.4925, -0.4964, -0.4968, -0.4952, -0.4934, -0.4861, -0.4849,\n",
            "        -0.4942, -0.5188, -0.5141, -0.4610, -0.4324, -0.3838, -0.3613, -0.4855,\n",
            "        -0.6931, -0.6327, -0.5420, -0.3905, -0.3522, -0.3165, -0.3030, -0.3061,\n",
            "        -0.3455], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.9708341956138611 0.31992679834365845 2.23058819770813 0.6788022518157959 366\n",
            "pred tensor([-0.5847, -0.7625, -0.6712, -0.5502, -0.4334, -0.3697, -0.3159, -0.2931,\n",
            "        -0.2829, -0.3839, -0.6929, -0.7052, -0.5607, -0.4800, -0.3675, -0.3090,\n",
            "        -0.2768, -0.2837, -0.3937, -0.6955, -0.6899, -0.5516, -0.4481, -0.3725,\n",
            "        -0.3039], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 5.2439727783203125 0.3060621917247772 2.9618964195251465 0.7177484631538391 617\n",
            "pred tensor([-0.4982, -0.4940, -0.4980, -0.4964, -0.4922, -0.4852, -0.4810, -0.4912,\n",
            "        -0.5268, -0.5451, -0.4851, -0.4380, -0.3992, -0.3462, -0.3256, -0.4483,\n",
            "        -0.6960, -0.6725, -0.5543, -0.5013, -0.4042, -0.3788, -0.3265, -0.3030,\n",
            "        -0.2982], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.9538260698318481 0.2910516858100891 3.905749559402466 0.6650708913803101 372\n",
            "pred tensor([-0.3437, -0.5930, -0.7354, -0.5922, -0.5005, -0.4389, -0.4092, -0.3283,\n",
            "        -0.2940, -0.2845, -0.4540, -0.6982, -0.6186, -0.4923, -0.4432, -0.3994,\n",
            "        -0.3358, -0.2854, -0.2843, -0.4178, -0.6361, -0.6449, -0.5197, -0.4638,\n",
            "        -0.3863], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.25048828125 0.31170475482940674 2.56211519241333 0.6669411063194275 558\n",
            "pred tensor([-0.4939, -0.4942, -0.4954, -0.4917, -0.4921, -0.4933, -0.4911, -0.4919,\n",
            "        -0.4956, -0.4969, -0.4894, -0.4828, -0.4621, -0.4604, -0.5395, -0.5418,\n",
            "        -0.4566, -0.4204, -0.3870, -0.3147, -0.2892, -0.3475, -0.5909, -0.7078,\n",
            "        -0.5876], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.9352553486824036 0.32797783613204956 1.8150174617767334 0.6847826242446899 328\n",
            "pred tensor([-0.4729, -0.4320, -0.4111, -0.3705, -0.2919, -0.2672, -0.2867, -0.5254,\n",
            "        -0.7140, -0.5890, -0.4686, -0.4440, -0.4161, -0.3513, -0.2868, -0.2764,\n",
            "        -0.3765, -0.6453, -0.6315, -0.4704, -0.4566, -0.4216, -0.3805, -0.3080,\n",
            "        -0.2867], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 5.97823429107666 0.3390474319458008 1.4064428806304932 0.6936697959899902 433\n",
            "pred tensor([-0.4947, -0.4966, -0.4935, -0.4949, -0.4939, -0.4994, -0.5038, -0.5075,\n",
            "        -0.4867, -0.4752, -0.4431, -0.3894, -0.4251, -0.6107, -0.5936, -0.4703,\n",
            "        -0.4310, -0.4368, -0.3767, -0.2846, -0.2568, -0.2973, -0.5680, -0.7453,\n",
            "        -0.5779], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.9401987195014954 0.34094738960266113 1.3523255586624146 0.6727110743522644 296\n",
            "pred tensor([-0.4509, -0.4491, -0.4461, -0.3579, -0.2574, -0.2425, -0.3908, -0.7050,\n",
            "        -0.6531, -0.4477, -0.4580, -0.4499, -0.3798, -0.2726, -0.2510, -0.3898,\n",
            "        -0.7157, -0.6544, -0.4573, -0.4699, -0.4553, -0.4096, -0.3102, -0.2799,\n",
            "        -0.3892], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.76740026473999 0.33212053775787354 1.6729352474212646 0.6996296644210815 437\n",
            "4\n",
            "pred tensor([-0.4934, -0.4956, -0.4976, -0.4951, -0.4966, -0.4930, -0.4880, -0.4865,\n",
            "        -0.4942, -0.5130, -0.5163, -0.4719, -0.4705, -0.3793, -0.2842, -0.4091,\n",
            "        -0.6908, -0.6197, -0.4727, -0.4756, -0.4698, -0.4193, -0.2842, -0.2333,\n",
            "        -0.2563], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.9154244065284729 0.3106149137020111 2.6627235412597656 0.672588586807251 327\n",
            "pred tensor([-0.5213, -0.7733, -0.6318, -0.4697, -0.5078, -0.5063, -0.4164, -0.2513,\n",
            "        -0.2261, -0.3613, -0.7230, -0.6997, -0.4927, -0.4986, -0.5116, -0.4854,\n",
            "        -0.2901, -0.2315, -0.2912, -0.5942, -0.7820, -0.5937, -0.4815, -0.4869,\n",
            "        -0.5281], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 4.388920783996582 0.2982974648475647 3.5077171325683594 0.7163212895393372 776\n",
            "pred tensor([-0.4946, -0.4991, -0.4945, -0.4973, -0.5007, -0.4957, -0.4917, -0.4889,\n",
            "        -0.4953, -0.5149, -0.5144, -0.4958, -0.4983, -0.3979, -0.3096, -0.4984,\n",
            "        -0.6921, -0.5507, -0.5180, -0.5329, -0.4954, -0.3223, -0.2345, -0.2319,\n",
            "        -0.4620], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.9223305583000183 0.3070639967918396 2.9362778663635254 0.666576087474823 565\n",
            "pred tensor([-0.7479, -0.6563, -0.5150, -0.5714, -0.5750, -0.4676, -0.2601, -0.2124,\n",
            "        -0.3372, -0.6886, -0.7077, -0.5236, -0.5636, -0.5809, -0.5446, -0.3165,\n",
            "        -0.2186, -0.2478, -0.5164, -0.7344, -0.6606, -0.5150, -0.5394, -0.5801,\n",
            "        -0.5737], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 4.4681196212768555 0.31846892833709717 2.3387486934661865 0.6923200488090515 963\n",
            "pred tensor([-0.4948, -0.4960, -0.4952, -0.4988, -0.4986, -0.4970, -0.4909, -0.4853,\n",
            "        -0.4981, -0.5388, -0.5269, -0.5165, -0.5409, -0.3948, -0.2688, -0.3196,\n",
            "        -0.6125, -0.6971, -0.5537, -0.5474, -0.5919, -0.5932, -0.4201, -0.2564,\n",
            "        -0.2039], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.8867484331130981 0.33052387833595276 1.831559658050537 0.658037006855011 638\n",
            "pred tensor([-0.2688, -0.5943, -0.7526, -0.5988, -0.5535, -0.6279, -0.6318, -0.4368,\n",
            "        -0.2383, -0.1925, -0.3421, -0.7028, -0.6710, -0.5293, -0.5847, -0.6281,\n",
            "        -0.6087, -0.3701, -0.2201, -0.2099, -0.3867, -0.6748, -0.6902, -0.5678,\n",
            "        -0.5320], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.563298225402832 0.3330528438091278 1.6407105922698975 0.696967601776123 975\n",
            "pred tensor([-0.4962, -0.4985, -0.4957, -0.4993, -0.4991, -0.4992, -0.4987, -0.4998,\n",
            "        -0.4905, -0.4855, -0.5020, -0.5300, -0.5125, -0.5382, -0.5233, -0.3070,\n",
            "        -0.2521, -0.4994, -0.7116, -0.5859, -0.5745, -0.6347, -0.6362, -0.4528,\n",
            "        -0.2632], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.8866018056869507 0.3280562162399292 1.809194564819336 0.6605411767959595 692\n",
            "pred tensor([-0.1934, -0.2682, -0.5981, -0.7171, -0.5843, -0.5967, -0.6766, -0.6630,\n",
            "        -0.4176, -0.2176, -0.1994, -0.3910, -0.6984, -0.6231, -0.5401, -0.6759,\n",
            "        -0.6762, -0.5250, -0.2798, -0.1862, -0.2622, -0.5753, -0.6910, -0.5714,\n",
            "        -0.5827], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.888340473175049 0.31816115975379944 2.2620689868927 0.7012664675712585 995\n",
            "pred tensor([-0.4991, -0.4963, -0.4968, -0.5004, -0.4961, -0.4992, -0.5006, -0.4944,\n",
            "        -0.4868, -0.4834, -0.5065, -0.5229, -0.5144, -0.5561, -0.4436, -0.2594,\n",
            "        -0.3524, -0.6534, -0.6070, -0.5611, -0.6595, -0.6685, -0.5357, -0.2832,\n",
            "        -0.1892], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.8584831357002258 0.3081921339035034 2.8419225215911865 0.6543814539909363 687\n",
            "pred tensor([-0.2073, -0.4891, -0.7143, -0.6050, -0.6091, -0.6951, -0.6765, -0.4370,\n",
            "        -0.2154, -0.1823, -0.3536, -0.6823, -0.6280, -0.5776, -0.6921, -0.6866,\n",
            "        -0.4800, -0.2282, -0.1802, -0.3197, -0.6450, -0.6453, -0.5651, -0.6798,\n",
            "        -0.6872], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.9011144638061523 0.30705025792121887 2.937932014465332 0.7315555214881897 1012\n",
            "pred tensor([-0.4969, -0.4974, -0.4952, -0.4949, -0.4989, -0.4956, -0.4959, -0.4928,\n",
            "        -0.4849, -0.4862, -0.5120, -0.5143, -0.5232, -0.5326, -0.3464, -0.2727,\n",
            "        -0.5181, -0.6292, -0.5510, -0.6544, -0.6664, -0.5351, -0.2767, -0.1866,\n",
            "        -0.2121], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.8483917117118835 0.3140278458595276 2.4753923416137695 0.6580057740211487 647\n",
            "pred tensor([-0.4987, -0.6968, -0.5848, -0.6442, -0.6882, -0.6185, -0.3087, -0.1838,\n",
            "        -0.2209, -0.5506, -0.6575, -0.5735, -0.6919, -0.6777, -0.4670, -0.2115,\n",
            "        -0.1913, -0.4045, -0.6780, -0.6054, -0.6459, -0.6917, -0.6120, -0.3239,\n",
            "        -0.1971], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 4.380614757537842 0.3206443190574646 2.135986328125 0.7116492986679077 982\n",
            "pred tensor([-0.4960, -0.4955, -0.4998, -0.4950, -0.4975, -0.4978, -0.4921, -0.4844,\n",
            "        -0.4880, -0.5014, -0.5177, -0.5301, -0.5474, -0.4248, -0.2749, -0.3575,\n",
            "        -0.6327, -0.5897, -0.6094, -0.6697, -0.6481, -0.4054, -0.2165, -0.1849,\n",
            "        -0.3214], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.8475086688995361 0.32472774386405945 1.9245973825454712 0.6599730253219604 608\n",
            "pred tensor([-0.6500, -0.6198, -0.5967, -0.6921, -0.6635, -0.4222, -0.2063, -0.1923,\n",
            "        -0.4062, -0.6828, -0.6043, -0.6560, -0.6854, -0.5642, -0.2674, -0.1934,\n",
            "        -0.2886, -0.6220, -0.6260, -0.6215, -0.6867, -0.6209, -0.3772, -0.2082,\n",
            "        -0.2467], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.225126266479492 0.33003687858581543 1.7316864728927612 0.7159951329231262 957\n",
            "pred tensor([-0.4965, -0.4980, -0.4936, -0.4941, -0.4947, -0.4940, -0.4913, -0.4877,\n",
            "        -0.4942, -0.5091, -0.5123, -0.5202, -0.4845, -0.3524, -0.3680, -0.5945,\n",
            "        -0.5708, -0.6317, -0.6478, -0.5192, -0.2772, -0.2025, -0.2538, -0.5468,\n",
            "        -0.6466], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.8283482193946838 0.3252269923686981 1.9528732299804688 0.6612123250961304 586\n",
            "pred tensor([-0.5765, -0.6763, -0.6511, -0.4592, -0.2306, -0.2014, -0.3839, -0.6752,\n",
            "        -0.6059, -0.6390, -0.6639, -0.5869, -0.2731, -0.2073, -0.2869, -0.5852,\n",
            "        -0.6390, -0.5994, -0.6614, -0.6389, -0.4537, -0.2478, -0.2265, -0.3611,\n",
            "        -0.5786], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.015561580657959 0.32072198390960693 2.190983533859253 0.6880749464035034 934\n",
            "pred tensor([-0.4964, -0.4941, -0.4933, -0.4986, -0.4944, -0.4932, -0.4948, -0.4923,\n",
            "        -0.4997, -0.5065, -0.5130, -0.5105, -0.4568, -0.3734, -0.4339, -0.6012,\n",
            "        -0.5599, -0.6346, -0.6300, -0.4569, -0.2543, -0.2183, -0.2956, -0.5819,\n",
            "        -0.6367], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.8127381205558777 0.30965787172317505 2.7044098377227783 0.6740552186965942 600\n",
            "pred tensor([-0.5820, -0.6680, -0.6523, -0.5126, -0.2583, -0.2191, -0.3079, -0.6178,\n",
            "        -0.6335, -0.5971, -0.6712, -0.6397, -0.4247, -0.2336, -0.2276, -0.3990,\n",
            "        -0.6714, -0.6382, -0.6119, -0.6547, -0.6395, -0.4686, -0.2749, -0.2279,\n",
            "        -0.2682], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.058810710906982 0.30371350049972534 3.031405448913574 0.7081500291824341 940\n",
            "pred tensor([-0.4961, -0.4937, -0.4935, -0.4958, -0.4932, -0.4968, -0.4945, -0.4875,\n",
            "        -0.4871, -0.4988, -0.5111, -0.5120, -0.5090, -0.4142, -0.3439, -0.4744,\n",
            "        -0.5992, -0.5711, -0.6445, -0.6236, -0.4658, -0.2695, -0.2280, -0.2647,\n",
            "        -0.5034], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.7879331111907959 0.31044498085975647 2.6393814086914062 0.6736040115356445 587\n",
            "pred tensor([-0.6660, -0.5942, -0.6432, -0.6546, -0.5946, -0.3177, -0.2335, -0.2526,\n",
            "        -0.4853, -0.6628, -0.5962, -0.6485, -0.6386, -0.5519, -0.2933, -0.2343,\n",
            "        -0.2721, -0.5205, -0.6371, -0.6058, -0.6466, -0.6330, -0.5712, -0.3763,\n",
            "        -0.2609], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.8007755279541016 0.3173423409461975 2.274486780166626 0.7202655076980591 948\n",
            "pred tensor([-0.4953, -0.5005, -0.4941, -0.4960, -0.4972, -0.4978, -0.5000, -0.4972,\n",
            "        -0.4934, -0.4902, -0.4931, -0.5111, -0.5088, -0.5121, -0.4589, -0.3531,\n",
            "        -0.4000, -0.5807, -0.5638, -0.6289, -0.6160, -0.4891, -0.2889, -0.2492,\n",
            "        -0.2797], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.7578383088111877 0.3233361542224884 2.003847122192383 0.6630080938339233 566\n",
            "pred tensor([-0.5092, -0.6224, -0.5624, -0.6429, -0.6389, -0.5150, -0.2916, -0.2530,\n",
            "        -0.3453, -0.5824, -0.5875, -0.5845, -0.6559, -0.6059, -0.3725, -0.2566,\n",
            "        -0.2741, -0.4760, -0.6318, -0.5919, -0.6337, -0.6377, -0.5474, -0.3377,\n",
            "        -0.2499], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.6171982288360596 0.325893759727478 1.8739358186721802 0.6983223557472229 923\n",
            "pred tensor([-0.4942, -0.4941, -0.4941, -0.4936, -0.4931, -0.4965, -0.4935, -0.4894,\n",
            "        -0.4896, -0.4843, -0.5076, -0.5149, -0.5277, -0.5189, -0.3799, -0.3191,\n",
            "        -0.4175, -0.5722, -0.5439, -0.6069, -0.6164, -0.5457, -0.3295, -0.2654,\n",
            "        -0.2752], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.7423883676528931 0.3238009512424469 1.9698846340179443 0.6755225658416748 562\n",
            "pred tensor([-0.4511, -0.5809, -0.5216, -0.6193, -0.6215, -0.4733, -0.2835, -0.2679,\n",
            "        -0.3716, -0.5794, -0.5287, -0.6026, -0.6324, -0.5466, -0.3236, -0.2718,\n",
            "        -0.3208, -0.5174, -0.5511, -0.5740, -0.6488, -0.6181, -0.5162, -0.3591,\n",
            "        -0.2781], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.660015344619751 0.32084226608276367 2.1108999252319336 0.7040097117424011 893\n",
            "pred tensor([-0.4946, -0.4941, -0.4943, -0.4939, -0.4923, -0.4958, -0.4965, -0.4966,\n",
            "        -0.4979, -0.4974, -0.4923, -0.4787, -0.4653, -0.5007, -0.5235, -0.5446,\n",
            "        -0.5503, -0.3839, -0.3007, -0.3176, -0.5027, -0.5455, -0.5162, -0.6042,\n",
            "        -0.6055], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.7104616761207581 0.31943416595458984 2.1670684814453125 0.68278968334198 547\n",
            "pred tensor([-0.4818, -0.3097, -0.2829, -0.3170, -0.5180, -0.5222, -0.5068, -0.6009,\n",
            "        -0.5836, -0.3988, -0.2792, -0.2795, -0.4399, -0.5659, -0.4937, -0.5736,\n",
            "        -0.6014, -0.5298, -0.3379, -0.2831, -0.3227, -0.4910, -0.5720, -0.5175,\n",
            "        -0.5871], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.824854850769043 0.3137917220592499 2.4477193355560303 0.6825273036956787 829\n",
            "pred tensor([-0.4942, -0.4984, -0.4996, -0.4966, -0.4989, -0.4951, -0.4939, -0.4919,\n",
            "        -0.5031, -0.5003, -0.5014, -0.4975, -0.4576, -0.4255, -0.4944, -0.5203,\n",
            "        -0.5138, -0.5600, -0.5211, -0.3686, -0.3109, -0.3136, -0.4435, -0.5765,\n",
            "        -0.5206], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.7269899249076843 0.31163740158081055 2.593357563018799 0.6881200075149536 513\n",
            "pred tensor([-0.5331, -0.5858, -0.5518, -0.3633, -0.2931, -0.3120, -0.4700, -0.5733,\n",
            "        -0.4978, -0.5645, -0.5812, -0.4465, -0.3040, -0.3098, -0.3985, -0.5921,\n",
            "        -0.5199, -0.5465, -0.5995, -0.5395, -0.3678, -0.2991, -0.3420, -0.4876,\n",
            "        -0.6002], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 4.215149402618408 0.3112508952617645 2.577854871749878 0.7041754126548767 849\n",
            "pred tensor([-0.4946, -0.4949, -0.4949, -0.4940, -0.4944, -0.4963, -0.4934, -0.4958,\n",
            "        -0.4959, -0.4979, -0.4974, -0.5003, -0.4960, -0.4966, -0.4826, -0.4802,\n",
            "        -0.4755, -0.4822, -0.5056, -0.4417, -0.3543, -0.3721, -0.5057, -0.5884,\n",
            "        -0.5434], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.6926639080047607 0.3125992715358734 2.511131525039673 0.6844713091850281 538\n",
            "pred tensor([-0.5261, -0.5713, -0.5653, -0.4483, -0.3450, -0.3282, -0.3897, -0.5329,\n",
            "        -0.5919, -0.5299, -0.5403, -0.5824, -0.5429, -0.3901, -0.3320, -0.4152,\n",
            "        -0.5364, -0.5560, -0.5057, -0.5470, -0.5634, -0.4492, -0.3680, -0.4224,\n",
            "        -0.4738], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.6656224727630615 0.31466981768608093 2.4180586338043213 0.6888346672058105 867\n",
            "pred tensor([-0.4953, -0.4957, -0.4979, -0.4943, -0.4936, -0.4962, -0.4974, -0.5015,\n",
            "        -0.5006, -0.4985, -0.4925, -0.4803, -0.5002, -0.5240, -0.5020, -0.5196,\n",
            "        -0.5039, -0.3778, -0.3524, -0.4329, -0.5828, -0.5452, -0.4909, -0.5541,\n",
            "        -0.5527], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.6607329845428467 0.32007309794425964 2.1338419914245605 0.6825065612792969 532\n",
            "pred tensor([-0.4745, -0.3447, -0.3383, -0.4072, -0.5835, -0.5773, -0.4858, -0.5397,\n",
            "        -0.5455, -0.4603, -0.3334, -0.3522, -0.4706, -0.6105, -0.5231, -0.4978,\n",
            "        -0.5470, -0.5341, -0.3829, -0.3218, -0.3859, -0.5286, -0.6166, -0.5037,\n",
            "        -0.4997], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.9641518592834473 0.3251153528690338 1.919202446937561 0.6965972781181335 811\n",
            "pred tensor([-0.4995, -0.4950, -0.4964, -0.4972, -0.4944, -0.4943, -0.4956, -0.4940,\n",
            "        -0.4957, -0.4993, -0.5035, -0.5077, -0.5033, -0.4937, -0.4404, -0.4452,\n",
            "        -0.5694, -0.5387, -0.4692, -0.5148, -0.5058, -0.3918, -0.3324, -0.3931,\n",
            "        -0.5255], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.6366000175476074 0.31900715827941895 2.1832799911499023 0.68394535779953 499\n",
            "pred tensor([-0.6612, -0.5279, -0.4474, -0.5044, -0.5102, -0.3824, -0.3279, -0.4142,\n",
            "        -0.5932, -0.6414, -0.4845, -0.4842, -0.5238, -0.4644, -0.3514, -0.3829,\n",
            "        -0.4953, -0.6384, -0.5667, -0.4688, -0.5086, -0.5041, -0.4136, -0.3570,\n",
            "        -0.4294], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.7610530853271484 0.320260226726532 2.136669635772705 0.7005125284194946 696\n",
            "pred tensor([-0.4978, -0.4956, -0.4973, -0.4967, -0.4972, -0.4976, -0.4972, -0.4979,\n",
            "        -0.4967, -0.4949, -0.4906, -0.4909, -0.5107, -0.5274, -0.4867, -0.4869,\n",
            "        -0.4508, -0.3625, -0.4371, -0.6124, -0.6197, -0.4613, -0.4609, -0.5013,\n",
            "        -0.4717], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.638013482093811 0.32190123200416565 2.0538575649261475 0.6787839531898499 379\n",
            "pred tensor([-0.3691, -0.3457, -0.4681, -0.6520, -0.6505, -0.4561, -0.4385, -0.4980,\n",
            "        -0.4736, -0.3649, -0.3815, -0.5283, -0.6555, -0.5434, -0.4015, -0.4826,\n",
            "        -0.4957, -0.3989, -0.3623, -0.4901, -0.6323, -0.5940, -0.4379, -0.4550,\n",
            "        -0.4801], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.7613773345947266 0.31461241841316223 2.4049203395843506 0.7018784284591675 532\n",
            "pred tensor([-0.4974, -0.4952, -0.4975, -0.4953, -0.4942, -0.4963, -0.4952, -0.4951,\n",
            "        -0.4970, -0.5051, -0.5184, -0.5087, -0.4911, -0.4846, -0.4340, -0.4723,\n",
            "        -0.6174, -0.5473, -0.4057, -0.4530, -0.4704, -0.3893, -0.3471, -0.4291,\n",
            "        -0.5824], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.6229907274246216 0.3098392188549042 2.6512162685394287 0.6903471350669861 377\n",
            "pred tensor([-0.6757, -0.5053, -0.3669, -0.4394, -0.4663, -0.3804, -0.3600, -0.4773,\n",
            "        -0.6440, -0.6142, -0.4002, -0.4140, -0.4677, -0.4104, -0.3552, -0.4702,\n",
            "        -0.6281, -0.5961, -0.4018, -0.4223, -0.4751, -0.4124, -0.3860, -0.4940,\n",
            "        -0.6223], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.7841296195983887 0.3131256699562073 2.4774131774902344 0.705798864364624 497\n",
            "5\n",
            "pred tensor([-0.4985, -0.4948, -0.4947, -0.4941, -0.4957, -0.4950, -0.4976, -0.4981,\n",
            "        -0.4993, -0.4978, -0.4918, -0.4880, -0.4906, -0.5094, -0.4972, -0.4420,\n",
            "        -0.4635, -0.4164, -0.3734, -0.4937, -0.6452, -0.5863, -0.4116, -0.4062,\n",
            "        -0.4603], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 0.6074371933937073 0.31577742099761963 2.3352420330047607 0.6874047517776489 355\n",
            "pred tensor([-0.4526, -0.3820, -0.3741, -0.4932, -0.6422, -0.6237, -0.4137, -0.3930,\n",
            "        -0.4688, -0.4579, -0.3699, -0.4168, -0.5611, -0.6511, -0.4525, -0.3738,\n",
            "        -0.4602, -0.4801, -0.3817, -0.4333, -0.5524, -0.6364, -0.4674, -0.3653,\n",
            "        -0.4379], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.4458675384521484 0.32055404782295227 2.122152805328369 0.7069122195243835 464\n",
            "pred tensor([-0.4959, -0.5002, -0.4940, -0.4956, -0.4974, -0.4982, -0.4978, -0.5000,\n",
            "        -0.4975, -0.5022, -0.5131, -0.5057, -0.4925, -0.4891, -0.4430, -0.4535,\n",
            "        -0.5765, -0.5559, -0.4144, -0.4301, -0.4785, -0.4182, -0.3729, -0.4263,\n",
            "        -0.5379], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.6189201474189758 0.3204619586467743 2.1268250942230225 0.6880164742469788 359\n",
            "pred tensor([-0.6278, -0.5142, -0.3850, -0.4416, -0.4919, -0.4099, -0.3713, -0.4461,\n",
            "        -0.5899, -0.6016, -0.4164, -0.4154, -0.4945, -0.4773, -0.3852, -0.4187,\n",
            "        -0.5321, -0.6171, -0.4868, -0.3846, -0.4705, -0.5115, -0.4343, -0.3805,\n",
            "        -0.4483], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.5503156185150146 0.3168121874332428 2.2986483573913574 0.7009345889091492 477\n",
            "pred tensor([-0.5012, -0.4984, -0.4980, -0.4983, -0.4973, -0.4954, -0.4981, -0.4955,\n",
            "        -0.4951, -0.5039, -0.5143, -0.4934, -0.4883, -0.4921, -0.4295, -0.4722,\n",
            "        -0.5683, -0.5406, -0.4117, -0.4393, -0.4821, -0.4639, -0.3980, -0.3957,\n",
            "        -0.4832], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.6277074813842773 0.3162563145160675 2.3110508918762207 0.6875004172325134 327\n",
            "pred tensor([-0.5702, -0.5621, -0.4197, -0.4318, -0.5060, -0.4872, -0.3968, -0.4081,\n",
            "        -0.4868, -0.5772, -0.4555, -0.4001, -0.4822, -0.5200, -0.4170, -0.3839,\n",
            "        -0.4446, -0.5388, -0.5270, -0.4111, -0.4438, -0.5063, -0.5100, -0.4186,\n",
            "        -0.3896], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.5131280422210693 0.313617080450058 2.457645893096924 0.6848229169845581 512\n",
            "pred tensor([-0.4954, -0.4960, -0.4943, -0.4997, -0.4969, -0.4994, -0.4979, -0.4980,\n",
            "        -0.4982, -0.4967, -0.4935, -0.5095, -0.5114, -0.4726, -0.4874, -0.4942,\n",
            "        -0.4298, -0.4313, -0.5238, -0.5833, -0.4578, -0.4023, -0.4842, -0.5206,\n",
            "        -0.4533], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.6017491817474365 0.314311683177948 2.415642261505127 0.6896600723266602 413\n",
            "pred tensor([-0.4074, -0.4305, -0.5060, -0.5788, -0.4500, -0.3879, -0.4793, -0.5355,\n",
            "        -0.4443, -0.3854, -0.4449, -0.5365, -0.5562, -0.3989, -0.4374, -0.5184,\n",
            "        -0.5009, -0.4063, -0.4006, -0.4789, -0.5566, -0.4789, -0.3951, -0.4623,\n",
            "        -0.5209], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.6775312423706055 0.32053592801094055 2.109724521636963 0.6951343417167664 500\n",
            "pred tensor([-0.4997, -0.4954, -0.4973, -0.4985, -0.4960, -0.5005, -0.4978, -0.5007,\n",
            "        -0.5014, -0.5039, -0.5065, -0.5045, -0.4998, -0.4954, -0.4600, -0.4789,\n",
            "        -0.5093, -0.4296, -0.4414, -0.5145, -0.4802, -0.4122, -0.4028, -0.4791,\n",
            "        -0.5393], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5754517912864685 0.3167021572589874 2.2971537113189697 0.6919132471084595 473\n",
            "pred tensor([-0.4890, -0.4047, -0.4661, -0.5415, -0.4867, -0.4034, -0.4165, -0.4886,\n",
            "        -0.5281, -0.4102, -0.4135, -0.5222, -0.5230, -0.4083, -0.4103, -0.4740,\n",
            "        -0.5243, -0.4140, -0.4075, -0.5135, -0.5208, -0.4145, -0.3965, -0.4635,\n",
            "        -0.5317], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.9732964038848877 0.3187403082847595 2.1725597381591797 0.695198655128479 555\n",
            "pred tensor([-0.5055, -0.4975, -0.4957, -0.4985, -0.5008, -0.4946, -0.4938, -0.4984,\n",
            "        -0.5021, -0.5016, -0.5018, -0.5027, -0.5017, -0.4953, -0.4969, -0.4846,\n",
            "        -0.4397, -0.5045, -0.4906, -0.4170, -0.4415, -0.4963, -0.5130, -0.4033,\n",
            "        -0.4086], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5645515322685242 0.3155430555343628 2.3360815048217773 0.6903876066207886 510\n",
            "pred tensor([-0.5283, -0.5591, -0.4586, -0.4177, -0.4560, -0.5008, -0.5100, -0.3938,\n",
            "        -0.4122, -0.5404, -0.5580, -0.4430, -0.4158, -0.4895, -0.5108, -0.4210,\n",
            "        -0.3829, -0.5111, -0.5631, -0.4607, -0.4107, -0.4669, -0.5197, -0.4767,\n",
            "        -0.3883], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.6097378730773926 0.3166080713272095 2.2812881469726562 0.6898661851882935 528\n",
            "pred tensor([-0.4981, -0.4991, -0.5011, -0.4968, -0.4961, -0.4962, -0.4997, -0.4985,\n",
            "        -0.5011, -0.5018, -0.5033, -0.5090, -0.5059, -0.5034, -0.5027, -0.4755,\n",
            "        -0.4736, -0.4857, -0.4037, -0.4348, -0.5346, -0.5016, -0.4219, -0.4316,\n",
            "        -0.4953], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5378137230873108 0.3150227963924408 2.364887237548828 0.689518392086029 570\n",
            "pred tensor([-0.5364, -0.4375, -0.3804, -0.5005, -0.5723, -0.4847, -0.4237, -0.4619,\n",
            "        -0.5366, -0.5040, -0.3926, -0.4461, -0.5596, -0.5483, -0.4377, -0.4483,\n",
            "        -0.5318, -0.5280, -0.4178, -0.4051, -0.5199, -0.5550, -0.4891, -0.4516,\n",
            "        -0.4820], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.7311251163482666 0.3170972764492035 2.2676188945770264 0.6923991441726685 718\n",
            "pred tensor([-0.5013, -0.4961, -0.5013, -0.4995, -0.4996, -0.4987, -0.4966, -0.5009,\n",
            "        -0.5027, -0.5031, -0.5071, -0.5075, -0.5013, -0.4876, -0.4983, -0.4891,\n",
            "        -0.4196, -0.4756, -0.5333, -0.4565, -0.4194, -0.4695, -0.5439, -0.5027,\n",
            "        -0.3823], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5439823865890503 0.31573486328125 2.325867176055908 0.6912738680839539 658\n",
            "pred tensor([-0.4261, -0.5431, -0.5594, -0.4462, -0.4291, -0.5091, -0.5544, -0.4417,\n",
            "        -0.3725, -0.5161, -0.5714, -0.4484, -0.4204, -0.5129, -0.5563, -0.3888,\n",
            "        -0.4176, -0.5696, -0.5272, -0.4290, -0.4652, -0.5305, -0.4925, -0.3790,\n",
            "        -0.4999], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.2847747802734375 0.32032692432403564 2.122684955596924 0.6959084272384644 695\n",
            "pred tensor([-0.4991, -0.5006, -0.4984, -0.4960, -0.4969, -0.4986, -0.5019, -0.5010,\n",
            "        -0.5028, -0.5045, -0.4994, -0.5063, -0.5109, -0.4978, -0.4797, -0.5205,\n",
            "        -0.4974, -0.4315, -0.4859, -0.5541, -0.5003, -0.3876, -0.4493, -0.5486,\n",
            "        -0.5561], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.5528611540794373 0.31367552280426025 2.420231342315674 0.6885919570922852 730\n",
            "pred tensor([-0.4484, -0.4100, -0.4828, -0.5569, -0.5161, -0.3742, -0.4451, -0.5609,\n",
            "        -0.5215, -0.4080, -0.4454, -0.5357, -0.4954, -0.3652, -0.4699, -0.5765,\n",
            "        -0.4558, -0.4049, -0.4831, -0.5238, -0.4312, -0.4036, -0.5333, -0.5423,\n",
            "        -0.4543], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.6856558322906494 0.3152809143066406 2.3275115489959717 0.6936252117156982 637\n",
            "pred tensor([-0.4984, -0.5004, -0.4965, -0.5032, -0.5014, -0.4975, -0.4972, -0.4966,\n",
            "        -0.5022, -0.5077, -0.4935, -0.5017, -0.5118, -0.4801, -0.4550, -0.5151,\n",
            "        -0.5390, -0.4196, -0.4211, -0.5333, -0.5652, -0.4610, -0.4091, -0.4461,\n",
            "        -0.5284], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.594224750995636 0.31562697887420654 2.300692319869995 0.6844797134399414 683\n",
            "pred tensor([-0.5406, -0.3907, -0.3948, -0.5309, -0.5679, -0.4187, -0.3985, -0.4855,\n",
            "        -0.5197, -0.3750, -0.4306, -0.5570, -0.5156, -0.3844, -0.4375, -0.5156,\n",
            "        -0.4538, -0.3800, -0.5083, -0.5644, -0.4069, -0.3889, -0.4893, -0.4838,\n",
            "        -0.3926], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.1045453548431396 0.316077321767807 2.295081377029419 0.6982969045639038 551\n",
            "pred tensor([-0.5011, -0.5011, -0.5039, -0.4977, -0.4952, -0.4996, -0.4990, -0.5016,\n",
            "        -0.5012, -0.5034, -0.5103, -0.5160, -0.5014, -0.5059, -0.5127, -0.4656,\n",
            "        -0.4549, -0.5265, -0.5039, -0.3946, -0.4514, -0.5410, -0.5420, -0.4366,\n",
            "        -0.3841], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5868770480155945 0.3177906572818756 2.187730073928833 0.685080349445343 646\n",
            "pred tensor([-0.4398, -0.5364, -0.5410, -0.3886, -0.3960, -0.5297, -0.5599, -0.4199,\n",
            "        -0.3890, -0.4943, -0.5150, -0.3700, -0.4313, -0.5588, -0.4867, -0.3860,\n",
            "        -0.4216, -0.5213, -0.4396, -0.3653, -0.5099, -0.5613, -0.4253, -0.3801,\n",
            "        -0.4976], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.0677263736724854 0.3127748668193817 2.426008939743042 0.6952946782112122 526\n",
            "pred tensor([-0.4967, -0.4988, -0.4962, -0.4964, -0.4998, -0.4980, -0.4963, -0.5003,\n",
            "        -0.4962, -0.4992, -0.4936, -0.4934, -0.5163, -0.5150, -0.4454, -0.5009,\n",
            "        -0.5350, -0.4513, -0.4011, -0.4585, -0.5541, -0.5403, -0.4009, -0.4039,\n",
            "        -0.5233], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5922394394874573 0.3098336160182953 2.566673517227173 0.6841751337051392 652\n",
            "pred tensor([-0.5563, -0.4255, -0.3693, -0.4529, -0.5586, -0.4516, -0.3434, -0.4749,\n",
            "        -0.5622, -0.4219, -0.3514, -0.4543, -0.5378, -0.3963, -0.3709, -0.5159,\n",
            "        -0.5275, -0.4010, -0.3844, -0.5048, -0.4937, -0.3710, -0.4213, -0.5279,\n",
            "        -0.4900], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.4201395511627197 0.31732580065727234 2.1678683757781982 0.6893322467803955 525\n",
            "pred tensor([-0.4979, -0.4963, -0.4984, -0.4974, -0.4976, -0.4971, -0.4980, -0.5046,\n",
            "        -0.5020, -0.4988, -0.5023, -0.4967, -0.4769, -0.5058, -0.5225, -0.4291,\n",
            "        -0.4308, -0.5240, -0.4853, -0.3995, -0.4011, -0.5062, -0.5706, -0.4409,\n",
            "        -0.3357], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.5620192885398865 0.31187576055526733 2.3884382247924805 0.6861919164657593 616\n",
            "pred tensor([-0.4351, -0.5459, -0.4860, -0.3840, -0.4011, -0.5305, -0.5448, -0.3685,\n",
            "        -0.3740, -0.5159, -0.5370, -0.4001, -0.3899, -0.5210, -0.5239, -0.3730,\n",
            "        -0.3844, -0.5164, -0.5396, -0.4103, -0.3900, -0.4982, -0.5245, -0.4081,\n",
            "        -0.3737], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.3465018272399902 0.3165076971054077 2.1196539402008057 0.6962385177612305 595\n",
            "pred tensor([-0.4964, -0.5004, -0.5016, -0.4971, -0.4984, -0.4967, -0.4951, -0.4975,\n",
            "        -0.4988, -0.4990, -0.5053, -0.5179, -0.5018, -0.4654, -0.5177, -0.5015,\n",
            "        -0.4220, -0.4740, -0.5762, -0.5033, -0.3447, -0.4092, -0.5292, -0.5205,\n",
            "        -0.4112], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5446220636367798 0.316143274307251 2.1361889839172363 0.6813262701034546 631\n",
            "pred tensor([-0.4034, -0.5166, -0.5820, -0.4286, -0.3220, -0.4547, -0.5666, -0.4455,\n",
            "        -0.3715, -0.4998, -0.5774, -0.4099, -0.3256, -0.4749, -0.5639, -0.4379,\n",
            "        -0.3961, -0.5106, -0.5738, -0.4215, -0.3349, -0.4631, -0.5565, -0.4875,\n",
            "        -0.3917], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.136446475982666 0.3156431019306183 2.084583282470703 0.7133487462997437 613\n",
            "pred tensor([-0.4982, -0.5005, -0.4992, -0.4987, -0.5011, -0.4959, -0.4970, -0.5000,\n",
            "        -0.4992, -0.5069, -0.5173, -0.5075, -0.4858, -0.5063, -0.5162, -0.4529,\n",
            "        -0.4752, -0.5839, -0.4995, -0.3517, -0.4258, -0.5440, -0.5195, -0.4149,\n",
            "        -0.4135], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5569648742675781 0.30643948912620544 2.437124252319336 0.6859843134880066 675\n",
            "pred tensor([-0.5300, -0.5941, -0.4221, -0.3377, -0.4647, -0.5740, -0.4707, -0.3814,\n",
            "        -0.5056, -0.5906, -0.4253, -0.3401, -0.4828, -0.5744, -0.4626, -0.3965,\n",
            "        -0.5175, -0.5980, -0.4438, -0.3523, -0.4660, -0.5665, -0.5209, -0.4065,\n",
            "        -0.4616], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.781317949295044 0.303590327501297 2.519826889038086 0.6950325965881348 664\n",
            "pred tensor([-0.4971, -0.4979, -0.4980, -0.4981, -0.5019, -0.4996, -0.5003, -0.4990,\n",
            "        -0.4997, -0.5022, -0.5012, -0.5145, -0.5169, -0.4723, -0.4766, -0.5327,\n",
            "        -0.4759, -0.4315, -0.5264, -0.5948, -0.4601, -0.3388, -0.4336, -0.5545,\n",
            "        -0.5346], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.5651267170906067 0.3016720712184906 2.563570976257324 0.6953142285346985 710\n",
            "pred tensor([-0.4396, -0.4324, -0.5436, -0.6018, -0.4373, -0.3350, -0.4517, -0.5741,\n",
            "        -0.5161, -0.4087, -0.4856, -0.5859, -0.5340, -0.3664, -0.4069, -0.5314,\n",
            "        -0.5775, -0.4614, -0.4386, -0.5174, -0.5899, -0.5085, -0.3833, -0.3784,\n",
            "        -0.4865], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.2562835216522217 0.2912399172782898 3.2184224128723145 0.6919674873352051 727\n",
            "pred tensor([-0.5043, -0.5004, -0.5008, -0.4968, -0.5015, -0.5004, -0.4996, -0.4987,\n",
            "        -0.5035, -0.5017, -0.5067, -0.5030, -0.4936, -0.5296, -0.5228, -0.4207,\n",
            "        -0.4384, -0.5433, -0.5270, -0.4600, -0.4690, -0.5871, -0.6223, -0.4659,\n",
            "        -0.3441], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.6056632399559021 0.29513639211654663 3.0340640544891357 0.6931763291358948 792\n",
            "pred tensor([-0.4185, -0.5374, -0.5464, -0.4561, -0.4659, -0.5884, -0.6223, -0.4209,\n",
            "        -0.3632, -0.4751, -0.5837, -0.4794, -0.4446, -0.5378, -0.6258, -0.4532,\n",
            "        -0.3577, -0.4513, -0.5737, -0.5065, -0.4413, -0.5039, -0.5996, -0.5223,\n",
            "        -0.4004], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.0449938774108887 0.31331390142440796 2.055605411529541 0.7075608968734741 790\n",
            "pred tensor([-0.5032, -0.4986, -0.4979, -0.4977, -0.4985, -0.4980, -0.4996, -0.4971,\n",
            "        -0.5022, -0.5097, -0.5169, -0.4862, -0.5028, -0.5242, -0.4898, -0.5098,\n",
            "        -0.5936, -0.5504, -0.4066, -0.4196, -0.5238, -0.5651, -0.4916, -0.4504,\n",
            "        -0.5563], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.6167092323303223 0.31697317957878113 1.9063719511032104 0.6982243657112122 891\n",
            "pred tensor([-0.6282, -0.5496, -0.4015, -0.4381, -0.5463, -0.5590, -0.4665, -0.5228,\n",
            "        -0.6275, -0.5701, -0.4065, -0.4510, -0.5504, -0.5400, -0.4593, -0.5553,\n",
            "        -0.6250, -0.5239, -0.4032, -0.4749, -0.5806, -0.5102, -0.4892, -0.5767,\n",
            "        -0.6227], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.902358055114746 0.31530648469924927 1.9507981538772583 0.702182948589325 907\n",
            "6\n",
            "pred tensor([-0.5028, -0.5016, -0.4991, -0.4999, -0.4985, -0.5017, -0.5001, -0.5050,\n",
            "        -0.5001, -0.4992, -0.5062, -0.5087, -0.5095, -0.5496, -0.5585, -0.4736,\n",
            "        -0.4676, -0.5386, -0.5526, -0.5090, -0.4927, -0.5791, -0.6364, -0.5459,\n",
            "        -0.4260], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.5823507308959961 0.31233155727386475 2.0905566215515137 0.6887694001197815 1026\n",
            "pred tensor([-0.4738, -0.5507, -0.5491, -0.4801, -0.5133, -0.6161, -0.6123, -0.4743,\n",
            "        -0.4785, -0.5438, -0.5439, -0.4646, -0.5442, -0.6192, -0.5548, -0.4527,\n",
            "        -0.5025, -0.5717, -0.5077, -0.4979, -0.6032, -0.6360, -0.4884, -0.4715,\n",
            "        -0.5383], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 3.121968984603882 0.300546795129776 2.635112762451172 0.6919918060302734 1065\n",
            "pred tensor([-0.5003, -0.5039, -0.4998, -0.4978, -0.5045, -0.5008, -0.5033, -0.5047,\n",
            "        -0.4999, -0.5006, -0.5079, -0.5053, -0.5348, -0.5379, -0.5042, -0.4980,\n",
            "        -0.5248, -0.5173, -0.4876, -0.5256, -0.6198, -0.6095, -0.5278, -0.4844,\n",
            "        -0.5203], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5639363527297974 0.29296061396598816 3.064770221710205 0.6916304230690002 1168\n",
            "pred tensor([-0.5507, -0.5077, -0.4865, -0.5700, -0.6348, -0.5937, -0.4975, -0.5123,\n",
            "        -0.5588, -0.5178, -0.4908, -0.5815, -0.6293, -0.5703, -0.4845, -0.5131,\n",
            "        -0.5508, -0.4863, -0.5109, -0.6186, -0.6434, -0.5482, -0.4900, -0.5232,\n",
            "        -0.5351], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.9541015625 0.2942158579826355 2.956857204437256 0.692402720451355 1214\n",
            "pred tensor([-0.5018, -0.5030, -0.5011, -0.5013, -0.4990, -0.5011, -0.4992, -0.4988,\n",
            "        -0.5021, -0.5017, -0.5077, -0.5128, -0.5143, -0.5059, -0.5021, -0.5029,\n",
            "        -0.4911, -0.5228, -0.5556, -0.5056, -0.4840, -0.5291, -0.5265, -0.4899,\n",
            "        -0.5060], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.526519238948822 0.2951931357383728 2.9371304512023926 0.6896713972091675 1230\n",
            "pred tensor([-0.6054, -0.6263, -0.5772, -0.4926, -0.5121, -0.5547, -0.5286, -0.4945,\n",
            "        -0.5687, -0.6159, -0.5884, -0.5055, -0.5166, -0.5585, -0.5241, -0.5048,\n",
            "        -0.5947, -0.6169, -0.5982, -0.5037, -0.5186, -0.5563, -0.5095, -0.5178,\n",
            "        -0.6134], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.882220983505249 0.3040192723274231 2.4331321716308594 0.6967522501945496 1255\n",
            "pred tensor([-0.5014, -0.5038, -0.4989, -0.5007, -0.4978, -0.5007, -0.4999, -0.5048,\n",
            "        -0.5088, -0.5108, -0.5096, -0.5011, -0.5040, -0.4989, -0.5139, -0.5545,\n",
            "        -0.5467, -0.4860, -0.5011, -0.5173, -0.5130, -0.5004, -0.5545, -0.6228,\n",
            "        -0.6051], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5033392906188965 0.3139416575431824 2.0224244594573975 0.6933903098106384 1159\n",
            "pred tensor([-0.5191, -0.4888, -0.5193, -0.5208, -0.4968, -0.5279, -0.6210, -0.6064,\n",
            "        -0.5214, -0.4982, -0.5202, -0.5277, -0.4935, -0.5653, -0.6113, -0.5655,\n",
            "        -0.4926, -0.5027, -0.5280, -0.5198, -0.5138, -0.6042, -0.5970, -0.5458,\n",
            "        -0.5003], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.1325767040252686 0.3177969753742218 1.8425248861312866 0.6952921152114868 1332\n",
            "pred tensor([-0.5019, -0.5005, -0.4996, -0.4995, -0.5007, -0.4974, -0.5015, -0.5026,\n",
            "        -0.5034, -0.5051, -0.5056, -0.5067, -0.5081, -0.5130, -0.5091, -0.5000,\n",
            "        -0.4980, -0.4942, -0.5055, -0.5751, -0.5682, -0.4902, -0.4884, -0.5159,\n",
            "        -0.5267], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4891500473022461 0.314010351896286 1.96161687374115 0.6900363564491272 1074\n",
            "pred tensor([-0.5094, -0.5197, -0.5843, -0.6054, -0.5592, -0.5017, -0.5000, -0.5396,\n",
            "        -0.5411, -0.5084, -0.5699, -0.6014, -0.5686, -0.5046, -0.5088, -0.5441,\n",
            "        -0.5393, -0.5157, -0.5860, -0.5867, -0.5451, -0.4910, -0.4915, -0.5368,\n",
            "        -0.5212], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.9379706382751465 0.3065374195575714 2.286990165710449 0.6992673277854919 1316\n",
            "pred tensor([-0.5038, -0.4987, -0.5013, -0.4992, -0.4963, -0.5008, -0.4991, -0.5006,\n",
            "        -0.5009, -0.4981, -0.5015, -0.5037, -0.5112, -0.5319, -0.5357, -0.5151,\n",
            "        -0.4865, -0.5048, -0.5164, -0.5047, -0.5100, -0.5625, -0.5943, -0.5476,\n",
            "        -0.4849], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4895445704460144 0.2962479293346405 2.854874849319458 0.6913149952888489 952\n",
            "pred tensor([-0.4803, -0.5176, -0.5188, -0.4969, -0.5448, -0.5703, -0.5065, -0.4741,\n",
            "        -0.4927, -0.5205, -0.5219, -0.5104, -0.5585, -0.5311, -0.4671, -0.4841,\n",
            "        -0.5280, -0.5407, -0.4808, -0.5354, -0.5470, -0.5076, -0.4618, -0.5073,\n",
            "        -0.5298], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.956941604614258 0.2960241436958313 2.824094772338867 0.6931964159011841 1135\n",
            "pred tensor([-0.5014, -0.4986, -0.5003, -0.4991, -0.5000, -0.4990, -0.5004, -0.5018,\n",
            "        -0.4983, -0.5013, -0.5051, -0.5046, -0.5046, -0.5058, -0.5021, -0.4974,\n",
            "        -0.4945, -0.5027, -0.4929, -0.5356, -0.5481, -0.4896, -0.4531, -0.4755,\n",
            "        -0.5243], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4913485646247864 0.2944321036338806 2.9279706478118896 0.6922377347946167 835\n",
            "pred tensor([-0.5348, -0.5102, -0.5303, -0.5476, -0.4999, -0.4470, -0.4620, -0.5103,\n",
            "        -0.5404, -0.5140, -0.5285, -0.5474, -0.5020, -0.4493, -0.4675, -0.5148,\n",
            "        -0.5458, -0.5124, -0.5302, -0.5578, -0.5074, -0.4561, -0.4600, -0.5041,\n",
            "        -0.5377], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.8899452686309814 0.30111050605773926 2.5730395317077637 0.6918051838874817 1014\n",
            "pred tensor([-0.4985, -0.4957, -0.4938, -0.4946, -0.4970, -0.4960, -0.4984, -0.4984,\n",
            "        -0.4971, -0.5021, -0.5024, -0.5063, -0.5129, -0.5031, -0.4858, -0.4747,\n",
            "        -0.5001, -0.5188, -0.5160, -0.5397, -0.5543, -0.5114, -0.4461, -0.4437,\n",
            "        -0.4694], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.5079410672187805 0.30306389927864075 2.465442180633545 0.6892499327659607 692\n",
            "pred tensor([-0.5082, -0.5392, -0.5336, -0.5530, -0.5328, -0.4431, -0.4140, -0.4403,\n",
            "        -0.5193, -0.5475, -0.5269, -0.5400, -0.5068, -0.4109, -0.4364, -0.4803,\n",
            "        -0.5391, -0.5281, -0.5415, -0.5215, -0.4573, -0.3976, -0.4414, -0.5179,\n",
            "        -0.5550], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.637803554534912 0.31235989928245544 2.035737991333008 0.6921948194503784 937\n",
            "pred tensor([-0.4951, -0.4950, -0.4967, -0.4970, -0.4971, -0.4969, -0.4959, -0.4959,\n",
            "        -0.5014, -0.5004, -0.5020, -0.4937, -0.4941, -0.5108, -0.5168, -0.5316,\n",
            "        -0.5358, -0.4786, -0.4294, -0.4252, -0.4803, -0.5181, -0.5397, -0.5527,\n",
            "        -0.5618], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.48420417308807373 0.31701377034187317 1.820414423942566 0.6913620829582214 573\n",
            "pred tensor([-0.4875, -0.4008, -0.3967, -0.4429, -0.5147, -0.5648, -0.5674, -0.5472,\n",
            "        -0.4482, -0.3794, -0.4203, -0.4763, -0.5427, -0.5677, -0.5561, -0.4909,\n",
            "        -0.4213, -0.3993, -0.4391, -0.5263, -0.5742, -0.5744, -0.5469, -0.4656,\n",
            "        -0.4113], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.6052045822143555 0.30739647150039673 2.2439687252044678 0.6845303177833557 795\n",
            "pred tensor([-0.4969, -0.4970, -0.4984, -0.4976, -0.4966, -0.4921, -0.4945, -0.4948,\n",
            "        -0.5073, -0.5030, -0.5015, -0.4979, -0.4909, -0.4946, -0.5098, -0.5188,\n",
            "        -0.5243, -0.4604, -0.3935, -0.4035, -0.4638, -0.5193, -0.5772, -0.5923,\n",
            "        -0.5662], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.45281997323036194 0.3042188882827759 2.396007537841797 0.6859537959098816 525\n",
            "pred tensor([-0.4534, -0.3545, -0.3744, -0.4235, -0.5162, -0.6106, -0.6250, -0.5737,\n",
            "        -0.4359, -0.3536, -0.3865, -0.4414, -0.5415, -0.6186, -0.6221, -0.5395,\n",
            "        -0.4187, -0.3644, -0.4174, -0.4579, -0.5580, -0.6285, -0.6318, -0.5609,\n",
            "        -0.4406], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.0942764282226562 0.2946212887763977 2.9126055240631104 0.6948039531707764 774\n",
            "pred tensor([-0.4945, -0.4971, -0.4962, -0.4985, -0.4933, -0.4944, -0.4993, -0.4960,\n",
            "        -0.4979, -0.4958, -0.4992, -0.4920, -0.4946, -0.5054, -0.5246, -0.5365,\n",
            "        -0.4811, -0.3971, -0.4015, -0.4690, -0.5461, -0.6107, -0.6289, -0.5732,\n",
            "        -0.4500], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4179862141609192 0.29555070400238037 2.8337020874023438 0.6812246441841125 522\n",
            "pred tensor([-0.3395, -0.3647, -0.4290, -0.5395, -0.6436, -0.6680, -0.5932, -0.4203,\n",
            "        -0.3208, -0.3828, -0.4612, -0.5721, -0.6648, -0.6309, -0.5157, -0.3840,\n",
            "        -0.3485, -0.4158, -0.5114, -0.6212, -0.6718, -0.6018, -0.4480, -0.3571,\n",
            "        -0.3669], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.840252637863159 0.2967400848865509 2.7683942317962646 0.7047795653343201 801\n",
            "pred tensor([-0.4945, -0.4972, -0.4980, -0.4984, -0.4949, -0.4976, -0.4935, -0.4959,\n",
            "        -0.4962, -0.5000, -0.5039, -0.4987, -0.4942, -0.4929, -0.4977, -0.5230,\n",
            "        -0.5540, -0.5342, -0.4296, -0.3729, -0.4088, -0.4926, -0.6089, -0.6619,\n",
            "        -0.6340], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4151846170425415 0.30286720395088196 2.4457757472991943 0.6820732951164246 519\n",
            "pred tensor([-0.5374, -0.3923, -0.3373, -0.3940, -0.4924, -0.6097, -0.6851, -0.6269,\n",
            "        -0.4963, -0.3758, -0.3549, -0.4297, -0.5416, -0.6627, -0.6557, -0.5631,\n",
            "        -0.4122, -0.3347, -0.3827, -0.4744, -0.5703, -0.6488, -0.6384, -0.5860,\n",
            "        -0.4637], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.1616809368133545 0.3059881031513214 2.2958805561065674 0.7087928056716919 805\n",
            "pred tensor([-0.4960, -0.4936, -0.4973, -0.4943, -0.4955, -0.4963, -0.4967, -0.4938,\n",
            "        -0.4937, -0.4957, -0.5023, -0.5067, -0.5074, -0.4901, -0.4729, -0.4736,\n",
            "        -0.4994, -0.5745, -0.6067, -0.5702, -0.4370, -0.3556, -0.3715, -0.4264,\n",
            "        -0.5202], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.43048086762428284 0.3103518784046173 2.125596046447754 0.6730005741119385 521\n",
            "pred tensor([-0.6426, -0.6883, -0.6695, -0.5563, -0.4199, -0.3368, -0.3841, -0.4677,\n",
            "        -0.5882, -0.6993, -0.6594, -0.5243, -0.3862, -0.3375, -0.4099, -0.5320,\n",
            "        -0.6825, -0.6849, -0.5600, -0.4275, -0.3212, -0.3900, -0.4981, -0.6477,\n",
            "        -0.6802], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.0365548133850098 0.3111073672771454 2.0816969871520996 0.7195437550544739 864\n",
            "pred tensor([-0.4949, -0.4954, -0.4949, -0.4923, -0.4938, -0.4949, -0.4968, -0.4977,\n",
            "        -0.4955, -0.4897, -0.4881, -0.4933, -0.5160, -0.5459, -0.5485, -0.4876,\n",
            "        -0.4340, -0.4280, -0.4564, -0.5202, -0.6434, -0.6732, -0.6227, -0.5035,\n",
            "        -0.3962], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.45116665959358215 0.3054879903793335 2.317723274230957 0.6904342770576477 512\n",
            "pred tensor([-0.4015, -0.4295, -0.5008, -0.6450, -0.6794, -0.5793, -0.4382, -0.3716,\n",
            "        -0.4261, -0.4869, -0.6317, -0.6829, -0.5615, -0.4260, -0.3726, -0.4280,\n",
            "        -0.5163, -0.6704, -0.6487, -0.5034, -0.4006, -0.3959, -0.4503, -0.5491,\n",
            "        -0.6775], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.153660297393799 0.3004065454006195 2.5697824954986572 0.6934212446212769 812\n",
            "pred tensor([-0.4958, -0.4972, -0.4955, -0.4920, -0.4920, -0.4917, -0.4963, -0.4989,\n",
            "        -0.4959, -0.4916, -0.4899, -0.4912, -0.5037, -0.5349, -0.5469, -0.5233,\n",
            "        -0.4709, -0.4397, -0.4434, -0.4652, -0.4989, -0.6127, -0.6434, -0.6307,\n",
            "        -0.5590], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4752500653266907 0.2982634902000427 2.6706414222717285 0.6877464652061462 489\n",
            "pred tensor([-0.4602, -0.4244, -0.4580, -0.4636, -0.5171, -0.6477, -0.6383, -0.5389,\n",
            "        -0.4208, -0.4135, -0.4524, -0.5031, -0.6373, -0.6393, -0.5005, -0.4025,\n",
            "        -0.4528, -0.4569, -0.5524, -0.6628, -0.5759, -0.4293, -0.4209, -0.4765,\n",
            "        -0.4925], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.1147730350494385 0.2982805371284485 2.657933235168457 0.7093412280082703 765\n",
            "pred tensor([-0.4956, -0.4982, -0.4923, -0.4925, -0.4961, -0.4930, -0.4947, -0.4939,\n",
            "        -0.4926, -0.4945, -0.4936, -0.4975, -0.5020, -0.5082, -0.4952, -0.4751,\n",
            "        -0.4791, -0.4879, -0.4904, -0.5558, -0.5935, -0.5777, -0.5062, -0.4610,\n",
            "        -0.4728], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4491856098175049 0.30259987711906433 2.454986095428467 0.6925275325775146 466\n",
            "pred tensor([-0.5180, -0.4875, -0.5111, -0.6132, -0.6185, -0.5474, -0.4678, -0.4885,\n",
            "        -0.5396, -0.4960, -0.5376, -0.6345, -0.5787, -0.4727, -0.4744, -0.5458,\n",
            "        -0.4957, -0.5275, -0.6341, -0.5621, -0.4623, -0.4817, -0.5492, -0.4906,\n",
            "        -0.5394], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.0147626399993896 0.30322134494781494 2.397618532180786 0.6961736083030701 976\n",
            "pred tensor([-0.4947, -0.4939, -0.4974, -0.4930, -0.4929, -0.4912, -0.4941, -0.4935,\n",
            "        -0.4934, -0.4988, -0.4985, -0.4975, -0.4985, -0.5062, -0.5149, -0.5028,\n",
            "        -0.4871, -0.5102, -0.5105, -0.4854, -0.5537, -0.5901, -0.5467, -0.5020,\n",
            "        -0.5139], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.41461050510406494 0.3028765022754669 2.410796642303467 0.6904931664466858 672\n",
            "pred tensor([-0.5888, -0.5369, -0.4777, -0.5602, -0.5989, -0.5264, -0.4904, -0.5740,\n",
            "        -0.5853, -0.4870, -0.5344, -0.6082, -0.5236, -0.4782, -0.5751, -0.5936,\n",
            "        -0.4837, -0.5529, -0.6080, -0.5081, -0.4673, -0.5883, -0.5709, -0.4730,\n",
            "        -0.5532], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.357245445251465 0.30449050664901733 2.3201303482055664 0.6887179613113403 1197\n",
            "pred tensor([-0.4932, -0.4950, -0.4943, -0.4941, -0.4948, -0.4941, -0.4947, -0.4952,\n",
            "        -0.4944, -0.4952, -0.4988, -0.5006, -0.5067, -0.5049, -0.5058, -0.4959,\n",
            "        -0.5073, -0.5180, -0.4951, -0.5095, -0.5692, -0.5166, -0.4738, -0.5547,\n",
            "        -0.5843], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3816227316856384 0.3027280271053314 2.391843557357788 0.6892790198326111 696\n",
            "pred tensor([-0.5337, -0.5184, -0.6026, -0.6411, -0.5398, -0.4641, -0.5552, -0.5803,\n",
            "        -0.5227, -0.5426, -0.6460, -0.6085, -0.4647, -0.5080, -0.5910, -0.5384,\n",
            "        -0.5144, -0.6166, -0.6373, -0.5026, -0.4762, -0.5731, -0.5584, -0.5100,\n",
            "        -0.5412], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.145892381668091 0.30290287733078003 2.355527639389038 0.7013393044471741 1284\n",
            "pred tensor([-0.4963, -0.4967, -0.4960, -0.4974, -0.4963, -0.4956, -0.4942, -0.4953,\n",
            "        -0.4963, -0.4983, -0.4984, -0.5064, -0.5041, -0.4990, -0.4965, -0.5039,\n",
            "        -0.5054, -0.5031, -0.5445, -0.5694, -0.4841, -0.4661, -0.5405, -0.5623,\n",
            "        -0.5204], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4087044894695282 0.3011033236980438 2.441659450531006 0.6861206889152527 735\n",
            "pred tensor([-0.5724, -0.6575, -0.6517, -0.5161, -0.4424, -0.5320, -0.5841, -0.5314,\n",
            "        -0.5794, -0.6696, -0.6111, -0.4445, -0.4916, -0.5873, -0.5488, -0.5530,\n",
            "        -0.6596, -0.6253, -0.4471, -0.4791, -0.5903, -0.5512, -0.5366, -0.6347,\n",
            "        -0.6465], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.7614965438842773 0.30474674701690674 2.2173209190368652 0.6889452934265137 1264\n",
            "7\n",
            "pred tensor([-0.4950, -0.4963, -0.4949, -0.4933, -0.4948, -0.4937, -0.4937, -0.4942,\n",
            "        -0.4990, -0.4993, -0.5069, -0.5179, -0.5088, -0.4843, -0.4957, -0.5194,\n",
            "        -0.5215, -0.5311, -0.5978, -0.6170, -0.5197, -0.4302, -0.4635, -0.5501,\n",
            "        -0.5679], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.39789879322052 0.2999124228954315 2.42122483253479 0.6914656162261963 690\n",
            "pred tensor([-0.5406, -0.5983, -0.6750, -0.6440, -0.4799, -0.4217, -0.5440, -0.5715,\n",
            "        -0.5301, -0.6255, -0.6633, -0.5465, -0.4084, -0.5162, -0.5787, -0.5337,\n",
            "        -0.6255, -0.6547, -0.5324, -0.4185, -0.5373, -0.5813, -0.5349, -0.6248,\n",
            "        -0.6427], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.730684518814087 0.29870715737342834 2.425598621368408 0.7027685642242432 1238\n",
            "pred tensor([-0.4936, -0.4950, -0.4992, -0.4946, -0.4989, -0.4961, -0.4976, -0.4936,\n",
            "        -0.4937, -0.4978, -0.5034, -0.5105, -0.5246, -0.5324, -0.5049, -0.4753,\n",
            "        -0.4969, -0.5393, -0.5316, -0.5395, -0.6135, -0.6497, -0.5785, -0.4474,\n",
            "        -0.4133], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4317619800567627 0.2987518608570099 2.373863697052002 0.6847420930862427 719\n",
            "pred tensor([-0.4962, -0.5691, -0.5649, -0.5427, -0.6447, -0.6815, -0.5901, -0.4174,\n",
            "        -0.4299, -0.5559, -0.5610, -0.5317, -0.6415, -0.6514, -0.5199, -0.4114,\n",
            "        -0.5162, -0.5808, -0.5447, -0.6159, -0.6697, -0.6077, -0.4318, -0.4613,\n",
            "        -0.5788], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.845095157623291 0.29618212580680847 2.4243900775909424 0.7147657871246338 1225\n",
            "pred tensor([-0.4943, -0.4969, -0.4914, -0.4919, -0.4957, -0.4954, -0.4946, -0.4952,\n",
            "        -0.4993, -0.5028, -0.5064, -0.5007, -0.4905, -0.4920, -0.5138, -0.5125,\n",
            "        -0.5181, -0.5761, -0.5528, -0.4384, -0.4482, -0.5426, -0.5624, -0.5306,\n",
            "        -0.5910], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.40632331371307373 0.29101526737213135 2.6807479858398438 0.6822500228881836 687\n",
            "pred tensor([-0.6590, -0.6180, -0.4848, -0.4062, -0.4990, -0.5803, -0.5362, -0.5427,\n",
            "        -0.6461, -0.6220, -0.4893, -0.4108, -0.5196, -0.5751, -0.5298, -0.5567,\n",
            "        -0.6509, -0.6101, -0.4745, -0.4219, -0.5211, -0.5716, -0.5373, -0.5417,\n",
            "        -0.6167], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.7421960830688477 0.2865302860736847 2.891505002975464 0.7042633295059204 1200\n",
            "pred tensor([-0.4942, -0.4968, -0.4949, -0.4929, -0.4942, -0.4948, -0.4943, -0.4933,\n",
            "        -0.4962, -0.5023, -0.5081, -0.5069, -0.4870, -0.4918, -0.5167, -0.5251,\n",
            "        -0.5317, -0.5866, -0.5752, -0.4555, -0.4164, -0.5169, -0.5675, -0.5318,\n",
            "        -0.5530], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4253982603549957 0.28366824984550476 3.071993827819824 0.6910420656204224 713\n",
            "pred tensor([-0.6291, -0.6044, -0.4805, -0.3992, -0.4945, -0.5645, -0.5214, -0.5554,\n",
            "        -0.6291, -0.5640, -0.4140, -0.4193, -0.5376, -0.5414, -0.5064, -0.6096,\n",
            "        -0.6114, -0.5299, -0.4174, -0.4344, -0.5358, -0.5598, -0.5253, -0.5659,\n",
            "        -0.5976], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.9008843898773193 0.28612080216407776 2.9868364334106445 0.6953620314598083 1148\n",
            "pred tensor([-0.4922, -0.4921, -0.4916, -0.4919, -0.4908, -0.4926, -0.4911, -0.4917,\n",
            "        -0.4971, -0.4992, -0.5073, -0.5121, -0.4911, -0.4700, -0.4958, -0.5283,\n",
            "        -0.5222, -0.5362, -0.5687, -0.5346, -0.4262, -0.3971, -0.5003, -0.5637,\n",
            "        -0.5402], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4319733679294586 0.2957961857318878 2.495811939239502 0.6886926889419556 652\n",
            "pred tensor([-0.5211, -0.5736, -0.5551, -0.4309, -0.3837, -0.5045, -0.5574, -0.4971,\n",
            "        -0.5571, -0.5645, -0.4681, -0.3827, -0.4724, -0.5619, -0.5102, -0.5345,\n",
            "        -0.5649, -0.4922, -0.3862, -0.4286, -0.5562, -0.5369, -0.5109, -0.5704,\n",
            "        -0.5421], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.564162015914917 0.29958832263946533 2.2793540954589844 0.6850963234901428 1014\n",
            "pred tensor([-0.4920, -0.4915, -0.4924, -0.4909, -0.4909, -0.4919, -0.4905, -0.4955,\n",
            "        -0.4955, -0.4950, -0.4945, -0.4930, -0.4899, -0.4946, -0.5060, -0.5024,\n",
            "        -0.5047, -0.5135, -0.4451, -0.4163, -0.5001, -0.5443, -0.5180, -0.5410,\n",
            "        -0.5512], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.43539533019065857 0.3018450438976288 2.1585278511047363 0.6915947794914246 546\n",
            "pred tensor([-0.4753, -0.3603, -0.3768, -0.5078, -0.5451, -0.5058, -0.5479, -0.5406,\n",
            "        -0.4459, -0.3573, -0.4496, -0.5510, -0.5178, -0.5278, -0.5485, -0.4887,\n",
            "        -0.3656, -0.3993, -0.5270, -0.5443, -0.5111, -0.5589, -0.5443, -0.4557,\n",
            "        -0.3737], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.546074628829956 0.29414671659469604 2.4764814376831055 0.6955346465110779 869\n",
            "pred tensor([-0.4893, -0.4916, -0.4925, -0.4909, -0.4886, -0.4904, -0.4923, -0.4943,\n",
            "        -0.4960, -0.4887, -0.4883, -0.4907, -0.4990, -0.4999, -0.5046, -0.5065,\n",
            "        -0.4911, -0.4172, -0.4064, -0.5003, -0.5280, -0.5129, -0.5396, -0.5149,\n",
            "        -0.4149], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4364701807498932 0.29382988810539246 2.5278146266937256 0.6862661838531494 499\n",
            "pred tensor([-0.3347, -0.4065, -0.5338, -0.5190, -0.5220, -0.5167, -0.4449, -0.3268,\n",
            "        -0.3860, -0.5319, -0.5217, -0.5290, -0.5105, -0.4295, -0.3292, -0.4211,\n",
            "        -0.5487, -0.5256, -0.5512, -0.5184, -0.4053, -0.3403, -0.4339, -0.5501,\n",
            "        -0.5331], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.778761863708496 0.2912192642688751 2.641878604888916 0.6989027261734009 752\n",
            "pred tensor([-0.4902, -0.4923, -0.4886, -0.4891, -0.4886, -0.4880, -0.4971, -0.4968,\n",
            "        -0.4959, -0.4853, -0.4763, -0.4838, -0.4997, -0.5119, -0.5112, -0.5014,\n",
            "        -0.4598, -0.3877, -0.3790, -0.4665, -0.5360, -0.5364, -0.5548, -0.5317,\n",
            "        -0.4755], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4313582479953766 0.2860604226589203 2.924356698989868 0.6868271827697754 443\n",
            "pred tensor([-0.3664, -0.3230, -0.4134, -0.5240, -0.5283, -0.5640, -0.5114, -0.4086,\n",
            "        -0.3215, -0.3995, -0.5295, -0.5275, -0.5479, -0.4931, -0.3537, -0.3321,\n",
            "        -0.4696, -0.5247, -0.5344, -0.5306, -0.4585, -0.3335, -0.3581, -0.4948,\n",
            "        -0.5298], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.6853694915771484 0.28932100534439087 2.722529888153076 0.6894928812980652 744\n",
            "pred tensor([-0.4887, -0.4890, -0.4889, -0.4901, -0.4921, -0.4895, -0.4918, -0.4917,\n",
            "        -0.4924, -0.4910, -0.4940, -0.4958, -0.5026, -0.5011, -0.4915, -0.4718,\n",
            "        -0.4572, -0.4781, -0.5051, -0.5075, -0.4858, -0.3976, -0.3321, -0.3878,\n",
            "        -0.5080], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.4184415936470032 0.29071688652038574 2.675119638442993 0.6837738156318665 410\n",
            "pred tensor([-0.5466, -0.5773, -0.5468, -0.4544, -0.3361, -0.3261, -0.4468, -0.5408,\n",
            "        -0.5720, -0.5716, -0.5020, -0.3785, -0.3308, -0.4346, -0.5329, -0.5642,\n",
            "        -0.5890, -0.5287, -0.3935, -0.3310, -0.4178, -0.5212, -0.5516, -0.5891,\n",
            "        -0.5471], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.6361777782440186 0.2982061505317688 2.3198676109313965 0.7096275687217712 771\n",
            "pred tensor([-0.4909, -0.4914, -0.4910, -0.4908, -0.4906, -0.4953, -0.4919, -0.4908,\n",
            "        -0.4915, -0.4900, -0.4894, -0.4914, -0.4938, -0.4975, -0.5030, -0.4931,\n",
            "        -0.4810, -0.4492, -0.4435, -0.4883, -0.5371, -0.5281, -0.4675, -0.3726,\n",
            "        -0.3369], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.38918083906173706 0.29783666133880615 2.328514575958252 0.6808090209960938 392\n",
            "pred tensor([-0.3915, -0.5063, -0.5591, -0.6282, -0.5865, -0.4920, -0.3660, -0.3374,\n",
            "        -0.4305, -0.5345, -0.5857, -0.6333, -0.5488, -0.4263, -0.3387, -0.3927,\n",
            "        -0.5204, -0.5580, -0.6207, -0.5714, -0.4526, -0.3495, -0.3702, -0.4890,\n",
            "        -0.5250], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.7493419647216797 0.2903503179550171 2.6803500652313232 0.69572913646698 758\n",
            "pred tensor([-0.4924, -0.4906, -0.4909, -0.4895, -0.4918, -0.4906, -0.4922, -0.4944,\n",
            "        -0.4968, -0.4940, -0.4922, -0.4878, -0.4896, -0.4930, -0.4992, -0.5135,\n",
            "        -0.4994, -0.4708, -0.4201, -0.4202, -0.4851, -0.5432, -0.5960, -0.5327,\n",
            "        -0.4408], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3733687698841095 0.2880335748195648 2.8273916244506836 0.6795164942741394 386\n",
            "pred tensor([-0.3489, -0.3415, -0.4150, -0.5264, -0.5973, -0.6384, -0.5499, -0.4310,\n",
            "        -0.3386, -0.3747, -0.5025, -0.5617, -0.6187, -0.5492, -0.4330, -0.3532,\n",
            "        -0.3959, -0.5054, -0.5430, -0.5961, -0.5638, -0.4713, -0.3894, -0.3970,\n",
            "        -0.4688], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.066779136657715 0.2911241352558136 2.6381359100341797 0.7014089226722717 806\n",
            "pred tensor([-0.4936, -0.4940, -0.4893, -0.4903, -0.4897, -0.4922, -0.4910, -0.4923,\n",
            "        -0.4913, -0.4932, -0.4953, -0.4959, -0.4987, -0.5023, -0.5046, -0.5089,\n",
            "        -0.5020, -0.4888, -0.4718, -0.4602, -0.4685, -0.4819, -0.5103, -0.4720,\n",
            "        -0.3837], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.34668147563934326 0.2871602177619934 2.832329273223877 0.6804258823394775 393\n",
            "pred tensor([-0.3669, -0.4211, -0.5046, -0.5693, -0.6265, -0.5717, -0.4419, -0.3647,\n",
            "        -0.3880, -0.4997, -0.5797, -0.6188, -0.5803, -0.4443, -0.3745, -0.4348,\n",
            "        -0.5404, -0.5821, -0.6116, -0.5551, -0.4556, -0.4195, -0.4597, -0.5330,\n",
            "        -0.5618], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.8410820960998535 0.2887541651725769 2.750789165496826 0.6917316317558289 830\n",
            "pred tensor([-0.4923, -0.4928, -0.4909, -0.4934, -0.4919, -0.4914, -0.4906, -0.4932,\n",
            "        -0.4979, -0.4993, -0.4994, -0.4957, -0.4878, -0.4859, -0.4890, -0.4973,\n",
            "        -0.5067, -0.5244, -0.5062, -0.4548, -0.4082, -0.4284, -0.4932, -0.5567,\n",
            "        -0.6357], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.35009515285491943 0.29167836904525757 2.584690809249878 0.6828293204307556 426\n",
            "pred tensor([-0.5965, -0.4612, -0.3660, -0.3643, -0.4402, -0.5350, -0.5906, -0.6635,\n",
            "        -0.5449, -0.4087, -0.3562, -0.4311, -0.5393, -0.5821, -0.6421, -0.4940,\n",
            "        -0.3705, -0.3886, -0.4785, -0.5537, -0.6092, -0.6123, -0.4792, -0.3773,\n",
            "        -0.3986], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.9850592613220215 0.293746680021286 2.470222234725952 0.6970604658126831 824\n",
            "pred tensor([-0.4914, -0.4914, -0.4934, -0.4910, -0.4926, -0.4904, -0.4904, -0.4915,\n",
            "        -0.4985, -0.5020, -0.5107, -0.4953, -0.4799, -0.4735, -0.4811, -0.5038,\n",
            "        -0.5344, -0.5800, -0.5182, -0.4284, -0.3740, -0.4086, -0.4869, -0.5561,\n",
            "        -0.6279], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3754023015499115 0.297335684299469 2.314192295074463 0.6732048988342285 428\n",
            "pred tensor([-0.6347, -0.4945, -0.3745, -0.3609, -0.4518, -0.5454, -0.6122, -0.6558,\n",
            "        -0.4998, -0.3654, -0.3707, -0.4680, -0.5551, -0.6303, -0.6289, -0.4573,\n",
            "        -0.3583, -0.4034, -0.4984, -0.5913, -0.6670, -0.5775, -0.4187, -0.3539,\n",
            "        -0.4415], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.0908899307250977 0.2971663177013397 2.3167412281036377 0.6889788508415222 814\n",
            "pred tensor([-0.4913, -0.4917, -0.4914, -0.4906, -0.4907, -0.4961, -0.4917, -0.4898,\n",
            "        -0.4881, -0.4962, -0.5036, -0.5141, -0.5140, -0.4847, -0.4498, -0.4478,\n",
            "        -0.4849, -0.5312, -0.5865, -0.6371, -0.5471, -0.4404, -0.3657, -0.3758,\n",
            "        -0.4506], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.36606964468955994 0.2933605909347534 2.4874162673950195 0.6686640977859497 426\n",
            "pred tensor([-0.5427, -0.6042, -0.6963, -0.5808, -0.4262, -0.3456, -0.4187, -0.5280,\n",
            "        -0.5950, -0.6835, -0.5062, -0.3621, -0.3597, -0.4609, -0.5574, -0.6180,\n",
            "        -0.6129, -0.4500, -0.3535, -0.4009, -0.4855, -0.5632, -0.6361, -0.5867,\n",
            "        -0.4331], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.872227191925049 0.29177117347717285 2.5896220207214355 0.7053930759429932 817\n",
            "pred tensor([-0.4924, -0.4907, -0.4918, -0.4911, -0.4921, -0.4930, -0.4895, -0.4897,\n",
            "        -0.4923, -0.5003, -0.5120, -0.5155, -0.5006, -0.4750, -0.4603, -0.4780,\n",
            "        -0.5081, -0.5615, -0.6301, -0.5598, -0.4422, -0.3711, -0.3971, -0.4703,\n",
            "        -0.5537], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3600237965583801 0.28723764419555664 2.844548225402832 0.6850035786628723 470\n",
            "pred tensor([-0.6280, -0.7005, -0.5402, -0.4017, -0.3500, -0.4434, -0.5473, -0.6245,\n",
            "        -0.6782, -0.4984, -0.3615, -0.3701, -0.4828, -0.5537, -0.6446, -0.6184,\n",
            "        -0.4456, -0.3573, -0.4128, -0.5073, -0.5724, -0.6756, -0.5598, -0.4204,\n",
            "        -0.3537], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.7777297496795654 0.28935232758522034 2.7098867893218994 0.6915120482444763 796\n",
            "pred tensor([-0.4909, -0.4918, -0.4908, -0.4963, -0.4935, -0.4907, -0.4883, -0.4886,\n",
            "        -0.4928, -0.5029, -0.5170, -0.5159, -0.4862, -0.4533, -0.4550, -0.4796,\n",
            "        -0.5209, -0.5963, -0.6586, -0.5563, -0.4370, -0.3642, -0.3941, -0.4644,\n",
            "        -0.5451], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.36456283926963806 0.2886275053024292 2.7174649238586426 0.6689892411231995 429\n",
            "pred tensor([-0.6362, -0.7087, -0.5331, -0.3906, -0.3523, -0.4333, -0.5331, -0.6363,\n",
            "        -0.6789, -0.4903, -0.3597, -0.3946, -0.4894, -0.5772, -0.7125, -0.5406,\n",
            "        -0.3926, -0.3500, -0.4366, -0.5332, -0.6482, -0.6324, -0.4477, -0.3525,\n",
            "        -0.4194], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.912121534347534 0.2916404604911804 2.5658740997314453 0.7176764011383057 819\n",
            "pred tensor([-0.4908, -0.4907, -0.4920, -0.4897, -0.4937, -0.4921, -0.4917, -0.4907,\n",
            "        -0.4904, -0.4891, -0.4947, -0.5101, -0.5193, -0.5116, -0.4827, -0.4567,\n",
            "        -0.4650, -0.4833, -0.5281, -0.6188, -0.6296, -0.5121, -0.4152, -0.3694,\n",
            "        -0.4113], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3587905466556549 0.2933271527290344 2.498352289199829 0.6737160086631775 432\n",
            "pred tensor([-0.4553, -0.5118, -0.6141, -0.6917, -0.5236, -0.3977, -0.3672, -0.4265,\n",
            "        -0.4946, -0.5878, -0.6784, -0.4954, -0.3753, -0.3851, -0.4567, -0.5283,\n",
            "        -0.6516, -0.6032, -0.4406, -0.3669, -0.4256, -0.4982, -0.5871, -0.6655,\n",
            "        -0.4930], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.861917018890381 0.2903780937194824 2.639921188354492 0.6925654411315918 739\n",
            "pred tensor([-0.4918, -0.4898, -0.4905, -0.4906, -0.4904, -0.4904, -0.4925, -0.4907,\n",
            "        -0.4875, -0.4878, -0.4921, -0.5081, -0.5259, -0.5267, -0.5032, -0.4722,\n",
            "        -0.4507, -0.4603, -0.4668, -0.5058, -0.5733, -0.6552, -0.5976, -0.4897,\n",
            "        -0.4062], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.40161019563674927 0.2879091203212738 2.7545456886291504 0.6683148741722107 425\n",
            "pred tensor([-0.3700, -0.4131, -0.4435, -0.5190, -0.6302, -0.6956, -0.5134, -0.3961,\n",
            "        -0.3736, -0.4239, -0.4989, -0.6100, -0.6823, -0.4931, -0.3828, -0.3922,\n",
            "        -0.4452, -0.5437, -0.6912, -0.6086, -0.4491, -0.3732, -0.4234, -0.4893,\n",
            "        -0.6007], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.2419838905334473 0.29138946533203125 2.578972578048706 0.6982386112213135 687\n",
            "8\n",
            "pred tensor([-0.4905, -0.4911, -0.4903, -0.4913, -0.4922, -0.4940, -0.4941, -0.4906,\n",
            "        -0.4855, -0.4876, -0.4938, -0.5101, -0.5365, -0.5473, -0.5159, -0.4756,\n",
            "        -0.4400, -0.4365, -0.4511, -0.4668, -0.5092, -0.6043, -0.7119, -0.6298,\n",
            "        -0.4970], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3972852826118469 0.291512131690979 2.578481674194336 0.6684622168540955 427\n",
            "pred tensor([-0.4018, -0.3682, -0.4072, -0.4703, -0.5599, -0.7230, -0.6332, -0.4438,\n",
            "        -0.3599, -0.3979, -0.4678, -0.5924, -0.7110, -0.4818, -0.3740, -0.3762,\n",
            "        -0.4205, -0.5259, -0.6784, -0.5930, -0.4312, -0.3561, -0.4164, -0.4468,\n",
            "        -0.5653], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.8925695419311523 0.2906225025653839 2.6235105991363525 0.700819194316864 663\n",
            "pred tensor([-0.4912, -0.4918, -0.4906, -0.4920, -0.4915, -0.4917, -0.4925, -0.4923,\n",
            "        -0.4893, -0.4900, -0.4899, -0.5025, -0.5178, -0.5279, -0.5055, -0.4719,\n",
            "        -0.4514, -0.4626, -0.4732, -0.5306, -0.6565, -0.6655, -0.5056, -0.4187,\n",
            "        -0.3683], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.416960746049881 0.2869202196598053 2.8172173500061035 0.6853229403495789 431\n",
            "pred tensor([-0.4171, -0.4482, -0.5322, -0.6944, -0.6592, -0.4592, -0.3649, -0.3995,\n",
            "        -0.4645, -0.5563, -0.7245, -0.4978, -0.3898, -0.3686, -0.4317, -0.4920,\n",
            "        -0.6648, -0.6200, -0.4388, -0.3538, -0.4180, -0.4707, -0.5863, -0.6978,\n",
            "        -0.4723], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 3.823166608810425 0.2879211902618408 2.7475249767303467 0.6994327306747437 626\n",
            "pred tensor([-0.4913, -0.4902, -0.4889, -0.4891, -0.4925, -0.4927, -0.4945, -0.4913,\n",
            "        -0.4827, -0.4815, -0.4845, -0.5003, -0.5348, -0.5457, -0.5053, -0.4531,\n",
            "        -0.4107, -0.4403, -0.4576, -0.5236, -0.6530, -0.6871, -0.4917, -0.4133,\n",
            "        -0.3611], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3918365240097046 0.2905425727367401 2.6110639572143555 0.6785426735877991 371\n",
            "pred tensor([-0.4177, -0.4727, -0.5852, -0.7102, -0.4880, -0.3898, -0.3712, -0.4443,\n",
            "        -0.5069, -0.6730, -0.5925, -0.4222, -0.3531, -0.4240, -0.4815, -0.6378,\n",
            "        -0.6345, -0.4307, -0.3606, -0.4354, -0.4889, -0.6068, -0.6688, -0.4433,\n",
            "        -0.3781], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.143630027770996 0.2931574285030365 2.488311290740967 0.711828887462616 609\n",
            "pred tensor([-0.4944, -0.4897, -0.4892, -0.4918, -0.4904, -0.4915, -0.4881, -0.4875,\n",
            "        -0.4879, -0.4941, -0.5024, -0.5234, -0.5099, -0.4737, -0.4501, -0.4636,\n",
            "        -0.4638, -0.5242, -0.6363, -0.6100, -0.4493, -0.3894, -0.3914, -0.4476,\n",
            "        -0.4989], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.4043706953525543 0.2911922037601471 2.5818932056427 0.6839896440505981 351\n",
            "pred tensor([-0.5990, -0.6756, -0.4438, -0.3977, -0.4031, -0.4553, -0.5105, -0.6544,\n",
            "        -0.5817, -0.4173, -0.3672, -0.4583, -0.4968, -0.6107, -0.6197, -0.4233,\n",
            "        -0.3683, -0.4565, -0.4974, -0.5942, -0.6357, -0.4299, -0.3786, -0.4607,\n",
            "        -0.5072], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.201632022857666 0.2910367250442505 2.596095561981201 0.6843306422233582 609\n",
            "pred tensor([-0.4922, -0.4917, -0.4918, -0.4900, -0.4900, -0.4912, -0.4912, -0.4924,\n",
            "        -0.4901, -0.4848, -0.4893, -0.4857, -0.5010, -0.5338, -0.5280, -0.4657,\n",
            "        -0.4277, -0.4478, -0.4722, -0.5165, -0.6163, -0.6657, -0.4442, -0.3988,\n",
            "        -0.3869], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3846052587032318 0.2929394543170929 2.520648956298828 0.6851314306259155 349\n",
            "pred tensor([-0.4823, -0.5085, -0.6090, -0.6934, -0.4493, -0.3906, -0.4162, -0.4873,\n",
            "        -0.5280, -0.6576, -0.5929, -0.4146, -0.3778, -0.4733, -0.5136, -0.6198,\n",
            "        -0.6521, -0.4211, -0.3853, -0.4649, -0.5144, -0.5757, -0.6856, -0.4499,\n",
            "        -0.4052], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.8827016353607178 0.2895197570323944 2.682129383087158 0.7099241614341736 780\n",
            "pred tensor([-0.4901, -0.4907, -0.4921, -0.4908, -0.4908, -0.4906, -0.4914, -0.4922,\n",
            "        -0.4879, -0.4877, -0.4913, -0.4983, -0.5129, -0.5154, -0.4913, -0.4636,\n",
            "        -0.4613, -0.4887, -0.5048, -0.5961, -0.6439, -0.4678, -0.4107, -0.3941,\n",
            "        -0.4752], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.39100533723831177 0.2891681492328644 2.698751449584961 0.6732964515686035 392\n",
            "pred tensor([-0.5159, -0.5915, -0.6823, -0.6397, -0.4337, -0.3922, -0.4548, -0.5180,\n",
            "        -0.5923, -0.7017, -0.5472, -0.4201, -0.3871, -0.4974, -0.5611, -0.6417,\n",
            "        -0.6362, -0.4243, -0.3928, -0.4689, -0.5310, -0.6004, -0.7016, -0.5311,\n",
            "        -0.4245], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.808847665786743 0.28394412994384766 2.990140199661255 0.6955407857894897 866\n",
            "pred tensor([-0.4919, -0.4925, -0.4907, -0.4912, -0.4908, -0.4917, -0.4908, -0.4865,\n",
            "        -0.4853, -0.4911, -0.4982, -0.5147, -0.5447, -0.5164, -0.4679, -0.4408,\n",
            "        -0.4672, -0.5010, -0.5534, -0.6500, -0.7035, -0.5003, -0.4182, -0.3843,\n",
            "        -0.4709], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.39116981625556946 0.2863936722278595 2.837339401245117 0.6675445437431335 451\n",
            "pred tensor([-0.5183, -0.6249, -0.7297, -0.5992, -0.4195, -0.3797, -0.4798, -0.5594,\n",
            "        -0.6580, -0.6894, -0.4234, -0.3945, -0.4469, -0.5136, -0.6103, -0.7144,\n",
            "        -0.5687, -0.4148, -0.3911, -0.4831, -0.5488, -0.6326, -0.6942, -0.5022,\n",
            "        -0.4142], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.1015000343322754 0.2959768772125244 2.3660850524902344 0.6998173594474792 859\n",
            "pred tensor([-0.4940, -0.4917, -0.4937, -0.4922, -0.4909, -0.4907, -0.4925, -0.4879,\n",
            "        -0.4858, -0.4896, -0.4970, -0.5207, -0.5376, -0.5011, -0.4632, -0.4437,\n",
            "        -0.4769, -0.5105, -0.6032, -0.7094, -0.6554, -0.4480, -0.3982, -0.3883,\n",
            "        -0.4698], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.37635260820388794 0.2987469732761383 2.2339277267456055 0.6750257015228271 451\n",
            "pred tensor([-0.5262, -0.6417, -0.7562, -0.5858, -0.4137, -0.3706, -0.4652, -0.5544,\n",
            "        -0.6719, -0.6873, -0.4121, -0.3791, -0.4323, -0.4966, -0.6349, -0.7313,\n",
            "        -0.4797, -0.3993, -0.3870, -0.4795, -0.5922, -0.6781, -0.6374, -0.4153,\n",
            "        -0.3918], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.955195665359497 0.299349308013916 2.2211833000183105 0.7022926211357117 762\n",
            "pred tensor([-0.4926, -0.4902, -0.4906, -0.4915, -0.4919, -0.4923, -0.4899, -0.4864,\n",
            "        -0.4854, -0.4886, -0.5049, -0.5378, -0.5292, -0.4775, -0.4485, -0.4514,\n",
            "        -0.4755, -0.5391, -0.6545, -0.7243, -0.5454, -0.4240, -0.3827, -0.4251,\n",
            "        -0.4827], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.36829447746276855 0.29410219192504883 2.4695229530334473 0.6830495595932007 417\n",
            "pred tensor([-0.5865, -0.7019, -0.6330, -0.4119, -0.3782, -0.4330, -0.5052, -0.6484,\n",
            "        -0.7074, -0.4057, -0.3903, -0.4095, -0.4832, -0.6294, -0.7215, -0.4199,\n",
            "        -0.4026, -0.4164, -0.4693, -0.6126, -0.7102, -0.5187, -0.4167, -0.3897,\n",
            "        -0.4549], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.92793345451355 0.28796541690826416 2.7540547847747803 0.6915064454078674 697\n",
            "pred tensor([-0.4917, -0.4907, -0.4929, -0.4894, -0.4875, -0.4876, -0.4878, -0.4968,\n",
            "        -0.5143, -0.5106, -0.4835, -0.4674, -0.4670, -0.4809, -0.5283, -0.6301,\n",
            "        -0.6658, -0.4746, -0.4217, -0.3871, -0.4335, -0.4679, -0.5807, -0.7077,\n",
            "        -0.6218], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.39268478751182556 0.28441256284713745 2.930601119995117 0.679084062576294 409\n",
            "pred tensor([-0.4122, -0.3919, -0.4224, -0.4676, -0.6161, -0.7216, -0.4340, -0.4066,\n",
            "        -0.3967, -0.4392, -0.5664, -0.7055, -0.5739, -0.4173, -0.3814, -0.4450,\n",
            "        -0.5122, -0.6477, -0.6591, -0.4188, -0.4003, -0.4401, -0.4699, -0.6182,\n",
            "        -0.7132], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.1517224311828613 0.28485187888145447 2.935137987136841 0.6951186656951904 663\n",
            "pred tensor([-0.4897, -0.4906, -0.4898, -0.4926, -0.4907, -0.4885, -0.4896, -0.4889,\n",
            "        -0.4954, -0.4888, -0.4863, -0.4828, -0.4858, -0.4964, -0.5400, -0.5673,\n",
            "        -0.4938, -0.4417, -0.4201, -0.4463, -0.5055, -0.6580, -0.7016, -0.4381,\n",
            "        -0.4144], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3875327408313751 0.288601815700531 2.728044033050537 0.6684336066246033 386\n",
            "pred tensor([-0.3821, -0.4187, -0.4785, -0.6502, -0.7082, -0.4130, -0.4150, -0.3938,\n",
            "        -0.4339, -0.5546, -0.7072, -0.5875, -0.4095, -0.3962, -0.4380, -0.4864,\n",
            "        -0.6487, -0.6826, -0.4116, -0.4154, -0.4254, -0.4597, -0.5794, -0.7063,\n",
            "        -0.6187], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.801140546798706 0.2877159118652344 2.776681423187256 0.7005412578582764 645\n",
            "pred tensor([-0.4932, -0.4900, -0.4914, -0.4917, -0.4912, -0.4899, -0.4910, -0.4919,\n",
            "        -0.4902, -0.4930, -0.4949, -0.4959, -0.4990, -0.4946, -0.4869, -0.4818,\n",
            "        -0.4775, -0.4909, -0.5511, -0.4706, -0.4254, -0.4143, -0.4344, -0.4887,\n",
            "        -0.6421], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3782869577407837 0.29086095094680786 2.5958948135375977 0.6636866927146912 387\n",
            "pred tensor([-0.7418, -0.5110, -0.4068, -0.4086, -0.4142, -0.4485, -0.6021, -0.7451,\n",
            "        -0.6077, -0.4046, -0.4160, -0.4193, -0.4663, -0.6409, -0.7648, -0.5381,\n",
            "        -0.4349, -0.4130, -0.4444, -0.5083, -0.6842, -0.7506, -0.4791, -0.4270,\n",
            "        -0.4273], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.5458786487579346 0.29304739832878113 2.4995296001434326 0.6890522241592407 633\n",
            "pred tensor([-0.4911, -0.4929, -0.4923, -0.4911, -0.4876, -0.4867, -0.4886, -0.4967,\n",
            "        -0.5290, -0.5268, -0.4749, -0.4607, -0.4568, -0.4517, -0.4948, -0.6419,\n",
            "        -0.7409, -0.5762, -0.4017, -0.4174, -0.4098, -0.4112, -0.4940, -0.6923,\n",
            "        -0.7782], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3881649076938629 0.2955021560192108 2.3948378562927246 0.6604575514793396 408\n",
            "pred tensor([-0.4897, -0.3896, -0.4047, -0.4026, -0.5271, -0.7319, -0.6751, -0.3494,\n",
            "        -0.4159, -0.3996, -0.4397, -0.6410, -0.7632, -0.4767, -0.3918, -0.4159,\n",
            "        -0.4050, -0.5175, -0.6982, -0.7011, -0.3724, -0.4154, -0.4274, -0.4140,\n",
            "        -0.5200], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.7727015018463135 0.29438894987106323 2.4546992778778076 0.6971482634544373 625\n",
            "pred tensor([-0.4946, -0.4905, -0.4902, -0.4898, -0.4914, -0.4930, -0.4952, -0.4906,\n",
            "        -0.4829, -0.4803, -0.4821, -0.4873, -0.5433, -0.6082, -0.5507, -0.4284,\n",
            "        -0.4304, -0.4274, -0.4209, -0.4908, -0.6915, -0.8045, -0.6092, -0.3587,\n",
            "        -0.4164], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.38900625705718994 0.29117849469184875 2.5778348445892334 0.6761160492897034 430\n",
            "pred tensor([-0.3942, -0.4028, -0.6126, -0.7960, -0.5903, -0.3416, -0.4117, -0.3768,\n",
            "        -0.5093, -0.7556, -0.6991, -0.3233, -0.4121, -0.3861, -0.4303, -0.6895,\n",
            "        -0.7770, -0.3824, -0.3981, -0.4186, -0.3910, -0.5851, -0.7557, -0.5785,\n",
            "        -0.3524], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.645862340927124 0.2938717007637024 2.4634594917297363 0.7159184217453003 650\n",
            "pred tensor([-0.4900, -0.4895, -0.4887, -0.4902, -0.4888, -0.4877, -0.4894, -0.4887,\n",
            "        -0.4964, -0.4947, -0.4910, -0.4864, -0.4856, -0.4853, -0.5026, -0.5431,\n",
            "        -0.5190, -0.4261, -0.4365, -0.4161, -0.4824, -0.7155, -0.7243, -0.3729,\n",
            "        -0.3673], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3645728826522827 0.29276183247566223 2.5442819595336914 0.6590955257415771 363\n",
            "pred tensor([-0.4084, -0.3660, -0.4675, -0.7182, -0.7549, -0.3654, -0.3660, -0.4100,\n",
            "        -0.3746, -0.5877, -0.7618, -0.5405, -0.3183, -0.4214, -0.3728, -0.5117,\n",
            "        -0.7349, -0.7156, -0.3039, -0.4067, -0.3942, -0.3922, -0.6406, -0.7681,\n",
            "        -0.5172], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.617422103881836 0.29231083393096924 2.5527563095092773 0.6760322451591492 625\n",
            "pred tensor([-0.4909, -0.4890, -0.4896, -0.4894, -0.4889, -0.4873, -0.4871, -0.4870,\n",
            "        -0.4880, -0.4919, -0.4982, -0.5017, -0.4930, -0.4811, -0.4783, -0.4749,\n",
            "        -0.5086, -0.5963, -0.4928, -0.3768, -0.4214, -0.3900, -0.4511, -0.7030,\n",
            "        -0.7720], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.35704848170280457 0.2901206910610199 2.6217381954193115 0.6844625473022461 342\n",
            "pred tensor([-0.4136, -0.2881, -0.4073, -0.3639, -0.4740, -0.7477, -0.6931, -0.2702,\n",
            "        -0.3745, -0.3853, -0.3826, -0.6744, -0.7629, -0.3880, -0.3116, -0.4039,\n",
            "        -0.3524, -0.6100, -0.7708, -0.4782, -0.2764, -0.4158, -0.3547, -0.5456,\n",
            "        -0.7640], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.412400484085083 0.28596240282058716 2.8829145431518555 0.7122504711151123 593\n",
            "pred tensor([-0.4906, -0.4894, -0.4872, -0.4878, -0.4870, -0.4892, -0.4863, -0.4890,\n",
            "        -0.4890, -0.4869, -0.4849, -0.4853, -0.4873, -0.5033, -0.5320, -0.5149,\n",
            "        -0.4415, -0.4460, -0.4216, -0.5061, -0.7248, -0.6000, -0.2679, -0.3562,\n",
            "        -0.4036], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3656848073005676 0.28603094816207886 2.8547732830047607 0.654526948928833 322\n",
            "pred tensor([-0.3485, -0.5008, -0.7482, -0.7290, -0.3106, -0.2959, -0.3976, -0.3482,\n",
            "        -0.5768, -0.7729, -0.5301, -0.2353, -0.3874, -0.3626, -0.4592, -0.7319,\n",
            "        -0.7192, -0.2794, -0.3228, -0.3991, -0.3525, -0.6193, -0.7705, -0.4667,\n",
            "        -0.2428], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.4514901638031006 0.29503899812698364 2.3935978412628174 0.7208244204521179 597\n",
            "pred tensor([-0.4879, -0.4892, -0.4894, -0.4880, -0.4909, -0.4846, -0.4771, -0.4790,\n",
            "        -0.4803, -0.4948, -0.5455, -0.5389, -0.4323, -0.4049, -0.4362, -0.4071,\n",
            "        -0.4315, -0.6181, -0.7687, -0.5721, -0.2522, -0.3410, -0.4000, -0.3362,\n",
            "        -0.5258], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3555087745189667 0.29431605339050293 2.4403252601623535 0.6687209010124207 331\n",
            "pred tensor([-0.7647, -0.6559, -0.2413, -0.3403, -0.3822, -0.3641, -0.6708, -0.7498,\n",
            "        -0.3123, -0.2686, -0.4061, -0.3305, -0.6231, -0.7641, -0.3842, -0.2305,\n",
            "        -0.4127, -0.3490, -0.5272, -0.7515, -0.5639, -0.2281, -0.3415, -0.3873,\n",
            "        -0.3645], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.249272346496582 0.2888926565647125 2.688369035720825 0.7070043683052063 569\n",
            "pred tensor([-0.4898, -0.4884, -0.4878, -0.4887, -0.4876, -0.4878, -0.4870, -0.4834,\n",
            "        -0.4857, -0.4873, -0.4995, -0.5185, -0.5026, -0.4528, -0.4585, -0.4431,\n",
            "        -0.4554, -0.6516, -0.6390, -0.2847, -0.3323, -0.4111, -0.3409, -0.4960,\n",
            "        -0.7443], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.35437142848968506 0.2895895838737488 2.6535205841064453 0.6717886328697205 338\n",
            "pred tensor([-0.6344, -0.2351, -0.3374, -0.3994, -0.3523, -0.6382, -0.7251, -0.3443,\n",
            "        -0.2459, -0.4332, -0.3473, -0.5621, -0.7542, -0.4777, -0.2229, -0.4081,\n",
            "        -0.3756, -0.4428, -0.7127, -0.6908, -0.3033, -0.2756, -0.4284, -0.3617,\n",
            "        -0.5311], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.211461067199707 0.28875499963760376 2.7138683795928955 0.6830183267593384 535\n",
            "9\n",
            "pred tensor([-0.4879, -0.4874, -0.4881, -0.4883, -0.4915, -0.4887, -0.4783, -0.4753,\n",
            "        -0.4813, -0.4766, -0.5169, -0.5895, -0.5064, -0.3520, -0.4043, -0.4282,\n",
            "        -0.3794, -0.4881, -0.7017, -0.7408, -0.3604, -0.2365, -0.4152, -0.3717,\n",
            "        -0.3837], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3530429005622864 0.29106399416923523 2.5884766578674316 0.6673117280006409 341\n",
            "pred tensor([-0.6626, -0.7211, -0.3018, -0.2390, -0.4369, -0.3379, -0.5696, -0.7529,\n",
            "        -0.3838, -0.2108, -0.4444, -0.3430, -0.5425, -0.7508, -0.4285, -0.2101,\n",
            "        -0.4323, -0.3613, -0.4854, -0.7172, -0.5520, -0.2222, -0.3594, -0.4081,\n",
            "        -0.3767], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.2081351280212402 0.2940575182437897 2.445138454437256 0.6740772724151611 517\n",
            "pred tensor([-0.4899, -0.4882, -0.4874, -0.4875, -0.4880, -0.4893, -0.4888, -0.4833,\n",
            "        -0.4822, -0.4841, -0.4859, -0.5062, -0.5311, -0.4811, -0.4172, -0.4552,\n",
            "        -0.4320, -0.4748, -0.6775, -0.6671, -0.2745, -0.2671, -0.4362, -0.3666,\n",
            "        -0.4377], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.33618098497390747 0.2946850657463074 2.4213154315948486 0.6853950023651123 323\n",
            "pred tensor([-0.6826, -0.7168, -0.2713, -0.2092, -0.4459, -0.3589, -0.5348, -0.7503,\n",
            "        -0.5036, -0.1805, -0.3904, -0.3907, -0.4270, -0.6828, -0.6513, -0.2332,\n",
            "        -0.2559, -0.4395, -0.3622, -0.6035, -0.7313, -0.3492, -0.1930, -0.4367,\n",
            "        -0.3924], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.139592170715332 0.29225096106529236 2.532339334487915 0.7211250066757202 537\n",
            "pred tensor([-0.4893, -0.4889, -0.4883, -0.4868, -0.4892, -0.4878, -0.4864, -0.4841,\n",
            "        -0.4851, -0.4865, -0.4896, -0.5069, -0.5140, -0.4530, -0.4331, -0.4670,\n",
            "        -0.4335, -0.5391, -0.6989, -0.4797, -0.2145, -0.3264, -0.4339, -0.3663,\n",
            "        -0.4936], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.35068008303642273 0.28628548979759216 2.828091621398926 0.6731377840042114 321\n",
            "pred tensor([-0.7131, -0.6815, -0.2548, -0.2172, -0.4499, -0.3736, -0.5216, -0.7393,\n",
            "        -0.5470, -0.1851, -0.3430, -0.4234, -0.3949, -0.6429, -0.6819, -0.2636,\n",
            "        -0.2253, -0.4595, -0.3730, -0.5198, -0.7381, -0.5542, -0.1991, -0.3502,\n",
            "        -0.4384], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.183283805847168 0.28467997908592224 2.947017192840576 0.6836009621620178 523\n",
            "pred tensor([-0.4882, -0.4886, -0.4878, -0.4861, -0.4876, -0.4892, -0.4934, -0.4905,\n",
            "        -0.4805, -0.4775, -0.4835, -0.4822, -0.5202, -0.5820, -0.4710, -0.3292,\n",
            "        -0.4142, -0.4426, -0.4048, -0.5631, -0.7363, -0.6690, -0.2683, -0.2191,\n",
            "        -0.4184], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.34411585330963135 0.28530389070510864 2.8901009559631348 0.664925217628479 309\n",
            "pred tensor([-0.4095, -0.4164, -0.6430, -0.7614, -0.4187, -0.1838, -0.3733, -0.4201,\n",
            "        -0.4272, -0.6709, -0.7051, -0.2894, -0.2161, -0.4547, -0.3871, -0.5328,\n",
            "        -0.7424, -0.5740, -0.2009, -0.3197, -0.4431, -0.4114, -0.6340, -0.7293,\n",
            "        -0.3446], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.352257251739502 0.29563090205192566 2.3593273162841797 0.7350974082946777 587\n",
            "pred tensor([-0.4912, -0.4917, -0.4887, -0.4874, -0.4907, -0.4882, -0.4869, -0.4850,\n",
            "        -0.4863, -0.4918, -0.5019, -0.5056, -0.4754, -0.4599, -0.4783, -0.4662,\n",
            "        -0.5572, -0.6649, -0.4031, -0.2594, -0.3948, -0.4334, -0.4084, -0.5643,\n",
            "        -0.7456], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.33973953127861023 0.2956077456474304 2.387972831726074 0.6652016043663025 325\n",
            "pred tensor([-0.7374, -0.3400, -0.2240, -0.4086, -0.4260, -0.4430, -0.6696, -0.7649,\n",
            "        -0.4737, -0.2174, -0.3838, -0.4386, -0.4478, -0.6711, -0.7510, -0.4420,\n",
            "        -0.2292, -0.3990, -0.4394, -0.4647, -0.6755, -0.7401, -0.4304, -0.2441,\n",
            "        -0.4026], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.3314054012298584 0.29243218898773193 2.5472965240478516 0.7151984572410583 624\n",
            "pred tensor([-0.4888, -0.4897, -0.4877, -0.4887, -0.4911, -0.4927, -0.4934, -0.4865,\n",
            "        -0.4789, -0.4817, -0.4829, -0.5078, -0.5694, -0.5501, -0.3843, -0.3943,\n",
            "        -0.4542, -0.4287, -0.5534, -0.7376, -0.7348, -0.3587, -0.2519, -0.4036,\n",
            "        -0.4312], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.34826308488845825 0.2889404296875 2.6825501918792725 0.6706699132919312 358\n",
            "pred tensor([-0.4209, -0.6239, -0.7779, -0.6691, -0.2801, -0.3150, -0.4582, -0.4115,\n",
            "        -0.6053, -0.7585, -0.6135, -0.2605, -0.3537, -0.4591, -0.4276, -0.6196,\n",
            "        -0.7403, -0.6208, -0.2844, -0.3218, -0.4617, -0.4295, -0.4983, -0.6785,\n",
            "        -0.7375], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.19012451171875 0.2849600911140442 2.9083688259124756 0.7183302640914917 679\n",
            "pred tensor([-0.4891, -0.4912, -0.4899, -0.4886, -0.4873, -0.4893, -0.4919, -0.5000,\n",
            "        -0.5005, -0.4789, -0.4764, -0.4803, -0.4851, -0.5760, -0.6472, -0.4429,\n",
            "        -0.3475, -0.4533, -0.4290, -0.4686, -0.6687, -0.7761, -0.5703, -0.2684,\n",
            "        -0.3638], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.36263230443000793 0.289036363363266 2.7006287574768066 0.6539071798324585 377\n",
            "pred tensor([-0.4609, -0.4125, -0.6053, -0.7632, -0.6225, -0.2862, -0.3778, -0.4605,\n",
            "        -0.4282, -0.6282, -0.7431, -0.5396, -0.2893, -0.4096, -0.4534, -0.4483,\n",
            "        -0.6307, -0.7336, -0.5884, -0.3057, -0.3730, -0.4700, -0.4329, -0.5210,\n",
            "        -0.6685], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.1510682106018066 0.2895860970020294 2.6563186645507812 0.7135159373283386 676\n",
            "pred tensor([-0.4938, -0.4909, -0.4902, -0.4908, -0.4941, -0.4900, -0.4857, -0.4864,\n",
            "        -0.4872, -0.4912, -0.5197, -0.5603, -0.4984, -0.4247, -0.4598, -0.4537,\n",
            "        -0.4817, -0.6638, -0.7543, -0.5428, -0.3113, -0.4039, -0.4591, -0.4206,\n",
            "        -0.5722], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.35468918085098267 0.29428645968437195 2.420236587524414 0.6661123037338257 367\n",
            "pred tensor([-0.7427, -0.7165, -0.3744, -0.3633, -0.4617, -0.4186, -0.6015, -0.7412,\n",
            "        -0.5772, -0.3092, -0.4305, -0.4351, -0.4572, -0.6412, -0.7245, -0.5227,\n",
            "        -0.3166, -0.4223, -0.4538, -0.4462, -0.5926, -0.7080, -0.6524, -0.3878,\n",
            "        -0.3523], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.0839667320251465 0.29790762066841125 2.2487149238586426 0.7152562737464905 705\n",
            "pred tensor([-0.4906, -0.4919, -0.4924, -0.4899, -0.4914, -0.4934, -0.4904, -0.4886,\n",
            "        -0.4869, -0.4873, -0.4982, -0.5290, -0.5329, -0.4635, -0.4628, -0.4617,\n",
            "        -0.4938, -0.6805, -0.7042, -0.4212, -0.3791, -0.4621, -0.4206, -0.5219,\n",
            "        -0.7144], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3535248041152954 0.29302293062210083 2.487102508544922 0.6792698502540588 386\n",
            "pred tensor([-0.7053, -0.4207, -0.4009, -0.4591, -0.4323, -0.6122, -0.7235, -0.5331,\n",
            "        -0.3483, -0.4690, -0.4203, -0.5073, -0.6851, -0.6804, -0.4216, -0.3933,\n",
            "        -0.4629, -0.4333, -0.6113, -0.7091, -0.5650, -0.3564, -0.4568, -0.4410,\n",
            "        -0.4733], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.0083277225494385 0.2900790572166443 2.647806167602539 0.6970720887184143 665\n",
            "pred tensor([-0.4934, -0.4924, -0.4903, -0.4901, -0.4894, -0.4925, -0.4922, -0.4953,\n",
            "        -0.4947, -0.4968, -0.4974, -0.4928, -0.4922, -0.4930, -0.5051, -0.5175,\n",
            "        -0.4699, -0.4606, -0.4414, -0.4950, -0.6668, -0.6094, -0.3913, -0.4404,\n",
            "        -0.4440], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.36487841606140137 0.2875504791736603 2.7677862644195557 0.6781366467475891 402\n",
            "pred tensor([-0.4156, -0.5538, -0.7189, -0.6875, -0.4367, -0.4371, -0.4341, -0.4329,\n",
            "        -0.6408, -0.7105, -0.4964, -0.4229, -0.4571, -0.4315, -0.6347, -0.7140,\n",
            "        -0.5052, -0.4306, -0.4664, -0.4198, -0.6099, -0.7101, -0.5411, -0.4306,\n",
            "        -0.4847], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.1252105236053467 0.28627848625183105 2.832096576690674 0.7074652910232544 658\n",
            "pred tensor([-0.4934, -0.4923, -0.4935, -0.4909, -0.4903, -0.4908, -0.4910, -0.4943,\n",
            "        -0.4929, -0.4890, -0.4867, -0.4857, -0.5087, -0.5481, -0.5336, -0.4599,\n",
            "        -0.4586, -0.4264, -0.5281, -0.6882, -0.6772, -0.4546, -0.4465, -0.4341,\n",
            "        -0.4141], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3546733856201172 0.2830027937889099 3.0003297328948975 0.6789067387580872 411\n",
            "pred tensor([-0.5887, -0.7050, -0.5880, -0.4247, -0.4635, -0.3885, -0.5187, -0.6742,\n",
            "        -0.6670, -0.4440, -0.4654, -0.4174, -0.4585, -0.6351, -0.6751, -0.4946,\n",
            "        -0.4565, -0.4378, -0.4227, -0.5867, -0.6714, -0.5529, -0.4474, -0.4670,\n",
            "        -0.4031], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.0716981887817383 0.28650933504104614 2.805405855178833 0.6996514797210693 700\n",
            "pred tensor([-0.4930, -0.4920, -0.4914, -0.4908, -0.4913, -0.4918, -0.4927, -0.4940,\n",
            "        -0.4917, -0.4894, -0.4896, -0.4964, -0.5044, -0.5125, -0.4988, -0.4800,\n",
            "        -0.4625, -0.4862, -0.6074, -0.6053, -0.4511, -0.4596, -0.4241, -0.4144,\n",
            "        -0.5418], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3463878929615021 0.2957210838794708 2.3446669578552246 0.6691156029701233 389\n",
            "pred tensor([-0.6690, -0.6587, -0.4974, -0.4614, -0.4266, -0.4100, -0.5916, -0.6701,\n",
            "        -0.5561, -0.4489, -0.4587, -0.3761, -0.5266, -0.6577, -0.6202, -0.4521,\n",
            "        -0.4782, -0.4091, -0.4500, -0.6000, -0.6418, -0.5277, -0.4710, -0.4650,\n",
            "        -0.3959], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.019667148590088 0.29566648602485657 2.366152048110962 0.7023324370384216 751\n",
            "pred tensor([-0.4918, -0.4943, -0.4921, -0.4906, -0.4900, -0.4912, -0.4912, -0.4976,\n",
            "        -0.4966, -0.4925, -0.4861, -0.4892, -0.5215, -0.5491, -0.5089, -0.4689,\n",
            "        -0.4336, -0.4038, -0.5150, -0.6400, -0.6424, -0.5037, -0.4659, -0.4419,\n",
            "        -0.3675], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.35031118988990784 0.2980860769748688 2.2513961791992188 0.6826362609863281 405\n",
            "pred tensor([-0.4824, -0.6098, -0.6206, -0.5094, -0.4783, -0.4301, -0.3854, -0.5481,\n",
            "        -0.6298, -0.5877, -0.4640, -0.4772, -0.3875, -0.4600, -0.5919, -0.6035,\n",
            "        -0.5374, -0.4770, -0.4584, -0.3889, -0.4949, -0.5957, -0.6040, -0.5368,\n",
            "        -0.4802], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.9218454360961914 0.2948139011859894 2.4058799743652344 0.6874685287475586 729\n",
            "pred tensor([-0.4908, -0.4906, -0.4892, -0.4921, -0.4904, -0.4901, -0.4908, -0.4928,\n",
            "        -0.4933, -0.4933, -0.4937, -0.4878, -0.4880, -0.5040, -0.5204, -0.4967,\n",
            "        -0.4749, -0.4314, -0.4268, -0.5312, -0.6178, -0.5701, -0.4680, -0.4692,\n",
            "        -0.3944], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.33979305624961853 0.28987258672714233 2.6424009799957275 0.6798897385597229 399\n",
            "pred tensor([-0.3774, -0.5369, -0.6072, -0.5980, -0.4999, -0.4850, -0.3892, -0.4021,\n",
            "        -0.5746, -0.6032, -0.5382, -0.4799, -0.4486, -0.3590, -0.4893, -0.5833,\n",
            "        -0.5795, -0.5055, -0.4943, -0.4211, -0.3723, -0.5327, -0.5982, -0.5708,\n",
            "        -0.4764], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.1254725456237793 0.2875892221927643 2.7568843364715576 0.6978608965873718 729\n",
            "pred tensor([-0.4897, -0.4909, -0.4914, -0.4922, -0.4895, -0.4907, -0.4875, -0.4928,\n",
            "        -0.4979, -0.5023, -0.5014, -0.4874, -0.4696, -0.4597, -0.5116, -0.5809,\n",
            "        -0.5486, -0.4829, -0.4629, -0.3813, -0.3867, -0.5136, -0.6054, -0.6133,\n",
            "        -0.5286], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.33360517024993896 0.2882547974586487 2.719545841217041 0.6813104748725891 400\n",
            "pred tensor([-0.4899, -0.4236, -0.3401, -0.4829, -0.5637, -0.5936, -0.5300, -0.4920,\n",
            "        -0.4041, -0.3617, -0.5259, -0.5899, -0.5874, -0.4913, -0.4719, -0.3483,\n",
            "        -0.4248, -0.5433, -0.5843, -0.5583, -0.4856, -0.4336, -0.3589, -0.4693,\n",
            "        -0.5609], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.9637322425842285 0.2907640039920807 2.587717056274414 0.7044237852096558 765\n",
            "pred tensor([-0.4920, -0.4917, -0.4897, -0.4891, -0.4918, -0.4903, -0.4919, -0.4922,\n",
            "        -0.4887, -0.4850, -0.4827, -0.5054, -0.5391, -0.5159, -0.4901, -0.4348,\n",
            "        -0.3898, -0.4750, -0.5679, -0.6165, -0.5390, -0.4927, -0.4542, -0.3554,\n",
            "        -0.3792], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.34104180335998535 0.2943941354751587 2.419759511947632 0.6725732684135437 388\n",
            "pred tensor([-0.5115, -0.5878, -0.6210, -0.5342, -0.4949, -0.3959, -0.3728, -0.5188,\n",
            "        -0.5826, -0.5950, -0.4926, -0.4613, -0.3527, -0.4508, -0.5439, -0.5916,\n",
            "        -0.5492, -0.4991, -0.4232, -0.3555, -0.4963, -0.5674, -0.5887, -0.5086,\n",
            "        -0.4916], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.0627145767211914 0.2901901304721832 2.6194541454315186 0.6856217384338379 804\n",
            "pred tensor([-0.4921, -0.4919, -0.4904, -0.4899, -0.4908, -0.4899, -0.4926, -0.4923,\n",
            "        -0.4896, -0.4882, -0.4908, -0.5111, -0.5224, -0.5073, -0.4839, -0.4389,\n",
            "        -0.4113, -0.4779, -0.5723, -0.6009, -0.5248, -0.4888, -0.4279, -0.3457,\n",
            "        -0.4035], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.33044278621673584 0.2887417674064636 2.698953628540039 0.6763157248497009 409\n",
            "pred tensor([-0.5316, -0.6256, -0.6485, -0.5463, -0.4885, -0.3877, -0.3765, -0.5444,\n",
            "        -0.6087, -0.6066, -0.4906, -0.4453, -0.3459, -0.4867, -0.5769, -0.6242,\n",
            "        -0.5474, -0.4946, -0.3750, -0.4140, -0.5618, -0.6192, -0.5814, -0.4963,\n",
            "        -0.4354], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.1219828128814697 0.2848946452140808 2.9097557067871094 0.7023559212684631 814\n",
            "pred tensor([-0.4916, -0.4908, -0.4937, -0.4963, -0.4907, -0.4921, -0.4868, -0.4876,\n",
            "        -0.5040, -0.5150, -0.5129, -0.4893, -0.4487, -0.4248, -0.4740, -0.5806,\n",
            "        -0.6550, -0.5952, -0.5061, -0.4597, -0.3686, -0.3771, -0.5160, -0.6173,\n",
            "        -0.6596], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "repr, std, cov, clossl, wrong 0.33783218264579773 0.28947722911834717 2.6531870365142822 0.6675684452056885 426\n",
            "pred tensor([-0.5705, -0.4875, -0.3930, -0.3741, -0.5486, -0.6315, -0.6223, -0.4958,\n",
            "        -0.4328, -0.3412, -0.4924, -0.5804, -0.6467, -0.5412, -0.4724, -0.3698,\n",
            "        -0.4241, -0.5440, -0.6185, -0.5766, -0.4828, -0.4082, -0.3638, -0.4702,\n",
            "        -0.5787], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.0065712928771973 0.2951153814792633 2.382373571395874 0.699057936668396 850\n",
            "pred tensor([-0.4917, -0.4932, -0.4937, -0.4932, -0.4933, -0.4914, -0.4916, -0.4959,\n",
            "        -0.4969, -0.4970, -0.4907, -0.4830, -0.4788, -0.4946, -0.5268, -0.5342,\n",
            "        -0.4967, -0.4509, -0.3948, -0.4333, -0.5457, -0.6614, -0.6646, -0.5306,\n",
            "        -0.4725], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3201008141040802 0.29488441348075867 2.3841147422790527 0.6730508804321289 471\n",
            "pred tensor([-0.3756, -0.3796, -0.5554, -0.6651, -0.6910, -0.5200, -0.4475, -0.3547,\n",
            "        -0.4756, -0.6050, -0.6871, -0.5656, -0.4709, -0.3665, -0.4433, -0.5837,\n",
            "        -0.6636, -0.5724, -0.4727, -0.3787, -0.4085, -0.5670, -0.6395, -0.6143,\n",
            "        -0.4893], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.8791202306747437 0.29437604546546936 2.400987386703491 0.7068015336990356 834\n",
            "10\n",
            "pred tensor([-0.4934, -0.4917, -0.4927, -0.4927, -0.4894, -0.4917, -0.4948, -0.4932,\n",
            "        -0.4950, -0.4892, -0.4869, -0.5006, -0.5228, -0.5250, -0.5016, -0.4677,\n",
            "        -0.4322, -0.4453, -0.5406, -0.6482, -0.6265, -0.5070, -0.4516, -0.3729,\n",
            "        -0.3844], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3173331022262573 0.28606024384498596 2.815011978149414 0.6660016775131226 476\n",
            "pred tensor([-0.5391, -0.6540, -0.7057, -0.5754, -0.4697, -0.3848, -0.3976, -0.5837,\n",
            "        -0.6688, -0.6558, -0.4913, -0.4237, -0.3689, -0.5233, -0.6183, -0.6919,\n",
            "        -0.5687, -0.4754, -0.3883, -0.4151, -0.5706, -0.6499, -0.6383, -0.5015,\n",
            "        -0.4417], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.8350682258605957 0.28321513533592224 2.980832815170288 0.6932376623153687 831\n",
            "pred tensor([-0.4901, -0.4926, -0.4904, -0.4923, -0.4927, -0.4919, -0.4915, -0.4879,\n",
            "        -0.4835, -0.4915, -0.5263, -0.5380, -0.5135, -0.4782, -0.4382, -0.4415,\n",
            "        -0.5101, -0.6258, -0.6841, -0.5893, -0.4897, -0.4328, -0.3754, -0.4101,\n",
            "        -0.5577], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.31387051939964294 0.28955715894699097 2.6309328079223633 0.6814783811569214 470\n",
            "pred tensor([-0.6591, -0.7115, -0.5603, -0.4636, -0.3862, -0.3863, -0.5625, -0.6644,\n",
            "        -0.6498, -0.4850, -0.4153, -0.3539, -0.4736, -0.5923, -0.6780, -0.5587,\n",
            "        -0.4693, -0.3909, -0.3709, -0.5248, -0.6335, -0.6729, -0.5373, -0.4641,\n",
            "        -0.3856], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.7475814819335938 0.29278844594955444 2.468806743621826 0.6882261633872986 821\n",
            "pred tensor([-0.4893, -0.4923, -0.4900, -0.4896, -0.4909, -0.4866, -0.4850, -0.4907,\n",
            "        -0.5127, -0.5193, -0.5012, -0.4715, -0.4386, -0.4352, -0.5134, -0.6304,\n",
            "        -0.6780, -0.5744, -0.4784, -0.4153, -0.3669, -0.4090, -0.5730, -0.6737,\n",
            "        -0.7160], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3203373849391937 0.2920691668987274 2.512920379638672 0.66721510887146 466\n",
            "pred tensor([-0.5433, -0.4538, -0.3857, -0.3714, -0.5712, -0.6675, -0.6697, -0.4950,\n",
            "        -0.4282, -0.3560, -0.4366, -0.6079, -0.6757, -0.5842, -0.4620, -0.3998,\n",
            "        -0.3440, -0.4717, -0.6073, -0.6905, -0.6114, -0.4735, -0.4245, -0.3626,\n",
            "        -0.4184], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.984604001045227 0.29276299476623535 2.462709903717041 0.6910160779953003 804\n",
            "pred tensor([-0.4915, -0.4921, -0.4925, -0.4882, -0.4886, -0.4897, -0.4933, -0.4946,\n",
            "        -0.4878, -0.4833, -0.4832, -0.5009, -0.5274, -0.5269, -0.4894, -0.4479,\n",
            "        -0.4082, -0.4698, -0.6025, -0.6871, -0.5777, -0.4628, -0.4028, -0.3546,\n",
            "        -0.4100], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3129524886608124 0.28925129771232605 2.6380302906036377 0.6611629724502563 444\n",
            "pred tensor([-0.5986, -0.6931, -0.7098, -0.5160, -0.4242, -0.3499, -0.3878, -0.6268,\n",
            "        -0.6994, -0.6038, -0.4471, -0.3818, -0.3392, -0.5139, -0.6652, -0.7059,\n",
            "        -0.5435, -0.4375, -0.3703, -0.3655, -0.5706, -0.6972, -0.6921, -0.4993,\n",
            "        -0.4246], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.8251644372940063 0.28853029012680054 2.7177042961120605 0.7125171422958374 807\n",
            "pred tensor([-0.4920, -0.4896, -0.4894, -0.4910, -0.4879, -0.4869, -0.4883, -0.4943,\n",
            "        -0.5002, -0.4875, -0.4755, -0.4656, -0.4902, -0.5591, -0.5937, -0.5144,\n",
            "        -0.4501, -0.3842, -0.3679, -0.5175, -0.6569, -0.7155, -0.5710, -0.4523,\n",
            "        -0.3909], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.30367422103881836 0.2892513871192932 2.626610279083252 0.673154354095459 439\n",
            "pred tensor([-0.3372, -0.4449, -0.6387, -0.7039, -0.6276, -0.4616, -0.4029, -0.3469,\n",
            "        -0.4685, -0.6484, -0.6956, -0.5629, -0.4422, -0.3786, -0.3532, -0.5465,\n",
            "        -0.6675, -0.6782, -0.5053, -0.4225, -0.3576, -0.4001, -0.6003, -0.6814,\n",
            "        -0.5895], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 1.821626901626587 0.2842935025691986 2.8772811889648438 0.6880989074707031 772\n",
            "pred tensor([-0.4884, -0.4874, -0.4892, -0.4901, -0.4892, -0.4886, -0.4924, -0.4904,\n",
            "        -0.4922, -0.4922, -0.4856, -0.4836, -0.4823, -0.4992, -0.5108, -0.5077,\n",
            "        -0.4850, -0.4481, -0.4297, -0.5041, -0.6262, -0.6131, -0.4735, -0.4202,\n",
            "        -0.3517], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.2979315519332886 0.2917443513870239 2.4996562004089355 0.6795186400413513 413\n",
            "pred tensor([-0.3680, -0.5528, -0.6875, -0.6791, -0.4883, -0.4214, -0.3412, -0.4092,\n",
            "        -0.6279, -0.6935, -0.5294, -0.4272, -0.3570, -0.3682, -0.6122, -0.6832,\n",
            "        -0.5310, -0.4305, -0.3733, -0.3472, -0.5884, -0.6844, -0.5910, -0.4522,\n",
            "        -0.3968], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.072784900665283 0.2951442003250122 2.335733413696289 0.7140915989875793 768\n",
            "pred tensor([-0.4890, -0.4888, -0.4894, -0.4888, -0.4890, -0.4880, -0.4899, -0.4901,\n",
            "        -0.4917, -0.4889, -0.4876, -0.4834, -0.4850, -0.4990, -0.5133, -0.5076,\n",
            "        -0.4856, -0.4498, -0.4080, -0.4300, -0.5446, -0.6071, -0.4912, -0.4411,\n",
            "        -0.3658], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.2945447564125061 0.2911502420902252 2.5337178707122803 0.6626293063163757 367\n",
            "pred tensor([-0.3047, -0.4070, -0.5961, -0.6980, -0.5886, -0.4643, -0.4054, -0.3031,\n",
            "        -0.4193, -0.6163, -0.6998, -0.5450, -0.4524, -0.3683, -0.3283, -0.5752,\n",
            "        -0.6846, -0.6104, -0.4761, -0.4058, -0.3243, -0.4650, -0.6217, -0.6787,\n",
            "        -0.5146], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.9149516820907593 0.2908807694911957 2.5363898277282715 0.710308313369751 729\n",
            "pred tensor([-0.4876, -0.4886, -0.4892, -0.4871, -0.4880, -0.4871, -0.4886, -0.4871,\n",
            "        -0.4847, -0.4821, -0.4905, -0.5105, -0.5165, -0.5004, -0.4784, -0.4500,\n",
            "        -0.4219, -0.4495, -0.5561, -0.6220, -0.5157, -0.4556, -0.3866, -0.3109,\n",
            "        -0.3484], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.30065280199050903 0.2881760597229004 2.6720240116119385 0.6572556495666504 353\n",
            "pred tensor([-0.5378, -0.6866, -0.6737, -0.4898, -0.4238, -0.3087, -0.3674, -0.5814,\n",
            "        -0.6842, -0.5178, -0.4414, -0.3266, -0.3606, -0.5806, -0.6818, -0.5128,\n",
            "        -0.4394, -0.3279, -0.3762, -0.5700, -0.6729, -0.5032, -0.4463, -0.3366,\n",
            "        -0.3723], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.0499894618988037 0.2854372560977936 2.807544708251953 0.7063084244728088 730\n",
            "pred tensor([-0.4907, -0.4877, -0.4874, -0.4868, -0.4858, -0.4851, -0.4869, -0.4911,\n",
            "        -0.4942, -0.4885, -0.4831, -0.4728, -0.4759, -0.4999, -0.5366, -0.5457,\n",
            "        -0.5062, -0.4757, -0.4314, -0.3833, -0.3690, -0.4500, -0.5847, -0.6905,\n",
            "        -0.6018], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.33992472290992737 0.28665024042129517 2.7513012886047363 0.654405415058136 367\n",
            "pred tensor([-0.4858, -0.4312, -0.3368, -0.3261, -0.5090, -0.6506, -0.6755, -0.4874,\n",
            "        -0.4164, -0.3085, -0.4220, -0.5851, -0.6888, -0.4939, -0.4273, -0.3171,\n",
            "        -0.4382, -0.5927, -0.6827, -0.4858, -0.4129, -0.3195, -0.4612, -0.5938,\n",
            "        -0.6693], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.29457688331604 0.28897079825401306 2.607588768005371 0.6850415468215942 704\n",
            "pred tensor([-0.4880, -0.4883, -0.4885, -0.4878, -0.4867, -0.4871, -0.4863, -0.4884,\n",
            "        -0.4848, -0.4820, -0.4809, -0.4885, -0.5115, -0.5204, -0.5090, -0.4860,\n",
            "        -0.4603, -0.4324, -0.4197, -0.4833, -0.5952, -0.6568, -0.5676, -0.4840,\n",
            "        -0.4222], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3405744135379791 0.2907449007034302 2.5265817642211914 0.6555579900741577 360\n",
            "pred tensor([-0.3383, -0.3185, -0.4768, -0.6300, -0.7224, -0.5371, -0.4564, -0.3435,\n",
            "        -0.3115, -0.5634, -0.6759, -0.5603, -0.4532, -0.3450, -0.3269, -0.5524,\n",
            "        -0.6554, -0.5349, -0.4394, -0.3360, -0.3562, -0.5499, -0.6389, -0.5267,\n",
            "        -0.4378], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.8263399600982666 0.29140976071357727 2.489130973815918 0.695181667804718 730\n",
            "pred tensor([-0.4887, -0.4884, -0.4862, -0.4850, -0.4854, -0.4865, -0.4881, -0.4885,\n",
            "        -0.4854, -0.4821, -0.4817, -0.4932, -0.5095, -0.5204, -0.5110, -0.4933,\n",
            "        -0.4721, -0.4431, -0.4149, -0.4217, -0.4903, -0.6000, -0.6368, -0.5392,\n",
            "        -0.4737], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.36410558223724365 0.2910509705543518 2.505821943283081 0.6573435664176941 383\n",
            "pred tensor([-0.3985, -0.3099, -0.3098, -0.4778, -0.6459, -0.7311, -0.5355, -0.4410,\n",
            "        -0.3068, -0.3284, -0.5569, -0.6920, -0.5505, -0.4450, -0.3026, -0.3415,\n",
            "        -0.5553, -0.6747, -0.5176, -0.4318, -0.2939, -0.3739, -0.5679, -0.6406,\n",
            "        -0.5019], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.8830556869506836 0.2917146384716034 2.4588396549224854 0.6878388524055481 709\n",
            "pred tensor([-0.4867, -0.4881, -0.4867, -0.4864, -0.4856, -0.4858, -0.4829, -0.4810,\n",
            "        -0.4839, -0.4964, -0.5070, -0.5023, -0.4878, -0.4719, -0.4458, -0.4384,\n",
            "        -0.4643, -0.5338, -0.6284, -0.6380, -0.5358, -0.4739, -0.3896, -0.3010,\n",
            "        -0.2996], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.338372141122818 0.291730135679245 2.4488861560821533 0.649880588054657 377\n",
            "pred tensor([-0.4479, -0.6559, -0.7742, -0.5916, -0.4532, -0.3350, -0.2524, -0.4678,\n",
            "        -0.6879, -0.6907, -0.4724, -0.3592, -0.2516, -0.4181, -0.6221, -0.7179,\n",
            "        -0.5019, -0.4037, -0.2761, -0.3539, -0.5810, -0.7177, -0.5778, -0.4655,\n",
            "        -0.3582], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.54626727104187 0.28648751974105835 2.6978931427001953 0.7223400473594666 734\n",
            "pred tensor([-0.4860, -0.4878, -0.4865, -0.4853, -0.4856, -0.4841, -0.4867, -0.4891,\n",
            "        -0.4887, -0.4838, -0.4758, -0.4686, -0.4845, -0.5272, -0.5556, -0.5480,\n",
            "        -0.4979, -0.4541, -0.3936, -0.3513, -0.4061, -0.5808, -0.7344, -0.6576,\n",
            "        -0.4837], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3315031826496124 0.2874453365802765 2.6393606662750244 0.6447828412055969 386\n",
            "pred tensor([-0.3921, -0.2763, -0.2961, -0.5230, -0.7388, -0.7307, -0.4919, -0.3822,\n",
            "        -0.2604, -0.3715, -0.6133, -0.7615, -0.5367, -0.4252, -0.2854, -0.3072,\n",
            "        -0.5770, -0.7515, -0.5776, -0.4561, -0.3363, -0.2812, -0.5008, -0.7018,\n",
            "        -0.6983], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.3675217628479004 0.28898417949676514 2.54551362991333 0.7067589163780212 708\n",
            "pred tensor([-0.4869, -0.4856, -0.4851, -0.4846, -0.4853, -0.4895, -0.4900, -0.4894,\n",
            "        -0.4836, -0.4752, -0.4696, -0.4975, -0.5463, -0.5718, -0.5297, -0.4785,\n",
            "        -0.4217, -0.3559, -0.3619, -0.5356, -0.7303, -0.7287, -0.4993, -0.4104,\n",
            "        -0.2896], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3243047297000885 0.288409948348999 2.5617082118988037 0.6543550491333008 391\n",
            "pred tensor([-0.2932, -0.5509, -0.7657, -0.7087, -0.4696, -0.3667, -0.2665, -0.4209,\n",
            "        -0.6880, -0.7871, -0.5166, -0.4113, -0.2827, -0.3255, -0.6118, -0.7829,\n",
            "        -0.5873, -0.4493, -0.3381, -0.2755, -0.4627, -0.7002, -0.7455, -0.5114,\n",
            "        -0.4392], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.367060422897339 0.28605592250823975 2.6933822631835938 0.7183757424354553 732\n",
            "pred tensor([-0.4866, -0.4867, -0.4853, -0.4856, -0.4840, -0.4844, -0.4872, -0.4877,\n",
            "        -0.4875, -0.4853, -0.4807, -0.4800, -0.4960, -0.5202, -0.5253, -0.4971,\n",
            "        -0.4729, -0.4313, -0.3819, -0.3931, -0.5535, -0.7010, -0.5740, -0.4531,\n",
            "        -0.3470], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.32862183451652527 0.28096261620521545 2.937469959259033 0.6498761773109436 389\n",
            "pred tensor([-0.2947, -0.4509, -0.7177, -0.8111, -0.5527, -0.4477, -0.3045, -0.3186,\n",
            "        -0.6217, -0.7920, -0.6282, -0.4767, -0.3737, -0.2928, -0.5290, -0.7443,\n",
            "        -0.7466, -0.5222, -0.4421, -0.3273, -0.3346, -0.5637, -0.7303, -0.6934,\n",
            "        -0.5153], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.481208086013794 0.2845238745212555 2.716175079345703 0.7198163270950317 771\n",
            "pred tensor([-0.4858, -0.4864, -0.4863, -0.4857, -0.4847, -0.4862, -0.4872, -0.4901,\n",
            "        -0.4865, -0.4823, -0.4806, -0.4891, -0.5099, -0.5267, -0.5024, -0.4696,\n",
            "        -0.4323, -0.3828, -0.4488, -0.6555, -0.6167, -0.4746, -0.3962, -0.3121,\n",
            "        -0.3469], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3467833697795868 0.2869774103164673 2.5840814113616943 0.6573784947395325 407\n",
            "pred tensor([-0.5734, -0.7775, -0.7611, -0.5189, -0.4570, -0.3329, -0.3162, -0.5909,\n",
            "        -0.7831, -0.6962, -0.5100, -0.4312, -0.3061, -0.4423, -0.6842, -0.8010,\n",
            "        -0.5685, -0.4840, -0.3616, -0.2866, -0.5444, -0.7490, -0.6754, -0.5030,\n",
            "        -0.4105], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.383702039718628 0.28866085410118103 2.5270557403564453 0.6998434662818909 763\n",
            "pred tensor([-0.4864, -0.4879, -0.4854, -0.4858, -0.4867, -0.4881, -0.4870, -0.4834,\n",
            "        -0.4811, -0.4753, -0.4890, -0.5168, -0.5308, -0.4998, -0.4762, -0.4403,\n",
            "        -0.3977, -0.4231, -0.5987, -0.7300, -0.5644, -0.4728, -0.3821, -0.2904,\n",
            "        -0.4233], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3425488770008087 0.29050618410110474 2.377920150756836 0.640688955783844 403\n",
            "pred tensor([-0.6827, -0.7975, -0.5444, -0.4683, -0.3394, -0.2852, -0.5580, -0.7668,\n",
            "        -0.5943, -0.4817, -0.3720, -0.2744, -0.5329, -0.7503, -0.6243, -0.4912,\n",
            "        -0.3983, -0.2808, -0.4854, -0.7287, -0.7305, -0.5017, -0.4331, -0.2919,\n",
            "        -0.4030], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.5100622177124023 0.2883264422416687 2.444458484649658 0.7095022201538086 753\n",
            "pred tensor([-0.4852, -0.4849, -0.4842, -0.4851, -0.4868, -0.4866, -0.4856, -0.4812,\n",
            "        -0.4784, -0.4884, -0.5227, -0.5327, -0.5058, -0.4787, -0.4440, -0.3918,\n",
            "        -0.3803, -0.5060, -0.7078, -0.6996, -0.5016, -0.4611, -0.3434, -0.2793,\n",
            "        -0.4773], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.3389799892902374 0.28831177949905396 2.4325575828552246 0.6489865183830261 393\n",
            "pred tensor([-0.7245, -0.7598, -0.5038, -0.4640, -0.3037, -0.3511, -0.6173, -0.7867,\n",
            "        -0.5158, -0.4761, -0.3219, -0.3133, -0.5868, -0.7749, -0.5366, -0.4773,\n",
            "        -0.3464, -0.2939, -0.5599, -0.7603, -0.5758, -0.4844, -0.3861, -0.2820,\n",
            "        -0.5098], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.2625162601470947 0.2813534438610077 2.7471325397491455 0.7166773080825806 720\n",
            "pred tensor([-0.4866, -0.4861, -0.4850, -0.4850, -0.4850, -0.4872, -0.4874, -0.4861,\n",
            "        -0.4812, -0.4810, -0.4870, -0.5139, -0.5245, -0.4915, -0.4683, -0.4335,\n",
            "        -0.3804, -0.4529, -0.6317, -0.6123, -0.4849, -0.4562, -0.3617, -0.2998,\n",
            "        -0.4108], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3280066251754761 0.2789995074272156 2.8268818855285645 0.6543551087379456 379\n",
            "pred tensor([-0.6389, -0.7970, -0.6172, -0.4999, -0.4488, -0.3157, -0.4093, -0.6688,\n",
            "        -0.7926, -0.5495, -0.4905, -0.3714, -0.2939, -0.5645, -0.7552, -0.6428,\n",
            "        -0.4960, -0.4327, -0.2935, -0.4889, -0.7261, -0.7527, -0.5000, -0.4748,\n",
            "        -0.3635], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.206564426422119 0.27747219800949097 2.9397172927856445 0.6985850930213928 684\n",
            "11\n",
            "pred tensor([-0.4844, -0.4837, -0.4843, -0.4838, -0.4866, -0.4854, -0.4837, -0.4783,\n",
            "        -0.4767, -0.4829, -0.5074, -0.5247, -0.5036, -0.4846, -0.4582, -0.4149,\n",
            "        -0.3978, -0.5205, -0.7139, -0.6533, -0.4901, -0.4612, -0.3514, -0.2950,\n",
            "        -0.4963], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3524916172027588 0.27560174465179443 3.068521738052368 0.6490415930747986 386\n",
            "pred tensor([-0.7468, -0.7618, -0.4919, -0.4842, -0.3644, -0.3085, -0.5676, -0.7704,\n",
            "        -0.5677, -0.4884, -0.4205, -0.2964, -0.5077, -0.7140, -0.6607, -0.4881,\n",
            "        -0.4671, -0.3447, -0.3814, -0.6100, -0.7718, -0.5641, -0.4838, -0.4424,\n",
            "        -0.3317], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 3.232567548751831 0.283934086561203 2.599334478378296 0.700280487537384 691\n",
            "pred tensor([-0.4855, -0.4874, -0.4842, -0.4833, -0.4828, -0.4859, -0.4837, -0.4831,\n",
            "        -0.4801, -0.4816, -0.4875, -0.5092, -0.5126, -0.4907, -0.4738, -0.4504,\n",
            "        -0.4247, -0.4986, -0.6320, -0.5539, -0.4774, -0.4492, -0.3661, -0.3014,\n",
            "        -0.4271], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 0.33140769600868225 0.28581011295318604 2.5501580238342285 0.6516721844673157 369\n",
            "pred tensor([-0.6515, -0.8046, -0.6471, -0.4995, -0.4880, -0.3687, -0.2990, -0.5295,\n",
            "        -0.7538, -0.7462, -0.5008, -0.4952, -0.3767, -0.3246, -0.5711, -0.7663,\n",
            "        -0.6143, -0.4998, -0.4441, -0.3036, -0.5141, -0.7322, -0.7136, -0.5042,\n",
            "        -0.4775], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 2.085085868835449 0.2863176465034485 2.4681363105773926 0.7100797295570374 724\n",
            "pred tensor([-0.4844, -0.4837, -0.4820, -0.4827, -0.4833, -0.4882, -0.4866, -0.4846,\n",
            "        -0.4833, -0.4832, -0.4986, -0.5237, -0.5247, -0.4858, -0.4707, -0.4283,\n",
            "        -0.3823, -0.4957, -0.6932, -0.6247, -0.4799, -0.4673, -0.3811, -0.2976,\n",
            "        -0.4009], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.3417353332042694 0.28628215193748474 2.490563154220581 0.6555442810058594 394\n",
            "pred tensor([-0.6367, -0.8168, -0.6147, -0.4962, -0.4745, -0.3349, -0.3522, -0.6107,\n",
            "        -0.7999, -0.5610, -0.5075, -0.4272, -0.2845, -0.5265, -0.7560, -0.6879,\n",
            "        -0.5036, -0.4797, -0.3299, -0.4296, -0.6847, -0.7832, -0.4944, -0.5036,\n",
            "        -0.3757], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 1.8851463794708252 0.2790813446044922 2.8741259574890137 0.6920504570007324 721\n",
            "pred tensor([-0.4837, -0.4853, -0.4862, -0.4853, -0.4858, -0.4826, -0.4811, -0.4833,\n",
            "        -0.4894, -0.4995, -0.4933, -0.4802, -0.4656, -0.4472, -0.4850, -0.5992,\n",
            "        -0.6072, -0.4757, -0.4642, -0.3939, -0.3185, -0.3813, -0.6190, -0.8179,\n",
            "        -0.6772], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "repr, std, cov, clossl, wrong 0.34490370750427246 0.2767484188079834 2.97149395942688 0.653535008430481 385\n",
            "pred tensor([-0.4885, -0.4789, -0.3515, -0.2904, -0.5396, -0.7773, -0.7374, -0.4837,\n",
            "        -0.4831, -0.3318, -0.3731, -0.6501, -0.8184, -0.5037, -0.4960, -0.3620,\n",
            "        -0.3006, -0.5826, -0.7997, -0.5581, -0.4946, -0.3813, -0.3040, -0.5651,\n",
            "        -0.7936], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.])\n",
            "repr, std, cov, clossl, wrong 2.010709285736084 0.27570465207099915 3.0253968238830566 0.7187181115150452 710\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(100):\n",
        "    print(i)\n",
        "    train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    # checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    # torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "# batch64 28m58s 84\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "31c1755c-ef2a-4f8c-ba23-806590aaa7fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "# ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n",
        "\n",
        "\n",
        "# # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "# 2  5/11 8\n",
        "# 1/10 4 7/9\n",
        "# 0  3/12 6\n",
        "\n",
        "# 13 11 14\n",
        "# 10 12 9\n",
        "\n",
        "# from gymnasium.wrappers import TimeLimit\n",
        "from gym.wrappers import TimeLimit\n",
        "env = TimeLimit(env, max_episode_steps=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PraFUAPB3j7v",
        "outputId": "329ef0aa-3ac2-43e9-8784-567b3a45bd4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-42-ff80b479d892>:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-42-ff80b479d892>:85: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dided\n",
            "time\n",
            "[13, 13, 2, 1, 0, 4, 13, 13, 0, 13, 12, 0, 12, 13, 13, 12, 13, 13, 13, 4, 13, 13, 13, 13, 10, 10, 0, 11, 7, 12, 4, 12, 13, 12, 14, 4, 12, 4, 4, 12, 6, 1, 9, 9, 14, 4, 13, 13, 13, 13, 13, 13, 4, 13, 11, 13, 13, 0, 13, 13, 4, 4, 13, 13, 13, 13, 12, 12, 0, 12, 1, 1, 1, 1, 6, 11, 13, 12, 14, 13, 12, 4, 13, 13, 13, 12, 12, 0, 4, 1, 6, 6, 7, 13, 14, 0, 12, 13, 13, 13, 13, 12, 4, 13, 13, 4, 12, 13, 12, 13, 4, 12, 13, 13, 13, 11, 4, 13, 4, 4, 4, 13, 13, 10, 13, 0, 13, 13, 4, 13, 13, 13, 13, 4, 13, 4, 4, 13, 13, 6, 13, 4, 13, 13, 13, 13, 1, 1, 12, 13, 4, 13, 13, 13, 13, 13, 4, 10, 13, 11, 13, 13, 13, 4, 13, 13, 13, 13, 12, 4, 13, 4, 5, 1, 1, 2, 13, 0, 13, 12, 4, 13, 13, 1, 13, 12, 13, 12, 4, 13, 13, 10, 13, 4, 13, 4, 13, 13, 13, 1, 12, 13, 12, 4, 13, 12, 13, 13, 10, 6, 1, 1, 1, 6, 6, 6, 0, 13, 13, 13, 4, 12, 13, 13, 13, 13, 4, 13, 4, 4, 13, 4, 0, 13, 13, 13, 13, 4, 13, 4, 4, 13, 13, 13, 13, 13, 4, 4, 13, 4, 12, 13, 0, 12, 4, 13, 10, 6, 0, 14, 1, 1, 5, 1, 12, 13, 13, 4, 4, 13, 13, 1, 12, 0, 12, 13, 4, 12, 13, 13, 12, 13, 12, 13, 4, 4, 0, 13, 13, 4, 13, 13, 4, 13, 13, 0, 13, 13, 13, 13, 13, 7, 4, 13, 13, 13, 13, 13, 1, 1, 10, 1, 4, 4, 4, 13, 4, 10, 4, 0, 13]\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# print(env.action_space) # 15\n",
        "\n",
        "def simulate(agent, buffer=[], k=4):\n",
        "    # agent.eval()\n",
        "    out=None\n",
        "    writer = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # writer = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    act_list=[]\n",
        "    lstate=[]\n",
        "    # h0 = torch.randn((agent.jepa.pred.num_layers, agent.d_model), device=device)\n",
        "    while True:\n",
        "    # for i in range(400):\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        # if len(act)<=0: act = agent(state).cpu()[0,:4].tolist()\n",
        "        # print(act.shape, h0.shape) # [1, 6], [1, 256]\n",
        "        lstate.append(state)\n",
        "        if len(act)<=0:\n",
        "            # lact, lh0, lx, lz = agent(state, h0)\n",
        "            # act = lact.cpu()[0,:k].tolist()\n",
        "            # act = agent(state, k)\n",
        "            act = agent(lstate, k=k)\n",
        "            lstate=[]\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        # print(i, 'act: ',action, 'reward: ',reward)\n",
        "        act_list.append(action)\n",
        "        writer.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"dided\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    print(act_list)\n",
        "    env.close()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO"
      },
      "outputs": [],
      "source": [
        "# @title alllll\n",
        "for i in range(30):\n",
        "    # print(\"#### simulate ####\")\n",
        "    # buffer_=[]\n",
        "    for _ in range(5):\n",
        "        buffer = simulate(agent, buffer)\n",
        "        # buffer_ = simulate(agent, buffer_)\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len)\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    # checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    # torch.save(checkpoint, folder+'agentoptim1.pkl')\n",
        "\n",
        "    # buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "    # with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "    print(\"train_data.data\",len(train_data.data))\n",
        "    while len(train_data.data)>20000: # 10000:6.9gb, 20000:5.5gb\n",
        "        buffer.pop(random.randrange(len(buffer)))\n",
        "        train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "b8zxYU9jpE8K",
        "outputId": "9a3cbf99-0034-44f6-d61c-1af446e408c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "eb772df9-211e-4169-994b-9235c6746e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240926_151905-tt74nb5t</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/tt74nb5t' target=\"_blank\">grateful-voice-88</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/tt74nb5t' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/tt74nb5t</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(project=\"procgen\",\n",
        "    config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xLh80kPvEzwX"
      },
      "outputs": [],
      "source": [
        "# @title agent pixel save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.emb = torch.nn.Embedding(15, dim_a) # env.action_space # 15\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        for i in range(20): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "\n",
        "            dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "\n",
        "            # loss, sx_ = self.rnn_pred(sx_, x)\n",
        "            loss, sx_ = self.rnn_pred(sx_, x_)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(syaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb #+ clossl\n",
        "\n",
        "                    loss = loss + jloss + closs #+ conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sy_ = sy_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29O1eyvhnRSD",
        "outputId": "c470e601-d5da-4b94-bb69-928dd9d823af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-77-bbc83a6aed37>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=2. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        # 0.0083 0.06 1.0 = 1, 7, 120.5\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        optim_z = torch.optim.SGD([z], lr=1e2, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.95)) #\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.data)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i,x.data, z.squeeze(), loss.item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        # print(\"search\",loss.item())\n",
        "        return lact#, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        _,T,_ = sx.shape\n",
        "        batch = 1\n",
        "        lr = 1e-1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                x[:,:self.lx.shape[1]] = self.lx[:,:T]\n",
        "                z[:,:self.lz.shape[1]] = self.lz[:,:T]\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            # print(i,x.data, z.squeeze(), loss.item())\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        return lact, lh0, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, gamma=0.9): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sx = self.jepa.pred(sxaz)\n",
        "                sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        # if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            # loss=0\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(syaz)\n",
        "                    sy_ = sy_ + self.jepa.pred(syaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # cost loss\n",
        "                    reward_ = self.tcost(sy_).squeeze(-1) # [batch_size]\n",
        "                    clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    _, st = self.get(st, world_state=world_zero)\n",
        "                    # print(\"stt\",st.shape)\n",
        "                    stt = self.tcost(self.jepa.enc(st.unsqueeze(1))).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb + clossl\n",
        "\n",
        "                    # loss = loss + jloss + closs\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    # loss=0\n",
        "                else:\n",
        "                    scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mY7BITKjSKC",
        "outputId": "cbad0ffc-e8e9-4a4d-bd3c-d6d9ddaf6e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2336301\n",
            "1278976\n",
            "399360\n",
            "1024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-76-e20d23bca149>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=3, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v, drop=0.2)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=50. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # e = d_model**-0.5\n",
        "        # self.h0 = torch.empty((self.jepa.pred.num_layers, 1, d_model), device=device).uniform_(-e, e) # [num_layers, batch, d_model]\n",
        "        # self.h0 = torch.normal(mean=0, std=e, size=(self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # torch.nn.init.xavier_uniform_(self.h0) # xavier_uniform_, kaiming_normal_\n",
        "\n",
        "        # self.lx, self.lz = torch.empty(1,0,dim_a), torch.empty(1,0,dim_z)\n",
        "        self.lx, self.lz = None, None\n",
        "        state = torch.zeros((1, 3,64,64), device=device)\n",
        "        self.sx = self.jepa.enc(state)\n",
        "\n",
        "    # def forward(self, state, k=1): # live run in env # np (64, 64, 3)\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        self.update_h0(lstate, laction)\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "            # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.h0=lh0[k].unsqueeze(1) # [num_layers, 1, d_model]\n",
        "        # self.lx, self.lz = lx[:,k:], lz[:,k:] # [batch, T, dim_a], [batch, T, dim_z]\n",
        "        self.lx, self.lz = lx[k:], lz[k:] # [T, dim_a], [T, dim_z]\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "\n",
        "                # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "                # print(torch.cat(lstate, dim=0).shape)\n",
        "                # lsx = self.jepa.enc(torch.stack(lstate, dim=0))#.unsqueeze(0)\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx-torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                # batch, seq_len, _ = lstate.shape\n",
        "                # seq_len, _ = lstate.shape\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    try: la = self.emb(self.la[:seq_len])\n",
        "                    except:\n",
        "                        print(\"err self.la\")\n",
        "                        # la = self.emb([0]*seq_len)\n",
        "                        la = self.emb(torch.zeros(seq_len, dtype=int, device=device))\n",
        "\n",
        "        # lz = nn.Parameter(torch.zeros((batch, seq_len, self.dim_z),device=device))\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        # optim_z = torch.optim.SGD([lz], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([lz], 1e0, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "\n",
        "        for i in range(20): # num epochs\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                # print(sxaz.shape, self.h0.shape)\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                # sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                loss = F.mse_loss(out_, out)\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            print(lz.data)\n",
        "            with torch.no_grad(): lz.clamp_(min=-1, max=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1]\n",
        "        self.la = la[k:]\n",
        "        return h0\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                # x[:,:self.lx.shape[1]], z[:,:self.lz.shape[1]] = self.lx[:,:T], self.lz[:,:T]\n",
        "                x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].repeat(batch,1,1), self.lz[:T].repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            # print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            # print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i, \"loss\", loss.squeeze().data)\n",
        "            # print(x.shape,torch.argmax(-dist,dim=-1).shape,z.shape,loss.shape) # [16, 6, 3], [16, 6], [16, 6, 1], [16, 1]\n",
        "            # print(i, torch.cat([x,torch.argmax(-dist,dim=-1),z],dim=-1).squeeze().data)\n",
        "            print(i, \"x act z\", torch.cat([x[0],torch.argmax(-dist,dim=-1)[0].unsqueeze(-1),z[0]],dim=-1).squeeze().data)\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, t, dim_a], [batch, t, dim_z]\n",
        "\n",
        "\n",
        "    def search_optimxz(self, sx, T=6, h0=None):\n",
        "        self.eval()\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 4 # 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1 ; sgd\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_uniform_(z) # xavier_normal_, xavier_uniform_\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        # optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e1, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].unsqueeze(0).repeat(batch,1,1), self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        print(\"search\", z[0].squeeze())\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        for i in range(10): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, lsx, lh0,c = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.sum().backward()\n",
        "            # optim_x.step(); optim_z.step()\n",
        "            # optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            print(i, \"search loss\", loss.squeeze().data)\n",
        "            # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "            print(i, \"search z\", z[0].squeeze().data)\n",
        "            # print(torch.argmin(dist,dim=-1).int())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        print(\"c\",torch.stack(c)[:,idx])\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # cost += tcost + icost\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "        c=[]\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            # print(sx.shape, a.shape, z.shape)\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            c.append(tcost)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    # imshow(state[0].cpu())\n",
        "                    # print(\"norm\", torch.norm(sy[0]-sy_[0], dim=-1))\n",
        "                    # # if torch.norm(sy[0]-sy_[0], dim=-1) > 1:\n",
        "                    # print(i, reward[0])\n",
        "                    # print(sy)\n",
        "                    # print(sy_)\n",
        "                    # print(sy[0]-sy_[0])\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "\n",
        "                    # cost loss\n",
        "                    # syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = 100*clossl\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batc h_size, d_model]\n",
        "            # sx=sy_\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "\n",
        "                    # z = self.jepa.argm(sy_, a, sy)\n",
        "                    z = self.argm(sy, sy_, h0, a, reward)\n",
        "                    with torch.no_grad(): z.mul_(torch.rand_like(z)).mul_((torch.rand_like(z)>0.5).bool()) # dropout without scailing\n",
        "\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "\n",
        "                    # cost loss\n",
        "                    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    # syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = self.closs_coeff * clossl\n",
        "\n",
        "                    # print(h0.requires_grad)\n",
        "                    # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "                    # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "                    # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # torch.norm(sy-sx, dim=-1)\n",
        "                    # sx=sy\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    norm = torch.norm(sy, dim=-1)[0].item()\n",
        "                    z_norm = torch.norm(z)\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "\n",
        "                # lh0 = torch.zeros((rwd.shape[1],)+h0.shape, device=device)\n",
        "                # lz = torch.zeros((lsy.shape[0], lsy.shape[1], self.dim_z), device=device)\n",
        "                    # for name, param in agent.tcost.named_parameters():\n",
        "                    #     print(\"param.data\",param.max().item(),param.min().item())\n",
        "                    #     print(\"agent.tcost\",param.data)\n",
        "\n",
        "\n",
        "# # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "# ema_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.999))\n",
        "# for epoch in range(300):\n",
        "#       for input, target in loader:\n",
        "#           optimizer.zero_grad()\n",
        "#           loss_fn(model(input), target).backward()\n",
        "#           optimizer.step()\n",
        "#           ema_model.update_parameters(model)\n",
        "# # Update bn statistics for the ema_model at the end\n",
        "# torch.optim.swa_utils.update_bn(loader, ema_model)\n",
        "# # Use ema_model to make predictions on test data\n",
        "# preds = ema_model(test_input)\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "\n",
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cg0BI2TwY9-p"
      },
      "outputs": [],
      "source": [
        "# @title z.grad.data = -z.grad.data\n",
        "\n",
        "# self.eval()\n",
        "batch = 4 # 16\n",
        "x = nn.Parameter(torch.empty((batch, T, agent.dim_a),device=device))\n",
        "torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# optim_ = torch.optim.SGD([x,z], lr=1e1) # 3e3\n",
        "optim_ = torch.optim.AdamW([x,z], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "print(\"search z\", z[0].squeeze())\n",
        "print(\"search x\", x[0].squeeze())\n",
        "sx, h0 = sx.detach(), h0.detach()\n",
        "for i in range(10): # num epochs\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    z.grad.data = -z.grad.data\n",
        "    optim_.step()\n",
        "    optim_.zero_grad()\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "    print(i, \"search loss\", loss.squeeze().data)\n",
        "    print(i, \"search z\", z[0].squeeze().data)\n",
        "    print(i, \"search x\", x[0].squeeze().data)\n",
        "dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "print(\"c\",torch.stack(c)[:,idx])\n",
        "# return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "# print(lact[idx], lh0[:,:,idx,:], x[idx], z[idx])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5VMebkQ1mJtD"
      },
      "outputs": [],
      "source": [
        "# @title argm agent.rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def argm(sx, x,h0, lr=3e3): # 3e3\n",
        "    # agent.eval()\n",
        "    # batch_size, T, _ = sx.shape\n",
        "    batch = 16 # 16\n",
        "    z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "    torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "    optim_z = torch.optim.SGD([z], lr=1e3, maximize=True) # 3e3\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.LBFGS([z], max_iter=5, lr=1)\n",
        "\n",
        "    # print(\"argm\", z[0].squeeze())\n",
        "    sx, h0 = sx.detach(), h0.detach()\n",
        "    x = x.detach().repeat(batch,1,1)\n",
        "    for i in range(5): # num epochs\n",
        "        # print(sx.shape, x.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "        loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "        loss.sum().backward()\n",
        "        optim_z.step()\n",
        "        optim_z.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "        # print(i, \"argm loss\", loss.squeeze().data)\n",
        "        # print(i, \"argm z\", z[0].squeeze().data)\n",
        "    idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "    return z[idx].unsqueeze(0)\n",
        "\n",
        "\n",
        "T=1\n",
        "xx = torch.empty((1, T, agent.dim_a))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "# print(x.shape)\n",
        "optim_x = torch.optim.SGD([x], lr=1e1) # 1e-1,1e-0,1e4 ; 1e2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "\n",
        "state = torch.zeros((1, 3,64,64))\n",
        "with torch.no_grad():\n",
        "    sx = agent.jepa.enc(state).detach()\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "print(time.time()-start)\n",
        "\n",
        "print(\"search\",x.squeeze().data)\n",
        "for i in range(20): # 5\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    z = argm(sx, x_,h0)\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [1, 1, 3], [1, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "    print(i, \"search loss\", x.squeeze().data, loss.item())\n",
        "    # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "\n",
        "# z sgd 1e3\n",
        "# 9 search loss tensor([0.0142, 0.0142, 0.0142, 0.0142])\n",
        "# 9 search z tensor([-0.3381, -0.7005, -0.5877, -0.0664, -0.1439,  0.0283,  0.0541, -0.1439])\n",
        "\n",
        "# x sgd 1e2\n",
        "# 1 tensor([0.3561, 0.3059, 0.8830]) 0.014148875139653683\n",
        "# 9 tensor([0.3560, 0.3064, 0.8828]) 2.328815611463142e-07\n",
        "\n",
        "# 1e0\n",
        "# 19 tensor([-0.5768,  0.5778,  0.5774]) 6.543130552927323e-07\n",
        "# 19 tensor([0.3570, 0.6689, 0.6521]) 2.474381801675918e-07\n",
        "# 19 tensor([0.5783, 0.5765, 0.5772]) 1.519319567933053e-07\n",
        "# 19 tensor([0.3427, 0.6795, 0.6487]) 4.220427456402831e-07\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gcvgdCB1h1_E"
      },
      "outputs": [],
      "source": [
        "# @title torch.optim.LBFGS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Example of a deep nonlinear model f(x)\n",
        "class DeepNonlinearModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNonlinearModel, self).__init__()\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(10, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "f = DeepNonlinearModel()\n",
        "# x = torch.randn(1, 10, requires_grad=True)\n",
        "# xx = torch.randn((1,10))\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "\n",
        "# Define loss function (mean squared error for this example)\n",
        "target = torch.tensor([[0.0]])  # Target output\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    return loss\n",
        "\n",
        "optimizer = torch.optim.LBFGS([x], lr=1.0, max_iter=5)  # Limit to 2-3 iterations for speed\n",
        "start_time = time.time()\n",
        "for _ in range(2):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step(closure)  # Perform a step of optimisation\n",
        "    print(loss.item())\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "start_time = time.time()\n",
        "optimizer = torch.optim.SGD([x], lr=1e1, maximize=True) # 3e3\n",
        "for _ in range(5):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step()  # Perform a step of optimisation\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    print(loss.item())\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "# optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "    # def argm(self, sx, a, lr=3e3): # 3e3\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "    #     optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    #     # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    #     sx, a = sx.detach(), a.detach()\n",
        "    #     for i in range(5): # 10\n",
        "    #         sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #         with torch.amp.autocast('cuda'):\n",
        "    #             # sx_ = self.jepa.pred(sxaz)\n",
        "    #             sx_ = sx + self.jepa.pred(sxaz)\n",
        "    #             cost = -self.tcost(sx_)\n",
        "\n",
        "    #         cost.backward()\n",
        "    #         optim.step()\n",
        "    #         # scaler.scale(cost).backward()\n",
        "    #         # scaler.step(optim)\n",
        "    #         # scaler.update()\n",
        "    #         optim.zero_grad()\n",
        "    #         with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "    #         print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def argm(self, sx, lr=3e3): # 3e3\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch_size, T, _ = sx.shape\n",
        "        batch = 16\n",
        "        # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "        z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "        optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "        sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "        # sx = sx.detach()\n",
        "        for i in range(20): # 10\n",
        "            # print(sx.shape,z.shape)\n",
        "            sxz = torch.cat([sx, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                cost = model(sxz)\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "            # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "            # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        # return z.detach()\n",
        "        # print(\"argm z\",z.squeeze().data)\n",
        "        # print(\"cost\",cost.squeeze())\n",
        "        idx = torch.argmax(loss)\n",
        "        # return z[idx].detach().unsqueeze(0)\n",
        "        return z[:,idx].detach()\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch=1\n",
        "        T=1\n",
        "        x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "\n",
        "        lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "        # ratio = 6e0\n",
        "        lr = 1e-1 # adamw 1e-1\n",
        "        ratio = 4\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        # optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze())\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "        for i in range(50):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            z = argm(x)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "            # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "            # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                x.clamp_(min=-1, max=1)\n",
        "            # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "        idx = torch.argmax(loss)\n",
        "        print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd):\n",
        "        self.tcost.eval()\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "            lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "                for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                    syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                    out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                    lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                    lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "                repr_loss = F.mse_loss(lsy, lsy_)\n",
        "                syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "                clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "                # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "                cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "outputs": [],
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.amp.autocast('cuda'):\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjm2kV3H7ZVR"
      },
      "outputs": [],
      "source": [
        "for name, p in agent.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(name, p.numel())\n",
        "\n",
        "\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HcOidvtW9KAH"
      },
      "outputs": [],
      "source": [
        "# @title from RNN2\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, h0=None, c0=None): # [batch_size, seq_len, input_size]\n",
        "        if h0 is None: h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        if c0 is None: c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        out, h0 = self.rnn(x, h0)\n",
        "        # out, (h0,c0) = self.lstm(x, (h0,c0))\n",
        "        # out:(batch_size, seq_length, hidden_size) (n, 28, 128)\n",
        "        out = out[:, -1, :] # out: (n, 128)\n",
        "        out = self.fc(out) # out: (n, 10)\n",
        "        return out\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "\n",
        "d_model,dim_a,dim_z = 256,3,1\n",
        "pred = nn.Sequential(\n",
        "    nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model),\n",
        "    )\n",
        "gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "\n",
        "print(sum(p.numel() for p in pred.parameters() if p.requires_grad)) # 264192\n",
        "print(sum(p.numel() for p in gru.parameters() if p.requires_grad)) # 397824\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AodVas3L4ZS",
        "outputId": "f1940ab6-b72d-4c8d-f97d-6d876f1b92e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 256])\n",
            "136960\n",
            "136960\n"
          ]
        }
      ],
      "source": [
        "# @title efficientnet\n",
        "# https://arxiv.org/pdf/2207.10318 # visualise kernal\n",
        "\n",
        "# https://pytorch.org/hub/research-models\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/shufflenetv2.py\n",
        "\n",
        "import torch\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py\n",
        "from torchvision.models.efficientnet import *\n",
        "from torchvision.models import efficientnet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # https://arxiv.org/pdf/2104.00298\n",
        "# Stage Operator Stride #Channels #Layers\n",
        "# 0 Conv3x3 2 24 1\n",
        "# 1 Fused-MBConv1, k3x3 1 24 2\n",
        "# 2 Fused-MBConv4, k3x3 2 48 4\n",
        "# 3 Fused-MBConv4, k3x3 2 64 4\n",
        "# 4 MBConv4, k3x3, SE0.25 2 128 6\n",
        "# 5 MBConv6, k3x3, SE0.25 1 160 9\n",
        "# 6 MBConv6, k3x3, SE0.25 2 256 15\n",
        "# 7 Conv1x1 & Pooling & FC - 1280 1\n",
        "\n",
        "# # elif arch.startswith(\"efficientnet_v2_s\"):\n",
        "# inverted_residual_setting = [\n",
        "#     FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
        "#     FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
        "#     FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
        "#     MBConvConfig(4, 3, 2, 64, 128, 6),\n",
        "#     MBConvConfig(6, 3, 1, 128, 160, 9),\n",
        "#     MBConvConfig(6, 3, 2, 160, 256, 15),\n",
        "# ]\n",
        "# last_channel = 1280\n",
        "\n",
        "# d_list=[24, 48, 64, 128, 160, 256] #\n",
        "d_list=[16, 32, 48, 96, 108, 172] #\n",
        "inverted_residual_setting = [\n",
        "    efficientnet.FusedMBConvConfig(1, 3, 1, d_list[0], d_list[0], 2),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[0], d_list[1], 4),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[1], d_list[2], 4),\n",
        "    efficientnet.MBConvConfig(4, 3, 2, d_list[2], d_list[3], 6),\n",
        "    efficientnet.MBConvConfig(6, 3, 1, d_list[3], d_list[4], 9),\n",
        "    efficientnet.MBConvConfig(6, 3, 2, d_list[4], d_list[5], 15),\n",
        "]\n",
        "last_channel = 512\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "\n",
        "effnet = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "effnet.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "\n",
        "#   (features): Sequential(\n",
        "#     (0): Conv2dNormActivation(\n",
        "#       (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "#       (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "#       (2): SiLU(inplace=True)\n",
        "\n",
        "input = torch.rand((1,1,256,256), device=device)\n",
        "out = effnet(input)\n",
        "print(out.shape)\n",
        "# print(effnet)\n",
        "print(sum(p.numel() for p in effnet.parameters() if p.requires_grad)) #\n",
        "print(sum(p.numel() for p in effnet.parameters())) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "# !pip install -qq vector-quantize-pytorch\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LK5u500Vad2P"
      },
      "outputs": [],
      "source": [
        "# @title FSQ jax\n",
        "# https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "Codeword = jax.Array\n",
        "Indices = jax.Array\n",
        "\n",
        "def round_ste(z):\n",
        "  \"\"\"Round with straight through gradients.\"\"\"\n",
        "  zhat = jnp.round(z)\n",
        "  return z + jax.lax.stop_gradient(zhat - z)\n",
        "\n",
        "class FSQ:\n",
        "  \"\"\"Quantizer.\"\"\"\n",
        "  def __init__(self, levels: list[int], eps: float = 1e-3):\n",
        "    self._levels = levels\n",
        "    self._eps = eps\n",
        "    self._levels_np = np.asarray(levels)\n",
        "    self._basis = np.concatenate(([1], np.cumprod(self._levels_np[:-1]))).astype(np.uint32)\n",
        "    self._implicit_codebook = self.indexes_to_codes(np.arange(self.codebook_size))\n",
        "    print(\"self._basis\",self._basis)\n",
        "    print(\"self._implicit_codebook\",self._implicit_codebook)\n",
        "\n",
        "  @property\n",
        "  def num_dimensions(self):\n",
        "    \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
        "    return len(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook_size(self):\n",
        "    \"\"\"Size of the codebook.\"\"\"\n",
        "    return np.prod(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook(self):\n",
        "    \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
        "    return self._implicit_codebook\n",
        "\n",
        "  def bound(self, z: jax.Array) -> jax.Array:\n",
        "    \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "    half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
        "    offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
        "    shift = jnp.tan(offset / half_l)\n",
        "    return jnp.tanh(z + shift) * half_l - offset\n",
        "\n",
        "  def quantize(self, z: jax.Array) -> Codeword:\n",
        "    \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
        "    quantized = round_ste(self.bound(z))\n",
        "\n",
        "    # Renormalize to [-1, 1].\n",
        "    half_width = self._levels_np // 2\n",
        "    return quantized / half_width\n",
        "\n",
        "  def _scale_and_shift(self, zhat_normalized):\n",
        "    # Scale and shift to range [0, ..., L-1]\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "  def _scale_and_shift_inverse(self, zhat):\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat - half_width) / half_width\n",
        "\n",
        "  def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
        "    \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
        "    assert zhat.shape[-1] == self.num_dimensions\n",
        "    zhat = self._scale_and_shift(zhat)\n",
        "    return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
        "\n",
        "  def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
        "    \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
        "    indices = indices[..., jnp.newaxis]\n",
        "    print(indices, self._basis, self._levels_np)\n",
        "    print(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    codes_non_centered = np.mod(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    return self._scale_and_shift_inverse(codes_non_centered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xHxv7ptuwVHX"
      },
      "outputs": [],
      "source": [
        "# @title FSQ torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module): # https://colab.research.google.com/github/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "    def __init__(self, levels, eps = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cat([torch.ones(1, device=device), torch.cumprod(self.levels[:-1], dim=0)]).long()\n",
        "        self.num_dimensions = len(levels)\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        # self.mean = self.codebook.mean(dim=0)\n",
        "        # self.max = self.codebook.max(dim=0).values\n",
        "        # self.min = self.codebook.min(dim=0).values\n",
        "\n",
        "    def bound(self, z):\n",
        "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "        half_l = (self.levels - 1) * (1 - self.eps) / 2 # [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "        # half_l = (self.levels-1)/2 # me ?\n",
        "        offset = torch.where(self.levels % 2 == 1, 0.0, 0.5) # [0.0000, 0.0000, 0.5000] mean?\n",
        "        # print(\"half_l\", half_l)\n",
        "        # shift = torch.tan(offset / half_l) # [0.0000, 0.0000, 1.5608] < tan(1)\n",
        "\n",
        "        # print(\"shift\", shift)\n",
        "        # print(\"bound\", torch.tanh(z + shift) * half_l - offset)\n",
        "\n",
        "        # print(f'half_l {half_l}, shift {shift}, bound {torch.tanh(z + shift) * half_l - offset}')\n",
        "        # return torch.tanh(z + shift) * half_l - offset\n",
        "        # return torch.tanh(z - shift) * half_l + offset\n",
        "        return torch.tanh(z) * half_l + offset\n",
        "\n",
        "    def forward(self, z):\n",
        "        quantized = ste_round(self.bound(z))\n",
        "        # print(\"quantized\", quantized)\n",
        "        half_width = self.levels // 2 # Renormalize to [-1, 1]\n",
        "        return quantized / half_width\n",
        "\n",
        "    def _scale_and_shift(self, zhat_normalized): # Scale and shift to range [0, ..., L-1]\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "    def _scale_and_shift_inverse(self, zhat):\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat - half_width) / half_width\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        assert zhat.shape[-1] == self.num_dimensions\n",
        "        zhat = self._scale_and_shift(zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).long()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes_non_centered = torch.fmod(indices // self.basis, self.levels)\n",
        "        return self._scale_and_shift_inverse(codes_non_centered)\n",
        "\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "# print(fsq.codebook)\n",
        "\n",
        "# batch_size, seq_len = 1, 1\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SnfcKPses5X",
        "outputId": "7c50a3e3-281a-4375-b86f-ece58f6775c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "half_l tensor([0.9990, 0.9990, 0.4995]), shift tensor([0.0000, 0.0000, 1.5608]), bound tensor([-0.4617,  0.5365, -0.0515])\n",
            "quantized tensor([0., 1., 0.])\n",
            "tensor([0., 1., 0.])\n"
          ]
        }
      ],
      "source": [
        "# @title test fsq\n",
        "fsq = FSQ(levels = [4])\n",
        "\n",
        "# 2: 1.6 half_l tensor([0.4995]), shift tensor([1.5608]), bound tensor([-0.5195])\n",
        "# 3: 0.6 # half_l tensor([0.9990]), shift tensor([0.]), bound tensor([-0.9207])\n",
        "# 4: 0.4, 1.3 # half_l tensor([1.4985]), shift tensor([0.3466]), bound tensor([-1.7726])\n",
        "# 5: 0.5, 1 # half_l [1.9980], shift [0.], bound [-1.8415]\n",
        "x = torch.tensor([.9],device=device)\n",
        "# x = torch.tensor([-1.6],device=device)\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.tensor([-0.6,0.6,-1.6],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,-1.5],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,1.6],device=device)\n",
        "x = torch.tensor([-0.5,0.6,-0.1],device=device)\n",
        "\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "round emb\n",
        "\n",
        "# half_l [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "# offset [0.0000, 0.0000, 0.5000] mean?\n",
        "# shift [0.0000, 0.0000, 1.5608] torch.tan(offset / half_l)\n",
        "# bound [-0.5365,  0.5365, -0.4696] tanh(z + shift) * half_l - offset\n",
        "\n",
        "\n",
        "\n",
        "levels = torch.tensor([3,3,2])\n",
        "eps = 1e-3\n",
        "\n",
        "half_l = (levels - 1) * (1 - eps) / 2\n",
        "offset = torch.where(levels % 2 == 1, 0.0, 0.5)\n",
        "# print(\"half_l\", half_l)\n",
        "shift = torch.tan(offset / half_l)\n",
        "# print(\"shift\", shift)\n",
        "# print(\"bound\", torch.tanh(x + shift) * half_l - offset)\n",
        "# return torch.tanh(x + shift) * half_l - offset\n",
        "out = torch.tanh(x) * half_l + offset\n",
        "print(out)\n",
        "\n",
        "shift=torch.tan(torch.tensor([1.]))\n",
        "print(shift)\n",
        "bound = torch.tanh(x - shift)\n",
        "print(bound)\n",
        "\n",
        "print(torch.tanh(torch.tensor([0.])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_VgsenYLpM",
        "outputId": "8c7b23ae-8cdb-4846-dae3-32fd046a4d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[0.0437, 0.3097, 0.4537]]], requires_grad=True)\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n"
          ]
        }
      ],
      "source": [
        "# @title test rnn_pred symlog\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "# fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # xx = fsq(x)\n",
        "    # xx = fsq(x.clone())\n",
        "    # print(xx)\n",
        "    # x = torch.tanh(x)\n",
        "    # loss = x.sum()\n",
        "    # loss = model(xx)\n",
        "    loss = model(x)\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    # x = torch.clamp(x, min=-1, max=1)\n",
        "    # x = torch.clamp(x.clone(), min=-1, max=1)\n",
        "    with torch.no_grad():\n",
        "        # x.clamp_(min=-1, max=1)\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # model = nn.Sequential(nn.Linear(3,1))\n",
        "# model = nn.Sequential(nn.Linear(3*2,1))\n",
        "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# batch_size = 1\n",
        "# seq_len = 3\n",
        "# x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# # torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "\n",
        "# def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "#     batch, seq_len, dim_a = la.shape\n",
        "#     cost = 0\n",
        "#     lsx=sx\n",
        "#     for t in range(seq_len): # simple single layer\n",
        "#         a = la[:,t] # [1, dim_a]\n",
        "#         sxaz = torch.cat([sx, a], dim=-1)\n",
        "#         # with torch.amp.autocast('cuda'):\n",
        "#         cost = cost + model(sxaz)\n",
        "#         lsx = torch.cat([lsx, sx], dim=0)\n",
        "#     return cost, sx\n",
        "\n",
        "\n",
        "# # def ste_clamp(input, min=-1, max=1):\n",
        "# #     clamped_output = torch.clamp(input, min, max)\n",
        "# #     clamp_mask = (input < min) | (input > max)\n",
        "# #     return torch.where(clamp_mask, input, clamped_output)\n",
        "\n",
        "# def ste_clamp(x, min=-1, max=1):\n",
        "#     return torch.clamp(x, min, max).detach() + x - x.detach()\n",
        "\n",
        "# def ste_abs(x): return x.sign() * x\n",
        "# def symlog(x): return torch.sign(x) * torch.log(ste_abs(x) + 1.0)\n",
        "# def symexp(x): return torch.sign(x) * torch.exp(ste_abs(x) - 1.0)\n",
        "\n",
        "\n",
        "# sx = torch.rand((batch_size,3),device=device)\n",
        "# sx_ = sx.detach()\n",
        "# for i in range(10): # num epochs\n",
        "#     # la = fsq(x.clone())\n",
        "#     la = fsq(x)\n",
        "#     print(i)\n",
        "#     print(x,x.requires_grad)\n",
        "#     print(la,la.requires_grad)\n",
        "#     loss, sx_ = rnn_pred(sx_, la)\n",
        "#     # loss.backward()\n",
        "#     loss.backward(retain_graph=True) # retain_graph bec fsq got tanh that creates new graph?\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     # x = torch.tanh(x)\n",
        "#     # x = torch.clamp(x, min=-1, max=1)\n",
        "#     # x = ste_clamp(x.clone(), min=-1, max=1)\n",
        "#     # x = symlog(x.clone())\n",
        "#     # sx_ = sx_.detach()\n",
        "\n",
        "\n",
        "# # print(xx)\n",
        "# print(x)\n",
        "# # print(xhat)\n",
        "# print(la)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YWmwVYhVVh5R"
      },
      "outputs": [],
      "source": [
        "# @title test ste_argmin\n",
        "import torch\n",
        "emb = torch.nn.Embedding(15, 3) # env.action_space # 15\n",
        "x = torch.rand(1,3)\n",
        "\n",
        "# def ste_argmin(x, dim=-1):\n",
        "#     idx = torch.argmin(x, dim)\n",
        "#     # out = torch.zeros_like(x)\n",
        "#     out = torch.zeros_like(idx).unsqueeze(-1)\n",
        "#     print(idx.shape, out.shape)\n",
        "#     out.scatter_(1, idx, 1)\n",
        "#     return out\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# def softargmin(x, beta=10):\n",
        "#     # Apply softmax to the negative of the input to approximate argmin\n",
        "#     weights = F.softmax(-x * beta, dim=-1)\n",
        "#     indices = torch.arange(x.size(-1), dtype=x.dtype, device=x.device)\n",
        "#     soft_argmin = torch.sum(weights * indices, dim=-1)\n",
        "#     return soft_argmin\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "# out = differentiable_argmax(-x)\n",
        "# print(out)\n",
        "\n",
        "\n",
        "# def softargmax1d(input, beta=100): # https://github.com/david-wb/softargmax/blob/master/softargmax.py\n",
        "#     *_, n = input.shape\n",
        "#     input = nn.functional.softmin(beta * input, dim=-1)\n",
        "#     indices = torch.linspace(0, 1, n)\n",
        "#     result = torch.sum((n - 1) * input * indices, dim=-1)\n",
        "#     return result\n",
        "\n",
        "# ste_round\n",
        "\n",
        "# # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "# dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "# print(lact)\n",
        "\n",
        "device='cpu'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "    dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    A=differentiable_argmax(-dist)\n",
        "    # print(A.shape)\n",
        "    print(torch.argmax(A))\n",
        "    x_=A@emb.weight.data\n",
        "    # print(\"dist\", dist.shape)\n",
        "    # lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = ste_argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = softargmin(dist)\n",
        "    # print(lact)\n",
        "    # x = emb.weight.data[lact]\n",
        "\n",
        "    # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "    print(\"x_\",x_)\n",
        "    # x = emb(x_)\n",
        "\n",
        "    loss = model(x_).sum()\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "x_ = torch.tensor([14])\n",
        "x = emb(x_)\n",
        "# print(x)\n",
        "# # print(emb.weight)\n",
        "# pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "pseudo_inverse_weight = torch.linalg.pinv(emb.weight)\n",
        "# weight_inv = torch.pinverse(emb.weight.T)\n",
        "\n",
        "dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "# print(x@pseudo_inverse_weight)\n",
        "# A=differentiable_argmax(-x@pseudo_inverse_weight)\n",
        "A=differentiable_argmax(-dist)\n",
        "print(A)\n",
        "\n",
        "# print(pseudo_inverse_weight.shape, pseudo_inverse_weight)\n",
        "# # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "# x_ = x@ pseudo_inverse_weight\n",
        "# print(\"x_\",x_)\n",
        "\n",
        "# print(emb.weight@ pseudo_inverse_weight)\n",
        "# dist=torch.dist(emb.weight@ pseudo_inverse_weight, torch.eye(15))\n",
        "# print(dist)\n",
        "# print(pseudo_inverse_weight@ emb.weight)\n",
        "\n",
        "# print(emb.weight@ weight_inv.T)\n",
        "# print(weight_inv.T@ emb.weight)\n",
        "\n",
        "# torch.linalg.lstsq(A, B).solution\n",
        "\n",
        "\n",
        "x_ = torch.tensor([4])\n",
        "embx = emb(x_) # emb.weight[x_,:]\n",
        "print(embx)\n",
        "\n",
        "Apinv = torch.linalg.pinv(A)\n",
        "x = embx@Apinv\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pGZld_gLH1RA"
      },
      "outputs": [],
      "source": [
        "# @title test bptt\n",
        "\n",
        "x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    loss=0\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        # loss = loss -stcost(xxx.clone()).sum()\n",
        "        loss = loss -stcost(xxx).sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "# RuntimeError: Output 1 of SplitBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size, T = 1,6\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "# optim = torch.optim.SGD([x], lr=1e-3)\n",
        "# # xx = torch.split(x, bptt, dim=1)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    loss=0\n",
        "    # xx = torch.split(x, bptt, dim=1)\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        loss = loss -stcost(xxx.clone()).sum()\n",
        "        # loss = loss -stcost(xxx).sum()\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jepapred = nn.Sequential(nn.Linear(3*2,3))\n",
        "stcost = nn.Sequential(nn.Linear(3,1))\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    for t in range(seq_len): # simple single layer\n",
        "        # print(la.shape)\n",
        "        a = la[:,t,:].clone() # [1, dim_a]\n",
        "        # sxaz = torch.cat([sx, a], dim=-1)\n",
        "        sxaz = torch.cat([sx.clone(), a.clone()], dim=-1)\n",
        "        # sxaz = torch.cat([sx.clone(), a], dim=-1)\n",
        "        sx = jepapred(sxaz)\n",
        "        tcost = -stcost(sx).sum()\n",
        "        lsx = torch.cat([lsx, sx], dim=0)\n",
        "        # print(lsx.requires_grad, sx.requires_grad)\n",
        "        # icost = 0.5*icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(icost.requires_grad)\n",
        "        cost += tcost# + icost\n",
        "    return cost, sx#, z\n",
        "\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "sx = torch.rand((batch_size,3),device=device)\n",
        "T = 6\n",
        "bptt = 3\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device)) # FSQ 3 levels\n",
        "x = torch.empty((batch_size, T, 3),device=device) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "# optim = torch.optim.SGD([x], lr=1e-3) #, maximize=True)\n",
        "# print(x.shape)\n",
        "# print(len(xx))\n",
        "# print(xx[0].shape)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    sx_ = sx.detach()\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "\n",
        "        # xxx=x\n",
        "        # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        la = fsq(xxx)\n",
        "        # la = xxx\n",
        "        # print(x,x.requires_grad)\n",
        "        # print(la,la.requires_grad)\n",
        "        # loss, sx_ = rnn_pred(sx_, la)\n",
        "        loss = -stcost(la).sum()\n",
        "\n",
        "        print(\"loss\",loss)\n",
        "        loss.backward()\n",
        "        # loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # sx_ = sx_.detach()\n",
        "        # print(loss.item(), lact)\n",
        "\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    x = torch.tanh(x) # clamp\n",
        "    print(x)\n",
        "    # print(x)\n",
        "print(\"search\",loss.item())\n",
        "# print(lact)\n",
        "# return la, lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # def search(self, sx, T=256, bptt=32):\n",
        "    # def search(self, sx, T=None, bptt=None):\n",
        "    #     if T==None: T = 256\n",
        "    #     if bptt==None: bptt = min(T,3)\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "    #     torch.nn.init.xavier_uniform_(x)\n",
        "    #     # optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "    #     # xx = torch.split(x, bptt, dim=1)\n",
        "    #     xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "    #     optim = torch.optim.SGD(xx, lr=1e7) #, maximize=True)\n",
        "\n",
        "    #     for _ in range(10): # num epochs\n",
        "    #         sx_ = sx.detach()\n",
        "    #         for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    #             # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "    #             la = fsq(xxx.clone())\n",
        "    #             # print(x,x.requires_grad)\n",
        "    #             # print(la,la.requires_grad)\n",
        "    #             loss, sx_ = self.rnn_pred(sx_, la)\n",
        "    #             loss.backward(retain_graph=True)\n",
        "    #             optim.step()\n",
        "    #             optim.zero_grad()\n",
        "    #             sx_ = sx_.detach()\n",
        "    #             # print(loss.item(), lact)\n",
        "    #             # xx = torch.tanh(xx) # clamp\n",
        "    #         xx = [torch.tanh(xxx) for xxx in xx]\n",
        "    #         x = torch.cat(xx,dim=1)\n",
        "    #         # x = torch.tanh(x) # clamp\n",
        "    #         print(x)\n",
        "    #     print(\"search\",loss.item())\n",
        "    #     # print(lact)\n",
        "    #     return la, lact # [batch_size, T]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jx0k_ndHOEMe"
      },
      "outputs": [],
      "source": [
        "# @title visualise kernels\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "# https://stackoverflow.com/questions/55594969/how-to-visualise-filters-in-a-cnn-with-pytorch\n",
        "\n",
        "layers = [0,3,6,9]\n",
        "layers = [0,3,6,9,12]\n",
        "layer = 9\n",
        "\n",
        "def visualise(model,layer):\n",
        "    kernels = model.cnn[layer].weight.data.clone()\n",
        "    n,c,w,h = kernels.shape\n",
        "    print(kernels.shape)\n",
        "    if c not in [1,3]:\n",
        "        # kernels = kernels.mean(dim=1, keepdim=True)\n",
        "        kernels = kernels[:,2,:,:].unsqueeze(dim=1)\n",
        "    nrow=10\n",
        "    rows = np.min((kernels.shape[0]//nrow + 1, 64))\n",
        "    grid = utils.make_grid(kernels, nrow=nrow, normalize=True, padding=1)\n",
        "    plt.figure(figsize=(nrow,rows))\n",
        "\n",
        "    kernels = kernels - kernels.min()\n",
        "    kernels = kernels / kernels.max()\n",
        "    filter_img = utils.make_grid(kernels, nrow = 12)\n",
        "    # change ordering since matplotlib requires images to\n",
        "    # be (H, W, C)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0))\n",
        "\n",
        "    # plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "# visualise(agent.sense,layer)\n",
        "visualise(agent.jepa.enc,layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "N2TGs69fnrZo",
        "outputId": "e7624553-e17a-4a9f-85a4-512720ed329a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tcost.1.weight torch.Size([2, 512])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRU(267, 256, batch_first=True, dropout=0.2)\n"
          ]
        }
      ],
      "source": [
        "# @title visualise lin\n",
        "# https://matplotlib.org/stable/plot_types/index.html\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for name, param in agent.jepa.pred.named_parameters(): # for param in model.parameters():\n",
        "# for name, param in agent.emb.named_parameters():\n",
        "for name, param in agent.tcost.named_parameters():\n",
        "    print(name, param.shape)\n",
        "    if len(param.shape)==1: param=param.unsqueeze(0)\n",
        "    Z=param.detach()#.numpy()\n",
        "\n",
        "    filter_img = utils.make_grid(Z, nrow = 12, normalize=True, padding=1)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0)) # (H, W, C)\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "    # pos=ax.imshow(Z)\n",
        "    # fig.colorbar(pos)\n",
        "    plt.show()\n",
        "\n",
        "print(agent.jepa.pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEWGq2WGi9a",
        "outputId": "649e3612-f156-496e-d8d5-fc576110e2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0015, -0.0132,  0.0280,  ...,  0.0297,  0.0289,  0.0152],\n",
            "        [ 0.0168,  0.0031, -0.0288,  ..., -0.0064, -0.0137, -0.0085]])\n"
          ]
        }
      ],
      "source": [
        "# print(vars(agent.jepa.pred.))\n",
        "# print(vars(agent.tcost.state_dict()))\n",
        "# print(agent.jepa.pred._parameters.keys())\n",
        "# print(agent.jepa.pred._parameters['weight_ih_l0'])\n",
        "# print(agent.jepa.pred._parameters['weight_hh_l2']) # weight_hh_l0, weight_hh_l2\n",
        "# print(agent.tcost.state_dict().keys())\n",
        "print(agent.tcost.state_dict()['tcost.1.weight']) # tcost.2.bias, tcost.4.bias\n",
        "# print(agent.tcost.named_parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90BTTw0Lr-t",
        "outputId": "a95870e2-bc89-43ba-d40b-febea4ce2382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 256])\n",
            "690080\n"
          ]
        }
      ],
      "source": [
        "# @title ConvEnc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ConvEnc(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[5], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[5], d_list[5], 2, 2, 0), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # 2457024\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # 685248\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 4, 2, 2), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 4, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 4, 2, 2), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 4, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # # #\n",
        "\n",
        "\n",
        "            nn.Conv2d(1, d_list[0], 4, 4, 0), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 4, 4, 0), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 4, 4, 0), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 4, 4, 0), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            #\n",
        "\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[5],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "\n",
        "convenc = ConvEnc(256).to(device)\n",
        "input = torch.rand((4,1,256,256), device=device)\n",
        "out = convenc(input)\n",
        "print(out.shape)\n",
        "print(sum(p.numel() for p in convenc.parameters() if p.requires_grad)) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S_xnBFjXVxgz"
      },
      "outputs": [],
      "source": [
        "# @title transfer weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "d = 10  # size of the first dimension\n",
        "a = 5   # size of the extra nodes to omit\n",
        "m = 8   # output dimension\n",
        "\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "target_layer = nn.Linear(d, m)\n",
        "# source_layer = nn.Linear(d, m)\n",
        "# target_layer = nn.Linear(d+a, m)\n",
        "\n",
        "def transfer(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt.weight[:, :src.weight.shape[1]].copy_(src.weight[:, :tgt.weight.shape[1]])\n",
        "        tgt.bias.copy_(src.bias)\n",
        "    return tgt,src\n",
        "\n",
        "target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "src_sd = source_layer.state_dict()\n",
        "tgt_sd = target_layer.state_dict()\n",
        "\n",
        "def transfersd(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt['weight'][:, :src['weight'].shape[1]].copy_(src['weight'][:, :tgt['weight'].shape[1]])\n",
        "        tgt['bias'].copy_(src['bias'])\n",
        "    return tgt\n",
        "\n",
        "tgt_sd = transfersd(tgt_sd, src_sd)\n",
        "target_layer.load_state_dict(tgt_sd)\n",
        "\n",
        "\n",
        "agent_src = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "\n",
        "# agent.tcost = TCost((1+agent.jepa.pred.num_layers)*agent.d_model) # replace tcost\n",
        "\n",
        "agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# agent.jepa.pred\n",
        "# target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(vars(agent.jepa.pred))\n",
        "# gru = agent.jepa.pred\n",
        "# gru = agent_src.jepa.pred\n",
        "# for wht_name in gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, gru._parameters[wht_name].shape)\n",
        "\n",
        "# weight_ih_l0 dim_z=3: [768, 262] , dim_z=1: [768, 260]\n",
        "# weight_hh_l0 torch.Size([768, 256])\n",
        "# bias_ih_l0 torch.Size([768])\n",
        "# bias_hh_l0 torch.Size([768])\n",
        "\n",
        "# tgt_gru = agent.jepa.pred\n",
        "# src_gru = agent_src.jepa.pred\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "\n",
        "tgt_gru[]\n",
        "def transfer_gru(tgt_gru, src_gru): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for i in range(min(len(tgt_gru._all_weights), len(src_gru._all_weights))):\n",
        "        # for lyr in tgt_gru._all_weights:\n",
        "            lyr = tgt_gru._all_weights[i]\n",
        "            for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "                # print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "                tgt_wht, src_wht = tgt_gru._parameters[wht_name], src_gru._parameters[wht_name]\n",
        "                if len(tgt_wht.shape)==2:\n",
        "                    tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "                elif len(tgt_wht.shape)==1:\n",
        "                    tgt_gru._parameters[wht_name] = src_wht\n",
        "    return tgt_gru\n",
        "tgt_gru = transfer_gru(tgt_gru, src_gru)\n",
        "\n",
        "# for wht_name in tgt_gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d_model=256; dim_a=3; dim_z=1; dim_v=512\n",
        "\n",
        "pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "# pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "print(pred._all_weights)\n",
        "for lyr in pred._all_weights:\n",
        "    for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "        print(wht_name, pred._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(pred.state_dict().keys())\n",
        "\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "print(tgt_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "print(src_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "\n",
        "print(tgt_gru.state_dict()['bias_ih_l0'][:10])\n",
        "print(src_gru.state_dict()['bias_ih_l0'][:10])\n",
        "tgt_gru.state_dict().keys()\n",
        "src_gru.state_dict().keys()\n",
        "\n",
        "# tgt_gru\n",
        "# src_gru\n",
        "for wht_name in tgt_gru.state_dict().keys():\n",
        "    if not wht_name in src_gru.state_dict().keys(): continue\n",
        "    print(wht_name)\n",
        "    # print(tgt_gru.state_dict()[wht_name])\n",
        "    # tgt_gru.state_dict()[wht_name].copy_(src_gru.state_dict()[wht_name])\n",
        "\n",
        "tgt_sd = tgt_gru.state_dict()\n",
        "src_sd = src_gru.state_dict()\n",
        "def transfer_sd(tgt_sd, src_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            # print(wht_name)\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            if len(tgt_wht.shape)==2:\n",
        "                tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "            elif len(tgt_wht.shape)==1:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "    return tgt_sd\n",
        "tgt_sd = transfer_sd(tgt_sd, src_sd)\n",
        "print(tgt_sd['weight_ih_l0'][0][:10])\n",
        "print(tgt_sd['bias_ih_l0'][:10])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwApoQMMKzB",
        "outputId": "98f67f91-ef5b-406f-b852-5a93130f9e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0012018680572509766\n",
            "tensor([0.2797, 0.2218, 0.2731, 0.3268, 0.2632, 0.2914, 0.3217, 0.2845])\n"
          ]
        }
      ],
      "source": [
        "# @title test init norm\n",
        "print(agent.emb.state_dict()['weight'].norm(dim=-1))\n",
        "\n",
        "# x = torch.rand(16)\n",
        "x = torch.rand(8,16)\n",
        "# print(x)\n",
        "# torch.nn.init.normal_(x, mean=0.0, std=1.0)\n",
        "# torch.nn.init.xavier_normal_(x)\n",
        "import time\n",
        "start = time.time()\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # 0.00966, 0.000602, 0.0004\n",
        "# torch.nn.init.normal_(x, mean=0.0, std=1./x.shape[-1]**0.5)\n",
        "torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "print(time.time()-start)\n",
        "# std = ((Sum (xi-mean)^2)/ N)^(1/2)\n",
        "# print(x)\n",
        "# print(((x**2).sum())**(0.5))\n",
        "print(torch.norm(x, dim=-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B1yvJkX89C_o"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein\n",
        "import torch\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    # cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    # dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # cs = (x-y).cumsum(dim=-1)\n",
        "    cs = (x-y) @ torch.tril(torch.ones(x.shape[0], x.shape[0]))\n",
        "    # dist = weight * torch.abs(cs)\n",
        "    dist = weight * cs**2\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "\n",
        "def soft_wasserstein_loss(x, y, smoothing=0.1):\n",
        "    # Normalise distributions\n",
        "    x = x / x.sum()\n",
        "    y = y / y.sum()\n",
        "    # Compute the cumulative distributions (CDFs) with a small smoothing factor\n",
        "    cdf_x = torch.cumsum(x, dim=-1) + smoothing\n",
        "    cdf_y = torch.cumsum(y, dim=-1) + smoothing\n",
        "    # Compute smooth Wasserstein distance (L2 distance between CDFs)\n",
        "    distance = torch.norm(cdf_x - cdf_y, p=2)  # L2 distance instead of L1 for smoother gradients\n",
        "    return distance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5], dtype=float))\n",
        "x = nn.Parameter(torch.tensor([-0.01, -0.0, -0.99], dtype=torch.float))\n",
        "y = torch.tensor([0.0, 0.0, -1.0], dtype=torch.float)\n",
        "\n",
        "# x = nn.Parameter(torch.rand(1024, dtype=float))\n",
        "# y = torch.rand(1024, dtype=float)\n",
        "# a = len(train_data.buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "a=1/45\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "print(weight)\n",
        "dist = wasserstein(x, y, weight=weight)\n",
        "print(time.time() - start)\n",
        "print(dist)  # Should output 0.7\n",
        "# dist.backward()\n",
        "\n",
        "# 0.0004496574401855469\n",
        "# 0.000331878662109375\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3nfZRhVc9Ssp"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein sinkhorn train\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# agent.eval()\n",
        "# batch_size, T, _ = sx.shape\n",
        "x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3) # 3e3\n",
        "# optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.999)) # ? 1e0 ; 3e-2 1e-1\n",
        "# optim = torch.optim.AdamW([x], 1e-0, (0.9, 0.95)) # ? 1e0 ; 3e-2 1e-1\n",
        "y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=torch.float)\n",
        "a=1/45\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "# print(weight)\n",
        "\n",
        "# loss = wasserstein(x, y, weight=weight)\n",
        "# loss = wasserstein(x, y)\n",
        "# loss = sinkhorn(x, y)\n",
        "# loss.backward()\n",
        "# print(x.grad)\n",
        "\n",
        "\n",
        "for i in range(50): # num epochs\n",
        "    loss = wasserstein(x, y, weight=weight)\n",
        "    # loss = sinkhorn(x, y)\n",
        "    # loss = sinkhorn(x, y,0.05,80)\n",
        "    loss.sum().backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(x.data, loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "def sinkhorn(x, y, epsilon=0.05, max_iters=100):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "\n",
        "    # Compute the cost matrix: here the cost is the squared distance between indices\n",
        "    # (|i-j|^2 for each position i, j)\n",
        "    posx = torch.arange(x.shape[-1], dtype=torch.float).unsqueeze(1)\n",
        "    posy = torch.arange(y.shape[-1], dtype=torch.float).unsqueeze(0)\n",
        "    cost_matrix = (posx - posy).pow(2)  # squared distance\n",
        "\n",
        "    # Initialize the dual variables\n",
        "    u = torch.zeros_like(x)\n",
        "    v = torch.zeros_like(y)\n",
        "\n",
        "    # Sinkhorn iterations\n",
        "    K = torch.exp(-cost_matrix / epsilon)  # Kernel matrix, regularised with epsilon\n",
        "    for _ in range(max_iters):\n",
        "        u = x / (K @ (y / (K.t() @ u + 1e-8)) + 1e-8)\n",
        "        v = y / (K.t() @ (x / (K @ v + 1e-8)) + 1e-8)\n",
        "    # print(K,u.data,v.data)\n",
        "    plan = torch.diag(u) @ K @ torch.diag(v)\n",
        "    dist = torch.sum(plan * cost_matrix)\n",
        "    return dist\n",
        "\n",
        "# Example\n",
        "x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float, requires_grad=True)\n",
        "y = torch.tensor([0.0, 0.0, 1.0], dtype=torch.float)\n",
        "# x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "# y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=float)\n",
        "\n",
        "# dist = sinkhorn(x, y)\n",
        "dist = sinkhorn(x, y, 0.05,80)\n",
        "dist.backward()  # To compute gradients with respect to x\n",
        "\n",
        "print(dist.item())\n",
        "print(x.grad)\n",
        "\n",
        "# [2.0000e+07, 3.0000e+07, 1.0000e-08]) tensor([       0.,        0., 49999996.] episodes>=80\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s1_GgDzoDyYB"
      },
      "outputs": [],
      "source": [
        "# @title torchrl.data.PrioritizedReplayBuffer\n",
        "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
        "buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
        "\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "buffer_lazymemmap = ReplayBuffer(storage=LazyMemmapStorage(size), batch_size=32, sampler=SamplerWithoutReplacement())\n",
        "\n",
        "\n",
        "from torchrl.data import ListStorage, PrioritizedReplayBuffer\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "rb = PrioritizedReplayBuffer(alpha=0.7, beta=0.9, storage=ListStorage(10))\n",
        "data = range(10)\n",
        "rb.extend(data)\n",
        "# rb.extend(buffer)\n",
        "\n",
        "\n",
        "sample = rb.sample(3)\n",
        "print(sample)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_UlGz6Xoq3"
      },
      "source": [
        "## plot 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VX5IExbRriwm"
      },
      "outputs": [],
      "source": [
        "# @title sklearn RBF\n",
        "# https://gist.github.com/eljost/2c4e1af652ef02b2989da341c5569af7\n",
        "# from nn_plot.ipynb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import scipy.stats as st\n",
        "\n",
        "# np.random.seed(1)\n",
        "def func(x):\n",
        "    # print(x.shape)\n",
        "    # x= np.sum(x**2, axis=-1)\n",
        "    x=np.random.rand(x.shape[0])\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "res = 50\n",
        "num_pts=15\n",
        "X=np.random.rand(num_pts,2)*res\n",
        "# Y = func(X)\n",
        "Y=np.random.rand(num_pts)\n",
        "# print(X);print(Y)\n",
        "\n",
        "lim = 1\n",
        "# lin = np.linspace(-lim, lim, res)\n",
        "lin = np.linspace(0, res, res)\n",
        "x1, x2 = np.meshgrid(lin, lin)\n",
        "xx = np.vstack((x1.flatten(), x2.flatten())).T\n",
        "\n",
        "kernel = RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X, Y)\n",
        "# print(\"Learned kernel\", gp.kernel_)\n",
        "y_mean, y_cov = gp.predict(xx, return_cov=True)\n",
        "\n",
        "posteriors = st.multivariate_normal.rvs(mean=y_mean, cov=y_cov, size=1)\n",
        "\n",
        "ax = plt.figure().add_subplot(projection='3d')\n",
        "Z=posteriors.reshape(-1, res)\n",
        "# ax.plot_surface(x1, x2, Z)\n",
        "ax.plot_surface(x1, x2, Z, cmap='rainbow', alpha=0.7)\n",
        "\n",
        "# ax.plot_surface(x1, x2, posteriors.reshape(-1, res))\n",
        "ax.contour(x1, x2, Z, zdir='z', offset=-1, cmap='coolwarm') # https://matplotlib.org/stable/gallery/mplot3d/contour3d_3.html#sphx-glr-gallery-mplot3d-contour3d-3-py\n",
        "# ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-0.4, 0.5))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-1, 2))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, c=zdata, cmap='Greens');\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, cmap='Greens');\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusX7gpzxFNL",
        "outputId": "9f14a9da-e188-49ba-f5f5-70192ff33134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.6321], grad_fn=<AddBackward0>)\n",
            "tensor([2.7358]) tensor([-4.7358])\n"
          ]
        }
      ],
      "source": [
        "# @title chatgpt RBFKernelLayer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RBFKernelLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(RBFKernelLayer, self).__init__()\n",
        "        self.centres = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        dists = torch.cdist(x, self.centres, p=2) ** 2\n",
        "        return torch.exp(-dists / (2 * self.sigma ** 2))\n",
        "\n",
        "class SaddlePointNetwork(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(SaddlePointNetwork, self).__init__()\n",
        "        self.rbf_layer = RBFKernelLayer(in_features, out_features, sigma)\n",
        "        self.linear = nn.Linear(out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rbf_output = self.rbf_layer(x)\n",
        "        # Introduce a saddle point structure\n",
        "        linear_output = self.linear(rbf_output)\n",
        "        # Example saddle function: x^2 - y^2\n",
        "        saddle_output = torch.sum(linear_output[:, :1]**2 - linear_output[:, 1:]**2, dim=1, keepdim=True)\n",
        "        return saddle_output\n",
        "\n",
        "# sin(ax)sin(bx)\n",
        "# (x^2 - y^2)\n",
        "import torch\n",
        "\n",
        "def rbf_saddle(x, y, gamma=1.0, a=1.0, b=1.0):\n",
        "    # RBF-like term\n",
        "    rbf_term = torch.exp(-gamma * torch.norm(x - y, p=2)**2)\n",
        "    # Saddle point term\n",
        "    saddle_term = (a * x)**2 - (b * y)**2\n",
        "    return rbf_term + saddle_term\n",
        "\n",
        "# Example usage\n",
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "output = rbf_saddle(x, y)\n",
        "print(output)\n",
        "\n",
        "# Compute gradients\n",
        "output.backward()\n",
        "print(x.grad, y.grad)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rTmCo7pm0NxL"
      },
      "outputs": [],
      "source": [
        "# @title plot 3d\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "y = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "X, Y = torch.meshgrid(x, y)\n",
        "Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7fWZaQTDFg1",
        "outputId": "4c5ced88-54f1-436e-89f9-66f1c8396373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000, -0.7231,  0.3792,  0.0000]]) tensor([0.3362])\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# @title shape NN\n",
        "num_pts=1\n",
        "\n",
        "# X=torch.rand(num_pts,4)*2-1\n",
        "# X=torch.cat([torch.tensor([0,0]).unsqueeze(0),torch.rand(num_pts,2)*2-1], dim=-1)\n",
        "X=torch.cat([torch.zeros(1,1),torch.rand(num_pts,2)*2-1,torch.zeros(1,1)], dim=-1)\n",
        "Y=torch.rand(num_pts)\n",
        "print(X,Y)\n",
        "optim = torch.optim.SGD(model.parameters(), 1e-1)\n",
        "\n",
        "# model.train()\n",
        "pred = model(X)\n",
        "# print(Y.shape,pred.shape)\n",
        "# loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "loss = F.mse_loss(Y, pred.squeeze(-1))\n",
        "loss.backward()\n",
        "optim.step()\n",
        "optim.zero_grad()\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "boDd__PE2sGy"
      },
      "outputs": [],
      "source": [
        "# @title plot NN\n",
        "\n",
        "xx = torch.linspace(-1, 1, 100)\n",
        "yy = torch.linspace(-1, 1, 100)\n",
        "X, Y = torch.meshgrid(xx, yy) # [100,100]\n",
        "xy = torch.cat([X.unsqueeze(-1), torch.zeros(X.shape+(2,)), Y.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "with torch.no_grad(): Z = model(xy).squeeze(-1)\n",
        "# print(Z)\n",
        "# print(Z.shape)\n",
        "\n",
        "# Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qW6BYoXsX57o"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle same time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def f(x, y):\n",
        "    return x ** 2 - y ** 2 + x * y\n",
        "# (x-y)(x+y)+xy\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "dim_x, dim_z = 3, 8\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "xx = torch.empty((1, T, dim_x))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "# x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "\n",
        "# tensor([[0.6478, 0.0531, 0.0861]]) tensor([[-1.,  1.]]) 0.2974517047405243\n",
        "# tensor([-0.9419, -1.0000,  0.4416, -1.0000,  1.0000,  0.2963])\n",
        "\n",
        "# x = nn.Parameter(torch.tensor([[0.6478, 0.0531, 0.0861]]))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "z = nn.Parameter(torch.empty((batch, T, dim_z)))\n",
        "# z = torch.empty((1, T, 1))\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# z = nn.Parameter(z.repeat(batch,1,1))\n",
        "# z = nn.Parameter(torch.tensor([[-1.,  1.]]))\n",
        "# optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "# optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.95), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "# .95,1e-1,3e-1\n",
        "# .99,\n",
        "\n",
        "d_model = 4\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(10): # num epochs\n",
        "    # loss = f(x,z)\n",
        "    # loss = f(x.sum(-1),z)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step(); optim_z.step()\n",
        "    optim_x.zero_grad(); optim_z.zero_grad()\n",
        "    # print(i,x.squeeze(), z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    print(i,x.squeeze()[0].data, z[0].squeeze().data, loss[0].squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "        z.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "print(loss.squeeze())\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "# idx = torch.argmax(loss)\n",
        "# print(x[idx],z[idx],loss[idx])\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GJdFpDr2wIMT"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle argm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def argm(sx, lr=3e3): # 3e3\n",
        "    # batch=sx.size(dim=0)\n",
        "    batch_size, T, _ = sx.shape\n",
        "    batch = 16\n",
        "    # z = nn.Parameter(torch.zeros((batch,1),device=device))\n",
        "    # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "    z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "    torch.nn.init.xavier_uniform_(z)\n",
        "    # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "    # sx = sx.detach()\n",
        "    for i in range(20): # 10\n",
        "        # print(sx.shape,z.shape)\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            cost = model(sxz)\n",
        "        cost.sum().backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "        # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    # return z.detach()\n",
        "    print(cost.squeeze().data)\n",
        "    idx = torch.argmax(cost.squeeze(), dim=1)\n",
        "    return z[torch.arange(z.shape[0]),idx].detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# x = nn.Parameter(xx.clone())\n",
        "x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "# ratio = 6e0\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(50):\n",
        "    z = argm(x)\n",
        "    # print(x.shape,z.shape)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "# print(\"z\",z)\n",
        "# print(loss.squeeze())\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvjIJP6RlEv2",
        "outputId": "447fdefd-452b-437d-c228-1847492b36f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.randn(16, 16)\n",
        "# print((b==torch.max(b)).nonzero())\n",
        "x = torch.randn(10, 3)\n",
        "idx = torch.randint(3,(10,))\n",
        "# print(x[:,idx].shape)\n",
        "print(x[torch.arange(x.shape[0]),idx].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gJ3X_hQelW2x"
      },
      "outputs": [],
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wi4ODp-XlZoU"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QYbOgNoZn6JL"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_kcajtpjr7Io"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "outputs": [],
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "    def get_down(self, state, world_state=None): # update world_state and mem from state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        return world_state\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    world_state = self.get_down(state, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "                    sy = self.effnet(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "\n",
        "                    world_state_ = self.deconvenc(sy).squeeze(1) # ae\n",
        "                    # loss = F.mse_loss(world_state_, world_state)\n",
        "                    loss = F.mse_loss(world_state_, world_state.detach())\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cX71EprCMSNG"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim bad?\n",
        "\n",
        "import torch\n",
        "\n",
        "def transfer_optim(src_optim, tgt_optim, param_mapping):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    tgt_sd = tgt_optim.state_dict()\n",
        "\n",
        "    # Iterate over each parameter in the target optimizer\n",
        "    for (tgt_idx, target_param) in enumerate(tgt_optim.param_groups[0]['params']):\n",
        "        target_id = id(target_param)\n",
        "\n",
        "        # Find the corresponding source parameter using param_mapping\n",
        "        if target_id in param_mapping:\n",
        "            source_param = param_mapping[target_id]\n",
        "            source_id = id(source_param)\n",
        "\n",
        "            # If there's an existing state for the source parameter, transfer it\n",
        "            if source_id in src_sd['state']:\n",
        "                source_state = src_sd['state'][source_id]\n",
        "                target_state = {}\n",
        "\n",
        "                # Handle momentum/first and second moments (e.g., `exp_avg`, `exp_avg_sq` in Adam)\n",
        "                for key in source_state.keys():\n",
        "                    if source_state[key].shape == target_param.shape: target_state[key] = source_state[key].clone()\n",
        "                    # If size doesn't match, either copy what you can or initialise new values\n",
        "                    elif key in ['exp_avg', 'exp_avg_sq']:  # Momentums (specific to Adam-like optimizers)\n",
        "                        target_state[key] = torch.zeros_like(target_param)\n",
        "                        target_state[key][:source_param.numel()] = source_state[key].flatten()[:target_param.numel()]\n",
        "                    else: target_state[key] = torch.zeros_like(target_param) # init\n",
        "                tgt_sd['state'][target_id] = target_state\n",
        "\n",
        "    # Load the updated state dict back into the target optimizer\n",
        "    tgt_optim.load_state_dict(tgt_sd)\n",
        "    return tgt_optim\n",
        "# {'state': {0: {'step': tensor(1.), 'exp_avg': tensor, 'exp_avg_sq': tensor}, 1: }}\n",
        "\n",
        "\n",
        "\n",
        "model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "source_optimizer = optim.AdamW(model_src.parameters())\n",
        "target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "dummy_input = torch.randn(3, 10)\n",
        "dummy_target = torch.randn(3, 5)\n",
        "criterion = torch.nn.MSELoss()\n",
        "output = model_src(dummy_input)\n",
        "loss = criterion(output, dummy_target)\n",
        "loss.backward()\n",
        "source_optimizer.step()\n",
        "\n",
        "param_mapping = {id(tgt_param): src_param for src_param, tgt_param in zip(model_src.parameters(), model_tgt.parameters())}\n",
        "target_optimizer = transfer_optim(source_optimizer, target_optimizer, param_mapping)\n",
        "\n",
        "print(source_optimizer.state_dict())\n",
        "print(target_optimizer.state_dict())\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "\n",
        "# optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title transfer_optim bad? 2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    opt_state_dict = optimizer.state_dict()\n",
        "    for group in opt_state_dict['param_groups']:\n",
        "        # For each parameter index (p in param group refers to the layer parameters)\n",
        "        for param_idx, p in enumerate(group['params']):\n",
        "            print(p,source_layer.weight)\n",
        "            if p == source_layer.weight:\n",
        "                # Find the corresponding target layer parameter (in this case, target_layer.weight)\n",
        "                target_param = target_layer.weight\n",
        "                source_state = optimizer.state[p]  # Get the state for the source parameter\n",
        "\n",
        "                # If the parameter is found in the optimizer's state dict\n",
        "                if 'exp_avg' in source_state and 'exp_avg_sq' in source_state:\n",
        "                    exp_avg = source_state['exp_avg']  # First moment (momentum)\n",
        "                    exp_avg_sq = source_state['exp_avg_sq']  # Second moment (variance)\n",
        "\n",
        "                    # Handle input dimension mismatch (copy/truncate or pad)\n",
        "                    source_in_dim = source_layer.weight.shape[1]\n",
        "                    target_in_dim = target_layer.weight.shape[1]\n",
        "\n",
        "                    # Copy optimizer state (exp_avg and exp_avg_sq) accordingly\n",
        "                    with torch.no_grad():\n",
        "                        # Copy the available part and initialize new dimensions to zero\n",
        "                        new_exp_avg = torch.zeros_like(target_param)\n",
        "                        new_exp_avg_sq = torch.zeros_like(target_param)\n",
        "                        # new_exp_avg[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        # new_exp_avg_sq[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        new_exp_avg[:, :source_in_dim] = exp_avg[:, :target_in_dim]\n",
        "                        new_exp_avg_sq[:, :source_in_dim] = exp_avg_sq[:, :target_in_dim]\n",
        "\n",
        "                    # Update the target layer's optimizer state\n",
        "                    optimizer.state[target_param] = {\n",
        "                        'exp_avg': new_exp_avg,\n",
        "                        'exp_avg_sq': new_exp_avg_sq,\n",
        "                        'step': source_state['step']  # Keep the same step count\n",
        "                    }\n",
        "\n",
        "                # Handle the bias (if it exists)\n",
        "                if hasattr(source_layer, 'bias') and hasattr(target_layer, 'bias'):\n",
        "                    source_bias = optimizer.state[source_layer.bias]\n",
        "                    target_bias = target_layer.bias\n",
        "\n",
        "                    optimizer.state[target_bias] = source_bias\n",
        "    return optimizer\n",
        "\n",
        "# Example usage:\n",
        "d = 10  # Input dimension of the source layer\n",
        "a = 5   # Extra nodes to be omitted or added in the target layer\n",
        "m = 8   # Output dimension (same for both)\n",
        "\n",
        "# Source layer (input dimension d+a)\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "\n",
        "# Target layer (input dimension d, or d+a, or arbitrary)\n",
        "target_layer = nn.Linear(d, m)\n",
        "\n",
        "# Optimizer (using AdamW in this case)\n",
        "optimizer = torch.optim.AdamW(source_layer.parameters())\n",
        "\n",
        "# Perform weight transfer (from d+a to d or vice versa) here (assumed done already)\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "# Transfer optimizer states\n",
        "optimizer = transfer_optimizer_state(source_layer, target_layer, optimizer)\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    state_dict = optimizer.state_dict()\n",
        "    for old_param, new_param in zip(source_layer.parameters(), target_layer.parameters()):\n",
        "        # If old_param exists in optimizer state\n",
        "        if old_param in state_dict['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = state_dict['state'][old_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                if key in ['exp_avg', 'exp_avg_sq']:  # for Adam or AdamW momentum estimates\n",
        "                    # Handle the shape adjustment (copy, shrink, or randomly initialise the extra nodes)\n",
        "                    new_state[key] = torch.zeros_like(new_param)  # Initialise with zeros\n",
        "                    new_state[key][:old_param.shape[0]] = value[:new_param.shape[0]]  # Copy old values\n",
        "                    # else:\n",
        "                    #     new_state[key] = value.clone()  # Copy directly if shapes match\n",
        "                else:\n",
        "                    new_state[key] = value  # Copy other states directly if they exist\n",
        "\n",
        "            # Set the new parameter in optimizer state\n",
        "            state_dict['state'][new_param] = new_state\n",
        "            # Remove the old parameter from the optimizer state\n",
        "            del state_dict['state'][old_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(state_dict)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optim(src_model, tgt_model, src_optim, tgt_optim):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    for src_param, tgt_param in zip(src_model.parameters(), tgt_model.parameters()):\n",
        "        # If src_param exists in optimizer state\n",
        "        if src_param in src_sd['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = src_sd['state'][src_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                new_state[key] = torch.zeros_like(tgt_param)  # Initialise with zeros\n",
        "                new_state[key][:src_param.shape[0]] = value[:tgt_param.shape[0]]  # Copy old values\n",
        "\n",
        "            src_sd['state'][tgt_param] = new_state\n",
        "            del src_sd['state'][src_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(src_sd)\n",
        "    return optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "LKUSzmYLLuRh",
        "outputId": "07ca4b89-257b-4205-c5c8-6a96474ae82a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-186620617543>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# j=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mwht_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwht_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title rename wht_name\n",
        "# wht_name='jepa.enc.cnn.0.weight'\n",
        "wht_name='jepa.pred.weight_ih_l0'\n",
        "# wht_name='emb.weight'\n",
        "# print(o.isnumeric())\n",
        "# mask = [x.isnumeric() for x in o]\n",
        "# print(o[mask])\n",
        "na_=''\n",
        "# j=0\n",
        "\n",
        "for wht_name in agent.state_dict().keys():\n",
        "    o=wht_name.split('.')\n",
        "    # print(o)\n",
        "    name=wht_name\n",
        "    print(\"####\", wht_name)\n",
        "    for i in range(len(o)):\n",
        "        c = o[i]\n",
        "        if c.isnumeric():\n",
        "            na = '.'.join(o[:i])\n",
        "            me = '.'.join(o[i+1:])\n",
        "            # print(c_,c, c_<c, )\n",
        "            c=int(c)\n",
        "            if na!=na_: # param name diff\n",
        "                j=0 # reset num\n",
        "                c_=c # track wht_name num\n",
        "                na_=na # track param name\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('1', name)\n",
        "            elif c_<c: # same param name, diff num\n",
        "                j+=1\n",
        "                c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('2', name)\n",
        "            else: # same param name, same num\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('3', name)\n",
        "    print('4', name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CACQCCaxA_Y",
        "outputId": "b5d127cd-18ce-49e5-b1e2-d883cb34125a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1746836772511624\n"
          ]
        }
      ],
      "source": [
        "# @title geomloss, Python Optimal Transport\n",
        "# !pip install geomloss[full]\n",
        "\n",
        "import torch\n",
        "from geomloss import SamplesLoss  # See also ImagesLoss, VolumesLoss\n",
        "\n",
        "# # Create some large point clouds in 3D\n",
        "# x = torch.randn(100000, 3, requires_grad=True).cuda()\n",
        "# y = torch.randn(200000, 3).cuda()\n",
        "\n",
        "# x = torch.rand(1000, 1)\n",
        "# y = torch.rand(1000, 1)\n",
        "x = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "y = torch.tensor([0, 1, 0]).float().unsqueeze(-1)\n",
        "# k=1.\n",
        "# y = torch.tensor([k, k, k]).float().unsqueeze(-1)\n",
        "\n",
        "\n",
        "\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01) # 0.05, quadratic, Wasserstein-2. low blur => closer to true Wasserstein dist but slower compute\n",
        "\n",
        "loss = loss_fn(x, y)  # By default, use constant weights = 1/number of samples\n",
        "print(loss)\n",
        "# g_x, = torch.autograd.grad(L, [x])\n",
        "\n",
        "# [0, 1, 0]: 2.4253e-12, 2.4253e-12\n",
        "# [0, 0, 0.1]: 0.1350; [0, 0, 0.5]: 0.0417; [0, 0, 1]: 0\n",
        "# k=0.: 0.1666; k=0.1: 0.1383; k=0.333: 0.1111; k=0.5: 0.1250; k=1.: 0.3333\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from geomloss import SamplesLoss\n",
        "\n",
        "# Define x and y as n-dimensional tensors representing mass distributions\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# y = torch.tensor([0, 0, 1], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# x = torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1))\n",
        "x = nn.Parameter(torch.tensor([0,1.5,0]).float().unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "\n",
        "# Create a position tensor representing the index of each element\n",
        "positions_x = torch.arange(x.shape[0], dtype=float).unsqueeze(1)\n",
        "positions_y = torch.arange(y.shape[0], dtype=float).unsqueeze(1)\n",
        "\n",
        "# Sinkhorn loss using GeomLoss\n",
        "loss_fn = SamplesLoss(\"sinkhorn\", p=1, blur=0.05)  # p=1 for Wasserstein-1\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=1, blur=0.05, scaling=0.9, debias=True)\n",
        "\n",
        "transport_cost = loss_fn(positions_x, x, positions_y, y)\n",
        "\n",
        "print(transport_cost.item())\n",
        "# 1.298424361328248\n",
        "\n",
        "transport_cost.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pip install POT\n",
        "\n",
        "import ot\n",
        "import numpy as np\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / np.sum(x)\n",
        "    # y = y / np.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = np.abs(np.arange(n)[:, None] - np.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = np.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "x = np.array([0.2, 0.3, 0.5])\n",
        "y = np.array([0, 0, 1])\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "# distance.backward()\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / torch.sum(x)\n",
        "    # y = y / torch.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = torch.abs(torch.arange(n)[:, None] - torch.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = torch.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "# x = np.array([0.2, 0.3, 0.5])\n",
        "# y = np.array([0, 0, 1])\n",
        "x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float())#.unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float()#.unsqueeze(-1)\n",
        "\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "distance.backward()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MqBL9hljvW-5"
      },
      "outputs": [],
      "source": [
        "# @title batchify argm train\n",
        "\n",
        "def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "    self.jepa.pred.train()\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "    lsx=sx.unsqueeze(1)\n",
        "    h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "    lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "    # print(lsx.shape, la.shape, lz.shape)\n",
        "    c=[]\n",
        "    for t in range(seq_len):\n",
        "        a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "        # print(sx.shape, a.shape, z.shape)\n",
        "        sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "            syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            tcost = -self.tcost(syh0)\n",
        "        c.append(tcost)\n",
        "        lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "        lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        cost += (tcost + icost)*gamma**t\n",
        "    return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "\n",
        "def argm(self, sy, sy_, h0, a, reward, lr=3e3): # 3e3\n",
        "    self.tcost.eval()\n",
        "    batch_size = sy.shape[0] # [batch_size, d_model]\n",
        "    z = nn.Parameter(torch.zeros((batch_size, self.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(z)\n",
        "    torch.nn.init.normal_(z, mean=0., std=.3/z.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([z], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    sy, sy_ = sy.detach(), sy_.detach()\n",
        "    out = sy - sy_\n",
        "    h0, a, reward = h0.detach(), a.detach(), reward.detach()\n",
        "    for i in range(10): # 10\n",
        "        with torch.amp.autocast('cuda'):\n",
        "\n",
        "\n",
        "\n",
        "            syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "            out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            repr_loss = F.mse_loss(out, out_[:, -1, :])\n",
        "            # syh0 = torch.cat([sy.flatten(1),F.dropout(h0_, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            syh0 = torch.cat([sy.flatten(1),h0_.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "            z_loss = torch.abs(z).sum() # z_loss = torch.norm(z)\n",
        "            print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def argm(lsy, sy, h0, la, rwd):\n",
        "    # lz = agent.argm(out, h0, la, reward)\n",
        "    agent.tcost.eval()\n",
        "    batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "    lz = nn.Parameter(torch.zeros((batch_size, bptt, agent.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(lz)\n",
        "    torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "    for i in range(3): # 10\n",
        "        sy_, h0_ = sy.detach(), h0.detach()\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "        with torch.cuda.amp.autocast():\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0_ = agent.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl + agent.zloss_coeff * z_loss\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    agent.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return lz.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# closs_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01)\n",
        "bptt = 25\n",
        "for batch, Sar in enumerate(train_loader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "    state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "    sy_ = agent.jepa.enc(state).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    # sx=sy_\n",
        "    state, action, reward = Sar # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "    state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "    for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "\n",
        "        with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "            lsy = agent.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "            la = agent.emb(act) # [batch_size, bptt, dim_a]\n",
        "            out = lsy - torch.cat([sy_, lsy[:,:-1]], dim=1)\n",
        "            # lz = agent.argm(out, h0, la, reward)\n",
        "            lz = argm(lsy, sy_, h0, la, rwd)\n",
        "            # lz = torch.zeros((batch_size, bptt, agent.dim_z), device=device)\n",
        "\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0 = agent.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0.unsqueeze(0)), dim=0)\n",
        "\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            std_loss, cov_loss = agent.jepa.v_creg(agent.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "            jloss = agent.jepa.sim_coeff * repr_loss + agent.jepa.std_coeff * std_loss + agent.jepa.cov_coeff * cov_loss\n",
        "\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # print(\"syh0, rwd\",syh0.shape,rwd.shape)\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            # reward_ = agent.tcost(syh0)\n",
        "            # clossl = wasserstein(rwd, reward_)#.squeeze(-1)\n",
        "            closs = agent.closs_coeff * clossl\n",
        "\n",
        "            # print(h0.requires_grad)\n",
        "            # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "            # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "            # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "            # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "            # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "            loss = jloss + closs\n",
        "\n",
        "            # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "            norm = torch.norm(lsy, dim=-1)[0][0].item()\n",
        "            z_norm = torch.norm(z)\n",
        "            # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "            # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "            print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "            scaler.scale(loss).backward()\n",
        "            # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "            optim.zero_grad()\n",
        "            sy_, h0 = sy_.detach(), h0.detach()\n",
        "    break\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Jt_UlGz6Xoq3",
        "wUhKd009Qvk3"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}