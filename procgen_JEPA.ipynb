{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "2aa3f870-eea2-41fe-97ec-466460736d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.7/267.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq procgen faiss-cpu vector-quantize-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(1,3,64,64)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "import faiss\n",
        "import torch\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        # bore = (linsx@lsx[-1].T).sum()/self.n #\n",
        "        # bore = -((linsx*self.linmul)@lsx.T).sum() # [-1,1]\n",
        "        # print(linsx.shape, lsx.shape, bore.shape)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "39158215-0997-4a66-875f-a34b1a1cf93b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "\n",
        "ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "cellView": "form",
        "id": "FuA25qQknUAX"
      },
      "outputs": [],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = nn.Sequential(nn.Linear(in_dim, d_model),)\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            )\n",
        "        # self.pred = gru(emb_dim, rnn_units, num_layers)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(True),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(True),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(True),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25.0 # 25.0 # λ\n",
        "        self.std_coeff=1.0 # 25.0 # µ\n",
        "        self.cov_coeff=25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy):\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.rand((batch,self.dim_z),device=device)*2 -1)#*self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "        optim = torch.optim.SGD([z], lr=1e2)\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        num_steps = 10\n",
        "        for i in range(num_steps):\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            sy_ = self.pred(sxaz)\n",
        "            # print(\"y_, y\",y_.shape, y.shape)\n",
        "            loss = lossfn(sy_, sy)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "        if loss.item()>0.1: print(\"argm\",loss.item(), z[0].item())\n",
        "        return z#.detach()\n",
        "\n",
        "    def loss(self, x, y, a, z=None):\n",
        "        sx, sy = self.enc(x), self.enc(y)\n",
        "        z = self.argm(sx, a, sy)\n",
        "        sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "        sy_ = self.pred(sxaz)\n",
        "        repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "        # v_c_loss = self.v_creg(self.exp(sx))\n",
        "        vx, vy = self.exp(sx), self.exp(sy)\n",
        "        v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "        return repr_loss + v_c_loss\n",
        "\n",
        "    def forward(self, sx, a): # state, ctrl\n",
        "        batch=sx.size(dim=0)\n",
        "        z=torch.zeros((batch,self.dim_z),device=device)\n",
        "        sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "        sy_ = self.pred(sxaz)\n",
        "        return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "cellView": "form",
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=20)\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e2)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(10): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None): # state, ctrl\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t]\n",
        "            # cost += self.tcost(sx) + self.icost(sx)\n",
        "            # cost += self.tcost(sx) + self.icost.boredom(lsx, linsx=None)\n",
        "            icost=self.icost.boredom(lsx, linsx=None)\n",
        "            tcost=self.tcost(sx)\n",
        "            cost += tcost + icost\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            sx = self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            sx = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "\n",
        "            lst=list(range(0,len(Sar),bptt))[1:]+[len(Sar)] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # c,c_= 0,0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                sx_ = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                # sxa = torch.cat([sx, a], dim=-1)\n",
        "                # c_ = c_ + self.tcost(sx_).squeeze(-1) #sxa\n",
        "                c_ = torch.cat([c_, self.tcost(sx_).squeeze(-1)]) #sxa\n",
        "                # c = c + self.icost(world_state_) + reward.to(torch.float32)\n",
        "                # c = c + self.icost(sx_) + reward.to(torch.float32)\n",
        "                c = torch.cat([c, self.icost(sx_) + reward.to(torch.float32)])\n",
        "                a = self.quantizer.indices_to_codes(action)\n",
        "                z = self.jepa.argm(sx, a, sx_)\n",
        "                sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "                sy_ = self.jepa.pred(sxaz)\n",
        "                repr_loss = self.jepa.sim_coeff * F.mse_loss(sx_, sy_) # s(sy, sy~) # invariance loss\n",
        "                std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sx_))\n",
        "                jloss = repr_loss + std_loss + cov_loss\n",
        "                loss = loss + jloss\n",
        "\n",
        "                if i in lst:\n",
        "                    loss = loss + F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # closs=F.mse_loss(c_, c)\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), F.mse_loss(c_, c).item(), F.l1_loss(c_, c).item())\n",
        "                    # loss = loss + closs\n",
        "                    loss.backward()\n",
        "                    optim.step()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx = sx_.detach()\n",
        "                    loss=0\n",
        "                    # c,c_= 0,0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "                try: wandb.log({\"train loss\": loss.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "42a84662-f7ad-4367-99c6-db1b28cce998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "\n",
        "import pickle\n",
        "# def save(folder=''):\n",
        "#     agent.save(folder)\n",
        "#     with open(folder+'buffer.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# def load(folder=''):\n",
        "#     agent.load(folder)\n",
        "#     with open(folder+'buffer.pkl', 'rb') as f: return pickle.load(f)\n",
        "\n",
        "\n",
        "def save(folder, name='agent.pth'):\n",
        "    torch.save(agent.state_dict(), folder+name)\n",
        "    agent.mem.save(file=folder+name)\n",
        "    with open(folder+'buffer.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "def load(folder, name='agent.pth'):\n",
        "    agent.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    # agent.mem.load(file=folder+name)\n",
        "    with open(folder+'buffer.pkl', 'rb') as f: return pickle.load(f)\n",
        "\n",
        "\n",
        "# save(folder)\n",
        "save('/content/')\n",
        "# buffer = load(folder)\n",
        "# buffer = load('/content/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NVcknabHMxH6"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = self.data_process(buffer)\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    # def data_process(self, data): # str 10780437\n",
        "    #     return torch.tensor([self.stoi.get(c) for c in data]) # list of int 4570571 # stoi.get(c,UNK_IDX)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        # state = list(state)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(\"__getitem__\",state)\n",
        "        return state, action, reward\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "    def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "        lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "        with torch.no_grad():\n",
        "            imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "            data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "            # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "            data=data.flatten(start_dim=-3)\n",
        "            data=lin(data) # random projection\n",
        "            data = F.normalize(data, dim=-1)\n",
        "            idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "            sample = data[idx]\n",
        "            index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "            # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "            index.add(data)\n",
        "            D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "            priority = (2**-D).sum(-1) # L2\n",
        "            # priority = -D.sum(-1) # IP\n",
        "            topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "            index_list = idx[topk.values] # most clustered\n",
        "            for i in reversed(index_list): data.pop(i)\n",
        "        return data\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 16 #512\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j-nT5j864BIn"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PraFUAPB3j7v"
      },
      "outputs": [],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        if len(act)<=0: act = agent(state).cpu()\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cm6KjvBrnNO",
        "outputId": "1d03faae-8889-4e42-e9d3-926e8004932f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 #### train ####\n",
            "repr, std, cov, closs 0.05129430070519447 0.4949233829975128 1.0431635999452737e-08 0.01787145622074604 0.049825701862573624\n",
            "argm 0.4973950684070587 -0.8522764444351196\n",
            "argm 0.4923790693283081 -0.5631132125854492\n",
            "argm 0.4973466396331787 0.7065016031265259\n",
            "argm 0.5037955045700073 0.9390090703964233\n",
            "argm 0.5040555000305176 -0.43358659744262695\n",
            "argm 0.5099117159843445 -0.6796882748603821\n",
            "argm 0.5091655850410461 -0.7179591655731201\n",
            "argm 0.4987511932849884 0.9662615656852722\n",
            "argm 0.49979138374328613 0.1796155869960785\n",
            "argm 0.5092971324920654 0.5599759817123413\n",
            "argm 0.5006476640701294 -0.6116141080856323\n",
            "argm 0.5134825706481934 0.6741665601730347\n",
            "argm 0.5242654085159302 0.07268472015857697\n",
            "argm 0.5233727693557739 -0.6406309604644775\n",
            "argm 0.5249689817428589 0.514257550239563\n",
            "argm 0.5237626433372498 0.17545296251773834\n",
            "argm 0.5241981148719788 -0.33161091804504395\n",
            "argm 0.5254954099655151 0.4602454602718353\n",
            "argm 0.5293627381324768 -0.4968411326408386\n",
            "argm 0.5269424915313721 0.03282299265265465\n",
            "argm 0.5292198657989502 -0.33095166087150574\n",
            "argm 0.5291458368301392 -0.09785626828670502\n",
            "argm 0.5222607851028442 -0.40461716055870056\n",
            "argm 0.5249649286270142 -0.10009746998548508\n",
            "argm 0.5203777551651001 -0.9173659682273865\n",
            "argm 0.5201212167739868 0.4957086443901062\n",
            "argm 0.5239682197570801 -0.43403488397598267\n",
            "argm 0.5321576595306396 -0.04232623055577278\n",
            "argm 0.5264244079589844 0.9971058964729309\n",
            "argm 0.5344461798667908 0.864120364189148\n",
            "argm 0.5474874973297119 -0.477191686630249\n",
            "argm 0.5537985563278198 -0.045035794377326965\n",
            "argm 0.5497089624404907 0.202481210231781\n",
            "argm 0.5347729325294495 0.5467891097068787\n",
            "argm 0.5464375615119934 0.30006134510040283\n",
            "argm 0.5445829033851624 0.4106786549091339\n",
            "argm 0.5515787601470947 0.7325541973114014\n",
            "argm 0.5573813915252686 0.2047768086194992\n",
            "argm 0.5374844074249268 -0.774927020072937\n",
            "argm 0.5357885360717773 -0.72341388463974\n",
            "argm 0.5332995057106018 -0.4435391128063202\n",
            "argm 0.5438498258590698 0.8942006230354309\n",
            "argm 0.5480870008468628 0.5371798872947693\n",
            "argm 0.5467257499694824 0.2693054974079132\n",
            "argm 0.5511660575866699 0.020020682364702225\n",
            "argm 0.5540803670883179 -0.08693061023950577\n",
            "repr, std, cov, closs 1.7796791791915894 0.4932374358177185 9.72849884419702e-05 0.001096741994842887 0.03131185099482536\n",
            "argm 0.16322165727615356 0.19499137997627258\n",
            "argm 0.15741655230522156 0.3165329694747925\n",
            "argm 0.16662555932998657 0.8676287531852722\n",
            "argm 0.1649312674999237 0.522285521030426\n",
            "argm 0.16216841340065002 0.3066532611846924\n",
            "argm 0.16941964626312256 -0.6176339387893677\n",
            "argm 0.16847780346870422 0.12573197484016418\n",
            "argm 0.16755330562591553 0.9326336979866028\n",
            "argm 0.16929006576538086 -0.9629479050636292\n",
            "argm 0.1738280951976776 0.06167127564549446\n",
            "argm 0.1722729653120041 -0.7887144684791565\n",
            "argm 0.1788143664598465 0.17362196743488312\n",
            "argm 0.1777292788028717 0.2057025134563446\n",
            "argm 0.17928475141525269 -0.09634377807378769\n",
            "argm 0.17898118495941162 0.823218822479248\n",
            "argm 0.17828743159770966 -0.16420771181583405\n",
            "argm 0.17406398057937622 -0.9281694889068604\n",
            "argm 0.17087872326374054 0.8532111048698425\n",
            "argm 0.17775169014930725 0.03542226180434227\n",
            "argm 0.17460568249225616 0.4259861707687378\n",
            "argm 0.17567993700504303 0.134439155459404\n",
            "argm 0.1723751425743103 -0.2547198235988617\n",
            "argm 0.1744692623615265 -0.8284296989440918\n",
            "argm 0.1719352751970291 0.6293781995773315\n",
            "argm 0.17552664875984192 0.25423723459243774\n",
            "argm 0.17240335047245026 0.5316989421844482\n",
            "argm 0.17034052312374115 -0.2107349932193756\n",
            "argm 0.18759837746620178 -0.18980436027050018\n",
            "argm 0.1886506974697113 -0.4905368387699127\n",
            "argm 0.18693608045578003 -0.19540265202522278\n",
            "argm 0.1839343011379242 -0.9592195153236389\n",
            "argm 0.183958500623703 0.8385686874389648\n",
            "argm 0.18589726090431213 0.6194313168525696\n",
            "argm 0.187862366437912 0.11746340990066528\n",
            "argm 0.19427195191383362 0.2508571743965149\n",
            "argm 0.19856739044189453 -0.3203636407852173\n",
            "argm 0.1926315426826477 -0.48967447876930237\n",
            "argm 0.18148024380207062 -0.29009658098220825\n",
            "argm 0.18536581099033356 -0.6446689963340759\n",
            "argm 0.1876031756401062 0.2080727070569992\n",
            "argm 0.18770070374011993 -0.7098982334136963\n",
            "argm 0.19806838035583496 0.1384841352701187\n",
            "argm 0.22711239755153656 -0.6845446228981018\n",
            "argm 0.231423482298851 0.8013478517532349\n",
            "argm 0.2286987006664276 -0.09634290635585785\n",
            "argm 0.22625556588172913 0.4424375891685486\n",
            "argm 0.10674305260181427 0.21824881434440613\n",
            "argm 0.10413989424705505 -0.21051762998104095\n",
            "argm 0.10884924978017807 0.9909569025039673\n",
            "argm 0.10930876433849335 0.47466927766799927\n",
            "repr, std, cov, closs 2.732717752456665 0.49212461709976196 0.00039564634789712727 0.0026710224337875843 0.04908924177289009\n",
            "argm 0.13566622138023376 -0.7547276616096497\n",
            "argm 0.1413622945547104 -0.18791775405406952\n",
            "argm 0.14840011298656464 -0.7761574983596802\n",
            "argm 0.14770787954330444 -0.20690692961215973\n",
            "argm 0.13715419173240662 0.2711431682109833\n",
            "argm 0.13427777588367462 0.49042102694511414\n",
            "argm 0.13883566856384277 0.32271629571914673\n",
            "argm 0.14149382710456848 0.2883641719818115\n",
            "argm 0.13903531432151794 -0.1510670930147171\n",
            "argm 0.14476025104522705 0.8257126808166504\n",
            "argm 0.14632196724414825 -0.9733938574790955\n",
            "argm 0.14976894855499268 0.18424898386001587\n",
            "argm 0.13421879708766937 -0.2182619720697403\n",
            "argm 0.14176687598228455 -0.21000541746616364\n",
            "argm 0.1246170625090599 0.5257811546325684\n",
            "argm 0.13258779048919678 -0.882956862449646\n",
            "argm 0.12974876165390015 0.004122547805309296\n",
            "argm 0.13818901777267456 -0.008007500320672989\n",
            "argm 0.1314135044813156 0.9617494344711304\n",
            "argm 0.14312362670898438 -0.203611820936203\n",
            "argm 0.14313727617263794 0.3752768635749817\n",
            "argm 0.13032296299934387 -0.19601288437843323\n",
            "argm 0.13279138505458832 -0.10950629413127899\n",
            "argm 0.13121825456619263 -0.2738173305988312\n",
            "argm 0.13198226690292358 -0.7549715042114258\n",
            "argm 0.12559634447097778 -0.5494301319122314\n",
            "argm 0.12384270876646042 0.6502693891525269\n",
            "argm 0.1304018199443817 -0.2332744598388672\n",
            "argm 0.13131564855575562 -0.8390735387802124\n",
            "argm 0.13994990289211273 0.9276649355888367\n",
            "argm 0.13964739441871643 0.9232383966445923\n",
            "argm 0.14470915496349335 -0.8385508060455322\n",
            "argm 0.12912192940711975 -0.20837509632110596\n",
            "argm 0.1391495019197464 0.938988208770752\n",
            "argm 0.13937091827392578 0.7874963879585266\n",
            "argm 0.14278198778629303 -0.32087963819503784\n",
            "argm 0.14678631722927094 0.1574384719133377\n",
            "argm 0.14221471548080444 0.7040411233901978\n",
            "argm 0.14680787920951843 0.2791709005832672\n",
            "argm 0.1383827030658722 0.6437159776687622\n",
            "argm 0.14349399507045746 -0.6242856979370117\n",
            "argm 0.141494482755661 -0.7457038760185242\n",
            "argm 0.142881840467453 0.215180903673172\n",
            "argm 0.14461025595664978 0.42170482873916626\n",
            "argm 0.15362301468849182 -0.138990581035614\n",
            "argm 0.1516774296760559 0.5615195035934448\n",
            "argm 0.2396666705608368 -0.020653709769248962\n",
            "argm 0.24347442388534546 -0.2861041724681854\n",
            "argm 0.2507491111755371 -0.7845295071601868\n",
            "argm 0.24142026901245117 0.8617687225341797\n",
            "repr, std, cov, closs 6.035503387451172 0.4638335704803467 0.5232751369476318 0.005704858340322971 0.07291588187217712\n",
            "repr, std, cov, closs 0.681696355342865 0.4851230978965759 0.009538641199469566 0.00035596516681835055 0.015855710953474045\n",
            "argm 0.10004253685474396 -0.5275856256484985\n",
            "argm 0.10240411013364792 -0.4474259912967682\n",
            "argm 0.10067024827003479 -0.6514419913291931\n",
            "argm 0.10497976094484329 -0.6202462911605835\n",
            "repr, std, cov, closs 1.6196098327636719 0.485073983669281 0.010458726435899734 0.0162938442081213 0.03351741284132004\n",
            "1 #### train ####\n",
            "repr, std, cov, closs 0.6082798838615417 0.49296337366104126 0.00011085808364441618 0.01559717021882534 0.02925841696560383\n",
            "repr, std, cov, closs 0.5799525380134583 0.4933484196662903 4.6770252083661035e-05 0.015348495915532112 0.028701473027467728\n",
            "repr, std, cov, closs 0.3926640450954437 0.4934207797050476 3.7803882150910795e-05 0.00015893689123913646 0.007309594191610813\n",
            "repr, std, cov, closs 0.4624805450439453 0.4928385317325592 0.00011532394273672253 0.00020307296654209495 0.012490964494645596\n",
            "repr, std, cov, closs 0.6504749059677124 0.4914999306201935 0.0003920758026652038 0.00017840841610450298 0.011633681133389473\n",
            "repr, std, cov, closs 0.1274942010641098 0.4935811758041382 3.8154685171321034e-05 0.00014749568072147667 0.011121205985546112\n",
            "2 #### train ####\n",
            "repr, std, cov, closs 0.28444698452949524 0.49144425988197327 0.00044327270006760955 0.01601887121796608 0.02361512929201126\n",
            "repr, std, cov, closs 0.3929813504219055 0.4888937771320343 0.0029974360950291157 2.648317240527831e-05 0.0029644255992025137\n",
            "repr, std, cov, closs 2.360496997833252 0.47214362025260925 0.21623247861862183 0.018198871985077858 0.027619030326604843\n",
            "repr, std, cov, closs 0.4154333770275116 0.4912022352218628 0.0007248339243233204 6.257931818254292e-05 0.0056684669107198715\n",
            "repr, std, cov, closs 0.9099358916282654 0.48699265718460083 0.006572903599590063 0.00014993062359280884 0.008334689773619175\n",
            "repr, std, cov, closs 0.4671436846256256 0.49301135540008545 7.552368333563209e-05 6.96841671015136e-05 0.0066282376646995544\n",
            "3 #### train ####\n",
            "repr, std, cov, closs 1.6866438388824463 0.4898979067802429 0.0017038419609889388 0.0005350952269509435 0.011176986619830132\n",
            "repr, std, cov, closs 0.15095894038677216 0.49324899911880493 5.398245411925018e-05 0.015738001093268394 0.01903047226369381\n",
            "repr, std, cov, closs 0.23594996333122253 0.4926351010799408 0.00020932986808475107 2.4169497919501737e-05 0.004594077356159687\n",
            "repr, std, cov, closs 0.6892292499542236 0.49018967151641846 0.0017805916722863913 0.015683062374591827 0.017666907981038094\n",
            "repr, std, cov, closs 0.30353185534477234 0.4918549656867981 0.00040961423655971885 3.649496647994965e-05 0.005099638365209103\n",
            "repr, std, cov, closs 0.5502133965492249 0.49128371477127075 0.0007472669240087271 0.00012597613385878503 0.009045563638210297\n",
            "4 #### train ####\n",
            "repr, std, cov, closs 0.1798849254846573 0.4943163990974426 6.816157110733911e-06 0.00010280324204359204 0.00993052776902914\n",
            "repr, std, cov, closs 0.5342864394187927 0.4888872504234314 0.002685955259948969 2.825095180014614e-05 0.004915204364806414\n",
            "repr, std, cov, closs 0.23633155226707458 0.49039044976234436 0.0012522430624812841 0.0156860314309597 0.01834655925631523\n",
            "repr, std, cov, closs 0.15693582594394684 0.49191826581954956 0.0004242759896442294 0.01575978845357895 0.020664112642407417\n",
            "repr, std, cov, closs 0.1830916851758957 0.49224966764450073 0.0003280862874817103 2.1240564819891006e-05 0.004254373721778393\n",
            "repr, std, cov, closs 0.11208311468362808 0.4919652044773102 0.00035656694672070444 1.3764114328296273e-06 0.0008254527347162366\n",
            "5 #### train ####\n",
            "repr, std, cov, closs 0.11536139249801636 0.48932093381881714 0.0022806532215327024 0.015614532865583897 0.019113868474960327\n",
            "repr, std, cov, closs 0.1402924358844757 0.48936983942985535 0.0022480457555502653 0.01515976432710886 0.02009143866598606\n",
            "repr, std, cov, closs 0.06214961037039757 0.4924396276473999 0.0002609521907288581 8.039760359679349e-06 0.0019382357131689787\n",
            "repr, std, cov, closs 0.03476545214653015 0.49293339252471924 0.00014688460214529186 1.629155121918302e-05 0.0032190820202231407\n",
            "repr, std, cov, closs 0.17329169809818268 0.4918907880783081 0.0004125863197259605 5.5384531151503325e-05 0.0032939519733190536\n",
            "repr, std, cov, closs 0.058103159070014954 0.4885225296020508 0.003058217465877533 1.5592702766298316e-05 0.003685292787849903\n",
            "6 #### train ####\n",
            "repr, std, cov, closs 0.06492801755666733 0.4864567816257477 0.006854439619928598 1.1980246199527755e-05 0.0021750638261437416\n",
            "repr, std, cov, closs 0.08835510164499283 0.48509711027145386 0.010530071333050728 1.2963226254214533e-05 0.0023032911121845245\n",
            "repr, std, cov, closs 0.030496349558234215 0.49255383014678955 0.00020840666547883302 0.015506447292864323 0.019172068685293198\n",
            "repr, std, cov, closs 0.022361893206834793 0.4932178556919098 0.00010153790935873985 3.984759132436011e-06 0.0018734134500846267\n",
            "repr, std, cov, closs 0.08406484127044678 0.4905710816383362 0.0010534314205870032 0.015697406604886055 0.017583515495061874\n",
            "repr, std, cov, closs 0.037893909960985184 0.49296441674232483 0.00014245326747186482 1.6517642507096753e-06 0.0012247445993125439\n",
            "7 #### train ####\n",
            "repr, std, cov, closs 0.03170894831418991 0.4937164783477783 4.069382339366712e-05 0.01558202039450407 0.01710582710802555\n",
            "repr, std, cov, closs 0.05637179687619209 0.49196523427963257 0.0003762257983908057 9.373305147164501e-06 0.0020501718390733004\n",
            "repr, std, cov, closs 0.08639861643314362 0.49096202850341797 0.0007976348279044032 1.2819946277886629e-05 0.0025230571627616882\n",
            "repr, std, cov, closs 0.019732937216758728 0.4945903420448303 3.2774507872090908e-06 1.4149487469694577e-05 0.00341366371139884\n",
            "repr, std, cov, closs 0.01458523329347372 0.49417251348495483 1.7009755538310856e-05 0.015522260218858719 0.016537975519895554\n",
            "repr, std, cov, closs 0.028687389567494392 0.49333131313323975 8.873809565557167e-05 7.718832421232946e-06 0.002083829138427973\n",
            "8 #### train ####\n",
            "repr, std, cov, closs 0.02457231655716896 0.49306827783584595 0.00012255297042429447 2.2738963707524817e-06 0.0012833857908844948\n",
            "repr, std, cov, closs 0.01346995122730732 0.49360400438308716 5.466737275128253e-05 2.0180486899334937e-06 0.0013878617901355028\n",
            "repr, std, cov, closs 0.005897236056625843 0.4949009418487549 1.1737386529375726e-07 0.015595530159771442 0.01634022407233715\n",
            "repr, std, cov, closs 0.014648346230387688 0.49437209963798523 9.53355265664868e-06 5.810348966406309e-07 0.0003615453897509724\n",
            "repr, std, cov, closs 0.012700285762548447 0.49425292015075684 1.4024516531208064e-05 6.1239993556228e-06 0.0024730716831982136\n",
            "repr, std, cov, closs 0.009320258162915707 0.4937075972557068 4.873899160884321e-05 7.3272594818263315e-06 0.0026970217004418373\n",
            "9 #### train ####\n",
            "repr, std, cov, closs 0.0027723500970751047 0.49484091997146606 4.7477053044531203e-07 0.01564730890095234 0.01641537807881832\n",
            "repr, std, cov, closs 0.0033706936519593 0.4946994483470917 1.8885991721617756e-06 0.015531358309090137 0.0189089123159647\n",
            "repr, std, cov, closs 0.006111279129981995 0.49426811933517456 1.2485621482483111e-05 2.4191451302613132e-05 0.004916992504149675\n",
            "repr, std, cov, closs 0.006217798218131065 0.4939509630203247 2.8424725314835086e-05 1.5523341062362306e-05 0.003935839980840683\n",
            "repr, std, cov, closs 0.011884443461894989 0.49147114157676697 0.000585119123570621 7.279745091182122e-07 0.0008330654818564653\n",
            "repr, std, cov, closs 0.003259110264480114 0.49418845772743225 1.623853313503787e-05 1.588373379490804e-05 0.003980895970016718\n",
            "10 #### train ####\n",
            "repr, std, cov, closs 0.003114828374236822 0.4945731461048126 3.6100125271332217e-06 3.261474194005132e-05 0.005707548465579748\n",
            "repr, std, cov, closs 0.002457830822095275 0.4942251145839691 1.3936991308582947e-05 2.692083944566548e-05 0.00518452562391758\n",
            "repr, std, cov, closs 0.0023763165809214115 0.4945090413093567 5.084339136374183e-06 7.914046364021488e-06 0.002807753160595894\n",
            "repr, std, cov, closs 0.00542063731700182 0.49302801489830017 0.000130896718474105 0.031154802069067955 0.032713085412979126\n",
            "repr, std, cov, closs 0.002157908398658037 0.4940512776374817 2.3435884941136464e-05 7.601303877891041e-06 0.0027556901331990957\n",
            "repr, std, cov, closs 0.011782917194068432 0.4861640930175781 0.00747478473931551 4.15061867897748e-06 0.001967907650396228\n",
            "11 #### train ####\n",
            "repr, std, cov, closs 0.0058812228962779045 0.49166226387023926 0.0004763794131577015 3.399793513381155e-07 0.0005587630439549685\n",
            "repr, std, cov, closs 0.016049116849899292 0.4857749938964844 0.008316056802868843 1.2710547707683872e-06 0.001051328843459487\n",
            "repr, std, cov, closs 0.009132779203355312 0.4904886484146118 0.0010698192054405808 2.3412609095885273e-07 0.00046719308011233807\n",
            "repr, std, cov, closs 0.006068446207791567 0.4921731948852539 0.00031002695322968066 0.015599346719682217 0.01625939831137657\n",
            "repr, std, cov, closs 0.006903422996401787 0.4910426437854767 0.0007333373068831861 0.01566402055323124 0.016684839501976967\n",
            "repr, std, cov, closs 0.007212451659142971 0.4908338189125061 0.0008194118272513151 3.847673610835045e-07 0.0006008947966620326\n",
            "12 #### train ####\n",
            "repr, std, cov, closs 0.014069924131035805 0.49039363861083984 0.0010489707347005606 0.03115268051624298 0.03266432136297226\n",
            "repr, std, cov, closs 0.007967098616063595 0.49273407459259033 0.00016712784417904913 1.292378897232993e-06 0.001135551487095654\n",
            "repr, std, cov, closs 0.002255026949569583 0.4934810996055603 6.569288962054998e-05 1.1189049473614432e-06 0.0010555930202826858\n",
            "repr, std, cov, closs 0.0022787428461015224 0.4941544532775879 1.739136132528074e-05 1.116011276280915e-06 0.0010533955646678805\n",
            "repr, std, cov, closs 0.006223335396498442 0.4914637804031372 0.0005265834042802453 5.789009946965962e-07 0.0007556256605312228\n",
            "repr, std, cov, closs 0.007496168836951256 0.48813992738723755 0.003139100270345807 1.7520461881304072e-07 0.000414458365412429\n",
            "13 #### train ####\n",
            "repr, std, cov, closs 0.010877692140638828 0.4874265193939209 0.003976854495704174 3.0782125577388797e-06 0.0017283211927860975\n",
            "repr, std, cov, closs 0.00578858470544219 0.4919220805168152 0.000354303716449067 2.856315859389724e-06 0.0016688316827639937\n",
            "repr, std, cov, closs 0.006107043940573931 0.49179303646087646 0.00038976804353296757 0.01561873871833086 0.015811605378985405\n",
            "repr, std, cov, closs 0.001308482140302658 0.49437445402145386 8.870192687027156e-06 3.916586138075218e-06 0.001978526823222637\n",
            "repr, std, cov, closs 0.0038098704535514116 0.49387508630752563 3.2124517019838095e-05 0.015569934621453285 0.017352301627397537\n",
            "repr, std, cov, closs 0.004736454226076603 0.49201250076293945 0.00031907984521239996 1.1427195545365976e-07 0.0003125634102616459\n",
            "14 #### train ####\n",
            "repr, std, cov, closs 0.007180092390626669 0.4872094988822937 0.00418039271607995 0.015635685995221138 0.016144659370183945\n",
            "repr, std, cov, closs 0.0027030964847654104 0.4913119673728943 0.0005390688893385231 1.8198534235125408e-06 0.0013409244129434228\n",
            "repr, std, cov, closs 0.00744104478508234 0.48783165216445923 0.0032233428210020065 0.015597156248986721 0.01670255698263645\n",
            "repr, std, cov, closs 0.006067054811865091 0.4884606599807739 0.00246754614636302 7.046432415336312e-07 0.0008226751815527678\n",
            "repr, std, cov, closs 0.0018252839799970388 0.4933369755744934 7.741069566691294e-05 6.918314738868503e-07 0.0008281447808258235\n",
            "repr, std, cov, closs 0.005430552177131176 0.49082809686660767 0.0007313152891583741 6.679927082586801e-07 0.0008121002465486526\n",
            "15 #### train ####\n",
            "repr, std, cov, closs 0.006004912778735161 0.4876291751861572 0.003445901907980442 0.015611686743795872 0.016180630773305893\n",
            "repr, std, cov, closs 0.004391540307551622 0.48891302943229675 0.0020039633382111788 1.208959702125867e-06 0.0010864890646189451\n",
            "repr, std, cov, closs 0.004984707105904818 0.4899240732192993 0.001225817366503179 1.0801429652929073e-06 0.0010254948865622282\n",
            "repr, std, cov, closs 0.002827867865562439 0.4929215908050537 0.00012968287046533078 0.015593726187944412 0.016383344307541847\n",
            "repr, std, cov, closs 0.00255422480404377 0.49064362049102783 0.0008076397352851927 5.649441163768643e-07 0.0007443544454872608\n",
            "repr, std, cov, closs 0.001701714238151908 0.49084603786468506 0.0007140447269193828 1.0902101621468319e-06 0.0010390132665634155\n",
            "16 #### train ####\n",
            "repr, std, cov, closs 0.0035462158266454935 0.48792701959609985 0.0030241836793720722 8.8985575530387e-07 0.0009316375944763422\n",
            "repr, std, cov, closs 0.002861659275367856 0.48901450634002686 0.0018941700691357255 0.031185509636998177 0.03211938217282295\n",
            "repr, std, cov, closs 0.0015841674758121371 0.4915851354598999 0.00043186364928260446 9.4335490530284e-07 0.0009697506902739406\n",
            "repr, std, cov, closs 0.0023301991168409586 0.4886048436164856 0.002279197098687291 4.928016892336018e-07 0.0006870558718219399\n",
            "repr, std, cov, closs 0.0018142968183383346 0.49181538820266724 0.00036202245973981917 2.0196569039399037e-07 0.0004326927592046559\n",
            "repr, std, cov, closs 0.0021292034070938826 0.4870350956916809 0.004269466735422611 1.2772347872669343e-06 0.0011156626278534532\n",
            "17 #### train ####\n",
            "repr, std, cov, closs 0.004714854061603546 0.48144423961639404 0.021122045814990997 1.3433619869829272e-06 0.0011287354864180088\n",
            "repr, std, cov, closs 0.013742467388510704 0.4772055745124817 0.050655797123909 1.5259058727679076e-06 0.0011452088365331292\n",
            "repr, std, cov, closs 0.01231122761964798 0.49239063262939453 0.00022581825032830238 0.03131921589374542 0.03233439475297928\n",
            "repr, std, cov, closs 0.0403253547847271 0.47661006450653076 0.05670912191271782 1.0094854587805457e-06 0.000956504256464541\n",
            "repr, std, cov, closs 0.0356341190636158 0.4836822748184204 0.012127701193094254 7.308484839541052e-08 0.000267756957327947\n",
            "repr, std, cov, closs 0.04047291353344917 0.4842792749404907 0.010396646335721016 3.5353486964595504e-06 0.0018582931952551007\n",
            "18 #### train ####\n",
            "repr, std, cov, closs 0.0373319648206234 0.49220553040504456 0.0002857350918930024 4.2899546315311454e-06 0.002064689062535763\n",
            "repr, std, cov, closs 0.028521014377474785 0.4909367561340332 0.0007142181857489049 0.015530317090451717 0.016178175806999207\n",
            "repr, std, cov, closs 0.023859024047851562 0.49186280369758606 0.00037100998451933265 4.659919795813039e-06 0.002153410343453288\n",
            "repr, std, cov, closs 0.018875719979405403 0.49274182319641113 0.0002214650739915669 0.015536361373960972 0.01857178285717964\n",
            "repr, std, cov, closs 0.012148654088377953 0.4945322275161743 2.673637482075719e-06 4.01730267185485e-06 0.0020026362035423517\n",
            "repr, std, cov, closs 0.011635709553956985 0.494275838136673 1.1975136658293195e-05 4.6989669044705806e-08 0.000200072827283293\n",
            "19 #### train ####\n",
            "repr, std, cov, closs 0.01385823730379343 0.49429357051849365 1.0971072697429918e-05 8.55003236210905e-07 0.000904249376617372\n",
            "repr, std, cov, closs 0.017278363928198814 0.4946088194847107 2.8809092782466905e-06 2.9314600169527694e-07 0.0005253481213003397\n",
            "repr, std, cov, closs 0.0070497458800673485 0.49488067626953125 2.113859807195695e-07 3.946845936297905e-06 0.0019293645163998008\n",
            "repr, std, cov, closs 0.0060340347699820995 0.4945443272590637 4.488461399887456e-06 0.015593494288623333 0.0176742784678936\n",
            "repr, std, cov, closs 0.010096224956214428 0.49364766478538513 6.165761442389339e-05 5.39888489470286e-08 0.00020151346689090133\n",
            "repr, std, cov, closs 0.011163566261529922 0.4936792254447937 5.735787271987647e-05 0.015642158687114716 0.016055453568696976\n",
            "20 #### train ####\n",
            "repr, std, cov, closs 0.006910353899002075 0.49449342489242554 5.993923878122587e-06 1.8398085330773029e-06 0.0013303193263709545\n",
            "repr, std, cov, closs 0.0019150306470692158 0.4949667155742645 9.709609116725915e-09 8.008335612430528e-07 0.0008786724647507071\n",
            "repr, std, cov, closs 0.004676623735576868 0.4948561191558838 3.812271529568534e-07 7.900113132564002e-07 0.0008717859745956957\n",
            "repr, std, cov, closs 0.005854039918631315 0.49474281072616577 1.294394678552635e-06 1.1922345493076136e-06 0.0010810805251821876\n",
            "repr, std, cov, closs 0.004802369978278875 0.4947400689125061 1.3601666069007479e-06 0.031201664358377457 0.03140351548790932\n",
            "repr, std, cov, closs 0.0028639747761189938 0.4948599338531494 3.456528361311939e-07 9.22953304893781e-08 0.00027802467229776084\n",
            "21 #### train ####\n",
            "repr, std, cov, closs 0.0033938230480998755 0.4949234127998352 8.579187493751306e-08 0.015596942976117134 0.016488537192344666\n",
            "repr, std, cov, closs 0.0027752190362662077 0.494877427816391 1.8727921258232527e-07 6.081165793148102e-08 0.0002121621510013938\n",
            "repr, std, cov, closs 0.005283622071146965 0.49465349316596985 2.497808509360766e-06 4.401484261506994e-07 0.0006306100985966623\n",
            "repr, std, cov, closs 0.0024908899795264006 0.4945181906223297 5.753683581133373e-06 0.015660706907510757 0.01649213209748268\n",
            "repr, std, cov, closs 0.004891459830105305 0.4943798780441284 9.911229426506907e-06 3.700819206642336e-08 0.00011154633830301464\n",
            "repr, std, cov, closs 0.0019319155253469944 0.49452900886535645 5.070565748610534e-06 2.4015397670495986e-08 0.00010902452049776912\n",
            "22 #### train ####\n",
            "repr, std, cov, closs 0.00627681240439415 0.49470335245132446 1.8641429733179393e-06 4.942376108374447e-07 0.0006978623569011688\n",
            "repr, std, cov, closs 0.0038333775009959936 0.49475935101509094 1.0633152669470292e-06 1.7479770519912563e-07 0.00036706592072732747\n",
            "repr, std, cov, closs 0.0045453030616045 0.4947436451911926 1.2812665772798937e-06 5.250322843153299e-08 0.00020863578538410366\n",
            "repr, std, cov, closs 0.0045343730598688126 0.4947311282157898 1.4411483562071226e-06 7.854818022678955e-07 0.0008694930002093315\n",
            "repr, std, cov, closs 0.0034274249337613583 0.4948909282684326 2.2514115016747382e-07 0.01562676578760147 0.01575363613665104\n",
            "repr, std, cov, closs 0.0019338020356371999 0.49485522508621216 2.2423192547194049e-07 0.01562960259616375 0.015805266797542572\n",
            "23 #### train ####\n",
            "repr, std, cov, closs 0.004687917418777943 0.49485597014427185 2.274455965789457e-07 6.383937147802499e-07 0.0007760027656331658\n",
            "repr, std, cov, closs 0.0017083024140447378 0.4949188232421875 7.848624505868429e-08 0.015611843205988407 0.016092756763100624\n",
            "repr, std, cov, closs 0.002835256513208151 0.494878351688385 2.1272401795613405e-07 6.593907642127306e-09 6.802380084991455e-05\n",
            "repr, std, cov, closs 0.0036286618560552597 0.4949178695678711 8.435578990884096e-08 2.375785790320606e-08 0.00013804688933305442\n",
            "repr, std, cov, closs 0.001288389670662582 0.4948580861091614 2.393669262801268e-07 1.981788045668509e-06 0.001406447496265173\n",
            "repr, std, cov, closs 0.0033017692621797323 0.4945725202560425 3.2359744182031136e-06 0.01566164381802082 0.016821127384901047\n",
            "24 #### train ####\n",
            "repr, std, cov, closs 0.003598629031330347 0.4946608245372772 1.8184032342105638e-06 5.444002226795419e-07 0.0007258362602442503\n",
            "repr, std, cov, closs 0.002137730596587062 0.49451181292533875 4.010888915217947e-06 0.015592890791594982 0.016623415052890778\n",
            "repr, std, cov, closs 0.0022532870061695576 0.49471282958984375 1.222415448864922e-06 7.145303015931859e-08 0.0002612437237985432\n",
            "repr, std, cov, closs 0.0016248344909399748 0.4944746494293213 6.439044682338135e-06 2.4219417582571623e-08 0.00014826073311269283\n",
            "repr, std, cov, closs 0.00265853526070714 0.4941466748714447 1.937098022608552e-05 1.0175966735914699e-06 0.0010037424508482218\n",
            "repr, std, cov, closs 0.003307210048660636 0.49364548921585083 5.685242285835557e-05 0.015644080936908722 0.016198717057704926\n",
            "25 #### train ####\n",
            "repr, std, cov, closs 0.0022579047363251448 0.49319928884506226 0.0001163107153843157 0.015587006695568562 0.016842570155858994\n",
            "repr, std, cov, closs 0.001565671875141561 0.49362364411354065 5.648439400829375e-05 2.082260380120715e-06 0.00144187081605196\n",
            "repr, std, cov, closs 0.0020676066633313894 0.4926888346672058 0.0002180739538744092 7.24755295777868e-08 0.0002456617366988212\n",
            "repr, std, cov, closs 0.005593825597316027 0.4883788824081421 0.0036940681748092175 5.232667717791628e-06 0.002274338388815522\n",
            "repr, std, cov, closs 0.0032119322568178177 0.49345749616622925 7.514641765737906e-05 0.015702957287430763 0.018307765945792198\n",
            "repr, std, cov, closs 0.0031535890884697437 0.4927878975868225 0.0001824423234211281 3.6247702155378647e-06 0.0019005776848644018\n",
            "26 #### train ####\n",
            "repr, std, cov, closs 0.003792643081396818 0.4905828833580017 0.0011678836308419704 0.015623963437974453 0.01574653945863247\n",
            "repr, std, cov, closs 0.00438925065100193 0.49037691950798035 0.001342522562481463 0.015636209398508072 0.01633458025753498\n",
            "repr, std, cov, closs 0.0019657325465232134 0.492538720369339 0.00024328487052116543 1.4138046822154138e-07 0.000370879570255056\n",
            "repr, std, cov, closs 0.0018861891003325582 0.4935246706008911 7.112928142305464e-05 1.7676845800451702e-06 0.0013286084868013859\n",
            "repr, std, cov, closs 0.002382724778726697 0.49175578355789185 0.00048392461030744016 1.6174924439837923e-06 0.0012698256177827716\n",
            "repr, std, cov, closs 0.0037791419308632612 0.4892118275165558 0.0023162448778748512 1.0520675886027675e-08 8.549116319045424e-05\n",
            "27 #### train ####\n",
            "repr, std, cov, closs 0.001208708737976849 0.4936603009700775 5.0479873607400805e-05 0.015611382201313972 0.016255931928753853\n",
            "repr, std, cov, closs 0.002799973590299487 0.4917899966239929 0.0004404852807056159 2.8237245430773328e-08 0.00012131905532442033\n",
            "repr, std, cov, closs 0.0036983455065637827 0.4857564866542816 0.00870779063552618 0.01562075037509203 0.015804728493094444\n",
            "repr, std, cov, closs 0.0018002094002440572 0.4919670522212982 0.0003735627979040146 1.0164183095184853e-06 0.0009788303868845105\n",
            "repr, std, cov, closs 0.005879403557628393 0.48684048652648926 0.005796823650598526 2.1603324285024428e-07 0.00045776498154737055\n",
            "repr, std, cov, closs 0.005254042334854603 0.4890018701553345 0.002338506281375885 2.547005806263769e-06 0.0015892368974164128\n",
            "28 #### train ####\n",
            "repr, std, cov, closs 0.008844060823321342 0.485939621925354 0.008005714043974876 4.733977675641654e-06 0.0021720225922763348\n",
            "repr, std, cov, closs 0.05994754657149315 0.4864683151245117 0.006263338029384613 0.01571122743189335 0.01659509912133217\n",
            "repr, std, cov, closs 0.007518291939049959 0.49272090196609497 0.00019412461551837623 2.1154678506718483e-06 0.0014541400596499443\n",
            "repr, std, cov, closs 0.010528805665671825 0.48518773913383484 0.009851101785898209 0.015691526234149933 0.017664171755313873\n",
            "repr, std, cov, closs 0.03227081522345543 0.49011844396591187 0.0011978523107245564 2.0188415419397643e-06 0.0013174781342968345\n",
            "repr, std, cov, closs 0.016951922327280045 0.49261873960494995 0.00020706882060039788 9.258254749511252e-07 0.000924749649129808\n",
            "29 #### train ####\n",
            "repr, std, cov, closs 0.02117561735212803 0.49113959074020386 0.0007297788397409022 2.118172687914921e-06 0.001430140109732747\n",
            "repr, std, cov, closs 0.02495797723531723 0.49145880341529846 0.000521463924087584 4.884332724941487e-07 0.0005679783062078059\n",
            "repr, std, cov, closs 0.009508286602795124 0.494052529335022 1.9303604858578183e-05 2.288787072757259e-06 0.0015111935790628195\n",
            "repr, std, cov, closs 0.01684083230793476 0.4945744276046753 3.860030574287521e-06 3.3526348488521762e-06 0.0018157390877604485\n",
            "repr, std, cov, closs 0.0035026790574193 0.49449992179870605 4.220641130814329e-06 0.015657585114240646 0.016611039638519287\n",
            "repr, std, cov, closs 0.012855378910899162 0.4941772520542145 1.3635184586746618e-05 0.015596828423440456 0.016601521521806717\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "for i in range(30):\n",
        "    # # buffer=[]\n",
        "    # print(\"#### simulate ####\")\n",
        "    # buffer = simulate(agent, buffer)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    agent.train_jepa(train_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6a49EohtiJX"
      },
      "outputs": [],
      "source": [
        "!grep MemTotal /proc/meminfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8zxYU9jpE8K"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "###save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uT9m-J1BUWyz"
      },
      "outputs": [],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(\n",
        "    project=\"vicreg\",\n",
        "    config={\n",
        "        \"model\": \"res18\",\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZeny7pRU6bG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "sx=torch.randn((1, d_model), device=device)\n",
        "batch=sx.size(dim=0)\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*4 -2\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*3 -1.5\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "\n",
        "xx = torch.split(x, bptt, dim=1)\n",
        "for _ in range(20): # num epochs\n",
        "    sx_ = sx.detach()\n",
        "    # print(sx_[0][:10])\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "        la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# z_ = z_/scale\n",
        "\n",
        "# z=nn.Parameter(z_.clone())\n",
        "# print(z)\n",
        "# # optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e2)\n",
        "# # optim = torch.optim.SGD([z], lr=3e1)\n",
        "# # optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "# lossfn = torch.nn.MSELoss()\n",
        "# num_steps = 20\n",
        "# agent.jepa.eval()\n",
        "# import time\n",
        "# start=time.time()\n",
        "# for i in range(num_steps):\n",
        "#     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "#     # loss, sx = agent.rnn_pred(sx, la)\n",
        "#     sy_ = agent.jepa.pred(sxaz)\n",
        "#     # print(\"y_, y\",y_.shape, y.shape)\n",
        "#     loss = lossfn(sy_, sy)\n",
        "#     loss.backward()\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     print(\"argm\",loss.item(), z[0].item())\n",
        "# # print(time.time()-start)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "### trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wUhKd009Qvk3"
      ],
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1X2rEy9liqB6p-8y0dU_Qo5qAkZzUibWY",
      "authorship_tag": "ABX9TyNNJtW5eJg8X6Wf5gVey/6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}