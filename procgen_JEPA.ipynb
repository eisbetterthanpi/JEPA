{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "1a9c7739-685f-4146-8fe3-34ebf9c9fb9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.4/291.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -qq procgen\n",
        "# !pip install -qq procgen faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEY9MmwZhA8a",
        "outputId": "bb48853e-514b-423e-d3a1-8162cd14e4d3",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1278976\n",
            "torch.Size([4, 256])\n",
            "1278979\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model=256, drop=0.2):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278976\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.GELU(),\n",
        "            nn.Dropout2d(drop), nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.GELU(), # ReLU GELU SiLU\n",
        "            nn.Dropout2d(drop), nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.GELU(),\n",
        "            nn.Dropout2d(drop), nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.GELU(),\n",
        "            nn.Dropout2d(drop), nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.GELU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[4], d_model, 2, 1, 0), nn.GELU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Dropout(p=drop),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278979\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "conv = Conv().to(device)\n",
        "print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = conv(input)\n",
        "print(out.shape)\n",
        "\n",
        "deconv = Deconv(256).to(device)\n",
        "print(sum(p.numel() for p in deconv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,256), device=device)\n",
        "out = deconv(input)\n",
        "print(out.shape)\n",
        "\n",
        "# print(conv)\n",
        "# 1278976\n",
        "# 1278979\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "Bos81kQf1dwh"
      },
      "outputs": [],
      "source": [
        "# @title transfer_sd store_sd load_sd\n",
        "\n",
        "def transfer_sd(tgt_sd, src_sd): #\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            # print(wht_name, tgt_wht.shape, src_wht.shape)\n",
        "            if tgt_wht.shape==src_wht.shape:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "                continue\n",
        "            if tgt_wht.shape[0] != src_wht.shape[0]: continue # output dim diff\n",
        "            if len(tgt_wht.shape)==2: tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "    return tgt_sd\n",
        "\n",
        "def store_sd(all_sd, new_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in new_sd.keys():\n",
        "            if not wht_name in all_sd.keys():\n",
        "                # print(wht_name, new_sd[wht_name].shape)\n",
        "                all_sd[wht_name] = (new_sd[wht_name],)\n",
        "                continue\n",
        "            all_tpl, new_wht = all_sd[wht_name], new_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                print(wht_name, all_wht.shape, new_wht.shape)\n",
        "                if all_wht.shape==new_wht.shape:\n",
        "                    all_wht = new_wht\n",
        "                    break\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: continue # diff output shape\n",
        "                if len(all_wht.shape)==2: all_wht[:, :new_wht.shape[1]] = new_wht[:, :all_wht.shape[1]]\n",
        "                break\n",
        "            if len(all_wht.shape)>=2 and len(all_wht.shape)>=2:\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: all_tpl = all_tpl + (new_wht,) # wht not in all_wht\n",
        "    return all_sd\n",
        "\n",
        "def load_sd(tgt_sd, all_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in all_sd.keys(): continue\n",
        "            tgt_wht, all_tpl = tgt_sd[wht_name], all_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                # try: print(wht_name, tgt_wht.shape, all_wht.shape)\n",
        "                # except: print(wht_name, tgt_wht, all_wht)\n",
        "                if tgt_wht.shape==all_wht.shape:\n",
        "                    tgt_wht.copy_(all_wht)\n",
        "                    break\n",
        "                if tgt_wht.shape[0] != all_wht.shape[0]: continue # output dim diff\n",
        "                if len(tgt_wht.shape)==2: tgt_wht[:, :all_wht.shape[1]].copy_(all_wht[:, :tgt_wht.shape[1]])\n",
        "                break\n",
        "    return tgt_sd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# modelsd = torch.load('agent.pkl', map_location=device).values()\n",
        "# tgt_sd = transfer_sd(agent.state_dict(), modelsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = {}\n",
        "# all_sd = store_sd(all_sd, agent1.state_dict())\n",
        "# print(all_sd.keys())\n",
        "# checkpoint = {'model': all_sd}\n",
        "# torch.save(checkpoint, 'all_sd.pkl')\n",
        "\n",
        "# agent3 = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "# agent3.tcost = tcost3\n",
        "# tgt_sd = load_sd(agent3.state_dict(), all_sd)\n",
        "# agent3.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "# for x,y in zip(agent1.state_dict().values(), agent3.state_dict().values()):\n",
        "#     print((x==y).all())\n",
        "\n",
        "# print(agent1.jepa.enc.cnn[1].num_batches_tracked)\n",
        "# jepa.enc.cnn.0.weight\n",
        "# print(agent1.jepa.enc.cnn[0].weight.shape)\n",
        "# print(agent1.jepa.enc.cnn[0].weight[0][0])\n",
        "# print(agent3.jepa.enc.cnn[0].weight[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "SFVbGqMDqcDR"
      },
      "outputs": [],
      "source": [
        "# @title rename_sd\n",
        "def rename_sd(agent_sd):\n",
        "    sd_={}\n",
        "    convert={}\n",
        "    na_=''\n",
        "    for wht_name, wht in agent_sd.items():\n",
        "        o=wht_name.split('.')\n",
        "        # print(\"####\", wht_name)\n",
        "        name=wht_name\n",
        "        for i in range(len(o)):\n",
        "            c = o[i]\n",
        "            if c.isnumeric():\n",
        "                na, me = '.'.join(o[:i]), '.'.join(o[i+1:])\n",
        "                c=int(c)\n",
        "                if na!=na_: # param name diff\n",
        "                    j=0 # reset num\n",
        "                    c_=c # track wht_name num\n",
        "                    na_=na # track param name\n",
        "                elif c_<c: # same param name, diff num\n",
        "                    j+=1\n",
        "                    c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "        # print(name)\n",
        "        sd_[name] = wht\n",
        "        convert[name] = wht_name\n",
        "    return sd_, convert\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# # modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, _ = rename_sd(modelsd)\n",
        "\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# agent.load_state_dict(modelsd, strict=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "riBHnAAkkzrd"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim me\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# def transfer_optim(tgt_sd, src_sd, tgt_optim, src_optim): #\n",
        "def transfer_optim(tgt_sd, src_sd, tgt_optim_sd, src_optim_sd): #\n",
        "    non_lst = ['running_mean', 'running_var', 'num_batches_tracked', 'num_batches_tracked', 'loss_fn']\n",
        "    tgt_lst, src_lst = [], []\n",
        "    for i, (k,v) in enumerate(tgt_sd.items()):\n",
        "        # print(i, k, v.shape, any(s in k for s in non_lst))\n",
        "        if not any(s in k for s in non_lst): tgt_lst.append(k)\n",
        "    for i, (k,v) in enumerate(src_sd.items()):\n",
        "        if not any(s in k for s in non_lst): src_lst.append(k)\n",
        "\n",
        "    # tgt_optim_st, src_optim_st = tgt_optim.state_dict()['state'], src_optim.state_dict()['state']\n",
        "    tgt_optim_st, src_optim_st = tgt_optim_sd['state'], src_optim_sd['state']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, wht_name in enumerate(tgt_lst):\n",
        "            if not wht_name in src_lst: continue\n",
        "            tgt_wht, src_wht = tgt_optim_st[tgt_lst.index(wht_name)], src_optim_st[src_lst.index(wht_name)]\n",
        "            # print(wht_name, tgt_wht, src_wht)\n",
        "            tgt_shp, src_shp = tgt_wht['exp_avg'].shape, src_wht['exp_avg'].shape\n",
        "            if tgt_shp==src_shp:\n",
        "                tgt_wht = src_wht\n",
        "                continue\n",
        "            if tgt_shp[0] != src_shp[0]: continue # output dim diff\n",
        "            if len(tgt_shp)==2:\n",
        "                tgt_wht['step'] = src_wht['step']\n",
        "                tgt_wht['exp_avg'][:, :src_shp[1]] = src_wht['exp_avg'][:, :tgt_shp[1]]\n",
        "                tgt_wht['exp_avg_sq'][:, :src_shp[1]] = src_wht['exp_avg_sq'][:, :tgt_shp[1]]\n",
        "    # return tgt_optim.state_dict()\n",
        "    return tgt_optim_sd\n",
        "\n",
        "# model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "# model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "# source_optimizer = optim.AdamW(model_src.parameters())\n",
        "# target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "# dummy_input = torch.randn(3, 10)\n",
        "# dummy_target = torch.randn(3, 5)\n",
        "# criterion = torch.nn.MSELoss()\n",
        "# output = model_src(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# source_optimizer.step()\n",
        "\n",
        "# dummy_input = torch.randn(3, 20)\n",
        "# output = model_tgt(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# target_optimizer.step()\n",
        "\n",
        "\n",
        "# print(source_optimizer.state_dict())\n",
        "# print(target_optimizer.state_dict())\n",
        "\n",
        "# optimsd = transfer_optim(model_tgt.state_dict(), model_src.state_dict(), target_optimizer, source_optimizer)\n",
        "# target_optimizer.load_state_dict(optimsd)\n",
        "# print(target_optimizer.state_dict())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AfjFbveH64Io",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title TCost\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class TCost(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=256, drop=0.5): # in_dim=(1+self.jepa.pred.num_layers)*d_model\n",
        "        super().__init__()\n",
        "        self.tc = torch.tensor([-1., 0.], device=device).unsqueeze(-1) # unsqueeze(0).T\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Dropout(p=drop), nn.Linear(in_dim, 2)#, bias=False)\n",
        "            nn.Dropout(p=drop), nn.Linear(in_dim, 2, bias=False)\n",
        "            # nn.Dropout(p=drop), nn.Linear(in_dim, d_model), nn.ReLU(),\n",
        "            # nn.Dropout(p=drop), nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            # nn.Dropout(p=drop), nn.Linear(d_model, 2)\n",
        "            )\n",
        "        self.loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def update_loss_weight(self, train_data):\n",
        "        a = len(buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "        # self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device))\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device), reduction='none')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.softmax(self.tcost(x), dim=-1)@self.tc\n",
        "\n",
        "    def loss(self, x, y, reduction='mean'):\n",
        "        out = self.tcost(x)\n",
        "        y = torch.where(y < -0.5, 0, 1)\n",
        "        if reduction=='mean': return self.loss_fn(out, y).mean()\n",
        "        return self.loss_fn(out, y)\n",
        "\n",
        "\n",
        "# tcost=TCost(1024).to(device)\n",
        "# x=torch.randn((256,1024), device=device)\n",
        "# # import time\n",
        "# # start = time.time()\n",
        "# out=tcost(x).squeeze()\n",
        "# # out=tcost.tcost(x).squeeze()\n",
        "# print(out)\n",
        "# # out=F.gumbel_softmax(out)\n",
        "# print(time.time()-start)\n",
        "# # nn.AdaptiveLogSoftmaxWithLoss(in_features=2, n_classes=2, cutoffs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ILwCZmDU5wUQ"
      },
      "outputs": [],
      "source": [
        "# @title RNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# self.pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.3)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, num_layers=1, batch_first=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.fcin = nn.Linear(in_dim, d_model, bias=False)\n",
        "        # self.normin = nn.RMSNorm(d_model)\n",
        "        # self.normout = nn.RMSNorm(d_model)\n",
        "        self.act = nn.GELU() # GELU SiLU\n",
        "        self.num_layers = num_layers\n",
        "        # self.rnn = nn.GRU(d_model, d_model, num_layers=num_layers, batch_first=True, dropout=0.3)\n",
        "        self.rnn = nn.GRU(in_dim, d_model, num_layers=num_layers, batch_first=True, dropout=0.3)\n",
        "        # self.drop = nn.Dropout(.0)\n",
        "        self.fc = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.fc = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, h0=None,c0=None): # [batch_size, seq_len, in_dim]\n",
        "        # x = self.fcin(x)\n",
        "        # # x = self.drop(x)\n",
        "        # # x = self.normin(x)\n",
        "        # x = self.act(x)\n",
        "        out, h0 = self.rnn(x, h0) # [batch_size, seq_len, d_model], [num_layers, batch_size, d_model]\n",
        "        # out, _ = self.lstm(x, (h0,c0))\n",
        "        # out = out[:, -1, :] # [batch_size, d_model]\n",
        "        # out = self.drop(out)\n",
        "        out = self.fc(out) # [batch_size, seq_len, out_dim]\n",
        "        # out = self.normout(out)\n",
        "        out = self.act(out)\n",
        "        return out, h0\n",
        "\n",
        "# model = RNN(input_size, hidden_size).to(device)\n",
        "# print(model)\n",
        "# out, h0 = self.gru(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuA25qQknUAX",
        "outputId": "02f78a50-c970-4c5a-e4d1-ebb9f9e92af3",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-6656c27ad3bb>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model) # pixel\n",
        "        # self.enc = ConvEnc(d_model) #\n",
        "        # self.enc = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.enc.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "        # self.pred = nn.Sequential(\n",
        "        #     nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        # self.pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.3)\n",
        "        self.pred = RNN(d_model+dim_a+dim_z, d_model)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.GELU(), # ReLU GELU\n",
        "            nn.Linear(dim_v, dim_v), nn.GELU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=3e3, h0=None): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95))\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        for i in range(5): # 10\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sy_ = self.pred(sxaz)\n",
        "                sy_, _ = self.pred(sxaz, h0)\n",
        "                loss = lossfn(sy_, sy)# + self.z_coeff * torch.norm(z)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"argm\",i,loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "# torch.norm(z, dim=-1)\n",
        "# -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "# in RL, distribution of action, if certainty is high, entropy is low\n",
        "\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkI44ygzfxu",
        "outputId": "4ee04d39-4f36-4b45-9df0-19b330de4d24",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-a3510b4016a5>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=8, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.fc = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=3. # 10 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 1 # ν cov Covariance\n",
        "        self.closs_coeff=3. # 3\n",
        "        # self.zloss_coeff=0. # 10 1\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "        self.lx, self.lz = torch.empty((0,self.dim_a),device=device), torch.empty((0,self.dim_z),device=device) # [T,dim_az]\n",
        "        self.sx = self.jepa.enc(torch.zeros((1, 3,64,64))) # [1,d_model]\n",
        "        self.la = torch.empty(0,device=device) # []\n",
        "\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        if len(self.la)>1 or laction!=None:\n",
        "            self.update_h0(lstate, laction)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                self.sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(self.sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.la, self.lx, self.lz = lact, lx, lz\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                lsy = self.jepa.enc(torch.cat(lstate, dim=0))\n",
        "                # self.icost.update(sx)\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None: self.la = torch.cat([torch.tensor(laction, device=device), self.la[len(laction):]], dim=-1)\n",
        "                la = self.emb(self.la[:seq_len])\n",
        "\n",
        "        batch = 64 # 16\n",
        "        lz = nn.Parameter(torch.zeros((batch, seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5) # torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        # optim_z = torch.optim.SGD([lz], lr=1e0) # 1e0\n",
        "        optim_z = torch.optim.SGD([lz], lr=1e0, momentum=.3) # 1e0,.3\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-3, (0.9, 0.999)) # 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-1, (0.1, 0.5)) # 1e-3\n",
        "        lsy, la = lsy.detach(), la.detach() # [T, d_model], [T, dim_a]\n",
        "        lsx = torch.cat([self.sx, lsy[:-1]], dim=0) # [T, dim_a]\n",
        "        lsy, la, lsx = lsy.repeat(batch,1,1), la.repeat(batch,1,1), lsx.repeat(batch,1,1) # [batch, T, d_model], [batch, T, dim_a]\n",
        "        out_ = lsy - lsx\n",
        "\n",
        "        # print(\"update_h0 lz\", lz[0][0].data)\n",
        "        self.jepa.pred.train()\n",
        "        for i in range(5): # 1?\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1)#.unsqueeze(0) # [batch, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0.detach().repeat(1,batch,1)) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                # loss = ((lsy-out)**2).flatten(1).mean(-1) # [batch,seq_len,d_model] -> [batch]\n",
        "                loss = ((out_-out)**2).flatten(1).mean(-1) # [batch,seq_len,d_model] -> [batch]\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            # print(\"update_h0 loss, lz\",i,loss[0].item(), lz[0][0].data)\n",
        "            print(\"update_h0 loss\",i,loss[0].item())\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(\"loss\",loss.data)\n",
        "        idx = torch.argmax(loss, dim=0) # loss [batch*batch_, T] -> [batch_]\n",
        "        self.h0 = h0[:,idx]\n",
        "        self.sx = lsx[idx][-1].unsqueeze(0)\n",
        "        self.la, self.lx, self.lz = self.la[seq_len:], self.lx[seq_len:], self.lz[seq_len:] # [T], [T, dim_a], [T, dim_z]\n",
        "        return self.h0\n",
        "\n",
        "\n",
        "    def argm_s(self, sx, x, h0, zz=None): # [1, d_model], [batch_, T, dim_a], [num_layers, 1, d_model], zz[batch_,T, dim_z] # batch argm z for search\n",
        "        batch_, T, _ = x.shape\n",
        "        batch = 16 # 16\n",
        "        z = nn.Parameter(torch.zeros((batch*batch_, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # 1.:norm~1 ; 1.\n",
        "        optim_z = torch.optim.SGD([z], lr=1e3, momentum=0.999, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-1, (0.1, 0.5), maximize=True) # 1e-1, (0.1, 0.5)\n",
        "        with torch.no_grad():\n",
        "            z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch*batch_,1,1) # [batch*batch_, seq_len, dim_z]\n",
        "            if zz != None: z[:batch_]=zz #z[::batch]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, T, dim_a]\n",
        "        # print(\"argm_s\", z[0][0].squeeze())\n",
        "        for i in range(5): # 2 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward() # [batch, T]\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm_s z\", z[0][0].squeeze().data)\n",
        "            print(i, \"argm_s loss\", loss.sum(-1)[0].data)\n",
        "            # # print(torch.norm(z, dim=-1)) # all 1\n",
        "        idx = torch.argmax(loss.sum(-1).unflatten(0, (batch,batch_)), dim=0) # loss [batch*batch_, T] -> [batch_]\n",
        "        # print(\"argm_s loss[idx]\", loss[idx].sum().item())\n",
        "        return z.unflatten(0, (batch,batch_))[idx, torch.arange(batch_)]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch = 16 # 16\n",
        "        x = nn.Parameter(torch.zeros((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5) # .3\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e1, momentum=.7) # 1e-1,1e-0,1e4 ; 1e2 ; 1e1,.7\n",
        "        optim_x = torch.optim.AdamW([x], 1e-1, (0.1, 0.999)) # 1e-1 (0.1, 0.999)\n",
        "        with torch.no_grad(): x[:,:self.lx.shape[0]] = self.lx.repeat(batch,1,1)[:,:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        # print(\"search x\",x[0][0].squeeze().data)\n",
        "        z=None\n",
        "        z = torch.zeros((batch, T, self.dim_z),device=device)\n",
        "        for i in range(100):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [batch, T, dim_a]\n",
        "            # z = self.argm_s(sx, x_,h0,z) # [batch,T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # print(i, \"search x\", x[0][0].squeeze().data)\n",
        "            print(i, \"search loss\", loss.sum(-1)[0].data)\n",
        "\n",
        "            # reg\n",
        "\n",
        "            if i>=6: break # 5 10\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        idx = torch.argmin(loss.sum(-1)) # loss [batch, T]\n",
        "        dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2)[idx], dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        # print(lact.data)\n",
        "        # print(\"search loss[idx]\",loss[idx].sum().item())\n",
        "        return lact, lh0[:,:,idx], x.data[idx], z[idx] # [batch,T], [T, num_layers, batch, d_model], [batch,T, dim_a], [batch,T, dim_z]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz, h0, gamma=0.9): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        lsx, lh0 = self.rnn_it(sx, la, lz, h0)\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        syh0 = torch.cat([lsx, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,T,d_model], [T,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "        tcost = -self.tcost(syh0).unflatten(0, (batch, seq_len)).squeeze(-1)\n",
        "        c = (tcost + icost)*gamma**torch.arange(seq_len, device=device)\n",
        "        # if len(c.shape) == 1: print(\"rnn_pred c\", [f'{cc.item():g}' for cc in c.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        if len(tcost.shape) == 1: print(\"rnn_pred tcost\", [f'{cc.item():g}' for cc in tcost.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        return c, lh0\n",
        "\n",
        "    def rnn_it(self, sx, la, lz, h0): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        batch_ = batch//sx.shape[0]\n",
        "        sx, h0 = sx.repeat(batch_, 1), h0.repeat(1, batch_, 1)\n",
        "        lsx = torch.empty((batch, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1) # [batch, d_model+dim_a/z]\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            sx = sx + out.squeeze(1) # [batch,seq_len,d_model] # h0 = h0 +\n",
        "            # sx = out.squeeze(1) # [batch,1,d_model]\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        return lsx, lh0\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd): # best case z for train\n",
        "        # self.tcost.eval() # disable tcost dropout\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        batch = 64 # 64\n",
        "        lsy, la, rwd = lsy.repeat(batch,1,1), la.repeat(batch,1,1), rwd.repeat(batch,1) # [batch*batch_size, bptt, d_model], [batch*batch_size, d_model, dim_a], [batch*batch_size, bptt]\n",
        "        lz = nn.Parameter(torch.zeros((batch*batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.25/lz.shape[-1]**0.5) # .25?\n",
        "        # optim = torch.optim.SGD([lz], lr=1e2, momentum=.5) # 1e-2 1e3 1e2 1e1 1e2,.5\n",
        "        optim = torch.optim.AdamW([lz], 1e-2, (0.1, 0.9)) # 1e-1, (0.1, 0.5)\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(5): # 3 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lsy_, lh0 = self.rnn_it(sy_, la, lz, h0_)\n",
        "            # repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            repr_loss = ((lsy-lsy_)**2).unflatten(0, (batch,batch_size)).flatten(1).mean(-1)\n",
        "            syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch*batch_size,bptt,d_model], [bptt,num_layers,batch*batch_size,d_model] -> [batch*batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "            clossl = self.tcost.loss(syh0, rwd.flatten(), reduction='none').unflatten(0, (batch,batch_size*bptt)).mean(-1) # [batch*batch_size*bptt] -> [batch]\n",
        "            # z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"argm lz[0]\", i, lz[0][0].data)\n",
        "            # # print(i, repr_loss[0].item(), clossl[0].item())\n",
        "            # print(repr_loss.data, clossl.data)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(repr_loss.data, clossl.data)\n",
        "        # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        idx = torch.argmin(cost)\n",
        "        return lz.unflatten(0, (batch,batch_size))[idx].squeeze(0).detach()\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    # with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0.5)).mul_((torch.rand_like(lz)>0.1).bool()) # dropout without scaling\n",
        "                    with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0)).mul_((torch.rand_like(lz)>0.5).bool()) # dropout without scaling\n",
        "                    lsy_, lh0 = self.rnn_it(sy_.squeeze(1), la, lz, h0)\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                    # pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "                    # print(\"pred\",pred[0])\n",
        "                    # print(\"rwd\",rwd[0])\n",
        "                    # mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "                    # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # reprloss = ((lsy-lsy_)**2).mean(-1) # [batch_size, bptt]\n",
        "                    # print(\"reprloss\",reprloss[0])\n",
        "                    # mask = (reprloss>0.05)[0]\n",
        "                    # # imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[0][mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "                # torch.norm(lsy-torch.cat([sy_,lsy[:-1]], dim=1), dim=-1) # -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "                # prob = F.softmax(output, dim=-1)\n",
        "                # entropy = -torch.sum(prob * torch.log(prob + 1e-5), dim=-1)\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                norm = torch.norm(lsy[0][0], dim=-1).item()\n",
        "                z_norm = torch.norm(lz[0][-1], dim=-1)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                # print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                scaler.scale(loss).backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item(), \"z_norm\": z_norm.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "\n",
        "    def test_jepa(self, dataloader, bptt=25): #32\n",
        "        self.eval()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    lsy_, lh0 = self.rnn_it(sy_.squeeze(1), la, lz, h0)\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                norm = torch.norm(lsy[0][0], dim=-1).item()\n",
        "                z_norm = torch.norm(lz[0][-1], dim=-1)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                # print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                try: wandb.log({\"reprt\": repr_loss.item(), \"stdt\": std_loss.item(), \"covt\": cov_loss.item(), \"closst\": clossl.item()})\n",
        "                # try: wandb.log({\"reprt\": repr_loss.item(), \"stdt\": std_loss.item(), \"covt\": cov_loss.item(), \"closst\": clossl.item(), \"z_normt\": z_norm.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.999)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "# !pip show torch triton\n",
        "# # !pip install --upgrade torch\n",
        "# !pip install --upgrade triton\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "# print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "# print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "# print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fO_GAAWEy1v6"
      },
      "outputs": [],
      "source": [
        "batch, batch_ = 5,3\n",
        "idx = torch.randint(0, batch, (batch_,))\n",
        "print(idx)\n",
        "z=torch.rand(batch*batch_, 4)\n",
        "print(z)\n",
        "id= torch.arange(batch_)\n",
        "# print(z.unflatten(0, (batch,batch_))[idx, id])\n",
        "zz=torch.rand(batch_, 4)\n",
        "print(zz)\n",
        "z[::batch]=zz\n",
        "print(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVeF35lpwqlJ",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1b16fd5b-f616-42c9-a750-8bee255fae01"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9800ceaf3cec>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# for batch, (state, action, reward) in enumerate(train_loader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [num_layers, batch, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0msy_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, 1, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# state, action, reward = state.to(device), action.to(device), reward.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title test batch argm\n",
        "\n",
        "def argm(lsy, sy, h0, la, rwd): # best case z for train\n",
        "    # self.tcost.eval() # disable tcost dropout\n",
        "    batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "    batch = 16 # 16\n",
        "    lsy, la, rwd = lsy.repeat(batch,1,1), la.repeat(batch,1,1), rwd.repeat(batch,1) # [batch*batch_size, bptt, d_model], [batch*batch_size, d_model, dim_a], [batch*batch_size, bptt]\n",
        "    lz = nn.Parameter(torch.zeros((batch*batch_size, bptt, agent.dim_z), device=device))\n",
        "    torch.nn.init.normal_(lz, mean=0., std=.25/lz.shape[-1]**0.5)\n",
        "    # torch.nn.init.normal_(lz, mean=0., std=.1/lz.shape[-1]**0.5)\n",
        "    optim = torch.optim.SGD([lz], lr=1e1) # 1e-2 1e3 1e2 1e1\n",
        "    # optim = torch.optim.AdamW([lz], lr=1e-0) # 1e-2\n",
        "\n",
        "    # optim = torch.optim.AdamW([{'params': z, 'lr': 1e-1} for z in lz], (0.1, 0.5)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.1, 0.5)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.6, 0.9)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.7, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.8, 0.99)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-0, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "    lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "    for i in range(10): # 3 10\n",
        "        sy_, h0_ = sy.detach(), h0.detach()\n",
        "        lsy_, lh0 = agent.rnn_it(sy_, la, lz, h0_)\n",
        "        # repr_loss = F.mse_loss(lsy, lsy_)\n",
        "        repr_loss = ((lsy-lsy_)**2).unflatten(0, (batch,batch_size)).flatten(1).mean(-1)\n",
        "        syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch*batch_size,bptt,d_model], [bptt,num_layers,batch*batch_size,d_model] -> [batch*batch_size*bptt, (1+num_layers)*d_model]\n",
        "        # clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "        clossl = agent.tcost.loss(syh0, rwd.flatten(), reduction='none').unflatten(0, (batch,batch_size*bptt)).mean(-1) # [batch*batch_size*bptt] -> [batch]\n",
        "        z_loss = torch.abs(lz[0][0]).sum() # z_loss = torch.norm(z)\n",
        "        # print(\"z_loss\", i, lz[0][0].data, z_loss)\n",
        "        # print(\"z_loss\", i, lz[0].data, z_loss)\n",
        "        # print(i, repr_loss[0], clossl[0])\n",
        "        print(torch.norm(lz, dim=-1))\n",
        "        print(i, repr_loss.data, clossl.data)\n",
        "        cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "        # cost = repr_loss + clossl# + self.zloss_coeff * z_loss\n",
        "        cost.sum().backward()\n",
        "        # print(lz.grad[0][0].norm())\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(i, \"repr closs, lz\", torch.cat([torch.tensor([repr_loss[0], clossl[0]]), lz[0].cpu()],dim=-1).squeeze().data)\n",
        "    print(repr_loss[0].item(), clossl[0].item())\n",
        "    # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    idx = torch.argmin(cost)\n",
        "    return lz.unflatten(0, (batch,batch_size))[idx].squeeze(0).detach()\n",
        "\n",
        "# repr_loss, clossl untrained # 0.0850 # 0.6967\n",
        "# repr_loss, clossl trained # 0.0168, 0.4233\n",
        "\n",
        "# nn.HuberLoss() # near 0 is L2, outside is L1. less sensitive to outliers than L2? use like mse\n",
        "\n",
        "\n",
        "# # for batch, (state, action, reward) in enumerate(train_loader):\n",
        "# #     imshow(torchvision.utils.make_grid(state[0].cpu(), nrow=10))\n",
        "# #     break\n",
        "# it = iter(train_loader)\n",
        "# state, action, reward = next(it)\n",
        "# # imshow(torchvision.utils.make_grid(state[0].cpu(), nrow=10))\n",
        "\n",
        "\n",
        "# for batch, (state, action, reward) in enumerate(train_loader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "sy_ = agent.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "# state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "bptt=25#25\n",
        "for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        lsy = agent.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "        la = agent.emb(act) # [batch_size, bptt, dim_a]\n",
        "        # lz = argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "        lz = agent.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "    break\n",
        "# break\n",
        "# print(lz.squeeze().data)\n",
        "\n",
        "# import torch\n",
        "# la = torch.arange(15).reshape(3, 5)\n",
        "# la = la.repeat(2,1)\n",
        "# print(la)\n",
        "# print(la.unflatten(0, (2,3)))\n",
        "# # idx = torch.argmin(loss.unflatten(0, (batch_size,batch)), dim=1) # choose best x even with greatest adv z\n",
        "\n",
        "# 0.0120, grad_fn=<SelectBackward0>) tensor(0.0026\n",
        "# 0.01625952310860157 0.006073409225791693\n",
        "# 0.012133662588894367 0.002644716529175639\n",
        "\n",
        "# 1e-1, (0.6, 0.9) 0.012200677767395973 0.0026760129258036613   0.0070, 0.0015\n",
        "# 1e0, (0.6, 0.9) 0.01657252572476864 0.006728994660079479\n",
        "# 1e-1, (0.7, 0.95) 0.01258037332445383 0.0025434442795813084   0.0079, 0.0017\n",
        "# 1e-1, (0.8, 0.99) 0.01308276318013668 0.0030850034672766924   0.0087, 0.0018\n",
        "# 1e-1, (0.9, 0.999) 0.013740073889493942 0.0036710305139422417 0.0116, 0.0020\n",
        "# 1e0, (0.9, 0.999) 0.015708010643720627 0.003271286841481924\n",
        "\n",
        "# 0.0069, 0.0780\n",
        "# 0.0071], grad_fn=<MeanBackward1>) tensor([0.0019 ; 0.0071], grad_fn=<MeanBackward1>) tensor([0.0017\n",
        "# sgd 1e2 0.013228558003902435 0.006260296329855919 0.0065, 0.0014\n",
        "# sgd 1e3 0.01344290841370821 0.003109498880803585  0.0201, 0.0300\n",
        "# sgd 1e4 0.024299193173646927 0.04469054192304611\n",
        "# sgd 1e5 0.024356722831726074 0.04473479837179184\n",
        "\n",
        "\n",
        "# 1e-1, (0.3, 0.9) 0.011701214127242565 0.0031367409974336624\n",
        "# 1e-1, (0.4, 0.9) 0.011715513654053211 0.0027481389697641134\n",
        "# 1e-1, (0.5, 0.9) 0.01180238462984562 0.002659460064023733\n",
        "# 1e-1, (0.6, 0.9) 0.012142348103225231 0.0024781511165201664\n",
        "# 1e-1, (0.7, 0.9) 0.012586873024702072 0.0027804935816675425\n",
        "\n",
        "# 1e-1, (0.6, 0.8) 0.012026924639940262 0.0027117012068629265\n",
        "\n",
        "# 1e-1, (0.5, 0.7) 0.0068, 0.0009\n",
        "# 1e-1, (0.5, 0.8) 0.0065, 0.0015\n",
        "# 1e-1, (0.5, 0.9) 0.0073, 0.0010 0.0074, 0.0013\n",
        "# 1e-1, (0.5, 0.97) 0.0067, 0.0009 0.0080, 0.0016\n",
        "\n",
        "\n",
        "\n",
        "# 1e-1, (0.1, 0.5) 0.0066,0.0011; 0.0065,0.0013; 0.0062, 0.0015\n",
        "# 0.0075], grad_fn=<MeanBackward1>) tensor([0.0019\n",
        "# 1e-1, (0.1, 0.6) 0.0065,0.0012; 0.0067,0.0014; 0.0067,0.0010\n",
        "\n",
        "# 0.0007\n",
        "\n",
        "# 1e-2 0.0847, grad_fn=<SelectBackward0>) tensor(0.6741\n",
        "\n",
        "# 1e1,.0 9 tensor(0.0041, grad_fn=<SelectBackward0>) tensor(0.0012, grad_fn=<SelectBackward0>)\n",
        "# 1e1,.5 9 tensor(0.0040, grad_fn=<SelectBackward0>) tensor(0.0011, grad_fn=<SelectBackward0>)\n",
        "# 1e1,.9 9 tensor(0.0040, grad_fn=<SelectBackward0>) tensor(0.0009, grad_fn=<SelectBackward0>)\n",
        "# 1e1,.999 9 tensor(0.0042, grad_fn=<SelectBackward0>) tensor(0.0011, grad_fn=<SelectBackward0>)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49RERFWFMgA_"
      },
      "outputs": [],
      "source": [
        "# print(agent.jepa.enc.parameters().values()[0].requires_grad)\n",
        "# for name, param in agent.tcost.named_parameters():\n",
        "# # # for name, param in agent.named_parameters():\n",
        "# #     # print(name, param.requires_grad)\n",
        "#     print(name, param)\n",
        "\n",
        "# for name, param in agent.tcost.named_parameters(): print(param.data)\n",
        "# print(agent.tcost.1.weight.data)\n",
        "# print(agent.tcost.named_parameters()['tcost.1.weight'])\n",
        "# print(vars(agent.jepa.exp.named_parameters()['exp.1.weight']))\n",
        "\n",
        "for p,n in zip(rnn.parameters(),rnn._all_weights[0]):\n",
        "    if n[:6] == 'weight':\n",
        "        print('===========\\ngradient:{}\\n----------\\n{}'.format(n,p.grad))\n",
        "\n",
        "writer = torch.utils.tensorboard.SummaryWriter(\"runs/\")\n",
        "for name, param in model.named_parameters():\n",
        "        writer.add_histogram(name + '/grad', param.grad, global_step=epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEH1P802JkHU",
        "outputId": "9ec8ec34-cae1-45dd-f37a-d82c21b65326",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-118-568c189aaf97>:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-118-568c189aaf97>:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update_h0 loss, lz 0 0.004363055806607008 tensor([-0.0713,  0.0811,  0.1602,  0.0254, -0.0097, -0.0686,  0.0545,  0.1344])\n",
            "update_h0 loss, lz 1 0.0027771356981247663 tensor([-0.0646,  0.0743,  0.1532,  0.0319, -0.0164, -0.0617,  0.0614,  0.1411])\n",
            "update_h0 loss, lz 2 0.0019661574624478817 tensor([-0.0598,  0.0694,  0.1482,  0.0366, -0.0213, -0.0568,  0.0663,  0.1460])\n",
            "update_h0 loss, lz 3 0.001524916384369135 tensor([-0.0563,  0.0658,  0.1445,  0.0400, -0.0248, -0.0532,  0.0699,  0.1495])\n",
            "update_h0 loss, lz 4 0.0012645721435546875 tensor([-0.0537,  0.0631,  0.1418,  0.0425, -0.0274, -0.0506,  0.0725,  0.1521])\n",
            "loss tensor([0.0013, 0.0006, 0.0010, 0.0009, 0.0022, 0.0004, 0.0009, 0.0006, 0.0008,\n",
            "        0.0008, 0.0018, 0.0010, 0.0008, 0.0008, 0.0012, 0.0008, 0.0016, 0.0012,\n",
            "        0.0004, 0.0021, 0.0011, 0.0012, 0.0010, 0.0009, 0.0006, 0.0005, 0.0006,\n",
            "        0.0008, 0.0006, 0.0017, 0.0016, 0.0015, 0.0004, 0.0012, 0.0005, 0.0006,\n",
            "        0.0007, 0.0016, 0.0013, 0.0006, 0.0012, 0.0013, 0.0006, 0.0010, 0.0005,\n",
            "        0.0012, 0.0013, 0.0018, 0.0005, 0.0007, 0.0008, 0.0006, 0.0015, 0.0020,\n",
            "        0.0010, 0.0006, 0.0014, 0.0010, 0.0007, 0.0010, 0.0012, 0.0008, 0.0008,\n",
            "        0.0009])\n"
          ]
        }
      ],
      "source": [
        "# @title test agent act\n",
        "\n",
        "# dim_a, dim_z = 3, 8\n",
        "# batch, T = 4,6\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_a),device=device))\n",
        "# torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "# dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# x = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "# z = nn.Parameter(torch.zeros((batch, T, dim_z),device=device))\n",
        "# torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# state = torch.zeros((1, 3,64,64))\n",
        "# # state = torch.rand((1, 3,64,64), device=device)\n",
        "# sx = agent.jepa.enc(state)\n",
        "\n",
        "# it = iter(train_loader)\n",
        "# s, a, r = next(it)\n",
        "state = s[0][0].unsqueeze(0).to(device)\n",
        "agent.reset()\n",
        "act = agent([state], k=4)\n",
        "state = s[0][1:5].to(device)\n",
        "act = agent([s.unsqueeze(0) for s in state], k=4)\n",
        "# h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "# lact, lh0, lx, lz = agent.search(sx, T=6, h0=h0)\n",
        "# loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "# print(loss,c)\n",
        "# print(lact, lh0, lx, lz)\n",
        "\n",
        "# [6, 5, 4, 4, 6, 2] 0.9696626663208008\n",
        "# [6, 5, 4, 7, 6, 2]) 0.9663428664207458\n",
        "# [1.1180, 1.0691, 0.9897, 0.9656, 0.9760, 1.0352, 1.1865, 0.9776, 1.0289, 1.1148, 1.0500, 1.0257, 0.9723]\n",
        "# 1e-1, (0.1, 0.9) [1.1618, 0.9638, 1.0382, 1.1130, 1.0236, 0.9600, 1.0738, 1.0931, 1.0106, 0.9615, 0.9682, 0.9757, 0.9634]\n",
        "# search loss.sum tensor([1.2238, 1.1183, 1.3781, 1.1171, 1.0220, 1.3172, 1.0393, 1.1780, 1.2760])\n",
        "# search loss.sum tensor([1.1833, 1.1186, 0.9994, 1.1570, 1.1355, 1.2449, 1.1247, 1.0864, 1.1216])\n",
        "# 1e-1, (0.9, 0.999) [1.2336, 1.0372, 1.2104, 1.1552, 1.1631, 1.1355, 1.1355, 1.1828, 1.1648]\n",
        "# 1.0780, 0.9988, 0.9698, 1.0506, 0.9182, 1.0336, 1.0316, 1.0746, 1.0269]\n",
        "\n",
        "# # 1e-1, (0.1, 0.3) [0.9715, 1.0063, 1.0706, 0.9696, 0.9552, 1.0364, 0.9797, 1.0607, 1.0219]\n",
        "# [0.9764, 1.0664, 1.0225, 1.0212, 0.9708, 1.0481, 1.0137, 1.2192, 1.0950])\n",
        "# tensor([ 6, 11,  4,  7,  6,  2])\n",
        "# search loss[idx] 0.9707597494125366\n",
        "\n",
        "\n",
        "# 1e1, momentum=.0 [0.9720, 0.9751, 0.9707, 1.0203, 0.9752, 0.9754, 0.9792, 0.9843, 0.9779])\n",
        "# 1e1,.9 [0.9821, 1.0221, 1.0236, 0.9857, 1.0129, 0.9819, 1.0231, 0.9855, 0.9744]\n",
        "# 1e1,.5 [0.9750, 0.9819, 0.9720, 0.9727, 1.0492, 1.1431, 0.9818, 0.9738, 0.9724]\n",
        "# 1e1,.1 [0.9801, 1.0427, 1.0292, 0.9751, 0.9921, 1.0126, 0.9739, 0.9733, 0.9681]\n",
        "\n",
        "\n",
        "# [12,  2, 13,  6,  7,  2])# search loss[idx] 1.0242162942886353\n",
        "# 1e1,.0 tensor([12,  5, 13, 13,  0,  0]) search loss[idx] 1.0148924589157104\n",
        "\n",
        "# 1e1, (0.1, 0.3) [ 9,  5, 11,  4,  7,  5]) search loss[idx] 0.8813437223434448 [ 6,  5,  9, 11, 11, 14]) search loss[idx] 1.0106048583984375\n",
        "# [1.2524, 1.1733, 1.2672, 1.4926, 1.2828, 1.1139, 1.0241, 1.0392, 1.0212, 1.2391, 1.1198, 1.3839, 1.2508, 1.0636, 1.2459, 1.2499]\n",
        "# 1e0, (0.1, 0.9) [0.9938, 1.1715, 1.0707, 1.1385, 0.9807, 1.0192, 0.9877, 1.1334, 1.1742, 1.3075, 1.0620, 1.2562, 1.1120, 1.1075, 1.0227, 0.9718])\n",
        "# 1e-1, (0.9, 0.9) [1.2246, 1.2571, 1.2877, 1.1991, 1.0697, 1.3019, 1.1740, 1.1950, 1.2564, 1.2413, 1.2670, 1.1604, 1.2582, 1.2152, 1.2209, 1.1972])\n",
        "# tensor([ 6,  2,  7,  6, 11,  8])\n",
        "\n",
        "# update_h0 loss, lz 0 0.0011654631234705448 tensor([[-0.0977,  0.1298,  0.2779,  0.1330,  0.0029,  0.0278, -0.0582,  0.0025]])\n",
        "# update_h0 loss, lz 0 0.0003931076789740473 tensor([[ 0.0144, -0.0157, -0.0158,  0.0143, -0.0145,  0.0147,  0.0153,  0.0147]])\n",
        "# update_h0 loss, lz 9 0.0003664720570668578 tensor([[ 0.0039, -0.0050, -0.0049,  0.0041, -0.0040,  0.0039,  0.0048,  0.0042]])\n",
        "\n",
        "# update_h0 loss, lz 9 0.00036650229594670236 tensor([[ 0.0041, -0.0049, -0.0047,  0.0044, -0.0042,  0.0040,  0.0048,  0.0044]])\n",
        "# update_h0 loss, lz 9 0.0003664720570668578 tensor([[ 0.0039, -0.0050, -0.0049,  0.0041, -0.0040,  0.0039,  0.0048,  0.0042]])\n",
        "# update_h0 loss, lz 4 0.00036711347638629377 tensor([[ 0.0048, -0.0058, -0.0057,  0.0050, -0.0049,  0.0049,  0.0056,  0.0051]])\n",
        "# update_h0 loss, lz 4 0.00036707421531900764 tensor([[-0.0148, -0.0120,  0.0243,  0.0181, -0.0427, -0.0563,  0.0583, -0.0059]])\n",
        "# update_h0 loss, lz 4 0.000381751247914508 tensor([[ 0.2584, -0.0135,  0.1350, -0.0565, -0.0178, -0.1457,  0.1509, -0.0498]])\n",
        "\n",
        "# loss tensor([0.0008, 0.0020, 0.0012, 0.0006, 0.0006, 0.0010, 0.0006, 0.0009, 0.0005,\n",
        "# loss tensor([0.0009, 0.0008, 0.0015, 0.0021, 0.0005, 0.0006, 0.0007, 0.0009, 0.0022,\n",
        "# loss tensor([0.0020, 0.0014, 0.0041, 0.0077, 0.0009, 0.0022, 0.0018, 0.0012, 0.0017,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "4_b7ZSW6IF1-"
      },
      "outputs": [],
      "source": [
        "# @title gdown\n",
        "# !gdown 1bGWBbcKUgHESkbD3NfYt1WWikScVSFOj -O agentoptim.pkl # M1 gru3 tcost1\n",
        "# !gdown 1XBDhD2efIFW9lnewGRLrb362w47a8b1q -O agentoptim.pkl # B2 gru3 tcost1\n",
        "# !gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3\n",
        "# !gdown 1zoZ52jctM0jed6TgD7kAwrtnuDMeA5II -O agentoptim.pkl # T4 gru1 tcost1 drop\n",
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "# !gdown 1UDgNtFsWGAhvqR9lwA0QbMLhUtmip4ne -O agentoptim.pkl # M1 agentoptimgru3tcost1\n",
        "# !gdown 1-0oc6yucS5JXLHX1zqbYe3NTVMuhP_5r -O agentoptim.pkl # A2 agentoptim25251c25z3\n",
        "# !gdown 1U1CuCU1FugkrzPXsvTPpIX-wzWz6szl2 -O agentoptim.pkl # T4 agentoptimargm\n",
        "# !gdown 1CWZAtiEwSnglClJbq2LJTYlKhPN10gfo -O agentoptim.pkl # S3 agentoptimargm\n",
        "# !gdown 1XAbr6l1pCmcUCKR6kYlQ_dSDsOBqRg_j -O agentoptim.pkl # B2 argm2search2\n",
        "# !gdown 1UkQuf-IC2LYErSapkF6rZM1dv3svGI5P -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1-4sNf6mINCiD5YsBdQvCrlyqzzfS64si -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1MV9Qj_53Vu6wpe7nOFn47M5vDj7F7-gv -O agentoptim.pkl # S3 agentoptimargm2\n",
        "# !gdown 1--1Vl3337zugQng-j1qbptFY8EvhZA-T -O agentoptim.pkl # T4 agentoptimargm3 online\n",
        "# !gdown 1XHFBVPSH4T4FpUOBKN8X20xDQLNmL7go -O agentoptim.pkl # M1 agentoptimargm4\n",
        "# !gdown 1fFXsee_cSZxhTRewD7ZkGT68NXeq8OcH -O agentoptim.pkl # B2 agentoptimargm4\n",
        "# !gdown 1H31OMz5YBPfmgb7yxVePGddljS9cwVOF -O agentoptim.pkl # B2 agent_nores1\n",
        "# !gdown 1tZpMKsMz7Bh3-X7WE49dsySs-2XOk6Wc -O agentoptim.pkl # T4 agentgru3tcost3\n",
        "# !gdown 1Dsz-poj8y6j_AatGvc4jSu6JWpdPzK0p -O agentoptim.pkl # S3 agentcovgru1fctcost1drop512\n",
        "# !gdown 1U3Go8OzoOzIkPEiS_aAlgpzWNt6Xgdal -O agentoptim.pkl # T4 agent30313res\n",
        "\n",
        "\n",
        "# !gdown 1sCW9uvcdCJkCH5HQDdISLws5rMvmkmFR -O all_sd.pkl # M1 all_sd\n",
        "\n",
        "import pickle\n",
        "# !gdown 1j9hOq8_752duPB0PMYUJqabNvYoGLysX -O buffer512down.pkl # S\n",
        "# with open('buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY -O buffer512.pkl # S\n",
        "# with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB -O buffergo.pkl # S3\n",
        "# !gdown 1egXy0t_kn0M0oL6sbwixoVr7bqMfcB8j -O buffergo.pkl # T4\n",
        "# !gdown 1-34fhOMTdMvtuAeHuL28Y4taSINvOejQ -O buffergo.pkl # B2\n",
        "with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "553bbaa1-006a-4c89-fd36-1c58673bcc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "# with open(folder+'buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# # modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# # _, convert = rename_sd(agent.state_dict())\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# # modelsd = transfer_sd(agentsd, modelsd)\n",
        "# # modelsd = transfer_sd(agent.state_dict(), modelsd)\n",
        "# agent.load_state_dict(modelsd, strict=False)\n",
        "# # # optimsd = transfer_optim(agent.state_dict(), modelsd, optim.state_dict(), optimsd)\n",
        "# optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = torch.load(folder+'all_sd.pkl', map_location=device)\n",
        "# # all_sd = torch.load('all_sd.pkl', map_location=device)\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in all_sd.items())\n",
        "# allsd = {}\n",
        "# for (k, v) in all_sd.items():\n",
        "#     try: allsd[convert[k]] = v\n",
        "#     except Exception as e: print('dict err', e)\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# tgt_sd = load_sd(agent.state_dict(), allsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# for i, (k,v) in enumerate(modelsd.items()):\n",
        "# for i, (k,v) in enumerate(agent.state_dict().items()):\n",
        "#     print(i,k,v.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZBfBomEBnJu0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "760d2514-27da-4a91-b38f-a9d39f5d02a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'folder' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-0f056159ebe1>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# torch.save(checkpoint, folder+'agentgru3tcost3.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'agent3113rnninout.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# torch.save(checkpoint, 'agentoptim.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'folder' is not defined"
          ]
        }
      ],
      "source": [
        "# buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# checkpoint = {'model': agentsd, 'optimizer': optim.state_dict(),}\n",
        "checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentgru3tcost3.pkl')\n",
        "torch.save(checkpoint, folder+'agent3113rnninout.pkl')\n",
        "# torch.save(checkpoint, 'agentoptim.pkl')\n",
        "\n",
        "# all_sd = {}\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# all_sd = store_sd(all_sd, agentsd)\n",
        "# # torch.save(all_sd, 'all_sd.pkl')\n",
        "# torch.save(all_sd, folder+'all_sd.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3f5hTNB0f7_W"
      },
      "outputs": [],
      "source": [
        "# print(len(buffer)) # 1159\n",
        "# buffer1=buffer[:512]\n",
        "# # buffer2=buffer[512:]\n",
        "# buffer2=buffer[512:640]\n",
        "# # # buffer=buffer1\n",
        "buffer1=buffer[:-128]\n",
        "buffer2=buffer[-128:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "NVcknabHMxH6"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in self.process(buffer) for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def process(self, buffer):\n",
        "        cleaned = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "        cleaned = [episode[-random.randint(20, 100):] for episode in cleaned]\n",
        "        random.shuffle(cleaned)\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "\n",
        "    # def pop_unif(self, buffer_, n=3):\n",
        "    #     buffer_.pop(random.randrange(len(buffer_)))\n",
        "    #     return buffer_\n",
        "\n",
        "# while len(train_data.data)>10000:\n",
        "#     buffer.pop(random.randrange(len(buffer)))\n",
        "#     train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 128 #128\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True)\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # # [3,T,batch]\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1e3fpbtNOiz1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06fc59c-b21f-47df-b700-63ccf4133a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.,  0.,  0., -1.,  0., -1.,  0., -1.,  0.,  0.])\n",
            "tensor([ 0.,  0., -1.,  0.,  0., -1.,  0.,  0., -1., -1.])\n",
            "tensor([-1.,  0., -1., -1.,  0.,  0., -1.,  0.,  0., -1.])\n",
            "tensor([ 0., -1., -1., -1., -1.,  0.,  0.,  0., -1.,  0.])\n",
            "tensor([-9.3997e-01, -3.8775e-01, -2.9575e-04, -9.9318e-01, -6.9665e-04,\n",
            "        -9.5636e-01, -6.9154e-04, -9.6287e-01, -1.5436e-01, -7.5913e-04])\n",
            "tensor([-0.2185, -0.0014, -0.9003, -0.0344, -0.0016, -0.9849, -0.0290, -0.0060,\n",
            "        -0.8436, -0.9866])\n",
            "tensor([-5.1347e-01, -6.4734e-04, -9.6657e-01, -9.5203e-01, -2.4150e-03,\n",
            "        -4.8795e-01, -8.0988e-01, -1.1452e-03, -2.7982e-03, -9.6281e-01])\n",
            "tensor([-1.1662e-02, -9.8781e-01, -9.3918e-01, -9.8854e-01, -9.1996e-01,\n",
            "        -3.1383e-03, -3.6186e-02, -5.6972e-04, -9.0578e-01, -8.0936e-04])\n",
            "tensor(2.8577, device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "tensor(0.0201)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "reward, pred tensor([]) tensor([])\n"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# data = [step for episode in buffer for step in episode]\n",
        "data = [step for episode in buffer1 for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "ctrain_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    ctrain_data=list(zip(state,reward))\n",
        "    ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "trainiter = iter(c_loader)\n",
        "images, labels = next(trainiter)\n",
        "# images, labels = images.to(device), labels.to(device)\n",
        "batch=min(40, batch_size)\n",
        "images, labels = images[:batch], labels[:batch]\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# print(labels)\n",
        "for x in range(len(labels)//10):\n",
        "    print(labels[10*x:10*x+10])\n",
        "\n",
        "# # try:\n",
        "with torch.no_grad():\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "    # _, world_state = agent.get(images.to(device))\n",
        "    # pred = agent.tcost(agent.jepa.enc(world_state.unsqueeze(1))).squeeze(-1).cpu()\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch, agent.d_model), device=device)\n",
        "    # h0 = torch.empty((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device)\n",
        "    # torch.nn.init.xavier_normal_(h0)\n",
        "    sy = agent.jepa.enc(images.to(device)) # [batch_size, d_model]\n",
        "    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "    pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "\n",
        "    # print(pred)\n",
        "    for x in range(len(pred)//10):\n",
        "        print(pred[10*x:10*x+10])\n",
        "    # print((labels==pred).sum())\n",
        "# except: pass\n",
        "print(agent.tcost.loss(syh0, labels.to(device)).squeeze(-1))\n",
        "print(F.mse_loss(labels, pred))\n",
        "\n",
        "# torch.where(abs(labels- pred)>0.5,1,0)\n",
        "for x in range(len(pred)//10):\n",
        "    print(torch.where(abs(labels- pred)>0.5,1,0)[10*x:10*x+10])\n",
        "\n",
        "# mask = torch.where(abs(labels- pred)>0.5,1,0).bool()\n",
        "mask = (abs(labels- pred)>0.5)\n",
        "print(\"reward, pred\", labels[mask].data, pred[mask].data)\n",
        "try: imshow(torchvision.utils.make_grid(images[mask], nrow=10))\n",
        "except ZeroDivisionError: pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksm4ha7XA-BN"
      },
      "outputs": [],
      "source": [
        "# optim = torch.optim.SGD(agent.parameters(), 1e-1, momentum=0.9, dampening=0, weight_decay=0)\n",
        "# print(optim.param_groups[0][\"lr\"])\n",
        "# print(optim)\n",
        "optim.param_groups[0][\"lr\"] = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "iGYjyJZ5aG5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "cellView": "form",
        "outputId": "3481f6b8-850d-4fba-e9cb-1a4e5b4751be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "## train ##\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-a3510b4016a5>:260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 127.06 MiB is free. Process 225773 has 14.62 GiB memory in use. Of the allocated memory 12.70 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-9609b4beedc8>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## train ##\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_jepa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## test ##\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-a3510b4016a5>\u001b[0m in \u001b[0;36mtrain_jepa\u001b[0;34m(self, dataloader, optim, bptt)\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mlsy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, bptt, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, bptt, dim_a]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                     \u001b[0mlz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, bptt, d_model],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0.5)).mul_((torch.rand_like(lz)>0.1).bool()) # dropout without scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dropout without scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-a3510b4016a5>\u001b[0m in \u001b[0;36margm\u001b[0;34m(self, lsy, sy, h0, la, rwd)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 3 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0msy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mlsy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;31m# repr_loss = F.mse_loss(lsy, lsy_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mrepr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlsy_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-a3510b4016a5>\u001b[0m in \u001b[0;36mrnn_it\u001b[0;34m(self, sx, la, lz, h0)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch,seq_len,d_model] # h0 = h0 +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# sx = out.squeeze(1) # [batch,1,d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mlsx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlsx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, T, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0mlh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [seq_len, num_layers, batch, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlsx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlh0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 127.06 MiB is free. Process 225773 has 14.62 GiB memory in use. Of the allocated memory 12.70 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    # plt.figure(figsize=(4, 4))\n",
        "    plt.figure()\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(100):\n",
        "    print(i)\n",
        "    train_data = BufferDataset(buffer1, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    test_data = BufferDataset(buffer2, seq_len) # one line of poem is roughly 50 characters\n",
        "    test_loader = DataLoader(test_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    print(\"## train ##\")\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    print(\"## test ##\")\n",
        "    agent.test_jepa(test_loader)\n",
        "\n",
        "    # checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    # # # # torch.save(checkpoint, folder+'agentgru3tcost3.pkl')\n",
        "    # # # torch.save(checkpoint, folder+'agentcovgru1tcost3drop.pkl')\n",
        "    # torch.save(checkpoint, folder+'agent30313res.pkl')\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "# batch64 28m58s 84\n",
        "\n",
        "\n",
        "# repr, std, cov, clossl, z, norm 0.005674966610968113 0.3493117690086365 0.1219848245382309 0.11347860097885132 0.16498714685440063 1.429775595664978\n",
        "# repr, std, cov, clossl, z, norm 0.004161856137216091 0.35110002756118774 0.10768019407987595 0.14673584699630737 0.17844633758068085 8.552577018737793\n",
        "# repr, std, cov, clossl, z, norm 0.005356341600418091 0.354144811630249 0.10272272676229477 0.14740866422653198 0.1459342986345291 0.08476211130619049\n",
        "\n",
        "\n",
        "# repr, std, cov, clossl, z, norm 0.03280682861804962 0.3602587580680847 0.0940496101975441 12.544517517089844 0.0145032973960042 0.10470973700284958\n",
        "# repr, std, cov, clossl, z, norm 0.0022784259635955095 0.37327876687049866 0.12404247373342514 5.347583770751953 0.0835014060139656 0.7087528705596924\n",
        "# repr, std, cov, clossl, z, norm 0.005345265381038189 0.34533047676086426 0.4332529306411743 2.4848036766052246 0.12125874310731888 0.9996055960655212\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "043cebd2-5381-4dae-9e5c-09305911841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "# ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n",
        "\n",
        "\n",
        "# # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "# 2  5/11 8\n",
        "# 1/10 4 7/9\n",
        "# 0  3/12 6\n",
        "\n",
        "# 13 11 14\n",
        "# 10 12 9\n",
        "\n",
        "# from gymnasium.wrappers import TimeLimit\n",
        "from gym.wrappers import TimeLimit\n",
        "env = TimeLimit(env, max_episode_steps=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PraFUAPB3j7v"
      },
      "outputs": [],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# print(env.action_space) # 15\n",
        "\n",
        "def simulate(agent, buffer=[], k=4):\n",
        "    # agent.eval()\n",
        "    out=None\n",
        "    writer = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # writer = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    act_list=[]\n",
        "    lstate=[]\n",
        "    # h0 = torch.randn((agent.jepa.pred.num_layers, agent.d_model), device=device)\n",
        "    while True:\n",
        "    # for i in range(400):\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        # if len(act)<=0: act = agent(state).cpu()[0,:4].tolist()\n",
        "        # print(act.shape, h0.shape) # [1, 6], [1, 256]\n",
        "        lstate.append(state)\n",
        "        if len(act)<=0:\n",
        "            # lact, lh0, lx, lz = agent(state, h0)\n",
        "            # act = lact.cpu()[0,:k].tolist()\n",
        "            # act = agent(state, k)\n",
        "            act = agent(lstate, k=k)\n",
        "            lstate=[]\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        # print(i, 'act: ',action, 'reward: ',reward)\n",
        "        act_list.append(action)\n",
        "        writer.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"dided\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    print(act_list)\n",
        "    env.close()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO"
      },
      "outputs": [],
      "source": [
        "# @title alllll\n",
        "for i in range(200):\n",
        "    # print(\"#### simulate ####\")\n",
        "    # buffer_=[]\n",
        "    for _ in range(5):\n",
        "        buffer = simulate(agent, buffer)\n",
        "        # buffer_ = simulate(agent, buffer_)\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len)\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    torch.save(checkpoint, folder+'agentgru1tcost3goscratch.pkl')\n",
        "\n",
        "    # buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "    with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "    print(\"train_data.data\",len(train_data.data))\n",
        "    while len(train_data.data)>10000: # 10000:6.9gb, 20000:5.5gb\n",
        "        buffer.pop(random.randrange(len(buffer)))\n",
        "        train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8zxYU9jpE8K"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "4de768d8-efa9-4288-f230-e19675effd56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:gqwusltz) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>closs</td><td>▇█▇▆▆▆▅▇▅▆▅▅▅▅▅▅▄▄▃▃▃▂▂▃▃▂▂▁▁▂▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>closst</td><td>█▇▅▃▂▂▂▂▁▁▂▂▂▃▂▂▂▃▂▂▂▁▂▂▃▁▁▂▂▂▂▃▁▂▃▁▂▂▃▂</td></tr><tr><td>cov</td><td>▁▂▃▃▂▆▂▆▅▄▆▆▄▄▅▆▆▆▇▆▇█▅▄▆▆▆▇▇█▇▇▇▇▆▇█▇▇▇</td></tr><tr><td>covt</td><td>▃▄▆▄▄▁▆▆▂▅▂█▇▄▄▆▆▄▇█▄▄▅▅▃▅▄▃▄▄▆▄▅▅▅▅▅▅▄▄</td></tr><tr><td>repr</td><td>▁▄▃▄▄▄▄▅▅▆▅▄▆▄▅█▆▇▆▇▇▇▇▆▅▆▆▅▆▆▆▅▅▅▅▄▄▄▄▃</td></tr><tr><td>reprt</td><td>▁▁▂▁▃▃▂▂▂▂▂▂▂▃▃▂▂▃▃▃▃▄▅▄▅▃▄▄█▃▃▆▇▆▅▇▃▆▆▄</td></tr><tr><td>std</td><td>██▇▇▆▇▇▆▆▆▅▄▅▄▅▃▃▃▃▃▂▃▃▃▂▂▂▂▁▂▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>stdt</td><td>███▆▆▆▆▆▆▆▅▅▅▄▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▂▂▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>closs</td><td>0.20651</td></tr><tr><td>closst</td><td>0.47918</td></tr><tr><td>cov</td><td>0.02466</td></tr><tr><td>covt</td><td>0.03725</td></tr><tr><td>repr</td><td>0.01521</td></tr><tr><td>reprt</td><td>0.04679</td></tr><tr><td>std</td><td>0.39966</td></tr><tr><td>stdt</td><td>0.39282</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">daily-serenity-168</strong> at: <a href='https://wandb.ai/bobdole/procgen/runs/gqwusltz' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/gqwusltz</a><br/> View project at: <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241104_074350-gqwusltz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:gqwusltz). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241104_081504-ryf0ukwu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/ryf0ukwu' target=\"_blank\">avid-serenity-169</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/ryf0ukwu' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/ryf0ukwu</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(project=\"procgen\",\n",
        "    config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xLh80kPvEzwX"
      },
      "outputs": [],
      "source": [
        "# @title agent pixel save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.emb = torch.nn.Embedding(15, dim_a) # env.action_space # 15\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        for i in range(20): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "\n",
        "            dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "\n",
        "            # loss, sx_ = self.rnn_pred(sx_, x)\n",
        "            loss, sx_ = self.rnn_pred(sx_, x_)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(syaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb #+ clossl\n",
        "\n",
        "                    loss = loss + jloss + closs #+ conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sy_ = sy_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29O1eyvhnRSD",
        "outputId": "c470e601-d5da-4b94-bb69-928dd9d823af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-77-bbc83a6aed37>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=2. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        # 0.0083 0.06 1.0 = 1, 7, 120.5\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        optim_z = torch.optim.SGD([z], lr=1e2, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.95)) #\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.data)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i,x.data, z.squeeze(), loss.item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        # print(\"search\",loss.item())\n",
        "        return lact#, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        _,T,_ = sx.shape\n",
        "        batch = 1\n",
        "        lr = 1e-1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                x[:,:self.lx.shape[1]] = self.lx[:,:T]\n",
        "                z[:,:self.lz.shape[1]] = self.lz[:,:T]\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            # print(i,x.data, z.squeeze(), loss.item())\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        return lact, lh0, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, gamma=0.9): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sx = self.jepa.pred(sxaz)\n",
        "                sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        # if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            # loss=0\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(syaz)\n",
        "                    sy_ = sy_ + self.jepa.pred(syaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # cost loss\n",
        "                    reward_ = self.tcost(sy_).squeeze(-1) # [batch_size]\n",
        "                    clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    _, st = self.get(st, world_state=world_zero)\n",
        "                    # print(\"stt\",st.shape)\n",
        "                    stt = self.tcost(self.jepa.enc(st.unsqueeze(1))).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb + clossl\n",
        "\n",
        "                    # loss = loss + jloss + closs\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    # loss=0\n",
        "                else:\n",
        "                    scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mY7BITKjSKC",
        "outputId": "cbad0ffc-e8e9-4a4d-bd3c-d6d9ddaf6e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2336301\n",
            "1278976\n",
            "399360\n",
            "1024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-76-e20d23bca149>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=3, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v, drop=0.2)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=50. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # e = d_model**-0.5\n",
        "        # self.h0 = torch.empty((self.jepa.pred.num_layers, 1, d_model), device=device).uniform_(-e, e) # [num_layers, batch, d_model]\n",
        "        # self.h0 = torch.normal(mean=0, std=e, size=(self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # torch.nn.init.xavier_uniform_(self.h0) # xavier_uniform_, kaiming_normal_\n",
        "\n",
        "        # self.lx, self.lz = torch.empty(1,0,dim_a), torch.empty(1,0,dim_z)\n",
        "        self.lx, self.lz = None, None\n",
        "        state = torch.zeros((1, 3,64,64), device=device)\n",
        "        self.sx = self.jepa.enc(state)\n",
        "\n",
        "    # def forward(self, state, k=1): # live run in env # np (64, 64, 3)\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        self.update_h0(lstate, laction)\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "            # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.h0=lh0[k].unsqueeze(1) # [num_layers, 1, d_model]\n",
        "        # self.lx, self.lz = lx[:,k:], lz[:,k:] # [batch, T, dim_a], [batch, T, dim_z]\n",
        "        self.lx, self.lz = lx[k:], lz[k:] # [T, dim_a], [T, dim_z]\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "\n",
        "                # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "                # print(torch.cat(lstate, dim=0).shape)\n",
        "                # lsx = self.jepa.enc(torch.stack(lstate, dim=0))#.unsqueeze(0)\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx-torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                # batch, seq_len, _ = lstate.shape\n",
        "                # seq_len, _ = lstate.shape\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    try: la = self.emb(self.la[:seq_len])\n",
        "                    except:\n",
        "                        print(\"err self.la\")\n",
        "                        # la = self.emb([0]*seq_len)\n",
        "                        la = self.emb(torch.zeros(seq_len, dtype=int, device=device))\n",
        "\n",
        "        # lz = nn.Parameter(torch.zeros((batch, seq_len, self.dim_z),device=device))\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        # optim_z = torch.optim.SGD([lz], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([lz], 1e0, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "\n",
        "        for i in range(20): # num epochs\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                # print(sxaz.shape, self.h0.shape)\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                # sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                loss = F.mse_loss(out_, out)\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            print(lz.data)\n",
        "            with torch.no_grad(): lz.clamp_(min=-1, max=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1]\n",
        "        self.la = la[k:]\n",
        "        return h0\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                # x[:,:self.lx.shape[1]], z[:,:self.lz.shape[1]] = self.lx[:,:T], self.lz[:,:T]\n",
        "                x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].repeat(batch,1,1), self.lz[:T].repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            # print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            # print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i, \"loss\", loss.squeeze().data)\n",
        "            # print(x.shape,torch.argmax(-dist,dim=-1).shape,z.shape,loss.shape) # [16, 6, 3], [16, 6], [16, 6, 1], [16, 1]\n",
        "            # print(i, torch.cat([x,torch.argmax(-dist,dim=-1),z],dim=-1).squeeze().data)\n",
        "            print(i, \"x act z\", torch.cat([x[0],torch.argmax(-dist,dim=-1)[0].unsqueeze(-1),z[0]],dim=-1).squeeze().data)\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, t, dim_a], [batch, t, dim_z]\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        x = nn.Parameter(torch.empty((T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        optim_x = torch.optim.SGD([x], lr=1e3) # 1e-1,1e-0,1e4 ; 1e2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        with torch.no_grad(): x[:self.lx.shape[0]] = self.lx[:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        # print(\"search x\",x.squeeze().data)\n",
        "        for i in range(2): # 5\n",
        "            dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0) # [T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_.unsqueeze(0), z.unsqueeze(0), h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i, \"search x loss\", x.squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        return lact, lh0, x.data, z # [T], [T, num_layers, batch, d_model], [T, dim_a], [T, dim_z]\n",
        "\n",
        "\n",
        "    def search_optimxz(self, sx, T=6, h0=None):\n",
        "        self.eval()\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 4 # 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1 ; sgd\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_uniform_(z) # xavier_normal_, xavier_uniform_\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        # optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e1, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].unsqueeze(0).repeat(batch,1,1), self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        print(\"search\", z[0].squeeze())\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        for i in range(10): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, lsx, lh0,c = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.sum().backward()\n",
        "            # optim_x.step(); optim_z.step()\n",
        "            # optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            print(i, \"search loss\", loss.squeeze().data)\n",
        "            # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "            print(i, \"search z\", z[0].squeeze().data)\n",
        "            # print(torch.argmin(dist,dim=-1).int())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        print(\"c\",torch.stack(c)[:,idx])\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "\n",
        "    def argm_s(self, sx, x, h0): # [1, d_model], [batch_, T, dim_a], [num_layers, 1, d_model] # batch argm z for search\n",
        "        batch_, T, _ = x.shape\n",
        "        batch = 16 # 16\n",
        "        # z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        z = nn.Parameter(torch.zeros((batch*batch_, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        optim_z = torch.optim.SGD([z], lr=1e4, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # with torch.no_grad(): z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_z]\n",
        "        with torch.no_grad(): z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch*batch_,1,1) # [batch, seq_len, dim_z]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, T, dim_a]\n",
        "        # print(\"argm\", z[0].squeeze())\n",
        "        for i in range(2): # 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm z loss\", z[0].squeeze().data, loss[0].squeeze().data)\n",
        "        # idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        idx = torch.argmin(loss.sum(-1).unflatten(0, (batch,batch_)), dim=0) # loss [batch*batch_, T]\n",
        "        return torch.index_select(z, 0, idx) # [batch_, T,dim_z]\n",
        "\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # cost += tcost + icost\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "        c=[]\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            # print(sx.shape, a.shape, z.shape)\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            c.append(tcost)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    # imshow(state[0].cpu())\n",
        "                    # print(\"norm\", torch.norm(sy[0]-sy_[0], dim=-1))\n",
        "                    # # if torch.norm(sy[0]-sy_[0], dim=-1) > 1:\n",
        "                    # print(i, reward[0])\n",
        "                    # print(sy)\n",
        "                    # print(sy_)\n",
        "                    # print(sy[0]-sy_[0])\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "\n",
        "                    # cost loss\n",
        "                    # syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = 100*clossl\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batc h_size, d_model]\n",
        "            # sx=sy_\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "\n",
        "                    # z = self.jepa.argm(sy_, a, sy)\n",
        "                    z = self.argm(sy, sy_, h0, a, reward)\n",
        "                    with torch.no_grad(): z.mul_(torch.rand_like(z)).mul_((torch.rand_like(z)>0.5).bool()) # dropout without scailing\n",
        "\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "\n",
        "                    # cost loss\n",
        "                    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    # syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = self.closs_coeff * clossl\n",
        "\n",
        "                    # print(h0.requires_grad)\n",
        "                    # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "                    # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "                    # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # torch.norm(sy-sx, dim=-1)\n",
        "                    # sx=sy\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    norm = torch.norm(sy, dim=-1)[0].item()\n",
        "                    z_norm = torch.norm(z)\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "\n",
        "                # lh0 = torch.zeros((rwd.shape[1],)+h0.shape, device=device)\n",
        "                # lz = torch.zeros((lsy.shape[0], lsy.shape[1], self.dim_z), device=device)\n",
        "                    # for name, param in agent.tcost.named_parameters():\n",
        "                    #     print(\"param.data\",param.max().item(),param.min().item())\n",
        "                    #     print(\"agent.tcost\",param.data)\n",
        "\n",
        "# # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "# ema_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.999))\n",
        "# for epoch in range(300):\n",
        "#       for input, target in loader:\n",
        "#           optimizer.zero_grad()\n",
        "#           loss_fn(model(input), target).backward()\n",
        "#           optimizer.step()\n",
        "#           ema_model.update_parameters(model)\n",
        "# # Update bn statistics for the ema_model at the end\n",
        "# torch.optim.swa_utils.update_bn(loader, ema_model)\n",
        "# # Use ema_model to make predictions on test data\n",
        "# preds = ema_model(test_input)\n",
        "\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd): # best case z for train\n",
        "        # self.tcost.eval() # disable tcost dropout\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(2): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lsy_, lh0 = self.rnn_it(sy_, la, lz, h0_)\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            clossl = self.tcost.loss(syh0, rwd.flatten(), reduction='none')\n",
        "            # z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "\n",
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_EPhszEbbwD",
        "outputId": "bcb0b4b7-e261-48ff-aac0-65f53ba04747"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-4f4b4824202d>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru batch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=8, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 10 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=3. # 50 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 1 # ν cov Covariance\n",
        "        self.closs_coeff=10. # 10\n",
        "        # self.zloss_coeff=0. # 10 1\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        self.lx, self.lz = torch.empty((0,dim_a),device=device), torch.empty((0,dim_z),device=device) # [T,dim_az]\n",
        "        self.sx = self.jepa.enc(torch.zeros((1, 3,64,64)))\n",
        "        self.la = torch.empty(0,device=device)\n",
        "\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        if len(self.la)>1 or laction!=None:\n",
        "            self.update_h0(lstate, laction)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                self.sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(self.sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.la, self.lx, self.lz = lact, lx, lz\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                lsy = self.jepa.enc(torch.cat(lstate, dim=0))\n",
        "                # self.icost.update(sx)\n",
        "                # out_ = lsx - torch.cat([self.sx, lsx[:-1]], dim=0) # if using residual\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    self.la = torch.cat([torch.tensor(laction, device=device), self.la[len(laction):]], dim=-1)\n",
        "                la = self.emb(self.la[:seq_len])\n",
        "\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5) # torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        optim_z = torch.optim.SGD([lz], lr=1e0) # 3e3;1e1;\n",
        "        # optim_z = torch.optim.SGD([lz], lr=1e0, momentum=.1) # 1e-1,1e-0,1e4 ; 1e2 ; 1e1,.7\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-3, (0.9, 0.999)) # 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-1, (0.1, 0.5)) # 1e-3\n",
        "        lsy, la = lsy.detach(), la.detach() # [T, d_model], [T, dim_a]\n",
        "        lsx = torch.cat([self.sx, lsy[:-1]], dim=0)\n",
        "        print(\"update_h0 lz\", lz.data)\n",
        "        self.jepa.pred.train()\n",
        "        for i in range(5): # 1?\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                # # out = self.fc(out)\n",
        "                # out, h0 = self.gru(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "\n",
        "                # loss = F.mse_loss(out_, out.squeeze(0))\n",
        "                loss = F.mse_loss(lsy, out.squeeze(0))\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            print(\"update_h0 loss, lz\",i,loss.item(), lz.data)\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1].unsqueeze(0)\n",
        "        # print(\"update_h0\", self.lx.data)\n",
        "        self.la, self.lx, self.lz = self.la[seq_len:], self.lx[seq_len:], self.lz[seq_len:] # [T, dim_a], [T, dim_z]\n",
        "        return h0\n",
        "\n",
        "\n",
        "    def argm_s(self, sx, x, h0): # [1, d_model], [batch_, T, dim_a], [num_layers, 1, d_model] # batch argm z for search\n",
        "        batch_, T, _ = x.shape\n",
        "        batch = 16 # 16\n",
        "        z = nn.Parameter(torch.zeros((batch*batch_, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        optim_z = torch.optim.SGD([z], lr=1e4, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        with torch.no_grad(): z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch*batch_,1,1) # [batch*batch_, seq_len, dim_z]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, T, dim_a]\n",
        "        # print(\"argm\", z[0].squeeze())\n",
        "        for i in range(2): # 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm z loss\", z[0].squeeze().data, loss[0].squeeze().data)\n",
        "        idx = torch.argmin(loss.sum(-1).unflatten(0, (batch,batch_)), dim=0) # loss [batch*batch_, T] -> [batch_]\n",
        "        return torch.index_select(z, 0, idx) # [batch_, T,dim_z]\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch = 16\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        optim_x = torch.optim.SGD([x], lr=1e3) # 1e-1,1e-0,1e4 ; 1e2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        with torch.no_grad(): x[:,:self.lx.shape[0]] = self.lx.repeat(batch,1,1)[:,:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        # print(\"search x\",x.squeeze().data)\n",
        "        for i in range(2): # 5\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [batch, T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0) # [batch,T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i, \"search x loss\", x.squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        idx = torch.argmin(loss.sum(-1)) # loss [batch, T]\n",
        "        return lact[idx], lh0[:,:,idx], x.data[idx], z[idx] # [batch,T], [T, num_layers, batch, d_model], [batch,T, dim_a], [batch,T, dim_z]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz, h0, gamma=0.9): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        lsx, lh0 = self.rnn_it(sx, la, lz, h0)\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        syh0 = torch.cat([lsx, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,T,d_model], [T,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "        tcost = -self.tcost(syh0).unflatten(0, (batch, seq_len)).squeeze(-1)\n",
        "        c = (tcost + icost)*gamma**torch.arange(seq_len, device=device)\n",
        "        # if len(c.shape) == 1: print(\"rnn_pred c\", [f'{cc.item():g}' for cc in c.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        if len(tcost.shape) == 1: print(\"rnn_pred tcost\", [f'{cc.item():g}' for cc in tcost.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        return c, lh0\n",
        "\n",
        "    def rnn_it(self, sx, la, lz, h0): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        batch_ = batch//sx.shape[0]\n",
        "        sx, h0 = sx.repeat(batch_, 1), h0.repeat(1, batch_, 1)\n",
        "        lsx = torch.empty((batch, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1) # [batch, d_model+dim_a/z]\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            # sx = sx + out.squeeze(1) # [batch,seq_len,d_model] # h0 = h0 +\n",
        "            sx = out.squeeze(1) # [batch,1,d_model]\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        return lsx, lh0\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd): # best case z for train\n",
        "        # self.tcost.eval() # disable tcost dropout\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        batch = 64 # 16\n",
        "        lsy, la, rwd = lsy.repeat(batch,1,1), la.repeat(batch,1,1), rwd.repeat(batch,1) # [batch*batch_size, bptt, d_model], [batch*batch_size, d_model, dim_a], [batch*batch_size, bptt]\n",
        "        lz = nn.Parameter(torch.zeros((batch*batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lsy_, lh0 = self.rnn_it(sy_, la, lz, h0_)\n",
        "            # repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            repr_loss = ((lsy-lsy_)**2).unflatten(0, (batch,batch_size)).flatten(1).mean(-1)\n",
        "            syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch*batch_size,bptt,d_model], [bptt,num_layers,batch*batch_size,d_model] -> [batch*batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "            clossl = self.tcost.loss(syh0, rwd.flatten(), reduction='none').unflatten(0, (batch,batch_size*bptt)).mean(-1) # [batch*batch_size*bptt] -> [batch]\n",
        "            # z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        idx = torch.argmin(cost)\n",
        "        return lz.unflatten(0, (batch,batch_size))[idx].squeeze(0).detach()\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    # with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0.5)).mul_((torch.rand_like(lz)>0.1).bool()) # dropout without scaling\n",
        "                    with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0)).mul_((torch.rand_like(lz)>0.5).bool()) # dropout without scaling\n",
        "                    lsy_, lh0 = self.rnn_it(sy_.squeeze(1), la, lz, h0)\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                    # pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "                    # print(\"pred\",pred[0])\n",
        "                    # print(\"rwd\",rwd[0])\n",
        "                    # mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "                    # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # reprloss = ((lsy-lsy_)**2).mean(-1) # [batch_size, bptt]\n",
        "                    # print(\"reprloss\",reprloss[0])\n",
        "                    # mask = (reprloss>0.05)[0]\n",
        "                    # # imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[0][mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "                # torch.norm(lsy-torch.cat([sy_,lsy[:-1]], dim=1), dim=-1) # -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "                # prob = F.softmax(output, dim=-1)\n",
        "                # entropy = -torch.sum(prob * torch.log(prob + 1e-5), dim=-1)\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                norm = torch.norm(lsy[0][0], dim=-1).item()\n",
        "                z_norm = torch.norm(lz[0][-1], dim=-1)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                # print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                scaler.scale(loss).backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item(), \"z_norm\": z_norm.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.999)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "# !pip show torch triton\n",
        "# # !pip install --upgrade torch\n",
        "# !pip install --upgrade triton\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "# print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "# print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "# print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AAXyi7QJRRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# rnn = nn.GRU(4, 5, 2) # [in_dim, out_dim, num_layers]\n",
        "rnn = nn.GRU(4, 5, 2, batch_first=True) # [in_dim, out_dim, num_layers]\n",
        "input = torch.randn(1, 3, 4) # [batch_size, seq_len, in_dim]\n",
        "h0 = torch.randn(2, 1, 5) # [num_layers, batch_size, out_dim]\n",
        "output, hn = rnn(input, h0) # [batch_size, seq_len, out_dim], [num_layers, batch_size, out_dim]\n",
        "print(output)\n",
        "print(hn)\n",
        "# print(hn[-1,:,:])\n",
        "print(output[:,-1,:])\n",
        "print(hn[-1,:,:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cg0BI2TwY9-p"
      },
      "outputs": [],
      "source": [
        "# @title z.grad.data = -z.grad.data\n",
        "\n",
        "# self.eval()\n",
        "batch = 4 # 16\n",
        "x = nn.Parameter(torch.empty((batch, T, agent.dim_a),device=device))\n",
        "torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# optim_ = torch.optim.SGD([x,z], lr=1e1) # 3e3\n",
        "optim_ = torch.optim.AdamW([x,z], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "print(\"search z\", z[0].squeeze())\n",
        "print(\"search x\", x[0].squeeze())\n",
        "sx, h0 = sx.detach(), h0.detach()\n",
        "for i in range(10): # num epochs\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    z.grad.data = -z.grad.data\n",
        "    optim_.step()\n",
        "    optim_.zero_grad()\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "    print(i, \"search loss\", loss.squeeze().data)\n",
        "    print(i, \"search z\", z[0].squeeze().data)\n",
        "    print(i, \"search x\", x[0].squeeze().data)\n",
        "dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "print(\"c\",torch.stack(c)[:,idx])\n",
        "# return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "# print(lact[idx], lh0[:,:,idx,:], x[idx], z[idx])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5VMebkQ1mJtD"
      },
      "outputs": [],
      "source": [
        "# @title argm agent.rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def argm(sx, x,h0, lr=3e3): # 3e3\n",
        "    # agent.eval()\n",
        "    # batch_size, T, _ = sx.shape\n",
        "    batch = 16 # 16\n",
        "    z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "    torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "    optim_z = torch.optim.SGD([z], lr=1e3, maximize=True) # 3e3\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.LBFGS([z], max_iter=5, lr=1)\n",
        "\n",
        "    # print(\"argm\", z[0].squeeze())\n",
        "    sx, h0 = sx.detach(), h0.detach()\n",
        "    x = x.detach().repeat(batch,1,1)\n",
        "    for i in range(5): # num epochs\n",
        "        # print(sx.shape, x.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "        loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "        loss.sum().backward()\n",
        "        optim_z.step()\n",
        "        optim_z.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "        # print(i, \"argm loss\", loss.squeeze().data)\n",
        "        # print(i, \"argm z\", z[0].squeeze().data)\n",
        "    idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "    return z[idx].unsqueeze(0)\n",
        "\n",
        "\n",
        "T=1\n",
        "xx = torch.empty((1, T, agent.dim_a))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "# print(x.shape)\n",
        "optim_x = torch.optim.SGD([x], lr=1e1) # 1e-1,1e-0,1e4 ; 1e2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "\n",
        "state = torch.zeros((1, 3,64,64))\n",
        "with torch.no_grad():\n",
        "    sx = agent.jepa.enc(state).detach()\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "print(time.time()-start)\n",
        "\n",
        "print(\"search\",x.squeeze().data)\n",
        "for i in range(20): # 5\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    z = argm(sx, x_,h0)\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [1, 1, 3], [1, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "    print(i, \"search loss\", x.squeeze().data, loss.item())\n",
        "    # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "\n",
        "# z sgd 1e3\n",
        "# 9 search loss tensor([0.0142, 0.0142, 0.0142, 0.0142])\n",
        "# 9 search z tensor([-0.3381, -0.7005, -0.5877, -0.0664, -0.1439,  0.0283,  0.0541, -0.1439])\n",
        "\n",
        "# x sgd 1e2\n",
        "# 1 tensor([0.3561, 0.3059, 0.8830]) 0.014148875139653683\n",
        "# 9 tensor([0.3560, 0.3064, 0.8828]) 2.328815611463142e-07\n",
        "\n",
        "# 1e0\n",
        "# 19 tensor([-0.5768,  0.5778,  0.5774]) 6.543130552927323e-07\n",
        "# 19 tensor([0.3570, 0.6689, 0.6521]) 2.474381801675918e-07\n",
        "# 19 tensor([0.5783, 0.5765, 0.5772]) 1.519319567933053e-07\n",
        "# 19 tensor([0.3427, 0.6795, 0.6487]) 4.220427456402831e-07\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "# optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "    # def argm(self, sx, a, lr=3e3): # 3e3\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "    #     optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    #     # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    #     sx, a = sx.detach(), a.detach()\n",
        "    #     for i in range(5): # 10\n",
        "    #         sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #         with torch.amp.autocast('cuda'):\n",
        "    #             # sx_ = self.jepa.pred(sxaz)\n",
        "    #             sx_ = sx + self.jepa.pred(sxaz)\n",
        "    #             cost = -self.tcost(sx_)\n",
        "\n",
        "    #         cost.backward()\n",
        "    #         optim.step()\n",
        "    #         # scaler.scale(cost).backward()\n",
        "    #         # scaler.step(optim)\n",
        "    #         # scaler.update()\n",
        "    #         optim.zero_grad()\n",
        "    #         with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "    #         print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def argm(self, sx, lr=3e3): # 3e3\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch_size, T, _ = sx.shape\n",
        "        batch = 16\n",
        "        # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "        z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "        optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "        sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "        # sx = sx.detach()\n",
        "        for i in range(20): # 10\n",
        "            # print(sx.shape,z.shape)\n",
        "            sxz = torch.cat([sx, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                cost = model(sxz)\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "            # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "            # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        # return z.detach()\n",
        "        # print(\"argm z\",z.squeeze().data)\n",
        "        # print(\"cost\",cost.squeeze())\n",
        "        idx = torch.argmax(loss)\n",
        "        # return z[idx].detach().unsqueeze(0)\n",
        "        return z[:,idx].detach()\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch=1\n",
        "        T=1\n",
        "        x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "\n",
        "        lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "        # ratio = 6e0\n",
        "        lr = 1e-1 # adamw 1e-1\n",
        "        ratio = 4\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        # optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze())\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "        for i in range(50):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            z = argm(x)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "            # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "            # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                x.clamp_(min=-1, max=1)\n",
        "            # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "        idx = torch.argmax(loss)\n",
        "        print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd):\n",
        "        self.tcost.eval()\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "            lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "                for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                    syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                    out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                    lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                    lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "                repr_loss = F.mse_loss(lsy, lsy_)\n",
        "                syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "                clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "                # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "                cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "outputs": [],
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.amp.autocast('cuda'):\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjm2kV3H7ZVR"
      },
      "outputs": [],
      "source": [
        "for name, p in agent.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(name, p.numel())\n",
        "\n",
        "\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jx0k_ndHOEMe"
      },
      "outputs": [],
      "source": [
        "# @title visualise kernels\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "# https://stackoverflow.com/questions/55594969/how-to-visualise-filters-in-a-cnn-with-pytorch\n",
        "\n",
        "layers = [0,3,6,9]\n",
        "layers = [0,3,6,9,12]\n",
        "layer = 9\n",
        "\n",
        "def visualise(model,layer):\n",
        "    kernels = model.cnn[layer].weight.data.clone()\n",
        "    n,c,w,h = kernels.shape\n",
        "    print(kernels.shape)\n",
        "    if c not in [1,3]:\n",
        "        # kernels = kernels.mean(dim=1, keepdim=True)\n",
        "        kernels = kernels[:,2,:,:].unsqueeze(dim=1)\n",
        "    nrow=10\n",
        "    rows = np.min((kernels.shape[0]//nrow + 1, 64))\n",
        "    grid = utils.make_grid(kernels, nrow=nrow, normalize=True, padding=1)\n",
        "    plt.figure(figsize=(nrow,rows))\n",
        "\n",
        "    kernels = kernels - kernels.min()\n",
        "    kernels = kernels / kernels.max()\n",
        "    filter_img = utils.make_grid(kernels, nrow = 12)\n",
        "    # change ordering since matplotlib requires images to\n",
        "    # be (H, W, C)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0))\n",
        "\n",
        "    # plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "# visualise(agent.sense,layer)\n",
        "visualise(agent.jepa.enc,layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "N2TGs69fnrZo",
        "outputId": "9eb594ee-4cad-4dce-f8ab-3ff44dde383a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcost.1.weight torch.Size([2, 512])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcost.1.bias torch.Size([2])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (fcin): Linear(in_features=267, out_features=256, bias=False)\n",
            "  (lyrnorm): RMSNorm((256,), eps=None, elementwise_affine=True)\n",
            "  (act): GELU(approximate='none')\n",
            "  (rnn): GRU(256, 256, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=256, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# @title visualise lin\n",
        "# https://matplotlib.org/stable/plot_types/index.html\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for name, param in agent.jepa.pred.named_parameters(): # for param in model.parameters():\n",
        "# for name, param in agent.emb.named_parameters():\n",
        "for name, param in agent.tcost.named_parameters():\n",
        "    print(name, param.shape)\n",
        "    if len(param.shape)==1: param=param.unsqueeze(0)\n",
        "    Z=param.detach()#.numpy()\n",
        "\n",
        "    filter_img = utils.make_grid(Z, nrow = 12, normalize=True, padding=1)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0)) # (H, W, C)\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "    # pos=ax.imshow(Z)\n",
        "    # fig.colorbar(pos)\n",
        "    plt.show()\n",
        "\n",
        "print(agent.jepa.pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for name, param in agent.tcost.named_parameters():\n",
        "# for name, param in agent.emb.named_parameters():\n",
        "for name, param in agent.jepa.pred.named_parameters(): # for param in model.parameters():\n",
        "    print(name, param)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5COoj0lFTy5",
        "outputId": "b7ec946e-b337-4a31-d0f5-3c357efac3b4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fcin.weight Parameter containing:\n",
            "tensor([[ 0.0665, -0.0174,  0.0690,  ...,  0.0634,  0.1680, -0.1121],\n",
            "        [-0.0374, -0.0035, -0.0385,  ...,  0.2693,  0.2640, -0.2615],\n",
            "        [-0.0041, -0.0063,  0.0093,  ...,  0.1746,  0.2163, -0.1880],\n",
            "        ...,\n",
            "        [ 0.0264,  0.0032, -0.0008,  ..., -0.2745, -0.1655,  0.3006],\n",
            "        [-0.0046,  0.0234,  0.0354,  ...,  0.1962,  0.2504, -0.3031],\n",
            "        [-0.0659,  0.0019, -0.0219,  ...,  0.1848,  0.2462, -0.1328]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "lyrnorm.weight Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n",
            "rnn.weight_ih_l0 Parameter containing:\n",
            "tensor([[-0.0132, -0.0828,  0.0145,  ..., -0.0687, -0.0139,  0.0634],\n",
            "        [-0.0103,  0.0078, -0.0008,  ...,  0.0272, -0.0188, -0.0034],\n",
            "        [ 0.0018, -0.0402,  0.0030,  ...,  0.0348,  0.0705,  0.0538],\n",
            "        ...,\n",
            "        [-0.0161,  0.0206,  0.0186,  ..., -0.0408, -0.0205, -0.0225],\n",
            "        [ 0.0518, -0.0721,  0.0128,  ...,  0.0765,  0.0434,  0.0330],\n",
            "        [ 0.0245, -0.0742, -0.0738,  ..., -0.0284, -0.0117, -0.0166]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "rnn.weight_hh_l0 Parameter containing:\n",
            "tensor([[-5.3698e-03,  1.2000e-01,  2.6369e-02,  ...,  1.6344e-02,\n",
            "          8.5422e-02,  2.8928e-02],\n",
            "        [-6.8956e-02, -5.2952e-02, -5.1288e-02,  ...,  3.2694e-02,\n",
            "          8.7613e-03, -1.1936e-04],\n",
            "        [-4.3188e-02,  6.2122e-02,  1.0784e-02,  ...,  1.4494e-02,\n",
            "         -4.8099e-02, -6.1869e-02],\n",
            "        ...,\n",
            "        [-1.7740e-02,  6.3463e-02,  6.4353e-02,  ..., -1.4446e-02,\n",
            "          6.7421e-02, -7.7800e-03],\n",
            "        [-1.3777e-02, -6.4095e-02,  2.6653e-02,  ..., -2.3495e-02,\n",
            "         -1.0058e-01,  5.3073e-02],\n",
            "        [ 5.3584e-02, -2.4836e-02, -1.3977e-02,  ..., -1.1048e-03,\n",
            "         -2.6712e-02, -6.3503e-02]], device='cuda:0', requires_grad=True)\n",
            "rnn.bias_ih_l0 Parameter containing:\n",
            "tensor([-6.1357e-02,  7.5051e-03,  1.7222e-02, -6.7694e-02, -3.4049e-02,\n",
            "        -5.5463e-02, -8.8458e-03, -3.1544e-02, -2.9783e-03, -6.2401e-02,\n",
            "         8.1870e-03,  3.1152e-02, -6.8453e-02, -7.3960e-02, -9.7328e-02,\n",
            "        -1.5886e-02,  2.4971e-02, -1.1915e-01,  5.3751e-03, -3.0691e-02,\n",
            "        -4.8052e-03, -6.1592e-02,  5.1328e-02,  2.1335e-02, -6.5298e-02,\n",
            "        -6.6851e-02, -1.8860e-02, -6.8281e-02,  1.8252e-03, -4.0378e-02,\n",
            "        -2.2992e-02, -5.2502e-02, -1.7942e-02,  1.6135e-02, -1.2805e-01,\n",
            "        -1.6613e-02, -1.0337e-02, -1.9006e-02, -7.6161e-03, -9.3850e-02,\n",
            "        -9.2461e-02,  2.8369e-03, -3.3666e-02,  1.4879e-02,  1.6467e-03,\n",
            "        -6.0740e-02, -5.4501e-02, -1.2656e-02, -8.3271e-02,  4.9417e-02,\n",
            "        -3.2934e-02,  1.3562e-02, -4.8685e-02, -6.7339e-02, -1.8476e-02,\n",
            "        -3.3686e-02, -8.4134e-02, -4.4888e-02, -3.6117e-02,  8.1494e-03,\n",
            "         4.5620e-02,  5.1680e-02,  1.7596e-02, -7.7159e-02, -4.5412e-02,\n",
            "        -4.3553e-02,  2.3073e-02, -1.0403e-02, -8.2437e-02, -1.1355e-01,\n",
            "         3.2639e-02, -5.8523e-02,  5.3450e-02, -3.2124e-02, -6.7370e-02,\n",
            "         6.6819e-03, -2.9885e-02, -7.2717e-02, -8.6014e-02, -3.3138e-02,\n",
            "        -8.4306e-02, -9.8446e-02,  2.7376e-02,  9.6570e-03, -6.1471e-02,\n",
            "        -9.4379e-02, -6.4225e-02,  3.3320e-02, -6.0023e-02, -6.4763e-02,\n",
            "         2.0835e-02, -3.8168e-02, -5.1989e-02, -1.0207e-02, -6.6818e-02,\n",
            "        -1.8663e-03, -1.5276e-02, -3.8222e-02,  2.4761e-03, -5.1621e-02,\n",
            "        -6.8002e-02, -4.1448e-02, -9.7239e-03, -2.1353e-02,  6.0490e-03,\n",
            "        -3.2509e-02, -1.1825e-01, -7.2251e-02, -6.3429e-02, -1.2946e-02,\n",
            "        -1.6671e-02, -6.1799e-02, -1.0433e-02, -5.0689e-02, -3.2492e-02,\n",
            "        -3.1485e-02, -2.7853e-02, -2.7654e-02,  2.8232e-03, -1.2291e-01,\n",
            "         2.1764e-02,  2.2462e-03, -7.7271e-02, -1.6921e-02,  1.6654e-02,\n",
            "        -3.8695e-02, -5.8364e-02, -4.3010e-02, -1.4181e-02, -1.1246e-02,\n",
            "        -1.9858e-02, -9.0052e-03,  4.8331e-02, -2.3171e-02, -1.8783e-02,\n",
            "        -6.5684e-02, -7.5570e-02, -5.2436e-02, -5.2859e-02, -4.4300e-02,\n",
            "        -2.1623e-02, -7.2710e-02, -7.0945e-02,  2.4663e-02,  1.1879e-02,\n",
            "        -6.2515e-02,  1.0036e-02, -1.5936e-02, -2.8252e-02, -8.2357e-03,\n",
            "         8.5220e-04, -2.5990e-02, -2.2816e-02, -4.6022e-02, -7.7929e-02,\n",
            "         6.3379e-03, -4.3240e-02,  5.3273e-02, -4.1068e-02, -8.5454e-03,\n",
            "        -8.4028e-02, -2.6550e-02,  3.1862e-02, -1.1420e-02,  6.2099e-02,\n",
            "        -6.5742e-02,  5.6581e-03, -8.0079e-02, -2.0777e-02, -4.8797e-02,\n",
            "         3.8479e-02, -1.1152e-02,  7.8878e-02,  3.2795e-03,  3.0025e-03,\n",
            "        -3.2652e-02, -4.5755e-02, -1.2672e-01, -6.0878e-02,  3.2321e-02,\n",
            "        -3.2535e-02, -1.0791e-01,  1.5311e-02, -1.5138e-02, -5.4547e-02,\n",
            "        -3.0671e-02, -6.1273e-02, -7.7472e-02, -2.2591e-02,  3.4195e-02,\n",
            "        -2.0185e-02, -5.5056e-02, -6.1531e-02,  1.8068e-02, -5.6346e-02,\n",
            "        -6.6944e-02, -5.8430e-02,  1.4018e-03, -4.4076e-02, -1.7872e-02,\n",
            "        -7.8201e-02, -9.7723e-02,  8.7339e-03, -5.1038e-02,  5.8751e-03,\n",
            "        -5.0555e-02, -6.8500e-02,  2.4236e-02,  4.3838e-02, -3.2824e-02,\n",
            "        -4.6733e-02, -2.9631e-02, -4.9195e-02, -5.3859e-02, -6.4468e-02,\n",
            "        -2.4367e-02,  3.7206e-02, -8.3943e-04,  4.6126e-02, -8.8369e-02,\n",
            "        -1.9003e-02,  4.9000e-02,  3.7742e-02, -1.7896e-02,  5.1998e-03,\n",
            "        -1.3724e-02,  3.0231e-02, -5.4640e-03,  6.0885e-03, -7.9490e-03,\n",
            "        -8.3386e-02, -5.4423e-02,  5.1011e-02, -1.9636e-02,  3.7611e-02,\n",
            "        -3.7614e-02, -7.7326e-02, -4.7908e-02, -4.7540e-03, -8.2945e-02,\n",
            "        -3.0761e-02,  1.3161e-02, -8.1163e-03,  4.3698e-02, -9.2223e-02,\n",
            "        -3.0183e-02, -7.2471e-02, -4.0437e-02, -7.7030e-03, -4.7247e-02,\n",
            "        -3.5555e-02, -2.5194e-02,  6.6387e-03, -9.1468e-02, -6.7239e-02,\n",
            "        -3.4540e-02,  1.5627e-02, -5.4640e-02, -1.6158e-02, -3.5314e-02,\n",
            "        -1.0882e-02, -1.8955e-02, -2.6329e-02,  4.0518e-02, -2.2458e-02,\n",
            "         9.5376e-02, -2.1290e-02,  2.1882e-02,  8.3130e-02,  4.2235e-02,\n",
            "         2.9491e-02, -5.1685e-02,  3.5251e-02,  8.1180e-03, -6.2107e-05,\n",
            "        -3.5914e-02,  3.1343e-02, -2.6751e-02,  5.3303e-02,  1.2483e-01,\n",
            "         1.5185e-02,  7.9590e-03, -5.4382e-02,  2.4543e-02,  8.9477e-02,\n",
            "        -8.7551e-03, -3.7866e-02,  5.8752e-02,  7.0304e-02,  7.1155e-02,\n",
            "         8.6742e-02, -2.9229e-02,  2.4971e-02, -9.0924e-02,  7.7150e-02,\n",
            "        -1.8066e-02,  5.1964e-04,  4.0781e-02, -1.4992e-02,  9.5950e-02,\n",
            "         9.0059e-02, -4.4196e-02,  3.1650e-02,  4.3653e-02,  2.4795e-02,\n",
            "        -1.4527e-02, -6.3023e-02, -3.8380e-02,  3.7692e-02,  1.3326e-02,\n",
            "        -3.2949e-02, -1.7101e-02,  3.1130e-02,  9.5167e-02, -6.9872e-02,\n",
            "        -3.6812e-02,  6.7315e-03,  5.2389e-02,  4.6180e-02,  3.3907e-02,\n",
            "         1.8851e-02,  1.2397e-02,  3.6428e-02,  8.6019e-03,  2.4933e-02,\n",
            "         9.3265e-02, -6.4771e-03, -6.2776e-04, -4.1692e-02,  6.7267e-02,\n",
            "        -7.2718e-03,  4.7059e-02,  3.4577e-02, -2.1929e-02,  3.4601e-02,\n",
            "        -6.2374e-02, -1.3206e-02,  1.6050e-02, -4.5311e-03, -7.3940e-02,\n",
            "         2.5435e-02,  1.6461e-03,  1.4034e-02,  2.5937e-02,  6.4474e-02,\n",
            "         6.2509e-02, -5.6219e-02,  8.3010e-02,  8.7223e-02,  5.2906e-02,\n",
            "         1.1368e-02,  4.1568e-02, -8.0270e-02,  7.1232e-02,  1.7204e-03,\n",
            "         8.3777e-02, -4.1449e-02,  4.7072e-02,  1.8981e-02,  4.7525e-02,\n",
            "        -2.9203e-02,  4.3084e-02,  6.9115e-02,  4.2093e-02,  4.3844e-02,\n",
            "         4.8661e-02, -3.8727e-03,  1.4264e-02,  3.3437e-03, -1.3632e-01,\n",
            "         3.4662e-02,  6.7761e-02,  6.7259e-02, -1.6211e-02, -1.7267e-02,\n",
            "         3.4811e-04,  2.3604e-02,  6.4983e-02,  1.9885e-02,  1.4621e-02,\n",
            "         5.4053e-02,  8.0718e-02, -3.7847e-02,  1.6916e-02, -1.8095e-02,\n",
            "         4.3680e-02,  1.8830e-02, -1.7465e-02, -1.3795e-02,  2.6873e-02,\n",
            "        -1.1794e-01,  1.8809e-02,  1.0255e-01, -5.0453e-02,  1.4307e-01,\n",
            "         7.0246e-02,  6.1587e-02,  9.8992e-02,  8.5029e-02,  6.3025e-02,\n",
            "        -1.3309e-02,  2.7459e-02, -6.9595e-02, -1.9099e-03, -2.8663e-02,\n",
            "         7.9456e-02, -1.2279e-03,  1.6402e-02,  6.1095e-02,  5.4677e-02,\n",
            "         1.8897e-02,  6.6789e-02, -4.0813e-02, -4.9970e-02,  9.4112e-02,\n",
            "        -3.7573e-03, -3.2970e-02, -5.5474e-02, -4.8997e-02,  1.0210e-01,\n",
            "         1.9110e-02,  7.4085e-02,  6.8511e-02,  2.2666e-02,  5.9639e-02,\n",
            "        -2.2468e-02, -1.2956e-02,  7.4303e-03, -4.1062e-02, -4.0295e-03,\n",
            "         5.6381e-03, -3.0186e-02,  4.1120e-02, -1.2813e-02,  4.2757e-02,\n",
            "         5.0797e-02,  6.3194e-02,  6.7750e-02,  1.5202e-02, -1.8720e-02,\n",
            "         5.5798e-03, -7.5184e-02, -6.2418e-02, -4.9936e-02,  3.1998e-02,\n",
            "         3.4521e-02,  9.9417e-02,  2.0448e-02, -3.8418e-02,  1.0203e-01,\n",
            "        -5.4380e-02,  5.0404e-02,  1.5417e-01,  1.9802e-02, -3.6766e-02,\n",
            "         4.4029e-02,  3.1229e-02, -2.1355e-02, -5.8609e-02, -1.5606e-02,\n",
            "         9.9045e-02, -4.9198e-02, -3.8632e-03,  6.3657e-03, -4.9420e-03,\n",
            "         3.3184e-02,  4.8440e-02,  4.2107e-02, -6.0590e-02,  9.7738e-02,\n",
            "        -1.9570e-02, -1.2904e-02,  6.4350e-02, -1.0158e-02,  2.9574e-02,\n",
            "         4.0869e-02, -8.1715e-02,  6.4997e-02, -1.4420e-02,  3.9624e-02,\n",
            "         6.7453e-02, -1.9303e-02,  3.8306e-02, -5.3895e-02,  1.2371e-02,\n",
            "        -6.7129e-03,  5.0556e-02,  1.5969e-02,  1.1901e-01,  4.8880e-03,\n",
            "         2.7330e-02, -4.4678e-02,  9.6149e-02,  1.0640e-01, -2.8316e-02,\n",
            "         5.8654e-02, -2.4803e-02,  6.1269e-02,  2.2771e-02,  6.3923e-03,\n",
            "         1.9993e-03,  5.5617e-03,  1.3623e-02,  7.4991e-02, -2.0182e-02,\n",
            "        -2.2186e-02, -1.1399e-02, -4.0789e-02,  1.0390e-01,  9.6216e-03,\n",
            "         7.9169e-02,  8.1203e-02, -3.2682e-02, -5.4597e-02, -2.8908e-02,\n",
            "         1.5577e-02, -2.4819e-02,  2.6625e-02,  3.1432e-02, -3.5030e-02,\n",
            "        -2.8957e-02,  1.9746e-02, -2.2616e-02, -3.5867e-02,  2.7201e-02,\n",
            "         2.8880e-03, -2.8594e-02,  2.1678e-02, -1.7180e-02,  1.1435e-02,\n",
            "        -1.8757e-02, -7.3747e-03, -3.2573e-02, -3.2664e-02,  2.0503e-02,\n",
            "         3.9218e-03,  3.2156e-03, -4.7828e-02, -4.2884e-02, -1.5247e-02,\n",
            "        -6.5646e-03,  2.6366e-02, -3.3350e-02, -1.0063e-02, -1.4141e-02,\n",
            "         3.7792e-02,  1.4224e-02,  4.5225e-03, -4.8789e-03,  3.3126e-02,\n",
            "        -2.7392e-02,  6.9773e-04, -2.4000e-03, -4.4560e-02,  1.7757e-02,\n",
            "        -9.5050e-04, -3.5207e-02,  3.8695e-02, -1.4505e-04, -1.4657e-02,\n",
            "        -6.1529e-03, -1.7625e-02, -5.1093e-03, -4.0016e-02,  2.3534e-02,\n",
            "         1.2227e-03,  2.0663e-02, -2.7923e-02,  1.6523e-02,  2.9876e-02,\n",
            "         1.2815e-02, -2.7999e-02,  2.5434e-02,  1.8900e-03,  5.8246e-03,\n",
            "         3.7236e-02, -5.7620e-03,  1.3187e-02,  1.2052e-02, -1.6312e-02,\n",
            "         7.1135e-03,  5.9535e-02,  3.6820e-02,  4.3993e-02,  2.5804e-02,\n",
            "        -1.3371e-02, -3.1386e-02,  2.0610e-02, -1.4299e-02,  3.3051e-02,\n",
            "         5.2337e-02,  3.9459e-02,  2.7636e-02,  2.1013e-02,  3.5713e-02,\n",
            "        -1.1853e-02, -3.0259e-02,  2.5138e-02, -1.7856e-02,  2.5734e-02,\n",
            "        -3.8781e-02, -1.3783e-02,  4.4441e-02,  5.2529e-03,  1.7314e-02,\n",
            "         1.3940e-02,  1.5187e-02, -2.7525e-02,  2.0410e-02,  3.1324e-02,\n",
            "        -1.4654e-02, -2.5789e-02,  1.6109e-02, -3.5076e-02, -6.5151e-03,\n",
            "        -6.8936e-03, -2.1916e-02, -4.5256e-02,  2.8466e-02,  1.4988e-02,\n",
            "         3.7489e-02,  1.8525e-02,  1.8325e-02,  4.4045e-02,  2.9005e-02,\n",
            "        -1.6518e-03, -1.6019e-03,  2.4106e-02, -2.7111e-02, -2.6056e-02,\n",
            "        -1.8559e-02, -6.3891e-03, -2.2043e-02,  3.1683e-02,  3.6066e-02,\n",
            "        -2.2591e-03,  1.4949e-02,  1.3211e-02, -3.0304e-02,  2.4628e-02,\n",
            "         2.7671e-02,  5.6694e-03,  2.6023e-02, -2.4138e-02,  1.6116e-02,\n",
            "         1.5792e-03,  1.8137e-02, -9.1573e-03, -4.1499e-02,  4.9018e-04,\n",
            "         3.7014e-02,  2.3138e-02,  6.9305e-03,  3.5283e-02, -2.0352e-02,\n",
            "         2.0662e-02, -2.3484e-02, -2.4294e-02, -2.2890e-02,  2.7392e-02,\n",
            "        -2.5428e-02,  6.7624e-03, -1.7878e-02,  5.0871e-03, -2.0438e-02,\n",
            "        -3.8836e-02,  2.5178e-02, -1.5746e-02, -4.0582e-02, -2.1551e-02,\n",
            "         2.5573e-02, -4.1173e-03, -1.3017e-03, -4.1657e-02, -2.4337e-02,\n",
            "        -2.0081e-02, -2.3338e-02, -2.4197e-02,  2.5982e-02, -2.5887e-04,\n",
            "         1.8676e-02, -1.5345e-02, -5.0081e-02, -1.1299e-02,  5.4219e-02,\n",
            "        -1.6307e-02,  1.8626e-02,  2.3875e-02,  2.1265e-02,  1.0482e-02,\n",
            "         5.5732e-03, -1.3511e-02, -4.3073e-02, -3.6003e-02, -3.5264e-02,\n",
            "         4.5023e-02,  9.3779e-03,  2.2787e-02, -7.9574e-03, -4.9397e-02,\n",
            "        -3.7145e-02,  2.6205e-02, -2.5926e-02, -2.7971e-02,  1.7447e-02,\n",
            "         2.4865e-02, -4.2060e-02,  1.7116e-02, -4.7002e-02,  8.0017e-03,\n",
            "        -2.1272e-02,  1.9130e-02,  2.7891e-02, -4.3177e-03,  1.3033e-02,\n",
            "         1.5845e-02,  1.2487e-02, -2.1152e-02, -1.2178e-02,  2.2995e-02,\n",
            "        -1.8189e-03,  2.2595e-02, -3.5653e-02,  3.8537e-02,  5.8942e-03,\n",
            "         2.2931e-02,  2.3561e-02, -4.3524e-02,  7.7588e-03, -2.9191e-02,\n",
            "        -3.8002e-02, -2.9414e-02, -5.0736e-03,  3.1543e-02, -1.4023e-02,\n",
            "        -1.7266e-02, -4.7567e-02,  1.0067e-03,  7.8911e-03,  1.3797e-02,\n",
            "        -1.0500e-03,  1.2059e-02, -1.2137e-02,  1.1857e-03,  2.5849e-02,\n",
            "        -1.6525e-02, -8.9160e-03,  1.5057e-02,  2.7585e-02,  2.7266e-02,\n",
            "         1.7131e-02, -3.2836e-02,  9.0477e-03, -2.1986e-02, -1.9460e-02,\n",
            "        -2.6415e-02, -1.6869e-02, -2.3156e-02, -4.1308e-02,  2.0748e-02,\n",
            "         1.7109e-02,  8.4342e-03,  2.7682e-02, -5.3558e-04,  1.1310e-02,\n",
            "         1.7118e-02,  6.0491e-03,  1.8877e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "rnn.bias_hh_l0 Parameter containing:\n",
            "tensor([-0.0559,  0.0137, -0.0208, -0.0436, -0.0649, -0.0581, -0.0958, -0.0661,\n",
            "         0.0129, -0.0774,  0.0356,  0.0033, -0.0530, -0.0777, -0.1063, -0.0503,\n",
            "         0.0147, -0.0256,  0.0307,  0.0098,  0.0466, -0.0081,  0.0262, -0.0634,\n",
            "         0.0138,  0.0257, -0.0190, -0.0462, -0.0388, -0.0511, -0.0708, -0.0219,\n",
            "         0.0008,  0.0197, -0.1076, -0.0513,  0.0353, -0.0442, -0.0541,  0.0240,\n",
            "        -0.0815,  0.0298, -0.0789, -0.0400, -0.0499, -0.0882, -0.0611, -0.0116,\n",
            "        -0.0144,  0.0346,  0.0416, -0.0772, -0.0095, -0.0872, -0.0376, -0.1170,\n",
            "        -0.0426, -0.0567, -0.0283,  0.0016, -0.0351,  0.0406, -0.0863, -0.0477,\n",
            "        -0.0609, -0.0836, -0.0649,  0.0282,  0.0193, -0.0803,  0.0103,  0.0213,\n",
            "         0.0057, -0.0324, -0.0119, -0.0431, -0.0210, -0.0507, -0.0603,  0.0105,\n",
            "        -0.0736, -0.0195,  0.0392, -0.0048,  0.0186, -0.0512, -0.0887,  0.0405,\n",
            "        -0.0940, -0.0681,  0.0260, -0.0540,  0.0067, -0.0281, -0.0854, -0.0126,\n",
            "         0.0004,  0.0310,  0.0364, -0.0906, -0.0195, -0.0648,  0.0222, -0.0339,\n",
            "        -0.0199, -0.0101, -0.0697, -0.0742,  0.0427, -0.0477, -0.0904, -0.0530,\n",
            "        -0.0058, -0.0699, -0.0337, -0.0195,  0.0067,  0.0506, -0.0633, -0.0797,\n",
            "        -0.0722,  0.0348, -0.0665, -0.0187,  0.0347, -0.0078, -0.0168, -0.1030,\n",
            "        -0.0194, -0.0867, -0.0048, -0.0531, -0.0293, -0.0134, -0.0339, -0.0389,\n",
            "         0.0197, -0.0555, -0.0163, -0.0239, -0.0180, -0.0089, -0.0752,  0.0162,\n",
            "        -0.0849, -0.0152, -0.0312, -0.0152, -0.0574,  0.0019, -0.0469, -0.0037,\n",
            "         0.0134,  0.0231, -0.1029, -0.0265,  0.0120, -0.0437, -0.0574, -0.0572,\n",
            "         0.0069, -0.0625,  0.0067, -0.0467,  0.0417, -0.0719,  0.0254, -0.0169,\n",
            "        -0.0905,  0.0067, -0.0329, -0.0747,  0.0329, -0.0100, -0.0302, -0.0625,\n",
            "         0.0384, -0.1185, -0.0612, -0.0409,  0.0314, -0.1114,  0.0194, -0.0417,\n",
            "        -0.0202,  0.0233, -0.1007, -0.1115,  0.0454,  0.0246, -0.0135, -0.0197,\n",
            "        -0.0392, -0.0593, -0.0719, -0.0078,  0.0420, -0.0266, -0.0612,  0.0159,\n",
            "        -0.0482,  0.0148, -0.0396,  0.0209, -0.0019, -0.0038, -0.0133, -0.0894,\n",
            "         0.0448, -0.0401, -0.0490, -0.0355,  0.0310, -0.0719, -0.0200, -0.0605,\n",
            "         0.0126,  0.0334, -0.0292, -0.0363,  0.0234, -0.0680,  0.0305, -0.0700,\n",
            "         0.0040, -0.0006, -0.0228, -0.0515, -0.0396, -0.0059, -0.0064, -0.0097,\n",
            "        -0.0578, -0.0359, -0.0552,  0.0041,  0.0167, -0.0540, -0.0261,  0.0317,\n",
            "         0.0034, -0.0641, -0.0644, -0.0082, -0.0719, -0.0299, -0.0246, -0.0292,\n",
            "         0.0030, -0.0132,  0.0335, -0.0604,  0.0273, -0.0434, -0.1133, -0.0150,\n",
            "        -0.0400, -0.0073,  0.0181,  0.0489, -0.0214,  0.0041,  0.0372, -0.0347,\n",
            "         0.0059,  0.0208, -0.0115,  0.0533, -0.0305, -0.0096,  0.0788,  0.0038,\n",
            "         0.0697, -0.0468,  0.0674,  0.0712,  0.0185,  0.0693,  0.0885,  0.1443,\n",
            "         0.0769,  0.0114,  0.0246, -0.0182,  0.0894, -0.0740,  0.0196,  0.0874,\n",
            "        -0.0328,  0.1051,  0.0455, -0.0591,  0.0533, -0.0107,  0.0628,  0.0418,\n",
            "        -0.0585, -0.0198,  0.0507,  0.1397,  0.0970,  0.0497,  0.0359,  0.0557,\n",
            "         0.0107, -0.0970,  0.0223, -0.0072,  0.0257,  0.0284,  0.0596,  0.0403,\n",
            "        -0.0319,  0.0640,  0.0387, -0.1182,  0.0775,  0.0133,  0.0969,  0.0493,\n",
            "         0.1244, -0.0002, -0.0183, -0.0494, -0.0306,  0.0614,  0.0021,  0.0169,\n",
            "        -0.0366,  0.0255, -0.0617,  0.0966,  0.0096, -0.0549,  0.0866, -0.0209,\n",
            "         0.0197, -0.0598, -0.0140, -0.0408, -0.0333, -0.0302, -0.0612,  0.0158,\n",
            "         0.1167,  0.0312, -0.0568,  0.0413,  0.1525,  0.0264,  0.0933,  0.0568,\n",
            "        -0.0198, -0.0206,  0.0587,  0.0551, -0.0079,  0.0882, -0.0533,  0.0241,\n",
            "         0.0308, -0.0357, -0.0095, -0.0273, -0.0221,  0.0544,  0.0589,  0.0298,\n",
            "         0.0117, -0.0966,  0.0871,  0.0668,  0.0435,  0.0052, -0.0077, -0.0286,\n",
            "        -0.0045,  0.0628,  0.0264,  0.0408,  0.0156,  0.0190, -0.0422, -0.0095,\n",
            "         0.0447,  0.0455,  0.0699, -0.0390,  0.0674,  0.0257, -0.1114,  0.0379,\n",
            "         0.0807, -0.0807,  0.0705,  0.0396, -0.0287,  0.0522,  0.0106, -0.0277,\n",
            "         0.0215, -0.0261,  0.0261,  0.0513, -0.0551,  0.0444, -0.0251,  0.0876,\n",
            "         0.0434,  0.1046,  0.0345,  0.0010, -0.0150, -0.0496,  0.1081,  0.0683,\n",
            "         0.0438, -0.0525, -0.0535,  0.0995,  0.0457, -0.0374, -0.0136,  0.0462,\n",
            "         0.0678, -0.0267,  0.0794, -0.0181,  0.0145, -0.0214, -0.0075,  0.0168,\n",
            "        -0.0049, -0.0271,  0.0450,  0.0300,  0.0285,  0.0660, -0.0330,  0.0398,\n",
            "         0.0076, -0.0145,  0.0006, -0.0499,  0.0677,  0.0356,  0.0241, -0.0635,\n",
            "        -0.0388,  0.1191,  0.0301,  0.0151,  0.1555,  0.0327,  0.0345, -0.0033,\n",
            "        -0.0551, -0.0069, -0.0053, -0.0293,  0.0788, -0.0715,  0.0223,  0.0250,\n",
            "        -0.0113,  0.0885, -0.0045,  0.0330, -0.0248, -0.0088,  0.0088, -0.0252,\n",
            "         0.0399, -0.0087, -0.0228,  0.0207, -0.0499,  0.0374, -0.0227,  0.0218,\n",
            "         0.0292,  0.0301,  0.0721,  0.0119, -0.1050,  0.0448,  0.0257, -0.0114,\n",
            "         0.0468,  0.0504, -0.0438,  0.0556,  0.1026,  0.1154,  0.0468,  0.0193,\n",
            "        -0.0387,  0.0119,  0.0774,  0.0985, -0.0316, -0.0006, -0.0620,  0.0662,\n",
            "         0.0751,  0.0364,  0.0356, -0.0836,  0.0885,  0.0359,  0.1011, -0.0067,\n",
            "         0.0614,  0.0457, -0.0042,  0.0387,  0.0080, -0.0251,  0.0165,  0.0029,\n",
            "         0.0439,  0.0049,  0.0415,  0.0310, -0.0622,  0.0241, -0.0237,  0.0223,\n",
            "         0.0394,  0.0309, -0.0150, -0.0101,  0.0649,  0.0607, -0.0411,  0.0456,\n",
            "         0.0233,  0.0396, -0.0088, -0.0119,  0.0474,  0.0197,  0.0086, -0.0055,\n",
            "        -0.0266,  0.0140, -0.0127,  0.0463,  0.0253, -0.0075,  0.0132, -0.0043,\n",
            "         0.0261,  0.0367,  0.0113,  0.0337,  0.0545, -0.0174,  0.0275,  0.0484,\n",
            "        -0.0089,  0.0230,  0.0185,  0.0417, -0.0018,  0.0166, -0.0314,  0.0153,\n",
            "         0.0049,  0.0515, -0.0549,  0.0202, -0.0510, -0.0069, -0.0248, -0.0142,\n",
            "        -0.0077,  0.0312,  0.0111,  0.0552,  0.0193, -0.0133, -0.0080, -0.0087,\n",
            "         0.0303,  0.0356, -0.0411,  0.0223, -0.0316,  0.0343, -0.0697, -0.0096,\n",
            "        -0.0515, -0.0175, -0.0121, -0.0101,  0.0318,  0.0277,  0.0051,  0.0386,\n",
            "        -0.0109, -0.0263,  0.0035, -0.0497,  0.0250, -0.0009, -0.0078,  0.0487,\n",
            "        -0.0117, -0.0158,  0.0658, -0.0030,  0.0104,  0.0269, -0.0224,  0.0280,\n",
            "        -0.0198,  0.0558,  0.0157, -0.0401, -0.0263,  0.0306, -0.0251, -0.0347,\n",
            "         0.0299,  0.0216, -0.0366,  0.0088,  0.0474, -0.0226, -0.0312, -0.0144,\n",
            "        -0.0318, -0.0280, -0.0269,  0.0149, -0.0313, -0.0410,  0.0574,  0.0027,\n",
            "         0.0257, -0.0032, -0.0233, -0.0047, -0.0283,  0.0446,  0.0289, -0.0091,\n",
            "         0.0340,  0.0041, -0.0451,  0.0098, -0.0026, -0.0221, -0.0080, -0.0665,\n",
            "        -0.0311,  0.0210,  0.0128, -0.0231,  0.0676,  0.0072,  0.0379,  0.0310,\n",
            "         0.0643,  0.0148,  0.0156, -0.0330,  0.0621,  0.0038, -0.0395, -0.0150,\n",
            "         0.0085,  0.0559, -0.0054,  0.0167,  0.0438, -0.0293, -0.0012, -0.0146,\n",
            "        -0.0271,  0.0456,  0.0330, -0.0313, -0.0659,  0.0496, -0.0209,  0.0131,\n",
            "        -0.0593,  0.0184,  0.0348, -0.0270,  0.0655, -0.0040,  0.0527,  0.0142,\n",
            "         0.0116,  0.0317,  0.0092,  0.0451,  0.0024, -0.0391,  0.0227,  0.0034,\n",
            "        -0.0317, -0.0124,  0.0349,  0.0196,  0.0659,  0.0146,  0.0012,  0.0175,\n",
            "        -0.0316,  0.0380, -0.0294, -0.0282,  0.0228,  0.0427,  0.0380, -0.0016,\n",
            "         0.0364, -0.0576,  0.0479, -0.0359, -0.0398, -0.0316, -0.0496,  0.0239,\n",
            "         0.0293,  0.0507,  0.0590, -0.0068,  0.0641, -0.0318,  0.0355,  0.0459,\n",
            "         0.0613, -0.0078, -0.0041, -0.0170, -0.0178, -0.0134, -0.0164, -0.0107,\n",
            "        -0.0366, -0.0325,  0.0018, -0.0513, -0.0398,  0.0166,  0.0068,  0.0083,\n",
            "         0.0300,  0.0272,  0.0567,  0.0504,  0.0047,  0.0441,  0.0187, -0.0013,\n",
            "        -0.0253, -0.0367, -0.0558, -0.0453, -0.0383, -0.0430, -0.0191, -0.0199],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "fc.weight Parameter containing:\n",
            "tensor([[-0.0078, -0.0117,  0.0297,  ...,  0.0033, -0.0503,  0.0034],\n",
            "        [-0.0264,  0.0081, -0.0340,  ..., -0.0421,  0.0224, -0.0007],\n",
            "        [ 0.0329, -0.0620,  0.0299,  ..., -0.0278,  0.0171, -0.0106],\n",
            "        ...,\n",
            "        [ 0.0169,  0.0596,  0.0451,  ...,  0.0536,  0.0043,  0.0519],\n",
            "        [-0.0423,  0.0513, -0.0425,  ...,  0.0271, -0.0224,  0.0222],\n",
            "        [ 0.0545,  0.0413, -0.0353,  ..., -0.0263,  0.0554, -0.0512]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "fc.bias Parameter containing:\n",
            "tensor([ 3.2572e-02, -1.0464e-02, -2.5509e-03, -7.2624e-03,  3.4888e-03,\n",
            "        -9.7075e-03, -1.4747e-02,  3.4233e-02, -3.7409e-02, -2.5019e-03,\n",
            "        -1.3208e-02, -2.7113e-02, -8.1463e-03, -1.7373e-02,  8.3301e-03,\n",
            "         1.5390e-03, -1.3858e-02, -6.6083e-03,  3.1442e-02, -1.9103e-02,\n",
            "         2.3520e-02,  2.5577e-03, -2.2017e-02, -2.3877e-03,  8.3177e-03,\n",
            "        -1.1290e-02,  1.7991e-02,  2.9763e-04,  9.9331e-03,  9.5805e-03,\n",
            "        -1.7585e-02, -7.1426e-03,  3.4039e-02, -7.0553e-03,  3.1702e-02,\n",
            "         1.2484e-02, -2.5751e-03, -3.2534e-02,  2.8350e-02, -2.5117e-02,\n",
            "        -8.0775e-03,  3.7476e-03, -6.6303e-03,  2.5945e-02,  2.4435e-02,\n",
            "        -8.4460e-03, -2.9880e-02,  2.4770e-02,  1.6974e-02, -1.3847e-02,\n",
            "         2.5687e-02,  1.7664e-02, -2.5589e-02, -4.8313e-03,  3.7409e-02,\n",
            "         1.1708e-02,  1.8203e-02, -1.0285e-02,  1.0915e-02,  1.3994e-02,\n",
            "        -1.4325e-02,  3.1096e-02, -2.2147e-02,  2.8764e-02, -3.1569e-02,\n",
            "        -1.8966e-02, -1.3277e-02, -3.7628e-03,  2.5015e-02,  4.6059e-03,\n",
            "         1.1312e-02, -7.5501e-03, -1.1653e-02, -1.8419e-02, -5.9227e-04,\n",
            "        -1.4639e-02, -2.3417e-02,  9.6286e-03,  1.5673e-02,  4.3584e-03,\n",
            "        -7.5146e-03, -2.4042e-02,  1.5498e-02, -2.7059e-02,  1.1528e-02,\n",
            "         2.1130e-02, -1.4762e-02,  1.5990e-02,  3.9127e-02, -3.6618e-03,\n",
            "         2.1328e-02,  4.3091e-04, -5.9002e-03,  1.9185e-02, -2.8408e-02,\n",
            "         2.6416e-02, -6.1565e-03,  1.3010e-02, -1.3462e-02, -1.9050e-02,\n",
            "         1.2722e-02,  1.2783e-02,  6.2174e-03,  1.9151e-02,  2.4441e-02,\n",
            "        -2.4284e-02,  9.4419e-03, -5.3482e-04,  1.5038e-02, -1.7879e-02,\n",
            "         1.9896e-02, -2.4852e-02, -1.6614e-02, -2.7862e-02,  1.7216e-02,\n",
            "         1.3628e-02, -1.2825e-02, -2.1505e-03,  2.3370e-04,  5.3221e-05,\n",
            "        -2.8401e-02, -1.0284e-02, -6.3256e-03,  4.5991e-02,  3.3347e-02,\n",
            "         2.4960e-02,  2.3779e-02, -4.6268e-03, -3.2727e-02,  1.1388e-02,\n",
            "         1.7611e-02,  1.4647e-02, -8.7033e-03, -3.2679e-02,  3.9148e-02,\n",
            "        -7.8524e-03, -4.5434e-03,  5.5608e-03,  9.2434e-03, -1.0095e-02,\n",
            "        -2.2147e-02, -2.8414e-02, -2.3113e-02, -1.1229e-02, -5.9250e-03,\n",
            "        -2.6303e-03, -4.4614e-03,  2.0282e-02,  5.0573e-03,  2.0991e-02,\n",
            "        -1.2356e-02, -7.6084e-03, -2.4732e-02,  1.3577e-02,  1.8948e-02,\n",
            "        -1.8441e-02,  1.5029e-02, -1.3473e-02,  2.9478e-02, -3.7355e-02,\n",
            "         1.7708e-02,  1.3006e-03,  2.1563e-03,  2.0734e-02, -2.8297e-02,\n",
            "        -3.1879e-02,  3.4726e-02, -3.2166e-02,  8.0805e-03, -1.1723e-02,\n",
            "        -1.0538e-02,  5.1845e-03,  2.2257e-02, -6.0376e-03,  3.6494e-02,\n",
            "        -1.1648e-02,  1.3176e-02,  2.3264e-02,  2.0011e-02,  1.8152e-03,\n",
            "         1.3040e-02, -1.2996e-02,  2.1902e-03, -5.9122e-03, -2.3662e-02,\n",
            "        -1.5256e-02, -1.8614e-02, -7.3763e-03, -2.0500e-02,  3.2907e-02,\n",
            "        -2.6348e-02,  3.2031e-02, -1.7042e-02,  3.4193e-02, -1.3551e-02,\n",
            "         5.3482e-03,  1.8011e-02, -4.8581e-03,  3.9242e-02,  9.3517e-03,\n",
            "        -6.2048e-03, -1.8391e-02, -1.3544e-02,  7.7136e-03, -1.6787e-02,\n",
            "        -1.4647e-02,  4.0825e-02, -2.6632e-02, -4.8677e-03,  2.2060e-02,\n",
            "         2.3129e-02,  2.2688e-02,  2.0481e-02, -2.8723e-02, -1.4987e-02,\n",
            "         1.4206e-03, -2.2272e-02, -1.4527e-02,  2.3970e-02,  3.2605e-02,\n",
            "         4.2814e-03, -2.4278e-02,  3.6037e-02, -1.1108e-02, -2.5274e-02,\n",
            "         8.6016e-03, -1.4938e-02,  1.1163e-02,  4.6899e-03, -2.5033e-02,\n",
            "         4.6811e-03,  2.1960e-02,  4.0731e-03,  1.6096e-02, -1.7405e-02,\n",
            "        -2.1317e-02, -1.1465e-02, -4.7924e-03, -1.8327e-02,  1.3925e-02,\n",
            "        -3.3434e-02,  2.4264e-02, -5.2903e-03, -7.8169e-03,  7.5401e-03,\n",
            "        -3.1435e-02,  9.2252e-03, -1.9421e-02,  2.4039e-02,  1.0782e-02,\n",
            "        -1.2087e-03,  2.8916e-02,  2.4656e-02, -1.0763e-02, -9.6870e-03,\n",
            "         4.3107e-03], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEWGq2WGi9a",
        "outputId": "649e3612-f156-496e-d8d5-fc576110e2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0015, -0.0132,  0.0280,  ...,  0.0297,  0.0289,  0.0152],\n",
            "        [ 0.0168,  0.0031, -0.0288,  ..., -0.0064, -0.0137, -0.0085]])\n"
          ]
        }
      ],
      "source": [
        "# print(vars(agent.jepa.pred.))\n",
        "# print(vars(agent.tcost.state_dict()))\n",
        "# print(agent.jepa.pred._parameters.keys())\n",
        "# print(agent.jepa.pred._parameters['weight_ih_l0'])\n",
        "# print(agent.jepa.pred._parameters['weight_hh_l2']) # weight_hh_l0, weight_hh_l2\n",
        "# print(agent.tcost.state_dict().keys())\n",
        "print(agent.tcost.state_dict()['tcost.1.weight']) # tcost.2.bias, tcost.4.bias\n",
        "# print(agent.tcost.named_parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S_xnBFjXVxgz"
      },
      "outputs": [],
      "source": [
        "# @title transfer weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "d = 10  # size of the first dimension\n",
        "a = 5   # size of the extra nodes to omit\n",
        "m = 8   # output dimension\n",
        "\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "target_layer = nn.Linear(d, m)\n",
        "# source_layer = nn.Linear(d, m)\n",
        "# target_layer = nn.Linear(d+a, m)\n",
        "\n",
        "def transfer(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt.weight[:, :src.weight.shape[1]].copy_(src.weight[:, :tgt.weight.shape[1]])\n",
        "        tgt.bias.copy_(src.bias)\n",
        "    return tgt,src\n",
        "\n",
        "target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "src_sd = source_layer.state_dict()\n",
        "tgt_sd = target_layer.state_dict()\n",
        "\n",
        "def transfersd(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt['weight'][:, :src['weight'].shape[1]].copy_(src['weight'][:, :tgt['weight'].shape[1]])\n",
        "        tgt['bias'].copy_(src['bias'])\n",
        "    return tgt\n",
        "\n",
        "tgt_sd = transfersd(tgt_sd, src_sd)\n",
        "target_layer.load_state_dict(tgt_sd)\n",
        "\n",
        "\n",
        "agent_src = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "\n",
        "# agent.tcost = TCost((1+agent.jepa.pred.num_layers)*agent.d_model) # replace tcost\n",
        "\n",
        "agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# agent.jepa.pred\n",
        "# target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(vars(agent.jepa.pred))\n",
        "# gru = agent.jepa.pred\n",
        "# gru = agent_src.jepa.pred\n",
        "# for wht_name in gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, gru._parameters[wht_name].shape)\n",
        "\n",
        "# weight_ih_l0 dim_z=3: [768, 262] , dim_z=1: [768, 260]\n",
        "# weight_hh_l0 torch.Size([768, 256])\n",
        "# bias_ih_l0 torch.Size([768])\n",
        "# bias_hh_l0 torch.Size([768])\n",
        "\n",
        "# tgt_gru = agent.jepa.pred\n",
        "# src_gru = agent_src.jepa.pred\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "\n",
        "tgt_gru[]\n",
        "def transfer_gru(tgt_gru, src_gru): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for i in range(min(len(tgt_gru._all_weights), len(src_gru._all_weights))):\n",
        "        # for lyr in tgt_gru._all_weights:\n",
        "            lyr = tgt_gru._all_weights[i]\n",
        "            for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "                # print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "                tgt_wht, src_wht = tgt_gru._parameters[wht_name], src_gru._parameters[wht_name]\n",
        "                if len(tgt_wht.shape)==2:\n",
        "                    tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "                elif len(tgt_wht.shape)==1:\n",
        "                    tgt_gru._parameters[wht_name] = src_wht\n",
        "    return tgt_gru\n",
        "tgt_gru = transfer_gru(tgt_gru, src_gru)\n",
        "\n",
        "# for wht_name in tgt_gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d_model=256; dim_a=3; dim_z=1; dim_v=512\n",
        "\n",
        "pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "# pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "print(pred._all_weights)\n",
        "for lyr in pred._all_weights:\n",
        "    for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "        print(wht_name, pred._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(pred.state_dict().keys())\n",
        "\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "print(tgt_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "print(src_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "\n",
        "print(tgt_gru.state_dict()['bias_ih_l0'][:10])\n",
        "print(src_gru.state_dict()['bias_ih_l0'][:10])\n",
        "tgt_gru.state_dict().keys()\n",
        "src_gru.state_dict().keys()\n",
        "\n",
        "# tgt_gru\n",
        "# src_gru\n",
        "for wht_name in tgt_gru.state_dict().keys():\n",
        "    if not wht_name in src_gru.state_dict().keys(): continue\n",
        "    print(wht_name)\n",
        "    # print(tgt_gru.state_dict()[wht_name])\n",
        "    # tgt_gru.state_dict()[wht_name].copy_(src_gru.state_dict()[wht_name])\n",
        "\n",
        "tgt_sd = tgt_gru.state_dict()\n",
        "src_sd = src_gru.state_dict()\n",
        "def transfer_sd(tgt_sd, src_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            # print(wht_name)\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            if len(tgt_wht.shape)==2:\n",
        "                tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "            elif len(tgt_wht.shape)==1:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "    return tgt_sd\n",
        "tgt_sd = transfer_sd(tgt_sd, src_sd)\n",
        "print(tgt_sd['weight_ih_l0'][0][:10])\n",
        "print(tgt_sd['bias_ih_l0'][:10])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwApoQMMKzB",
        "outputId": "55f16b74-1895-4f1d-d8a8-1d2599b24e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.4819, 0.6553, 0.9985, 1.0000, 0.9985, 0.9994, 0.9359, 0.9996, 0.9644,\n",
            "        0.9341, 0.9024, 0.9997, 1.0000, 0.7107, 0.9998])\n",
            "0.0003056526184082031\n",
            "tensor([0.2441, 0.1957, 0.3679, 0.2116, 0.2805, 0.2153, 0.2356, 0.2736])\n"
          ]
        }
      ],
      "source": [
        "# @title test init norm\n",
        "print(agent.emb.state_dict()['weight'].norm(dim=-1))\n",
        "\n",
        "# x = torch.rand(16)\n",
        "x = torch.rand(8,16)\n",
        "# print(x)\n",
        "# torch.nn.init.normal_(x, mean=0.0, std=1.0)\n",
        "# torch.nn.init.xavier_normal_(x)\n",
        "import time\n",
        "start = time.time()\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # 0.00966, 0.000602, 0.0004\n",
        "torch.nn.init.normal_(x, mean=0.0, std=.25/x.shape[-1]**0.5)\n",
        "# torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "print(time.time()-start)\n",
        "# std = ((Sum (xi-mean)^2)/ N)^(1/2)\n",
        "# print(x)\n",
        "# print(((x**2).sum())**(0.5))\n",
        "print(torch.norm(x, dim=-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_VgsenYLpM",
        "outputId": "8c7b23ae-8cdb-4846-dae3-32fd046a4d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[0.0437, 0.3097, 0.4537]]], requires_grad=True)\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n"
          ]
        }
      ],
      "source": [
        "# @title test rnn_pred symlog\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "# fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # xx = fsq(x)\n",
        "    # xx = fsq(x.clone())\n",
        "    # print(xx)\n",
        "    # x = torch.tanh(x)\n",
        "    # loss = x.sum()\n",
        "    # loss = model(xx)\n",
        "    loss = model(x)\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    # x = torch.clamp(x, min=-1, max=1)\n",
        "    # x = torch.clamp(x.clone(), min=-1, max=1)\n",
        "    with torch.no_grad():\n",
        "        # x.clamp_(min=-1, max=1)\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # model = nn.Sequential(nn.Linear(3,1))\n",
        "# model = nn.Sequential(nn.Linear(3*2,1))\n",
        "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# batch_size = 1\n",
        "# seq_len = 3\n",
        "# x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# # torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "\n",
        "# def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "#     batch, seq_len, dim_a = la.shape\n",
        "#     cost = 0\n",
        "#     lsx=sx\n",
        "#     for t in range(seq_len): # simple single layer\n",
        "#         a = la[:,t] # [1, dim_a]\n",
        "#         sxaz = torch.cat([sx, a], dim=-1)\n",
        "#         # with torch.amp.autocast('cuda'):\n",
        "#         cost = cost + model(sxaz)\n",
        "#         lsx = torch.cat([lsx, sx], dim=0)\n",
        "#     return cost, sx\n",
        "\n",
        "\n",
        "# # def ste_clamp(input, min=-1, max=1):\n",
        "# #     clamped_output = torch.clamp(input, min, max)\n",
        "# #     clamp_mask = (input < min) | (input > max)\n",
        "# #     return torch.where(clamp_mask, input, clamped_output)\n",
        "\n",
        "# def ste_clamp(x, min=-1, max=1):\n",
        "#     return torch.clamp(x, min, max).detach() + x - x.detach()\n",
        "\n",
        "# def ste_abs(x): return x.sign() * x\n",
        "# def symlog(x): return torch.sign(x) * torch.log(ste_abs(x) + 1.0)\n",
        "# def symexp(x): return torch.sign(x) * torch.exp(ste_abs(x) - 1.0)\n",
        "\n",
        "\n",
        "# sx = torch.rand((batch_size,3),device=device)\n",
        "# sx_ = sx.detach()\n",
        "# for i in range(10): # num epochs\n",
        "#     # la = fsq(x.clone())\n",
        "#     la = fsq(x)\n",
        "#     print(i)\n",
        "#     print(x,x.requires_grad)\n",
        "#     print(la,la.requires_grad)\n",
        "#     loss, sx_ = rnn_pred(sx_, la)\n",
        "#     # loss.backward()\n",
        "#     loss.backward(retain_graph=True) # retain_graph bec fsq got tanh that creates new graph?\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     # x = torch.tanh(x)\n",
        "#     # x = torch.clamp(x, min=-1, max=1)\n",
        "#     # x = ste_clamp(x.clone(), min=-1, max=1)\n",
        "#     # x = symlog(x.clone())\n",
        "#     # sx_ = sx_.detach()\n",
        "\n",
        "\n",
        "# # print(xx)\n",
        "# print(x)\n",
        "# # print(xhat)\n",
        "# print(la)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pGZld_gLH1RA"
      },
      "outputs": [],
      "source": [
        "# @title test bptt\n",
        "\n",
        "x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    loss=0\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        # loss = loss -stcost(xxx.clone()).sum()\n",
        "        loss = loss -stcost(xxx).sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "# RuntimeError: Output 1 of SplitBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size, T = 1,6\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "# optim = torch.optim.SGD([x], lr=1e-3)\n",
        "# # xx = torch.split(x, bptt, dim=1)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    loss=0\n",
        "    # xx = torch.split(x, bptt, dim=1)\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        loss = loss -stcost(xxx.clone()).sum()\n",
        "        # loss = loss -stcost(xxx).sum()\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jepapred = nn.Sequential(nn.Linear(3*2,3))\n",
        "stcost = nn.Sequential(nn.Linear(3,1))\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    for t in range(seq_len): # simple single layer\n",
        "        # print(la.shape)\n",
        "        a = la[:,t,:].clone() # [1, dim_a]\n",
        "        # sxaz = torch.cat([sx, a], dim=-1)\n",
        "        sxaz = torch.cat([sx.clone(), a.clone()], dim=-1)\n",
        "        # sxaz = torch.cat([sx.clone(), a], dim=-1)\n",
        "        sx = jepapred(sxaz)\n",
        "        tcost = -stcost(sx).sum()\n",
        "        lsx = torch.cat([lsx, sx], dim=0)\n",
        "        # print(lsx.requires_grad, sx.requires_grad)\n",
        "        # icost = 0.5*icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(icost.requires_grad)\n",
        "        cost += tcost# + icost\n",
        "    return cost, sx#, z\n",
        "\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "sx = torch.rand((batch_size,3),device=device)\n",
        "T = 6\n",
        "bptt = 3\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device)) # FSQ 3 levels\n",
        "x = torch.empty((batch_size, T, 3),device=device) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "# optim = torch.optim.SGD([x], lr=1e-3) #, maximize=True)\n",
        "# print(x.shape)\n",
        "# print(len(xx))\n",
        "# print(xx[0].shape)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    sx_ = sx.detach()\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "\n",
        "        # xxx=x\n",
        "        # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        la = fsq(xxx)\n",
        "        # la = xxx\n",
        "        # print(x,x.requires_grad)\n",
        "        # print(la,la.requires_grad)\n",
        "        # loss, sx_ = rnn_pred(sx_, la)\n",
        "        loss = -stcost(la).sum()\n",
        "\n",
        "        print(\"loss\",loss)\n",
        "        loss.backward()\n",
        "        # loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # sx_ = sx_.detach()\n",
        "        # print(loss.item(), lact)\n",
        "\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    x = torch.tanh(x) # clamp\n",
        "    print(x)\n",
        "    # print(x)\n",
        "print(\"search\",loss.item())\n",
        "# print(lact)\n",
        "# return la, lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # def search(self, sx, T=256, bptt=32):\n",
        "    # def search(self, sx, T=None, bptt=None):\n",
        "    #     if T==None: T = 256\n",
        "    #     if bptt==None: bptt = min(T,3)\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "    #     torch.nn.init.xavier_uniform_(x)\n",
        "    #     # optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "    #     # xx = torch.split(x, bptt, dim=1)\n",
        "    #     xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "    #     optim = torch.optim.SGD(xx, lr=1e7) #, maximize=True)\n",
        "\n",
        "    #     for _ in range(10): # num epochs\n",
        "    #         sx_ = sx.detach()\n",
        "    #         for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    #             # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "    #             la = fsq(xxx.clone())\n",
        "    #             # print(x,x.requires_grad)\n",
        "    #             # print(la,la.requires_grad)\n",
        "    #             loss, sx_ = self.rnn_pred(sx_, la)\n",
        "    #             loss.backward(retain_graph=True)\n",
        "    #             optim.step()\n",
        "    #             optim.zero_grad()\n",
        "    #             sx_ = sx_.detach()\n",
        "    #             # print(loss.item(), lact)\n",
        "    #             # xx = torch.tanh(xx) # clamp\n",
        "    #         xx = [torch.tanh(xxx) for xxx in xx]\n",
        "    #         x = torch.cat(xx,dim=1)\n",
        "    #         # x = torch.tanh(x) # clamp\n",
        "    #         print(x)\n",
        "    #     print(\"search\",loss.item())\n",
        "    #     # print(lact)\n",
        "    #     return la, lact # [batch_size, T]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YWmwVYhVVh5R"
      },
      "outputs": [],
      "source": [
        "# @title test ste_argmin\n",
        "import torch\n",
        "emb = torch.nn.Embedding(15, 3) # env.action_space # 15\n",
        "x = torch.rand(1,3)\n",
        "\n",
        "# def ste_argmin(x, dim=-1):\n",
        "#     idx = torch.argmin(x, dim)\n",
        "#     # out = torch.zeros_like(x)\n",
        "#     out = torch.zeros_like(idx).unsqueeze(-1)\n",
        "#     print(idx.shape, out.shape)\n",
        "#     out.scatter_(1, idx, 1)\n",
        "#     return out\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# def softargmin(x, beta=10):\n",
        "#     # Apply softmax to the negative of the input to approximate argmin\n",
        "#     weights = F.softmax(-x * beta, dim=-1)\n",
        "#     indices = torch.arange(x.size(-1), dtype=x.dtype, device=x.device)\n",
        "#     soft_argmin = torch.sum(weights * indices, dim=-1)\n",
        "#     return soft_argmin\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "# out = differentiable_argmax(-x)\n",
        "# print(out)\n",
        "\n",
        "\n",
        "# def softargmax1d(input, beta=100): # https://github.com/david-wb/softargmax/blob/master/softargmax.py\n",
        "#     *_, n = input.shape\n",
        "#     input = nn.functional.softmin(beta * input, dim=-1)\n",
        "#     indices = torch.linspace(0, 1, n)\n",
        "#     result = torch.sum((n - 1) * input * indices, dim=-1)\n",
        "#     return result\n",
        "\n",
        "# ste_round\n",
        "\n",
        "# # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "# dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "# print(lact)\n",
        "\n",
        "device='cpu'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "    dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    A=differentiable_argmax(-dist)\n",
        "    # print(A.shape)\n",
        "    print(torch.argmax(A))\n",
        "    x_=A@emb.weight.data\n",
        "    # print(\"dist\", dist.shape)\n",
        "    # lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = ste_argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = softargmin(dist)\n",
        "    # print(lact)\n",
        "    # x = emb.weight.data[lact]\n",
        "\n",
        "    # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "    print(\"x_\",x_)\n",
        "    # x = emb(x_)\n",
        "\n",
        "    loss = model(x_).sum()\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "x_ = torch.tensor([14])\n",
        "x = emb(x_)\n",
        "# print(x)\n",
        "# # print(emb.weight)\n",
        "# pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "pseudo_inverse_weight = torch.linalg.pinv(emb.weight)\n",
        "# weight_inv = torch.pinverse(emb.weight.T)\n",
        "\n",
        "dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "# print(x@pseudo_inverse_weight)\n",
        "# A=differentiable_argmax(-x@pseudo_inverse_weight)\n",
        "A=differentiable_argmax(-dist)\n",
        "print(A)\n",
        "\n",
        "# print(pseudo_inverse_weight.shape, pseudo_inverse_weight)\n",
        "# # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "# x_ = x@ pseudo_inverse_weight\n",
        "# print(\"x_\",x_)\n",
        "\n",
        "# print(emb.weight@ pseudo_inverse_weight)\n",
        "# dist=torch.dist(emb.weight@ pseudo_inverse_weight, torch.eye(15))\n",
        "# print(dist)\n",
        "# print(pseudo_inverse_weight@ emb.weight)\n",
        "\n",
        "# print(emb.weight@ weight_inv.T)\n",
        "# print(weight_inv.T@ emb.weight)\n",
        "\n",
        "# torch.linalg.lstsq(A, B).solution\n",
        "\n",
        "\n",
        "x_ = torch.tensor([4])\n",
        "embx = emb(x_) # emb.weight[x_,:]\n",
        "print(embx)\n",
        "\n",
        "Apinv = torch.linalg.pinv(A)\n",
        "x = embx@Apinv\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_UlGz6Xoq3"
      },
      "source": [
        "## archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AodVas3L4ZS",
        "outputId": "f1940ab6-b72d-4c8d-f97d-6d876f1b92e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 256])\n",
            "136960\n",
            "136960\n"
          ]
        }
      ],
      "source": [
        "# @title efficientnet\n",
        "# https://arxiv.org/pdf/2207.10318 # visualise kernal\n",
        "\n",
        "# https://pytorch.org/hub/research-models\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/shufflenetv2.py\n",
        "\n",
        "import torch\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py\n",
        "from torchvision.models.efficientnet import *\n",
        "from torchvision.models import efficientnet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # https://arxiv.org/pdf/2104.00298\n",
        "# Stage Operator Stride #Channels #Layers\n",
        "# 0 Conv3x3 2 24 1\n",
        "# 1 Fused-MBConv1, k3x3 1 24 2\n",
        "# 2 Fused-MBConv4, k3x3 2 48 4\n",
        "# 3 Fused-MBConv4, k3x3 2 64 4\n",
        "# 4 MBConv4, k3x3, SE0.25 2 128 6\n",
        "# 5 MBConv6, k3x3, SE0.25 1 160 9\n",
        "# 6 MBConv6, k3x3, SE0.25 2 256 15\n",
        "# 7 Conv1x1 & Pooling & FC - 1280 1\n",
        "\n",
        "# # elif arch.startswith(\"efficientnet_v2_s\"):\n",
        "# inverted_residual_setting = [\n",
        "#     FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
        "#     FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
        "#     FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
        "#     MBConvConfig(4, 3, 2, 64, 128, 6),\n",
        "#     MBConvConfig(6, 3, 1, 128, 160, 9),\n",
        "#     MBConvConfig(6, 3, 2, 160, 256, 15),\n",
        "# ]\n",
        "# last_channel = 1280\n",
        "\n",
        "# d_list=[24, 48, 64, 128, 160, 256] #\n",
        "d_list=[16, 32, 48, 96, 108, 172] #\n",
        "inverted_residual_setting = [\n",
        "    efficientnet.FusedMBConvConfig(1, 3, 1, d_list[0], d_list[0], 2),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[0], d_list[1], 4),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[1], d_list[2], 4),\n",
        "    efficientnet.MBConvConfig(4, 3, 2, d_list[2], d_list[3], 6),\n",
        "    efficientnet.MBConvConfig(6, 3, 1, d_list[3], d_list[4], 9),\n",
        "    efficientnet.MBConvConfig(6, 3, 2, d_list[4], d_list[5], 15),\n",
        "]\n",
        "last_channel = 512\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "\n",
        "effnet = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "effnet.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "\n",
        "#   (features): Sequential(\n",
        "#     (0): Conv2dNormActivation(\n",
        "#       (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "#       (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "#       (2): SiLU(inplace=True)\n",
        "\n",
        "input = torch.rand((1,1,256,256), device=device)\n",
        "out = effnet(input)\n",
        "print(out.shape)\n",
        "# print(effnet)\n",
        "print(sum(p.numel() for p in effnet.parameters() if p.requires_grad)) #\n",
        "print(sum(p.numel() for p in effnet.parameters())) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "# !pip install -qq vector-quantize-pytorch\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LK5u500Vad2P"
      },
      "outputs": [],
      "source": [
        "# @title FSQ jax\n",
        "# https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "Codeword = jax.Array\n",
        "Indices = jax.Array\n",
        "\n",
        "def round_ste(z):\n",
        "  \"\"\"Round with straight through gradients.\"\"\"\n",
        "  zhat = jnp.round(z)\n",
        "  return z + jax.lax.stop_gradient(zhat - z)\n",
        "\n",
        "class FSQ:\n",
        "  \"\"\"Quantizer.\"\"\"\n",
        "  def __init__(self, levels: list[int], eps: float = 1e-3):\n",
        "    self._levels = levels\n",
        "    self._eps = eps\n",
        "    self._levels_np = np.asarray(levels)\n",
        "    self._basis = np.concatenate(([1], np.cumprod(self._levels_np[:-1]))).astype(np.uint32)\n",
        "    self._implicit_codebook = self.indexes_to_codes(np.arange(self.codebook_size))\n",
        "    print(\"self._basis\",self._basis)\n",
        "    print(\"self._implicit_codebook\",self._implicit_codebook)\n",
        "\n",
        "  @property\n",
        "  def num_dimensions(self):\n",
        "    \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
        "    return len(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook_size(self):\n",
        "    \"\"\"Size of the codebook.\"\"\"\n",
        "    return np.prod(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook(self):\n",
        "    \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
        "    return self._implicit_codebook\n",
        "\n",
        "  def bound(self, z: jax.Array) -> jax.Array:\n",
        "    \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "    half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
        "    offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
        "    shift = jnp.tan(offset / half_l)\n",
        "    return jnp.tanh(z + shift) * half_l - offset\n",
        "\n",
        "  def quantize(self, z: jax.Array) -> Codeword:\n",
        "    \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
        "    quantized = round_ste(self.bound(z))\n",
        "\n",
        "    # Renormalize to [-1, 1].\n",
        "    half_width = self._levels_np // 2\n",
        "    return quantized / half_width\n",
        "\n",
        "  def _scale_and_shift(self, zhat_normalized):\n",
        "    # Scale and shift to range [0, ..., L-1]\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "  def _scale_and_shift_inverse(self, zhat):\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat - half_width) / half_width\n",
        "\n",
        "  def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
        "    \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
        "    assert zhat.shape[-1] == self.num_dimensions\n",
        "    zhat = self._scale_and_shift(zhat)\n",
        "    return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
        "\n",
        "  def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
        "    \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
        "    indices = indices[..., jnp.newaxis]\n",
        "    print(indices, self._basis, self._levels_np)\n",
        "    print(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    codes_non_centered = np.mod(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    return self._scale_and_shift_inverse(codes_non_centered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xHxv7ptuwVHX"
      },
      "outputs": [],
      "source": [
        "# @title FSQ torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module): # https://colab.research.google.com/github/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "    def __init__(self, levels, eps = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cat([torch.ones(1, device=device), torch.cumprod(self.levels[:-1], dim=0)]).long()\n",
        "        self.num_dimensions = len(levels)\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        # self.mean = self.codebook.mean(dim=0)\n",
        "        # self.max = self.codebook.max(dim=0).values\n",
        "        # self.min = self.codebook.min(dim=0).values\n",
        "\n",
        "    def bound(self, z):\n",
        "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "        half_l = (self.levels - 1) * (1 - self.eps) / 2 # [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "        # half_l = (self.levels-1)/2 # me ?\n",
        "        offset = torch.where(self.levels % 2 == 1, 0.0, 0.5) # [0.0000, 0.0000, 0.5000] mean?\n",
        "        # print(\"half_l\", half_l)\n",
        "        # shift = torch.tan(offset / half_l) # [0.0000, 0.0000, 1.5608] < tan(1)\n",
        "\n",
        "        # print(\"shift\", shift)\n",
        "        # print(\"bound\", torch.tanh(z + shift) * half_l - offset)\n",
        "\n",
        "        # print(f'half_l {half_l}, shift {shift}, bound {torch.tanh(z + shift) * half_l - offset}')\n",
        "        # return torch.tanh(z + shift) * half_l - offset\n",
        "        # return torch.tanh(z - shift) * half_l + offset\n",
        "        return torch.tanh(z) * half_l + offset\n",
        "\n",
        "    def forward(self, z):\n",
        "        quantized = ste_round(self.bound(z))\n",
        "        # print(\"quantized\", quantized)\n",
        "        half_width = self.levels // 2 # Renormalize to [-1, 1]\n",
        "        return quantized / half_width\n",
        "\n",
        "    def _scale_and_shift(self, zhat_normalized): # Scale and shift to range [0, ..., L-1]\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "    def _scale_and_shift_inverse(self, zhat):\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat - half_width) / half_width\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        assert zhat.shape[-1] == self.num_dimensions\n",
        "        zhat = self._scale_and_shift(zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).long()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes_non_centered = torch.fmod(indices // self.basis, self.levels)\n",
        "        return self._scale_and_shift_inverse(codes_non_centered)\n",
        "\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "# print(fsq.codebook)\n",
        "\n",
        "# batch_size, seq_len = 1, 1\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SnfcKPses5X",
        "outputId": "7c50a3e3-281a-4375-b86f-ece58f6775c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "half_l tensor([0.9990, 0.9990, 0.4995]), shift tensor([0.0000, 0.0000, 1.5608]), bound tensor([-0.4617,  0.5365, -0.0515])\n",
            "quantized tensor([0., 1., 0.])\n",
            "tensor([0., 1., 0.])\n"
          ]
        }
      ],
      "source": [
        "# @title test fsq\n",
        "fsq = FSQ(levels = [4])\n",
        "\n",
        "# 2: 1.6 half_l tensor([0.4995]), shift tensor([1.5608]), bound tensor([-0.5195])\n",
        "# 3: 0.6 # half_l tensor([0.9990]), shift tensor([0.]), bound tensor([-0.9207])\n",
        "# 4: 0.4, 1.3 # half_l tensor([1.4985]), shift tensor([0.3466]), bound tensor([-1.7726])\n",
        "# 5: 0.5, 1 # half_l [1.9980], shift [0.], bound [-1.8415]\n",
        "x = torch.tensor([.9],device=device)\n",
        "# x = torch.tensor([-1.6],device=device)\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.tensor([-0.6,0.6,-1.6],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,-1.5],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,1.6],device=device)\n",
        "x = torch.tensor([-0.5,0.6,-0.1],device=device)\n",
        "\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "round emb\n",
        "\n",
        "# half_l [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "# offset [0.0000, 0.0000, 0.5000] mean?\n",
        "# shift [0.0000, 0.0000, 1.5608] torch.tan(offset / half_l)\n",
        "# bound [-0.5365,  0.5365, -0.4696] tanh(z + shift) * half_l - offset\n",
        "\n",
        "\n",
        "\n",
        "levels = torch.tensor([3,3,2])\n",
        "eps = 1e-3\n",
        "\n",
        "half_l = (levels - 1) * (1 - eps) / 2\n",
        "offset = torch.where(levels % 2 == 1, 0.0, 0.5)\n",
        "# print(\"half_l\", half_l)\n",
        "shift = torch.tan(offset / half_l)\n",
        "# print(\"shift\", shift)\n",
        "# print(\"bound\", torch.tanh(x + shift) * half_l - offset)\n",
        "# return torch.tanh(x + shift) * half_l - offset\n",
        "out = torch.tanh(x) * half_l + offset\n",
        "print(out)\n",
        "\n",
        "shift=torch.tan(torch.tensor([1.]))\n",
        "print(shift)\n",
        "bound = torch.tanh(x - shift)\n",
        "print(bound)\n",
        "\n",
        "print(torch.tanh(torch.tensor([0.])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90BTTw0Lr-t",
        "outputId": "a95870e2-bc89-43ba-d40b-febea4ce2382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 256])\n",
            "690080\n"
          ]
        }
      ],
      "source": [
        "# @title ConvEnc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ConvEnc(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[5], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[5], d_list[5], 2, 2, 0), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # 2457024\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # 685248\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 4, 2, 2), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 4, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 4, 2, 2), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 4, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # # #\n",
        "\n",
        "\n",
        "            nn.Conv2d(1, d_list[0], 4, 4, 0), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 4, 4, 0), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 4, 4, 0), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 4, 4, 0), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            #\n",
        "\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[5],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "\n",
        "convenc = ConvEnc(256).to(device)\n",
        "input = torch.rand((4,1,256,256), device=device)\n",
        "out = convenc(input)\n",
        "print(out.shape)\n",
        "print(sum(p.numel() for p in convenc.parameters() if p.requires_grad)) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B1yvJkX89C_o"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein\n",
        "import torch\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    # cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    # dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # cs = (x-y).cumsum(dim=-1)\n",
        "    cs = (x-y) @ torch.tril(torch.ones(x.shape[0], x.shape[0]))\n",
        "    # dist = weight * torch.abs(cs)\n",
        "    dist = weight * cs**2\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "\n",
        "def soft_wasserstein_loss(x, y, smoothing=0.1):\n",
        "    # Normalise distributions\n",
        "    x = x / x.sum()\n",
        "    y = y / y.sum()\n",
        "    # Compute the cumulative distributions (CDFs) with a small smoothing factor\n",
        "    cdf_x = torch.cumsum(x, dim=-1) + smoothing\n",
        "    cdf_y = torch.cumsum(y, dim=-1) + smoothing\n",
        "    # Compute smooth Wasserstein distance (L2 distance between CDFs)\n",
        "    distance = torch.norm(cdf_x - cdf_y, p=2)  # L2 distance instead of L1 for smoother gradients\n",
        "    return distance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5], dtype=float))\n",
        "x = nn.Parameter(torch.tensor([-0.01, -0.0, -0.99], dtype=torch.float))\n",
        "y = torch.tensor([0.0, 0.0, -1.0], dtype=torch.float)\n",
        "\n",
        "# x = nn.Parameter(torch.rand(1024, dtype=float))\n",
        "# y = torch.rand(1024, dtype=float)\n",
        "# a = len(train_data.buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "a=1/45\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "print(weight)\n",
        "dist = wasserstein(x, y, weight=weight)\n",
        "print(time.time() - start)\n",
        "print(dist)  # Should output 0.7\n",
        "# dist.backward()\n",
        "\n",
        "# 0.0004496574401855469\n",
        "# 0.000331878662109375\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3nfZRhVc9Ssp"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein sinkhorn train\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# agent.eval()\n",
        "# batch_size, T, _ = sx.shape\n",
        "x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3) # 3e3\n",
        "# optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.999)) # ? 1e0 ; 3e-2 1e-1\n",
        "# optim = torch.optim.AdamW([x], 1e-0, (0.9, 0.95)) # ? 1e0 ; 3e-2 1e-1\n",
        "y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=torch.float)\n",
        "a=1/45\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "# print(weight)\n",
        "\n",
        "# loss = wasserstein(x, y, weight=weight)\n",
        "# loss = wasserstein(x, y)\n",
        "# loss = sinkhorn(x, y)\n",
        "# loss.backward()\n",
        "# print(x.grad)\n",
        "\n",
        "\n",
        "for i in range(50): # num epochs\n",
        "    loss = wasserstein(x, y, weight=weight)\n",
        "    # loss = sinkhorn(x, y)\n",
        "    # loss = sinkhorn(x, y,0.05,80)\n",
        "    loss.sum().backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(x.data, loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "def sinkhorn(x, y, epsilon=0.05, max_iters=100):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "\n",
        "    # Compute the cost matrix: here the cost is the squared distance between indices\n",
        "    # (|i-j|^2 for each position i, j)\n",
        "    posx = torch.arange(x.shape[-1], dtype=torch.float).unsqueeze(1)\n",
        "    posy = torch.arange(y.shape[-1], dtype=torch.float).unsqueeze(0)\n",
        "    cost_matrix = (posx - posy).pow(2)  # squared distance\n",
        "\n",
        "    # Initialize the dual variables\n",
        "    u = torch.zeros_like(x)\n",
        "    v = torch.zeros_like(y)\n",
        "\n",
        "    # Sinkhorn iterations\n",
        "    K = torch.exp(-cost_matrix / epsilon)  # Kernel matrix, regularised with epsilon\n",
        "    for _ in range(max_iters):\n",
        "        u = x / (K @ (y / (K.t() @ u + 1e-8)) + 1e-8)\n",
        "        v = y / (K.t() @ (x / (K @ v + 1e-8)) + 1e-8)\n",
        "    # print(K,u.data,v.data)\n",
        "    plan = torch.diag(u) @ K @ torch.diag(v)\n",
        "    dist = torch.sum(plan * cost_matrix)\n",
        "    return dist\n",
        "\n",
        "# Example\n",
        "x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float, requires_grad=True)\n",
        "y = torch.tensor([0.0, 0.0, 1.0], dtype=torch.float)\n",
        "# x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "# y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=float)\n",
        "\n",
        "# dist = sinkhorn(x, y)\n",
        "dist = sinkhorn(x, y, 0.05,80)\n",
        "dist.backward()  # To compute gradients with respect to x\n",
        "\n",
        "print(dist.item())\n",
        "print(x.grad)\n",
        "\n",
        "# [2.0000e+07, 3.0000e+07, 1.0000e-08]) tensor([       0.,        0., 49999996.] episodes>=80\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s1_GgDzoDyYB"
      },
      "outputs": [],
      "source": [
        "# @title torchrl.data.PrioritizedReplayBuffer\n",
        "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
        "buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
        "\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "buffer_lazymemmap = ReplayBuffer(storage=LazyMemmapStorage(size), batch_size=32, sampler=SamplerWithoutReplacement())\n",
        "\n",
        "\n",
        "from torchrl.data import ListStorage, PrioritizedReplayBuffer\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "rb = PrioritizedReplayBuffer(alpha=0.7, beta=0.9, storage=ListStorage(10))\n",
        "data = range(10)\n",
        "rb.extend(data)\n",
        "# rb.extend(buffer)\n",
        "\n",
        "\n",
        "sample = rb.sample(3)\n",
        "print(sample)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gcvgdCB1h1_E"
      },
      "outputs": [],
      "source": [
        "# @title torch.optim.LBFGS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Example of a deep nonlinear model f(x)\n",
        "class DeepNonlinearModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNonlinearModel, self).__init__()\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(10, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "f = DeepNonlinearModel()\n",
        "# x = torch.randn(1, 10, requires_grad=True)\n",
        "# xx = torch.randn((1,10))\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "\n",
        "# Define loss function (mean squared error for this example)\n",
        "target = torch.tensor([[0.0]])  # Target output\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    return loss\n",
        "\n",
        "optimizer = torch.optim.LBFGS([x], lr=1.0, max_iter=5)  # Limit to 2-3 iterations for speed\n",
        "start_time = time.time()\n",
        "for _ in range(2):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step(closure)  # Perform a step of optimisation\n",
        "    print(loss.item())\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "start_time = time.time()\n",
        "optimizer = torch.optim.SGD([x], lr=1e1, maximize=True) # 3e3\n",
        "for _ in range(5):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step()  # Perform a step of optimisation\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    print(loss.item())\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gfzJ6zoL6vGc"
      },
      "outputs": [],
      "source": [
        "# @title torch.optim.LBFGS\n",
        "\n",
        "# def closure():\n",
        "#     optimizer.zero_grad()  # Zero out the gradients\n",
        "#     output = f(x)          # Forward pass through the model\n",
        "#     loss = loss_fn(output, target)  # Calculate the loss\n",
        "#     loss.backward()         # Backpropagate\n",
        "#     return loss\n",
        "\n",
        "batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "z = nn.Parameter(torch.zeros((batch_size, bptt, 1), device=device))\n",
        "torch.nn.init.normal_(z, mean=0., std=.3/z.shape[-1]**0.5)\n",
        "lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "print(z.squeeze().data[-1])\n",
        "# print(lz.squeeze().data[-1])\n",
        "\n",
        "\n",
        "# for batch, (state, action, reward) in enumerate(train_loader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "sy = agent.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device))#.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "\n",
        "def closure():\n",
        "    lz = torch.cat([z, torch.zeros((batch_size, bptt, agent.dim_z-z.shape[-1]), device=device)], dim=-1)\n",
        "    sy_, h0_ = sy.detach(), h0.detach()\n",
        "    lsy_, lh0 = agent.rnn_it(sy_, la, lz, h0_)\n",
        "    repr_loss = F.mse_loss(lsy, lsy_)\n",
        "    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "    clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "    cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl\n",
        "    cost.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "    return cost\n",
        "\n",
        "import time\n",
        "optimizer = torch.optim.LBFGS([z], lr=1e-2, max_iter=10)  # Limit to 2-3 iterations for speed\n",
        "start_time = time.time()\n",
        "for _ in range(20):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step(closure)  # Perform a step of optimisation\n",
        "    print(loss.item())\n",
        "\n",
        "end_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viimAIpYSJq_",
        "outputId": "2377ee32-2d6a-4c90-a91f-93ff4b885315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6931, 0.3133, 0.6931])\n",
            "tensor([[0.6931, 0.6931],\n",
            "        [0.3133, 1.3133],\n",
            "        [0.6931, 0.6931]])\n"
          ]
        }
      ],
      "source": [
        "# @title test CrossEntropyLoss\n",
        "\n",
        "labels = torch.tensor([0,0,0])\n",
        "pred = torch.tensor([[50.,50.],[1.,0.],[1.,1.]])\n",
        "\n",
        "a=10\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "# loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)]))\n",
        "print(loss_fn(pred, labels))\n",
        "\n",
        "# weight=torch.tensor([1/a, 1/(1-a)])\n",
        "weight=torch.tensor([1, 1])\n",
        "# weight=torch.tensor([1/2, 1/2])\n",
        "\n",
        "\n",
        "# print((pred@torch.log(pred).T).sum())\n",
        "# print(nn.Softmax(dim=-1)(pred))\n",
        "# print(-(weight*torch.log(nn.Softmax(dim=-1)(pred))).mean(-1))\n",
        "# print(-(labels.float()@torch.log(nn.Softmax(dim=-1)(pred))))\n",
        "print(-(torch.log(nn.Softmax(dim=-1)(pred))))\n",
        "# print(pred,torch.log(pred).T)\n",
        "\n",
        "arange = torch.arange(pred.shape[-1]).repeat(pred.shape[0],1)\n",
        "# torch.where(1,0).bool()\n",
        "mask=(arange==pred)\n",
        "\n",
        "# 2*pred-1\n",
        "# (1-pred)\n",
        "(pred[mask] + (1-pred[mask]))\n",
        "\n",
        "log_preds = torch.log(torch.softmax(pred, dim=1))\n",
        "target_log_probs = log_preds[range(pred.shape[0]), labels]\n",
        "loss = -torch.mean(target_log_probs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwRYdovgABiv"
      },
      "outputs": [],
      "source": [
        "# @title tensorboard\n",
        "# !pip install tensorboard\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter('runs/molecules')\n",
        "\n",
        "# writer.add_scalar(\"Loss/train\", 3.0, 1)\n",
        "# writer.add_scalar(\"Loss/train\", 2.0, 2)\n",
        "# writer.add_scalar(\"Loss/train\", 1.5, 3)\n",
        "# writer.flush()\n",
        "# writer.close()\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8WHjFn2gmzI"
      },
      "source": [
        "## plot 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VX5IExbRriwm"
      },
      "outputs": [],
      "source": [
        "# @title sklearn RBF\n",
        "# https://gist.github.com/eljost/2c4e1af652ef02b2989da341c5569af7\n",
        "# from nn_plot.ipynb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import scipy.stats as st\n",
        "\n",
        "# np.random.seed(1)\n",
        "def func(x):\n",
        "    # print(x.shape)\n",
        "    # x= np.sum(x**2, axis=-1)\n",
        "    x=np.random.rand(x.shape[0])\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "res = 50\n",
        "num_pts=15\n",
        "X=np.random.rand(num_pts,2)*res\n",
        "# Y = func(X)\n",
        "Y=np.random.rand(num_pts)\n",
        "# print(X);print(Y)\n",
        "\n",
        "lim = 1\n",
        "# lin = np.linspace(-lim, lim, res)\n",
        "lin = np.linspace(0, res, res)\n",
        "x1, x2 = np.meshgrid(lin, lin)\n",
        "xx = np.vstack((x1.flatten(), x2.flatten())).T\n",
        "\n",
        "kernel = RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X, Y)\n",
        "# print(\"Learned kernel\", gp.kernel_)\n",
        "y_mean, y_cov = gp.predict(xx, return_cov=True)\n",
        "\n",
        "posteriors = st.multivariate_normal.rvs(mean=y_mean, cov=y_cov, size=1)\n",
        "\n",
        "ax = plt.figure().add_subplot(projection='3d')\n",
        "Z=posteriors.reshape(-1, res)\n",
        "# ax.plot_surface(x1, x2, Z)\n",
        "ax.plot_surface(x1, x2, Z, cmap='rainbow', alpha=0.7)\n",
        "\n",
        "# ax.plot_surface(x1, x2, posteriors.reshape(-1, res))\n",
        "ax.contour(x1, x2, Z, zdir='z', offset=-1, cmap='coolwarm') # https://matplotlib.org/stable/gallery/mplot3d/contour3d_3.html#sphx-glr-gallery-mplot3d-contour3d-3-py\n",
        "# ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-0.4, 0.5))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-1, 2))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, c=zdata, cmap='Greens');\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, cmap='Greens');\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusX7gpzxFNL",
        "outputId": "9f14a9da-e188-49ba-f5f5-70192ff33134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.6321], grad_fn=<AddBackward0>)\n",
            "tensor([2.7358]) tensor([-4.7358])\n"
          ]
        }
      ],
      "source": [
        "# @title chatgpt RBFKernelLayer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RBFKernelLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(RBFKernelLayer, self).__init__()\n",
        "        self.centres = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        dists = torch.cdist(x, self.centres, p=2) ** 2\n",
        "        return torch.exp(-dists / (2 * self.sigma ** 2))\n",
        "\n",
        "class SaddlePointNetwork(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(SaddlePointNetwork, self).__init__()\n",
        "        self.rbf_layer = RBFKernelLayer(in_features, out_features, sigma)\n",
        "        self.linear = nn.Linear(out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rbf_output = self.rbf_layer(x)\n",
        "        # Introduce a saddle point structure\n",
        "        linear_output = self.linear(rbf_output)\n",
        "        # Example saddle function: x^2 - y^2\n",
        "        saddle_output = torch.sum(linear_output[:, :1]**2 - linear_output[:, 1:]**2, dim=1, keepdim=True)\n",
        "        return saddle_output\n",
        "\n",
        "# sin(ax)sin(bx)\n",
        "# (x^2 - y^2)\n",
        "import torch\n",
        "\n",
        "def rbf_saddle(x, y, gamma=1.0, a=1.0, b=1.0):\n",
        "    # RBF-like term\n",
        "    rbf_term = torch.exp(-gamma * torch.norm(x - y, p=2)**2)\n",
        "    # Saddle point term\n",
        "    saddle_term = (a * x)**2 - (b * y)**2\n",
        "    return rbf_term + saddle_term\n",
        "\n",
        "# Example usage\n",
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "output = rbf_saddle(x, y)\n",
        "print(output)\n",
        "\n",
        "# Compute gradients\n",
        "output.backward()\n",
        "print(x.grad, y.grad)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rTmCo7pm0NxL"
      },
      "outputs": [],
      "source": [
        "# @title plot 3d\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "y = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "X, Y = torch.meshgrid(x, y)\n",
        "Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7fWZaQTDFg1",
        "outputId": "4c5ced88-54f1-436e-89f9-66f1c8396373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000, -0.7231,  0.3792,  0.0000]]) tensor([0.3362])\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# @title shape NN\n",
        "num_pts=1\n",
        "\n",
        "# X=torch.rand(num_pts,4)*2-1\n",
        "# X=torch.cat([torch.tensor([0,0]).unsqueeze(0),torch.rand(num_pts,2)*2-1], dim=-1)\n",
        "X=torch.cat([torch.zeros(1,1),torch.rand(num_pts,2)*2-1,torch.zeros(1,1)], dim=-1)\n",
        "Y=torch.rand(num_pts)\n",
        "print(X,Y)\n",
        "optim = torch.optim.SGD(model.parameters(), 1e-1)\n",
        "\n",
        "# model.train()\n",
        "pred = model(X)\n",
        "# print(Y.shape,pred.shape)\n",
        "# loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "loss = F.mse_loss(Y, pred.squeeze(-1))\n",
        "loss.backward()\n",
        "optim.step()\n",
        "optim.zero_grad()\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "boDd__PE2sGy"
      },
      "outputs": [],
      "source": [
        "# @title plot NN\n",
        "\n",
        "xx = torch.linspace(-1, 1, 100)\n",
        "yy = torch.linspace(-1, 1, 100)\n",
        "X, Y = torch.meshgrid(xx, yy) # [100,100]\n",
        "xy = torch.cat([X.unsqueeze(-1), torch.zeros(X.shape+(2,)), Y.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "with torch.no_grad(): Z = model(xy).squeeze(-1)\n",
        "# print(Z)\n",
        "# print(Z.shape)\n",
        "\n",
        "# Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qW6BYoXsX57o"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle same time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def f(x, y):\n",
        "    return x ** 2 - y ** 2 + x * y\n",
        "# (x-y)(x+y)+xy\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "dim_x, dim_z = 3, 8\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "xx = torch.empty((1, T, dim_x))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "# x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "\n",
        "# tensor([[0.6478, 0.0531, 0.0861]]) tensor([[-1.,  1.]]) 0.2974517047405243\n",
        "# tensor([-0.9419, -1.0000,  0.4416, -1.0000,  1.0000,  0.2963])\n",
        "\n",
        "# x = nn.Parameter(torch.tensor([[0.6478, 0.0531, 0.0861]]))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "z = nn.Parameter(torch.empty((batch, T, dim_z)))\n",
        "# z = torch.empty((1, T, 1))\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# z = nn.Parameter(z.repeat(batch,1,1))\n",
        "# z = nn.Parameter(torch.tensor([[-1.,  1.]]))\n",
        "# optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "# optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.95), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "# .95,1e-1,3e-1\n",
        "# .99,\n",
        "\n",
        "d_model = 4\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(10): # num epochs\n",
        "    # loss = f(x,z)\n",
        "    # loss = f(x.sum(-1),z)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step(); optim_z.step()\n",
        "    optim_x.zero_grad(); optim_z.zero_grad()\n",
        "    # print(i,x.squeeze(), z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    print(i,x.squeeze()[0].data, z[0].squeeze().data, loss[0].squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "        z.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "print(loss.squeeze())\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "# idx = torch.argmax(loss)\n",
        "# print(x[idx],z[idx],loss[idx])\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GJdFpDr2wIMT"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle argm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def argm(sx, lr=3e3): # 3e3\n",
        "    # batch=sx.size(dim=0)\n",
        "    batch_size, T, _ = sx.shape\n",
        "    batch = 16\n",
        "    # z = nn.Parameter(torch.zeros((batch,1),device=device))\n",
        "    # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "    z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "    torch.nn.init.xavier_uniform_(z)\n",
        "    # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "    # sx = sx.detach()\n",
        "    for i in range(20): # 10\n",
        "        # print(sx.shape,z.shape)\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            cost = model(sxz)\n",
        "        cost.sum().backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "        # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    # return z.detach()\n",
        "    print(cost.squeeze().data)\n",
        "    idx = torch.argmax(cost.squeeze(), dim=1)\n",
        "    return z[torch.arange(z.shape[0]),idx].detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# x = nn.Parameter(xx.clone())\n",
        "x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "# ratio = 6e0\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(50):\n",
        "    z = argm(x)\n",
        "    # print(x.shape,z.shape)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "# print(\"z\",z)\n",
        "# print(loss.squeeze())\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvjIJP6RlEv2",
        "outputId": "447fdefd-452b-437d-c228-1847492b36f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.randn(16, 16)\n",
        "# print((b==torch.max(b)).nonzero())\n",
        "x = torch.randn(10, 3)\n",
        "idx = torch.randint(3,(10,))\n",
        "# print(x[:,idx].shape)\n",
        "print(x[torch.arange(x.shape[0]),idx].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HcOidvtW9KAH"
      },
      "outputs": [],
      "source": [
        "# @title from RNN2\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, h0=None, c0=None): # [batch_size, seq_len, input_size]\n",
        "        if h0 is None: h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        if c0 is None: c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        out, h0 = self.rnn(x, h0)\n",
        "        # out, (h0,c0) = self.lstm(x, (h0,c0))\n",
        "        # out:(batch_size, seq_length, hidden_size) (n, 28, 128)\n",
        "        out = out[:, -1, :] # out: (n, 128)\n",
        "        out = self.fc(out) # out: (n, 10)\n",
        "        return out\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "\n",
        "d_model,dim_a,dim_z = 256,3,1\n",
        "pred = nn.Sequential(\n",
        "    nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model),\n",
        "    )\n",
        "gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "\n",
        "print(sum(p.numel() for p in pred.parameters() if p.requires_grad)) # 264192\n",
        "print(sum(p.numel() for p in gru.parameters() if p.requires_grad)) # 397824\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gJ3X_hQelW2x"
      },
      "outputs": [],
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wi4ODp-XlZoU"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QYbOgNoZn6JL"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_kcajtpjr7Io"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "outputs": [],
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "    def get_down(self, state, world_state=None): # update world_state and mem from state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        return world_state\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    world_state = self.get_down(state, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "                    sy = self.effnet(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "\n",
        "                    world_state_ = self.deconvenc(sy).squeeze(1) # ae\n",
        "                    # loss = F.mse_loss(world_state_, world_state)\n",
        "                    loss = F.mse_loss(world_state_, world_state.detach())\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cX71EprCMSNG"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim bad?\n",
        "\n",
        "import torch\n",
        "\n",
        "def transfer_optim(src_optim, tgt_optim, param_mapping):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    tgt_sd = tgt_optim.state_dict()\n",
        "\n",
        "    # Iterate over each parameter in the target optimizer\n",
        "    for (tgt_idx, target_param) in enumerate(tgt_optim.param_groups[0]['params']):\n",
        "        target_id = id(target_param)\n",
        "\n",
        "        # Find the corresponding source parameter using param_mapping\n",
        "        if target_id in param_mapping:\n",
        "            source_param = param_mapping[target_id]\n",
        "            source_id = id(source_param)\n",
        "\n",
        "            # If there's an existing state for the source parameter, transfer it\n",
        "            if source_id in src_sd['state']:\n",
        "                source_state = src_sd['state'][source_id]\n",
        "                target_state = {}\n",
        "\n",
        "                # Handle momentum/first and second moments (e.g., `exp_avg`, `exp_avg_sq` in Adam)\n",
        "                for key in source_state.keys():\n",
        "                    if source_state[key].shape == target_param.shape: target_state[key] = source_state[key].clone()\n",
        "                    # If size doesn't match, either copy what you can or initialise new values\n",
        "                    elif key in ['exp_avg', 'exp_avg_sq']:  # Momentums (specific to Adam-like optimizers)\n",
        "                        target_state[key] = torch.zeros_like(target_param)\n",
        "                        target_state[key][:source_param.numel()] = source_state[key].flatten()[:target_param.numel()]\n",
        "                    else: target_state[key] = torch.zeros_like(target_param) # init\n",
        "                tgt_sd['state'][target_id] = target_state\n",
        "\n",
        "    # Load the updated state dict back into the target optimizer\n",
        "    tgt_optim.load_state_dict(tgt_sd)\n",
        "    return tgt_optim\n",
        "# {'state': {0: {'step': tensor(1.), 'exp_avg': tensor, 'exp_avg_sq': tensor}, 1: }}\n",
        "\n",
        "\n",
        "\n",
        "model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "source_optimizer = optim.AdamW(model_src.parameters())\n",
        "target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "dummy_input = torch.randn(3, 10)\n",
        "dummy_target = torch.randn(3, 5)\n",
        "criterion = torch.nn.MSELoss()\n",
        "output = model_src(dummy_input)\n",
        "loss = criterion(output, dummy_target)\n",
        "loss.backward()\n",
        "source_optimizer.step()\n",
        "\n",
        "param_mapping = {id(tgt_param): src_param for src_param, tgt_param in zip(model_src.parameters(), model_tgt.parameters())}\n",
        "target_optimizer = transfer_optim(source_optimizer, target_optimizer, param_mapping)\n",
        "\n",
        "print(source_optimizer.state_dict())\n",
        "print(target_optimizer.state_dict())\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "\n",
        "# optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title transfer_optim bad? 2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    opt_state_dict = optimizer.state_dict()\n",
        "    for group in opt_state_dict['param_groups']:\n",
        "        # For each parameter index (p in param group refers to the layer parameters)\n",
        "        for param_idx, p in enumerate(group['params']):\n",
        "            print(p,source_layer.weight)\n",
        "            if p == source_layer.weight:\n",
        "                # Find the corresponding target layer parameter (in this case, target_layer.weight)\n",
        "                target_param = target_layer.weight\n",
        "                source_state = optimizer.state[p]  # Get the state for the source parameter\n",
        "\n",
        "                # If the parameter is found in the optimizer's state dict\n",
        "                if 'exp_avg' in source_state and 'exp_avg_sq' in source_state:\n",
        "                    exp_avg = source_state['exp_avg']  # First moment (momentum)\n",
        "                    exp_avg_sq = source_state['exp_avg_sq']  # Second moment (variance)\n",
        "\n",
        "                    # Handle input dimension mismatch (copy/truncate or pad)\n",
        "                    source_in_dim = source_layer.weight.shape[1]\n",
        "                    target_in_dim = target_layer.weight.shape[1]\n",
        "\n",
        "                    # Copy optimizer state (exp_avg and exp_avg_sq) accordingly\n",
        "                    with torch.no_grad():\n",
        "                        # Copy the available part and initialize new dimensions to zero\n",
        "                        new_exp_avg = torch.zeros_like(target_param)\n",
        "                        new_exp_avg_sq = torch.zeros_like(target_param)\n",
        "                        # new_exp_avg[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        # new_exp_avg_sq[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        new_exp_avg[:, :source_in_dim] = exp_avg[:, :target_in_dim]\n",
        "                        new_exp_avg_sq[:, :source_in_dim] = exp_avg_sq[:, :target_in_dim]\n",
        "\n",
        "                    # Update the target layer's optimizer state\n",
        "                    optimizer.state[target_param] = {\n",
        "                        'exp_avg': new_exp_avg,\n",
        "                        'exp_avg_sq': new_exp_avg_sq,\n",
        "                        'step': source_state['step']  # Keep the same step count\n",
        "                    }\n",
        "\n",
        "                # Handle the bias (if it exists)\n",
        "                if hasattr(source_layer, 'bias') and hasattr(target_layer, 'bias'):\n",
        "                    source_bias = optimizer.state[source_layer.bias]\n",
        "                    target_bias = target_layer.bias\n",
        "\n",
        "                    optimizer.state[target_bias] = source_bias\n",
        "    return optimizer\n",
        "\n",
        "# Example usage:\n",
        "d = 10  # Input dimension of the source layer\n",
        "a = 5   # Extra nodes to be omitted or added in the target layer\n",
        "m = 8   # Output dimension (same for both)\n",
        "\n",
        "# Source layer (input dimension d+a)\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "\n",
        "# Target layer (input dimension d, or d+a, or arbitrary)\n",
        "target_layer = nn.Linear(d, m)\n",
        "\n",
        "# Optimizer (using AdamW in this case)\n",
        "optimizer = torch.optim.AdamW(source_layer.parameters())\n",
        "\n",
        "# Perform weight transfer (from d+a to d or vice versa) here (assumed done already)\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "# Transfer optimizer states\n",
        "optimizer = transfer_optimizer_state(source_layer, target_layer, optimizer)\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    state_dict = optimizer.state_dict()\n",
        "    for old_param, new_param in zip(source_layer.parameters(), target_layer.parameters()):\n",
        "        # If old_param exists in optimizer state\n",
        "        if old_param in state_dict['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = state_dict['state'][old_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                if key in ['exp_avg', 'exp_avg_sq']:  # for Adam or AdamW momentum estimates\n",
        "                    # Handle the shape adjustment (copy, shrink, or randomly initialise the extra nodes)\n",
        "                    new_state[key] = torch.zeros_like(new_param)  # Initialise with zeros\n",
        "                    new_state[key][:old_param.shape[0]] = value[:new_param.shape[0]]  # Copy old values\n",
        "                    # else:\n",
        "                    #     new_state[key] = value.clone()  # Copy directly if shapes match\n",
        "                else:\n",
        "                    new_state[key] = value  # Copy other states directly if they exist\n",
        "\n",
        "            # Set the new parameter in optimizer state\n",
        "            state_dict['state'][new_param] = new_state\n",
        "            # Remove the old parameter from the optimizer state\n",
        "            del state_dict['state'][old_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(state_dict)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optim(src_model, tgt_model, src_optim, tgt_optim):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    for src_param, tgt_param in zip(src_model.parameters(), tgt_model.parameters()):\n",
        "        # If src_param exists in optimizer state\n",
        "        if src_param in src_sd['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = src_sd['state'][src_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                new_state[key] = torch.zeros_like(tgt_param)  # Initialise with zeros\n",
        "                new_state[key][:src_param.shape[0]] = value[:tgt_param.shape[0]]  # Copy old values\n",
        "\n",
        "            src_sd['state'][tgt_param] = new_state\n",
        "            del src_sd['state'][src_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(src_sd)\n",
        "    return optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "LKUSzmYLLuRh",
        "outputId": "07ca4b89-257b-4205-c5c8-6a96474ae82a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-186620617543>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# j=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mwht_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwht_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title rename wht_name\n",
        "# wht_name='jepa.enc.cnn.0.weight'\n",
        "wht_name='jepa.pred.weight_ih_l0'\n",
        "# wht_name='emb.weight'\n",
        "# print(o.isnumeric())\n",
        "# mask = [x.isnumeric() for x in o]\n",
        "# print(o[mask])\n",
        "na_=''\n",
        "# j=0\n",
        "\n",
        "for wht_name in agent.state_dict().keys():\n",
        "    o=wht_name.split('.')\n",
        "    # print(o)\n",
        "    name=wht_name\n",
        "    print(\"####\", wht_name)\n",
        "    for i in range(len(o)):\n",
        "        c = o[i]\n",
        "        if c.isnumeric():\n",
        "            na = '.'.join(o[:i])\n",
        "            me = '.'.join(o[i+1:])\n",
        "            # print(c_,c, c_<c, )\n",
        "            c=int(c)\n",
        "            if na!=na_: # param name diff\n",
        "                j=0 # reset num\n",
        "                c_=c # track wht_name num\n",
        "                na_=na # track param name\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('1', name)\n",
        "            elif c_<c: # same param name, diff num\n",
        "                j+=1\n",
        "                c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('2', name)\n",
        "            else: # same param name, same num\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('3', name)\n",
        "    print('4', name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CACQCCaxA_Y",
        "outputId": "b5d127cd-18ce-49e5-b1e2-d883cb34125a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1746836772511624\n"
          ]
        }
      ],
      "source": [
        "# @title geomloss, Python Optimal Transport\n",
        "# !pip install geomloss[full]\n",
        "\n",
        "import torch\n",
        "from geomloss import SamplesLoss  # See also ImagesLoss, VolumesLoss\n",
        "\n",
        "# # Create some large point clouds in 3D\n",
        "# x = torch.randn(100000, 3, requires_grad=True).cuda()\n",
        "# y = torch.randn(200000, 3).cuda()\n",
        "\n",
        "# x = torch.rand(1000, 1)\n",
        "# y = torch.rand(1000, 1)\n",
        "x = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "y = torch.tensor([0, 1, 0]).float().unsqueeze(-1)\n",
        "# k=1.\n",
        "# y = torch.tensor([k, k, k]).float().unsqueeze(-1)\n",
        "\n",
        "\n",
        "\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01) # 0.05, quadratic, Wasserstein-2. low blur => closer to true Wasserstein dist but slower compute\n",
        "\n",
        "loss = loss_fn(x, y)  # By default, use constant weights = 1/number of samples\n",
        "print(loss)\n",
        "# g_x, = torch.autograd.grad(L, [x])\n",
        "\n",
        "# [0, 1, 0]: 2.4253e-12, 2.4253e-12\n",
        "# [0, 0, 0.1]: 0.1350; [0, 0, 0.5]: 0.0417; [0, 0, 1]: 0\n",
        "# k=0.: 0.1666; k=0.1: 0.1383; k=0.333: 0.1111; k=0.5: 0.1250; k=1.: 0.3333\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from geomloss import SamplesLoss\n",
        "\n",
        "# Define x and y as n-dimensional tensors representing mass distributions\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# y = torch.tensor([0, 0, 1], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# x = torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1))\n",
        "x = nn.Parameter(torch.tensor([0,1.5,0]).float().unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "\n",
        "# Create a position tensor representing the index of each element\n",
        "positions_x = torch.arange(x.shape[0], dtype=float).unsqueeze(1)\n",
        "positions_y = torch.arange(y.shape[0], dtype=float).unsqueeze(1)\n",
        "\n",
        "# Sinkhorn loss using GeomLoss\n",
        "loss_fn = SamplesLoss(\"sinkhorn\", p=1, blur=0.05)  # p=1 for Wasserstein-1\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=1, blur=0.05, scaling=0.9, debias=True)\n",
        "\n",
        "transport_cost = loss_fn(positions_x, x, positions_y, y)\n",
        "\n",
        "print(transport_cost.item())\n",
        "# 1.298424361328248\n",
        "\n",
        "transport_cost.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pip install POT\n",
        "\n",
        "import ot\n",
        "import numpy as np\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / np.sum(x)\n",
        "    # y = y / np.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = np.abs(np.arange(n)[:, None] - np.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = np.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "x = np.array([0.2, 0.3, 0.5])\n",
        "y = np.array([0, 0, 1])\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "# distance.backward()\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / torch.sum(x)\n",
        "    # y = y / torch.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = torch.abs(torch.arange(n)[:, None] - torch.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = torch.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "# x = np.array([0.2, 0.3, 0.5])\n",
        "# y = np.array([0, 0, 1])\n",
        "x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float())#.unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float()#.unsqueeze(-1)\n",
        "\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "distance.backward()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MqBL9hljvW-5"
      },
      "outputs": [],
      "source": [
        "# @title batchify argm train\n",
        "\n",
        "def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "    self.jepa.pred.train()\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "    lsx=sx.unsqueeze(1)\n",
        "    h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "    lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "    # print(lsx.shape, la.shape, lz.shape)\n",
        "    c=[]\n",
        "    for t in range(seq_len):\n",
        "        a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "        # print(sx.shape, a.shape, z.shape)\n",
        "        sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "            syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            tcost = -self.tcost(syh0)\n",
        "        c.append(tcost)\n",
        "        lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "        lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        cost += (tcost + icost)*gamma**t\n",
        "    return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "\n",
        "def argm(self, sy, sy_, h0, a, reward, lr=3e3): # 3e3\n",
        "    self.tcost.eval()\n",
        "    batch_size = sy.shape[0] # [batch_size, d_model]\n",
        "    z = nn.Parameter(torch.zeros((batch_size, self.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(z)\n",
        "    torch.nn.init.normal_(z, mean=0., std=.3/z.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([z], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    sy, sy_ = sy.detach(), sy_.detach()\n",
        "    out = sy - sy_\n",
        "    h0, a, reward = h0.detach(), a.detach(), reward.detach()\n",
        "    for i in range(10): # 10\n",
        "        with torch.amp.autocast('cuda'):\n",
        "\n",
        "\n",
        "\n",
        "            syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "            out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            repr_loss = F.mse_loss(out, out_[:, -1, :])\n",
        "            # syh0 = torch.cat([sy.flatten(1),F.dropout(h0_, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            syh0 = torch.cat([sy.flatten(1),h0_.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "            z_loss = torch.abs(z).sum() # z_loss = torch.norm(z)\n",
        "            print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def argm(lsy, sy, h0, la, rwd):\n",
        "    # lz = agent.argm(out, h0, la, reward)\n",
        "    agent.tcost.eval()\n",
        "    batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "    lz = nn.Parameter(torch.zeros((batch_size, bptt, agent.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(lz)\n",
        "    torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "    for i in range(3): # 10\n",
        "        sy_, h0_ = sy.detach(), h0.detach()\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "        with torch.cuda.amp.autocast():\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0_ = agent.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl + agent.zloss_coeff * z_loss\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    agent.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return lz.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# closs_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01)\n",
        "bptt = 25\n",
        "for batch, Sar in enumerate(train_loader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "    state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "    sy_ = agent.jepa.enc(state).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    # sx=sy_\n",
        "    state, action, reward = Sar # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "    state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "    for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "\n",
        "        with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "            lsy = agent.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "            la = agent.emb(act) # [batch_size, bptt, dim_a]\n",
        "            out = lsy - torch.cat([sy_, lsy[:,:-1]], dim=1)\n",
        "            # lz = agent.argm(out, h0, la, reward)\n",
        "            lz = argm(lsy, sy_, h0, la, rwd)\n",
        "            # lz = torch.zeros((batch_size, bptt, agent.dim_z), device=device)\n",
        "\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0 = agent.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0.unsqueeze(0)), dim=0)\n",
        "\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            std_loss, cov_loss = agent.jepa.v_creg(agent.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "            jloss = agent.jepa.sim_coeff * repr_loss + agent.jepa.std_coeff * std_loss + agent.jepa.cov_coeff * cov_loss\n",
        "\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # print(\"syh0, rwd\",syh0.shape,rwd.shape)\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            # reward_ = agent.tcost(syh0)\n",
        "            # clossl = wasserstein(rwd, reward_)#.squeeze(-1)\n",
        "            closs = agent.closs_coeff * clossl\n",
        "\n",
        "            # print(h0.requires_grad)\n",
        "            # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "            # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "            # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "            # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "            # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "            loss = jloss + closs\n",
        "\n",
        "            # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "            norm = torch.norm(lsy, dim=-1)[0][0].item()\n",
        "            z_norm = torch.norm(z)\n",
        "            # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "            # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "            print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "            scaler.scale(loss).backward()\n",
        "            # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "            optim.zero_grad()\n",
        "            sy_, h0 = sy_.detach(), h0.detach()\n",
        "    break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o0UHSueqx9W8"
      },
      "outputs": [],
      "source": [
        "# @title test tcost3\n",
        "# def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "#     self.train()\n",
        "#     for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "#         state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "#         with torch.cuda.amp.autocast():\n",
        "#             lsy = self.jepa.enc(state.flatten(end_dim=1)) # [batch_size, bptt, d_model]\n",
        "#             # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "#             # lsy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "#             std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy))\n",
        "#             jloss = self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "#             clossl = self.tcost.loss(lsy, reward.flatten(end_dim=1))\n",
        "#             closs = self.closs_coeff * clossl\n",
        "\n",
        "#             pred = self.tcost(lsy).squeeze(-1).unflatten(0, reward.shape) # [batch_size, bptt]\n",
        "#             print(\"pred\",pred[0])\n",
        "#             print(\"rwd\",reward[0])\n",
        "#             mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "#             # # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "#             # try: imshow(torchvision.utils.make_grid(st[0].cpu(), nrow=10))\n",
        "#             # # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "#             # except ZeroDivisionError: pass\n",
        "\n",
        "#         loss = jloss + closs\n",
        "\n",
        "#         print(\"std, cov, clossl, wrong\", std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "#         # print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "#         scaler.scale(loss).backward()\n",
        "#         # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "#         scaler.step(optim)\n",
        "#         scaler.update()\n",
        "#         optim.zero_grad()\n",
        "#         try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "#         except: pass\n",
        "\n",
        "# # for i in range(5):\n",
        "# #     print(i)\n",
        "# #     train_jepa(agent, train_loader, optim)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Jt_UlGz6Xoq3",
        "m8WHjFn2gmzI"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}