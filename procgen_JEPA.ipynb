{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "5a1ae551-a258-4b0d-ab5c-079ca6dcf564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install -qq procgen faiss-cpu\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -qq procgen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "cellView": "form",
        "id": "nEY9MmwZhA8a"
      },
      "outputs": [],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# conv = Conv().to(device)\n",
        "# # print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# # input = torch.rand((4,1,256,256), device=device)\n",
        "# out = conv(input)\n",
        "# print(out.shape)\n",
        "\n",
        "# conv = Deconv(256).to(device)\n",
        "# # print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# input = torch.rand((4,256), device=device)\n",
        "# out = conv(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "cellView": "form",
        "id": "FuA25qQknUAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20dbaf9-f645-4c63-d294-7e48be03f530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-a5e320619cc7>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model)\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model),\n",
        "            )\n",
        "        # self.pred = gru(emb_dim, rnn_units, num_layers)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=1e5): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        num_steps = 5 # 10\n",
        "        for i in range(num_steps):\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sy_ = self.pred(sxaz)\n",
        "                # print(\"y_, y\",y_.shape, y.shape)\n",
        "                loss = lossfn(sy_, sy)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z = torch.clamp(z, min=-1, max=1)\n",
        "            # print(\"argm in\",loss.item())\n",
        "        # print(z.squeeze())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCD647ZpPrGf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cIF--UQMEEFx"
      },
      "outputs": [],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(3): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "                sx_ = sx_.detach()\n",
        "                # print(loss.item(), lact)\n",
        "        # print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "29O1eyvhnRSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abff2d2a-baff-466b-b431-167ea1a05cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-131-141d7fd857ab>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title agent pixel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        # self.fsq = FSQ(levels = [3,3,2])#.to(device)\n",
        "        self.emb = torch.nn.Embedding(1000, 3)\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        # lact = self.fsq.codes_to_indexes(la)\n",
        "        return lact[0]\n",
        "\n",
        "\n",
        "    # # def search(self, sx, T=256, bptt=32):\n",
        "    # def search(self, sx, T=None, bptt=None):\n",
        "    #     if T==None: T = 256\n",
        "    #     if bptt==None: bptt = min(T,3)\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "    #     torch.nn.init.xavier_uniform_(x)\n",
        "    #     # optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "    #     # xx = torch.split(x, bptt, dim=1)\n",
        "    #     xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "    #     optim = torch.optim.SGD(xx, lr=1e7) #, maximize=True)\n",
        "\n",
        "    #     for _ in range(10): # num epochs\n",
        "    #         sx_ = sx.detach()\n",
        "    #         for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    #             # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "    #             la = fsq(xxx.clone())\n",
        "    #             # print(x,x.requires_grad)\n",
        "    #             # print(la,la.requires_grad)\n",
        "    #             loss, sx_ = self.rnn_pred(sx_, la)\n",
        "    #             loss.backward(retain_graph=True)\n",
        "    #             optim.step()\n",
        "    #             optim.zero_grad()\n",
        "    #             sx_ = sx_.detach()\n",
        "    #             # print(loss.item(), lact)\n",
        "    #             # xx = torch.tanh(xx) # clamp\n",
        "    #         xx = [torch.tanh(xxx) for xxx in xx]\n",
        "    #         x = torch.cat(xx,dim=1)\n",
        "    #         # x = torch.tanh(x) # clamp\n",
        "    #         print(x)\n",
        "    #     print(\"search\",loss.item())\n",
        "    #     # print(lact)\n",
        "    #     return la, lact # [batch_size, T]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "        # x = torch.empty((batch, T, 3),device=device) # FSQ 3 levels\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # mean = self.fsq.mean.repeat(batch, T, 1)\n",
        "        # x = nn.Parameter(x + mean)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "\n",
        "        print(x)\n",
        "        for i in range(20): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            # la = self.fsq(x.clone())\n",
        "            # la = self.fsq(x)\n",
        "            la = x\n",
        "            # print(x,x.requires_grad)\n",
        "            # print(la,la.requires_grad)\n",
        "            loss, sx_ = self.rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            # loss.backward(retain_graph=True)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x.clamp_(min=-1, max=1)\n",
        "                # x.clamp_(min=self.fsq.min, max=self.fsq.max)\n",
        "            print(i,x)\n",
        "            print(la)\n",
        "        # la = self.fsq(x)\n",
        "        dist = torch.norm(self.emb.weight.data - x, dim=1)\n",
        "        lact = torch.argmin(dist)\n",
        "        print(\"search\",loss.item())\n",
        "        return la # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=17): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # a = self.fsq.indexes_to_codes(action)\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(syaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    try:\n",
        "                        st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb #+ clossl\n",
        "                    # print(loss, jloss, clossl, clossb)\n",
        "                    # print(loss.dtype, jloss.dtype, clossl.dtype, clossb.dtype)\n",
        "\n",
        "                    loss = loss + jloss + closs #+ conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # print(loss, loss.dtype)\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "!gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_b7ZSW6IF1-",
        "outputId": "69ab0a3d-4041-4b7e-a390-f3babceb08ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_\n",
            "From (redirected): https://drive.google.com/uc?id=12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_&confirm=t&uuid=7a45c8ca-269c-4a6a-845c-a79ddbc78173\n",
            "To: /content/agentoptim.pkl\n",
            "100% 44.2M/44.2M [00:01<00:00, 38.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "cellView": "form",
        "id": "ShHQ_ynlwoyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da11f3ec-c448-40b3-b0a9-2d033e5e54a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-7fc540255cf2>:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "def save(folder, name='agent.pth'):\n",
        "    torch.save(agent.state_dict(), folder+name)\n",
        "    # agent.mem.save(file=folder+name)\n",
        "    with open(folder+'buffer.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "def load(folder, name='agent.pth'):\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=torch.device(device)), strict=False)\n",
        "    # agent.load_state_dict(torch.load(folder+name, map_location=device), strict=False)\n",
        "    # torch.load(folder+name, map_location=torch.device('cpu'))\n",
        "    # agent.mem.load(file=folder+name)\n",
        "    with open(folder+'buffer512.pkl', 'rb') as f: return pickle.load(f)\n",
        "\n",
        "# save(folder)\n",
        "# save(folder, name='agent_jepa753333256.pth')\n",
        "# buffer = load(folder)\n",
        "# save('/content/')\n",
        "# buffer = load('/content/')\n",
        "\n",
        "# name='agent.pth'\n",
        "# print(folder+name)\n",
        "# torch.load(folder+name, map_location='o')\n",
        "# with open(folder+'buffer512down.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "with open(folder+'buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "agent.load_state_dict(modelsd)\n",
        "optim.load_state_dict(optimsd)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = buffer[7][80][0]\n",
        "state = transform(state).unsqueeze(0).to(device)#[0]\n",
        "act = agent(state).cpu()[:1].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG4Wn3c8IN4V",
        "outputId": "b6886c4e-779a-4d93-b09b-0b22263e3b99"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[-0.3991, -0.1542, -0.4281],\n",
            "         [-0.1695, -0.0062,  0.2831],\n",
            "         [-0.2244,  0.0481,  0.3850],\n",
            "         [-0.3830, -0.2448,  0.3852],\n",
            "         [-0.5320,  0.0128, -0.0057],\n",
            "         [ 0.1171, -0.0800,  0.4099]]], requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.4987, -0.0540, -0.3277],\n",
            "         [-0.0693, -0.1062,  0.1828],\n",
            "         [-0.1241, -0.0519,  0.2846],\n",
            "         [-0.4826, -0.3446,  0.2848],\n",
            "         [-0.6315, -0.0873, -0.1057],\n",
            "         [ 0.0170, -0.1799,  0.3095]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000]]], grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.5979,  0.0459, -0.2273],\n",
            "         [ 0.0267, -0.2058,  0.0831],\n",
            "         [-0.0245, -0.1519,  0.1843],\n",
            "         [-0.5816, -0.4436,  0.1845],\n",
            "         [-0.7228, -0.1871, -0.2023],\n",
            "         [-0.0771, -0.2796,  0.2092]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.]]], grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.6940, -0.0133, -0.1997],\n",
            "         [ 0.1196, -0.3038, -0.0138],\n",
            "         [ 0.0753, -0.2518,  0.0840],\n",
            "         [-0.6550, -0.5427,  0.0843],\n",
            "         [-0.8173, -0.2863, -0.3001],\n",
            "         [-0.1703, -0.3790,  0.1089]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.7911, -0.0876, -0.2083],\n",
            "         [ 0.0770, -0.4022, -0.1093],\n",
            "         [ 0.1654, -0.3507, -0.0144],\n",
            "         [-0.6979, -0.6327,  0.0064],\n",
            "         [-0.9130, -0.3857, -0.3985],\n",
            "         [-0.2634, -0.4781,  0.0086]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.8889, -0.1696, -0.2372],\n",
            "         [ 0.0138, -0.5011, -0.2060],\n",
            "         [ 0.1983, -0.4439, -0.1085],\n",
            "         [-0.6796, -0.6765, -0.0040],\n",
            "         [-1.0000, -0.4842, -0.4958],\n",
            "         [-0.3572, -0.5769, -0.0917]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-121-6082c429fe4e>:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "<ipython-input-119-5999dd6ec2cf>:24: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
            "  bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 Parameter containing:\n",
            "tensor([[[-0.9867, -0.2562, -0.2795],\n",
            "         [-0.0599, -0.6002, -0.3035],\n",
            "         [ 0.2054, -0.5292, -0.1958],\n",
            "         [-0.7189, -0.7186, -0.0495],\n",
            "         [-1.0000, -0.5791, -0.5893],\n",
            "         [-0.4405, -0.6632, -0.1808]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-1.0000, -0.3456, -0.3294],\n",
            "         [-0.1303, -0.6904, -0.4006],\n",
            "         [ 0.2012, -0.6059, -0.2749],\n",
            "         [-0.7758, -0.7597, -0.1104],\n",
            "         [-1.0000, -0.6640, -0.6795],\n",
            "         [-0.5218, -0.7402, -0.2620]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-1.0000, -0.4369, -0.3857],\n",
            "         [-0.2078, -0.7734, -0.4984],\n",
            "         [ 0.1617, -0.6771, -0.3553],\n",
            "         [-0.8425, -0.7995, -0.1803],\n",
            "         [-1.0000, -0.7407, -0.7665],\n",
            "         [-0.6069, -0.8094, -0.3367]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-1.0000, -0.5294, -0.4470],\n",
            "         [-0.2903, -0.8501, -0.5966],\n",
            "         [ 0.1059, -0.7437, -0.4366],\n",
            "         [-0.9156, -0.8386, -0.2566],\n",
            "         [-1.0000, -0.8103, -0.8500],\n",
            "         [-0.6831, -0.8691, -0.4148]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6224, -0.5121],\n",
            "         [-0.3765, -0.9214, -0.6947],\n",
            "         [ 0.0397, -0.8062, -0.5185],\n",
            "         [-0.9930, -0.8771, -0.3374],\n",
            "         [-1.0000, -0.8736, -0.9302],\n",
            "         [-0.7638, -0.9206, -0.4954]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "10 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7043, -0.5065],\n",
            "         [-0.4652, -0.9878, -0.7920],\n",
            "         [-0.0337, -0.8651, -0.6005],\n",
            "         [-1.0000, -0.9149, -0.4215],\n",
            "         [-1.0000, -0.9315, -1.0000],\n",
            "         [-0.8485, -0.9651, -0.5777]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "11 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7766, -0.4746],\n",
            "         [-0.5555, -1.0000, -0.8881],\n",
            "         [-0.1126, -0.9207, -0.6823],\n",
            "         [-1.0000, -0.9523, -0.5078],\n",
            "         [-1.0000, -0.9847, -1.0000],\n",
            "         [-0.9360, -1.0000, -0.6609]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "12 Parameter containing:\n",
            "tensor([[[-1.0000, -0.8405, -0.4269],\n",
            "         [-0.6464, -1.0000, -0.9837],\n",
            "         [-0.1950, -0.9713, -0.7624],\n",
            "         [-1.0000, -0.9863, -0.5956],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.7447]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "13 Parameter containing:\n",
            "tensor([[[-1.0000, -0.8970, -0.3679],\n",
            "         [-0.7374, -1.0000, -1.0000],\n",
            "         [-0.2803, -1.0000, -0.8407],\n",
            "         [-1.0000, -1.0000, -0.6842],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.8284]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "14 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9470, -0.3006],\n",
            "         [-0.8281, -1.0000, -1.0000],\n",
            "         [-0.3677, -1.0000, -0.9170],\n",
            "         [-1.0000, -1.0000, -0.7731],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9116]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9911, -0.2267],\n",
            "         [-0.9179, -1.0000, -1.0000],\n",
            "         [-0.4566, -1.0000, -0.9912],\n",
            "         [-1.0000, -1.0000, -0.8616],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9938]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.1476],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5465, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9495],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0644],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6369, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000,  0.0223],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.7292, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000,  0.0563],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8214, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search -0.5045252442359924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "NVcknabHMxH6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 64 #512\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "1e3fpbtNOiz1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "train_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "train_data = Datasetme(train_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    train_data=list(zip(state,reward))\n",
        "    train_data = Datasetme(train_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# trainiter = iter(c_loader)\n",
        "# images, labels = next(trainiter)\n",
        "# # imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# # print(labels)\n",
        "# for x in range((len(labels)//10)+1):\n",
        "#     print(labels[10*x:10*x+10])\n",
        "\n",
        "# try:\n",
        "#     with torch.no_grad():\n",
        "#         # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "#         pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "#         # print(pred)\n",
        "#         for x in range((len(pred)//10)+1):\n",
        "#             print(pred[10*x:10*x+10])\n",
        "#         # print((labels==pred).sum())\n",
        "# except: pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OksdjCeJYpYh",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cddc8a-3057-4331-ae62-28d461151879"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-776fa543b0ee>:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(): # automatic mixed percision\n",
            "<ipython-input-11-a5e320619cc7>:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repr, std, cov, closslb 0.0303669273853302 0.476806640625 0.00011483114212751389 0.01287792343646288 0.00010617330553941429\n",
            "0.004827989840968163 0.025525840918027492 1.0\n",
            "repr, std, cov, closslb 0.02720176987349987 0.4765625 0.00012138322927057743 0.00768207898363471 1.3421137737168465e-05\n",
            "0.004847330787587867 0.02567937936204927 1.0\n",
            "repr, std, cov, closslb 0.02714240923523903 0.476318359375 0.0001264831516891718 0.011937492527067661 0.012278124690055847\n",
            "0.004886245430940725 0.02606727810656019 1.0\n",
            "repr, std, cov, closslb 0.019234096631407738 0.475830078125 0.00013287970796227455 2.540681634854991e-05 2.7701556973624974e-05\n",
            "0.004886245430940725 0.026145558168781457 1.0\n",
            "repr, std, cov, closslb 0.029294639825820923 0.473876953125 0.00021886872127652168 0.012361161410808563 0.00014939003449399024\n",
            "0.004827989840968163 0.02537322048894137 1.0\n",
            "repr, std, cov, closslb 0.027242286130785942 0.472900390625 0.0002363491803407669 0.008010707795619965 0.015258115716278553\n",
            "0.0047656631321328895 0.024945733379132397 1.0\n",
            "repr, std, cov, closslb 0.01855948008596897 0.47509765625 0.00015054643154144287 5.632027023239061e-05 0.015712454915046692\n",
            "0.004732436529458552 0.024452019118968597 1.0\n",
            "repr, std, cov, closslb 0.020821083337068558 0.4755859375 0.0001300727017223835 0.008779899217188358 0.0001845797523856163\n",
            "0.0047088451680546 0.0242572803125127 1.0\n",
            "repr, std, cov, closslb 0.019058426842093468 0.472412109375 0.0002919945400208235 0.012031196616590023 0.015536285005509853\n",
            "0.004578890323796689 0.02349371129197447 1.0\n",
            "repr, std, cov, closslb 0.020749667659401894 0.472900390625 0.00022845040075480938 0.007692430634051561 0.015304557047784328\n",
            "0.0044972480955632966 0.02307481527051258 1.0\n",
            "repr, std, cov, closslb 0.015759803354740143 0.473876953125 0.0001888517290353775 4.423427162691951e-05 0.00024074820976238698\n",
            "0.00450174534365886 0.023028734772233345 1.0\n",
            "repr, std, cov, closslb 0.015303436666727066 0.475830078125 0.00013514491729438305 1.171287840406876e-05 6.676946941297501e-05\n",
            "0.004524299132870554 0.023028734772233345 1.0\n",
            "repr, std, cov, closslb 0.01571030169725418 0.474609375 0.00018340558744966984 1.9144819816574454e-05 0.0004347392823547125\n",
            "0.004537885607690862 0.02289104468031686 1.0\n",
            "repr, std, cov, closslb 0.01743527501821518 0.47509765625 0.0002205250784754753 0.004103473853319883 8.049045572988689e-05\n",
            "0.004524299132870554 0.022663388221262685 1.0\n",
            "repr, std, cov, closslb 0.015541489236056805 0.4765625 0.00014216243289411068 0.0007048399420455098 0.01565946266055107\n",
            "0.004578890323796689 0.02298274629689327 1.0\n",
            "repr, std, cov, closslb 0.01644599437713623 0.476806640625 0.00012707337737083435 0.0035571979824453592 0.0003524725034367293\n",
            "0.004592640736017939 0.023329911168297943 1.0\n",
            "repr, std, cov, closslb 0.023062657564878464 0.476806640625 0.0001353819388896227 0.0035656727850437164 0.014720296487212181\n",
            "0.004657357312956831 0.024088156521645174 1.0\n",
            "repr, std, cov, closslb 0.01876417174935341 0.477294921875 0.00011786841787397861 0.00373019534163177 0.01583295688033104\n",
            "0.004666676684940056 0.024500947609225648 1.0\n",
            "repr, std, cov, closslb 0.014820987358689308 0.47802734375 0.00011725933291018009 2.7672393116517924e-05 0.00017374323215335608\n",
            "0.004690056781821708 0.025221512585928304 1.0\n",
            "repr, std, cov, closslb 0.016114497557282448 0.478271484375 9.596860036253929e-05 0.004750646650791168 0.0002548033371567726\n",
            "0.004694746838603529 0.025653725636412862 1.0\n",
            "repr, std, cov, closslb 0.01507660187780857 0.4775390625 0.00013867043890058994 0.0047636679373681545 0.0008971219649538398\n",
            "0.004699441585442132 0.026329127048694636 1.0\n",
            "repr, std, cov, closslb 0.018351808190345764 0.479248046875 9.95369628071785e-05 0.015325509011745453 0.00024626863887533545\n",
            "0.004685371410411297 0.026673466921227018 1.0\n",
            "repr, std, cov, closslb 0.012761305086314678 0.47802734375 0.00010917824693024158 5.736814273404889e-05 0.0018424004083499312\n",
            "0.004694746838603529 0.02748538291605355 1.0\n",
            "repr, std, cov, closslb 0.015505262650549412 0.477783203125 9.697931818664074e-05 0.007539681624621153 0.0002856538922060281\n",
            "0.004694746838603529 0.027928462730618397 1.0\n",
            "repr, std, cov, closslb 0.020345307886600494 0.4765625 0.00015665078535676003 0.01063079945743084 0.002212341409176588\n",
            "0.004601830610130709 0.02778923836836156 1.0\n",
            "repr, std, cov, closslb 0.011758537031710148 0.4755859375 0.00016824668273329735 3.0301431252155453e-05 8.559094567317516e-05\n",
            "0.0045424234932985525 0.027430494496565927 1.0\n",
            "repr, std, cov, closslb 0.012313507497310638 0.476318359375 0.00017244555056095123 2.315692836418748e-05 0.00018197893223259598\n",
            "0.004465892905014541 0.026807101257370416 1.0\n",
            "repr, std, cov, closslb 0.019428612664341927 0.476806640625 0.00014264206402003765 0.01198788546025753 0.0001482863153796643\n",
            "0.004430325999482076 0.026487497274870157 1.0\n",
            "repr, std, cov, closslb 0.012740327045321465 0.474609375 0.00019463268108665943 0.0038373302668333054 5.576284456765279e-05\n",
            "0.004316678158769971 0.025730763800152726 1.0\n",
            "repr, std, cov, closslb 0.010759660974144936 0.47705078125 0.00011678971350193024 2.016314465436153e-05 0.00018156252917833626\n",
            "0.004325315831765669 0.02601522164804246 1.0\n",
            "repr, std, cov, closslb 0.012417284771800041 0.4775390625 0.00010856869630515575 1.817709744500462e-05 0.00043954281136393547\n",
            "0.004373132913392299 0.026620199901224672 1.0\n",
            "repr, std, cov, closslb 0.014334043487906456 0.4765625 0.000119753647595644 0.009245207533240318 0.0005901054246351123\n",
            "0.004386265435904348 0.026887603009253393 1.0\n",
            "repr, std, cov, closslb 0.01354813203215599 0.47705078125 0.00011564395390450954 0.004681822843849659 0.0002864611451514065\n",
            "0.004412648910292438 0.027595489469984268 1.0\n",
            "repr, std, cov, closslb 0.013208234682679176 0.476318359375 0.00013462849892675877 1.8708808056544513e-05 0.00024775631027296185\n",
            "0.004412648910292438 0.02790056216844995 1.0\n",
            "repr, std, cov, closslb 0.013267581351101398 0.477783203125 0.00011039548553526402 1.7038091755239293e-05 0.000311968382447958\n",
            "0.004465892905014541 0.028322012892928315 1.0\n",
            "repr, std, cov, closslb 0.01499789860099554 0.4755859375 0.00015571038238704205 0.003484999993816018 0.0005130842910148203\n",
            "0.004483783289860065 0.02840706392596778 1.0\n",
            "1\n",
            "repr, std, cov, closslb 0.013721096329391003 0.4755859375 0.0001755093690007925 0.003465444315224886 0.0013602916151285172\n",
            "0.004390651701340251 0.027567921548435834 1.0\n",
            "repr, std, cov, closslb 0.017366331070661545 0.47607421875 0.00015041581355035305 0.011788331903517246 0.014909885823726654\n",
            "0.004373132913392299 0.027348367322149156 1.0\n",
            "repr, std, cov, closslb 0.017117006704211235 0.475830078125 0.00014644884504377842 0.007634894456714392 0.016580235213041306\n",
            "0.004351332693064959 0.026995314854485745 1.0\n",
            "repr, std, cov, closslb 0.013253950513899326 0.473876953125 0.000186519930139184 1.8562628611107357e-05 8.953217911766842e-05\n",
            "0.004329641147597435 0.026753567369064923 1.0\n",
            "repr, std, cov, closslb 0.015187800861895084 0.47607421875 0.00012156623415648937 0.003722831141203642 0.0002502893330529332\n",
            "0.004303753981260493 0.026434601636994536 1.0\n",
            "repr, std, cov, closslb 0.012784079648554325 0.473876953125 0.00018866173923015594 0.009831792674958706 0.0012325868010520935\n",
            "0.004269478369520096 0.02601522164804246 1.0\n",
            "repr, std, cov, closslb 0.012539362534880638 0.47412109375 0.00019270507618784904 1.2290140148252249e-05 0.0012056061532348394\n",
            "0.004197546350903321 0.02529725281344535 1.0\n",
            "repr, std, cov, closslb 0.016190961003303528 0.475830078125 0.00013060984201729298 0.003924849443137646 0.015502972528338432\n",
            "0.004193352997905416 0.025171145124534118 1.0\n",
            "repr, std, cov, closslb 0.013681620359420776 0.475341796875 0.00013793609105050564 0.004133394919335842 0.03288218006491661\n",
            "0.00424395091979483 0.02509578246469686 1.0\n",
            "repr, std, cov, closslb 0.015005085617303848 0.4755859375 0.00012715673074126244 0.003944931086152792 0.0002195510605815798\n",
            "0.00424395091979483 0.024970679112511527 1.0\n",
            "repr, std, cov, closslb 0.013956747949123383 0.47412109375 0.00016973167657852173 0.0033987178467214108 0.0010005092481151223\n",
            "0.004201743897254224 0.02462369760187986 1.0\n",
            "repr, std, cov, closslb 0.013595886528491974 0.474853515625 0.00013951072469353676 0.003961355425417423 0.015124433673918247\n",
            "0.004193352997905416 0.02435445507449799 1.0\n",
            "repr, std, cov, closslb 0.00983344204723835 0.476318359375 0.00011541158892214298 0.004105729516595602 0.029689939692616463\n",
            "0.0041849788552161295 0.024112244678166816 1.0\n",
            "repr, std, cov, closslb 0.0182235985994339 0.474609375 0.0001668892800807953 0.015911128371953964 0.0008424820844084024\n",
            "0.004201743897254224 0.02396807621998245 1.0\n",
            "repr, std, cov, closslb 0.009256771765649319 0.474853515625 0.0001650904305279255 0.00010552231105975807 0.015437654219567776\n",
            "0.004222794676217916 0.02380096878428059 1.0\n",
            "repr, std, cov, closslb 0.0121091827750206 0.474853515625 0.00014891731552779675 0.0038080892991274595 3.9338836359092966e-05\n",
            "0.0042185761001177985 0.02368232012352013 1.0\n",
            "repr, std, cov, closslb 0.015547491610050201 0.475830078125 0.00012707337737083435 0.008004344068467617 0.0002683652564883232\n",
            "0.004231244488365027 0.02349371129197447 1.0\n",
            "repr, std, cov, closslb 0.010404938831925392 0.474609375 0.0001635439693927765 0.00013832966214977205 8.369486749870703e-05\n",
            "0.004210151586792628 0.02328332124249172 1.0\n",
            "repr, std, cov, closslb 0.012907534837722778 0.4765625 0.00010535935871303082 0.0048019555397331715 0.0009674227330833673\n",
            "0.004252443065585339 0.023446794256666886 1.0\n",
            "repr, std, cov, closslb 0.015266790986061096 0.475341796875 0.0001322051975876093 0.012753130868077278 0.00048581601004116237\n",
            "0.004269478369520096 0.023446794256666886 1.0\n",
            "repr, std, cov, closslb 0.010806811973452568 0.475830078125 0.00013394630514085293 0.0031326361931860447 0.0003095477295573801\n",
            "0.004269478369520096 0.02335324107946624 1.0\n",
            "repr, std, cov, closslb 0.012764878571033478 0.475830078125 0.00012354855425655842 0.009532670490443707 0.00033303204691037536\n",
            "0.0042822996173332425 0.023446794256666886 1.0\n",
            "repr, std, cov, closslb 0.016383593901991844 0.475341796875 0.0001674711238592863 0.009751316159963608 0.00011965918383793905\n",
            "0.004231244488365027 0.022776932022998422 1.0\n",
            "repr, std, cov, closslb 0.01578718237578869 0.47705078125 0.00010672654025256634 0.01127520389854908 6.12564108450897e-05\n",
            "0.00424395091979483 0.022776932022998422 1.0\n",
            "repr, std, cov, closslb 0.01362537033855915 0.4765625 0.00010644551366567612 0.0002095001982524991 0.00010538194328546524\n",
            "0.0043339707887450315 0.02330660456373421 1.0\n",
            "repr, std, cov, closslb 0.011594895273447037 0.47705078125 0.00010063033550977707 0.0030475324019789696 0.015289237722754478\n",
            "0.004351332693064959 0.02370600244364365 1.0\n",
            "repr, std, cov, closslb 0.015954390168190002 0.47705078125 0.0001147962175309658 0.006739419419318438 0.030501509085297585\n",
            "0.004364399749493564 0.024088156521645174 1.0\n",
            "repr, std, cov, closslb 0.014563232660293579 0.475830078125 0.00016046687960624695 0.004335386212915182 0.00011508623720146716\n",
            "0.004320994836928741 0.024088156521645174 1.0\n",
            "repr, std, cov, closslb 0.021074559539556503 0.476318359375 0.00014376570470631123 0.008174018934369087 0.00010604812996461987\n",
            "0.004286581916950576 0.023399970914866244 1.0\n",
            "repr, std, cov, closslb 0.017558187246322632 0.47607421875 0.0001484174281358719 1.4557406757376157e-05 6.0095371736679226e-05\n",
            "0.004303753981260493 0.023399970914866244 1.0\n",
            "repr, std, cov, closslb 0.014371020719408989 0.4755859375 0.00013713911175727844 2.208809928561095e-05 0.0010033072903752327\n",
            "0.004342643064293309 0.02330660456373421 1.0\n",
            "repr, std, cov, closslb 0.018277829512953758 0.4755859375 0.00012116366997361183 0.008099360391497612 5.0042457587551326e-05\n",
            "0.004338304759533776 0.02328332124249172 1.0\n",
            "repr, std, cov, closslb 0.024010485038161278 0.4765625 0.00011208420619368553 0.004549024626612663 0.015772420912981033\n",
            "0.004403836832790026 0.0233765943205457 1.0\n",
            "repr, std, cov, closslb 0.020219992846250534 0.475830078125 0.00010739616118371487 0.004598558414727449 0.00026001682272180915\n",
            "0.004439191081807038 0.023423370885781107 1.0\n",
            "repr, std, cov, closslb 0.014262489974498749 0.4755859375 0.00013485224917531013 0.004383597522974014 0.00019694207003340125\n",
            "0.004448073903161733 0.023848594522817932 1.0\n",
            "repr, std, cov, closslb 0.012061884626746178 0.4765625 0.00011913035996258259 2.6500154490349814e-05 0.00010456876771058887\n",
            "0.004456974499041959 0.02401603634049863 1.0\n",
            "2\n",
            "repr, std, cov, closslb 0.02119135484099388 0.476318359375 0.00012984126806259155 0.011168474331498146 1.4820698197581805e-05\n",
            "0.004412648910292438 0.023446794256666886 1.0\n",
            "repr, std, cov, closslb 0.018558474257588387 0.475830078125 0.00011554872617125511 0.0035482042003422976 0.015183476731181145\n",
            "0.004395042353041591 0.02321361074620726 1.0\n",
            "repr, std, cov, closslb 0.019760943949222565 0.47607421875 0.00012911041267216206 0.008117561228573322 0.015256480313837528\n",
            "0.004346985707357602 0.022799708955021418 1.0\n",
            "repr, std, cov, closslb 0.01631297543644905 0.47607421875 0.00010903109796345234 0.004175742622464895 7.742515299469233e-05\n",
            "0.004320994836928741 0.022595533810633825 1.0\n",
            "repr, std, cov, closslb 0.014346856623888016 0.4765625 0.0001023740042001009 1.3823691915604286e-05 0.015950554981827736\n",
            "0.004399437395394632 0.023051763507005576 1.0\n",
            "repr, std, cov, closslb 0.02215879037976265 0.474609375 0.00015183212235569954 0.007766818627715111 5.712035999749787e-05\n",
            "0.004421478620761933 0.022959786510382888 1.0\n",
            "repr, std, cov, closslb 0.015488688834011555 0.47509765625 0.0001360203605145216 3.34997421305161e-05 0.00012327654985710979\n",
            "0.004377506046305691 0.022415580275340567 1.0\n",
            "repr, std, cov, closslb 0.022144164890050888 0.47412109375 0.00017488421872258186 0.008241429924964905 8.18705593701452e-05\n",
            "0.004346985707357602 0.022082021266580844 1.0\n",
            "repr, std, cov, closslb 0.025030240416526794 0.475341796875 0.00012503261677920818 0.016023071482777596 1.775567579898052e-05\n",
            "0.004295159367366393 0.021580178955022022 1.0\n",
            "repr, std, cov, closslb 0.013557571917772293 0.475341796875 0.00011644395999610424 4.581262601277558e-06 3.711361569003202e-05\n",
            "0.004273747847889616 0.021429720139134485 1.0\n",
            "repr, std, cov, closslb 0.014135001227259636 0.474609375 0.00014618388377130032 0.0045795561745762825 0.015359113924205303\n",
            "0.004260952204159574 0.02125905128343489 1.0\n",
            "repr, std, cov, closslb 0.012589283287525177 0.474609375 0.00012782588601112366 0.0040685683488845825 0.00022166018607094884\n",
            "0.00424395091979483 0.021131942227977665 1.0\n",
            "repr, std, cov, closslb 0.014845260418951511 0.4755859375 0.00011704955250024796 0.004207668825984001 0.01521304901689291\n",
            "0.0042354757328533915 0.020921780428560296 1.0\n",
            "repr, std, cov, closslb 0.011707495898008347 0.474853515625 0.0001329304650425911 0.004130252171307802 1.9881608750438318e-05\n",
            "0.004231244488365027 0.020817484622323516 1.0\n",
            "repr, std, cov, closslb 0.0131874680519104 0.474853515625 0.0001381896436214447 0.004397123586386442 4.432595596881583e-05\n",
            "0.0042185761001177985 0.020548742279137857 1.0\n",
            "repr, std, cov, closslb 0.01858048141002655 0.474853515625 0.00013823178596794605 0.019237173721194267 0.01514485850930214\n",
            "0.0041766214357232476 0.020303752721903347 1.0\n",
            "repr, std, cov, closslb 0.015588317066431046 0.474609375 0.0001319688744843006 0.0037975122686475515 0.02716173604130745\n",
            "0.004155800831976256 0.02000161913674378 1.0\n",
            "repr, std, cov, closslb 0.01573796384036541 0.4755859375 0.00010515633039176464 0.012981219217181206 0.015240548178553581\n",
            "0.004159956632808232 0.019941734089331788 1.0\n",
            "repr, std, cov, closslb 0.007654058746993542 0.476318359375 0.00010624411515891552 5.485024303197861e-06 0.00014091494085732847\n",
            "0.004159956632808232 0.020021620755880522 1.0\n",
            "repr, std, cov, closslb 0.010057363659143448 0.475830078125 0.00010551232844591141 0.004489982966333628 0.015773512423038483\n",
            "0.004176621435723247 0.0200416423766364 1.0\n",
            "repr, std, cov, closslb 0.009927523322403431 0.475830078125 0.00010721036233007908 0.004600893706083298 0.00017238111468032002\n",
            "0.004147501681112352 0.019901910366688046 1.0\n",
            "repr, std, cov, closslb 0.013093920424580574 0.47705078125 8.75063706189394e-05 0.0035781196784228086 0.0001132307224906981\n",
            "0.004147501681112352 0.019961675823421118 1.0\n",
            "repr, std, cov, closslb 0.009141670539975166 0.47607421875 9.889411740005016e-05 0.004067056812345982 0.00010265623859595507\n",
            "0.004126826240359254 0.019842323848329197 1.0\n",
            "repr, std, cov, closslb 0.007338304538279772 0.474609375 0.00013304618187248707 5.370573944674106e-06 0.00013417420268524438\n",
            "0.004098053662022799 0.019586170297504396 1.0\n",
            "repr, std, cov, closslb 0.008275896310806274 0.476318359375 9.757676161825657e-05 0.003848116146400571 0.00012067193165421486\n",
            "0.004081702346093459 0.019508021086978373 1.0\n",
            "repr, std, cov, closslb 0.009655154310166836 0.476806640625 8.766818791627884e-05 0.00763819832354784 4.028362309327349e-05\n",
            "0.004061354917323809 0.019547056637173415 1.0\n",
            "repr, std, cov, closslb 0.009877949953079224 0.475830078125 0.00010426854714751244 0.004335803911089897 6.309988384600729e-05\n",
            "0.004077624721372087 0.019684297206654537 1.0\n",
            "repr, std, cov, closslb 0.01098838821053505 0.4775390625 8.140015415847301e-05 0.0075701563619077206 0.015570142306387424\n",
            "0.004085784048439552 0.019921812277054734 1.0\n",
            "repr, std, cov, closslb 0.006240337621420622 0.4765625 9.301584213972092e-05 4.695195002568653e-06 0.01542715448886156\n",
            "0.004126826240359254 0.02046675238718732 1.0\n",
            "repr, std, cov, closslb 0.005884093232452869 0.47705078125 9.491154924035072e-05 5.5213095038197935e-06 0.015403739176690578\n",
            "0.004126826240359254 0.020775912022366765 1.0\n",
            "repr, std, cov, closslb 0.007898423820734024 0.47705078125 8.783792145550251e-05 0.003923255018889904 8.061421976890415e-05\n",
            "0.004130953066599613 0.021131942227977665 1.0\n",
            "repr, std, cov, closslb 0.006635991390794516 0.475830078125 0.00010804366320371628 4.207297934044618e-06 2.4508946808055043e-05\n",
            "0.004114470481389174 0.02125905128343489 1.0\n",
            "repr, std, cov, closslb 0.01411785464733839 0.475830078125 0.00011320412158966064 0.0035255749244242907 0.015453973785042763\n",
            "0.0040572976197041045 0.020984608556109036 1.0\n",
            "repr, std, cov, closslb 0.011515708640217781 0.475341796875 0.00011750869452953339 0.007428990676999092 0.0002806473057717085\n",
            "0.004016946905163541 0.020610450172750844 1.0\n",
            "repr, std, cov, closslb 0.00521278940141201 0.4755859375 0.00011177454143762589 7.510767773055704e-06 0.01503903791308403\n",
            "0.003937445375212167 0.020021620755880522 1.0\n",
            "repr, std, cov, closslb 0.005714763421565294 0.474853515625 0.00013170833699405193 1.0398749509477057e-05 4.827377415494993e-05\n",
            "0.003909993176135826 0.019763152580021263 1.0\n",
            "3\n",
            "repr, std, cov, closslb 0.0063948133029043674 0.4755859375 0.00011245720088481903 0.00386028247885406 0.00023107296146918088\n",
            "0.003851809830798836 0.019294714824588444 1.0\n",
            "repr, std, cov, closslb 0.005269958637654781 0.4755859375 0.00012990250252187252 8.610966688138433e-06 0.015735050663352013\n",
            "0.003802085072106116 0.01902660400281714 1.0\n",
            "repr, std, cov, closslb 0.005073579028248787 0.47607421875 0.00010555004701018333 1.1789605196099728e-05 0.030623046681284904\n",
            "0.003760511990325882 0.018650038376306494 1.0\n",
            "repr, std, cov, closslb 0.005886080674827099 0.474609375 0.00013256235979497433 1.4593366358894855e-05 0.0001499168574810028\n",
            "0.0037380276790199337 0.018446113541401837 1.0\n",
            "repr, std, cov, closslb 0.006026786752045155 0.47509765625 0.00013433722779154778 0.003839949844405055 0.0001604443823453039\n",
            "0.003786914676759573 0.01828092556013701 1.0\n",
            "repr, std, cov, closslb 0.00906284898519516 0.47509765625 0.00012035248801112175 0.003656479762867093 4.8570058424957097e-05\n",
            "0.0037907015914363323 0.01822619228647454 1.0\n",
            "repr, std, cov, closslb 0.00748480437323451 0.475830078125 0.00010552862659096718 0.003944067750126123 6.52133094263263e-05\n",
            "0.003813502737379735 0.018171622884779928 1.0\n",
            "repr, std, cov, closslb 0.009708255529403687 0.4755859375 0.00010938523337244987 0.0069069769233465195 0.0002929270267486572\n",
            "0.0038287796446035004 0.018299206485697144 1.0\n",
            "repr, std, cov, closslb 0.012653050944209099 0.475830078125 0.00010585132986307144 0.012346392497420311 0.000447591592092067\n",
            "0.0038905017235762373 0.018799761930100165 1.0\n",
            "repr, std, cov, closslb 0.008164232596755028 0.47705078125 8.422601968050003e-05 0.0034564435482025146 0.00010598486551316455\n",
            "0.003909993176135826 0.019064676237426775 1.0\n",
            "repr, std, cov, closslb 0.012577801011502743 0.47705078125 0.00010569696314632893 0.003369653131812811 2.51781202678103e-05\n",
            "0.003925656624443307 0.019333323548952442 1.0\n",
            "repr, std, cov, closslb 0.0076417275704443455 0.477294921875 8.323951624333858e-05 0.0033650968689471483 0.015605488792061806\n",
            "0.003941382820587379 0.019684297206654537 1.0\n",
            "repr, std, cov, closslb 0.009028461761772633 0.476806640625 8.773594163358212e-05 0.007983402349054813 0.015375330112874508\n",
            "0.00397699748732747 0.02018235544992211 1.0\n",
            "repr, std, cov, closslb 0.006487030535936356 0.4765625 9.252200834453106e-05 1.5925810657790862e-05 0.00021813706553075463\n",
            "0.00396509031714001 0.020446306081106216 1.0\n",
            "repr, std, cov, closslb 0.00907682254910469 0.476806640625 8.660857565701008e-05 0.00393854221329093 0.0003534563584253192\n",
            "0.00397699748732747 0.020838302106945837 1.0\n",
            "repr, std, cov, closslb 0.006297174375504255 0.47607421875 0.00011118198744952679 6.1103792177164e-06 7.639358955202624e-05\n",
            "0.003949269527611373 0.02069301571860528 1.0\n",
            "repr, std, cov, closslb 0.0065790037624537945 0.47607421875 0.00010342267341911793 0.0055313254706561565 0.02132483944296837\n",
            "0.0038827323760916785 0.020263206046604094 1.0\n",
            "repr, std, cov, closslb 0.007897486910223961 0.474365234375 0.00014388212002813816 0.008965667337179184 5.107139440951869e-05\n",
            "0.0038479618689299063 0.019961675823421118 1.0\n",
            "repr, std, cov, closslb 0.005640470422804356 0.474853515625 0.00013103894889354706 7.624019417562522e-06 9.999712347052991e-05\n",
            "0.0037907015914363323 0.01952752910806535 1.0\n",
            "repr, std, cov, closslb 0.007184113375842571 0.476318359375 9.930925443768501e-05 0.0077142841182649136 0.00011052112677134573\n",
            "0.003771804811593341 0.019352656872501393 1.0\n",
            "repr, std, cov, closslb 0.00446205073967576 0.474609375 0.0001436099410057068 7.018930773483589e-06 0.01527556125074625\n",
            "0.0036860856999890368 0.018780980949151017 1.0\n",
            "repr, std, cov, closslb 0.006188267841935158 0.475830078125 0.00010598544031381607 0.004027626942843199 0.0002332206058781594\n",
            "0.0036603860016298957 0.018650038376306494 1.0\n",
            "repr, std, cov, closslb 0.004372193478047848 0.4755859375 0.00010864459909498692 1.8468759662937373e-05 2.050920738838613e-05\n",
            "0.00370085217405122 0.01891284287438705 1.0\n",
            "repr, std, cov, closslb 0.0069531649351119995 0.475830078125 0.00010363268665969372 0.008253615349531174 3.763574204640463e-05\n",
            "0.0036897717856890252 0.0187622187304206 1.0\n",
            "repr, std, cov, closslb 0.019939551129937172 0.474853515625 0.00021235039457678795 0.015929490327835083 2.9790482585667633e-05\n",
            "0.0036494267693919858 0.018299206485697144 1.0\n",
            "repr, std, cov, closslb 0.008504255674779415 0.476806640625 0.00010747951455414295 0.009063610807061195 0.008272049948573112\n",
            "0.0036567292723575385 0.018427685855546293 1.0\n",
            "repr, std, cov, closslb 0.005889155901968479 0.476806640625 0.0001095219049602747 1.2196372153994162e-05 0.0005449078162200749\n",
            "0.0036897717856890252 0.018799761930100165 1.0\n",
            "repr, std, cov, closslb 0.013512405566871166 0.47607421875 0.00012461794540286064 0.012245974503457546 9.77666350081563e-05\n",
            "0.003664046387631525 0.01863140696933716 1.0\n",
            "repr, std, cov, closslb 0.0073061189614236355 0.476318359375 0.00013211392797529697 0.0005841000820510089 0.02015468291938305\n",
            "0.0036824032966923446 0.0187622187304206 1.0\n",
            "repr, std, cov, closslb 0.007894877344369888 0.476318359375 9.770854376256466e-05 0.004414381459355354 9.190499258693308e-05\n",
            "0.00370085217405122 0.018799761930100165 1.0\n",
            "repr, std, cov, closslb 0.0077498736791312695 0.476318359375 0.00011219875887036324 0.007874769158661366 2.612147363834083e-05\n",
            "0.0036750495225976276 0.01868735710309748 1.0\n",
            "repr, std, cov, closslb 0.00636468967422843 0.4755859375 0.00011975527741014957 0.003847877262160182 0.0003945276257582009\n",
            "0.0036457809884035824 0.01863140696933716 1.0\n",
            "repr, std, cov, closslb 0.005708510056138039 0.4755859375 0.00010874168947339058 0.003853009082376957 0.0006399946287274361\n",
            "0.003616745552318447 0.018538528754797633 1.0\n",
            "repr, std, cov, closslb 0.004275717306882143 0.47607421875 0.00012005562894046307 1.2031739061058033e-05 0.015358676202595234\n",
            "0.003562925930138303 0.01822619228647454 1.0\n",
            "repr, std, cov, closslb 0.00507599301636219 0.47509765625 0.00012527359649538994 5.1943578000646085e-05 0.0601850301027298\n",
            "0.0035239678825771774 0.01793703716983216 1.0\n",
            "repr, std, cov, closslb 0.008362232707440853 0.475830078125 0.00012204982340335846 0.011318237520754337 0.031446147710084915\n",
            "0.0035204474351420356 0.01795497420700199 1.0\n",
            "4\n",
            "repr, std, cov, closslb 0.009119942784309387 0.477783203125 8.689728565514088e-05 0.016433045268058777 0.018433187156915665\n",
            "0.00355225849432758 0.018538528754797633 1.0\n",
            "repr, std, cov, closslb 0.013051582500338554 0.478759765625 7.708463817834854e-05 0.011733448132872581 0.0003986019582953304\n",
            "0.003573625400269433 0.018856217633976012 1.0\n",
            "repr, std, cov, closslb 0.006113886833190918 0.4775390625 8.473382331430912e-05 0.003961256705224514 0.015125762671232224\n",
            "0.0036095228970015472 0.019449613877055964 1.0\n",
            "repr, std, cov, closslb 0.006635837256908417 0.477294921875 8.221296593546867e-05 0.010474035516381264 0.015386926010251045\n",
            "0.003623982660168635 0.019802698648333884 1.0\n",
            "repr, std, cov, closslb 0.0041832346469163895 0.476806640625 9.79308970272541e-05 4.113140676054172e-06 6.652872980339453e-05\n",
            "0.003631234249471632 0.02020253780537203 1.0\n",
            "repr, std, cov, closslb 0.0064999740570783615 0.4765625 9.800074622035027e-05 0.007944749668240547 4.420502227731049e-05\n",
            "0.003616745552318447 0.020242963083520575 1.0\n",
            "repr, std, cov, closslb 0.005278538912534714 0.474853515625 0.00014220946468412876 0.0031265215948224068 2.8105936507927254e-05\n",
            "0.003577199025669702 0.019981637499244538 1.0\n",
            "repr, std, cov, closslb 0.0076426733285188675 0.476318359375 0.00010201707482337952 0.022870855405926704 0.012098042294383049\n",
            "0.0035451646199231145 0.019822501346982217 1.0\n",
            "repr, std, cov, closslb 0.004333076067268848 0.4755859375 0.00012039672583341599 1.3150264749128837e-05 0.00029248869395814836\n",
            "0.0035028978817081826 0.019644987586493967 1.0\n",
            "repr, std, cov, closslb 0.003932460676878691 0.4755859375 0.00012780027464032173 9.363998287881259e-06 2.9271537641761824e-05\n",
            "0.003485435813411206 0.01952752910806535 1.0\n",
            "repr, std, cov, closslb 0.010691872797906399 0.475830078125 0.00011218199506402016 0.00401208596304059 0.015832288190722466\n",
            "0.0034645961979367047 0.019236946255745502 1.0\n",
            "repr, std, cov, closslb 0.005492383614182472 0.47509765625 0.00011099083349108696 0.004146788269281387 1.4668641597381793e-05\n",
            "0.0034507723899360816 0.01916019045611838 1.0\n",
            "repr, std, cov, closslb 0.007792570628225803 0.4755859375 0.0001117452047765255 0.008282274007797241 0.0001310766820097342\n",
            "0.0034232900256659744 0.018799761930100165 1.0\n",
            "repr, std, cov, closslb 0.005422968417406082 0.474853515625 0.00012028799392282963 0.004346262663602829 0.00011279518366791308\n",
            "0.0033824763205603007 0.018501507238812772 1.0\n",
            "repr, std, cov, closslb 0.00404164707288146 0.475830078125 0.00011222041212022305 2.902830601669848e-05 0.0052209412679076195\n",
            "0.0033221663143734193 0.018117216864418865 1.0\n",
            "repr, std, cov, closslb 0.00506635894998908 0.475830078125 9.842799045145512e-05 0.0032973703928291798 0.013298921287059784\n",
            "0.0033089108044518345 0.01790121683494544 1.0\n",
            "repr, std, cov, closslb 0.015187745913863182 0.4765625 0.0001069498248398304 0.009787047281861305 1.0726516848080792e-05\n",
            "0.0033454913604587986 0.017990902110390197 1.0\n",
            "repr, std, cov, closslb 0.004041421692818403 0.4755859375 0.0001084033865481615 8.617677849542815e-06 3.41381601174362e-05\n",
            "0.003335474925920785 0.01781197864373149 1.0\n",
            "repr, std, cov, closslb 0.010324512608349323 0.4765625 9.296671487390995e-05 0.0026571587659418583 9.445029718335718e-05\n",
            "0.003335474925920785 0.01767012191423927 1.0\n",
            "repr, std, cov, closslb 0.004768931306898594 0.476318359375 9.024026803672314e-05 0.004048100207000971 0.0012266782578080893\n",
            "0.0033454913604587986 0.01770547982818966 1.0\n",
            "repr, std, cov, closslb 0.007176416926085949 0.476318359375 9.128963574767113e-05 0.007878709584474564 0.0003310798783786595\n",
            "0.0033757215018351294 0.017883333501444 1.0\n",
            "repr, std, cov, closslb 0.0056289066560566425 0.4755859375 0.00010931235738098621 0.003898776601999998 0.015512414276599884\n",
            "0.003372349152682447 0.01782979062237522 1.0\n",
            "repr, std, cov, closslb 0.0045425379648804665 0.47607421875 0.00010486133396625519 1.7493483028374612e-05 0.015773015096783638\n",
            "0.0033454913604587986 0.017687792036153508 1.0\n",
            "repr, std, cov, closslb 0.011190913617610931 0.475830078125 0.00011860998347401619 0.007489943876862526 0.00012740964302793145\n",
            "0.003352185688671076 0.01761721739279151 1.0\n",
            "repr, std, cov, closslb 0.00461762398481369 0.475830078125 0.0001132613979279995 1.2778699783666525e-05 0.0006149350665509701\n",
            "0.0033960265342337518 0.01797292918120899 1.0\n",
            "repr, std, cov, closslb 0.005911658518016338 0.476318359375 0.00011507375165820122 0.004808074329048395 0.00015321683895308524\n",
            "0.0033757215018351294 0.018099117746672194 1.0\n",
            "repr, std, cov, closslb 0.007565396837890148 0.477294921875 8.261622861027718e-05 0.004779296461492777 1.4970799384173006e-05\n",
            "0.003379097223336964 0.018189794507664708 1.0\n",
            "repr, std, cov, closslb 0.009524757042527199 0.47705078125 7.917685434222221e-05 0.008259115740656853 5.918373790336773e-05\n",
            "0.0033858587968808606 0.018446113541401837 1.0\n",
            "repr, std, cov, closslb 0.009304397739470005 0.475341796875 0.00012173340655863285 0.003481896361336112 2.9288385121617466e-05\n",
            "0.003379097223336964 0.018668688414682798 1.0\n",
            "repr, std, cov, closslb 0.006640518084168434 0.47607421875 0.0001097389031201601 0.003670631442219019 9.625738312024623e-05\n",
            "0.0033454913604587986 0.018520008746051583 1.0\n",
            "repr, std, cov, closslb 0.007090711034834385 0.4765625 9.743054397404194e-05 0.003979210276156664 0.030300786718726158\n",
            "0.003358893412234106 0.018743475255165436 1.0\n",
            "repr, std, cov, closslb 0.011534958146512508 0.476318359375 9.703566320240498e-05 0.004093490075320005 0.015332970768213272\n",
            "0.00336225230564634 0.019007596406410733 1.0\n",
            "repr, std, cov, closslb 0.003951318096369505 0.476318359375 0.0001110471785068512 0.0001382059563184157 0.00013376498827710748\n",
            "0.0033421492112475516 0.018875073851609987 1.0\n",
            "repr, std, cov, closslb 0.0043254634365439415 0.47607421875 0.00010680570267140865 2.3745955331833102e-05 1.4559181181539316e-05\n",
            "0.0033188474669065132 0.018988607798612122 1.0\n",
            "repr, std, cov, closslb 0.0044484324753284454 0.477783203125 8.457177318632603e-05 4.201234696665779e-05 2.790030703181401e-05\n",
            "0.003315531934971542 0.019102824654577865 1.0\n",
            "repr, std, cov, closslb 0.004147623665630817 0.478515625 6.600236520171165e-05 7.34626519260928e-05 0.015368335880339146\n",
            "0.0033288139691684798 0.019449613877055964 1.0\n",
            "5\n",
            "repr, std, cov, closslb 0.0041684797033667564 0.478515625 7.149111479520798e-05 1.2197757314424962e-05 0.014445491135120392\n",
            "0.0033689801725099375 0.020081745703032044 1.0\n",
            "repr, std, cov, closslb 0.005201034247875214 0.477783203125 7.743458263576031e-05 0.0040009887889027596 0.014987317845225334\n",
            "0.0033824763205603007 0.020446306081106216 1.0\n",
            "repr, std, cov, closslb 0.007326347753405571 0.477783203125 8.700951002538204e-05 0.007875768467783928 0.015715844929218292\n",
            "0.0034096310301173923 0.021005593164665142 1.0\n",
            "repr, std, cov, closslb 0.016630560159683228 0.477294921875 9.889155626296997e-05 0.007995772175490856 0.017268814146518707\n",
            "0.003392633900333419 0.02121659687309184 1.0\n",
            "repr, std, cov, closslb 0.007355593144893646 0.476806640625 0.00010919664055109024 0.007745916023850441 0.00012648066331166774\n",
            "0.0033221663143734193 0.021153074170205642 1.0\n",
            "repr, std, cov, closslb 0.004410783760249615 0.47509765625 0.00013200612738728523 2.8783037123503163e-05 0.015575265511870384\n",
            "0.0032858408010680374 0.020817484622323516 1.0\n",
            "repr, std, cov, closslb 0.004452638793736696 0.4755859375 0.00014786864630877972 9.357127055409364e-06 0.003148953430354595\n",
            "0.0032401822108585904 0.02034438053109987 1.0\n",
            "repr, std, cov, closslb 0.00919292401522398 0.474853515625 0.00013772700913250446 0.008196217939257622 0.00022986353724263608\n",
            "0.003198353230292857 0.019981637499244538 1.0\n",
            "repr, std, cov, closslb 0.009862248785793781 0.474365234375 0.0001496842596679926 0.003623389173299074 0.015350714325904846\n",
            "0.003153910328664897 0.019352656872501393 1.0\n",
            "repr, std, cov, closslb 0.006203632801771164 0.4736328125 0.0001653463114053011 0.0036846832372248173 1.8447502952767536e-05\n",
            "0.0031163082659945497 0.019045630606819956 1.0\n",
            "repr, std, cov, closslb 0.0052275387570261955 0.474853515625 0.0001296335831284523 3.6940858990419656e-05 2.068562025669962e-05\n",
            "0.0031007733604355285 0.018856217633976012 1.0\n",
            "repr, std, cov, closslb 0.007514611817896366 0.4755859375 0.00011768797412514687 0.0046579670161008835 0.00011361301585566252\n",
            "0.0031007733604355285 0.018799761930100165 1.0\n",
            "repr, std, cov, closslb 0.004343873355537653 0.4755859375 0.00011763162910938263 1.2980020983377472e-05 0.00033284525852650404\n",
            "0.0031131950709236264 0.018893948925461593 1.0\n",
            "repr, std, cov, closslb 0.011061741039156914 0.477783203125 9.307125583291054e-05 0.012930382043123245 0.015376766212284565\n",
            "0.003119424574260544 0.018950687472978695 1.0\n",
            "repr, std, cov, closslb 0.007337413262575865 0.476806640625 0.00011020503006875515 0.011694477871060371 7.080425712047145e-05\n",
            "0.0031507595690958017 0.019410772920442163 1.0\n",
            "repr, std, cov, closslb 0.006976945325732231 0.4775390625 8.997367694973946e-05 0.011246554553508759 0.03200549632310867\n",
            "0.0031665449060603226 0.019763152580021263 1.0\n",
            "repr, std, cov, closslb 0.00922433752566576 0.47705078125 8.996645919978619e-05 0.00710415281355381 0.015494327992200851\n",
            "0.0032047531351066722 0.020303752721903347 1.0\n",
            "repr, std, cov, closslb 0.005124324467033148 0.4765625 0.000107193598523736 1.1783165064116474e-05 0.000648092944175005\n",
            "0.0032208089803771136 0.020589860312438407 1.0\n",
            "repr, std, cov, closslb 0.01227576844394207 0.475830078125 0.00011988822370767593 0.0038953793700784445 0.0006484881741926074\n",
            "0.0032337115540389595 0.020610450172750844 1.0\n",
            "repr, std, cov, closslb 0.013624405488371849 0.47509765625 0.0001457519829273224 0.010284367948770523 0.03085605427622795\n",
            "0.0032143770119761497 0.020405474726179137 1.0\n",
            "repr, std, cov, closslb 0.010219098068773746 0.474609375 0.00017135916277766228 0.006288796663284302 3.1388612114824355e-05\n",
            "0.003176054043579766 0.019782915732601283 1.0\n",
            "repr, std, cov, closslb 0.008864682167768478 0.4755859375 0.0001279492862522602 0.005449701100587845 5.715066799893975e-05\n",
            "0.003182409327720968 0.01970398150386119 1.0\n",
            "repr, std, cov, closslb 0.007273854222148657 0.475830078125 0.00014036591164767742 2.5957553589250892e-05 0.01537431962788105\n",
            "0.0031919661061145226 0.019586170297504396 1.0\n",
            "repr, std, cov, closslb 0.007768778596073389 0.47607421875 0.00012393132783472538 0.004893525503575802 0.013475032523274422\n",
            "0.0031855917370486888 0.019566603693810587 1.0\n",
            "repr, std, cov, closslb 0.005952265113592148 0.4765625 0.00012719538062810898 4.8272457206621766e-05 5.963775038253516e-05\n",
            "0.0032079578882417787 0.019961675823421118 1.0\n",
            "repr, std, cov, closslb 0.013807862997055054 0.477294921875 8.97205900400877e-05 0.012733420357108116 4.3632542656268924e-05\n",
            "0.0032175913889881257 0.020242963083520575 1.0\n",
            "repr, std, cov, closslb 0.012083986774086952 0.4775390625 9.14447009563446e-05 0.008431222289800644 3.609377745306119e-05\n",
            "0.003262931643680878 0.020817484622323516 1.0\n",
            "repr, std, cov, closslb 0.006418952718377113 0.47802734375 9.822333231568336e-05 6.009480330249062e-06 0.00011375878966646269\n",
            "0.0032694607698998826 0.02119540147162022 1.0\n",
            "repr, std, cov, closslb 0.009462116286158562 0.478515625 7.567973807454109e-05 0.004786716774106026 0.0002720126649364829\n",
            "0.003305605199252582 0.021884273133507375 1.0\n",
            "repr, std, cov, closslb 0.02072630636394024 0.47705078125 0.00011681695468723774 0.008177429437637329 0.015614883974194527\n",
            "0.003308910804451834 0.021949991627611562 1.0\n",
            "repr, std, cov, closslb 0.007358540315181017 0.478515625 7.74008221924305e-05 0.0034096711315214634 0.000789435813203454\n",
            "0.003345491360458798 0.022618129344444456 1.0\n",
            "repr, std, cov, closslb 0.008059529587626457 0.4765625 0.00012004980817437172 0.0028956332243978977 0.015390554443001747\n",
            "0.003322166314373419 0.022822508663976438 1.0\n",
            "repr, std, cov, closslb 0.006109287030994892 0.475341796875 0.00015392364002764225 1.9148181308992207e-05 0.0003047276404686272\n",
            "0.0032825582428252123 0.022415580275340567 1.0\n",
            "repr, std, cov, closslb 0.0069454265758395195 0.47509765625 0.0001447929535061121 0.004144687671214342 9.410775237483904e-05\n",
            "0.0032434223930694487 0.022170481932124925 1.0\n",
            "repr, std, cov, closslb 0.010663018561899662 0.47314453125 0.0001859688200056553 0.009191729128360748 5.9910504205618054e-05\n",
            "0.0032015515835231495 0.021580178955022022 1.0\n",
            "repr, std, cov, closslb 0.0046612294390797615 0.474609375 0.00014868727885186672 3.3803635233198293e-06 0.00023653762764297426\n",
            "0.003163381524535787 0.02121659687309184 1.0\n",
            "6\n",
            "repr, std, cov, closslb 0.007301695644855499 0.475341796875 0.00012652832083404064 0.003697715699672699 0.00011939254181925207\n",
            "0.003131921001585848 0.02090087954901129 1.0\n",
            "repr, std, cov, closslb 0.011440369300544262 0.474853515625 0.00014315126463770866 0.0034291695337742567 0.0003279295633547008\n",
            "0.0031069780079297595 0.020672343375230055 1.0\n",
            "repr, std, cov, closslb 0.010161641985177994 0.474853515625 0.00015680817887187004 0.007272304035723209 8.194410474970937e-05\n",
            "0.0030638048159699663 0.020061684019013034 1.0\n",
            "repr, std, cov, closslb 0.00906483456492424 0.474365234375 0.0001633677165955305 0.007800490595400333 5.447801868285751e-06\n",
            "0.0030242527711266455 0.01970398150386119 1.0\n",
            "repr, std, cov, closslb 0.0038856714963912964 0.475830078125 0.00012922147288918495 2.2809499569120817e-05 0.012101870961487293\n",
            "0.00304853164194327 0.019842323848329197 1.0\n",
            "repr, std, cov, closslb 0.004808392375707626 0.4765625 0.00010819267481565475 0.0035912911407649517 0.0001166697038570419\n",
            "0.003054631753758798 0.02018235544992211 1.0\n",
            "repr, std, cov, closslb 0.008480488322675228 0.477294921875 0.00010005501098930836 0.007534070871770382 0.0003707374562509358\n",
            "0.0030853158969233554 0.02069301571860528 1.0\n",
            "repr, std, cov, closslb 0.005124949384480715 0.477294921875 8.95066186785698e-05 0.004494115710258484 0.002856805920600891\n",
            "0.0031007733604355285 0.02106867298194422 1.0\n",
            "repr, std, cov, closslb 0.007068512961268425 0.476318359375 0.00010969862341880798 0.007182341068983078 0.016426796093583107\n",
            "0.003128792209376472 0.021601759133977043 1.0\n",
            "repr, std, cov, closslb 0.0044359685853123665 0.47705078125 0.00010493886657059193 5.6099444918800145e-05 9.351754852104932e-05\n",
            "0.0031131950709236264 0.021709984163363876 1.0\n",
            "repr, std, cov, closslb 0.004231680650264025 0.47607421875 0.00013948092237114906 2.450053671054775e-06 0.001036434667184949\n",
            "0.0031413261634855296 0.022192652414057046 1.0\n",
            "repr, std, cov, closslb 0.004821731708943844 0.47607421875 0.00014413893222808838 0.002799341920763254 0.00011876446660608053\n",
            "0.00313818797551002 0.02237081627198034 1.0\n",
            "repr, std, cov, closslb 0.004621034022420645 0.475830078125 0.00013775378465652466 2.931596554844873e-06 0.01601799577474594\n",
            "0.0030822336632600955 0.022082021266580844 1.0\n",
            "repr, std, cov, closslb 0.005009625107049942 0.474853515625 0.00016314326785504818 2.721903547353577e-05 2.043945642071776e-05\n",
            "0.003076078430321024 0.021949991627611562 1.0\n",
            "repr, std, cov, closslb 0.014112813398241997 0.47509765625 0.00013051251880824566 0.007587306201457977 0.022346923127770424\n",
            "0.0030394043077676407 0.02179695444678395 1.0\n",
            "repr, std, cov, closslb 0.014739008620381355 0.475341796875 0.00013015465810894966 0.019107123836874962 0.015270843170583248\n",
            "0.0030182133262607984 0.021472601009132886 1.0\n",
            "repr, std, cov, closslb 0.009691281244158745 0.47509765625 0.0001506563276052475 0.012189728207886219 0.015094509348273277\n",
            "0.0029614367413471907 0.020817484622323516 1.0\n",
            "repr, std, cov, closslb 0.011665258556604385 0.474609375 0.00018107634969055653 0.01644028164446354 0.0001044481759890914\n",
            "0.0029525701701735903 0.02065169168354651 1.0\n",
            "repr, std, cov, closslb 0.008693798445165157 0.475830078125 0.00011976901441812515 0.007487906608730555 3.400992136448622e-05\n",
            "0.0029525701701735903 0.020528214065072787 1.0\n",
            "repr, std, cov, closslb 0.0038850512355566025 0.47607421875 0.00011673988774418831 4.8092160795931704e-06 1.0532990017964039e-05\n",
            "0.00294078935624637 0.02034438053109987 1.0\n",
            "repr, std, cov, closslb 0.0057032364420592785 0.4765625 9.845034219324589e-05 0.004405946936458349 5.292085916153155e-05\n",
            "0.002970329938842892 0.020507706358714076 1.0\n",
            "repr, std, cov, closslb 0.006424069404602051 0.4765625 0.00011016754433512688 0.004220372997224331 0.0001635024673305452\n",
            "0.0029822290924621858 0.02085914040905278 1.0\n",
            "repr, std, cov, closslb 0.013400038704276085 0.476806640625 0.00010904925875365734 0.004660033620893955 0.00029125844594091177\n",
            "0.0030182133262607984 0.021365559343061717 1.0\n",
            "repr, std, cov, closslb 0.0077766249887645245 0.47705078125 8.918787352740765e-05 0.010171194560825825 7.186112634371966e-05\n",
            "0.0030333346052225907 0.021731694147527236 1.0\n",
            "repr, std, cov, closslb 0.009129105135798454 0.477294921875 9.058788418769836e-05 0.007763518951833248 0.0006948086083866656\n",
            "0.0030638048159699663 0.022437995855615907 1.0\n",
            "repr, std, cov, closslb 0.0066473595798015594 0.478271484375 7.864530198276043e-05 0.004117565229535103 2.4998837034218013e-05\n",
            "0.0030607440718980685 0.022776932022998422 1.0\n",
            "repr, std, cov, closslb 0.00459566805511713 0.477294921875 9.318417869508266e-05 4.0475169953424484e-05 0.00017763151845429093\n",
            "0.0029971700900526246 0.022618129344444456 1.0\n",
            "repr, std, cov, closslb 0.005963063333183527 0.474853515625 0.00015029264613986015 0.008135545067489147 0.015198778361082077\n",
            "0.0029555227403437636 0.022237059911537568 1.0\n",
            "repr, std, cov, closslb 0.004019316751509905 0.475341796875 0.00014102831482887268 0.00010657971142791212 0.01537624467164278\n",
            "0.0029086339272943423 0.021580178955022022 1.0\n",
            "repr, std, cov, closslb 0.004062495194375515 0.473388671875 0.00018837559036910534 1.6056495951488614e-05 0.00016812639660201967\n",
            "0.0028797069250618037 0.02119540147162022 1.0\n",
            "repr, std, cov, closslb 0.004092797636985779 0.47509765625 0.00012688292190432549 4.014830483356491e-05 0.01543886587023735\n",
            "0.0028482193888209628 0.02069301571860528 1.0\n",
            "repr, std, cov, closslb 0.004359507467597723 0.474853515625 0.00014002597890794277 1.1580970749491826e-05 2.5364646717207506e-05\n",
            "0.0028170761462753898 0.0203850896365426 1.0\n",
            "repr, std, cov, closslb 0.008562322705984116 0.473388671875 0.00020206510089337826 0.006649297196418047 7.737519626971334e-05\n",
            "0.0027862734328196965 0.019743409170850414 1.0\n",
            "repr, std, cov, closslb 0.004957571625709534 0.474365234375 0.0001530996523797512 2.610534465929959e-05 0.015356461517512798\n",
            "0.002766847300982944 0.019547056637173415 1.0\n",
            "repr, std, cov, closslb 0.004178198520094156 0.474609375 0.00013684574514627457 2.581782382549136e-06 0.015399339608848095\n",
            "0.0027862734328196965 0.01931400953941303 1.0\n",
            "repr, std, cov, closslb 0.010022571310400963 0.47509765625 0.00012183375656604767 0.015542158856987953 0.041418567299842834\n",
            "0.002794640614724726 0.019256183202001245 1.0\n",
            "7\n",
            "repr, std, cov, closslb 0.00404557166621089 0.47509765625 0.00013212207704782486 1.4361818102770485e-05 0.015601396560668945\n",
            "0.0028482193888209628 0.019236946255745502 1.0\n",
            "repr, std, cov, closslb 0.00377267156727612 0.475830078125 0.00011430936865508556 6.065335128369043e-06 0.015531733632087708\n",
            "0.0028539186758179927 0.019256183202001245 1.0\n",
            "repr, std, cov, closslb 0.018682068213820457 0.4765625 0.0001283676829189062 0.011678114533424377 9.058480645762756e-05\n",
            "0.0029028253737215263 0.01972368548536505 1.0\n",
            "repr, std, cov, closslb 0.004232366103678942 0.47607421875 0.00011382251977920532 1.0390096576884389e-05 0.0003184931119903922\n",
            "0.0029115425612216365 0.020021620755880522 1.0\n",
            "repr, std, cov, closslb 0.004192540422081947 0.476318359375 0.0001068983692675829 3.292031033197418e-05 0.00017984760052058846\n",
            "0.002943730145602616 0.020487219139574506 1.0\n",
            "repr, std, cov, closslb 0.012545362114906311 0.478515625 7.034046575427055e-05 0.008065258152782917 0.0156329944729805\n",
            "0.0029614367413471907 0.02085914040905278 1.0\n",
            "repr, std, cov, closslb 0.005390286911278963 0.476806640625 9.891833178699017e-05 0.004585206508636475 0.00037143437657505274\n",
            "0.0029733002687817346 0.02119540147162022 1.0\n",
            "repr, std, cov, closslb 0.005945616867393255 0.47607421875 0.00012063444592058659 0.007969202473759651 6.756371294613928e-05\n",
            "0.0029643981780885374 0.021280310334718323 1.0\n",
            "repr, std, cov, closslb 0.004680058918893337 0.47509765625 0.00016995309852063656 0.0031598287168890238 0.01814592443406582\n",
            "0.00291736855788664 0.020921780428560296 1.0\n",
            "repr, std, cov, closslb 0.012111106887459755 0.475341796875 0.00014358456246554852 0.01636059582233429 0.0035419350024312735\n",
            "0.0028854692186188516 0.020589860312438407 1.0\n",
            "repr, std, cov, closslb 0.010279295034706593 0.476318359375 0.0001327740028500557 0.011242454871535301 0.0003088470548391342\n",
            "0.0028567725944938106 0.02036472491163097 1.0\n",
            "repr, std, cov, closslb 0.006301341578364372 0.4765625 0.00012660888023674488 0.010845152661204338 1.130278360506054e-05\n",
            "0.0028539186758179927 0.020589860312438407 1.0\n",
            "repr, std, cov, closslb 0.012680130079388618 0.477294921875 0.00010064058005809784 0.0073717087507247925 2.004058478632942e-05\n",
            "0.002882586631986865 0.021153074170205642 1.0\n",
            "repr, std, cov, closslb 0.005981556139886379 0.477294921875 0.00010555144399404526 0.008015243336558342 0.015427361242473125\n",
            "0.0028768300949668373 0.021451149859273617 1.0\n",
            "repr, std, cov, closslb 0.009781169705092907 0.4765625 0.00010642921552062035 0.004589494783431292 0.0004958140198141336\n",
            "0.002882586631986865 0.021928063564047518 1.0\n",
            "repr, std, cov, closslb 0.009481709450483322 0.4765625 0.00010778987780213356 0.00812206044793129 0.00015100216842256486\n",
            "0.0028883546878374702 0.022192652414057046 1.0\n",
            "repr, std, cov, closslb 0.005875940900295973 0.477294921875 0.00010456866584718227 0.003769113915041089 0.014686045236885548\n",
            "0.0029086339272943423 0.022799708955021418 1.0\n",
            "repr, std, cov, closslb 0.004355047829449177 0.476318359375 0.00013340869918465614 3.686447598738596e-06 0.00018627950339578092\n",
            "0.0029115425612216365 0.023120987975868867 1.0\n",
            "repr, std, cov, closslb 0.005224457010626793 0.47705078125 0.00012028426863253117 0.004108106251806021 0.0010637642117217183\n",
            "0.0028912430425253074 0.02335324107946624 1.0\n",
            "repr, std, cov, closslb 0.009860976599156857 0.4775390625 0.00010752701200544834 0.012784378603100777 8.929755858844146e-05\n",
            "0.0028854692186188516 0.023564262930477975 1.0\n",
            "repr, std, cov, closslb 0.0040197838097810745 0.47607421875 0.0001604126300662756 7.809241651557386e-06 0.0001334811677224934\n",
            "0.0028510676082097834 0.02358782719340845 1.0\n",
            "repr, std, cov, closslb 0.0037819372955709696 0.476318359375 0.0001348443329334259 3.4957683965330943e-06 0.00017277267761528492\n",
            "0.0028425314833228346 0.023920211876018543 1.0\n",
            "repr, std, cov, closslb 0.0036942693404853344 0.477783203125 0.00010813935659825802 7.369048944383394e-06 9.554725693305954e-05\n",
            "0.0028567725944938106 0.02452544855683487 1.0\n",
            "repr, std, cov, closslb 0.008309529162943363 0.477294921875 8.927611634135246e-05 0.0072767045348882675 0.014248109422624111\n",
            "0.0028710850537742353 0.024945733379132397 1.0\n",
            "repr, std, cov, closslb 0.004891933873295784 0.475830078125 0.00013941805809736252 3.6323408494354226e-06 0.00014916498912498355\n",
            "0.002859629367088304 0.02519631626965865 1.0\n",
            "repr, std, cov, closslb 0.003545749932527542 0.4765625 0.00010974239557981491 3.651252427516738e-06 1.4823730452917516e-05\n",
            "0.002836854936594709 0.025045666086857068 1.0\n",
            "repr, std, cov, closslb 0.008943907916545868 0.476318359375 0.00013399054296314716 0.003930022940039635 0.00030020304257050157\n",
            "0.00280023269059479 0.024697642590401993 1.0\n",
            "repr, std, cov, closslb 0.0047204745933413506 0.4755859375 0.00014353846199810505 0.00478281918913126 0.03071468137204647\n",
            "0.0027640832177651792 0.024476471138087562 1.0\n",
            "repr, std, cov, closslb 0.004517129622399807 0.474609375 0.00018533016555011272 0.010466734878718853 0.00031543587101623416\n",
            "0.002703967140308661 0.023777191592687905 1.0\n",
            "repr, std, cov, closslb 0.007689047604799271 0.473876953125 0.00018902448937296867 0.0043776207603514194 5.0586571887834e-05\n",
            "0.0026770755941534596 0.023399970914866244 1.0\n",
            "repr, std, cov, closslb 0.012620291672647 0.475341796875 0.00015208707191050053 0.013136671856045723 3.426663170102984e-05\n",
            "0.0026584107987976256 0.022731446398754518 1.0\n",
            "repr, std, cov, closslb 0.004203073214739561 0.47509765625 0.00016163568943738937 4.428157990332693e-05 0.015512491576373577\n",
            "0.0026584107987976256 0.022572960849784045 1.0\n",
            "repr, std, cov, closslb 0.004594048019498587 0.47607421875 0.0001204581931233406 7.43929558666423e-05 0.00041163217974826694\n",
            "0.0026824324224173604 0.022572960849784045 1.0\n",
            "repr, std, cov, closslb 0.004419858567416668 0.475830078125 0.00013063359074294567 3.448855204624124e-05 0.01047480944544077\n",
            "0.002679752669747613 0.02237081627198034 1.0\n",
            "repr, std, cov, closslb 0.0053159259259700775 0.4755859375 0.0001424611546099186 0.00022713610087521374 0.002604904118925333\n",
            "0.002703967140308661 0.022686051609483945 1.0\n",
            "repr, std, cov, closslb 0.005843407474458218 0.47509765625 0.00014284998178482056 0.00418457668274641 2.6355734007665887e-05\n",
            "0.0027066711074489693 0.022731446398754518 1.0\n",
            "8\n",
            "repr, std, cov, closslb 0.007381897419691086 0.47607421875 0.00011424487456679344 0.0038619418628513813 8.78695645951666e-05\n",
            "0.0027284004148627676 0.023028734772233345 1.0\n",
            "repr, std, cov, closslb 0.004881279077380896 0.475341796875 0.00014422647655010223 0.0037018591538071632 0.0004925242974422872\n",
            "0.0027229517883343114 0.02307481527051258 1.0\n",
            "repr, std, cov, closslb 0.0031306820455938578 0.475341796875 0.0001283995807170868 1.2499665444920538e-06 0.0003066060598939657\n",
            "0.00273112881527763 0.022913935724997177 1.0\n",
            "repr, std, cov, closslb 0.0038334298878908157 0.474853515625 0.0001545760314911604 5.2129573305137455e-05 3.577297684387304e-05\n",
            "0.0027229517883343114 0.022686051609483945 1.0\n",
            "repr, std, cov, closslb 0.015266470611095428 0.4765625 0.00012719468213617802 0.012068316340446472 0.03296838328242302\n",
            "0.0027365938040369996 0.022572960849784045 1.0\n",
            "repr, std, cov, closslb 0.004113409668207169 0.474365234375 0.00014425814151763916 6.614880931010703e-06 9.825584129430354e-05\n",
            "0.0027120871563349742 0.022326141662513656 1.0\n",
            "repr, std, cov, closslb 0.003949406091123819 0.4755859375 0.0001260086428374052 0.0033402489498257637 0.015245964750647545\n",
            "0.0027393303978410365 0.02246043385147152 1.0\n",
            "repr, std, cov, closslb 0.003837658790871501 0.475341796875 0.0001334184780716896 4.0026432543527335e-05 0.015228810720145702\n",
            "0.0027393303978410365 0.022348467804176167 1.0\n",
            "repr, std, cov, closslb 0.008346323855221272 0.475830078125 0.00011577853001654148 0.003922169096767902 3.745925278053619e-05\n",
            "0.002769614148283927 0.022708737661093426 1.0\n",
            "repr, std, cov, closslb 0.008948888629674911 0.47607421875 0.00011557596735656261 0.00790991447865963 0.0001910494756884873\n",
            "0.0027751561461946423 0.022731446398754518 1.0\n",
            "repr, std, cov, closslb 0.003207637695595622 0.4755859375 0.0001453158911317587 2.820649569912348e-05 0.016087645664811134\n",
            "0.002794640614724726 0.022822508663976438 1.0\n",
            "repr, std, cov, closslb 0.004069677088409662 0.475830078125 0.00011389539577066898 0.004683186765760183 0.0003830153727903962\n",
            "0.0027723837624322105 0.022731446398754518 1.0\n",
            "repr, std, cov, closslb 0.005545948166400194 0.47607421875 0.00011629029177129269 0.007948175072669983 0.001081972848623991\n",
            "0.0027448117979671158 0.0226407474737889 1.0\n",
            "repr, std, cov, closslb 0.00768619030714035 0.474609375 0.00014294707216322422 0.019297510385513306 0.008690516464412212\n",
            "0.0027175140427348 0.022348467804176167 1.0\n",
            "repr, std, cov, closslb 0.008684075437486172 0.47412109375 0.00015052431263029575 0.003770451759919524 0.030976317822933197\n",
            "0.0026690604030939094 0.021709984163363876 1.0\n",
            "repr, std, cov, closslb 0.0049544451758265495 0.47314453125 0.00017948588356375694 0.003544621402397752 0.0155643280595541\n",
            "0.0026425160120949025 0.02132289223569809 1.0\n",
            "repr, std, cov, closslb 0.0033472562208771706 0.47314453125 0.0001983456313610077 4.677125161833828e-06 0.00021102288155816495\n",
            "0.002616235610885221 0.02069301571860528 1.0\n",
            "repr, std, cov, closslb 0.007569205015897751 0.47509765625 0.00012104399502277374 0.0040421998128294945 4.362228719401173e-05\n",
            "0.0026372388970618823 0.020672343375230055 1.0\n",
            "repr, std, cov, closslb 0.010313183069229126 0.475830078125 0.00011261692270636559 0.01118564698845148 0.0004834710853174329\n",
            "0.0026744011929604994 0.020672343375230055 1.0\n",
            "repr, std, cov, closslb 0.00632247980684042 0.475830078125 9.794067591428757e-05 0.008746237494051456 0.015044339932501316\n",
            "0.0026985673071271 0.02090087954901129 1.0\n",
            "repr, std, cov, closslb 0.012344831600785255 0.477294921875 8.90018418431282e-05 0.004127788823097944 0.0002054303331533447\n",
            "0.0027284004148627676 0.021386924902404778 1.0\n",
            "repr, std, cov, closslb 0.01193350087851286 0.47705078125 9.860564023256302e-05 0.011023403145372868 2.385866355325561e-05\n",
            "0.0027202315567775343 0.021494073610142016 1.0\n",
            "repr, std, cov, closslb 0.012745433486998081 0.476806640625 0.00011411262676119804 0.010415487922728062 4.207516030874103e-05\n",
            "0.0027475566097650826 0.021928063564047518 1.0\n",
            "repr, std, cov, closslb 0.003199012251570821 0.476806640625 0.0001320401206612587 4.837693268200383e-06 0.018048441037535667\n",
            "0.002758563332536774 0.022237059911537568 1.0\n",
            "repr, std, cov, closslb 0.004101098049432039 0.47705078125 0.00010089040733873844 0.003592279739677906 4.5702370698563755e-05\n",
            "0.002769614148283927 0.0226407474737889 1.0\n",
            "repr, std, cov, closslb 0.004449487663805485 0.475830078125 0.00011923746205866337 0.003889064071699977 0.00036815687781199813\n",
            "0.00278348994287682 0.02293684966072217 1.0\n",
            "repr, std, cov, closslb 0.0032927223946899176 0.475830078125 0.00013049505650997162 2.3061909814714454e-05 0.0008560476126149297\n",
            "0.00280023269059479 0.02330660456373421 1.0\n",
            "repr, std, cov, closslb 0.0066517675295472145 0.475341796875 0.00012658163905143738 0.007767753675580025 0.0003309718449600041\n",
            "0.0027918487659587678 0.023260061181310413 1.0\n",
            "repr, std, cov, closslb 0.0034951758570969105 0.47607421875 0.00011050701141357422 4.742826604342554e-06 8.62675515236333e-05\n",
            "0.0027807092336431774 0.02309789008578309 1.0\n",
            "repr, std, cov, closslb 0.0036732610315084457 0.4755859375 0.00013348553329706192 4.780063136422541e-06 1.2054249054926913e-05\n",
            "0.0027640832177651792 0.022913935724997177 1.0\n",
            "repr, std, cov, closslb 0.004206140525639057 0.475341796875 0.00012230477295815945 0.0044652558863162994 2.9464617909980007e-05\n",
            "0.0027558075250117627 0.0226407474737889 1.0\n",
            "repr, std, cov, closslb 0.006968633271753788 0.474853515625 0.00012933742254972458 0.012964906170964241 0.015671083703637123\n",
            "0.0027202315567775343 0.022259296971449103 1.0\n",
            "repr, std, cov, closslb 0.00674760527908802 0.474609375 0.00011846190318465233 0.0036177674774080515 0.03165968134999275\n",
            "0.0026851148548397777 0.021775179267516435 1.0\n",
            "repr, std, cov, closslb 0.008470835164189339 0.474365234375 0.00012208707630634308 0.008445821702480316 0.006790428422391415\n",
            "0.002663730278806019 0.02140831182730718 1.0\n",
            "repr, std, cov, closslb 0.004745153710246086 0.473876953125 0.0001464318484067917 0.0034203322138637304 0.00016000933828763664\n",
            "0.0026372388970618823 0.02085914040905278 1.0\n",
            "repr, std, cov, closslb 0.004125544801354408 0.4736328125 0.00014181318692862988 2.6298148441128433e-06 1.1210961019969545e-05\n",
            "0.0026057967785645 0.020528214065072787 1.0\n",
            "9\n",
            "repr, std, cov, closslb 0.0038488712161779404 0.4736328125 0.0001614594366401434 4.607009941537399e-06 3.450956137385219e-05\n",
            "0.002567020758501194 0.019961675823421118 1.0\n",
            "repr, std, cov, closslb 0.006178850308060646 0.474365234375 0.00013619684614241123 0.007857907563447952 5.6830922403605655e-06\n",
            "0.0025414911741436287 0.019644987586493967 1.0\n",
            "repr, std, cov, closslb 0.0070663639344275 0.474365234375 0.00013533979654312134 0.010615077801048756 3.354269574629143e-05\n",
            "0.0025567782944240624 0.01952752910806535 1.0\n",
            "repr, std, cov, closslb 0.008447793312370777 0.47412109375 0.00012709549628198147 0.011020365171134472 0.00010913873848039657\n",
            "0.002574729524405993 0.019508021086978373 1.0\n",
            "repr, std, cov, closslb 0.005713696591556072 0.4755859375 0.00010358751751482487 0.007730682846158743 0.015451747924089432\n",
            "0.002587628945083437 0.019410772920442163 1.0\n",
            "repr, std, cov, closslb 0.005931152030825615 0.475341796875 0.00010237772949039936 0.003783367108553648 0.015478629618883133\n",
            "0.0026005929919875334 0.01939138153890326 1.0\n",
            "repr, std, cov, closslb 0.0041999672539532185 0.475830078125 0.00010524550452828407 0.005732209887355566 0.0005720389890484512\n",
            "0.002621470698342602 0.01937200952937389 1.0\n",
            "repr, std, cov, closslb 0.011082454584538937 0.474853515625 0.00013711582869291306 0.013896751217544079 0.015525417402386665\n",
            "0.002631972320448665 0.019449613877055964 1.0\n",
            "repr, std, cov, closslb 0.010496800765395164 0.475830078125 0.00010734959505498409 0.009047720581293106 4.769018414663151e-05\n",
            "0.002679752669747613 0.019684297206654537 1.0\n",
            "repr, std, cov, closslb 0.007219498977065086 0.4755859375 0.00011227582581341267 0.004429513588547707 0.0002590978401713073\n",
            "0.0026744011929604994 0.0196057564678019 1.0\n",
            "repr, std, cov, closslb 0.010397393256425858 0.475830078125 0.0001168388407677412 0.0051863896660506725 0.015258320607244968\n",
            "0.0026931782574339752 0.019802698648333884 1.0\n",
            "repr, std, cov, closslb 0.008441138081252575 0.474853515625 0.00013565365225076675 0.0034502341877669096 1.0461635611136444e-05\n",
            "0.002671729463497003 0.019508021086978373 1.0\n",
            "repr, std, cov, closslb 0.0036599489394575357 0.47412109375 0.00014539482071995735 5.323532150214305e-06 0.029619164764881134\n",
            "0.0026293429774711945 0.019007596406410733 1.0\n",
            "repr, std, cov, closslb 0.006598369684070349 0.476318359375 0.00010245107114315033 0.009166705422103405 0.000167208316270262\n",
            "0.002639876135958944 0.019045630606819956 1.0\n",
            "repr, std, cov, closslb 0.004456912167370319 0.475830078125 0.00010866252705454826 1.1648693316601566e-06 0.0004727515915874392\n",
            "0.002661069209596423 0.019449613877055964 1.0\n",
            "repr, std, cov, closslb 0.00449473736807704 0.47509765625 0.0001242274884134531 6.807910722272936e-06 9.554119060339872e-06\n",
            "0.002650451490321739 0.01937200952937389 1.0\n",
            "repr, std, cov, closslb 0.007374169304966927 0.475341796875 0.00011171959340572357 0.004646170884370804 0.001227481639944017\n",
            "0.002647803686635104 0.019430183693362604 1.0\n",
            "repr, std, cov, closslb 0.005307195242494345 0.47705078125 8.625281043350697e-05 0.0033740780781954527 0.0005262938793748617\n",
            "0.002639876135958944 0.019508021086978373 1.0\n",
            "repr, std, cov, closslb 0.004260500427335501 0.474853515625 0.00014055497013032436 6.958004632906523e-06 0.0005921627744100988\n",
            "0.0026425160120949025 0.019743409170850414 1.0\n",
            "repr, std, cov, closslb 0.003992593381553888 0.475830078125 0.00011237268336117268 2.8685672077699564e-05 0.000787555705755949\n",
            "0.002624092169040944 0.019566603693810587 1.0\n",
            "repr, std, cov, closslb 0.004245659336447716 0.475341796875 0.00012026727199554443 1.48704039020231e-05 0.000583506072871387\n",
            "0.002624092169040944 0.01919852999722107 1.0\n",
            "repr, std, cov, closslb 0.0039465283043682575 0.47509765625 0.0001181229017674923 3.0144867196213454e-05 3.754530189326033e-05\n",
            "0.002608402575343064 0.018969638160451673 1.0\n",
            "repr, std, cov, closslb 0.005709859076887369 0.474609375 0.00012658396735787392 0.003726257011294365 3.483001273707487e-05\n",
            "0.0025979949969905432 0.018612794175161998 1.0\n",
            "repr, std, cov, closslb 0.007104291580617428 0.474609375 0.0001279423013329506 0.0075127738527953625 1.937116394401528e-05\n",
            "0.0025953995973931505 0.018427685855546293 1.0\n",
            "repr, std, cov, closslb 0.004249097779393196 0.475341796875 0.00011594314128160477 2.5387833375134505e-05 5.661891191266477e-05\n",
            "0.002587628945083437 0.018153469415364564 1.0\n",
            "repr, std, cov, closslb 0.0068756574764847755 0.4765625 9.898422285914421e-05 0.0034610237926244736 0.00024135307467076927\n",
            "0.002611010977918407 0.018299206485697144 1.0\n",
            "repr, std, cov, closslb 0.010362952947616577 0.4755859375 0.00010333373211324215 0.009943453595042229 0.01464426051825285\n",
            "0.002639876135958944 0.018372513180093964 1.0\n",
            "repr, std, cov, closslb 0.005289848893880844 0.475830078125 0.00011261459439992905 2.088846667902544e-05 0.00021440020645968616\n",
            "0.002631972320448665 0.018538528754797633 1.0\n",
            "repr, std, cov, closslb 0.004958984442055225 0.476806640625 9.129266254603863e-05 5.261848127702251e-05 0.015443149954080582\n",
            "0.002647803686635104 0.018893948925461593 1.0\n",
            "repr, std, cov, closslb 0.006861983332782984 0.47705078125 8.965190500020981e-05 0.00488815875723958 2.052774652838707e-05\n",
            "0.0026531019418120604 0.019045630606819956 1.0\n",
            "repr, std, cov, closslb 0.010590586811304092 0.477294921875 7.96332024037838e-05 0.008005565032362938 7.19725139788352e-05\n",
            "0.0026851148548397777 0.019644987586493967 1.0\n",
            "repr, std, cov, closslb 0.006741414777934551 0.47705078125 9.224121458828449e-05 0.004334444645792246 9.035060429596342e-06\n",
            "0.0026744011929604994 0.01970398150386119 1.0\n",
            "repr, std, cov, closslb 0.004306190647184849 0.476318359375 0.00010561756789684296 4.360591447039042e-06 5.203380624152487e-06\n",
            "0.0026744011929604994 0.019901910366688046 1.0\n",
            "repr, std, cov, closslb 0.007853874936699867 0.474853515625 0.0001288573257625103 0.01295788399875164 6.397209654096514e-05\n",
            "0.002650451490321739 0.019586170297504396 1.0\n",
            "repr, std, cov, closslb 0.010452499613165855 0.474609375 0.00011569797061383724 0.007212088443338871 0.00017452117754146457\n",
            "0.002618851846496106 0.019121927479232442 1.0\n",
            "repr, std, cov, closslb 0.004468286409974098 0.47509765625 0.00012365961447358131 4.732338311441708e-06 0.0005086888559162617\n",
            "0.0025773042539303987 0.018799761930100165 1.0\n",
            "10\n",
            "repr, std, cov, closslb 0.00432074349373579 0.473876953125 0.000133417546749115 8.99084443517495e-06 3.345970617374405e-05\n",
            "0.0025162154871008055 0.01820798430217237 1.0\n",
            "repr, std, cov, closslb 0.0037786916363984346 0.474853515625 0.00012719654478132725 3.6596604786609532e-06 0.00045025424333289266\n",
            "0.002491191172308253 0.017883333501444 1.0\n",
            "repr, std, cov, closslb 0.01044304110109806 0.474365234375 0.00014542159624397755 0.007864084094762802 7.515914330724627e-05\n",
            "0.0024541205612484867 0.017407178538338303 1.0\n",
            "repr, std, cov, closslb 0.01086653396487236 0.4755859375 0.00012462842278182507 0.016943620517849922 1.0023595677921548e-05\n",
            "0.002449219672683448 0.01723406033060664 1.0\n",
            "repr, std, cov, closslb 0.015080294571816921 0.475341796875 0.00012950319796800613 0.0195637084543705 1.2428780792106409e-05\n",
            "0.0024639517780357836 0.017355061271983482 1.0\n",
            "repr, std, cov, closslb 0.005387622397392988 0.475830078125 0.00010238448157906532 0.004047958180308342 6.074719567550346e-05\n",
            "0.002478772497296677 0.01752939494871683 1.0\n",
            "repr, std, cov, closslb 0.008170966058969498 0.47802734375 6.812391802668571e-05 0.007889185100793839 0.0003386004245840013\n",
            "0.00251119059472077 0.017990902110390197 1.0\n",
            "repr, std, cov, closslb 0.0047682346776127815 0.47607421875 0.00010756775736808777 0.004420995246618986 6.603262590942904e-05\n",
            "0.002521250434290494 0.01820798430217237 1.0\n",
            "repr, std, cov, closslb 0.004327195230871439 0.4765625 0.00011268421076238155 0.0035083768889307976 0.015288173221051693\n",
            "0.0025137017853154903 0.018354159021072892 1.0\n",
            "repr, std, cov, closslb 0.0053800977766513824 0.475830078125 0.00012074667029082775 0.0037581301294267178 0.018636934459209442\n",
            "0.002506175737070892 0.018483024214598177 1.0\n",
            "repr, std, cov, closslb 0.011194813996553421 0.4765625 0.00010218448005616665 0.0075334105640649796 0.01488875038921833\n",
            "0.002471351027689176 0.018409276578967328 1.0\n",
            "repr, std, cov, closslb 0.003652433166280389 0.4775390625 9.356020018458366e-05 4.696911219070898e-06 0.00012853446241933852\n",
            "0.002483732521063767 0.018668688414682798 1.0\n",
            "repr, std, cov, closslb 0.004151523113250732 0.477783203125 8.460693061351776e-05 6.768036200810457e-06 0.01619022712111473\n",
            "0.0025011708941117747 0.019179350646574497 1.0\n",
            "repr, std, cov, closslb 0.007550454698503017 0.476318359375 9.313994087278843e-05 0.0037145051173865795 0.0006057447171770036\n",
            "0.00251119059472077 0.019430183693362604 1.0\n",
            "repr, std, cov, closslb 0.004092027898877859 0.47705078125 9.505869820713997e-05 4.795609129359946e-06 0.00013106899859849364\n",
            "0.00251119059472077 0.0196057564678019 1.0\n",
            "repr, std, cov, closslb 0.0076172794215381145 0.475341796875 0.00011793477460741997 0.011788420379161835 0.002098644617944956\n",
            "0.0024862162535848305 0.019586170297504396 1.0\n",
            "repr, std, cov, closslb 0.005172210279852152 0.476806640625 9.519397281110287e-05 0.00401814142242074 0.00035820345510728657\n",
            "0.0024862162535848305 0.019508021086978373 1.0\n",
            "repr, std, cov, closslb 0.005217238795012236 0.475341796875 0.0001173289492726326 0.0031329228077083826 0.00021998620650265366\n",
            "0.0024590312564915446 0.019352656872501393 1.0\n",
            "repr, std, cov, closslb 0.00858488492667675 0.475830078125 0.00010733888484537601 0.0040922812186181545 0.015802690759301186\n",
            "0.002478772497296677 0.0196253622242697 1.0\n",
            "repr, std, cov, closslb 0.005778790917247534 0.4765625 9.208661504089832e-05 0.004259276203811169 8.140564023051411e-05\n",
            "0.0024812512697939735 0.019901910366688046 1.0\n",
            "repr, std, cov, closslb 0.005995337851345539 0.47607421875 9.209499694406986e-05 0.004727841354906559 0.0003522586775943637\n",
            "0.002478772497296677 0.020061684019013034 1.0\n",
            "repr, std, cov, closslb 0.006689158268272877 0.4765625 8.573103696107864e-05 0.009162308648228645 0.0001827884989324957\n",
            "0.0024738223787168652 0.020081745703032044 1.0\n",
            "repr, std, cov, closslb 0.004553814884275198 0.4755859375 0.00012306938879191875 0.003178639803081751 4.604093192028813e-05\n",
            "0.002439447237290634 0.019586170297504396 1.0\n",
            "repr, std, cov, closslb 0.004297654144465923 0.475341796875 0.00012083817273378372 1.8754800521492143e-06 0.001504293642938137\n",
            "0.0024103632626880844 0.019275439385203243 1.0\n",
            "repr, std, cov, closslb 0.003243507817387581 0.4765625 0.00010684225708246231 2.4067649064818397e-06 1.2135829820181243e-05\n",
            "0.0023840076638155174 0.018950687472978695 1.0\n",
            "repr, std, cov, closslb 0.01021958515048027 0.47509765625 0.00013510091230273247 0.015231265686452389 7.195454600150697e-06\n",
            "0.0023721233023377107 0.0187622187304206 1.0\n",
            "repr, std, cov, closslb 0.005973021499812603 0.474853515625 0.0001331176608800888 0.0035185948945581913 5.055487417848781e-05\n",
            "0.0023321578539205953 0.018427685855546293 1.0\n",
            "repr, std, cov, closslb 0.0044409106485545635 0.4765625 9.705708362162113e-05 0.0033395809587091208 0.00016253268404398113\n",
            "0.002315897853950481 0.018372513180093964 1.0\n",
            "repr, std, cov, closslb 0.006109960377216339 0.475830078125 0.00010391394607722759 0.0037804488092660904 0.03042484261095524\n",
            "0.0022951586076886067 0.01813533408128328 1.0\n",
            "repr, std, cov, closslb 0.004428029526025057 0.4765625 9.54153947532177e-05 0.0031152779702097178 0.015409461222589016\n",
            "0.002299751220062591 0.01831750569218284 1.0\n",
            "repr, std, cov, closslb 0.004482662305235863 0.476806640625 9.465520270168781e-05 6.382853825925849e-06 0.01583227515220642\n",
            "0.002315897853950481 0.01863140696933716 1.0\n",
            "repr, std, cov, closslb 0.005215595476329327 0.475830078125 0.00010650628246366978 0.003947692923247814 4.433936555869877e-05\n",
            "0.002318213751804431 0.018950687472978695 1.0\n",
            "repr, std, cov, closslb 0.00335904723033309 0.477783203125 7.80054833739996e-05 2.3611311917193234e-05 0.00023110889014787972\n",
            "0.0023344900117745157 0.01931400953941303 1.0\n",
            "repr, std, cov, closslb 0.007568187080323696 0.475341796875 0.00012494833208620548 0.007224992383271456 0.015313451178371906\n",
            "0.002329828025894701 0.01937200952937389 1.0\n",
            "repr, std, cov, closslb 0.0038024880923330784 0.47509765625 0.00014283554628491402 2.501009112165775e-05 0.025316527113318443\n",
            "0.002288286879899981 0.018780980949151017 1.0\n",
            "repr, std, cov, closslb 0.004022488836199045 0.474365234375 0.00013543828390538692 7.855182957428042e-06 0.015733126550912857\n",
            "0.00226552936508782 0.018501507238812772 1.0\n",
            "11\n",
            "repr, std, cov, closslb 0.008063936606049538 0.475830078125 0.00010151462629437447 0.00436194846406579 0.015690159052610397\n",
            "0.0022768796898735323 0.018427685855546293 1.0\n",
            "repr, std, cov, closslb 0.011768847703933716 0.475830078125 0.00011440948583185673 0.015501693822443485 0.015352166257798672\n",
            "0.0022860008790209605 0.018354159021072892 1.0\n",
            "repr, std, cov, closslb 0.004100104793906212 0.475341796875 0.00010345084592700005 5.229332236922346e-05 0.00019309238996356726\n",
            "0.002288286879899981 0.018171622884779928 1.0\n",
            "repr, std, cov, closslb 0.004704749211668968 0.47509765625 0.0001242370344698429 9.362031050841324e-06 0.00014938358799554408\n",
            "0.0022632660989888313 0.01793703716983216 1.0\n",
            "repr, std, cov, closslb 0.004287309478968382 0.475341796875 0.00011100503616034985 1.0002044291468337e-05 0.015366398729383945\n",
            "0.0022564898576896996 0.01761721739279151 1.0\n",
            "repr, std, cov, closslb 0.004421093966811895 0.474853515625 0.00010853144340217113 1.6600210074102506e-05 1.6500249330420047e-05\n",
            "0.0022632660989888313 0.01752939494871683 1.0\n",
            "repr, std, cov, closslb 0.008762041106820107 0.475830078125 0.00010102079249918461 0.008047503419220448 0.03170356526970863\n",
            "0.0022768796898735323 0.01751188306565118 1.0\n",
            "repr, std, cov, closslb 0.006955598946660757 0.47607421875 9.154318831861019e-05 0.007650166749954224 0.016588222235441208\n",
            "0.00229286574194666 0.01767012191423927 1.0\n",
            "repr, std, cov, closslb 0.01160681527107954 0.476318359375 8.861767128109932e-05 0.007307744584977627 0.00038225078606046736\n",
            "0.002327500525369332 0.017847620412997593 1.0\n",
            "repr, std, cov, closslb 0.0069099776446819305 0.475341796875 9.747128933668137e-05 0.008688188157975674 0.00017143010336440057\n",
            "0.00233682450178629 0.018044928807418592 1.0\n",
            "repr, std, cov, closslb 0.006002412177622318 0.475830078125 9.359046816825867e-05 0.0036036944948136806 2.8171623853268102e-05\n",
            "0.002341500487614364 0.01826266289723977 1.0\n",
            "repr, std, cov, closslb 0.008302065543830395 0.475830078125 8.22567380964756e-05 0.007807998917996883 0.014908839948475361\n",
            "0.0023461858300900798 0.01833582319787502 1.0\n",
            "repr, std, cov, closslb 0.007807760499417782 0.475341796875 0.00010243896394968033 0.0173813309520483 1.6691603377694264e-05\n",
            "0.002327500525369332 0.018117216864418865 1.0\n",
            "repr, std, cov, closslb 0.004119161982089281 0.47509765625 0.00011706631630659103 2.7319687433191575e-05 0.0004287102783564478\n",
            "0.002325175350019313 0.018081036709962233 1.0\n",
            "repr, std, cov, closslb 0.015365885570645332 0.475341796875 0.00011624442413449287 0.0044466108083724976 0.0004369760281406343\n",
            "0.0023112729966841164 0.017794184459272222 1.0\n",
            "repr, std, cov, closslb 0.006710246670991182 0.475341796875 0.00011147861368954182 0.00399762112647295 0.015620043501257896\n",
            "0.0022768796898735323 0.01752939494871683 1.0\n",
            "repr, std, cov, closslb 0.004127211403101683 0.475341796875 0.00010478240437805653 3.480292798485607e-05 7.149419252527878e-05\n",
            "0.002258746347547389 0.01716529608580855 1.0\n",
            "repr, std, cov, closslb 0.006823898758739233 0.474853515625 0.00011467188596725464 0.004247665870934725 4.251946847944055e-06\n",
            "0.002254235622067632 0.01701157803556108 1.0\n",
            "repr, std, cov, closslb 0.0032788501121103764 0.4755859375 0.00011095800437033176 1.0478551303094719e-05 0.00014711462426930666\n",
            "0.0022474864181065723 0.016724967578253088 1.0\n",
            "repr, std, cov, closslb 0.00659151840955019 0.476318359375 8.890312165021896e-05 0.004394951276481152 0.0003952426777686924\n",
            "0.002251983638429203 0.01674169254583134 1.0\n",
            "repr, std, cov, closslb 0.0038007379043847322 0.47607421875 9.407568722963333e-05 6.917803148098756e-06 0.0003737373335752636\n",
            "0.002281435726132969 0.01718246138189436 1.0\n",
            "repr, std, cov, closslb 0.00948815606534481 0.476318359375 8.875224739313126e-05 0.00799503643065691 2.90998777927598e-05\n",
            "0.0022905751667798807 0.017355061271983482 1.0\n",
            "repr, std, cov, closslb 0.007981645874679089 0.4765625 8.483394049108028e-05 0.0077778855338692665 4.9210109864361584e-05\n",
            "0.0023321578539205953 0.01770547982818966 1.0\n",
            "repr, std, cov, closslb 0.0059338100254535675 0.4765625 8.03282018750906e-05 0.004730583168566227 0.030914679169654846\n",
            "0.00233682450178629 0.01795497420700199 1.0\n",
            "repr, std, cov, closslb 0.012407572939991951 0.476806640625 8.10984056442976e-05 0.01241379976272583 0.015237554907798767\n",
            "0.002357940244572421 0.018390885693274055 1.0\n",
            "repr, std, cov, closslb 0.002758357673883438 0.476806640625 7.862388156354427e-05 8.074389370449353e-06 0.00035512898466549814\n",
            "0.0023555846599125087 0.018520008746051583 1.0\n",
            "repr, std, cov, closslb 0.007051427848637104 0.476318359375 9.046867489814758e-05 0.0036398584488779306 0.00019313090888317674\n",
            "0.0023228524975217914 0.018117216864418865 1.0\n",
            "repr, std, cov, closslb 0.007686794735491276 0.47509765625 9.432598017156124e-05 0.007845957763493061 1.5816412997082807e-05\n",
            "0.002297453766296295 0.017847620412997593 1.0\n",
            "repr, std, cov, closslb 0.0036202343180775642 0.474853515625 0.00011080550029873848 1.0464334081916604e-05 5.031185719417408e-05\n",
            "0.0022632660989888313 0.01730310004524452 1.0\n",
            "repr, std, cov, closslb 0.0037613259628415108 0.473876953125 0.00011890241876244545 5.57503335585352e-06 1.0790125088533387e-05\n",
            "0.002236282619807329 0.01701157803556108 1.0\n",
            "repr, std, cov, closslb 0.009014887735247612 0.47314453125 0.00014541088603436947 0.007465350441634655 0.030401617288589478\n",
            "0.0022008044161533724 0.016492564827434022 1.0\n",
            "repr, std, cov, closslb 0.008564150892198086 0.47412109375 0.00011305208317935467 0.00706248264759779 0.00022284351871348917\n",
            "0.0021810958505605643 0.016230913384749107 1.0\n",
            "repr, std, cov, closslb 0.007684767711907625 0.474365234375 0.0001283641904592514 0.0031457010190933943 0.015296394005417824\n",
            "0.002168054956602966 0.015862045019241253 1.0\n",
            "repr, std, cov, closslb 0.007768245413899422 0.474853515625 0.00011411565355956554 0.011324383318424225 9.78762636805186e-06\n",
            "0.0021572471269138693 0.015688604898286412 1.0\n",
            "repr, std, cov, closslb 0.0036495658569037914 0.4755859375 9.29483212530613e-05 1.5826451544853626e-06 4.493327287491411e-05\n",
            "0.0021854602233575358 0.015735717794484565 1.0\n",
            "repr, std, cov, closslb 0.0057137287221848965 0.4765625 7.267529144883156e-05 0.007837171666324139 0.0009247648995369673\n",
            "0.0022030052205695254 0.01592558843505237 1.0\n",
            "12\n",
            "repr, std, cov, closslb 0.0026541505940258503 0.477294921875 6.612064316868782e-05 1.5842239236008027e-06 7.102282688720152e-05\n",
            "0.0022162563410644126 0.016377577283537555 1.0\n",
            "repr, std, cov, closslb 0.0030544656328856945 0.476806640625 7.366365753114223e-05 2.9584211915789638e-06 0.00021795390057377517\n",
            "0.0022162563410644126 0.01667489285832465 1.0\n",
            "repr, std, cov, closslb 0.008237607777118683 0.476318359375 0.000101038021966815 0.004861440509557724 0.00010993577598128468\n",
            "0.0022497339045246785 0.017148147937870683 1.0\n",
            "repr, std, cov, closslb 0.00401631835848093 0.475830078125 9.462540037930012e-05 2.0149279862380354e-06 0.015755921602249146\n",
            "0.002236282619807329 0.01718246138189436 1.0\n",
            "repr, std, cov, closslb 0.011912735179066658 0.476318359375 8.315360173583031e-05 0.006796171423047781 0.015928974375128746\n",
            "0.002225134672833957 0.01719964384327625 1.0\n",
            "repr, std, cov, closslb 0.003594049019739032 0.476318359375 8.540763519704342e-05 3.6271471799409483e-06 0.015441720373928547\n",
            "0.0022295871673142977 0.01733772354843505 1.0\n",
            "repr, std, cov, closslb 0.006675205193459988 0.475830078125 7.908325642347336e-05 0.004401682876050472 0.00023172918008640409\n",
            "0.002227359807506791 0.017389788749588717 1.0\n",
            "repr, std, cov, closslb 0.006383489817380905 0.4755859375 8.793268352746964e-05 0.007501870859414339 0.00027106032939627767\n",
            "0.0022184725974054766 0.01726854568532818 1.0\n",
            "repr, std, cov, closslb 0.003374710213392973 0.47607421875 0.00010154745541512966 2.365853561059339e-06 0.00013925884559284896\n",
            "0.002187645683580893 0.016994583452108976 1.0\n",
            "repr, std, cov, closslb 0.00475491164252162 0.4736328125 0.00013202475383877754 0.003766042646020651 7.912372893770225e-06\n",
            "0.0021615637784148235 0.016691567751182974 1.0\n",
            "repr, std, cov, closslb 0.004703062120825052 0.474365234375 0.00011649471707642078 0.004023144021630287 1.0209620086243376e-05\n",
            "0.0021293982461179787 0.016166151716292876 1.0\n",
            "repr, std, cov, closslb 0.008085309527814388 0.47412109375 0.00014100177213549614 0.011318384669721127 6.477760325651616e-05\n",
            "0.002106114798812179 0.015877907064260493 1.0\n",
            "repr, std, cov, closslb 0.009807603433728218 0.47412109375 0.00011187233030796051 0.007998836226761341 0.00010732938244473189\n",
            "0.002087254194319699 0.015424283845000076 1.0\n",
            "repr, std, cov, closslb 0.007130475714802742 0.474853515625 0.00010400405153632164 0.007792958058416843 7.586316496599466e-05\n",
            "0.0020914307899625325 0.015347393251260584 1.0\n",
            "repr, std, cov, closslb 0.003931755665689707 0.47509765625 0.00010825484059751034 9.512114047538489e-06 6.261948146857321e-05\n",
            "0.0021209019046024135 0.015270885959816682 1.0\n",
            "repr, std, cov, closslb 0.009029322303831577 0.4755859375 8.691754192113876e-05 0.011947618797421455 1.91243743756786e-05\n",
            "0.0021230228065070157 0.015270885959816682 1.0\n",
            "repr, std, cov, closslb 0.011135024949908257 0.475830078125 8.882349357008934e-05 0.007145493756979704 0.014575915411114693\n",
            "0.0021529390957832077 0.015470602984810889 1.0\n",
            "repr, std, cov, closslb 0.00814390555024147 0.476318359375 7.398403249680996e-05 0.003245530417189002 3.904497862095013e-05\n",
            "0.002165889067535431 0.015672931966320094 1.0\n",
            "repr, std, cov, closslb 0.007369134109467268 0.476318359375 8.887029252946377e-05 0.004547677002847195 0.015174759551882744\n",
            "0.0021529390957832077 0.015579222630380137 1.0\n",
            "repr, std, cov, closslb 0.00421097781509161 0.4765625 8.623884059488773e-05 3.3441515370213892e-06 0.00024585009668953717\n",
            "0.002144348825807484 0.015594801853010515 1.0\n",
            "repr, std, cov, closslb 0.0044670747593045235 0.4765625 0.00010093161836266518 1.3363622201723047e-05 0.020136065781116486\n",
            "0.0021336591720084604 0.015814553898070797 1.0\n",
            "repr, std, cov, closslb 0.004805444274097681 0.47705078125 7.966160774230957e-05 0.0041675264947116375 0.0005393393221311271\n",
            "0.0021357928311804687 0.01608556288530145 1.0\n",
            "repr, std, cov, closslb 0.004442967474460602 0.47705078125 8.105160668492317e-05 1.0450923582538962e-05 0.015524925664067268\n",
            "0.0021615637784148235 0.016608359702904776 1.0\n",
            "repr, std, cov, closslb 0.007810305804014206 0.478271484375 5.862233228981495e-05 0.01646190881729126 3.133998325210996e-05\n",
            "0.0021810958505605643 0.016909864859977284 1.0\n",
            "repr, std, cov, closslb 0.0032208338379859924 0.47802734375 5.945330485701561e-05 4.846042429562658e-06 4.794844790012576e-05\n",
            "0.0022162563410644126 0.01745945231289611 1.0\n",
            "repr, std, cov, closslb 0.005319793242961168 0.4765625 8.287513628602028e-05 0.0035061968956142664 0.0002701542980503291\n",
            "0.00221183046829735 0.01761721739279151 1.0\n",
            "repr, std, cov, closslb 0.005132652353495359 0.47607421875 9.251153096556664e-05 0.003716417122632265 0.0007386207580566406\n",
            "0.0022008044161533724 0.017476911765209 1.0\n",
            "repr, std, cov, closslb 0.005753261968493462 0.476318359375 8.438504301011562e-05 0.0073594204150140285 0.0003107034135609865\n",
            "0.002187645683580893 0.01733772354843505 1.0\n",
            "repr, std, cov, closslb 0.007691862527281046 0.47607421875 8.759461343288422e-05 0.007952465675771236 0.015889298170804977\n",
            "0.0021615637784148235 0.0168255685929866 1.0\n",
            "repr, std, cov, closslb 0.006894867867231369 0.474853515625 0.00010436400771141052 0.00846908614039421 0.012519343756139278\n",
            "0.002144348825807484 0.016558634108119464 1.0\n",
            "repr, std, cov, closslb 0.005816128104925156 0.474365234375 0.00012802775017917156 0.0034831417724490166 5.7387449487578124e-05\n",
            "0.0021103291345246013 0.01603740254940818 1.0\n",
            "repr, std, cov, closslb 0.008704456500709057 0.47412109375 0.0001291041262447834 0.0041627343744039536 0.015157882124185562\n",
            "0.002087254194319699 0.015751453512279048 1.0\n",
            "repr, std, cov, closslb 0.009677628055214882 0.47509765625 0.0001103885006159544 0.01209624856710434 0.0004972766619175673\n",
            "0.0020893414485140187 0.015579222630380137 1.0\n",
            "repr, std, cov, closslb 0.004049818031489849 0.475830078125 9.153969585895538e-05 1.1763767361117061e-05 0.00018649078265298158\n",
            "0.0020998090700749357 0.015532578282265919 1.0\n",
            "repr, std, cov, closslb 0.008174141868948936 0.475830078125 8.927006274461746e-05 0.008297137916088104 2.923355896200519e-05\n",
            "0.0021082209136109907 0.015517061221044876 1.0\n",
            "repr, std, cov, closslb 0.007882937788963318 0.476318359375 8.373125456273556e-05 0.003766822861507535 3.155656304443255e-05\n",
            "0.0021124394636591257 0.0156416330585699 1.0\n",
            "13\n",
            "repr, std, cov, closslb 0.008007057011127472 0.4765625 8.858880028128624e-05 0.0037569496780633926 0.015776582062244415\n",
            "0.0021400665526356607 0.015909678756296074 1.0\n",
            "repr, std, cov, closslb 0.016055990010499954 0.47705078125 7.894146256148815e-05 0.01150168664753437 0.00014605728210881352\n",
            "0.002146493174633291 0.016182317868009166 1.0\n",
            "repr, std, cov, closslb 0.006211403291672468 0.4765625 8.532754145562649e-05 0.0037735889200121164 0.0005211188108660281\n",
            "0.002165889067535431 0.016459629109585743 1.0\n",
            "repr, std, cov, closslb 0.0033857219386845827 0.477294921875 6.656302139163017e-05 1.857536699390039e-05 0.00020618829876184464\n",
            "0.002172393234571128 0.01662496806260768 1.0\n",
            "repr, std, cov, closslb 0.006975410971790552 0.47607421875 8.576642721891403e-05 0.003995739854872227 1.8871447537094355e-05\n",
            "0.0021810958505605643 0.016708259318934156 1.0\n",
            "repr, std, cov, closslb 0.0052196006290614605 0.475341796875 9.366869926452637e-05 1.611562584002968e-05 3.611044667195529e-05\n",
            "0.0021810958505605643 0.016724967578253088 1.0\n",
            "repr, std, cov, closslb 0.00421381089836359 0.47705078125 7.313443347811699e-05 1.1782483852584846e-05 3.0937073461245745e-05\n",
            "0.002165889067535431 0.0168255685929866 1.0\n",
            "repr, std, cov, closslb 0.0042417156510055065 0.47607421875 8.053658530116081e-05 1.185300607176032e-05 0.00021480926079675555\n",
            "0.002150788307475732 0.01667489285832465 1.0\n",
            "repr, std, cov, closslb 0.007842610590159893 0.475341796875 0.00010521290823817253 0.004027500282973051 0.0003993242571596056\n",
            "0.0021209019046024135 0.016198500185877172 1.0\n",
            "repr, std, cov, closslb 0.007877768948674202 0.474609375 0.00011253077536821365 0.0077996631152927876 9.355998190585524e-05\n",
            "0.0021019088791450103 0.01592558843505237 1.0\n",
            "repr, std, cov, closslb 0.004734016489237547 0.474853515625 0.0001123200636357069 9.79900414677104e-06 1.0977421879942995e-05\n",
            "0.002062369192894506 0.015439708128845073 1.0\n",
            "repr, std, cov, closslb 0.0037625539116561413 0.47509765625 0.0001126602292060852 1.528612119727768e-05 2.0467026843107305e-05\n",
            "0.0020520882104291126 0.015301443002622272 1.0\n",
            "repr, std, cov, closslb 0.00670885294675827 0.474853515625 0.00010259263217449188 0.0038725596386939287 0.004022886045277119\n",
            "0.0020479901820747814 0.015134132663889837 1.0\n",
            "repr, std, cov, closslb 0.0052132196724414825 0.47607421875 8.635269477963448e-05 0.003542487043887377 0.00031133327865973115\n",
            "0.0020706310521327797 0.015194760059893038 1.0\n",
            "repr, std, cov, closslb 0.006824650801718235 0.476318359375 8.090282790362835e-05 0.0034432499669492245 0.0005517940735444427\n",
            "0.002095615742973247 0.015332061190070516 1.0\n",
            "repr, std, cov, closslb 0.007542881183326244 0.476318359375 9.126123040914536e-05 0.007633230183273554 0.015201502479612827\n",
            "0.0021019088791450103 0.015579222630380137 1.0\n",
            "repr, std, cov, closslb 0.006979874335229397 0.477294921875 7.58906826376915e-05 0.008860021829605103 8.323097063112073e-06\n",
            "0.002093522220752495 0.015626007051518384 1.0\n",
            "repr, std, cov, closslb 0.00575958751142025 0.476318359375 9.12847463041544e-05 0.008734487928450108 0.0036457220558077097\n",
            "0.002093522220752495 0.015751453512279048 1.0\n",
            "repr, std, cov, closslb 0.003403372596949339 0.476806640625 8.191727101802826e-05 3.106861640844727e-06 3.497593934298493e-05\n",
            "0.0021124394636591257 0.016247144298133856 1.0\n",
            "repr, std, cov, closslb 0.013666031882166862 0.47705078125 7.184664718806744e-05 0.012094038538634777 5.0192316848551854e-05\n",
            "0.0021251458293135225 0.016542092016103363 1.0\n",
            "repr, std, cov, closslb 0.011723951436579227 0.476318359375 8.039036765694618e-05 0.007961226627230644 2.7892856451217085e-05\n",
            "0.0021230228065070157 0.016691567751182974 1.0\n",
            "repr, std, cov, closslb 0.010025152005255222 0.4755859375 9.112083353102207e-05 0.003926350735127926 5.060149123892188e-05\n",
            "0.0021145519031227846 0.01662496806260768 1.0\n",
            "repr, std, cov, closslb 0.023468155413866043 0.476318359375 8.323718793690205e-05 0.013204175978899002 0.015259889885783195\n",
            "0.0020893414485140187 0.016230913384749107 1.0\n",
            "repr, std, cov, closslb 0.00864194892346859 0.474853515625 0.0001013393048197031 0.008372465148568153 0.015351981855928898\n",
            "0.0020664959936494876 0.01598938640604146 1.0\n",
            "repr, std, cov, closslb 0.006907328963279724 0.473388671875 0.00013296795077621937 0.003778244601562619 0.015504980459809303\n",
            "0.0020439003374994455 0.015532578282265919 1.0\n",
            "repr, std, cov, closslb 0.01035714615136385 0.47314453125 0.00013669952750205994 0.008587541989982128 5.0542119424790144e-05\n",
            "0.00202965009308705 0.015286156845776498 1.0\n",
            "repr, std, cov, closslb 0.00497331703081727 0.473876953125 0.00014205812476575375 6.331027543637902e-05 2.2865977371111512e-05\n",
            "0.0020094647778354274 0.014923835451300797 1.0\n",
            "repr, std, cov, closslb 0.005080628674477339 0.474853515625 0.00011494406498968601 6.250977094168775e-06 0.00036230008117854595\n",
            "0.001991469690180329 0.014760653981153412 1.0\n",
            "repr, std, cov, closslb 0.0075924331322312355 0.476318359375 7.979408837854862e-05 0.003907223232090473 0.000486393750179559\n",
            "0.0020134857168558756 0.014983620395828966 1.0\n",
            "repr, std, cov, closslb 0.009435104206204414 0.476806640625 8.078268729150295e-05 0.008123640902340412 0.00011778454063460231\n",
            "0.00202965009308705 0.015240389939547652 1.0\n",
            "repr, std, cov, closslb 0.012158199213445187 0.47705078125 7.038144394755363e-05 0.003941686823964119 1.3348369066079613e-05\n",
            "0.0020706310521327797 0.01571999779668788 1.0\n",
            "repr, std, cov, closslb 0.0068181706592440605 0.4775390625 7.306598126888275e-05 0.007703901268541813 0.000699709402397275\n",
            "0.0020810049344206294 0.0160053757924475 1.0\n",
            "repr, std, cov, closslb 0.005459536798298359 0.47802734375 6.24938402324915e-05 0.00528675178065896 8.367975533474237e-05\n",
            "0.002093522220752495 0.016525566449653712 1.0\n",
            "repr, std, cov, closslb 0.005298266187310219 0.478759765625 5.514873191714287e-05 0.005494948476552963 0.015535886399447918\n",
            "0.00209771135871622 0.0168255685929866 1.0\n",
            "repr, std, cov, closslb 0.005613917019218206 0.477783203125 6.342772394418716e-05 0.0053080664947628975 0.00024638063041493297\n",
            "0.0021230228065070157 0.017355061271983482 1.0\n",
            "repr, std, cov, closslb 0.006623258348554373 0.477294921875 8.552731014788151e-05 0.004961606115102768 0.00014865721459500492\n",
            "0.0021019088791450103 0.017442010302593517 1.0\n",
            "14\n",
            "repr, std, cov, closslb 0.00838268268853426 0.476806640625 7.742177695035934e-05 0.0164377111941576 2.964387385873124e-05\n",
            "0.002095615742973247 0.017740908493325862 1.0\n",
            "repr, std, cov, closslb 0.005123425740748644 0.476806640625 9.32132825255394e-05 8.357403203262947e-06 0.0004257155233062804\n",
            "0.0020893414485140187 0.017794184459272222 1.0\n",
            "repr, std, cov, closslb 0.009402374736964703 0.475341796875 9.876280091702938e-05 0.008337889797985554 0.00011776444443967193\n",
            "0.002062369192894506 0.01726854568532818 1.0\n",
            "repr, std, cov, closslb 0.011800238862633705 0.474609375 0.00011332076974213123 0.031231673434376717 0.011400711722671986\n",
            "0.0020459442378369446 0.016960645201061657 1.0\n",
            "repr, std, cov, closslb 0.012268440797924995 0.474365234375 0.00011620507575571537 0.012106068432331085 0.0021139350719749928\n",
            "0.002015499202572731 0.01642675916449759 1.0\n",
            "repr, std, cov, closslb 0.005460432730615139 0.474853515625 0.00012136879377067089 7.436379746650346e-06 2.7492740628076717e-05\n",
            "0.0019835236863567063 0.01613386784673157 1.0\n",
            "repr, std, cov, closslb 0.00722790090367198 0.473876953125 0.00011961441487073898 0.003234936622902751 1.3208031305111945e-05\n",
            "0.0019481571931550092 0.01565727469162847 1.0\n",
            "repr, std, cov, closslb 0.00767419021576643 0.4755859375 9.329617023468018e-05 0.0081888847053051 4.003722278866917e-05\n",
            "0.0019384455614977567 0.015517061221044876 1.0\n",
            "repr, std, cov, closslb 0.00511957798153162 0.474365234375 0.00012035784311592579 3.5489341826178133e-05 0.00017009064322337508\n",
            "0.0019365090524453117 0.015316744445624893 1.0\n",
            "repr, std, cov, closslb 0.004902444779872894 0.4755859375 9.720632806420326e-05 1.0908856893365737e-05 0.00021968375949654728\n",
            "0.0019326418361312137 0.015240389939547652 1.0\n",
            "repr, std, cov, closslb 0.00723676010966301 0.47705078125 7.011904381215572e-05 0.0031856903806328773 8.934239303926006e-05\n",
            "0.001955961518665364 0.015579222630380137 1.0\n",
            "repr, std, cov, closslb 0.006224978249520063 0.4775390625 6.266101263463497e-05 0.00859067216515541 0.01573815383017063\n",
            "0.001959875397664213 0.015862045019241253 1.0\n",
            "repr, std, cov, closslb 0.004758510738611221 0.4775390625 6.539258174598217e-05 6.861872861918528e-06 0.00010697346442611888\n",
            "0.001981542144212494 0.016328542653620194 1.0\n",
            "repr, std, cov, closslb 0.01825314573943615 0.47705078125 7.734051905572414e-05 0.007891422137618065 0.030910305678844452\n",
            "0.0020054518686462666 0.016608359702904776 1.0\n",
            "repr, std, cov, closslb 0.008841410279273987 0.4755859375 9.73318237811327e-05 0.00382172386161983 0.00016722368309274316\n",
            "0.0020054518686462666 0.016658234623700953 1.0\n",
            "repr, std, cov, closslb 0.005707575939595699 0.4755859375 8.759740740060806e-05 0.0037292016204446554 0.0002870578900910914\n",
            "0.001989480209970359 0.01641034881568191 1.0\n",
            "repr, std, cov, closslb 0.004494945518672466 0.47509765625 9.734160266816616e-05 8.542571777070407e-06 4.8986636102199554e-05\n",
            "0.0019657609054432733 0.01594151402348742 1.0\n",
            "repr, std, cov, closslb 0.0046644145622849464 0.47509765625 0.00010064151138067245 6.988427685428178e-06 0.015466838143765926\n",
            "0.0019462109821728366 0.015704293503184696 1.0\n",
            "repr, std, cov, closslb 0.004734320100396872 0.475341796875 9.671272709965706e-05 2.822830356308259e-05 2.6102272386197e-05\n",
            "0.0019115097794881785 0.015255630329487197 1.0\n",
            "repr, std, cov, closslb 0.005290077067911625 0.475341796875 0.00010538939386606216 7.060220013954677e-06 0.015510905534029007\n",
            "0.001903882817304622 0.015134132663889837 1.0\n",
            "repr, std, cov, closslb 0.01290818303823471 0.475341796875 9.128800593316555e-05 0.017699260264635086 6.988784298300743e-05\n",
            "0.0019191672953127578 0.015013602620241017 1.0\n",
            "repr, std, cov, closslb 0.004172603599727154 0.475830078125 8.197152055799961e-05 7.2118300522561185e-06 0.00030668132239952683\n",
            "0.0019134212892676665 0.014923835451300797 1.0\n",
            "repr, std, cov, closslb 0.004888200666755438 0.4755859375 9.56172589212656e-05 2.829913228197256e-06 0.015578064136207104\n",
            "0.0019365090524453117 0.014923835451300797 1.0\n",
            "repr, std, cov, closslb 0.0070625189691782 0.4755859375 8.604861795902252e-05 0.004630677402019501 3.116598236374557e-05\n",
            "0.0019442667154573794 0.014953698046038846 1.0\n",
            "repr, std, cov, closslb 0.004565567709505558 0.47607421875 8.462811820209026e-05 7.758129868307151e-06 0.015453377738595009\n",
            "0.0019696943930150646 0.015043644839084117 1.0\n",
            "repr, std, cov, closslb 0.013003796339035034 0.4775390625 6.6002132371068e-05 0.007965805009007454 0.00176168920006603\n",
            "0.001975609387246983 0.015255630329487197 1.0\n",
            "repr, std, cov, closslb 0.006469636224210262 0.476318359375 7.367739453911781e-05 0.004002557601779699 4.2729203414637595e-05\n",
            "0.0020034484202260407 0.015610396654863523 1.0\n",
            "repr, std, cov, closslb 0.016721323132514954 0.47705078125 6.657582707703114e-05 0.015770060941576958 4.514799911703449e-06\n",
            "0.0020114742426132625 0.015862045019241253 1.0\n",
            "repr, std, cov, closslb 0.004627775400876999 0.476318359375 7.941504009068012e-05 2.0053372281836346e-05 0.015687741339206696\n",
            "0.00202965009308705 0.016214698686063046 1.0\n",
            "repr, std, cov, closslb 0.004502829164266586 0.475341796875 9.191595017910004e-05 1.1070061418649857e-06 4.549890218186192e-05\n",
            "0.0020054518686462666 0.0160053757924475 1.0\n",
            "repr, std, cov, closslb 0.007190226577222347 0.4755859375 8.371565490961075e-05 0.007470162585377693 0.01534444559365511\n",
            "0.0019696943930150646 0.015532578282265919 1.0\n",
            "repr, std, cov, closslb 0.006059242412447929 0.4755859375 8.94379336386919e-05 0.008349433541297913 0.00023138473625294864\n",
            "0.0019481571931550092 0.015270885959816682 1.0\n",
            "repr, std, cov, closslb 0.00504140742123127 0.474609375 0.00010248785838484764 7.103843017830513e-06 0.00012686310219578445\n",
            "0.001915334710556934 0.014834605005279342 1.0\n",
            "repr, std, cov, closslb 0.005831106565892696 0.47509765625 9.419862180948257e-05 0.004182965494692326 5.7993947848444805e-06\n",
            "0.0019000807557124418 0.01458467211159607 1.0\n",
            "repr, std, cov, closslb 0.007497201208025217 0.475341796875 8.631264790892601e-05 0.010839474387466908 6.572877464350313e-05\n",
            "0.0018662020611489244 0.01422475296397433 1.0\n",
            "repr, std, cov, closslb 0.009968566708266735 0.475830078125 7.632444612681866e-05 0.007514284923672676 3.4837306884583086e-05\n",
            "0.0018736780740725607 0.014182163911565739 1.0\n",
            "15\n",
            "repr, std, cov, closslb 0.003816916374489665 0.475830078125 8.156918920576572e-05 2.96598841487139e-06 0.0003218226775061339\n",
            "0.001875551752146633 0.014153842073576514 1.0\n",
            "repr, std, cov, closslb 0.006310179363936186 0.475341796875 8.40318389236927e-05 0.008863815106451511 4.8534471716266125e-05\n",
            "0.0018811840359338806 0.014153842073576514 1.0\n",
            "repr, std, cov, closslb 0.010680870153009892 0.4755859375 9.539932943880558e-05 0.010894110426306725 8.103821528493427e-06\n",
            "0.0018774273038987795 0.01408328467644426 1.0\n",
            "repr, std, cov, closslb 0.0038416236639022827 0.47705078125 6.923847831785679e-05 9.009744985633006e-07 3.212854790035635e-05\n",
            "0.001879304731202678 0.014253216694655239 1.0\n",
            "repr, std, cov, closslb 0.007058009505271912 0.476806640625 7.540266960859299e-05 0.0037985220551490784 0.000129231862956658\n",
            "0.0018981825731393027 0.014657741464794819 1.0\n",
            "repr, std, cov, closslb 0.005723055452108383 0.4765625 7.92178325355053e-05 0.004467722959816456 0.00010619011300150305\n",
            "0.0019000807557124418 0.014864289049894903 1.0\n",
            "repr, std, cov, closslb 0.004584928508847952 0.47705078125 7.458124309778214e-05 0.003977172076702118 0.017537759616971016\n",
            "0.0018868332334749734 0.015103909740499102 1.0\n",
            "repr, std, cov, closslb 0.008394559845328331 0.477783203125 6.306590512394905e-05 0.011868594214320183 1.5248423551383894e-05\n",
            "0.0018887200667084482 0.015301443002622272 1.0\n",
            "repr, std, cov, closslb 0.0043562669306993484 0.47705078125 7.218052633106709e-05 1.7418684592485079e-06 2.8124917662353255e-05\n",
            "0.0018811840359338806 0.015194760059893038 1.0\n",
            "repr, std, cov, closslb 0.007477186620235443 0.47509765625 9.445403702557087e-05 0.007640114985406399 0.00018810128676705062\n",
            "0.0018624752481773222 0.015058688483923199 1.0\n",
            "repr, std, cov, closslb 0.00882607139647007 0.47607421875 7.614330388605595e-05 0.00786534696817398 0.01516360230743885\n",
            "0.001855043934752673 0.014983620395828966 1.0\n",
            "repr, std, cov, closslb 0.009602902457118034 0.475830078125 7.714261300861835e-05 0.011413158848881721 7.035513408482075e-05\n",
            "0.0018402701428617307 0.014923835451300797 1.0\n",
            "repr, std, cov, closslb 0.006217891350388527 0.474609375 0.00010834215208888054 0.0036066193133592606 0.015543056651949883\n",
            "0.0018002460865170588 0.014454063973566529 1.0\n",
            "repr, std, cov, closslb 0.004658934194594622 0.474609375 0.00010388810187578201 5.342552412912482e-06 1.862117278506048e-05\n",
            "0.0017805616827333574 0.014238977716938302 1.0\n",
            "repr, std, cov, closslb 0.009305886924266815 0.473388671875 0.00014364742673933506 0.008802367374300957 9.43593040574342e-05\n",
            "0.0017558197852597672 0.013818359463458977 1.0\n",
            "repr, std, cov, closslb 0.012500625103712082 0.475341796875 8.560158312320709e-05 0.011548419483006 4.100882506463677e-05\n",
            "0.0017453216406585837 0.013653611970854669 1.0\n",
            "repr, std, cov, closslb 0.005819081328809261 0.47509765625 0.0001119344960898161 3.147128882119432e-05 3.2878899219213054e-05\n",
            "0.0017245132831363392 0.013343316092145834 1.0\n",
            "repr, std, cov, closslb 0.004498030059039593 0.47607421875 8.388538844883442e-05 4.323449502408039e-06 0.00010142817336600274\n",
            "0.001736621151315597 0.013396769469797572 1.0\n",
            "repr, std, cov, closslb 0.005264208186417818 0.476318359375 8.149328641593456e-05 4.445869126357138e-05 0.015385067090392113\n",
            "0.0017593331806500716 0.013790764144406024 1.0\n",
            "repr, std, cov, closslb 0.011816505342721939 0.47705078125 7.171859033405781e-05 0.00821659341454506 0.01509154587984085\n",
            "0.0017770058939395848 0.014041119181501098 1.0\n",
            "repr, std, cov, closslb 0.010427611880004406 0.4775390625 6.257346831262112e-05 0.0037250127643346786 0.0008502979762852192\n",
            "0.0018074578795424297 0.014497469542133209 1.0\n",
            "repr, std, cov, closslb 0.007188601419329643 0.47802734375 5.437619984149933e-05 0.004301972221583128 0.0001643179712118581\n",
            "0.0018219682527436593 0.014760653981153412 1.0\n",
            "repr, std, cov, closslb 0.006569156888872385 0.4775390625 6.541982293128967e-05 0.003619243623688817 4.714643000625074e-05\n",
            "0.001845796475941014 0.01522516477477288 1.0\n",
            "repr, std, cov, closslb 0.005673075094819069 0.47802734375 5.796155892312527e-05 5.0795629249478225e-06 1.1146364158776123e-05\n",
            "0.0018568989786874254 0.015486073587795699 1.0\n",
            "repr, std, cov, closslb 0.0072335428558290005 0.476806640625 7.671071216464043e-05 0.0037565261591225863 0.030393846333026886\n",
            "0.0018439525234175966 0.015610396654863523 1.0\n",
            "repr, std, cov, closslb 0.0049714515917003155 0.4765625 7.975543849170208e-05 1.1523893590492662e-05 0.015278183855116367\n",
            "0.0018274396252286162 0.0156416330585699 1.0\n",
            "repr, std, cov, closslb 0.009229142218828201 0.4765625 8.537177927792072e-05 0.0033412256743758917 1.9710223568836227e-05\n",
            "0.0018146985630395148 0.015704293503184696 1.0\n",
            "repr, std, cov, closslb 0.01836440898478031 0.4765625 8.060946129262447e-05 0.011319282464683056 9.018841956276447e-05\n",
            "0.0018074578795424297 0.015798755142927872 1.0\n",
            "repr, std, cov, closslb 0.006070038303732872 0.4755859375 9.230640716850758e-05 0.003857234725728631 0.015117357484996319\n",
            "0.0017787828998335241 0.015439708128845073 1.0\n",
            "repr, std, cov, closslb 0.013958624564111233 0.4755859375 9.776931256055832e-05 0.00401562312617898 1.3746737749897875e-05\n",
            "0.0017628536063445518 0.01520995481995293 1.0\n",
            "repr, std, cov, closslb 0.005111201666295528 0.476318359375 8.722557686269283e-05 0.00217297300696373 9.44423572946107e-06\n",
            "0.001752313406134093 0.015362740644511843 1.0\n",
            "repr, std, cov, closslb 0.007352420594543219 0.4765625 7.777591235935688e-05 0.003433849662542343 7.380489114439115e-05\n",
            "0.0017575756050450268 0.015501559661383493 1.0\n",
            "repr, std, cov, closslb 0.009439300745725632 0.47607421875 8.636410348117352e-05 0.010587173514068127 0.015411843545734882\n",
            "0.0017505628432908024 0.015362740644511843 1.0\n",
            "repr, std, cov, closslb 0.004350421018898487 0.47607421875 7.846439257264137e-05 2.911333012889372e-06 0.00032562040723860264\n",
            "0.0017383577724669125 0.015316744445624893 1.0\n",
            "repr, std, cov, closslb 0.004263139329850674 0.47607421875 8.557690307497978e-05 4.7154876483546104e-06 0.022695060819387436\n",
            "0.001736621151315597 0.015408874970030047 1.0\n",
            "repr, std, cov, closslb 0.010667583905160427 0.476318359375 8.527934551239014e-05 0.007993189617991447 8.241912291850895e-05\n",
            "0.0017331531119386084 0.015347393251260584 1.0\n",
            "16\n",
            "repr, std, cov, closslb 0.0053880647756159306 0.476318359375 8.12907237559557e-05 0.0037070591934025288 0.015328511595726013\n",
            "0.0017056569634088024 0.015194760059893038 1.0\n",
            "repr, std, cov, closslb 0.006556546315550804 0.476318359375 9.069615043699741e-05 0.012751979753375053 0.00014865826233290136\n",
            "0.00168869383087931 0.015134132663889837 1.0\n",
            "repr, std, cov, closslb 0.00280277943238616 0.4765625 8.611707016825676e-05 1.781993341865018e-05 0.015413044020533562\n",
            "0.001687006824055255 0.015301443002622272 1.0\n",
            "repr, std, cov, closslb 0.003465902991592884 0.475830078125 8.905376307666302e-05 3.916399691661354e-06 7.757596904411912e-06\n",
            "0.0016802756331460898 0.015270885959816682 1.0\n",
            "repr, std, cov, closslb 0.011787662282586098 0.475341796875 9.016669355332851e-05 0.010057766921818256 6.177891191327944e-05\n",
            "0.001663564923511856 0.014968651744084883 1.0\n",
            "repr, std, cov, closslb 0.0045097870752215385 0.4755859375 8.697621524333954e-05 0.004452565219253302 0.00029150195769034326\n",
            "0.001647020405549376 0.014775414635134564 1.0\n",
            "repr, std, cov, closslb 0.00593904685229063 0.474853515625 9.421282447874546e-05 0.0074781146831810474 0.015513592399656773\n",
            "0.0016079817684289234 0.014324625452898901 1.0\n",
            "repr, std, cov, closslb 0.0048691825941205025 0.47509765625 0.00010743527673184872 1.229477311426308e-05 5.006682113162242e-05\n",
            "0.001595175609196708 0.014097367961120702 1.0\n",
            "repr, std, cov, closslb 0.006784357130527496 0.474365234375 0.00011476804502308369 0.0040553598664700985 0.0003085578791797161\n",
            "0.001574582764346066 0.013708308395038006 1.0\n",
            "repr, std, cov, closslb 0.00573734613135457 0.475341796875 9.94314905256033e-05 0.0045276666060090065 0.00028124765958637\n",
            "0.0015777335044575222 0.013722016703433043 1.0\n",
            "repr, std, cov, closslb 0.006974962539970875 0.47607421875 8.835922926664352e-05 0.007532508112490177 6.275237683439627e-05\n",
            "0.0015919900371324065 0.013957166545377887 1.0\n",
            "repr, std, cov, closslb 0.008800867944955826 0.477294921875 6.010965444147587e-05 0.0133218290284276 0.000321870029438287\n",
            "0.001595175609196708 0.014182163911565739 1.0\n",
            "repr, std, cov, closslb 0.00935647077858448 0.47705078125 7.432978600263596e-05 0.007377776317298412 0.0004176549264229834\n",
            "0.0016225116269617226 0.014570102009586486 1.0\n",
            "repr, std, cov, closslb 0.00562808383256197 0.478271484375 6.289267912507057e-05 0.007952659390866756 9.303193655796349e-05\n",
            "0.0016355372412772877 0.014834605005279342 1.0\n",
            "repr, std, cov, closslb 0.003403180744498968 0.47705078125 6.72058667987585e-05 1.3368176951189525e-05 0.016122842207551003\n",
            "0.0016486674259549253 0.015194760059893038 1.0\n",
            "repr, std, cov, closslb 0.00494823232293129 0.47705078125 6.67809508740902e-05 0.00354950362816453 1.923123636515811e-05\n",
            "0.0016585841935201314 0.015455147836973916 1.0\n",
            "repr, std, cov, closslb 0.004127321764826775 0.476318359375 8.062086999416351e-05 6.656546702288324e-06 2.6059466108563356e-05\n",
            "0.001663564923511856 0.015688604898286412 1.0\n",
            "repr, std, cov, closslb 0.007232195232063532 0.47607421875 7.935147732496262e-05 0.007752463687211275 0.00010791582462843508\n",
            "0.0016519664094742606 0.015610396654863523 1.0\n",
            "repr, std, cov, closslb 0.003791121067479253 0.4765625 8.531310595571995e-05 9.089786544791423e-06 0.00015297610661946237\n",
            "0.001624134138588684 0.01520995481995293 1.0\n",
            "repr, std, cov, closslb 0.007468502968549728 0.475830078125 0.00010180729441344738 0.007778759114444256 0.015343941748142242\n",
            "0.001614423349826784 0.01520995481995293 1.0\n",
            "repr, std, cov, closslb 0.005340545438230038 0.47607421875 8.258293382823467e-05 0.00477239303290844 3.642644514911808e-05\n",
            "0.0016257582727272726 0.01522516477477288 1.0\n",
            "repr, std, cov, closslb 0.007369339466094971 0.476318359375 8.634594269096851e-05 0.004636822268366814 6.421893885999452e-06\n",
            "0.0016306404264460302 0.015316744445624893 1.0\n",
            "repr, std, cov, closslb 0.0075135123915970325 0.47607421875 7.557310163974762e-05 0.004437153693288565 4.172373883193359e-05\n",
            "0.0016225116269617226 0.015134132663889837 1.0\n",
            "repr, std, cov, closslb 0.005899225827306509 0.475341796875 8.483626879751682e-05 0.004821499809622765 0.00010468234540894628\n",
            "0.0016192714647607367 0.015028616222861257 1.0\n",
            "repr, std, cov, closslb 0.00991485919803381 0.475341796875 8.50246287882328e-05 0.011380380019545555 0.0001416954619344324\n",
            "0.0016160377731766107 0.014938759286752095 1.0\n",
            "repr, std, cov, closslb 0.008809042163193226 0.475341796875 8.582230657339096e-05 0.003912169486284256 0.00024208100512623787\n",
            "0.0016208907362254973 0.01507374717240712 1.0\n",
            "repr, std, cov, closslb 0.0046806917525827885 0.474853515625 0.00010396796278655529 7.029049811535515e-06 0.00020910389139316976\n",
            "0.0016015658890694469 0.014701758677071335 1.0\n",
            "repr, std, cov, closslb 0.011190235614776611 0.47607421875 7.578195072710514e-05 0.008691279217600822 3.273642869316973e-05\n",
            "0.0016095897501973522 0.014731176896184152 1.0\n",
            "repr, std, cov, closslb 0.00458587147295475 0.47607421875 7.937336340546608e-05 0.00414931308478117 1.157498081738595e-05\n",
            "0.0016128105392874967 0.014672399206259613 1.0\n",
            "repr, std, cov, closslb 0.0034793978556990623 0.47607421875 7.580616511404514e-05 2.6313168746128213e-06 3.1949577532941476e-05\n",
            "0.0016047706224134744 0.014628469896531862 1.0\n",
            "repr, std, cov, closslb 0.004463842138648033 0.475830078125 8.326978422701359e-05 0.0028481464833021164 0.00011260069004492834\n",
            "0.0015872236030651788 0.01428173738126124 1.0\n",
            "repr, std, cov, closslb 0.0185893215239048 0.474365234375 0.00011143647134304047 0.014938632026314735 0.015233351849019527\n",
            "0.0015808905491999413 0.01413970237120531 1.0\n",
            "repr, std, cov, closslb 0.003949921578168869 0.4775390625 7.765158079564571e-05 0.006347483955323696 0.00028269257745705545\n",
            "0.0015856379651000788 0.0142960191186425 1.0\n",
            "repr, std, cov, closslb 0.0036318376660346985 0.476806640625 7.318775169551373e-05 3.753350256374688e-06 0.00016250440967269242\n",
            "0.001595175609196708 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.005129627883434296 0.47705078125 6.61343801766634e-05 0.00357233383692801 0.01547689363360405\n",
            "0.0016160377731766107 0.014938759286752095 1.0\n",
            "repr, std, cov, closslb 0.01501559279859066 0.476318359375 7.166084833443165e-05 0.0034721866250038147 0.015353446826338768\n",
            "0.0016257582727272726 0.015179580479413627 1.0\n",
            "17\n",
            "repr, std, cov, closslb 0.003996188752353191 0.47607421875 8.354173041880131e-05 7.468978310498642e-06 0.015121245756745338\n",
            "0.0016322710668724761 0.015455147836973916 1.0\n",
            "repr, std, cov, closslb 0.004861857742071152 0.4755859375 8.689495734870434e-05 6.119752924860222e-06 0.0003582841600291431\n",
            "0.0016257582727272726 0.015517061221044876 1.0\n",
            "repr, std, cov, closslb 0.0040255761705338955 0.47607421875 8.121924474835396e-05 1.167259324574843e-05 8.118022378766909e-05\n",
            "0.0016095897501973522 0.015286156845776498 1.0\n",
            "repr, std, cov, closslb 0.046746835112571716 0.47412109375 0.0001351390965282917 0.007447180338203907 0.014797342009842396\n",
            "0.0015856379651000788 0.015013602620241017 1.0\n",
            "repr, std, cov, closslb 0.0046074953861534595 0.475830078125 8.557643741369247e-05 1.9960229110438377e-05 0.016011638566851616\n",
            "0.0015558100176238554 0.014628469896531862 1.0\n",
            "repr, std, cov, closslb 0.005269779358059168 0.47607421875 8.815666660666466e-05 1.023303502734052e-05 0.0004418882599566132\n",
            "0.001549602304591703 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.009295803494751453 0.475341796875 8.711451664566994e-05 0.011857477948069572 0.00030174420680850744\n",
            "0.0015449627798189442 0.014396391969735809 1.0\n",
            "repr, std, cov, closslb 0.009928496554493904 0.476318359375 7.455260492861271e-05 0.007683837786316872 0.00015691887529101223\n",
            "0.001549602304591703 0.01428173738126124 1.0\n",
            "repr, std, cov, closslb 0.005450563505291939 0.47509765625 9.278464131057262e-05 2.8026337531628087e-05 0.015363036654889584\n",
            "0.0015326585113535508 0.013971123711923264 1.0\n",
            "repr, std, cov, closslb 0.009846007451415062 0.476806640625 7.785414345562458e-05 0.01771390065550804 0.015424301847815514\n",
            "0.0015311273839695814 0.013929294028027806 1.0\n",
            "repr, std, cov, closslb 0.011701101437211037 0.4755859375 8.699065074324608e-05 0.008557388558983803 1.535625233373139e-05\n",
            "0.001526543173293638 0.013846010000745356 1.0\n",
            "repr, std, cov, closslb 0.013282546773552895 0.4765625 7.893331348896027e-05 0.01167445257306099 0.00015060434816405177\n",
            "0.0015311273839695814 0.013929294028027806 1.0\n",
            "repr, std, cov, closslb 0.011100555770099163 0.47705078125 7.002800703048706e-05 0.007674781139940023 0.015185357071459293\n",
            "0.0015589231934691203 0.014367642317458577 1.0\n",
            "repr, std, cov, closslb 0.00533195398747921 0.475830078125 8.403672836720943e-05 4.99799625686137e-06 0.030769895762205124\n",
            "0.0015620425987792517 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.008397744968533516 0.476806640625 6.489013321697712e-05 0.008180635049939156 1.6194280760828406e-05\n",
            "0.001574582764346066 0.014968651744084883 1.0\n",
            "repr, std, cov, closslb 0.014100218191742897 0.476318359375 7.842783816158772e-05 0.0032280208542943 6.40518483123742e-05\n",
            "0.0015604821166625893 0.01484943961028462 1.0\n",
            "repr, std, cov, closslb 0.006849708966910839 0.475341796875 9.066029451787472e-05 0.007734835147857666 0.0003398972621653229\n",
            "0.0015311273839695814 0.01451196701167534 1.0\n",
            "repr, std, cov, closslb 0.0063454220071434975 0.474853515625 0.0001108699943870306 5.226454504736466e-06 0.00020470900926738977\n",
            "0.0015189333022524252 0.014253216694655239 1.0\n",
            "repr, std, cov, closslb 0.011547831818461418 0.475341796875 9.824358858168125e-05 0.007859318517148495 4.131072637392208e-05\n",
            "0.001503827177479204 0.013846010000745356 1.0\n",
            "repr, std, cov, closslb 0.008990805596113205 0.4765625 7.090228609740734e-05 0.0036127923522144556 2.6982204872183502e-05\n",
            "0.001514385600778901 0.014027092089411688 1.0\n",
            "repr, std, cov, closslb 0.007917745038866997 0.477294921875 6.663519889116287e-05 0.0041261096484959126 3.503581683617085e-05\n",
            "0.0015311273839695816 0.014468518037540094 1.0\n",
            "repr, std, cov, closslb 0.007221357896924019 0.476318359375 7.224618457257748e-05 7.758033461868763e-06 0.0001243246515514329\n",
            "0.001535725361034769 0.014716460435748405 1.0\n",
            "repr, std, cov, closslb 0.00681235920637846 0.475830078125 8.000270463526249e-05 5.106858225190081e-06 0.0005583651945926249\n",
            "0.0015280697164669315 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.010759902186691761 0.47509765625 9.734020568430424e-05 0.007949537597596645 0.0001221510028699413\n",
            "0.001514385600778901 0.014310315137761142 1.0\n",
            "repr, std, cov, closslb 0.014143682084977627 0.474853515625 9.469455108046532e-05 0.0035060264635831118 2.5726416424731724e-05\n",
            "0.001499324703894086 0.013887589582623601 1.0\n",
            "repr, std, cov, closslb 0.006113619543612003 0.474365234375 0.00010581687092781067 0.004279243294149637 0.01578652113676071\n",
            "0.0014888712864294293 0.013708308395038006 1.0\n",
            "repr, std, cov, closslb 0.008770415559411049 0.47509765625 9.90796834230423e-05 0.0038167356979101896 0.00014104429283179343\n",
            "0.0014858980045223803 0.013450436981894048 1.0\n",
            "repr, std, cov, closslb 0.011379681527614594 0.4755859375 9.173457510769367e-05 0.00401022145524621 0.0002860593085642904\n",
            "0.0014918505178735744 0.01338338608371386 1.0\n",
            "repr, std, cov, closslb 0.00955707672983408 0.475830078125 7.281079888343811e-05 0.004036662168800831 0.0003709243901539594\n",
            "0.0015023248526265776 0.013558417844151438 1.0\n",
            "repr, std, cov, closslb 0.007237118668854237 0.47705078125 6.235204637050629e-05 0.003800405655056238 6.626415415666997e-05\n",
            "0.0015083431719970007 0.013694613781256752 1.0\n",
            "repr, std, cov, closslb 0.008673722855746746 0.476806640625 6.802380084991455e-05 0.004127865191549063 0.01564510352909565\n",
            "0.0015387983474821993 0.014111465329081821 1.0\n",
            "repr, std, cov, closslb 0.017480527982115746 0.47802734375 5.490216426551342e-05 0.013094025664031506 6.602864596061409e-05\n",
            "0.001552703058803191 0.014353289028430149 1.0\n",
            "repr, std, cov, closslb 0.006130136549472809 0.475830078125 8.439435623586178e-05 3.367702220202773e-06 0.00045261846389621496\n",
            "0.0015403371458296814 0.014570102009586486 1.0\n",
            "repr, std, cov, closslb 0.00611344538629055 0.47705078125 6.832112558186054e-05 0.004491378553211689 0.00017106879386119545\n",
            "0.0015480542503413619 0.014834605005279342 1.0\n",
            "repr, std, cov, closslb 0.006170632783323526 0.47607421875 7.633166387677193e-05 3.583279612939805e-05 0.01546480506658554\n",
            "0.0015372610863958038 0.014864289049894903 1.0\n",
            "repr, std, cov, closslb 0.010007141157984734 0.47509765625 9.698374196887016e-05 0.012429659254848957 4.4957196223549545e-05\n",
            "0.0015265431732936381 0.014701758677071335 1.0\n",
            "18\n",
            "repr, std, cov, closslb 0.006700244732201099 0.474365234375 9.994208812713623e-05 5.301584315020591e-05 9.723229595692828e-05\n",
            "0.0014933423683914477 0.014267469911349893 1.0\n",
            "repr, std, cov, closslb 0.007149267476052046 0.474853515625 9.310804307460785e-05 0.004408358596265316 0.015410520136356354\n",
            "0.0014829306602711782 0.014027092089411688 1.0\n",
            "repr, std, cov, closslb 0.005523249506950378 0.47509765625 8.332217112183571e-05 3.6892397474730387e-06 0.0001363812480121851\n",
            "0.0014535811918597802 0.013639971998855815 1.0\n",
            "repr, std, cov, closslb 0.012580329552292824 0.475830078125 7.167644798755646e-05 0.007859531790018082 0.00010254188964609057\n",
            "0.0014608636481740782 0.013585548238257581 1.0\n",
            "repr, std, cov, closslb 0.011602554470300674 0.475341796875 8.256477303802967e-05 0.007688845507800579 0.00024231064890045673\n",
            "0.0014667158737935782 0.013396769469797572 1.0\n",
            "repr, std, cov, closslb 0.009901221841573715 0.475830078125 7.569277659058571e-05 0.011290103197097778 0.01567673124372959\n",
            "0.001469650772257039 0.013329986106039795 1.0\n",
            "repr, std, cov, closslb 0.0064578731544315815 0.475341796875 9.705103002488613e-05 2.3747987142996863e-05 0.015616422519087791\n",
            "0.001472591543452325 0.013263535659683105 1.0\n",
            "repr, std, cov, closslb 0.009540388360619545 0.47607421875 7.37910158932209e-05 0.0041113500483334064 0.01588348113000393\n",
            "0.0014829306602711782 0.013423576405506633 1.0\n",
            "repr, std, cov, closslb 0.01219115313142538 0.47607421875 7.469533011317253e-05 0.007939610630273819 2.9093800549162552e-05\n",
            "0.0014873839025269025 0.013450436981894048 1.0\n",
            "repr, std, cov, closslb 0.006802094168961048 0.47509765625 8.475454524159431e-05 2.2770827854401432e-05 0.00029785727383568883\n",
            "0.0014873839025269025 0.013436999981912138 1.0\n",
            "repr, std, cov, closslb 0.010075727477669716 0.475830078125 8.215964771807194e-05 0.004283485468477011 0.00046206964179873466\n",
            "0.0014814492110601183 0.013290075994538127 1.0\n",
            "repr, std, cov, closslb 0.010955322533845901 0.475341796875 7.634703069925308e-05 0.007003058213740587 3.160681444569491e-05\n",
            "0.0014799692418183002 0.013263535659683105 1.0\n",
            "repr, std, cov, closslb 0.00862039439380169 0.4755859375 7.84415751695633e-05 0.00673912838101387 7.3769006121438e-05\n",
            "0.0014711204230292959 0.013001029980020283 1.0\n",
            "repr, std, cov, closslb 0.005658344365656376 0.475341796875 8.273404091596603e-05 7.624397312611109e-06 1.5967236322467215e-05\n",
            "0.001465250623170408 0.012884603617798085 1.0\n",
            "repr, std, cov, closslb 0.006313202437013388 0.47607421875 7.424573414027691e-05 6.960358405194711e-06 6.217608461156487e-05\n",
            "0.0014681825896673717 0.012833193792121245 1.0\n",
            "repr, std, cov, closslb 0.009379212744534016 0.475830078125 7.677450776100159e-05 0.008135330863296986 0.015262226574122906\n",
            "0.001472591543452325 0.01279477108176793 1.0\n",
            "repr, std, cov, closslb 0.005564509425312281 0.47607421875 6.988877430558205e-05 1.063192030414939e-05 0.0002351350849494338\n",
            "0.0014784907510672332 0.012949155610833717 1.0\n",
            "repr, std, cov, closslb 0.020242800936102867 0.476318359375 6.679142825305462e-05 0.014529896900057793 0.00012196079478599131\n",
            "0.0014829306602711782 0.013066165270295495 1.0\n",
            "repr, std, cov, closslb 0.006013244856148958 0.475830078125 8.915644139051437e-05 1.4169053429213818e-05 0.015675636008381844\n",
            "0.001469650772257039 0.012807565852849695 1.0\n",
            "repr, std, cov, closslb 0.013757232576608658 0.47607421875 6.77737407386303e-05 0.0037639064248651266 0.015310476534068584\n",
            "0.0014814492110601183 0.01292329609534693 1.0\n",
            "repr, std, cov, closslb 0.0062314365059137344 0.476318359375 7.218285463750362e-05 6.671959454251919e-06 0.0005614492110908031\n",
            "0.0014918505178735744 0.013171061177706035 1.0\n",
            "repr, std, cov, closslb 0.005022276658564806 0.4765625 6.19164202362299e-05 1.386496933264425e-05 5.584388418355957e-05\n",
            "0.0014844135909314491 0.013197416471122622 1.0\n",
            "repr, std, cov, closslb 0.007508421316742897 0.476806640625 6.605708040297031e-05 0.0038979779928922653 7.133275357773528e-05\n",
            "0.0014681825896673717 0.012988041938082203 1.0\n",
            "repr, std, cov, closslb 0.00981822144240141 0.475830078125 8.574896492063999e-05 0.008055747486650944 8.86415655259043e-05\n",
            "0.001459404243930148 0.012936219391442277 1.0\n",
            "repr, std, cov, closslb 0.004745667800307274 0.477294921875 6.227637641131878e-05 2.499368565622717e-05 0.00024337309878319502\n",
            "0.0014770137373299034 0.013343316092145834 1.0\n",
            "repr, std, cov, closslb 0.005287409760057926 0.47802734375 5.0372909754514694e-05 9.835381206357852e-06 0.00015074567636474967\n",
            "0.0014829306602711782 0.013585548238257581 1.0\n",
            "repr, std, cov, closslb 0.015759117901325226 0.477783203125 6.594182923436165e-05 0.007607719860970974 0.015740960836410522\n",
            "0.0014933423683914477 0.013929294028027806 1.0\n",
            "repr, std, cov, closslb 0.03496825695037842 0.47705078125 7.852073758840561e-05 0.012768793851137161 2.287000825162977e-05\n",
            "0.0014873839025269025 0.014055160300682597 1.0\n",
            "repr, std, cov, closslb 0.009062249213457108 0.4755859375 8.242623880505562e-05 0.0039593870751559734 0.00274088722653687\n",
            "0.0014888712864294293 0.014310315137761142 1.0\n",
            "repr, std, cov, closslb 0.009090926498174667 0.477294921875 6.876559928059578e-05 0.008044840767979622 0.0013712641084566712\n",
            "0.001472591543452325 0.014253216694655239 1.0\n",
            "repr, std, cov, closslb 0.017378075048327446 0.475830078125 9.204982779920101e-05 0.0074796006083488464 0.0002447986917104572\n",
            "0.0014550347730516399 0.0141255767944109 1.0\n",
            "repr, std, cov, closslb 0.012206482701003551 0.477294921875 6.546452641487122e-05 0.0035133175551891327 4.429642285685986e-05\n",
            "0.0014463350388445862 0.014097367961120702 1.0\n",
            "repr, std, cov, closslb 0.005342547316104174 0.476318359375 8.13477672636509e-05 1.7833472156780772e-05 0.0001889898267108947\n",
            "0.0014492291552573137 0.014310315137761142 1.0\n",
            "repr, std, cov, closslb 0.010154777206480503 0.475830078125 8.325581438839436e-05 0.004148383624851704 1.0014750841946807e-05\n",
            "0.0014319509197208108 0.014097367961120702 1.0\n",
            "repr, std, cov, closslb 0.010441143065690994 0.475341796875 8.717086166143417e-05 0.004135425202548504 1.4014714906807058e-05\n",
            "0.0014022082102242137 0.013735738720136474 1.0\n",
            "repr, std, cov, closslb 0.007454931270331144 0.474609375 0.00010738219134509563 5.129095370648429e-05 0.0011280318722128868\n",
            "0.0013854905754460407 0.013490828657601109 1.0\n",
            "19\n",
            "repr, std, cov, closslb 0.009458821266889572 0.47412109375 0.00010367482900619507 0.008604692295193672 0.0003738182131201029\n",
            "0.001378583856532083 0.013290075994538127 1.0\n",
            "repr, std, cov, closslb 0.006895778700709343 0.474365234375 9.992020204663277e-05 5.756210612162249e-06 5.358106500352733e-05\n",
            "0.001375830819063138 0.013197416471122622 1.0\n",
            "repr, std, cov, closslb 0.010904337279498577 0.474853515625 9.929877705872059e-05 0.004341814201325178 0.0055720689706504345\n",
            "0.001375830819063138 0.01305311215813736 1.0\n",
            "repr, std, cov, closslb 0.009575063362717628 0.476318359375 7.694587111473083e-05 0.006833006162196398 1.4387810551852454e-05\n",
            "0.0013827237452318322 0.01318423223888374 1.0\n",
            "repr, std, cov, closslb 0.01136934757232666 0.4765625 6.532412953674793e-05 0.006664261221885681 0.00013777118874713778\n",
            "0.0013980099848417246 0.013558417844151438 1.0\n",
            "repr, std, cov, closslb 0.010169300250709057 0.47802734375 4.987628199160099e-05 0.008337035775184631 0.00016185124695766717\n",
            "0.001405014028852872 0.013790764144406024 1.0\n",
            "repr, std, cov, closslb 0.014114446938037872 0.476318359375 6.873393431305885e-05 0.004819626919925213 0.01532564964145422\n",
            "0.001413465216357785 0.014069215460983279 1.0\n",
            "repr, std, cov, closslb 0.03528425469994545 0.47607421875 7.938779890537262e-05 0.012175843119621277 0.03148283064365387\n",
            "0.0014162935602557167 0.014196346075477304 1.0\n",
            "repr, std, cov, closslb 0.005260482430458069 0.476318359375 7.149716839194298e-05 1.0807492799358442e-05 3.503097832435742e-05\n",
            "0.0014008074028213926 0.01413970237120531 1.0\n",
            "repr, std, cov, closslb 0.006918177008628845 0.475830078125 7.482385262846947e-05 0.0035571821499615908 4.607572191162035e-05\n",
            "0.0013910408562346247 0.013985094835635186 1.0\n",
            "repr, std, cov, closslb 0.004245876334607601 0.4755859375 8.292053826153278e-05 5.789579518022947e-06 0.00013542629312723875\n",
            "0.0013896512050295953 0.014041119181501098 1.0\n",
            "repr, std, cov, closslb 0.008048729971051216 0.4755859375 8.283834904432297e-05 0.004350082017481327 0.01559930108487606\n",
            "0.0013703412266265374 0.013846010000745356 1.0\n",
            "repr, std, cov, closslb 0.00898764282464981 0.4765625 6.8658497184515e-05 0.003813554299995303 5.2668438002001494e-05\n",
            "0.001352650870712326 0.013558417844151438 1.0\n",
            "repr, std, cov, closslb 0.011104208417236805 0.47607421875 7.331790402531624e-05 0.008578707464039326 5.023325684305746e-06\n",
            "0.001355357525104621 0.013450436981894048 1.0\n",
            "repr, std, cov, closslb 0.012957107275724411 0.474853515625 9.406707249581814e-05 0.0041101542301476 0.015429196879267693\n",
            "0.001339198461184346 0.01311850838064602 1.0\n",
            "repr, std, cov, closslb 0.01717555709183216 0.4765625 7.811468094587326e-05 0.011516235768795013 0.0001228817127412185\n",
            "0.0013459078588735607 0.013105402977668355 1.0\n",
            "repr, std, cov, closslb 0.01423000916838646 0.475341796875 7.85535667091608e-05 0.011079709976911545 0.015154763124883175\n",
            "0.0013499496215196654 0.013250285374308798 1.0\n",
            "repr, std, cov, closslb 0.004092241637408733 0.476318359375 7.75451771914959e-05 7.15488386049401e-06 6.917412974871695e-05\n",
            "0.001352650870712326 0.013396769469797572 1.0\n",
            "repr, std, cov, closslb 0.006999420002102852 0.476318359375 7.435865700244904e-05 0.004009179305285215 7.033206202322617e-05\n",
            "0.0013662384113111322 0.013776987157248777 1.0\n",
            "repr, std, cov, closslb 0.005902741104364395 0.476806640625 6.961403414607048e-05 0.004122306127101183 6.002734153298661e-06\n",
            "0.001367604649722443 0.01399907993047082 1.0\n",
            "repr, std, cov, closslb 0.006315486505627632 0.476318359375 8.020130917429924e-05 0.0041746641509234905 9.381750714965165e-05\n",
            "0.0013799624403886149 0.014382009959776034 1.0\n",
            "repr, std, cov, closslb 0.00628611259162426 0.476318359375 7.180217653512955e-05 0.0038537997752428055 7.065696991048753e-05\n",
            "0.001367604649722443 0.014310315137761142 1.0\n",
            "repr, std, cov, closslb 0.009553547948598862 0.476806640625 6.575975567102432e-05 0.003969342913478613 0.0001258859847439453\n",
            "0.0013567128826297255 0.014111465329081821 1.0\n",
            "repr, std, cov, closslb 0.012013951316475868 0.4765625 6.637535989284515e-05 0.007963119074702263 0.00011202829045942053\n",
            "0.001360787092772975 0.01408328467644426 1.0\n",
            "repr, std, cov, closslb 0.01172603853046894 0.474609375 9.37522854655981e-05 0.004112547263503075 0.015487358905375004\n",
            "0.0013378606005837624 0.013639971998855815 1.0\n",
            "repr, std, cov, closslb 0.012572091072797775 0.47509765625 8.917995728552341e-05 0.01971171610057354 2.1444848243845627e-05\n",
            "0.0013311913187582143 0.013436999981912138 1.0\n",
            "repr, std, cov, closslb 0.010851170867681503 0.475341796875 8.137105032801628e-05 0.007804736029356718 7.62810668675229e-05\n",
            "0.0013140063667468717 0.013092310667001355 1.0\n",
            "repr, std, cov, closslb 0.005758121609687805 0.47509765625 9.087263606488705e-05 2.447741735522868e-06 0.030579611659049988\n",
            "0.0013087634551093416 0.013014031010000301 1.0\n",
            "repr, std, cov, closslb 0.0057143596932291985 0.474365234375 9.370292536914349e-05 7.060135885694763e-06 6.248585123103112e-05\n",
            "0.001312693673073798 0.012936219391442277 1.0\n",
            "repr, std, cov, closslb 0.004490230232477188 0.4755859375 8.3856750279665e-05 3.220896815037122e-06 1.7294720237259753e-05\n",
            "0.0013140063667468717 0.012871731885912174 1.0\n",
            "repr, std, cov, closslb 0.007318153046071529 0.4755859375 7.463106885552406e-05 0.0038906503468751907 0.015336662530899048\n",
            "0.0013258798388190605 0.012975066871210993 1.0\n",
            "repr, std, cov, closslb 0.004146500024944544 0.476318359375 7.124128751456738e-05 5.887442057428416e-06 0.015156205743551254\n",
            "0.0013325225100769722 0.013092310667001355 1.0\n",
            "repr, std, cov, closslb 0.007260936312377453 0.4765625 6.478582508862019e-05 0.00386498449370265 0.00015763660485390574\n",
            "0.0013594276651078673 0.013436999981912138 1.0\n",
            "repr, std, cov, closslb 0.006434177048504353 0.476318359375 6.68501015752554e-05 0.0037061215844005346 0.015620731748640537\n",
            "0.0013689722543721655 0.013680932848408345 1.0\n",
            "repr, std, cov, closslb 0.004620295017957687 0.47607421875 6.914651021361351e-05 8.874471859598998e-06 4.5365188270807266e-05\n",
            "0.0013896512050295953 0.013985094835635186 1.0\n",
            "repr, std, cov, closslb 0.01243920624256134 0.4765625 5.943840369582176e-05 0.003820783691480756 0.01549391821026802\n",
            "0.0013827237452318322 0.013929294028027806 1.0\n",
            "20\n",
            "repr, std, cov, closslb 0.008320678025484085 0.476318359375 7.663876749575138e-05 0.004072315525263548 0.015217962674796581\n",
            "0.0013799624403886149 0.013804554908550428 1.0\n",
            "repr, std, cov, closslb 0.009332951158285141 0.475830078125 7.434631697833538e-05 0.0036892658099532127 0.015148448757827282\n",
            "0.001364873537773359 0.013571976261995588 1.0\n",
            "repr, std, cov, closslb 0.008987393230199814 0.474853515625 8.983840234577656e-05 0.00874366145581007 0.0012684233952313662\n",
            "0.0013432200755024806 0.013171061177706035 1.0\n",
            "repr, std, cov, closslb 0.02115441858768463 0.474853515625 8.711684495210648e-05 0.004465725738555193 9.695651533547789e-05\n",
            "0.0013285329243765372 0.012949155610833717 1.0\n",
            "repr, std, cov, closslb 0.004960100166499615 0.474609375 8.97059217095375e-05 5.2461236919043586e-06 1.2407896974764299e-05\n",
            "0.0013166356934867318 0.012680191801910464 1.0\n",
            "repr, std, cov, closslb 0.010317862033843994 0.47509765625 7.718312554061413e-05 0.007844209671020508 5.2284936828073114e-05\n",
            "0.0013074559991102315 0.012516497459452068 1.0\n",
            "repr, std, cov, closslb 0.0053137256763875484 0.475341796875 9.964057244360447e-05 6.403864063031506e-06 0.00020744145149365067\n",
            "0.0013074559991102315 0.01237963850900369 1.0\n",
            "repr, std, cov, closslb 0.0046272906474769115 0.47607421875 6.622076034545898e-05 0.0034513988066464663 0.0155128613114357\n",
            "0.0013153203731136184 0.012491501964022062 1.0\n",
            "repr, std, cov, closslb 0.006364809349179268 0.476806640625 7.047341205179691e-05 0.0039400262758135796 3.408415796002373e-05\n",
            "0.0013258798388190605 0.012846026985913365 1.0\n",
            "repr, std, cov, closslb 0.007943597622215748 0.477294921875 5.4303789511322975e-05 0.0035965638235211372 0.00016102020163089037\n",
            "0.0013325225100769722 0.01307923143556579 1.0\n",
            "repr, std, cov, closslb 0.004129219334572554 0.47705078125 6.054132245481014e-05 8.169086868292652e-06 0.01507741678506136\n",
            "0.0013405376596455302 0.013343316092145834 1.0\n",
            "repr, std, cov, closslb 0.008665625005960464 0.476318359375 7.34210480004549e-05 0.0037419244181364775 8.694685675436631e-05\n",
            "0.001335188887619636 0.013477351306294816 1.0\n",
            "repr, std, cov, closslb 0.007495545782148838 0.4765625 7.216236554086208e-05 0.003721390850841999 0.015190137550234795\n",
            "0.0013325225100769722 0.013585548238257581 1.0\n",
            "repr, std, cov, closslb 0.005586129613220692 0.47607421875 7.240870036184788e-05 1.7210251826327294e-05 0.0003446280024945736\n",
            "0.0013272057186578794 0.013599133786495838 1.0\n",
            "repr, std, cov, closslb 0.00726347416639328 0.4765625 6.915908306837082e-05 0.0038738343864679337 0.00017073606431949884\n",
            "0.0013166356934867318 0.013544872971180259 1.0\n",
            "repr, std, cov, closslb 0.005335125140845776 0.4755859375 7.190555334091187e-05 1.1764908776967786e-05 5.97239522903692e-05\n",
            "0.0013113822907830151 0.013450436981894048 1.0\n",
            "repr, std, cov, closslb 0.013546539470553398 0.475341796875 7.783458568155766e-05 0.008142579346895218 5.7676505093695596e-05\n",
            "0.0012880001687590567 0.01305311215813736 1.0\n",
            "repr, std, cov, closslb 0.008925095200538635 0.474853515625 9.249243885278702e-05 0.011969970539212227 0.0003833931405097246\n",
            "0.0012777423812790627 0.012820373418702544 1.0\n",
            "repr, std, cov, closslb 0.005212364252656698 0.475341796875 7.645087316632271e-05 8.11688369140029e-06 0.014302661642432213\n",
            "0.0012599874383855726 0.012491501964022062 1.0\n",
            "repr, std, cov, closslb 0.006606744136661291 0.475341796875 7.751490920782089e-05 0.004365753382444382 0.0003074835694860667\n",
            "0.0012537063569937014 0.012354916321444483 1.0\n",
            "repr, std, cov, closslb 0.0061296820640563965 0.476806640625 6.469455547630787e-05 0.007087442558258772 0.0005459921667352319\n",
            "0.0012713727908766853 0.012330243504192597 1.0\n",
            "repr, std, cov, closslb 0.007922355085611343 0.4755859375 7.489649578928947e-05 0.0031257274094969034 0.00014922971604391932\n",
            "0.0012751907246390602 0.012479022941080983 1.0\n",
            "repr, std, cov, closslb 0.017300710082054138 0.476318359375 6.588990800082684e-05 0.012166716158390045 2.123859667335637e-05\n",
            "0.0012867134553037531 0.012820373418702544 1.0\n",
            "repr, std, cov, closslb 0.007018073461949825 0.476806640625 5.887076258659363e-05 0.003989698830991983 6.838171975687146e-05\n",
            "0.0012970432630690263 0.0130270450410103 1.0\n",
            "repr, std, cov, closslb 0.008346611633896828 0.476806640625 6.74547627568245e-05 0.0038173156790435314 0.015705646947026253\n",
            "0.0013074559991102315 0.013410166239267367 1.0\n",
            "repr, std, cov, closslb 0.011425862088799477 0.476806640625 6.298325024545193e-05 0.008667544461786747 0.048181645572185516\n",
            "0.0013140063667468717 0.013558417844151438 1.0\n",
            "repr, std, cov, closslb 0.012707611545920372 0.476806640625 5.993712693452835e-05 0.006843522656708956 0.000328414753312245\n",
            "0.0013258798388190605 0.013901477172206224 1.0\n",
            "repr, std, cov, closslb 0.012581195682287216 0.4775390625 5.8190664276480675e-05 0.011250889860093594 0.014071112498641014\n",
            "0.0013179523291802185 0.013901477172206224 1.0\n",
            "repr, std, cov, closslb 0.009196992963552475 0.47509765625 9.532831609249115e-05 0.0079358434304595 0.01316765882074833\n",
            "0.001295747515553473 0.013558417844151438 1.0\n",
            "repr, std, cov, closslb 0.012012392282485962 0.47607421875 7.587810978293419e-05 0.00802943017333746 0.015306790359318256\n",
            "0.0012777423812790627 0.013316669436603194 1.0\n",
            "repr, std, cov, closslb 0.006224997341632843 0.475341796875 9.202398359775543e-05 0.0032501621171832085 0.014442820101976395\n",
            "0.0012512027003902207 0.01292329609534693 1.0\n",
            "repr, std, cov, closslb 0.008704041130840778 0.476318359375 7.370556704699993e-05 0.008804614655673504 0.0307769738137722\n",
            "0.0012487040435989792 0.012910385709637295 1.0\n",
            "repr, std, cov, closslb 0.004521346651017666 0.47607421875 8.081924170255661e-05 1.781448008841835e-05 0.00010616804502205923\n",
            "0.001252453903090611 0.012962104766444549 1.0\n",
            "repr, std, cov, closslb 0.010146779008209705 0.474853515625 0.00010141544044017792 0.004351636860519648 0.00018105200433637947\n",
            "0.0012512027003902207 0.012884603617798085 1.0\n",
            "repr, std, cov, closslb 0.0043328190222382545 0.475830078125 8.682720363140106e-05 3.417628977331333e-05 0.031025581061840057\n",
            "0.0012412379723518979 0.012680191801910464 1.0\n",
            "repr, std, cov, closslb 0.003774627111852169 0.476806640625 7.045245729386806e-05 8.313645594171248e-06 9.76372102741152e-05\n",
            "0.0012387592151623583 0.012781989092675255 1.0\n",
            "21\n",
            "repr, std, cov, closslb 0.009850932285189629 0.4755859375 8.757179602980614e-05 0.011542838998138905 0.00016608316218480468\n",
            "0.0012375216934688896 0.012936219391442277 1.0\n",
            "repr, std, cov, closslb 0.006753347814083099 0.477294921875 6.259139627218246e-05 0.00409366050735116 0.00019339864957146347\n",
            "0.0012412379723518979 0.013171061177706035 1.0\n",
            "repr, std, cov, closslb 0.005509276408702135 0.478515625 5.25093637406826e-05 0.004469890613108873 0.00013534656318370253\n",
            "0.001252453903090611 0.013571976261995588 1.0\n",
            "repr, std, cov, closslb 0.009003957733511925 0.477783203125 5.7241879403591156e-05 0.008051407523453236 0.0001804860366974026\n",
            "0.0012625086732497817 0.013818359463458977 1.0\n",
            "repr, std, cov, closslb 0.005032727494835854 0.475830078125 0.00010118982754647732 0.00037576782051473856 0.0157333854585886\n",
            "0.0012574712384374595 0.014013079010401289 1.0\n",
            "repr, std, cov, closslb 0.01393185369670391 0.477294921875 6.531248800456524e-05 0.0045346450060606 0.00023591655190102756\n",
            "0.001252453903090611 0.014041119181501098 1.0\n",
            "repr, std, cov, closslb 0.008498536422848701 0.476806640625 8.140318095684052e-05 0.004377357196062803 0.00023404142120853066\n",
            "0.001254960063350695 0.014253216694655239 1.0\n",
            "repr, std, cov, closslb 0.010974963195621967 0.476806640625 7.889233529567719e-05 0.012589171528816223 0.015673043206334114\n",
            "0.0012487040435989792 0.014253216694655239 1.0\n",
            "repr, std, cov, closslb 0.003963921219110489 0.47802734375 6.290082819759846e-05 3.639699571067467e-05 7.765409827698022e-05\n",
            "0.0012562150234140456 0.014628469896531862 1.0\n",
            "repr, std, cov, closslb 0.005233414471149445 0.476806640625 6.787758320569992e-05 0.003803170984610915 0.0041331141255795956\n",
            "0.0012599874383855726 0.014834605005279342 1.0\n",
            "repr, std, cov, closslb 0.0063004270195961 0.476318359375 7.954915054142475e-05 0.0036197856534272432 0.000328024267219007\n",
            "0.0012387592151623583 0.014497469542133209 1.0\n",
            "repr, std, cov, closslb 0.009412752464413643 0.474609375 0.00011042342521250248 0.003283395431935787 0.00030047271866351366\n",
            "0.001221545965100186 0.014267469911349893 1.0\n",
            "repr, std, cov, closslb 0.00393418176099658 0.475830078125 8.509890176355839e-05 2.624822809593752e-05 9.910541120916605e-05\n",
            "0.0011961735265086457 0.013873715866756845 1.0\n",
            "repr, std, cov, closslb 0.00599925359711051 0.475830078125 9.777327068150043e-05 0.0033883461728692055 0.009712385945022106\n",
            "0.0011854615958007003 0.013667265582825522 1.0\n",
            "repr, std, cov, closslb 0.012645924463868141 0.476318359375 8.5463747382164e-05 0.010016357526183128 8.284810610348359e-05\n",
            "0.0011713280927605368 0.013329986106039795 1.0\n",
            "repr, std, cov, closslb 0.007631603628396988 0.476806640625 7.285014726221561e-05 0.01232969295233488 0.01558968611061573\n",
            "0.0011830942242579603 0.013571976261995588 1.0\n",
            "repr, std, cov, closslb 0.008669265545904636 0.47607421875 8.900836110115051e-05 0.004230848979204893 0.0008010029559955001\n",
            "0.0011819123119460144 0.013722016703433043 1.0\n",
            "repr, std, cov, closslb 0.011067565530538559 0.4765625 8.777319453656673e-05 0.0039587002247571945 9.236616460839286e-05\n",
            "0.0011795520283373118 0.013873715866756845 1.0\n",
            "repr, std, cov, closslb 0.0058519719168543816 0.47802734375 6.28491397947073e-05 0.0039197481237351894 0.00010872304119402543\n",
            "0.0011925921710264616 0.01428173738126124 1.0\n",
            "repr, std, cov, closslb 0.009612206369638443 0.478271484375 7.036677561700344e-05 0.00415955763310194 0.031088439747691154\n",
            "0.001200965402441729 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.00522293895483017 0.47900390625 5.444721318781376e-05 0.002512748120352626 0.015474830754101276\n",
            "0.0012203256394607254 0.015013602620241017 1.0\n",
            "repr, std, cov, closslb 0.014946520328521729 0.476318359375 0.0003755846992135048 0.015627792105078697 0.00023441750090569258\n",
            "0.0012276659226069058 0.015270885959816682 1.0\n",
            "repr, std, cov, closslb 0.010069470852613449 0.47802734375 7.249787449836731e-05 0.007779997307807207 0.00010136868513654917\n",
            "0.0012474565870119673 0.015751453512279048 1.0\n",
            "repr, std, cov, closslb 0.004555468447506428 0.47998046875 5.503580905497074e-05 1.1201818779227324e-05 2.395546471234411e-05\n",
            "0.0012537063569937014 0.015973412993048414 1.0\n",
            "repr, std, cov, closslb 0.015777043998241425 0.477783203125 7.35800713300705e-05 0.01211203821003437 0.015900200232863426\n",
            "0.0012474565870119673 0.01605343995195759 1.0\n",
            "repr, std, cov, closslb 0.02133120223879814 0.4765625 8.356827311217785e-05 0.007128717377781868 0.0003680465160869062\n",
            "0.0012301224821180418 0.01603740254940818 1.0\n",
            "repr, std, cov, closslb 0.004374738782644272 0.476318359375 0.00010395795106887817 1.9928320398321375e-05 0.0009326221188530326\n",
            "0.0012045719027462265 0.015672931966320094 1.0\n",
            "repr, std, cov, closslb 0.004055277910083532 0.4765625 9.197881445288658e-05 2.260230394313112e-05 8.859774243319407e-05\n",
            "0.0011878337044538972 0.015424283845000076 1.0\n",
            "repr, std, cov, closslb 0.0038819503970444202 0.4765625 8.6549436673522e-05 8.711889677215368e-06 0.0001312604726990685\n",
            "0.001180731580365649 0.015332061190070516 1.0\n",
            "repr, std, cov, closslb 0.0034937760792672634 0.47705078125 7.704203017055988e-05 1.0698156074795406e-05 2.920888437074609e-05\n",
            "0.001180731580365649 0.015393481488541508 1.0\n",
            "repr, std, cov, closslb 0.011300254613161087 0.4765625 7.582223042845726e-05 0.008181058801710606 2.6769152100314386e-05\n",
            "0.0011866470573965008 0.015830368451968866 1.0\n",
            "repr, std, cov, closslb 0.02849685586988926 0.476318359375 8.572195656597614e-05 0.008463267236948013 0.0002088303299387917\n",
            "0.0011973697000351542 0.01608556288530145 1.0\n",
            "repr, std, cov, closslb 0.003723946399986744 0.477294921875 9.282678365707397e-05 9.160570698441006e-06 0.000496179738547653\n",
            "0.0011961735265086457 0.01629593448870829 1.0\n",
            "repr, std, cov, closslb 0.010812695138156414 0.4765625 8.216802962124348e-05 0.011848650872707367 0.00011545346205821261\n",
            "0.001189021538158351 0.01627965483387442 1.0\n",
            "repr, std, cov, closslb 0.003084442112594843 0.477294921875 7.310253567993641e-05 2.828424476319924e-05 0.015512768179178238\n",
            "0.0011748455921944245 0.01610164844818675 1.0\n",
            "repr, std, cov, closslb 0.006938562728464603 0.474609375 9.6574192866683e-05 0.0036616320721805096 2.382614002272021e-05\n",
            "0.0011689889458798314 0.016182317868009166 1.0\n",
            "22\n",
            "repr, std, cov, closslb 0.005592050030827522 0.4755859375 9.02323517948389e-05 0.003895495319738984 8.445494131592568e-06\n",
            "0.0011585204575634508 0.015846198820420834 1.0\n",
            "repr, std, cov, closslb 0.00410406943410635 0.474853515625 9.614205919206142e-05 6.577702151844278e-06 8.092313510132954e-05\n",
            "0.0011458528646998115 0.015594801853010515 1.0\n",
            "repr, std, cov, closslb 0.010318486019968987 0.474609375 0.00010520126670598984 0.007741640321910381 0.0002768737031146884\n",
            "0.0011344571066897392 0.015270885959816682 1.0\n",
            "repr, std, cov, closslb 0.018101613968610764 0.4755859375 0.00011237640865147114 0.02106931060552597 0.0003148758551105857\n",
            "0.0011220526293626563 0.015088820919579525 1.0\n",
            "repr, std, cov, closslb 0.008838647976517677 0.474609375 0.00010148435831069946 0.0044716764241456985 0.000531246536411345\n",
            "0.0011164591578118445 0.014819785220059284 1.0\n",
            "repr, std, cov, closslb 0.00394663168117404 0.475341796875 8.678180165588856e-05 9.628839507058728e-06 0.015659010037779808\n",
            "0.0011164591578118445 0.014760653981153412 1.0\n",
            "repr, std, cov, closslb 0.008953128941357136 0.47509765625 9.434600360691547e-05 0.004238306079059839 2.566770854173228e-05\n",
            "0.0011242978566740108 0.014819785220059284 1.0\n",
            "repr, std, cov, closslb 0.006467726081609726 0.47607421875 7.707602344453335e-05 0.003943681251257658 8.469588647130877e-05\n",
            "0.0011299306001845482 0.014834605005279342 1.0\n",
            "repr, std, cov, closslb 0.014340557157993317 0.4755859375 8.926237933337688e-05 0.015513580292463303 0.00020212178060319275\n",
            "0.0011390017463981008 0.014745908073080334 1.0\n",
            "repr, std, cov, closslb 0.004163910634815693 0.475830078125 8.629867807030678e-05 1.1877375072799623e-05 0.00013843950000591576\n",
            "0.0011355915637964288 0.014716460435748405 1.0\n",
            "repr, std, cov, closslb 0.004846884403377771 0.47509765625 0.00010131043381989002 2.248450618935749e-05 0.0004178381059318781\n",
            "0.0011378638825155854 0.014657741464794819 1.0\n",
            "repr, std, cov, closslb 0.004422358237206936 0.475341796875 8.648284710943699e-05 7.216116500785574e-06 1.340572543995222e-05\n",
            "0.0011333237829068326 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.005156788043677807 0.475830078125 8.124625310301781e-05 2.048633359663654e-05 0.01607539877295494\n",
            "0.0011254221545306847 0.014324625452898901 1.0\n",
            "repr, std, cov, closslb 0.004504303447902203 0.475830078125 8.018850348889828e-05 5.255385076452512e-06 0.015689576044678688\n",
            "0.0011276741242619004 0.014310315137761142 1.0\n",
            "repr, std, cov, closslb 0.005366337951272726 0.4755859375 7.690442726016045e-05 4.765092853631359e-06 0.00023732840782031417\n",
            "0.0011412808888926432 0.0145410054576657 1.0\n",
            "repr, std, cov, closslb 0.011607479304075241 0.4755859375 8.151307702064514e-05 0.0076231760904192924 0.015274550765752792\n",
            "0.0011401407481444988 0.01458467211159607 1.0\n",
            "repr, std, cov, closslb 0.007110817823559046 0.475341796875 8.418620564043522e-05 0.003911655396223068 0.00022167192946653813\n",
            "0.0011367271553602253 0.01451196701167534 1.0\n",
            "repr, std, cov, closslb 0.019800391048192978 0.47607421875 7.624574936926365e-05 0.008798196911811829 0.015515796840190887\n",
            "0.0011310605307847327 0.014310315137761142 1.0\n",
            "repr, std, cov, closslb 0.009377291426062584 0.4755859375 8.460553362965584e-05 0.007141187787055969 2.1509793441509828e-05\n",
            "0.0011276741242619004 0.014097367961120702 1.0\n",
            "repr, std, cov, closslb 0.012591839767992496 0.47509765625 9.108684025704861e-05 0.007918672636151314 9.458752174396068e-06\n",
            "0.001118693192586626 0.013915378649378429 1.0\n",
            "repr, std, cov, closslb 0.0070763397961854935 0.4755859375 8.826772682368755e-05 0.0035028692800551653 5.401811358751729e-05\n",
            "0.0010976490939178752 0.013558417844151438 1.0\n",
            "repr, std, cov, closslb 0.01102652307599783 0.475341796875 8.30239150673151e-05 0.00791882909834385 0.00010904598457273096\n",
            "0.001098746743011793 0.013490828657601109 1.0\n",
            "repr, std, cov, closslb 0.0039138346910476685 0.475830078125 8.62970482558012e-05 7.5967650445818435e-06 6.645679968642071e-05\n",
            "0.0010943627215706363 0.013316669436603194 1.0\n",
            "repr, std, cov, closslb 0.004229286219924688 0.476318359375 6.879866123199463e-05 4.448373147170059e-06 3.8451809814432636e-05\n",
            "0.0010998454897548048 0.013396769469797572 1.0\n",
            "repr, std, cov, closslb 0.007293489761650562 0.47607421875 7.843226194381714e-05 0.00463012233376503 0.015516740269958973\n",
            "0.0011042514751872438 0.013585548238257581 1.0\n",
            "repr, std, cov, closslb 0.016131233423948288 0.4765625 6.920355372130871e-05 0.007618950679898262 0.015409435145556927\n",
            "0.0011064610823890932 0.013639971998855815 1.0\n",
            "repr, std, cov, closslb 0.0041753449477255344 0.47607421875 7.010274566709995e-05 1.0192456102231517e-05 9.790198237169534e-05\n",
            "0.001107567543471482 0.013667265582825522 1.0\n",
            "repr, std, cov, closslb 0.013530317693948746 0.475341796875 0.00010000821202993393 0.019952429458498955 0.008635316975414753\n",
            "0.001113116467945488 0.013763223933315463 1.0\n",
            "repr, std, cov, closslb 0.008799998089671135 0.476806640625 6.43415842205286e-05 0.007586747407913208 7.03747064108029e-05\n",
            "0.0011220526293626563 0.014069215460983279 1.0\n",
            "repr, std, cov, closslb 0.009481258690357208 0.4765625 7.298518903553486e-05 0.011356757953763008 4.971210000803694e-05\n",
            "0.0011198118857792124 0.0141255767944109 1.0\n",
            "repr, std, cov, closslb 0.00779333570972085 0.476318359375 6.652390584349632e-05 0.003026667982339859 0.00020467856666073203\n",
            "0.0011242978566740108 0.0142960191186425 1.0\n",
            "repr, std, cov, closslb 0.0038127207662910223 0.4755859375 7.651816122233868e-05 2.1082614694023505e-05 0.015346495434641838\n",
            "0.0011209316976649915 0.014196346075477304 1.0\n",
            "repr, std, cov, closslb 0.00655370345339179 0.475830078125 7.978384383022785e-05 0.004038187209516764 0.0010298261186107993\n",
            "0.001107567543471482 0.013929294028027806 1.0\n",
            "repr, std, cov, closslb 0.00902564637362957 0.47509765625 9.252410382032394e-05 0.004507153760641813 0.031423170119524\n",
            "0.0010954570842922069 0.013694613781256752 1.0\n",
            "repr, std, cov, closslb 0.007210948970168829 0.475830078125 8.232798427343369e-05 0.0047126878052949905 0.01565936952829361\n",
            "0.001107567543471482 0.013612732920282332 1.0\n",
            "repr, std, cov, closslb 0.008029556833207607 0.47607421875 8.094380609691143e-05 0.00936734490096569 0.0003073980624321848\n",
            "0.0011097837861259684 0.013694613781256752 1.0\n",
            "23\n",
            "repr, std, cov, closslb 0.019978195428848267 0.475341796875 8.382019586861134e-05 0.014102322049438953 0.00031574483728036284\n",
            "0.001098746743011793 0.013329986106039795 1.0\n",
            "repr, std, cov, closslb 0.004237814340740442 0.475341796875 8.281250484287739e-05 0.00020515279902610928 0.015599735081195831\n",
            "0.0010943627215706363 0.013197416471122622 1.0\n",
            "repr, std, cov, closslb 0.009676465764641762 0.475341796875 7.793796248733997e-05 0.007218114100396633 0.00012750146561302245\n",
            "0.0010910861886550196 0.013066165270295495 1.0\n",
            "repr, std, cov, closslb 0.01562795601785183 0.47607421875 7.591955363750458e-05 0.007828710600733757 0.015695247799158096\n",
            "0.001093269452118518 0.013092310667001355 1.0\n",
            "repr, std, cov, closslb 0.014123409986495972 0.475341796875 8.232099935412407e-05 0.007297358941286802 0.0001544937549624592\n",
            "0.0010954570842922069 0.012962104766444549 1.0\n",
            "repr, std, cov, closslb 0.006103986408561468 0.475830078125 7.795542478561401e-05 0.004194102715700865 0.00023265588970389217\n",
            "0.0010910861886550196 0.012858873012899277 1.0\n",
            "repr, std, cov, closslb 0.009709940291941166 0.47607421875 7.675145752727985e-05 0.003932728432118893 0.00017185774049721658\n",
            "0.001098746743011793 0.012988041938082203 1.0\n",
            "repr, std, cov, closslb 0.007141440641134977 0.476318359375 7.351604290306568e-05 0.003765718312934041 3.293783447588794e-05\n",
            "0.0011009453352445594 0.01311850838064602 1.0\n",
            "repr, std, cov, closslb 0.012500769458711147 0.47607421875 7.187225855886936e-05 0.00363924796693027 3.284822014393285e-05\n",
            "0.0011108935699120942 0.013436999981912138 1.0\n",
            "repr, std, cov, closslb 0.004734300076961517 0.47705078125 6.317929364740849e-05 1.8277558410773054e-05 0.016015859320759773\n",
            "0.0011153438139978468 0.013612732920282332 1.0\n",
            "repr, std, cov, closslb 0.0057236505672335625 0.475830078125 8.464069105684757e-05 0.0001733078679535538 0.00017126972670666873\n",
            "0.001118693192586626 0.013585548238257581 1.0\n",
            "repr, std, cov, closslb 0.017851166427135468 0.476318359375 6.703543476760387e-05 0.007345032412558794 0.0004594948550220579\n",
            "0.001118693192586626 0.013490828657601109 1.0\n",
            "repr, std, cov, closslb 0.005515516269952059 0.47509765625 8.943583816289902e-05 1.5182393326540478e-05 0.01603202521800995\n",
            "0.0010976490939178752 0.013197416471122622 1.0\n",
            "repr, std, cov, closslb 0.01639443449676037 0.473388671875 0.00020183203741908073 0.020745128393173218 4.1252103983424604e-05\n",
            "0.0010889072851773798 0.01307923143556579 1.0\n",
            "repr, std, cov, closslb 0.00767813716083765 0.4755859375 7.944670505821705e-05 0.004304517991840839 0.015375211834907532\n",
            "0.0010921772748436745 0.01318423223888374 1.0\n",
            "repr, std, cov, closslb 0.02184750884771347 0.47705078125 6.132805719971657e-05 0.0035422337241470814 2.5899855245370418e-05\n",
            "0.0010976490939178752 0.013329986106039795 1.0\n",
            "repr, std, cov, closslb 0.0053009213879704475 0.476318359375 6.912718527019024e-05 2.6920652089756913e-06 0.00010808109800564125\n",
            "0.0011120044634820062 0.013653611970854669 1.0\n",
            "repr, std, cov, closslb 0.012941659428179264 0.4765625 6.149499677121639e-05 0.01122544426470995 0.015263233333826065\n",
            "0.001113116467945488 0.013846010000745356 1.0\n",
            "repr, std, cov, closslb 0.004345191642642021 0.477294921875 5.7216500863432884e-05 0.0011227641953155398 0.0002707793901208788\n",
            "0.001118693192586626 0.014055160300682597 1.0\n",
            "repr, std, cov, closslb 0.014871219173073769 0.4765625 7.002870552241802e-05 0.011709203943610191 0.014389727264642715\n",
            "0.0011175756169696563 0.013985094835635186 1.0\n",
            "repr, std, cov, closslb 0.007052517496049404 0.475830078125 7.960805669426918e-05 0.003542648395523429 0.00021353385818656534\n",
            "0.0011031483268603836 0.013639971998855815 1.0\n",
            "repr, std, cov, closslb 0.013041989877820015 0.47509765625 8.515710942447186e-05 0.005184050649404526 8.482459088554606e-05\n",
            "0.001093269452118518 0.013436999981912138 1.0\n",
            "repr, std, cov, closslb 0.011556869372725487 0.47509765625 9.712530300021172e-05 0.015420591458678246 0.00025802571326494217\n",
            "0.0010694919223241935 0.013014031010000301 1.0\n",
            "repr, std, cov, closslb 0.007504686713218689 0.474609375 9.989575482904911e-05 0.005156544968485832 0.0002077051467495039\n",
            "0.0010546307356842802 0.012807565852849695 1.0\n",
            "repr, std, cov, closslb 0.003730416065081954 0.476318359375 8.166441693902016e-05 9.269950169255026e-06 3.5472639865474775e-05\n",
            "0.0010472777618270946 0.012616980602857254 1.0\n",
            "repr, std, cov, closslb 0.010853984393179417 0.47607421875 7.530511356890202e-05 0.00453732255846262 0.0010002998169511557\n",
            "0.0010483250395889215 0.012554084513839298 1.0\n",
            "repr, std, cov, closslb 0.006638468708842993 0.475830078125 8.374894969165325e-05 0.004505752120167017 0.015729766339063644\n",
            "0.0010451863439528452 0.012392018147512692 1.0\n",
            "repr, std, cov, closslb 0.004397059790790081 0.475341796875 9.120791219174862e-05 7.280977297341451e-05 0.00014275948342401534\n",
            "0.0010410160295732701 0.012342573747696787 1.0\n",
            "repr, std, cov, closslb 0.006750492844730616 0.477294921875 5.81198837608099e-05 0.0036426507867872715 0.015076913870871067\n",
            "0.001043099102648446 0.012604376226630624 1.0\n",
            "repr, std, cov, closslb 0.003952025435864925 0.476806640625 6.881961598992348e-05 4.813762643607333e-06 0.017444027587771416\n",
            "0.0010472777618270946 0.012833193792121245 1.0\n",
            "repr, std, cov, closslb 0.006759988609701395 0.477294921875 6.510317325592041e-05 0.003719319822266698 0.0009961171308532357\n",
            "0.0010652246282016541 0.013250285374308798 1.0\n",
            "repr, std, cov, closslb 0.010620860382914543 0.478515625 4.744366742670536e-05 0.01118957344442606 4.3114054278703406e-05\n",
            "0.0010770008625805027 0.013490828657601109 1.0\n",
            "repr, std, cov, closslb 0.004820621572434902 0.47802734375 5.417061038315296e-05 0.00399784417822957 0.015801940113306046\n",
            "0.0010976490939178752 0.013929294028027806 1.0\n",
            "repr, std, cov, closslb 0.010216345079243183 0.477783203125 6.020464934408665e-05 0.008011124096810818 3.392289363546297e-05\n",
            "0.001098746743011793 0.0141255767944109 1.0\n",
            "repr, std, cov, closslb 0.0036144244950264692 0.47705078125 6.549595855176449e-05 7.233120413729921e-06 5.9856240113731474e-05\n",
            "0.001093269452118518 0.014367642317458577 1.0\n",
            "repr, std, cov, closslb 0.0034995186142623425 0.4765625 6.969436071813107e-05 1.2222070836287457e-05 0.0002791639417409897\n",
            "0.0010813153323450803 0.014367642317458577 1.0\n",
            "24\n",
            "repr, std, cov, closslb 0.0035525704734027386 0.475341796875 8.69561918079853e-05 7.711723810643889e-06 0.00038328650407493114\n",
            "0.0010599144462216394 0.01399907993047082 1.0\n",
            "repr, std, cov, closslb 0.007080527488142252 0.4755859375 7.90588092058897e-05 0.0038989074528217316 3.446693153819069e-05\n",
            "0.0010493733646285103 0.013776987157248777 1.0\n",
            "repr, std, cov, closslb 0.0067957001738250256 0.4736328125 0.0001174400094896555 0.003730972297489643 0.016256775707006454\n",
            "0.0010316935597747638 0.013343316092145834 1.0\n",
            "repr, std, cov, closslb 0.01987127959728241 0.4755859375 8.64893663674593e-05 0.012082576751708984 0.00011723536590579897\n",
            "0.001023477028801135 0.013105402977668355 1.0\n",
            "repr, std, cov, closslb 0.004163853824138641 0.4755859375 8.203228935599327e-05 3.8068246794864535e-06 9.12025134311989e-05\n",
            "0.0010183749600623803 0.012975066871210993 1.0\n",
            "repr, std, cov, closslb 0.03988067805767059 0.476806640625 7.408461533486843e-05 0.013043317943811417 0.00028157676570117474\n",
            "0.0010214331410858225 0.013001029980020283 1.0\n",
            "repr, std, cov, closslb 0.004507118836045265 0.476806640625 6.808992475271225e-05 0.0033477446995675564 0.00028498764731921256\n",
            "0.0010214331410858225 0.01318423223888374 1.0\n",
            "repr, std, cov, closslb 0.0054086376912891865 0.476806640625 6.759678944945335e-05 0.00447299238294363 0.0004929091082885861\n",
            "0.0010265505313421014 0.013410166239267367 1.0\n",
            "repr, std, cov, closslb 0.005147027783095837 0.4765625 6.990879774093628e-05 0.004458790645003319 1.5082850950420834e-05\n",
            "0.0010286046589553168 0.013531341629550709 1.0\n",
            "repr, std, cov, closslb 0.00618141982704401 0.4765625 6.80028460919857e-05 0.0034951460547745228 3.7283987239788985e-06\n",
            "0.001029633263614272 0.013735738720136474 1.0\n",
            "repr, std, cov, closslb 0.009590222500264645 0.476806640625 6.681377999484539e-05 0.007040541619062424 0.015331962145864964\n",
            "0.0010316935597747638 0.013873715866756845 1.0\n",
            "repr, std, cov, closslb 0.003131281118839979 0.475830078125 8.098897524178028e-05 1.242996677319752e-05 0.015297857113182545\n",
            "0.0010327252533345384 0.013915378649378429 1.0\n",
            "repr, std, cov, closslb 0.007158677093684673 0.476318359375 7.565738633275032e-05 0.003599955001845956 0.00013104817480780184\n",
            "0.0010327252533345384 0.01399907993047082 1.0\n",
            "repr, std, cov, closslb 0.0035193213261663914 0.475830078125 7.700501009821892e-05 3.4925560612464324e-06 1.713157689664513e-05\n",
            "0.0010265505313421014 0.013971123711923264 1.0\n",
            "repr, std, cov, closslb 0.003529774025082588 0.4765625 7.142848335206509e-05 8.906723451218568e-06 4.171026375843212e-05\n",
            "0.001029633263614272 0.013957166545377887 1.0\n",
            "repr, std, cov, closslb 0.010705222375690937 0.476318359375 6.609223783016205e-05 0.003832791466265917 0.00026882666861638427\n",
            "0.001029633263614272 0.014027092089411688 1.0\n",
            "repr, std, cov, closslb 0.008241587318480015 0.475830078125 7.040542550384998e-05 0.003956121392548084 0.015386847779154778\n",
            "0.001029633263614272 0.014027092089411688 1.0\n",
            "repr, std, cov, closslb 0.0076759494841098785 0.475341796875 7.561198435723782e-05 0.006524322554469109 0.00031924538780003786\n",
            "0.001020412728357465 0.0138598560107461 1.0\n",
            "repr, std, cov, closslb 0.010110776871442795 0.475341796875 8.152634836733341e-05 0.004016213119029999 0.0002553899248596281\n",
            "0.0009992179800401946 0.013463887418875942 1.0\n",
            "repr, std, cov, closslb 0.0032542916014790535 0.47509765625 8.49792268127203e-05 1.3406518519332167e-05 0.015303763560950756\n",
            "0.0009882922458673187 0.013250285374308798 1.0\n",
            "repr, std, cov, closslb 0.0052437009289860725 0.475830078125 7.547368295490742e-05 0.004216391127556562 0.030606389045715332\n",
            "0.0009853332890150735 0.013157903274431604 1.0\n",
            "repr, std, cov, closslb 0.014132551848888397 0.47607421875 7.426389493048191e-05 0.008001730777323246 0.015505941584706306\n",
            "0.0009892805381131859 0.013131626889026665 1.0\n",
            "repr, std, cov, closslb 0.003768183756619692 0.4755859375 9.865383617579937e-05 1.2561737094074488e-05 7.087925041560084e-05\n",
            "0.0009755339333850418 0.012807565852849695 1.0\n",
            "repr, std, cov, closslb 0.016416987404227257 0.4755859375 8.943816646933556e-05 0.02236662432551384 2.85497990262229e-05\n",
            "0.0009745593740110309 0.01279477108176793 1.0\n",
            "repr, std, cov, closslb 0.003118415828794241 0.47607421875 7.854984141886234e-05 9.797231541597284e-06 0.00012757707736454904\n",
            "0.0009745593740110309 0.012730988701002359 1.0\n",
            "repr, std, cov, closslb 0.014786573126912117 0.476806640625 6.823777221143246e-05 0.0036622697953134775 0.000391447392757982\n",
            "0.0009794419262252932 0.012858873012899277 1.0\n",
            "repr, std, cov, closslb 0.012644774280488491 0.47705078125 5.722464993596077e-05 0.015902606770396233 0.01548082660883665\n",
            "0.000994236843506885 0.013263535659683105 1.0\n",
            "repr, std, cov, closslb 0.006114615127444267 0.477294921875 6.12188596278429e-05 0.003660449292510748 3.8609876355621964e-05\n",
            "0.0009972225377421727 0.013477351306294816 1.0\n",
            "repr, std, cov, closslb 0.00808521918952465 0.477294921875 6.286613643169403e-05 0.006860679481178522 0.0003505699278321117\n",
            "0.0010072397580101645 0.013901477172206224 1.0\n",
            "repr, std, cov, closslb 0.004806024022400379 0.4775390625 5.310378037393093e-05 0.0044599296525120735 0.031266409903764725\n",
            "0.0010082469977681745 0.0141255767944109 1.0\n",
            "repr, std, cov, closslb 0.004641370382159948 0.4765625 6.589340046048164e-05 0.00444488599896431 0.015444680117070675\n",
            "0.0010052282961894895 0.0142960191186425 1.0\n",
            "repr, std, cov, closslb 0.004114091396331787 0.475341796875 8.1588514149189e-05 1.8074639228871092e-05 6.424632738344371e-05\n",
            "0.0009952310803503918 0.014196346075477304 1.0\n",
            "repr, std, cov, closslb 0.005556317046284676 0.474853515625 8.847331628203392e-05 0.003990587778389454 0.00012879213318228722\n",
            "0.0009774859767857451 0.013763223933315463 1.0\n",
            "repr, std, cov, closslb 0.006365253124386072 0.474853515625 9.53224953263998e-05 0.00408148905262351 5.147951378603466e-05\n",
            "0.0009648671673282939 0.013517823805744966 1.0\n",
            "repr, std, cov, closslb 0.008779099211096764 0.47607421875 7.568090222775936e-05 0.0032202978618443012 1.0306313924957067e-05\n",
            "0.000950509290710088 0.013131626889026665 1.0\n",
            "repr, std, cov, closslb 0.0048599750734865665 0.47607421875 7.124943658709526e-05 0.004046296700835228 2.590175427030772e-05\n",
            "0.000949559730979109 0.0130270450410103 1.0\n",
            "25\n",
            "repr, std, cov, closslb 0.019562941044569016 0.47509765625 8.894572965800762e-05 0.01063495222479105 0.015337437391281128\n",
            "0.0009571828497412758 0.012975066871210993 1.0\n",
            "repr, std, cov, closslb 0.012496549636125565 0.474853515625 8.134543895721436e-05 0.00725811580196023 0.015338906086981297\n",
            "0.0009600572707962314 0.01292329609534693 1.0\n",
            "repr, std, cov, closslb 0.007461839355528355 0.476806640625 5.865050479769707e-05 0.003512290073558688 1.9006172806257382e-05\n",
            "0.0009755339333850418 0.013131626889026665 1.0\n",
            "repr, std, cov, closslb 0.012768931686878204 0.476806640625 6.691459566354752e-05 0.007780866697430611 0.00012013026571366936\n",
            "0.0009774859767857451 0.013343316092145834 1.0\n",
            "repr, std, cov, closslb 0.0068967305123806 0.476318359375 6.0353195294737816e-05 0.00895081739872694 0.0029430047143250704\n",
            "0.000969701161490105 0.013131626889026665 1.0\n",
            "repr, std, cov, closslb 0.009386525489389896 0.4755859375 7.675890810787678e-05 0.012303581461310387 0.015218525193631649\n",
            "0.0009726131750477606 0.01311850838064602 1.0\n",
            "repr, std, cov, closslb 0.0031152782030403614 0.47607421875 6.776582449674606e-05 2.7986163331661373e-05 0.00024154267157427967\n",
            "0.0009716415335142464 0.012975066871210993 1.0\n",
            "repr, std, cov, closslb 0.009141894988715649 0.475341796875 7.419846951961517e-05 0.011177458800375462 0.015516682527959347\n",
            "0.0009648671673282939 0.012820373418702544 1.0\n",
            "repr, std, cov, closslb 0.003821574617177248 0.474853515625 8.223927579820156e-05 0.0021192447748035192 0.015611925162374973\n",
            "0.000949559730979109 0.012529013956911519 1.0\n",
            "repr, std, cov, closslb 0.018708955496549606 0.4755859375 7.226737216114998e-05 0.008614322170615196 1.853402136475779e-05\n",
            "0.000949559730979109 0.012429231390401687 1.0\n",
            "repr, std, cov, closslb 0.009479794651269913 0.47607421875 7.577170617878437e-05 0.012819690629839897 0.015317374840378761\n",
            "0.000950509290710088 0.012244276013324586 1.0\n",
            "repr, std, cov, closslb 0.00638971570879221 0.47705078125 6.079697050154209e-05 0.003968728706240654 8.894121856428683e-05\n",
            "0.0009562266231181578 0.012342573747696787 1.0\n",
            "repr, std, cov, closslb 0.009687847457826138 0.476318359375 6.235972978174686e-05 0.010899340733885765 0.0002619631413836032\n",
            "0.000969701161490105 0.012516497459452068 1.0\n",
            "repr, std, cov, closslb 0.008662912994623184 0.476318359375 6.359908729791641e-05 0.003882939927279949 0.00013701060379389673\n",
            "0.0009726131750477606 0.01265486940822461 1.0\n",
            "repr, std, cov, closslb 0.007309670560061932 0.477294921875 5.680695176124573e-05 0.0037439996376633644 2.5782819648156874e-05\n",
            "0.0009794419262252932 0.012884603617798085 1.0\n",
            "repr, std, cov, closslb 0.005479869432747364 0.47705078125 5.914061330258846e-05 0.003920565824955702 0.01525201927870512\n",
            "0.0009873049409263924 0.01311850838064602 1.0\n",
            "repr, std, cov, closslb 0.0034864344634115696 0.476318359375 6.321817636489868e-05 3.4674119433475425e-06 0.00018343760166317225\n",
            "0.0009853332890150735 0.013290075994538127 1.0\n",
            "repr, std, cov, closslb 0.006022735498845577 0.477294921875 5.541485734283924e-05 0.0038312901742756367 7.554158946732059e-05\n",
            "0.0009814017895196697 0.013329986106039795 1.0\n",
            "repr, std, cov, closslb 0.003275836817920208 0.4755859375 7.197260856628418e-05 4.796392749994993e-05 2.7148318622494116e-05\n",
            "0.0009639032640642298 0.013014031010000301 1.0\n",
            "repr, std, cov, closslb 0.0034813699312508106 0.4755859375 8.018803782761097e-05 0.004390989895910025 0.00011149610509164631\n",
            "0.0009552713517663915 0.012858873012899277 1.0\n",
            "repr, std, cov, closslb 0.0031991833820939064 0.475341796875 8.058035746216774e-05 2.3929956114443485e-06 0.00022590196749661118\n",
            "0.0009382387355186484 0.012554084513839298 1.0\n",
            "repr, std, cov, closslb 0.005851292051374912 0.475341796875 8.127978071570396e-05 0.003763645887374878 1.1231029020564165e-05\n",
            "0.0009354296393761724 0.012441660621792087 1.0\n",
            "repr, std, cov, closslb 0.008696060627698898 0.47607421875 6.989692337810993e-05 0.012200986966490746 0.009431101381778717\n",
            "0.0009363650690155485 0.012416814575825863 1.0\n",
            "repr, std, cov, closslb 0.007379484828561544 0.476806640625 5.8345263823866844e-05 0.0075906869024038315 0.0001421970664523542\n",
            "0.0009419973236470289 0.012566638598353136 1.0\n",
            "repr, std, cov, closslb 0.0025627664290368557 0.4765625 6.399303674697876e-05 2.0523762032098603e-06 0.02991880662739277\n",
            "0.0009476634564028472 0.01279477108176793 1.0\n",
            "repr, std, cov, closslb 0.010156664997339249 0.477294921875 5.709961988031864e-05 0.007721154950559139 0.015515883453190327\n",
            "0.0009552713517663915 0.0130270450410103 1.0\n",
            "repr, std, cov, closslb 0.0033291045110672712 0.476318359375 7.049948908388615e-05 2.6287023501936346e-05 8.094812801573426e-05\n",
            "0.0009571828497412758 0.013210613887593743 1.0\n",
            "repr, std, cov, closslb 0.008514591492712498 0.4765625 6.241211667656898e-05 0.004167723469436169 4.6806700993329287e-05\n",
            "0.0009524112598007987 0.01314475851591569 1.0\n",
            "repr, std, cov, closslb 0.01794501394033432 0.476318359375 6.517511792480946e-05 0.01187925785779953 1.998461812036112e-05\n",
            "0.0009457709686944897 0.01289748822141588 1.0\n",
            "repr, std, cov, closslb 0.003177349455654621 0.475341796875 8.115940727293491e-05 4.3997961256536655e-06 0.015377894975244999\n",
            "0.0009316972564391569 0.012667524277632833 1.0\n",
            "repr, std, cov, closslb 0.003680095076560974 0.475830078125 8.099828846752644e-05 7.423484930768609e-06 0.000815275008790195\n",
            "0.0009289077455503618 0.012479022941080983 1.0\n",
            "repr, std, cov, closslb 0.006800048053264618 0.475830078125 7.591699250042439e-05 0.003869558684527874 0.00015323670231737196\n",
            "0.0009261265864850209 0.012342573747696787 1.0\n",
            "repr, std, cov, closslb 0.003697986714541912 0.476318359375 6.809760816395283e-05 1.3857250451110303e-05 5.99220693402458e-05\n",
            "0.0009289077455503618 0.012317925578613984 1.0\n",
            "repr, std, cov, closslb 0.0032896471675485373 0.476318359375 7.664854638278484e-05 1.2112357126170537e-06 9.499584848526865e-06\n",
            "0.0009261265864850209 0.012441660621792087 1.0\n",
            "repr, std, cov, closslb 0.003721097018569708 0.476318359375 6.48892018944025e-05 1.2425371096469462e-05 0.00015795006765984\n",
            "0.0009307664899492078 0.012529013956911519 1.0\n",
            "repr, std, cov, closslb 0.007115709595382214 0.47607421875 7.207063026726246e-05 0.009346634149551392 0.000274024554528296\n",
            "0.0009307664899492078 0.012579205236951487 1.0\n",
            "26\n",
            "repr, std, cov, closslb 0.006055965553969145 0.4765625 7.336214184761047e-05 0.003636582987383008 0.00021280208602547646\n",
            "0.0009326289536955959 0.012846026985913365 1.0\n",
            "repr, std, cov, closslb 0.006189185194671154 0.47607421875 7.607950828969479e-05 0.0036608788650482893 9.52467235038057e-06\n",
            "0.0009316972564391569 0.013001029980020283 1.0\n",
            "repr, std, cov, closslb 0.0066968416795134544 0.47607421875 7.138494402170181e-05 0.007910211570560932 3.517998266033828e-05\n",
            "0.0009335615826492914 0.013105402977668355 1.0\n",
            "repr, std, cov, closslb 0.003795656841248274 0.4755859375 7.331883534789085e-05 4.931364856020082e-06 1.541018718853593e-05\n",
            "0.0009252013850999211 0.012936219391442277 1.0\n",
            "repr, std, cov, closslb 0.008883647620677948 0.475830078125 7.33246561139822e-05 0.007825723849236965 0.00045100628631189466\n",
            "0.000922431322914777 0.012705564865706084 1.0\n",
            "repr, std, cov, closslb 0.006514142267405987 0.475830078125 7.514399476349354e-05 0.0034269546158611774 0.015478311106562614\n",
            "0.0009178329705494052 0.01254154297086843 1.0\n",
            "repr, std, cov, closslb 0.010893205180764198 0.474853515625 8.828053250908852e-05 0.003815318923443556 2.439923628116958e-05\n",
            "0.0009105232389341535 0.012293326632023307 1.0\n",
            "repr, std, cov, closslb 0.019475195556879044 0.4755859375 7.569673471152782e-05 0.003813649294897914 1.3248038158053532e-05\n",
            "0.0009032717228962471 0.012158907895006163 1.0\n",
            "repr, std, cov, closslb 0.007411318831145763 0.4755859375 7.170927710831165e-05 0.01030174270272255 0.015834897756576538\n",
            "0.0009014678856570475 0.012074134970361692 1.0\n",
            "repr, std, cov, closslb 0.005358763039112091 0.475830078125 6.793113425374031e-05 0.003768256865441799 0.030911799520254135\n",
            "0.0009032717228962471 0.012098295314437383 1.0\n",
            "repr, std, cov, closslb 0.008961614221334457 0.475830078125 6.879633292555809e-05 0.003941206261515617 0.015216972678899765\n",
            "0.0009105232389341535 0.012441660621792087 1.0\n",
            "repr, std, cov, closslb 0.010911338031291962 0.47607421875 7.133861072361469e-05 0.011681850999593735 0.0003124225477222353\n",
            "0.0009096136253088447 0.012479022941080983 1.0\n",
            "repr, std, cov, closslb 0.009070785716176033 0.476806640625 6.070500239729881e-05 0.0037667301949113607 6.229517748579383e-05\n",
            "0.0009096136253088447 0.012305619958655329 1.0\n",
            "repr, std, cov, closslb 0.007987197488546371 0.47607421875 6.226799450814724e-05 0.00777593906968832 2.6564022846287116e-05\n",
            "0.0009123451959352606 0.012354916321444483 1.0\n",
            "repr, std, cov, closslb 0.004376513417810202 0.476318359375 6.411923095583916e-05 4.414593604451511e-06 0.03230762109160423\n",
            "0.0009178329705494052 0.012392018147512692 1.0\n",
            "repr, std, cov, closslb 0.004724991042166948 0.4755859375 7.099099457263947e-05 4.024188456241973e-06 3.471344098215923e-05\n",
            "0.0009150849694709991 0.012305619958655329 1.0\n",
            "repr, std, cov, closslb 0.005560382269322872 0.4755859375 7.165386341512203e-05 0.003298611380159855 0.04461691156029701\n",
            "0.0009032717228962471 0.011977975114536467 1.0\n",
            "repr, std, cov, closslb 0.007541173603385687 0.47509765625 7.389741949737072e-05 0.003953992854803801 0.00043598562479019165\n",
            "0.0009023693535427044 0.011894463668397871 1.0\n",
            "repr, std, cov, closslb 0.006680070422589779 0.475830078125 6.673671305179596e-05 0.010080519132316113 7.526573608629405e-05\n",
            "0.0009032717228962471 0.011752653559142607 1.0\n",
            "repr, std, cov, closslb 0.00814781803637743 0.475830078125 6.971252150833607e-05 0.003806520253419876 1.9896207959391177e-05\n",
            "0.0009050791696137623 0.011740912646496113 1.0\n",
            "repr, std, cov, closslb 0.007956273853778839 0.47607421875 6.775232031941414e-05 0.003670772071927786 0.016129011288285255\n",
            "0.0009059842487833759 0.011659054019748268 1.0\n",
            "repr, std, cov, closslb 0.013763907365500927 0.4765625 5.9967394918203354e-05 0.011875665746629238 1.5587016605422832e-05\n",
            "0.0009105232389341535 0.011776170618914448 1.0\n",
            "repr, std, cov, closslb 0.005052858032286167 0.476806640625 5.793711170554161e-05 3.1429497084900504e-06 9.698470239527524e-05\n",
            "0.0009123451959352606 0.01187071037693363 1.0\n",
            "repr, std, cov, closslb 0.005361529067158699 0.4755859375 7.334374822676182e-05 6.678027602902148e-06 0.00022081607312429696\n",
            "0.0009032717228962471 0.011729183463033081 1.0\n",
            "repr, std, cov, closslb 0.004570179618895054 0.476318359375 6.374879740178585e-05 3.946298875234788e-06 0.0003143803623970598\n",
            "0.0009123451959352606 0.011906358132066268 1.0\n",
            "repr, std, cov, closslb 0.006075088866055012 0.476318359375 6.756908260285854e-05 7.035717317194212e-06 0.00012980001338291913\n",
            "0.0009169160544949104 0.011954055050380658 1.0\n",
            "repr, std, cov, closslb 0.01143806055188179 0.475830078125 6.615766324102879e-05 0.0028702777344733477 1.5553647244814783e-05\n",
            "0.000922431322914777 0.012074134970361692 1.0\n",
            "repr, std, cov, closslb 0.009235912933945656 0.476318359375 6.018020212650299e-05 0.003137753577902913 0.01604868471622467\n",
            "0.0009233537542376916 0.012086209105332053 1.0\n",
            "repr, std, cov, closslb 0.009090181440114975 0.47509765625 7.518171332776546e-05 0.004571619443595409 0.0004627638263627887\n",
            "0.0009123451959352606 0.011799734736322893 1.0\n",
            "repr, std, cov, closslb 0.00798015296459198 0.4755859375 6.752600893378258e-05 0.003885991172865033 0.01560990046709776\n",
            "0.0009096136253088447 0.011787946789533361 1.0\n",
            "repr, std, cov, closslb 0.0054988861083984375 0.4755859375 7.765088230371475e-05 2.480167722751503e-06 0.00025898998137563467\n",
            "0.0009059842487833759 0.011764406212701748 1.0\n",
            "repr, std, cov, closslb 0.008571142330765724 0.4755859375 6.898143328726292e-05 0.004607912618666887 0.015127411112189293\n",
            "0.0009005673183387088 0.011670713073768015 1.0\n",
            "repr, std, cov, closslb 0.004408455453813076 0.47607421875 6.738957017660141e-05 4.209586222714279e-06 0.0001568976731505245\n",
            "0.0008996676506880209 0.011520050549693003 1.0\n",
            "repr, std, cov, closslb 0.013565091416239738 0.475830078125 6.463378667831421e-05 0.011480848304927349 8.363797860511113e-06\n",
            "0.0008996676506880209 0.011543102170842937 1.0\n",
            "repr, std, cov, closslb 0.005374306812882423 0.475830078125 7.431837730109692e-05 2.7902582587557845e-05 0.0007452250574715436\n",
            "0.0008880534332683539 0.011348624398997061 1.0\n",
            "repr, std, cov, closslb 0.014474302530288696 0.4755859375 7.080752402544022e-05 0.013109154999256134 1.5165396689553745e-05\n",
            "0.0008809808694517494 0.011213321983454393 1.0\n",
            "27\n",
            "repr, std, cov, closslb 0.0037535030860453844 0.476318359375 6.72750174999237e-05 3.271392415626906e-06 0.01590746082365513\n",
            "0.0008783432039319986 0.01126950083878079 1.0\n",
            "repr, std, cov, closslb 0.01318763941526413 0.47705078125 5.3730327636003494e-05 0.008067053742706776 3.512481271172874e-05\n",
            "0.000881861850321201 0.011439731791990206 1.0\n",
            "repr, std, cov, closslb 0.0036594511475414038 0.4765625 6.903428584337234e-05 6.71931911710999e-06 0.03042188100516796\n",
            "0.0008916109788751283 0.011717465997036047 1.0\n",
            "repr, std, cov, closslb 0.00827837735414505 0.477294921875 5.49759715795517e-05 0.003856954164803028 0.00027783465338870883\n",
            "0.0008916109788751283 0.011799734736322893 1.0\n",
            "repr, std, cov, closslb 0.0039047864265739918 0.4765625 5.852058529853821e-05 1.4274389286583755e-05 0.00017107470193877816\n",
            "0.0009014678856570475 0.01205002287458964 1.0\n",
            "repr, std, cov, closslb 0.009418404661118984 0.476806640625 6.422866135835648e-05 0.0038801308255642653 5.9709607739932835e-05\n",
            "0.0008951827760238373 0.012146761133872292 1.0\n",
            "repr, std, cov, closslb 0.006606456823647022 0.476318359375 6.548920646309853e-05 0.003980792127549648 7.88628494774457e-06\n",
            "0.0008774657381938049 0.011942112937443216 1.0\n",
            "repr, std, cov, closslb 0.008984295651316643 0.476318359375 6.420165300369263e-05 0.003958466462790966 6.23278392595239e-05\n",
            "0.0008704774960478118 0.011918264490198333 1.0\n",
            "repr, std, cov, closslb 0.006006188690662384 0.4765625 6.736535578966141e-05 5.406992386269849e-06 0.00014795151946600527\n",
            "0.0008670042734594495 0.011942112937443216 1.0\n",
            "repr, std, cov, closslb 0.005480989348143339 0.476806640625 5.7509634643793106e-05 4.3402010305726435e-06 0.00011731252743629739\n",
            "0.0008696078881596523 0.012134626507364929 1.0\n",
            "repr, std, cov, closslb 0.010125983506441116 0.475830078125 6.567640230059624e-05 0.011533437296748161 8.265551150543615e-05\n",
            "0.0008670042734594495 0.012330243504192597 1.0\n",
            "repr, std, cov, closslb 0.011843012645840645 0.475830078125 7.665297016501427e-05 0.03966139256954193 0.015484407544136047\n",
            "0.0008609594470182032 0.012305619958655329 1.0\n",
            "repr, std, cov, closslb 0.007745613344013691 0.4755859375 7.400335744023323e-05 0.004303009249269962 2.1855830709682778e-05\n",
            "0.0008489959354063262 0.012146761133872292 1.0\n",
            "repr, std, cov, closslb 0.007986883632838726 0.476318359375 6.567477248609066e-05 0.004030655603855848 5.01178546983283e-05\n",
            "0.0008464540330984777 0.012158907895006163 1.0\n",
            "repr, std, cov, closslb 0.010145821608603 0.4755859375 6.980961188673973e-05 0.0038852421566843987 0.00014600015128962696\n",
            "0.0008346920823016482 0.012134626507364929 1.0\n",
            "repr, std, cov, closslb 0.014922413975000381 0.475830078125 6.858888082206249e-05 0.00373425823636353 0.01547788642346859\n",
            "0.0008388738979850741 0.012232043969355233 1.0\n",
            "repr, std, cov, closslb 0.004615345969796181 0.476806640625 7.036374881863594e-05 7.331575761782005e-05 6.228788697626442e-05\n",
            "0.0008422344301767363 0.012441660621792087 1.0\n",
            "repr, std, cov, closslb 0.005334783811122179 0.47705078125 5.9918733313679695e-05 9.133719140663743e-05 9.377072274219245e-05\n",
            "0.0008388738979850741 0.012554084513839298 1.0\n",
            "repr, std, cov, closslb 0.01755654439330101 0.4755859375 6.998958997428417e-05 0.01953335665166378 2.099851735692937e-05\n",
            "0.0008464540330984777 0.01254154297086843 1.0\n",
            "repr, std, cov, closslb 0.008782119490206242 0.476318359375 6.805546581745148e-05 0.004331896081566811 2.5504328732495196e-05\n",
            "0.0008439197412715198 0.01254154297086843 1.0\n",
            "repr, std, cov, closslb 0.006063177715986967 0.476318359375 6.799958646297455e-05 0.0038415109738707542 7.715506217209622e-05\n",
            "0.0008371986634594918 0.012466556384696289 1.0\n",
            "repr, std, cov, closslb 0.012913074344396591 0.475830078125 7.706531323492527e-05 0.007840150967240334 0.001221172045916319\n",
            "0.0008363623011583336 0.01254154297086843 1.0\n",
            "repr, std, cov, closslb 0.003594985231757164 0.476806640625 5.948287434875965e-05 9.161787602351978e-06 9.566268272465095e-05\n",
            "0.0008346920823016482 0.012503993465986083 1.0\n",
            "repr, std, cov, closslb 0.008281514048576355 0.476318359375 6.935675628483295e-05 0.00449711037799716 9.213999874191359e-05\n",
            "0.0008330251988786921 0.012566638598353136 1.0\n",
            "repr, std, cov, closslb 0.012332949787378311 0.476318359375 7.30385072529316e-05 0.004728769417852163 4.891551361652091e-05\n",
            "0.0008380358621229513 0.012642227181043568 1.0\n",
            "repr, std, cov, closslb 0.011378621682524681 0.475830078125 7.287412881851196e-05 0.007877741940319538 4.093032475793734e-05\n",
            "0.0008355267743839497 0.012667524277632833 1.0\n",
            "repr, std, cov, closslb 0.003965330310165882 0.4755859375 7.946137338876724e-05 1.0541160918364767e-05 6.197753100423142e-05\n",
            "0.0008239166639403097 0.012317925578613984 1.0\n",
            "repr, std, cov, closslb 0.016782909631729126 0.475830078125 7.502036169171333e-05 0.007778773084282875 0.01531046163290739\n",
            "0.0008239166639403097 0.012183237869704069 1.0\n",
            "repr, std, cov, closslb 0.008602770045399666 0.4755859375 6.824685260653496e-05 0.004244632553309202 0.0005682241171598434\n",
            "0.0008181722479229614 0.011977975114536467 1.0\n",
            "repr, std, cov, closslb 0.008967896923422813 0.4755859375 7.19134695827961e-05 0.008071459829807281 0.01556490920484066\n",
            "0.0008140936306882064 0.011894463668397871 1.0\n",
            "repr, std, cov, closslb 0.008621782064437866 0.4765625 6.1016762629151344e-05 0.0041613648645579815 0.031920190900564194\n",
            "0.0008247405806042499 0.012013944985783391 1.0\n",
            "repr, std, cov, closslb 0.005426971707493067 0.4765625 5.690031684935093e-05 0.004321656189858913 0.0005619576550088823\n",
            "0.0008263908865060389 0.012146761133872292 1.0\n",
            "repr, std, cov, closslb 0.007751932367682457 0.476806640625 6.0631195083260536e-05 0.007966499775648117 0.0005369719583541155\n",
            "0.0008263908865060389 0.012404410165660204 1.0\n",
            "repr, std, cov, closslb 0.015039891004562378 0.47705078125 5.894969217479229e-05 0.007801788859069347 0.00011726593947969377\n",
            "0.0008255653211848541 0.012466556384696289 1.0\n",
            "repr, std, cov, closslb 0.005020724609494209 0.47705078125 5.571567453444004e-05 0.0036668942775577307 0.0003183614753652364\n",
            "0.0008263908865060389 0.012642227181043568 1.0\n",
            "repr, std, cov, closslb 0.007173809222877026 0.475830078125 7.00152013450861e-05 0.0036097285337746143 0.01566041074693203\n",
            "0.0008247405806042499 0.012756463409393062 1.0\n",
            "28\n",
            "repr, std, cov, closslb 0.005477402359247208 0.47607421875 7.054931484162807e-05 0.007632337044924498 0.00016350307851098478\n",
            "0.0008230935703699399 0.012858873012899277 1.0\n",
            "repr, std, cov, closslb 0.006214306689798832 0.47607421875 6.723240949213505e-05 0.004906309302896261 6.905292684677988e-05\n",
            "0.0008181722479229614 0.012846026985913365 1.0\n",
            "repr, std, cov, closslb 0.0033480352722108364 0.475341796875 7.965322583913803e-05 8.02824979473371e-06 0.0243094302713871\n",
            "0.0008027813457279515 0.012466556384696289 1.0\n",
            "repr, std, cov, closslb 0.007626983802765608 0.474853515625 7.733912207186222e-05 0.0028099913615733385 2.1832518541486934e-05\n",
            "0.0007940035056994781 0.012244276013324586 1.0\n",
            "repr, std, cov, closslb 0.004301233682781458 0.475830078125 7.382268086075783e-05 1.3615144780487753e-05 0.00015438836999237537\n",
            "0.0007845371079676104 0.01193018275468853 1.0\n",
            "repr, std, cov, closslb 0.01962769776582718 0.4755859375 7.599452510476112e-05 0.014337352477014065 2.8732431019307114e-05\n",
            "0.00078925611437455 0.011942112937443216 1.0\n",
            "repr, std, cov, closslb 0.028320221230387688 0.475830078125 7.100100629031658e-05 0.00359332375228405 0.00028981902869418263\n",
            "0.0007955923067143825 0.011989953089651003 1.0\n",
            "repr, std, cov, closslb 0.00433248421177268 0.476806640625 5.692918784916401e-05 6.584788934560493e-06 0.00010845319047803059\n",
            "0.0007979814712070378 0.01206207289746423 1.0\n",
            "repr, std, cov, closslb 0.005070854909718037 0.475830078125 6.546825170516968e-05 2.2322066797642037e-05 0.0029303054325282574\n",
            "0.000807610091590178 0.012342573747696787 1.0\n",
            "repr, std, cov, closslb 0.024989061057567596 0.475341796875 7.894029840826988e-05 0.013239162042737007 0.00013067605323158205\n",
            "0.0008068032883018762 0.012268776809627246 1.0\n",
            "repr, std, cov, closslb 0.005410825368016958 0.47509765625 7.766298949718475e-05 1.275054910365725e-05 8.264958159998059e-05\n",
            "0.00080197936636159 0.012098295314437383 1.0\n",
            "repr, std, cov, closslb 0.00547297578305006 0.475830078125 7.14804045855999e-05 0.004225736018270254 0.015707405284047127\n",
            "0.0007987794526782447 0.01205002287458964 1.0\n",
            "repr, std, cov, closslb 0.011413432657718658 0.4755859375 7.362291216850281e-05 0.007080405484884977 0.00018623069627210498\n",
            "0.0007987794526782447 0.011894463668397871 1.0\n",
            "repr, std, cov, closslb 0.005042742937803268 0.475341796875 6.868108175694942e-05 1.4347609976539388e-05 6.016176848788746e-05\n",
            "0.0007955923067143825 0.01187071037693363 1.0\n",
            "repr, std, cov, closslb 0.008134440518915653 0.475830078125 6.444333121180534e-05 0.0045626056380569935 7.402557912428165e-06\n",
            "0.0008027813457279515 0.011823346005530273 1.0\n",
            "repr, std, cov, closslb 0.010737389326095581 0.4755859375 7.217866368591785e-05 0.007500132545828819 0.000230090445256792\n",
            "0.0007971842869201178 0.011682383786841782 1.0\n",
            "repr, std, cov, closslb 0.004773313645273447 0.4755859375 6.859004497528076e-05 0.003609736915677786 3.948237281292677e-05\n",
            "0.0007979814712070378 0.011624146695597245 1.0\n",
            "repr, std, cov, closslb 0.012069329619407654 0.475830078125 6.855628453195095e-05 0.003708231495693326 7.825459761079401e-05\n",
            "0.0007963878990210968 0.011624146695597245 1.0\n",
            "repr, std, cov, closslb 0.0122159942984581 0.475830078125 6.569293327629566e-05 0.008306807838380337 0.00011969836486969143\n",
            "0.0007900453704889244 0.011439731791990206 1.0\n",
            "repr, std, cov, closslb 0.01087874174118042 0.47607421875 6.235088221728802e-05 0.004158321302384138 0.00013206132280174643\n",
            "0.0007940035056994781 0.011416886601899807 1.0\n",
            "repr, std, cov, closslb 0.006224378943443298 0.476318359375 6.070174276828766e-05 0.0032580250408500433 0.015465613454580307\n",
            "0.0008011781881734167 0.011416886601899807 1.0\n",
            "repr, std, cov, closslb 0.0047560217790305614 0.4765625 6.143958307802677e-05 1.6969315765891224e-05 1.6280708223348483e-05\n",
            "0.0008059972910108655 0.011589343884323281 1.0\n",
            "repr, std, cov, closslb 0.018110614269971848 0.47607421875 6.190105341374874e-05 0.012117690406739712 2.6638348572305404e-05\n",
            "0.0008124678824554133 0.011787946789533361 1.0\n",
            "repr, std, cov, closslb 0.003891721833497286 0.47705078125 6.050383672118187e-05 2.481330739101395e-06 0.0036465723533183336\n",
            "0.0008132803503378686 0.011954055050380658 1.0\n",
            "repr, std, cov, closslb 0.0039734914898872375 0.476318359375 6.581097841262817e-05 1.523598166386364e-05 7.832341361790895e-05\n",
            "0.0008214498492216475 0.012281045586436872 1.0\n",
            "repr, std, cov, closslb 0.010706598870456219 0.4765625 5.4780859500169754e-05 0.00833058450371027 5.998287451802753e-05\n",
            "0.0008230935703699399 0.012354916321444483 1.0\n",
            "repr, std, cov, closslb 0.004452839028090239 0.475830078125 6.917142309248447e-05 3.851024303003214e-06 2.1519288566196337e-05\n",
            "0.0008165383546752564 0.012281045586436872 1.0\n",
            "repr, std, cov, closslb 0.010591714642941952 0.475830078125 6.296392530202866e-05 0.003468611277639866 0.015407622791826725\n",
            "0.000807610091590178 0.012086209105332053 1.0\n",
            "repr, std, cov, closslb 0.004173042718321085 0.475341796875 7.450953125953674e-05 1.2913911632495001e-05 9.753070480655879e-05\n",
            "0.0007932102954040742 0.01170576023679925 1.0\n",
            "repr, std, cov, closslb 0.004065871238708496 0.475341796875 7.563503459095955e-05 4.808009180123918e-06 9.981137554859743e-05\n",
            "0.0007861069667206535 0.011497044962722597 1.0\n",
            "repr, std, cov, closslb 0.010780527256429195 0.475830078125 6.918399594724178e-05 0.007824123837053776 0.00011671658285195008\n",
            "0.0007814067892434928 0.011258242596184607 1.0\n",
            "repr, std, cov, closslb 0.007871052250266075 0.4765625 5.997251719236374e-05 0.007871379144489765 0.00016318183043040335\n",
            "0.0007806261630804125 0.011224535305437846 1.0\n",
            "repr, std, cov, closslb 0.012672366574406624 0.47607421875 6.886105984449387e-05 0.0032995175570249557 0.00017241056775674224\n",
            "0.0007821881960327362 0.01117974918547068 1.0\n",
            "repr, std, cov, closslb 0.006552991922944784 0.476318359375 7.415376603603363e-05 0.004024849273264408 0.015592207200825214\n",
            "0.0007829703842287688 0.011235759840743282 1.0\n",
            "repr, std, cov, closslb 0.0206698477268219 0.476318359375 6.019091233611107e-05 0.011598220095038414 0.0057982285507023335\n",
            "0.0007924178775265478 0.011439731791990206 1.0\n",
            "repr, std, cov, closslb 0.016383729875087738 0.476806640625 6.331596523523331e-05 0.011621156707406044 0.00014446713612414896\n",
            "0.0007900453704889244 0.011497044962722597 1.0\n",
            "29\n",
            "repr, std, cov, closslb 0.04222344607114792 0.4765625 7.317960262298584e-05 0.0036950018256902695 0.015406670048832893\n",
            "0.0007987794526782447 0.011752653559142607 1.0\n",
            "repr, std, cov, closslb 0.005934614688158035 0.4765625 7.211603224277496e-05 2.9379121770034544e-05 4.567638097796589e-05\n",
            "0.0007955923067143825 0.011894463668397871 1.0\n",
            "repr, std, cov, closslb 0.008827836252748966 0.4775390625 5.892571061849594e-05 0.004438323900103569 0.00012697797501459718\n",
            "0.000807610091590178 0.01225652028933791 1.0\n",
            "repr, std, cov, closslb 0.013973020948469639 0.478271484375 4.3569132685661316e-05 0.008284559473395348 1.4016493878443725e-05\n",
            "0.0008084177016817681 0.012466556384696289 1.0\n",
            "repr, std, cov, closslb 0.0061003901064395905 0.477294921875 5.92479482293129e-05 8.832888852339238e-05 0.0004044118686579168\n",
            "0.0008165383546752564 0.012833193792121245 1.0\n",
            "repr, std, cov, closslb 0.004952211398631334 0.47705078125 7.88751058280468e-05 2.3733640773571096e-05 0.00025598867796361446\n",
            "0.000807610091590178 0.012858873012899277 1.0\n",
            "repr, std, cov, closslb 0.009314197115600109 0.4755859375 8.251890540122986e-05 0.004279096145182848 0.01528721023350954\n",
            "0.00078925611437455 0.012667524277632833 1.0\n",
            "repr, std, cov, closslb 0.004584775771945715 0.4755859375 9.52982809394598e-05 2.2677537344861776e-05 0.015657566487789154\n",
            "0.0007806261630804125 0.01254154297086843 1.0\n",
            "repr, std, cov, closslb 0.0036966411862522364 0.476806640625 8.464953862130642e-05 3.097741864621639e-05 0.015956813469529152\n",
            "0.000767474201450553 0.012491501964022062 1.0\n",
            "repr, std, cov, closslb 0.006033397279679775 0.476318359375 7.153535261750221e-05 3.951436156057753e-05 1.79059206857346e-05\n",
            "0.0007667074939565966 0.012667524277632833 1.0\n",
            "repr, std, cov, closslb 0.0036162114702165127 0.476806640625 7.058517076075077e-05 4.361914761830121e-06 0.015328309498727322\n",
            "0.0007667074939565966 0.012962104766444549 1.0\n",
            "repr, std, cov, closslb 0.0044278898276388645 0.477783203125 6.534182466566563e-05 1.910868741106242e-05 0.00024671346182003617\n",
            "0.0007705487061722279 0.01318423223888374 1.0\n",
            "repr, std, cov, closslb 0.017969664186239243 0.478759765625 4.7156354412436485e-05 0.011784381233155727 0.0002500653499737382\n",
            "0.0007775114491044771 0.013599133786495838 1.0\n",
            "repr, std, cov, closslb 0.006163363344967365 0.477294921875 6.184587255120277e-05 0.004412914626300335 3.360450500622392e-05\n",
            "0.0007806261630804125 0.013776987157248777 1.0\n",
            "repr, std, cov, closslb 0.004040364176034927 0.4775390625 6.469734944403172e-05 8.509646249876823e-06 2.9642291337950155e-05\n",
            "0.0007821881960327362 0.014055160300682597 1.0\n",
            "repr, std, cov, closslb 0.00406626844778657 0.476806640625 6.708758883178234e-05 2.085050437017344e-05 1.784888627298642e-05\n",
            "0.0007759587556344527 0.01413970237120531 1.0\n",
            "repr, std, cov, closslb 0.008341187611222267 0.47607421875 8.034147322177887e-05 0.003277732990682125 0.01555276196449995\n",
            "0.0007628854303180342 0.014111465329081821 1.0\n",
            "repr, std, cov, closslb 0.011941829696297646 0.475830078125 8.150655776262283e-05 0.016073793172836304 0.00010256704990752041\n",
            "0.0007545438235990682 0.014027092089411688 1.0\n",
            "repr, std, cov, closslb 0.0253000408411026 0.476806640625 7.722876034677029e-05 0.011019679717719555 0.015072619542479515\n",
            "0.0007470397198117271 0.014027092089411688 1.0\n",
            "repr, std, cov, closslb 0.005819460842758417 0.476318359375 7.995613850653172e-05 0.004230620339512825 0.017321821302175522\n",
            "0.0007448030754314037 0.01408328467644426 1.0\n",
            "repr, std, cov, closslb 0.002675211988389492 0.47607421875 7.523619569838047e-05 4.022988377982983e-06 0.00018810536130331457\n",
            "0.0007410902060843135 0.013971123711923264 1.0\n",
            "repr, std, cov, closslb 0.009907836094498634 0.476318359375 6.814301013946533e-05 0.007810172624886036 2.8757945983670652e-05\n",
            "0.0007388713746074961 0.01399907993047082 1.0\n",
            "repr, std, cov, closslb 0.010203156620264053 0.476318359375 6.745732389390469e-05 0.00802531372755766 0.00010223231220152229\n",
            "0.0007293329491864011 0.013735738720136474 1.0\n",
            "repr, std, cov, closslb 0.005965851247310638 0.475341796875 7.752585224807262e-05 0.0032897251658141613 0.0004532817401923239\n",
            "0.0007256971989590156 0.013612732920282332 1.0\n",
            "repr, std, cov, closslb 0.004432431422173977 0.475830078125 7.964251562952995e-05 1.3495284292730503e-05 0.000489187310449779\n",
            "0.00072424797875353 0.013423576405506633 1.0\n",
            "repr, std, cov, closslb 0.009773589670658112 0.4755859375 7.903482764959335e-05 0.008947174996137619 0.015422368422150612\n",
            "0.0007249722267322834 0.013329986106039795 1.0\n",
            "repr, std, cov, closslb 0.007189134135842323 0.474853515625 8.429051376879215e-05 0.004475241526961327 1.966206582437735e-05\n",
            "0.0007199176596217494 0.01304007208605131 1.0\n",
            "repr, std, cov, closslb 0.01372468750923872 0.4755859375 9.43448394536972e-05 0.022444572299718857 1.9370945665286854e-05\n",
            "0.0007199176596217494 0.012884603617798085 1.0\n",
            "repr, std, cov, closslb 0.003860750235617161 0.4755859375 7.415539585053921e-05 1.548081172586535e-06 7.337945135077462e-05\n",
            "0.0007264228961579745 0.012962104766444549 1.0\n",
            "repr, std, cov, closslb 0.017266806215047836 0.475830078125 6.816210225224495e-05 0.0038772255647927523 0.015182697214186192\n",
            "0.0007322546598989026 0.013014031010000301 1.0\n",
            "repr, std, cov, closslb 0.012445086613297462 0.4755859375 7.51325860619545e-05 0.011977480724453926 0.015157705172896385\n",
            "0.0007403498562280855 0.012988041938082203 1.0\n",
            "repr, std, cov, closslb 0.0090920589864254 0.47607421875 6.904802285134792e-05 0.01198374480009079 0.00021846909658052027\n",
            "0.0007388713746074961 0.012910385709637295 1.0\n",
            "repr, std, cov, closslb 0.006675520911812782 0.47607421875 6.913463585078716e-05 0.003859657561406493 6.701857637381181e-05\n",
            "0.0007403498562280855 0.01292329609534693 1.0\n",
            "repr, std, cov, closslb 0.009501367807388306 0.476318359375 6.255204789340496e-05 0.008648745715618134 0.0002463156415615231\n",
            "0.0007403498562280855 0.013001029980020283 1.0\n",
            "repr, std, cov, closslb 0.01202912162989378 0.475830078125 7.506692782044411e-05 0.00840364396572113 1.4176919648889452e-05\n",
            "0.0007366591863342752 0.012833193792121245 1.0\n",
            "repr, std, cov, closslb 0.014377838000655174 0.4755859375 7.052929140627384e-05 0.0034811091609299183 0.00014477298827841878\n",
            "0.0007366591863342752 0.01274371968970336 1.0\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "for i in range(30):\n",
        "    print(i)\n",
        "    # agent.train_ae(train_loader, optim)\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "    # state = buffer[7][80][0]\n",
        "    # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    # out= agent.deconv(sx_).squeeze(0)\n",
        "    # print(out.shape)\n",
        "    # imshow(state.detach().cpu())\n",
        "    # imshow(out.detach().cpu())\n",
        "\n",
        "# 10 epochs 15m23s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "bf94b35a-c17c-45d0-c2f5-dcdb4b881a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "\n",
        "ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "PraFUAPB3j7v",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9826e8a0-1be7-459e-e531-bd3eecdd1aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[ 0.3467, -0.2373, -0.2641],\n",
            "         [ 0.3155, -0.2761,  0.5294],\n",
            "         [ 0.4189,  0.3734, -0.3161],\n",
            "         [ 0.4592,  0.0187,  0.1814],\n",
            "         [ 0.3679, -0.2665,  0.0648],\n",
            "         [ 0.1917, -0.0190, -0.4969]]], requires_grad=True)\n",
            "tcost icost -0.40725257992744446 0.19674243032932281\n",
            "tcost icost 0.12985597550868988 0.1982341855764389\n",
            "tcost icost -0.3979145884513855 0.20427729189395905\n",
            "tcost icost 0.2041795253753662 0.20084796845912933\n",
            "tcost icost 0.07833603024482727 0.2110314816236496\n",
            "tcost icost -0.2621549665927887 0.2182517647743225\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.2464, -0.1370, -0.1638],\n",
            "         [ 0.2152, -0.3758,  0.4289],\n",
            "         [ 0.3185,  0.2730, -0.4158],\n",
            "         [ 0.3587, -0.0813,  0.0812],\n",
            "         [ 0.2676, -0.3663, -0.0353],\n",
            "         [ 0.0915, -0.1189, -0.5964]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.40725257992744446 0.19684112071990967\n",
            "tcost icost 0.12985605001449585 0.19355930387973785\n",
            "tcost icost -0.3979148268699646 0.20424959063529968\n",
            "tcost icost 0.20417925715446472 0.2052678018808365\n",
            "tcost icost -0.42906734347343445 0.213440403342247\n",
            "tcost icost -0.027437087148427963 0.22317709028720856\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.1461, -0.0369, -0.0636],\n",
            "         [ 0.1149, -0.4752,  0.3285],\n",
            "         [ 0.2181,  0.1727, -0.5152],\n",
            "         [ 0.2583, -0.1769, -0.0113],\n",
            "         [ 0.1890, -0.3942,  0.0053],\n",
            "         [ 0.0178, -0.1920, -0.6709]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.40725257992744446 0.19700489938259125\n",
            "tcost icost 0.12985605001449585 0.20289762318134308\n",
            "tcost icost -0.3979148268699646 0.20902785658836365\n",
            "tcost icost -0.03063921257853508 0.21352313458919525\n",
            "tcost icost 0.16117608547210693 0.21057870984077454\n",
            "tcost icost -0.38722294569015503 0.21846428513526917\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.0459,  0.0633,  0.0365],\n",
            "         [ 0.0147, -0.5741,  0.2281],\n",
            "         [ 0.1178,  0.0725, -0.6140],\n",
            "         [ 0.1612, -0.2572, -0.0916],\n",
            "         [ 0.1188, -0.4597, -0.0098],\n",
            "         [-0.0660, -0.2437, -0.6937]]], requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.013200782239437103 0.20150291919708252\n",
            "tcost icost 0.00482960045337677 0.19952523708343506\n",
            "tcost icost -0.1471417099237442 0.20004770159721375\n",
            "tcost icost -0.044084664434194565 0.2089814841747284\n",
            "tcost icost -0.06327919661998749 0.20457445085048676\n",
            "tcost icost -0.05589313432574272 0.21874426305294037\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.0354,  0.0977,  0.1123],\n",
            "         [-0.0606, -0.6340,  0.1921],\n",
            "         [ 0.0211, -0.0239, -0.7067],\n",
            "         [ 0.0632, -0.3291, -0.1661],\n",
            "         [ 0.0540, -0.5240, -0.0373],\n",
            "         [-0.1403, -0.2954, -0.7224]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.013200782239437103 0.20150291919708252\n",
            "tcost icost 0.004829611629247665 0.19495858252048492\n",
            "tcost icost -0.14714162051677704 0.20439192652702332\n",
            "tcost icost -0.044084664434194565 0.21371273696422577\n",
            "tcost icost -0.06327912211418152 0.19967743754386902\n",
            "tcost icost -0.055893223732709885 0.20926614105701447\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.1031,  0.0964,  0.1704],\n",
            "         [-0.1178, -0.6678,  0.1924],\n",
            "         [-0.0737, -0.1182, -0.7949],\n",
            "         [-0.0354, -0.3955, -0.2371],\n",
            "         [-0.0077, -0.5879, -0.0742],\n",
            "         [-0.2084, -0.3475, -0.7558]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [ 0., -1.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.013200782239437103 0.1966373324394226\n",
            "tcost icost 0.004829611629247665 0.19986476004123688\n",
            "tcost icost -0.14714162051677704 0.1996050775051117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-131-141d7fd857ab>:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "tcost icost -0.7364799976348877 0.3383875787258148\n",
            "tcost icost -0.023083452135324478 0.33739331364631653\n",
            "tcost icost 0.16506972908973694 0.3335411250591278\n",
            "tcost icost -0.3830924332141876 0.3344656825065613\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.2340,  0.2007, -0.0884],\n",
            "         [ 0.0439, -0.5219, -0.0759],\n",
            "         [-0.6936, -0.5166, -0.5505],\n",
            "         [ 0.1952, -0.0674, -0.7419],\n",
            "         [-0.2013,  0.1532, -0.0803],\n",
            "         [-0.1725,  0.1767, -0.0667]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.3426257073879242\n",
            "tcost icost -0.03683022782206535 0.34581977128982544\n",
            "tcost icost -0.21991175413131714 0.33458247780799866\n",
            "tcost icost -0.040731918066740036 0.34413647651672363\n",
            "tcost icost -0.06469881534576416 0.34387311339378357\n",
            "tcost icost -0.0554082952439785 0.35475459694862366\n",
            "3 Parameter containing:\n",
            "tensor([[[ 0.1586,  0.1187, -0.1707],\n",
            "         [-0.0518, -0.6034, -0.1595],\n",
            "         [-0.7610, -0.6116, -0.6491],\n",
            "         [ 0.0969, -0.1659, -0.8373],\n",
            "         [-0.2982,  0.0632, -0.1675],\n",
            "         [-0.2472,  0.1364, -0.0669]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.3426402807235718\n",
            "tcost icost -0.09805488586425781 0.3405833840370178\n",
            "tcost icost -0.27066636085510254 0.3388577103614807\n",
            "tcost icost -0.032691460102796555 0.3435667157173157\n",
            "tcost icost -0.06824873387813568 0.33424049615859985\n",
            "tcost icost -0.0541907362639904 0.34920215606689453\n",
            "4 Parameter containing:\n",
            "tensor([[[ 7.5764e-02,  3.1355e-02, -2.5801e-01],\n",
            "         [-1.2380e-01, -6.7391e-01, -2.4745e-01],\n",
            "         [-8.3135e-01, -6.9620e-01, -7.4615e-01],\n",
            "         [ 2.4367e-04, -2.6483e-01, -9.3301e-01],\n",
            "         [-3.9578e-01, -2.1185e-02, -2.5014e-01],\n",
            "         [-3.1469e-01,  9.3216e-02, -7.6060e-02]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.3425765037536621\n",
            "tcost icost -0.09805521368980408 0.34558773040771484\n",
            "tcost icost -0.2706664204597473 0.33913949131965637\n",
            "tcost icost -0.03269147500395775 0.3387792110443115\n",
            "tcost icost -0.0682487040758133 0.33941149711608887\n",
            "tcost icost -0.05419076606631279 0.34429672360420227\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.0116, -0.0593, -0.3484],\n",
            "         [-0.2030, -0.7362, -0.3381],\n",
            "         [-0.9035, -0.7731, -0.8417],\n",
            "         [-0.0955, -0.3638, -1.0000],\n",
            "         [-0.4939, -0.1019, -0.3298],\n",
            "         [-0.3769,  0.0471, -0.0926]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.3429085612297058\n",
            "tcost icost -0.09805488586425781 0.34112051129341125\n",
            "tcost icost -0.27066636085510254 0.33387017250061035\n",
            "tcost icost -0.032691460102796555 0.34371882677078247\n",
            "tcost icost -0.06824873387813568 0.3392105996608734\n",
            "tcost icost -0.0541907362639904 0.34017452597618103\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.1019, -0.1522, -0.4408],\n",
            "         [-0.2874, -0.7919, -0.4303],\n",
            "         [-0.9766, -0.8437, -0.9356],\n",
            "         [-0.1907, -0.4627, -1.0000],\n",
            "         [-0.5924, -0.1800, -0.4072],\n",
            "         [-0.4351, -0.0016, -0.1153]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.34261536598205566\n",
            "tcost icost -0.09805488586425781 0.345630943775177\n",
            "tcost icost -0.27066662907600403 0.3435090184211731\n",
            "tcost icost -0.03269144520163536 0.3340647220611572\n",
            "tcost icost -0.26879796385765076 0.3428029417991638\n",
            "tcost icost -0.035472895950078964 0.34374508261680603\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.1944, -0.2466, -0.5342],\n",
            "         [-0.3752, -0.8422, -0.5233],\n",
            "         [-1.0000, -0.9094, -1.0000],\n",
            "         [-0.2803, -0.5464, -1.0000],\n",
            "         [-0.6764, -0.2614, -0.4878],\n",
            "         [-0.4890, -0.0498, -0.1404]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.33805108070373535\n",
            "tcost icost -0.09805521368980408 0.34101784229278564\n",
            "tcost icost -0.27066656947135925 0.34367913007736206\n",
            "tcost icost -0.03269141539931297 0.33416062593460083\n",
            "tcost icost -0.2687980830669403 0.34304726123809814\n",
            "tcost icost -0.03547287359833717 0.3484897017478943\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.2883, -0.3420, -0.6282],\n",
            "         [-0.4655, -0.8881, -0.6167],\n",
            "         [-1.0000, -0.9708, -1.0000],\n",
            "         [-0.3654, -0.6178, -1.0000],\n",
            "         [-0.7629, -0.3467, -0.5725],\n",
            "         [-0.5394, -0.0977, -0.1676]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.34259432554244995\n",
            "tcost icost -0.09805488586425781 0.3455919623374939\n",
            "tcost icost -0.27066662907600403 0.33421948552131653\n",
            "tcost icost -0.06512302160263062 0.33913713693618774\n",
            "tcost icost -0.22097957134246826 0.34270867705345154\n",
            "tcost icost -0.038085777312517166 0.3393615484237671\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.3831, -0.4380, -0.7222],\n",
            "         [-0.5574, -0.9300, -0.7099],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.4507, -0.6833, -1.0000],\n",
            "         [-0.8522, -0.4334, -0.6600],\n",
            "         [-0.5866, -0.1461, -0.1972]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.33792853355407715\n",
            "tcost icost -0.19244973361492157 0.33522647619247437\n",
            "tcost icost -0.2707720398902893 0.3334091007709503\n",
            "tcost icost -0.057986628264188766 0.33838438987731934\n",
            "tcost icost -0.2262364625930786 0.33357563614845276\n",
            "tcost icost -0.1619354784488678 0.33339083194732666\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.4785, -0.5342, -0.8155],\n",
            "         [-0.6511, -0.9765, -0.8042],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5390, -0.7434, -1.0000],\n",
            "         [-0.9425, -0.5201, -0.7487],\n",
            "         [-0.6406, -0.2073, -0.2458]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.24681684374809265 0.33774837851524353\n",
            "tcost icost -0.19244973361492157 0.3394409716129303\n",
            "tcost icost -0.2707720398902893 0.33806949853897095\n",
            "tcost icost -0.057986628264188766 0.33881625533103943\n",
            "tcost icost -0.2262364625930786 0.34319570660591125\n",
            "tcost icost -0.1619357466697693 0.3430129587650299\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.5739, -0.6301, -0.9078],\n",
            "         [-0.7460, -1.0000, -0.8997],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6294, -0.7986, -1.0000],\n",
            "         [-1.0000, -0.6066, -0.8380],\n",
            "         [-0.6997, -0.2773, -0.3061]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.6142155528068542 0.3424457609653473\n",
            "tcost icost -0.18847543001174927 0.33857789635658264\n",
            "tcost icost -0.25519874691963196 0.33312439918518066\n",
            "tcost icost -0.2209230661392212 0.33706793189048767\n",
            "tcost icost -0.22534874081611633 0.33659130334854126\n",
            "tcost icost -0.1368778795003891 0.33714568614959717\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.6703, -0.7127, -0.9875],\n",
            "         [-0.8404, -1.0000, -0.9958],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6983, -0.8356, -1.0000],\n",
            "         [-1.0000, -0.6820, -0.9251],\n",
            "         [-0.7571, -0.3530, -0.3748]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.6142151951789856 0.3413780629634857\n",
            "tcost icost -0.18847563862800598 0.33910566568374634\n",
            "tcost icost -0.2551988959312439 0.3331730365753174\n",
            "tcost icost -0.22092360258102417 0.3334408700466156\n",
            "tcost icost -0.22534865140914917 0.33668822050094604\n",
            "tcost icost -0.13687777519226074 0.3420560956001282\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.7677, -0.7838, -1.0000],\n",
            "         [-0.9337, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.7728, -0.8576, -1.0000],\n",
            "         [-1.0000, -0.7478, -1.0000],\n",
            "         [-0.8128, -0.4336, -0.4496]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.6142155528068542 0.34135136008262634\n",
            "tcost icost -0.18847516179084778 0.33859142661094666\n",
            "tcost icost -0.25519901514053345 0.3375272750854492\n",
            "tcost icost -0.22092348337173462 0.3416211009025574\n",
            "tcost icost -0.22534865140914917 0.3371291160583496\n",
            "tcost icost -0.13687798380851746 0.35625317692756653\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.8657, -0.8448, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8524, -0.8668, -1.0000],\n",
            "         [-1.0000, -0.8051, -1.0000],\n",
            "         [-0.8670, -0.5182, -0.5289]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.6142155528068542 0.3364875614643097\n",
            "tcost icost -0.18847516179084778 0.3339867889881134\n",
            "tcost icost -0.25519901514053345 0.33775413036346436\n",
            "tcost icost -0.22092369198799133 0.3465653359889984\n",
            "tcost icost -0.22534847259521484 0.3324078917503357\n",
            "tcost icost -0.13687799870967865 0.34180212020874023\n",
            "15 Parameter containing:\n",
            "tensor([[[-0.9637, -0.8970, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9360, -0.8650, -1.0000],\n",
            "         [-1.0000, -0.8548, -1.0000],\n",
            "         [-0.9196, -0.6057, -0.6116]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.6142155528068542 0.3376900553703308\n",
            "tcost icost -0.18847516179084778 0.34834885597229004\n",
            "tcost icost -0.25519901514053345 0.34223395586013794\n",
            "tcost icost -0.22092360258102417 0.3379311263561249\n",
            "tcost icost -0.225348562002182 0.3372079133987427\n",
            "tcost icost -0.2226611077785492 0.3415411710739136\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9414, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8533, -1.0000],\n",
            "         [-1.0000, -0.8981, -1.0000],\n",
            "         [-0.9804, -0.6834, -0.6948]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.6142151951789856 0.34609630703926086\n",
            "tcost icost -0.1884753406047821 0.3388509750366211\n",
            "tcost icost -0.2551993429660797 0.3330143690109253\n",
            "tcost icost -0.22092360258102417 0.34608981013298035\n",
            "tcost icost -0.22534865140914917 0.3368993401527405\n",
            "tcost icost -0.22266048192977905 0.3413142263889313\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9788, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8329, -1.0000],\n",
            "         [-1.0000, -0.9355, -1.0000],\n",
            "         [-1.0000, -0.7524, -0.7782]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.614215075969696 0.34609630703926086\n",
            "tcost icost -0.18847540020942688 0.3435036540031433\n",
            "tcost icost -0.25519946217536926 0.3325461149215698\n",
            "tcost icost -0.2209239900112152 0.3368270695209503\n",
            "tcost icost -0.22534817457199097 0.3417274057865143\n",
            "tcost icost -0.22266077995300293 0.3461427390575409\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8044, -1.0000],\n",
            "         [-1.0000, -0.9678, -1.0000],\n",
            "         [-1.0000, -0.8135, -0.8612]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.614215075969696 0.3364492356777191\n",
            "tcost icost -0.18847540020942688 0.33429399132728577\n",
            "tcost icost -0.25519946217536926 0.3375473916530609\n",
            "tcost icost -0.2209239900112152 0.3325417935848236\n",
            "tcost icost -0.22534820437431335 0.34651365876197815\n",
            "tcost icost -0.22266119718551636 0.3418605327606201\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.7684, -1.0000],\n",
            "         [-1.0000, -0.9953, -1.0000],\n",
            "         [-1.0000, -0.8675, -0.9435]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search -0.04793177917599678\n",
            "Parameter containing:\n",
            "tensor([[[-0.3180,  0.0800, -0.1899],\n",
            "         [ 0.1460, -0.2014,  0.3866],\n",
            "         [-0.2959,  0.3486, -0.1817],\n",
            "         [-0.5181,  0.2452, -0.0208],\n",
            "         [-0.0805,  0.4342,  0.0470],\n",
            "         [ 0.1233,  0.0268,  0.4561]]], requires_grad=True)\n",
            "tcost icost -0.11363540589809418 0.33993542194366455\n",
            "tcost icost 0.017217447981238365 0.3427274227142334\n",
            "tcost icost -0.1277095079421997 0.3366751968860626\n",
            "tcost icost -0.038500312715768814 0.34000125527381897\n",
            "tcost icost 0.1545192152261734 0.3485318720340729\n",
            "tcost icost 0.08735214173793793 0.33655717968940735\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.4177, -0.0201, -0.0897],\n",
            "         [ 0.0458, -0.1012,  0.4863],\n",
            "         [-0.3956,  0.2483, -0.2815],\n",
            "         [-0.6176,  0.1450, -0.1208],\n",
            "         [-0.1804,  0.3338, -0.0530],\n",
            "         [ 0.0232, -0.0732,  0.3556]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11363540589809418 0.3397641181945801\n",
            "tcost icost 0.017217447981238365 0.3472073972225189\n",
            "tcost icost -0.1277095079421997 0.33612072467803955\n",
            "tcost icost -0.1615365743637085 0.3343117833137512\n",
            "tcost icost -0.045061636716127396 0.3442464768886566\n",
            "tcost icost 0.16747882962226868 0.33886241912841797\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.5171, -0.1201,  0.0104],\n",
            "         [-0.0525, -0.0012,  0.5849],\n",
            "         [-0.4951,  0.1483, -0.3803],\n",
            "         [-0.6923,  0.0559, -0.2121],\n",
            "         [-0.2802,  0.2542, -0.1358],\n",
            "         [-0.0708, -0.1729,  0.2555]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.030971836298704147 0.3402814269065857\n",
            "tcost icost 0.017773939296603203 0.33725735545158386\n",
            "tcost icost -0.13725371658802032 0.34093278646469116\n",
            "tcost icost -0.16499871015548706 0.3341626226902008\n",
            "tcost icost -0.044160228222608566 0.34366369247436523\n",
            "tcost icost 0.16818170249462128 0.32965534925460815\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.5840, -0.2201, -0.0261],\n",
            "         [-0.1514,  0.0983,  0.6839],\n",
            "         [-0.5656,  0.0488, -0.4785],\n",
            "         [-0.7772, -0.0376, -0.3068],\n",
            "         [-0.3798,  0.1816, -0.2131],\n",
            "         [-0.1670, -0.2726,  0.1553]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2362927496433258 0.33955439925193787\n",
            "tcost icost 0.024062298238277435 0.34211984276771545\n",
            "tcost icost -0.3545719087123871 0.34988635778427124\n",
            "tcost icost -0.14760145545005798 0.3430955708026886\n",
            "tcost icost -0.04495514556765556 0.3394133448600769\n",
            "tcost icost 0.17011018097400665 0.3430931866168976\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.6615, -0.3116, -0.0744],\n",
            "         [-0.2423,  0.1971,  0.7828],\n",
            "         [-0.6316, -0.0420, -0.5734],\n",
            "         [-0.8668, -0.1327, -0.4029],\n",
            "         [-0.4790,  0.1122, -0.2877],\n",
            "         [-0.2634, -0.3720,  0.0551]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.23629289865493774 0.3396456837654114\n",
            "tcost icost 0.024062279611825943 0.34179818630218506\n",
            "tcost icost -0.3545718193054199 0.34047380089759827\n",
            "tcost icost -0.14760185778141022 0.3385954201221466\n",
            "tcost icost -0.04495520517230034 0.33464735746383667\n",
            "tcost icost 0.1701100766658783 0.3386143147945404\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.7455, -0.4050, -0.1310],\n",
            "         [-0.3352,  0.2962,  0.8819],\n",
            "         [-0.7081, -0.1346, -0.6694],\n",
            "         [-0.9587, -0.2288, -0.5001],\n",
            "         [-0.5777,  0.0439, -0.3611],\n",
            "         [-0.3597, -0.4710, -0.0451]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2362927496433258 0.3446086645126343\n",
            "tcost icost 0.024062298238277435 0.3418489992618561\n",
            "tcost icost -0.35457202792167664 0.3354298770427704\n",
            "tcost icost -0.14760181307792664 0.34324461221694946\n",
            "tcost icost -0.18631812930107117 0.3428720533847809\n",
            "tcost icost -0.03991037979722023 0.338718980550766\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.8333, -0.5001, -0.1938],\n",
            "         [-0.4298,  0.3955,  0.9806],\n",
            "         [-0.7907, -0.2290, -0.7664],\n",
            "         [-1.0000, -0.3239, -0.5968],\n",
            "         [-0.6544, -0.0328, -0.4406],\n",
            "         [-0.4551, -0.5592, -0.1361]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.23629289865493774 0.34448009729385376\n",
            "tcost icost 0.024062279611825943 0.3466278314590454\n",
            "tcost icost -0.3545718193054199 0.34510934352874756\n",
            "tcost icost -0.14760196208953857 0.3430898189544678\n",
            "tcost icost -0.18631771206855774 0.34268322587013245\n",
            "tcost icost -0.06526201963424683 0.3395059406757355\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.9232, -0.5961, -0.2613],\n",
            "         [-0.5257,  0.4950,  1.0000],\n",
            "         [-0.8770, -0.3248, -0.8636],\n",
            "         [-1.0000, -0.4182, -0.6927],\n",
            "         [-0.7364, -0.1154, -0.5249],\n",
            "         [-0.5507, -0.6373, -0.2180]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.26020488142967224 0.3442489206790924\n",
            "tcost icost 0.028041603043675423 0.3370676636695862\n",
            "tcost icost -0.3796367049217224 0.3358626663684845\n",
            "tcost icost -0.14313018321990967 0.34251275658607483\n",
            "tcost icost -0.18785347044467926 0.3420397937297821\n",
            "tcost icost -0.25656235218048096 0.33886197209358215\n",
            "7 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6834, -0.2734],\n",
            "         [-0.6225,  0.5941,  1.0000],\n",
            "         [-0.9655, -0.4216, -0.9607],\n",
            "         [-1.0000, -0.5113, -0.7874],\n",
            "         [-0.8217, -0.2018, -0.6123],\n",
            "         [-0.6194, -0.7040, -0.3026]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.26020488142967224 0.33985134959220886\n",
            "tcost icost 0.2085677981376648 0.3389054834842682\n",
            "tcost icost -0.6605672836303711 0.3446447253227234\n",
            "tcost icost -0.10798469185829163 0.34287092089653015\n",
            "tcost icost -0.20087431371212006 0.33338505029678345\n",
            "tcost icost -0.25076550245285034 0.3335028886795044\n",
            "8 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7625, -0.2570],\n",
            "         [-0.6947,  0.6649,  1.0000],\n",
            "         [-1.0000, -0.5191, -1.0000],\n",
            "         [-1.0000, -0.6050, -0.8795],\n",
            "         [-0.9084, -0.2910, -0.7013],\n",
            "         [-0.6947, -0.7610, -0.3890]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.26020488142967224 0.34446191787719727\n",
            "tcost icost 0.20856773853302002 0.33889901638031006\n",
            "tcost icost -0.6605671048164368 0.3394322693347931\n",
            "tcost icost -0.1872110664844513 0.33290478587150574\n",
            "tcost icost -0.15107962489128113 0.3326692283153534\n",
            "tcost icost -0.25859034061431885 0.3560732901096344\n",
            "9 Parameter containing:\n",
            "tensor([[[-1.0000, -0.8345, -0.2221],\n",
            "         [-0.7723,  0.7121,  1.0000],\n",
            "         [-1.0000, -0.6171, -1.0000],\n",
            "         [-1.0000, -0.6906, -0.9697],\n",
            "         [-0.9924, -0.3819, -0.7901],\n",
            "         [-0.7716, -0.8107, -0.4741]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.26020488142967224 0.33957529067993164\n",
            "tcost icost 0.20856770873069763 0.3387397229671478\n",
            "tcost icost -0.6712173223495483 0.3345992863178253\n",
            "tcost icost -0.17464587092399597 0.3374691903591156\n",
            "tcost icost -0.15266644954681396 0.33706364035606384\n",
            "tcost icost -0.25501757860183716 0.34609389305114746\n",
            "10 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9000, -0.1743],\n",
            "         [-0.8546,  0.7341,  1.0000],\n",
            "         [-1.0000, -0.6992, -1.0000],\n",
            "         [-1.0000, -0.7696, -1.0000],\n",
            "         [-1.0000, -0.4738, -0.8781],\n",
            "         [-0.8530, -0.8540, -0.5580]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.26020488142967224 0.3447326421737671\n",
            "tcost icost 0.2085677981376648 0.3340359032154083\n",
            "tcost icost -0.6712173819541931 0.3391245901584625\n",
            "tcost icost -0.17464594542980194 0.3376496434211731\n",
            "tcost icost -0.15266630053520203 0.34622031450271606\n",
            "tcost icost -0.2550172209739685 0.34661731123924255\n",
            "11 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9596, -0.1167],\n",
            "         [-0.9400,  0.7369,  1.0000],\n",
            "         [-1.0000, -0.7676, -1.0000],\n",
            "         [-1.0000, -0.8427, -1.0000],\n",
            "         [-1.0000, -0.5662, -0.9650],\n",
            "         [-0.9382, -0.8917, -0.6405]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2602049708366394 0.3443974256515503\n",
            "tcost icost 0.20856770873069763 0.3388415575027466\n",
            "tcost icost -0.6712173223495483 0.3436514437198639\n",
            "tcost icost -0.17464569211006165 0.34143710136413574\n",
            "tcost icost -0.24164626002311707 0.34661996364593506\n",
            "tcost icost -0.220164954662323 0.3371211588382721\n",
            "12 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0516],\n",
            "         [-1.0000,  0.7246,  0.9847],\n",
            "         [-1.0000, -0.8244, -1.0000],\n",
            "         [-1.0000, -0.9109, -1.0000],\n",
            "         [-1.0000, -0.6467, -1.0000],\n",
            "         [-1.0000, -0.9242, -0.7232]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2602049708366394 0.33943793177604675\n",
            "tcost icost 0.20856769382953644 0.3341043293476105\n",
            "tcost icost -0.6712170839309692 0.34399664402008057\n",
            "tcost icost -0.17464587092399597 0.3419966697692871\n",
            "tcost icost -0.2416466474533081 0.34156906604766846\n",
            "tcost icost -0.22016459703445435 0.3466966450214386\n",
            "13 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000,  0.0196],\n",
            "         [-1.0000,  0.6996,  0.9564],\n",
            "         [-1.0000, -0.8712, -1.0000],\n",
            "         [-1.0000, -0.9746, -1.0000],\n",
            "         [-1.0000, -0.7167, -1.0000],\n",
            "         [-1.0000, -0.9520, -0.8057]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.13106530904769897 0.3446200489997864\n",
            "tcost icost 0.17984116077423096 0.3393479883670807\n",
            "tcost icost -0.6374632120132446 0.3342275023460388\n",
            "tcost icost -0.1788075566291809 0.342098593711853\n",
            "tcost icost -0.2403985857963562 0.34617307782173157\n",
            "tcost icost -0.2204614281654358 0.3425084054470062\n",
            "14 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000,  0.0273],\n",
            "         [-1.0000,  0.6621,  0.9154],\n",
            "         [-1.0000, -0.9092, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.7776, -1.0000],\n",
            "         [-1.0000, -0.9756, -0.8875]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.13106554746627808 0.3448616564273834\n",
            "tcost icost 0.17984114587306976 0.34390076994895935\n",
            "tcost icost -0.6374634504318237 0.3343614935874939\n",
            "tcost icost -0.17880770564079285 0.3415123522281647\n",
            "tcost icost -0.24039900302886963 0.3415904939174652\n",
            "tcost icost -0.2204613983631134 0.3321858048439026\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000,  0.0069],\n",
            "         [-1.0000,  0.6143,  0.8639],\n",
            "         [-1.0000, -0.9395, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8303, -1.0000],\n",
            "         [-1.0000, -0.9955, -0.9683]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.13106554746627808 0.34906741976737976\n",
            "tcost icost 0.17984114587306976 0.3347662687301636\n",
            "tcost icost -0.6374634504318237 0.3438720703125\n",
            "tcost icost -0.17880770564079285 0.33291390538215637\n",
            "tcost icost -0.24039888381958008 0.33721020817756653\n",
            "tcost icost -0.2204611897468567 0.34142765402793884\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0310],\n",
            "         [-1.0000,  0.5578,  0.8036],\n",
            "         [-1.0000, -0.9627, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8759, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2602049708366394 0.339415580034256\n",
            "tcost icost 0.208567813038826 0.33489665389060974\n",
            "tcost icost -0.6712175011634827 0.3390915095806122\n",
            "tcost icost -0.17464566230773926 0.3464601933956146\n",
            "tcost icost -0.24164637923240662 0.3372424840927124\n",
            "tcost icost -0.22016438841819763 0.3370330035686493\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0583],\n",
            "         [-1.0000,  0.4950,  0.7369],\n",
            "         [-1.0000, -0.9797, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9149, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2602049708366394 0.3399354815483093\n",
            "tcost icost 0.015106609091162682 0.34164953231811523\n",
            "tcost icost -0.4422628581523895 0.3354625105857849\n",
            "tcost icost -0.21473437547683716 0.3337552547454834\n",
            "tcost icost -0.23236733675003052 0.3375994861125946\n",
            "tcost icost -0.2229846715927124 0.3416001796722412\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0760],\n",
            "         [-1.0000,  0.4481,  0.6906],\n",
            "         [-1.0000, -0.9949, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9494, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2602049708366394 0.34429046511650085\n",
            "tcost icost 0.015106609091162682 0.3368706703186035\n",
            "tcost icost -0.4422631859779358 0.3444313406944275\n",
            "tcost icost -0.21473407745361328 0.3418503701686859\n",
            "tcost icost -0.23236751556396484 0.3373827040195465\n",
            "tcost icost -0.22298455238342285 0.33335164189338684\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0850],\n",
            "         [-1.0000,  0.4160,  0.6625],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9798, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.36989641189575195\n",
            "Parameter containing:\n",
            "tensor([[[ 0.0702, -0.2083,  0.3048],\n",
            "         [-0.4856, -0.3070, -0.4995],\n",
            "         [ 0.0700, -0.0834,  0.3420],\n",
            "         [-0.2479,  0.0204,  0.0781],\n",
            "         [ 0.2886,  0.0516,  0.5059],\n",
            "         [ 0.0165, -0.3988, -0.0221]]], requires_grad=True)\n",
            "tcost icost -0.014136221259832382 0.3403583765029907\n",
            "tcost icost -0.04698391631245613 0.3426567614078522\n",
            "tcost icost 0.12171736359596252 0.34170660376548767\n",
            "tcost icost 0.07269388437271118 0.3354751467704773\n",
            "tcost icost 0.11839856207370758 0.33367836475372314\n",
            "tcost icost -0.32076454162597656 0.34841471910476685\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.1701, -0.3081,  0.2045],\n",
            "         [-0.5851, -0.4067, -0.5990],\n",
            "         [ 0.1700, -0.1833,  0.2417],\n",
            "         [-0.3477, -0.0796, -0.0220],\n",
            "         [ 0.1883, -0.0485,  0.4054],\n",
            "         [-0.0835, -0.4984, -0.1220]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.34012463688850403\n",
            "tcost icost -0.11543712019920349 0.33734145760536194\n",
            "tcost icost 0.14216288924217224 0.34552130103111267\n",
            "tcost icost -0.39124947786331177 0.3441340923309326\n",
            "tcost icost 0.2068536877632141 0.3370790183544159\n",
            "tcost icost -0.42575451731681824 0.35309863090515137\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.1528, -0.3900,  0.1654],\n",
            "         [-0.6738, -0.5027, -0.6918],\n",
            "         [ 0.1992, -0.2659,  0.1627],\n",
            "         [-0.4251, -0.1759, -0.1219],\n",
            "         [ 0.0884, -0.1433,  0.3090],\n",
            "         [-0.1826, -0.5546, -0.1406]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.34483957290649414\n",
            "tcost icost -0.11543712019920349 0.3421190083026886\n",
            "tcost icost 0.14216282963752747 0.3317699730396271\n",
            "tcost icost -0.39124947786331177 0.3488093614578247\n",
            "tcost icost 0.20685362815856934 0.34209728240966797\n",
            "tcost icost -0.3413045108318329 0.33899009227752686\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.1028, -0.4657,  0.1568],\n",
            "         [-0.7667, -0.6002, -0.7872],\n",
            "         [ 0.1960, -0.3431,  0.0907],\n",
            "         [-0.5116, -0.2718, -0.2218],\n",
            "         [-0.0115, -0.2393,  0.2124],\n",
            "         [-0.2818, -0.5741, -0.1157]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.344850093126297\n",
            "tcost icost -0.22369524836540222 0.3373411297798157\n",
            "tcost icost 0.1646156907081604 0.33086341619491577\n",
            "tcost icost -0.4215873181819916 0.33897334337234497\n",
            "tcost icost 0.20895662903785706 0.3284553289413452\n",
            "tcost icost -0.34047892689704895 0.3436644673347473\n",
            "3 Parameter containing:\n",
            "tensor([[[ 0.0335, -0.5090,  0.1911],\n",
            "         [-0.8578, -0.6903, -0.8761],\n",
            "         [ 0.1690, -0.4176,  0.0215],\n",
            "         [-0.5952, -0.3677, -0.3209],\n",
            "         [-0.1115, -0.3366,  0.1148],\n",
            "         [-0.3813, -0.5708, -0.0690]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.34505119919776917\n",
            "tcost icost -0.22369524836540222 0.3366996645927429\n",
            "tcost icost 0.16461549699306488 0.3402463495731354\n",
            "tcost icost -0.7841041088104248 0.3427014648914337\n",
            "tcost icost 0.2383328378200531 0.3358894884586334\n",
            "tcost icost -0.344662070274353 0.3479558825492859\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.0450, -0.5324,  0.2439],\n",
            "         [-0.9468, -0.7749, -0.9602],\n",
            "         [ 0.1159, -0.4985, -0.0571],\n",
            "         [-0.6578, -0.4640, -0.4144],\n",
            "         [-0.2110, -0.4345,  0.0164],\n",
            "         [-0.4804, -0.5546, -0.0067]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.3413183391094208\n",
            "tcost icost -0.22369524836540222 0.3416713774204254\n",
            "tcost icost -0.031615886837244034 0.33563050627708435\n",
            "tcost icost -0.25591492652893066 0.33393096923828125\n",
            "tcost icost 0.19890624284744263 0.3377777338027954\n",
            "tcost icost -0.3378903865814209 0.3529520630836487\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.1293, -0.5307,  0.3099],\n",
            "         [-1.0000, -0.8566, -1.0000],\n",
            "         [ 0.0596, -0.5672, -0.1227],\n",
            "         [-0.7231, -0.5600, -0.5093],\n",
            "         [-0.3104, -0.5327, -0.0824],\n",
            "         [-0.5789, -0.5239,  0.0631]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.01413625106215477 0.34488216042518616\n",
            "tcost icost -0.22369477152824402 0.3418109118938446\n",
            "tcost icost -0.10332569479942322 0.3405190706253052\n",
            "tcost icost -0.28643539547920227 0.3393111228942871\n",
            "tcost icost -0.03234870359301567 0.33982399106025696\n",
            "tcost icost 0.16225895285606384 0.3424831032752991\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.2170, -0.5159,  0.3826],\n",
            "         [-1.0000, -0.9353, -1.0000],\n",
            "         [-0.0059, -0.6296, -0.1839],\n",
            "         [-0.7956, -0.6454, -0.6036],\n",
            "         [-0.4064, -0.6223, -0.1760],\n",
            "         [-0.6667, -0.5432,  0.0875]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.340031236410141\n",
            "tcost icost -0.22369524836540222 0.33715420961380005\n",
            "tcost icost -0.10332554578781128 0.3407558798789978\n",
            "tcost icost -0.286435067653656 0.33449265360832214\n",
            "tcost icost -0.06008143350481987 0.3496209681034088\n",
            "tcost icost 0.17142809927463531 0.33355480432510376\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.3069, -0.4909,  0.4600],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.0798, -0.6870, -0.2418],\n",
            "         [-0.8723, -0.7218, -0.6970],\n",
            "         [-0.5028, -0.7025, -0.2635],\n",
            "         [-0.7458, -0.5840,  0.0851]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.01413625106215477 0.3496931195259094\n",
            "tcost icost -0.22369477152824402 0.3465214669704437\n",
            "tcost icost -0.10332569479942322 0.3358059525489807\n",
            "tcost icost -0.28643539547920227 0.33899402618408203\n",
            "tcost icost -0.06008134409785271 0.33877670764923096\n",
            "tcost icost 0.0014855749905109406 0.3478652536869049\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.3984, -0.4568,  0.5405],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.1597, -0.7400, -0.2970],\n",
            "         [-0.9519, -0.7907, -0.7892],\n",
            "         [-0.5975, -0.7755, -0.3468],\n",
            "         [-0.8179, -0.6229,  0.0803]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.34014892578125\n",
            "tcost icost -0.22369524836540222 0.3417559862136841\n",
            "tcost icost -0.10332532227039337 0.33978286385536194\n",
            "tcost icost -0.2864353060722351 0.33895382285118103\n",
            "tcost icost -0.219407320022583 0.3423750102519989\n",
            "tcost icost 0.006913464516401291 0.35154101252555847\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.4908, -0.4154,  0.6230],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.2440, -0.7894, -0.3504],\n",
            "         [-1.0000, -0.8529, -0.8793],\n",
            "         [-0.6787, -0.8400, -0.4333],\n",
            "         [-0.8835, -0.6597,  0.0738]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.014136221259832382 0.34477102756500244\n",
            "tcost icost -0.22369524836540222 0.341661661863327\n",
            "tcost icost -0.10332532227039337 0.3444821834564209\n",
            "tcost icost -0.28643566370010376 0.3438226580619812\n",
            "tcost icost -0.21940714120864868 0.3472166061401367\n",
            "tcost icost 0.006913479417562485 0.3422853946685791\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.5837, -0.3675,  0.7068],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.3315, -0.8355, -0.4022],\n",
            "         [-1.0000, -0.9093, -0.9674],\n",
            "         [-0.7628, -0.8972, -0.5226],\n",
            "         [-0.9436, -0.6947,  0.0656]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645856589078903 0.34458014369010925\n",
            "tcost icost -0.25704556703567505 0.3466470241546631\n",
            "tcost icost -0.10031510889530182 0.3402462601661682\n",
            "tcost icost -0.28875869512557983 0.34351494908332825\n",
            "tcost icost -0.21857258677482605 0.34279319643974304\n",
            "tcost icost 0.006923291832208633 0.3383547365665436\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.6757, -0.3078,  0.7938],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.4212, -0.8788, -0.4525],\n",
            "         [-1.0000, -0.9604, -1.0000],\n",
            "         [-0.8500, -0.9479, -0.6141],\n",
            "         [-0.9988, -0.7281,  0.0558]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645856589078903 0.33992284536361694\n",
            "tcost icost -0.25704556703567505 0.33661505579948425\n",
            "tcost icost -0.10031510889530182 0.3453660309314728\n",
            "tcost icost -0.28875869512557983 0.3434983193874359\n",
            "tcost icost -0.21857327222824097 0.3328346014022827\n",
            "tcost icost 0.006923288106918335 0.35142257809638977\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.7665, -0.2392,  0.8834],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5126, -0.9195, -0.5016],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9398, -0.9929, -0.7070],\n",
            "         [-1.0000, -0.7601,  0.0445]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645871490240097 0.3400394022464752\n",
            "tcost icost -0.2570455074310303 0.3367159962654114\n",
            "tcost icost -0.10031495988368988 0.33585748076438904\n",
            "tcost icost -0.28875863552093506 0.34852176904678345\n",
            "tcost icost -0.21857303380966187 0.34735170006752014\n",
            "tcost icost 0.006923280656337738 0.33737489581108093\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.8560, -0.1639,  0.9746],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6050, -0.9579, -0.5494],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.8008],\n",
            "         [-1.0000, -0.7909,  0.0318]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645856589078903 0.34942784905433655\n",
            "tcost icost -0.25704556703567505 0.3416711091995239\n",
            "tcost icost -0.2235773205757141 0.33935993909835815\n",
            "tcost icost -0.24232035875320435 0.3428128659725189\n",
            "tcost icost -0.22325432300567627 0.34206315875053406\n",
            "tcost icost 0.007455836981534958 0.3410002291202545\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.9441, -0.0835,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6991, -0.9968, -0.6089],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.8951],\n",
            "         [-1.0000, -0.8205,  0.0178]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645841687917709 0.3396577537059784\n",
            "tcost icost -0.2570454478263855 0.33706411719322205\n",
            "tcost icost -0.2235771119594574 0.3437424898147583\n",
            "tcost icost -0.2423204779624939 0.3333474397659302\n",
            "tcost icost -0.2232545018196106 0.3421657979488373\n",
            "tcost icost 0.007455836981534958 0.3371587097644806\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000e+00,  9.3496e-04,  1.0000e+00],\n",
            "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
            "         [-7.9430e-01, -1.0000e+00, -6.7641e-01],\n",
            "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
            "         [-1.0000e+00, -1.0000e+00, -9.8930e-01],\n",
            "         [-1.0000e+00, -8.4901e-01,  2.5114e-03]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645841687917709 0.34458819031715393\n",
            "tcost icost -0.2570454478263855 0.3416629433631897\n",
            "tcost icost -0.2235771119594574 0.3341304063796997\n",
            "tcost icost -0.2423204779624939 0.3423483967781067\n",
            "tcost icost -0.2232545018196106 0.3417007327079773\n",
            "tcost icost 0.007455836981534958 0.34649530053138733\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000,  0.0886,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8900, -1.0000, -0.7498],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8766, -0.0140]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645841687917709 0.3447948694229126\n",
            "tcost icost -0.2570454478263855 0.3465838134288788\n",
            "tcost icost -0.2235771119594574 0.34377774596214294\n",
            "tcost icost -0.2423204779624939 0.33806806802749634\n",
            "tcost icost -0.2232545018196106 0.34204626083374023\n",
            "tcost icost -0.22453513741493225 0.3422487676143646\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000,  0.1789,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9857, -1.0000, -0.8274],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8989, -0.0434]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645841687917709 0.34465035796165466\n",
            "tcost icost -0.2570454478263855 0.33695071935653687\n",
            "tcost icost -0.2235771119594574 0.3391475975513458\n",
            "tcost icost -0.2423204779624939 0.3331424295902252\n",
            "tcost icost -0.2232545018196106 0.33298128843307495\n",
            "tcost icost -0.22453495860099792 0.34621497988700867\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000,  0.2713,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9081],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9164, -0.0834]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.007645841687917709 0.3397785425186157\n",
            "tcost icost -0.2570454478263855 0.33711928129196167\n",
            "tcost icost -0.22357720136642456 0.3343336582183838\n",
            "tcost icost -0.24232041835784912 0.3378361463546753\n",
            "tcost icost -0.2232545018196106 0.33738672733306885\n",
            "tcost icost -0.224534809589386 0.3326515555381775\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000,  0.3651,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9908],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9295, -0.1320]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.5207912921905518\n",
            "Parameter containing:\n",
            "tensor([[[-0.2418, -0.2856, -0.3777],\n",
            "         [ 0.3299, -0.3527, -0.3189],\n",
            "         [ 0.5182,  0.2753, -0.0599],\n",
            "         [-0.0960,  0.4963,  0.1097],\n",
            "         [-0.2444,  0.2962, -0.0204],\n",
            "         [ 0.0506, -0.3739, -0.5191]]], requires_grad=True)\n",
            "tcost icost -0.40171220898628235 0.34637922048568726\n",
            "tcost icost -0.028180856257677078 0.34927329421043396\n",
            "tcost icost -0.0769091248512268 0.3348124325275421\n",
            "tcost icost 0.16913361847400665 0.3337615430355072\n",
            "tcost icost -0.4026047885417938 0.34784936904907227\n",
            "tcost icost -0.02856144681572914 0.347452849149704\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.3416, -0.3854, -0.4774],\n",
            "         [ 0.2296, -0.4523, -0.4185],\n",
            "         [ 0.4177,  0.1750, -0.1599],\n",
            "         [-0.1959,  0.3958,  0.0095],\n",
            "         [-0.3442,  0.3959,  0.0797],\n",
            "         [-0.0495, -0.4735, -0.6186]]], requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.40171220898628235 0.3369758427143097\n",
            "tcost icost -0.028180856257677078 0.33473867177963257\n",
            "tcost icost -0.0769091248512268 0.33953961730003357\n",
            "tcost icost 0.16913361847400665 0.33393043279647827\n",
            "tcost icost 0.08590644598007202 0.33007290959358215\n",
            "tcost icost -0.2739082872867584 0.3431992828845978\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.4411, -0.4848, -0.5767],\n",
            "         [ 0.1295, -0.5518, -0.5181],\n",
            "         [ 0.3173,  0.0748, -0.2596],\n",
            "         [-0.2955,  0.2996, -0.0843],\n",
            "         [-0.4185,  0.3444,  0.1123],\n",
            "         [-0.1278, -0.5517, -0.6994]]], requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.40171220898628235 0.3416520059108734\n",
            "tcost icost -0.08806110918521881 0.34936708211898804\n",
            "tcost icost -0.05170587822794914 0.33456262946128845\n",
            "tcost icost -0.060640107840299606 0.3437781035900116\n",
            "tcost icost 0.16967034339904785 0.3381645381450653\n",
            "tcost icost -0.3238205313682556 0.33817997574806213\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.5402, -0.5837, -0.6751],\n",
            "         [ 0.0613, -0.6439, -0.6142],\n",
            "         [ 0.2216, -0.0251, -0.3592],\n",
            "         [-0.3636,  0.2178, -0.1698],\n",
            "         [-0.4842,  0.2731,  0.0824],\n",
            "         [-0.2140, -0.5823, -0.7091]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0., -1.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.40908077359199524 0.34584900736808777\n",
            "tcost icost -0.07810990512371063 0.33527758717536926\n",
            "tcost icost -0.055823128670454025 0.3389218747615814\n",
            "tcost icost -0.059736523777246475 0.33413323760032654\n",
            "tcost icost 0.16906556487083435 0.3386510908603668\n",
            "tcost icost -0.32380756735801697 0.3484016954898834\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.6361, -0.6596, -0.7383],\n",
            "         [-0.0182, -0.7317, -0.7052],\n",
            "         [ 0.1264, -0.1251, -0.4587],\n",
            "         [-0.4255,  0.1425, -0.2516],\n",
            "         [-0.5454,  0.1917,  0.0288],\n",
            "         [-0.3047, -0.5850, -0.6854]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333153486251831 0.3394363224506378\n",
            "tcost icost -0.06249673292040825 0.3440220057964325\n",
            "tcost icost -0.059692393988370895 0.3438534736633301\n",
            "tcost icost -0.05795825645327568 0.3395228385925293\n",
            "tcost icost 0.17068159580230713 0.3293655216693878\n",
            "tcost icost -0.3219919800758362 0.34837207198143005\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.7323, -0.6964, -0.7945],\n",
            "         [-0.1037, -0.8155, -0.7949],\n",
            "         [ 0.0300, -0.2233, -0.5550],\n",
            "         [-0.4948,  0.0707, -0.3301],\n",
            "         [-0.6035,  0.1047, -0.0378],\n",
            "         [-0.3980, -0.5684, -0.6421]]], requires_grad=True)\n",
            "tensor([[[-1., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0., -1.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333153486251831 0.3403426706790924\n",
            "tcost icost -0.06249673292040825 0.3392491340637207\n",
            "tcost icost -0.059692393988370895 0.34371039271354675\n",
            "tcost icost -0.05795825645327568 0.3388473391532898\n",
            "tcost icost -0.23447492718696594 0.34249940514564514\n",
            "tcost icost -0.06207213178277016 0.3437199890613556\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.8293, -0.7071, -0.8457],\n",
            "         [-0.1928, -0.8961, -0.8829],\n",
            "         [-0.0674, -0.3206, -0.6490],\n",
            "         [-0.5675,  0.0053, -0.4013],\n",
            "         [-0.6734,  0.0145, -0.1135],\n",
            "         [-0.4833, -0.5543, -0.6063]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333155274391174 0.34033265709877014\n",
            "tcost icost -0.06249666586518288 0.3389488458633423\n",
            "tcost icost -0.05969236418604851 0.3393990099430084\n",
            "tcost icost -0.23214063048362732 0.34276753664016724\n",
            "tcost icost -0.16215114295482635 0.3332085907459259\n",
            "tcost icost -0.06582339107990265 0.3486012816429138\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.9268, -0.6988, -0.8927],\n",
            "         [-0.2845, -0.9745, -0.9706],\n",
            "         [-0.1647, -0.4134, -0.7381],\n",
            "         [-0.6371, -0.0687, -0.4798],\n",
            "         [-0.7459, -0.0780, -0.1951],\n",
            "         [-0.5631, -0.5421, -0.5772]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333155274391174 0.3353615999221802\n",
            "tcost icost -0.06249666586518288 0.3346676826477051\n",
            "tcost icost -0.05969236418604851 0.33890262246131897\n",
            "tcost icost -0.23214063048362732 0.3387228548526764\n",
            "tcost icost -0.16215117275714874 0.3428896367549896\n",
            "tcost icost -0.178005188703537 0.3376582860946655\n",
            "7 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6757, -0.9363],\n",
            "         [-0.3780, -1.0000, -1.0000],\n",
            "         [-0.2618, -0.5024, -0.8227],\n",
            "         [-0.7134, -0.1486, -0.5632],\n",
            "         [-0.8175, -0.1713, -0.2799],\n",
            "         [-0.6436, -0.5664, -0.5876]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333151698112488 0.34481117129325867\n",
            "tcost icost -0.062496643513441086 0.33902618288993835\n",
            "tcost icost -0.059692393988370895 0.3485531210899353\n",
            "tcost icost -0.23214054107666016 0.338358998298645\n",
            "tcost icost -0.16215094923973083 0.337588369846344\n",
            "tcost icost -0.2626810371875763 0.3420804738998413\n",
            "8 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6408, -0.9771],\n",
            "         [-0.4727, -1.0000, -1.0000],\n",
            "         [-0.3587, -0.5880, -0.9033],\n",
            "         [-0.7950, -0.2326, -0.6500],\n",
            "         [-0.8881, -0.2653, -0.3669],\n",
            "         [-0.7280, -0.5815, -0.6165]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333152890205383 0.3354942202568054\n",
            "tcost icost -0.06249675527215004 0.3343045711517334\n",
            "tcost icost -0.10181200504302979 0.3346949815750122\n",
            "tcost icost -0.2010132372379303 0.3426753282546997\n",
            "tcost icost -0.17021986842155457 0.3426187038421631\n",
            "tcost icost -0.26097631454467773 0.34188637137413025\n",
            "9 Parameter containing:\n",
            "tensor([[[-1.0000, -0.5959, -1.0000],\n",
            "         [-0.5671, -1.0000, -1.0000],\n",
            "         [-0.4418, -0.6646, -0.9798],\n",
            "         [-0.8802, -0.3181, -0.7387],\n",
            "         [-0.9604, -0.3598, -0.4557],\n",
            "         [-0.8149, -0.5888, -0.6582]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.7333151698112488 0.33529770374298096\n",
            "tcost icost -0.1869266927242279 0.3375900685787201\n",
            "tcost icost -0.06631533801555634 0.3384546637535095\n",
            "tcost icost -0.21945089101791382 0.3378088176250458\n",
            "tcost icost -0.16389530897140503 0.34701406955718994\n",
            "tcost icost -0.261274129152298 0.34256744384765625\n",
            "10 Parameter containing:\n",
            "tensor([[[-1.0000, -0.5430, -1.0000],\n",
            "         [-0.6626, -1.0000, -1.0000],\n",
            "         [-0.5280, -0.7351, -1.0000],\n",
            "         [-0.9679, -0.4057, -0.8282],\n",
            "         [-1.0000, -0.4545, -0.5455],\n",
            "         [-0.9032, -0.5891, -0.7093]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.3406938910484314\n",
            "tcost icost -0.19155873358249664 0.3337014615535736\n",
            "tcost icost -0.06882837414741516 0.3377850353717804\n",
            "tcost icost -0.21779459714889526 0.3428592085838318\n",
            "tcost icost -0.16440142691135406 0.342548131942749\n",
            "tcost icost -0.2613411247730255 0.34210196137428284\n",
            "11 Parameter containing:\n",
            "tensor([[[-1.0000, -0.4954, -1.0000],\n",
            "         [-0.7592, -1.0000, -1.0000],\n",
            "         [-0.6163, -0.8002, -1.0000],\n",
            "         [-1.0000, -0.4946, -0.9179],\n",
            "         [-1.0000, -0.5491, -0.6358],\n",
            "         [-0.9922, -0.5832, -0.7675]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.3405275344848633\n",
            "tcost icost -0.1915585845708847 0.337983101606369\n",
            "tcost icost -0.24533528089523315 0.33235207200050354\n",
            "tcost icost -0.13617566227912903 0.3369661569595337\n",
            "tcost icost -0.1818428337574005 0.3370169401168823\n",
            "tcost icost -0.24125728011131287 0.34200519323349\n",
            "12 Parameter containing:\n",
            "tensor([[[-1.0000, -0.4526, -1.0000],\n",
            "         [-0.8560, -1.0000, -1.0000],\n",
            "         [-0.6965, -0.8524, -1.0000],\n",
            "         [-1.0000, -0.5843, -1.0000],\n",
            "         [-1.0000, -0.6449, -0.7272],\n",
            "         [-1.0000, -0.5734, -0.8278]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.33587729930877686\n",
            "tcost icost -0.1915585845708847 0.33296874165534973\n",
            "tcost icost -0.2453354001045227 0.33199644088745117\n",
            "tcost icost -0.22176748514175415 0.3412192761898041\n",
            "tcost icost -0.22449934482574463 0.3459668755531311\n",
            "tcost icost -0.22145581245422363 0.34128567576408386\n",
            "13 Parameter containing:\n",
            "tensor([[[-1.0000, -0.4144, -1.0000],\n",
            "         [-0.9524, -1.0000, -1.0000],\n",
            "         [-0.7799, -0.8938, -1.0000],\n",
            "         [-1.0000, -0.6625, -1.0000],\n",
            "         [-1.0000, -0.7296, -0.8168],\n",
            "         [-1.0000, -0.5603, -0.8892]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.33595481514930725\n",
            "tcost icost -0.1915585845708847 0.33836984634399414\n",
            "tcost icost -0.24533569812774658 0.34197989106178284\n",
            "tcost icost -0.22176724672317505 0.331725537776947\n",
            "tcost icost -0.22449931502342224 0.33687618374824524\n",
            "tcost icost -0.22145593166351318 0.34624943137168884\n",
            "14 Parameter containing:\n",
            "tensor([[[-1.0000, -0.3802, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8666, -0.9259, -1.0000],\n",
            "         [-1.0000, -0.7306, -1.0000],\n",
            "         [-1.0000, -0.8046, -0.9042],\n",
            "         [-1.0000, -0.5441, -0.9513]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.33611127734184265\n",
            "tcost icost -0.19155873358249664 0.33843082189559937\n",
            "tcost icost -0.24533551931381226 0.3411131501197815\n",
            "tcost icost -0.22176751494407654 0.33219000697135925\n",
            "tcost icost -0.2244991660118103 0.3366199731826782\n",
            "tcost icost -0.13676883280277252 0.3468317985534668\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000, -0.3498, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9559, -0.9499, -1.0000],\n",
            "         [-1.0000, -0.7898, -1.0000],\n",
            "         [-1.0000, -0.8705, -0.9895],\n",
            "         [-1.0000, -0.5587, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.33591610193252563\n",
            "tcost icost -0.19155873358249664 0.33333420753479004\n",
            "tcost icost -0.24533551931381226 0.3373039960861206\n",
            "tcost icost -0.22176751494407654 0.34088781476020813\n",
            "tcost icost -0.2244991660118103 0.3453158438205719\n",
            "tcost icost -0.22145584225654602 0.3323560059070587\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -0.3228, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9665, -1.0000],\n",
            "         [-1.0000, -0.8410, -1.0000],\n",
            "         [-1.0000, -0.9289, -1.0000],\n",
            "         [-1.0000, -0.5687, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.3360578119754791\n",
            "tcost icost -0.19155873358249664 0.3426026701927185\n",
            "tcost icost -0.24533510208129883 0.34173649549484253\n",
            "tcost icost -0.22176730632781982 0.3367471396923065\n",
            "tcost icost -0.22449934482574463 0.33246752619743347\n",
            "tcost icost -0.2214559018611908 0.33725106716156006\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -0.2990, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9764, -1.0000],\n",
            "         [-1.0000, -0.8852, -1.0000],\n",
            "         [-1.0000, -0.9804, -1.0000],\n",
            "         [-1.0000, -0.5745, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.33613425493240356\n",
            "tcost icost -0.19155873358249664 0.3474067151546478\n",
            "tcost icost -0.24533510208129883 0.33218833804130554\n",
            "tcost icost -0.22176730632781982 0.3410549759864807\n",
            "tcost icost -0.22449934482574463 0.3508344292640686\n",
            "tcost icost -0.22145551443099976 0.332256019115448\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -0.2781, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9802, -1.0000],\n",
            "         [-1.0000, -0.9230, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.5762, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8012251853942871 0.34070464968681335\n",
            "tcost icost -0.19155873358249664 0.33430182933807373\n",
            "tcost icost -0.24533510208129883 0.3370419144630432\n",
            "tcost icost -0.22176730632781982 0.34139394760131836\n",
            "tcost icost -0.22449934482574463 0.33181193470954895\n",
            "tcost icost -0.2214556634426117 0.3466140627861023\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -0.2599, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9784, -1.0000],\n",
            "         [-1.0000, -0.9551, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.5742, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search -0.22783097624778748\n",
            "Parameter containing:\n",
            "tensor([[[-0.1485,  0.1200,  0.5293],\n",
            "         [ 0.0663,  0.5109,  0.5192],\n",
            "         [ 0.2008,  0.3949, -0.5122],\n",
            "         [-0.4471, -0.1709,  0.0253],\n",
            "         [-0.4425, -0.3682, -0.1310],\n",
            "         [-0.5123,  0.2332, -0.3188]]], requires_grad=True)\n",
            "tcost icost -0.025655489414930344 0.3399317264556885\n",
            "tcost icost 0.04162268340587616 0.345319926738739\n",
            "tcost icost -0.2729622721672058 0.3448978066444397\n",
            "tcost icost 0.19158506393432617 0.3384319543838501\n",
            "tcost icost -0.4285857677459717 0.33864763379096985\n",
            "tcost icost -0.027779322117567062 0.34345003962516785\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.0484,  0.0198,  0.4288],\n",
            "         [-0.0338,  0.6104,  0.6187],\n",
            "         [ 0.3006,  0.2946, -0.6117],\n",
            "         [-0.5466, -0.2707, -0.0747],\n",
            "         [-0.5421, -0.2679, -0.0309],\n",
            "         [-0.6118,  0.1329, -0.4185]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.025655489414930344 0.33997678756713867\n",
            "tcost icost 0.2537144124507904 0.3368660509586334\n",
            "tcost icost -0.5160125494003296 0.34455594420433044\n",
            "tcost icost -0.02541555091738701 0.3387296199798584\n",
            "tcost icost -0.07592076063156128 0.33444860577583313\n",
            "tcost icost -0.2190380096435547 0.3481512665748596\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.0510, -0.0801,  0.3284],\n",
            "         [-0.1325,  0.6760,  0.6958],\n",
            "         [ 0.3013,  0.1975, -0.6959],\n",
            "         [-0.6304, -0.3472, -0.1613],\n",
            "         [-0.6217, -0.3112,  0.0077],\n",
            "         [-0.6910,  0.0526, -0.4980]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.025655489414930344 0.3442566990852356\n",
            "tcost icost 0.253714382648468 0.3320581018924713\n",
            "tcost icost -0.51601243019104 0.33907634019851685\n",
            "tcost icost -0.1127888560295105 0.3381839394569397\n",
            "tcost icost 0.18270236253738403 0.32747140526771545\n",
            "tcost icost -0.739027738571167 0.3414328694343567\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.1505, -0.1801,  0.2281],\n",
            "         [-0.2275,  0.7147,  0.7498],\n",
            "         [ 0.2658,  0.1000, -0.7753],\n",
            "         [-0.7108, -0.4261, -0.2503],\n",
            "         [-0.6853, -0.3801, -0.0037],\n",
            "         [-0.7778, -0.0317, -0.5842]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.025655489414930344 0.3398820459842682\n",
            "tcost icost 0.2537144422531128 0.3369130492210388\n",
            "tcost icost -0.5160118341445923 0.3445429801940918\n",
            "tcost icost -0.1127888411283493 0.34744971990585327\n",
            "tcost icost -0.2007303237915039 0.33322152495384216\n",
            "tcost icost -0.16732409596443176 0.34634271264076233\n",
            "3 Parameter containing:\n",
            "tensor([[[ 0.2501, -0.2800,  0.1277],\n",
            "         [-0.3221,  0.7401,  0.7939],\n",
            "         [ 0.2114,  0.0023, -0.8517],\n",
            "         [-0.7967, -0.5037, -0.3424],\n",
            "         [-0.7568, -0.4592, -0.0556],\n",
            "         [-0.8637, -0.1200, -0.6747]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.025655489414930344 0.3397359251976013\n",
            "tcost icost 0.2537144422531128 0.33715546131134033\n",
            "tcost icost -0.5160118341445923 0.33984220027923584\n",
            "tcost icost -0.11278904974460602 0.33336663246154785\n",
            "tcost icost -0.20072998106479645 0.3472762107849121\n",
            "tcost icost -0.1673242598772049 0.34216201305389404\n",
            "4 Parameter containing:\n",
            "tensor([[[ 0.3497, -0.3796,  0.0273],\n",
            "         [-0.4163,  0.7559,  0.8311],\n",
            "         [ 0.1457, -0.0956, -0.9261],\n",
            "         [-0.8853, -0.5806, -0.4362],\n",
            "         [-0.8329, -0.5443, -0.1231],\n",
            "         [-0.9485, -0.2106, -0.7673]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.025655489414930344 0.3448350727558136\n",
            "tcost icost 0.2537144422531128 0.34202539920806885\n",
            "tcost icost -0.5160118341445923 0.3350100517272949\n",
            "tcost icost -0.18467026948928833 0.33816951513290405\n",
            "tcost icost -0.15300610661506653 0.3422195315361023\n",
            "tcost icost -0.17784717679023743 0.3423924446105957\n",
            "5 Parameter containing:\n",
            "tensor([[[ 0.4492, -0.4790, -0.0731],\n",
            "         [-0.5086,  0.7566,  0.8546],\n",
            "         [ 0.0719, -0.1936, -0.9981],\n",
            "         [-0.9740, -0.6506, -0.5315],\n",
            "         [-0.9068, -0.6320, -0.1978],\n",
            "         [-1.0000, -0.3033, -0.8607]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [ 0.,  1.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [-1.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.17674767971038818 0.33947455883026123\n",
            "tcost icost 0.245853453874588 0.3426380455493927\n",
            "tcost icost -0.5024152994155884 0.3403800129890442\n",
            "tcost icost -0.19426757097244263 0.3417534828186035\n",
            "tcost icost -0.23987603187561035 0.3371507227420807\n",
            "tcost icost -0.13640126585960388 0.34676647186279297\n",
            "6 Parameter containing:\n",
            "tensor([[[ 0.4198, -0.5707, -0.1717],\n",
            "         [-0.6018,  0.7548,  0.8800],\n",
            "         [-0.0077, -0.2887, -1.0000],\n",
            "         [-1.0000, -0.7150, -0.6275],\n",
            "         [-0.9867, -0.7054, -0.2769],\n",
            "         [-1.0000, -0.3976, -0.9543]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.33935755491256714\n",
            "tcost icost 0.25892317295074463 0.3417772352695465\n",
            "tcost icost -0.5512544512748718 0.3400794565677643\n",
            "tcost icost -0.18126660585403442 0.33769649267196655\n",
            "tcost icost -0.24325338006019592 0.34687158465385437\n",
            "tcost icost -0.13558124005794525 0.3466910421848297\n",
            "7 Parameter containing:\n",
            "tensor([[[ 0.3672, -0.6390, -0.2692],\n",
            "         [-0.6965,  0.7372,  0.8875],\n",
            "         [-0.0920, -0.3815, -1.0000],\n",
            "         [-1.0000, -0.7745, -0.7233],\n",
            "         [-1.0000, -0.7644, -0.3596],\n",
            "         [-1.0000, -0.4929, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215739011764526 0.34408795833587646\n",
            "tcost icost 0.25892314314842224 0.33217817544937134\n",
            "tcost icost -0.5512540936470032 0.34933894872665405\n",
            "tcost icost -0.18126630783081055 0.3373014032840729\n",
            "tcost icost -0.24325335025787354 0.3422059416770935\n",
            "tcost icost -0.1355811506509781 0.3413592576980591\n",
            "8 Parameter containing:\n",
            "tensor([[[ 0.3023, -0.6886, -0.3656],\n",
            "         [-0.7921,  0.7068,  0.8806],\n",
            "         [-0.1798, -0.4724, -1.0000],\n",
            "         [-1.0000, -0.8297, -0.8184],\n",
            "         [-1.0000, -0.8114, -0.4446],\n",
            "         [-1.0000, -0.5886, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215739011764526 0.33974334597587585\n",
            "tcost icost 0.25892308354377747 0.33677250146865845\n",
            "tcost icost -0.5512543320655823 0.3446214199066162\n",
            "tcost icost -0.18126660585403442 0.33768945932388306\n",
            "tcost icost -0.24325311183929443 0.34699082374572754\n",
            "tcost icost -0.22054800391197205 0.34611204266548157\n",
            "9 Parameter containing:\n",
            "tensor([[[ 0.2291, -0.7230, -0.4609],\n",
            "         [-0.8879,  0.6658,  0.8617],\n",
            "         [-0.2702, -0.5614, -1.0000],\n",
            "         [-1.0000, -0.8813, -0.9125],\n",
            "         [-1.0000, -0.8488, -0.5311],\n",
            "         [-1.0000, -0.6726, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.3443661332130432\n",
            "tcost icost 0.2589230537414551 0.34158873558044434\n",
            "tcost icost -0.5027610659599304 0.3403829038143158\n",
            "tcost icost -0.19479358196258545 0.3333306312561035\n",
            "tcost icost -0.2400881052017212 0.34210556745529175\n",
            "tcost icost -0.22175121307373047 0.33281946182250977\n",
            "10 Parameter containing:\n",
            "tensor([[[ 0.1502, -0.7449, -0.5543],\n",
            "         [-0.9839,  0.6093,  0.8166],\n",
            "         [-0.3554, -0.6080, -1.0000],\n",
            "         [-1.0000, -0.9236, -1.0000],\n",
            "         [-1.0000, -0.8801, -0.6180],\n",
            "         [-1.0000, -0.7463, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.34426501393318176\n",
            "tcost icost 0.2589230537414551 0.338259220123291\n",
            "tcost icost -0.5027610659599304 0.3492361605167389\n",
            "tcost icost -0.1947934329509735 0.33791011571884155\n",
            "tcost icost -0.24008822441101074 0.34110522270202637\n",
            "tcost icost -0.22175103425979614 0.34179434180259705\n",
            "11 Parameter containing:\n",
            "tensor([[[ 0.0668, -0.7560, -0.6456],\n",
            "         [-1.0000,  0.5426,  0.7576],\n",
            "         [-0.4427, -0.6267, -1.0000],\n",
            "         [-1.0000, -0.9577, -1.0000],\n",
            "         [-1.0000, -0.9059, -0.7049],\n",
            "         [-1.0000, -0.8112, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.3441579043865204\n",
            "tcost icost 0.02488117292523384 0.3405108153820038\n",
            "tcost icost -0.292672723531723 0.34493348002433777\n",
            "tcost icost -0.23880189657211304 0.343021422624588\n",
            "tcost icost -0.22908562421798706 0.3373377323150635\n",
            "tcost icost -0.22500008344650269 0.3412047028541565\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.0201, -0.7575, -0.7359],\n",
            "         [-1.0000,  0.4922,  0.7185],\n",
            "         [-0.5318, -0.6494, -1.0000],\n",
            "         [-1.0000, -0.9910, -1.0000],\n",
            "         [-1.0000, -0.9266, -0.7911],\n",
            "         [-1.0000, -0.8683, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.33951833844184875\n",
            "tcost icost 0.02488117292523384 0.3451821804046631\n",
            "tcost icost -0.292672723531723 0.3401114046573639\n",
            "tcost icost -0.23880189657211304 0.34338900446891785\n",
            "tcost icost -0.22908562421798706 0.3507532477378845\n",
            "tcost icost -0.22500008344650269 0.35264596343040466\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.1097, -0.7505, -0.8248],\n",
            "         [-1.0000,  0.4565,  0.6970],\n",
            "         [-0.6231, -0.6759, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9426, -0.8763],\n",
            "         [-1.0000, -0.9186, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.3441236913204193\n",
            "tcost icost 0.02488117292523384 0.3451688289642334\n",
            "tcost icost -0.5144167542457581 0.33898836374282837\n",
            "tcost icost -0.19434261322021484 0.3375956118106842\n",
            "tcost icost -0.2359997034072876 0.341492623090744\n",
            "tcost icost -0.2214963436126709 0.35124802589416504\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.2016, -0.7357, -0.9123],\n",
            "         [-1.0000,  0.4424,  0.6969],\n",
            "         [-0.7092, -0.6939, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9532, -0.9604],\n",
            "         [-1.0000, -0.9628, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.33922725915908813\n",
            "tcost icost 0.02488117106258869 0.3454192578792572\n",
            "tcost icost -0.5144164562225342 0.33479419350624084\n",
            "tcost icost -0.19434262812137604 0.3418644368648529\n",
            "tcost icost -0.23599961400032043 0.35108160972595215\n",
            "tcost icost -0.22149616479873657 0.34643569588661194\n",
            "15 Parameter containing:\n",
            "tensor([[[-0.2953, -0.7138, -0.9981],\n",
            "         [-1.0000,  0.4456,  0.7134],\n",
            "         [-0.7905, -0.7043, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9587, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.3490125834941864\n",
            "tcost icost 0.02488117292523384 0.33567050099372864\n",
            "tcost icost -0.5144167542457581 0.33864864706993103\n",
            "tcost icost -0.19434261322021484 0.33725592494010925\n",
            "tcost icost -0.23599988222122192 0.3419388234615326\n",
            "tcost icost -0.22149616479873657 0.33211639523506165\n",
            "16 Parameter containing:\n",
            "tensor([[[-0.3903, -0.6852, -1.0000],\n",
            "         [-1.0000,  0.4629,  0.7428],\n",
            "         [-0.8673, -0.7079, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9596, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.3441157937049866\n",
            "tcost icost 0.02488117292523384 0.33564990758895874\n",
            "tcost icost -0.514416515827179 0.33907806873321533\n",
            "tcost icost -0.19434264302253723 0.3467169404029846\n",
            "tcost icost -0.23599958419799805 0.3371574282646179\n",
            "tcost icost -0.22149616479873657 0.3372819423675537\n",
            "17 Parameter containing:\n",
            "tensor([[[-0.4862, -0.6504, -1.0000],\n",
            "         [-1.0000,  0.4917,  0.7823],\n",
            "         [-0.9399, -0.7051, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9563, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.25215765833854675 0.34421616792678833\n",
            "tcost icost 0.02488117292523384 0.3360968828201294\n",
            "tcost icost -0.5144167542457581 0.3392360508441925\n",
            "tcost icost -0.19434261322021484 0.33763381838798523\n",
            "tcost icost -0.23599988222122192 0.3324574828147888\n",
            "tcost icost -0.22149616479873657 0.3558705747127533\n",
            "18 Parameter containing:\n",
            "tensor([[[-0.5826, -0.6098, -1.0000],\n",
            "         [-1.0000,  0.5299,  0.8299],\n",
            "         [-1.0000, -0.6965, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9489, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.5152331590652466 0.3388080298900604\n",
            "tcost icost 0.034407518804073334 0.3490992486476898\n",
            "tcost icost -0.5582944750785828 0.3343910574913025\n",
            "tcost icost -0.18308037519454956 0.34173133969306946\n",
            "tcost icost -0.2381150722503662 0.33210527896881104\n",
            "tcost icost -0.22067898511886597 0.34213536977767944\n",
            "19 Parameter containing:\n",
            "tensor([[[-0.6779, -0.5698, -1.0000],\n",
            "         [-1.0000,  0.5712,  0.8794],\n",
            "         [-1.0000, -0.6785, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9378, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.07971443235874176\n",
            "Parameter containing:\n",
            "tensor([[[-0.1341, -0.4778,  0.0337],\n",
            "         [-0.4012, -0.3057, -0.4306],\n",
            "         [ 0.4410, -0.2822, -0.0383],\n",
            "         [-0.0894, -0.3332, -0.3777],\n",
            "         [ 0.1221,  0.3144,  0.5203],\n",
            "         [ 0.4955, -0.4649,  0.2966]]], requires_grad=True)\n",
            "tcost icost -0.023014072328805923 0.3448410928249359\n",
            "tcost icost -0.041581232100725174 0.3524095118045807\n",
            "tcost icost -0.05072033032774925 0.3460415303707123\n",
            "tcost icost -0.05722494050860405 0.34941211342811584\n",
            "tcost icost 0.16127337515354156 0.3402051031589508\n",
            "tcost icost 0.08607374876737595 0.33966365456581116\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.0340, -0.5773, -0.0663],\n",
            "         [-0.5008, -0.4054, -0.5302],\n",
            "         [ 0.3405, -0.3819, -0.1383],\n",
            "         [-0.1893, -0.4329, -0.4773],\n",
            "         [ 0.0220,  0.2141,  0.4197],\n",
            "         [ 0.3950, -0.5645,  0.1964]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2302801012992859 0.34437137842178345\n",
            "tcost icost -0.02657955512404442 0.34354719519615173\n",
            "tcost icost -0.05787636712193489 0.34176018834114075\n",
            "tcost icost -0.054300110787153244 0.34476470947265625\n",
            "tcost icost 0.15933218598365784 0.34819522500038147\n",
            "tcost icost -0.0095449797809124 0.3625160753726959\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.1057, -0.5597, -0.1628],\n",
            "         [-0.5962, -0.4986, -0.6231],\n",
            "         [ 0.2404, -0.4815, -0.2382],\n",
            "         [-0.2892, -0.5319, -0.5759],\n",
            "         [-0.0779,  0.1139,  0.3196],\n",
            "         [ 0.2957, -0.6401,  0.1181]]], requires_grad=True)\n",
            "tensor([[[ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0., -1.,  1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2302801012992859 0.3446206748485565\n",
            "tcost icost -0.0623336099088192 0.3473212420940399\n",
            "tcost icost -0.05336494371294975 0.34561511874198914\n",
            "tcost icost -0.057766567915678024 0.34051430225372314\n",
            "tcost icost 0.16217945516109467 0.34344375133514404\n",
            "tcost icost -0.009568464010953903 0.33935415744781494\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.1894, -0.5099, -0.2606],\n",
            "         [-0.6922, -0.5941, -0.7171],\n",
            "         [ 0.1556, -0.5809, -0.3370],\n",
            "         [-0.3889, -0.6306, -0.6743],\n",
            "         [-0.1778,  0.0138,  0.2195],\n",
            "         [ 0.1964, -0.7058,  0.0479]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.17883947491645813 0.3543248772621155\n",
            "tcost icost -0.13764894008636475 0.35177502036094666\n",
            "tcost icost -0.11050520837306976 0.34078729152679443\n",
            "tcost icost -0.11090680956840515 0.34469911456108093\n",
            "tcost icost 0.17252595722675323 0.3485337197780609\n",
            "tcost icost -0.010125305503606796 0.348529577255249\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.2758, -0.5198, -0.3503],\n",
            "         [-0.7881, -0.6895, -0.8079],\n",
            "         [ 0.0913, -0.6638, -0.4361],\n",
            "         [-0.4482, -0.7177, -0.7620],\n",
            "         [-0.2777, -0.0864,  0.1193],\n",
            "         [ 0.1034, -0.7660, -0.0185]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.17883947491645813 0.34479764103889465\n",
            "tcost icost -0.13764886558055878 0.35117191076278687\n",
            "tcost icost -0.11050514876842499 0.3451881408691406\n",
            "tcost icost -0.11090683937072754 0.3544011116027832\n",
            "tcost icost 0.1725260466337204 0.3387017250061035\n",
            "tcost icost -0.3418772518634796 0.34821817278862\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.3639, -0.5567, -0.4348],\n",
            "         [-0.8850, -0.7842, -0.9010],\n",
            "         [ 0.0156, -0.7352, -0.5351],\n",
            "         [-0.5206, -0.7975, -0.8422],\n",
            "         [-0.3774, -0.1848,  0.0216],\n",
            "         [ 0.0463, -0.7995, -0.0288]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2302801012992859 0.34433889389038086\n",
            "tcost icost -0.1296100616455078 0.34676593542099\n",
            "tcost icost -0.1133258193731308 0.3408648669719696\n",
            "tcost icost -0.1105378270149231 0.3447246849536896\n",
            "tcost icost 0.17279936373233795 0.33898454904556274\n",
            "tcost icost -0.34160667657852173 0.34378582239151\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.4548, -0.5705, -0.5225],\n",
            "         [-0.9820, -0.8776, -0.9955],\n",
            "         [-0.0667, -0.7980, -0.6336],\n",
            "         [-0.6003, -0.8717, -0.9166],\n",
            "         [-0.4769, -0.2821, -0.0748],\n",
            "         [-0.0236, -0.8136, -0.0092]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2302801012992859 0.34934765100479126\n",
            "tcost icost -0.1296100616455078 0.3468688428401947\n",
            "tcost icost -0.1133258193731308 0.3454156816005707\n",
            "tcost icost -0.2739582061767578 0.338907927274704\n",
            "tcost icost -0.032786775380373 0.34322234988212585\n",
            "tcost icost -0.10333536565303802 0.34906336665153503\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.5475, -0.5671, -0.6121],\n",
            "         [-1.0000, -0.9699, -1.0000],\n",
            "         [-0.1533, -0.8527, -0.7306],\n",
            "         [-0.6846, -0.9396, -0.9972],\n",
            "         [-0.5700, -0.3699, -0.1627],\n",
            "         [-0.0953, -0.8240,  0.0044]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2302801012992859 0.35407304763793945\n",
            "tcost icost -0.12960976362228394 0.34701916575431824\n",
            "tcost icost -0.11332595348358154 0.3502708971500397\n",
            "tcost icost -0.2739582657814026 0.34819677472114563\n",
            "tcost icost -0.13795870542526245 0.3428298234939575\n",
            "tcost icost 0.0098249651491642 0.35189828276634216\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.6412, -0.5500, -0.7027],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.2428, -0.9009, -0.8262],\n",
            "         [-0.7721, -0.9999, -1.0000],\n",
            "         [-0.6473, -0.4580, -0.2531],\n",
            "         [-0.1597, -0.8358,  0.0122]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.40418970584869385 0.3539049029350281\n",
            "tcost icost -0.12361812591552734 0.34187647700309753\n",
            "tcost icost -0.11730305850505829 0.35480424761772156\n",
            "tcost icost -0.27659159898757935 0.3387998342514038\n",
            "tcost icost -0.13675883412361145 0.34331434965133667\n",
            "tcost icost 0.009812537580728531 0.3470834791660309\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.7357, -0.5830, -0.7869],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.3340, -0.9463, -0.9150],\n",
            "         [-0.8616, -1.0000, -1.0000],\n",
            "         [-0.7288, -0.5461, -0.3453],\n",
            "         [-0.2181, -0.8486,  0.0150]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.34878355264663696\n",
            "tcost icost -0.11942780017852783 0.34167149662971497\n",
            "tcost icost -0.1171257495880127 0.34050118923187256\n",
            "tcost icost -0.27813082933425903 0.3389304280281067\n",
            "tcost icost -0.13607464730739594 0.3519177734851837\n",
            "tcost icost 0.009805571287870407 0.3472118675708771\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.8286, -0.6109, -0.8633],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.4263, -0.9892, -0.9978],\n",
            "         [-0.9522, -1.0000, -1.0000],\n",
            "         [-0.8142, -0.6339, -0.4386],\n",
            "         [-0.2713, -0.8626,  0.0133]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4607168436050415 0.3489048480987549\n",
            "tcost icost -0.11942780017852783 0.3458787500858307\n",
            "tcost icost -0.11712530255317688 0.3461955785751343\n",
            "tcost icost -0.2781306207180023 0.34388217329978943\n",
            "tcost icost -0.22190076112747192 0.34686702489852905\n",
            "tcost icost 0.01320694014430046 0.35594359040260315\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.9197, -0.6343, -0.9329],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5192, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9025, -0.7125, -0.5315],\n",
            "         [-0.3202, -0.8777,  0.0073]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.3501826226711273\n",
            "tcost icost -0.11942780017852783 0.3462000787258148\n",
            "tcost icost -0.11712576448917389 0.35473135113716125\n",
            "tcost icost -0.2781306505203247 0.3527149260044098\n",
            "tcost icost -0.2219001054763794 0.34713417291641235\n",
            "tcost icost 0.013206914067268372 0.3372960686683655\n",
            "11 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6537, -0.9966],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6121, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9930, -0.7832, -0.6237],\n",
            "         [-0.3653, -0.8940, -0.0024]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.34395506978034973\n",
            "tcost icost -0.11942775547504425 0.3415898084640503\n",
            "tcost icost -0.25067102909088135 0.3441959619522095\n",
            "tcost icost -0.23976752161979675 0.3427067697048187\n",
            "tcost icost -0.22453880310058594 0.34665992856025696\n",
            "tcost icost -0.0533398799598217 0.3530774414539337\n",
            "12 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6696, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.7064, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8456, -0.7151],\n",
            "         [-0.4110, -0.9089, -0.0131]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.3484714925289154\n",
            "tcost icost -0.11942775547504425 0.3464343249797821\n",
            "tcost icost -0.25067102909088135 0.3487413823604584\n",
            "tcost icost -0.23976752161979675 0.34237778186798096\n",
            "tcost icost -0.224538654088974 0.3471478223800659\n",
            "tcost icost -0.05333985015749931 0.35774996876716614\n",
            "13 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6824, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8016, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9005, -0.8054],\n",
            "         [-0.4571, -0.9227, -0.0250]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.34421253204345703\n",
            "tcost icost -0.11942790448665619 0.341828852891922\n",
            "tcost icost -0.2506709694862366 0.33898791670799255\n",
            "tcost icost -0.23976710438728333 0.3519381880760193\n",
            "tcost icost -0.2245386242866516 0.3417748808860779\n",
            "tcost icost -0.053339894860982895 0.34348735213279724\n",
            "14 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6923, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8969, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9488, -0.8942],\n",
            "         [-0.5037, -0.9355, -0.0378]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.3489872217178345\n",
            "tcost icost -0.11942790448665619 0.34146225452423096\n",
            "tcost icost -0.25067102909088135 0.3440190255641937\n",
            "tcost icost -0.23976746201515198 0.34228774905204773\n",
            "tcost icost -0.2245386242866516 0.34155693650245667\n",
            "tcost icost -0.0533398874104023 0.3482832610607147\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000, -0.6996, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9919, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9913, -0.9814],\n",
            "         [-0.5506, -0.9473, -0.0515]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.3440805971622467\n",
            "tcost icost -0.11942790448665619 0.3513619005680084\n",
            "tcost icost -0.25067102909088135 0.34402957558631897\n",
            "tcost icost -0.23976746201515198 0.33798733353614807\n",
            "tcost icost -0.2245386242866516 0.3473075330257416\n",
            "tcost icost -0.22443389892578125 0.3417591154575348\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7046, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6094, -0.9525, -0.0858]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.3486090302467346\n",
            "tcost icost -0.11942790448665619 0.3463888168334961\n",
            "tcost icost -0.25067102909088135 0.34390971064567566\n",
            "tcost icost -0.23976746201515198 0.3474196493625641\n",
            "tcost icost -0.2245386838912964 0.3374069035053253\n",
            "tcost icost -0.22443389892578125 0.341813325881958\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7073, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.6764, -0.9516, -0.1339]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.34885287284851074\n",
            "tcost icost -0.11942790448665619 0.3466203808784485\n",
            "tcost icost -0.25067102909088135 0.3395364582538605\n",
            "tcost icost -0.23976746201515198 0.34632018208503723\n",
            "tcost icost -0.2245386838912964 0.338055282831192\n",
            "tcost icost -0.2244340181350708 0.3512730002403259\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7079, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.7495, -0.9450, -0.1920]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.46071672439575195 0.34891873598098755\n",
            "tcost icost -0.11942790448665619 0.3463415205478668\n",
            "tcost icost -0.25067102909088135 0.34380796551704407\n",
            "tcost icost -0.23976746201515198 0.34654539823532104\n",
            "tcost icost -0.2245386838912964 0.3373095989227295\n",
            "tcost icost -0.2244340479373932 0.33732515573501587\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -0.7066, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8270, -0.9331, -0.2577]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.17535336315631866\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1760, -0.3811,  0.0055],\n",
            "         [ 0.0615, -0.2521, -0.3403],\n",
            "         [ 0.1579, -0.5130, -0.3375],\n",
            "         [-0.4917, -0.1101,  0.4114],\n",
            "         [ 0.3048,  0.4286, -0.4523],\n",
            "         [-0.2446, -0.1814, -0.1972]]], requires_grad=True)\n",
            "tcost icost -0.030449319630861282 0.34490713477134705\n",
            "tcost icost -0.039040546864271164 0.3474965989589691\n",
            "tcost icost -0.051444556564092636 0.34094399213790894\n",
            "tcost icost 0.14707542955875397 0.3406953513622284\n",
            "tcost icost -0.39179354906082153 0.34397071599960327\n",
            "tcost icost -0.02957264706492424 0.3488200902938843\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.2758, -0.4807, -0.0945],\n",
            "         [-0.0386, -0.3518, -0.4399],\n",
            "         [ 0.0578, -0.6125, -0.4372],\n",
            "         [-0.5912, -0.2100,  0.3110],\n",
            "         [ 0.2045,  0.3281, -0.5518],\n",
            "         [-0.3443, -0.2812, -0.2970]]], requires_grad=True)\n",
            "tensor([[[0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.18243421614170074 0.34941524267196655\n",
            "tcost icost -0.028040114790201187 0.34331879019737244\n",
            "tcost icost -0.136665478348732 0.3502713739871979\n",
            "tcost icost 0.1356041580438614 0.34323978424072266\n",
            "tcost icost -0.38412487506866455 0.34860295057296753\n",
            "tcost icost -0.029241520911455154 0.34836891293525696\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.2057, -0.5801, -0.1862],\n",
            "         [-0.1359, -0.4438, -0.5290],\n",
            "         [-0.0160, -0.7021, -0.5339],\n",
            "         [-0.6789, -0.3098,  0.2137],\n",
            "         [ 0.1043,  0.2278, -0.6510],\n",
            "         [-0.4439, -0.3809, -0.3967]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34920427203178406\n",
            "tcost icost -0.026367325335741043 0.34757810831069946\n",
            "tcost icost -0.1402602195739746 0.34718379378318787\n",
            "tcost icost 0.13710443675518036 0.3350193500518799\n",
            "tcost icost -0.3863146901130676 0.3438013195991516\n",
            "tcost icost -0.02916106954216957 0.34835726022720337\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.1243, -0.6543, -0.2782],\n",
            "         [-0.2302, -0.5266, -0.6074],\n",
            "         [-0.1009, -0.7888, -0.6317],\n",
            "         [-0.7605, -0.4092,  0.1154],\n",
            "         [ 0.0041,  0.1274, -0.7496],\n",
            "         [-0.5430, -0.4802, -0.4959]]], requires_grad=True)\n",
            "tensor([[[ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34901535511016846\n",
            "tcost icost -0.026367325335741043 0.34303465485572815\n",
            "tcost icost -0.1402602195739746 0.35556474328041077\n",
            "tcost icost 0.13710446655750275 0.3393442928791046\n",
            "tcost icost -0.3863146901130676 0.3579511046409607\n",
            "tcost icost -0.02916104719042778 0.3438040316104889\n",
            "3 Parameter containing:\n",
            "tensor([[[ 0.0367, -0.7128, -0.3705],\n",
            "         [-0.3230, -0.6044, -0.6796],\n",
            "         [-0.1907, -0.8737, -0.7299],\n",
            "         [-0.8389, -0.5079,  0.0164],\n",
            "         [-0.0960,  0.0271, -0.8475],\n",
            "         [-0.6417, -0.5790, -0.5947]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.23381048440933228 0.34427985548973083\n",
            "tcost icost -0.07362954318523407 0.34322068095207214\n",
            "tcost icost -0.12087531387805939 0.34610313177108765\n",
            "tcost icost 0.13670025765895844 0.3486315906047821\n",
            "tcost icost -0.38538438081741333 0.3483487665653229\n",
            "tcost icost -0.1946956366300583 0.3519284129142761\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.0545, -0.7601, -0.4619],\n",
            "         [-0.4066, -0.6853, -0.7599],\n",
            "         [-0.2819, -0.9491, -0.8264],\n",
            "         [-0.9219, -0.6067, -0.0818],\n",
            "         [-0.1960, -0.0731, -0.9438],\n",
            "         [-0.7078, -0.6370, -0.6726]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34920427203178406\n",
            "tcost icost -0.07362942397594452 0.3429471552371979\n",
            "tcost icost -0.120875284075737 0.3412865400314331\n",
            "tcost icost -0.2600930631160736 0.3395161032676697\n",
            "tcost icost -0.033138927072286606 0.348724365234375\n",
            "tcost icost -0.35540905594825745 0.33841627836227417\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.1480, -0.7991, -0.5523],\n",
            "         [-0.4932, -0.7683, -0.8452],\n",
            "         [-0.3734, -1.0000, -0.9196],\n",
            "         [-0.9844, -0.7020, -0.1688],\n",
            "         [-0.2840, -0.1599, -1.0000],\n",
            "         [-0.7816, -0.6300, -0.7520]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34934863448143005\n",
            "tcost icost -0.07362942397594452 0.34871137142181396\n",
            "tcost icost -0.120875284075737 0.3411124646663666\n",
            "tcost icost -0.26009300351142883 0.34387001395225525\n",
            "tcost icost -0.033138956874608994 0.34458616375923157\n",
            "tcost icost -0.35540875792503357 0.3431592285633087\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.2429, -0.8313, -0.6416],\n",
            "         [-0.5830, -0.8525, -0.9337],\n",
            "         [-0.4650, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.7941, -0.2578],\n",
            "         [-0.3627, -0.2360, -1.0000],\n",
            "         [-0.8619, -0.5955, -0.8362]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34857556223869324\n",
            "tcost icost -0.12552335858345032 0.35180020332336426\n",
            "tcost icost -0.11349041759967804 0.3503759801387787\n",
            "tcost icost -0.2726324796676636 0.3438316583633423\n",
            "tcost icost -0.032814715057611465 0.33928215503692627\n",
            "tcost icost -0.354689359664917 0.34784355759620667\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.3388, -0.8582, -0.7283],\n",
            "         [-0.6745, -0.9395, -1.0000],\n",
            "         [-0.5568, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8785, -0.3494],\n",
            "         [-0.4336, -0.3034, -1.0000],\n",
            "         [-0.9464, -0.5444, -0.9239]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.3539661169052124\n",
            "tcost icost -0.12552335858345032 0.34697234630584717\n",
            "tcost icost -0.23199716210365295 0.3443232774734497\n",
            "tcost icost -0.2517789602279663 0.3522448241710663\n",
            "tcost icost -0.032615963369607925 0.3433336317539215\n",
            "tcost icost -0.2663019895553589 0.34801343083381653\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.4350, -0.8806, -0.8129],\n",
            "         [-0.7667, -1.0000, -1.0000],\n",
            "         [-0.6494, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9598, -0.4427],\n",
            "         [-0.4982, -0.3640, -1.0000],\n",
            "         [-1.0000, -0.5706, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34442782402038574\n",
            "tcost icost -0.12552344799041748 0.3422805368900299\n",
            "tcost icost -0.2319970726966858 0.3441205322742462\n",
            "tcost icost -0.2517786920070648 0.34294164180755615\n",
            "tcost icost -0.032615963369607925 0.3432294726371765\n",
            "tcost icost -0.3463006019592285 0.34284502267837524\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.5314, -0.8990, -0.8953],\n",
            "         [-0.8588, -1.0000, -1.0000],\n",
            "         [-0.7421, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.5375],\n",
            "         [-0.5578, -0.4192, -1.0000],\n",
            "         [-1.0000, -0.5834, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2338104248046875 0.34432247281074524\n",
            "tcost icost -0.12552344799041748 0.34235185384750366\n",
            "tcost icost -0.2319970726966858 0.3537755012512207\n",
            "tcost icost -0.251778781414032 0.34231606125831604\n",
            "tcost icost -0.13607871532440186 0.3422359526157379\n",
            "tcost icost -0.2665773630142212 0.3422108292579651\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.6274, -0.9141, -0.9754],\n",
            "         [-0.9504, -1.0000, -1.0000],\n",
            "         [-0.8345, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.6328],\n",
            "         [-0.6179, -0.4803, -1.0000],\n",
            "         [-1.0000, -0.5902, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.49323248863220215 0.34391969442367554\n",
            "tcost icost -0.11274823546409607 0.3465035855770111\n",
            "tcost icost -0.2518010139465332 0.34414541721343994\n",
            "tcost icost -0.24007576704025269 0.3380868434906006\n",
            "tcost icost -0.13784120976924896 0.3515698313713074\n",
            "tcost icost -0.26286742091178894 0.34666284918785095\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.7216, -0.9247, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9266, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.7280],\n",
            "         [-0.6784, -0.5460, -1.0000],\n",
            "         [-1.0000, -0.5916, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4932323694229126 0.3439851701259613\n",
            "tcost icost -0.11274844408035278 0.34206444025039673\n",
            "tcost icost -0.25180092453956604 0.3438984751701355\n",
            "tcost icost -0.2400760054588318 0.3378327190876007\n",
            "tcost icost -0.1378411203622818 0.3466281294822693\n",
            "tcost icost -0.2628675699234009 0.34701573848724365\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.8138, -0.9314, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.8225],\n",
            "         [-0.7390, -0.6152, -1.0000],\n",
            "         [-1.0000, -0.5880, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4932323694229126 0.3440952003002167\n",
            "tcost icost -0.11274844408035278 0.3512049615383148\n",
            "tcost icost -0.2518008351325989 0.3393167555332184\n",
            "tcost icost -0.240075945854187 0.3424362540245056\n",
            "tcost icost -0.22456270456314087 0.34219443798065186\n",
            "tcost icost -0.22445988655090332 0.35099634528160095\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.9039, -0.9345, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9160],\n",
            "         [-0.8052, -0.6748, -1.0000],\n",
            "         [-1.0000, -0.5788, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.49323248863220215 0.3438480794429779\n",
            "tcost icost -0.11274826526641846 0.3418132960796356\n",
            "tcost icost -0.25180086493492126 0.34370914101600647\n",
            "tcost icost -0.24007588624954224 0.3434373140335083\n",
            "tcost icost -0.22456306219100952 0.34214672446250916\n",
            "tcost icost -0.22445985674858093 0.341062992811203\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.9916, -0.9343, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8755, -0.7261, -1.0000],\n",
            "         [-1.0000, -0.5642, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4932323694229126 0.3500819206237793\n",
            "tcost icost -0.11274844408035278 0.35595080256462097\n",
            "tcost icost -0.2518008351325989 0.33925560116767883\n",
            "tcost icost -0.240075945854187 0.34730884432792664\n",
            "tcost icost -0.22456270456314087 0.3419470489025116\n",
            "tcost icost -0.22445985674858093 0.3432455062866211\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9311, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9489, -0.7698, -1.0000],\n",
            "         [-1.0000, -0.5447, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.49323225021362305 0.3438156247138977\n",
            "tcost icost -0.11274835467338562 0.34646353125572205\n",
            "tcost icost -0.25180068612098694 0.3439132273197174\n",
            "tcost icost -0.2400760054588318 0.34252098202705383\n",
            "tcost icost -0.22456282377243042 0.35134440660476685\n",
            "tcost icost -0.13839899003505707 0.35061702132225037\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9249, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8066, -1.0000],\n",
            "         [-1.0000, -0.5589, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.49323225021362305 0.3438946008682251\n",
            "tcost icost -0.11274835467338562 0.34668654203414917\n",
            "tcost icost -0.25180068612098694 0.34388497471809387\n",
            "tcost icost -0.2400760054588318 0.3472231328487396\n",
            "tcost icost -0.2245623767375946 0.3427082300186157\n",
            "tcost icost -0.22446006536483765 0.34666863083839417\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9161, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8373, -1.0000],\n",
            "         [-1.0000, -0.5671, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.49323225021362305 0.3536067605018616\n",
            "tcost icost -0.11274835467338562 0.34660011529922485\n",
            "tcost icost -0.25180068612098694 0.3437627851963043\n",
            "tcost icost -0.2400760054588318 0.355987012386322\n",
            "tcost icost -0.2245628833770752 0.33715397119522095\n",
            "tcost icost -0.224459707736969 0.3554053008556366\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9046, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8627, -1.0000],\n",
            "         [-1.0000, -0.5696, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.49323225021362305 0.3440738618373871\n",
            "tcost icost -0.11274835467338562 0.3511703908443451\n",
            "tcost icost -0.25180068612098694 0.35340672731399536\n",
            "tcost icost -0.2400760054588318 0.34257423877716064\n",
            "tcost icost -0.2245628833770752 0.3419632315635681\n",
            "tcost icost -0.22445976734161377 0.338210791349411\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -0.8906, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8831, -1.0000],\n",
            "         [-1.0000, -0.5670, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.1499868482351303\n",
            "Parameter containing:\n",
            "tensor([[[ 0.3909,  0.1380,  0.1289],\n",
            "         [ 0.4458,  0.2483,  0.4161],\n",
            "         [ 0.5344, -0.4139, -0.2048],\n",
            "         [-0.2591,  0.4798, -0.3997],\n",
            "         [ 0.0052, -0.5282,  0.3821],\n",
            "         [-0.3550, -0.3615,  0.2190]]], requires_grad=True)\n",
            "tcost icost -0.02695099636912346 0.3440701365470886\n",
            "tcost icost 0.0873999297618866 0.35247141122817993\n",
            "tcost icost -0.3351208567619324 0.34436360001564026\n",
            "tcost icost -0.03210223838686943 0.3438805937767029\n",
            "tcost icost 0.16166114807128906 0.3388025164604187\n",
            "tcost icost 0.09130953997373581 0.34395110607147217\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.4905,  0.0378,  0.0287],\n",
            "         [ 0.3454,  0.1481,  0.3157],\n",
            "         [ 0.4339, -0.5134, -0.3046],\n",
            "         [-0.3588,  0.3794, -0.4993],\n",
            "         [-0.0948, -0.6277,  0.2817],\n",
            "         [-0.4546, -0.4611,  0.1188]]], requires_grad=True)\n",
            "tensor([[[0., 0., 1.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02695099636912346 0.34399887919425964\n",
            "tcost icost 0.08739984035491943 0.34282931685447693\n",
            "tcost icost -0.3351210057735443 0.3443710505962372\n",
            "tcost icost -0.032102275639772415 0.3479885160923004\n",
            "tcost icost 0.005923174321651459 0.348026305437088\n",
            "tcost icost 0.13018396496772766 0.3484672009944916\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.5898, -0.0622, -0.0713],\n",
            "         [ 0.2450,  0.0479,  0.2154],\n",
            "         [ 0.3335, -0.6126, -0.4042],\n",
            "         [-0.4585,  0.2793, -0.5988],\n",
            "         [-0.1536, -0.6968,  0.2130],\n",
            "         [-0.5505, -0.5606,  0.0187]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.13349634408950806 0.34896233677864075\n",
            "tcost icost 0.07401829957962036 0.33954694867134094\n",
            "tcost icost -0.34573692083358765 0.349680095911026\n",
            "tcost icost -0.033377911895513535 0.33946067094802856\n",
            "tcost icost 0.005883414298295975 0.3429583013057709\n",
            "tcost icost -0.006789200007915497 0.3433692753314972\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.5359, -0.1622, -0.1667],\n",
            "         [ 0.1466, -0.0518,  0.1153],\n",
            "         [ 0.2511, -0.6912, -0.4869],\n",
            "         [-0.5336,  0.1797, -0.6976],\n",
            "         [-0.2033, -0.7543,  0.1532],\n",
            "         [-0.6475, -0.6420, -0.0650]]], requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.378126323223114 0.3485090434551239\n",
            "tcost icost 0.09651122242212296 0.34348878264427185\n",
            "tcost icost -0.37069180607795715 0.3445904552936554\n",
            "tcost icost -0.03311594948172569 0.3397957384586334\n",
            "tcost icost 0.005825672298669815 0.3484750986099243\n",
            "tcost icost -0.5425710082054138 0.34737518429756165\n",
            "3 Parameter containing:\n",
            "tensor([[[ 0.4640, -0.2531, -0.2630],\n",
            "         [ 0.0827, -0.1501,  0.0180],\n",
            "         [ 0.1656, -0.7524, -0.5385],\n",
            "         [-0.5822,  0.0799, -0.7964],\n",
            "         [-0.2707, -0.7891,  0.1301],\n",
            "         [-0.7223, -0.6906, -0.1432]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.378126323223114 0.3479965925216675\n",
            "tcost icost 0.09651122242212296 0.33898794651031494\n",
            "tcost icost -0.37069180607795715 0.34454038739204407\n",
            "tcost icost -0.13934601843357086 0.3430180847644806\n",
            "tcost icost 0.009521815925836563 0.3522375226020813\n",
            "tcost icost -0.561457633972168 0.3478131592273712\n",
            "4 Parameter containing:\n",
            "tensor([[[ 0.3834, -0.3459, -0.3597],\n",
            "         [ 0.0508, -0.2484, -0.0792],\n",
            "         [ 0.0760, -0.8006, -0.5680],\n",
            "         [-0.6387, -0.0056, -0.8856],\n",
            "         [-0.3245, -0.8171,  0.1284],\n",
            "         [-0.7883, -0.7210, -0.2137]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.378126323223114 0.343670129776001\n",
            "tcost icost -0.026444118469953537 0.34203749895095825\n",
            "tcost icost -0.13988527655601501 0.35042664408683777\n",
            "tcost icost -0.17678026854991913 0.34824517369270325\n",
            "tcost icost 0.01019272580742836 0.34316515922546387\n",
            "tcost icost -0.5729788541793823 0.34790825843811035\n",
            "5 Parameter containing:\n",
            "tensor([[[ 0.2976, -0.4405, -0.4560],\n",
            "         [-0.0034, -0.3377, -0.1681],\n",
            "         [-0.0141, -0.8444, -0.5976],\n",
            "         [-0.7081, -0.0919, -0.9772],\n",
            "         [-0.3749, -0.8389,  0.1406],\n",
            "         [-0.8637, -0.7373, -0.2786]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.378126323223114 0.3532973825931549\n",
            "tcost icost -0.026444118469953537 0.3418262302875519\n",
            "tcost icost -0.13988524675369263 0.3454369902610779\n",
            "tcost icost -0.17678001523017883 0.3389255106449127\n",
            "tcost icost 0.01019274815917015 0.3384677469730377\n",
            "tcost icost -0.5729786157608032 0.3431438207626343\n",
            "6 Parameter containing:\n",
            "tensor([[[ 0.2082, -0.5363, -0.5516],\n",
            "         [-0.0696, -0.4198, -0.2506],\n",
            "         [-0.1047, -0.8848, -0.6273],\n",
            "         [-0.7850, -0.1811, -1.0000],\n",
            "         [-0.4226, -0.8559,  0.1639],\n",
            "         [-0.9450, -0.7423, -0.3392]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.378126323223114 0.3532973825931549\n",
            "tcost icost -0.026444118469953537 0.3513534963130951\n",
            "tcost icost -0.13988524675369263 0.3406202495098114\n",
            "tcost icost -0.17677997052669525 0.33901190757751465\n",
            "tcost icost 0.01019272580742836 0.3435293734073639\n",
            "tcost icost -0.5729783773422241 0.347609281539917\n",
            "7 Parameter containing:\n",
            "tensor([[[ 0.1164, -0.6328, -0.6463],\n",
            "         [-0.1437, -0.4962, -0.3280],\n",
            "         [-0.1957, -0.9224, -0.6573],\n",
            "         [-0.8667, -0.2728, -1.0000],\n",
            "         [-0.4682, -0.8687,  0.1963],\n",
            "         [-1.0000, -0.7379, -0.3963]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377925992012024 0.34349414706230164\n",
            "tcost icost -0.025407087057828903 0.34627652168273926\n",
            "tcost icost -0.1405191421508789 0.35028693079948425\n",
            "tcost icost -0.1767335683107376 0.3480825424194336\n",
            "tcost icost 0.010181877762079239 0.3429172933101654\n",
            "tcost icost -0.5728893280029297 0.34353238344192505\n",
            "8 Parameter containing:\n",
            "tensor([[[ 0.0231, -0.7172, -0.7096],\n",
            "         [-0.2221, -0.5672, -0.4008],\n",
            "         [-0.2869, -0.9577, -0.6875],\n",
            "         [-0.9515, -0.3663, -1.0000],\n",
            "         [-0.5121, -0.8780,  0.2360],\n",
            "         [-1.0000, -0.7252, -0.4507]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377925992012024 0.3436048924922943\n",
            "tcost icost -0.06960180401802063 0.34139078855514526\n",
            "tcost icost -0.12262596189975739 0.3404064476490021\n",
            "tcost icost -0.1818910390138626 0.3437142074108124\n",
            "tcost icost 0.01029181107878685 0.34767332673072815\n",
            "tcost icost -0.5731269121170044 0.3476896584033966\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.0717, -0.7911, -0.7489],\n",
            "         [-0.2969, -0.6354, -0.4755],\n",
            "         [-0.3772, -0.9906, -0.7174],\n",
            "         [-1.0000, -0.4612, -1.0000],\n",
            "         [-0.5562, -0.8847,  0.2824],\n",
            "         [-1.0000, -0.7053, -0.5026]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377925992012024 0.34324491024017334\n",
            "tcost icost -0.06960180401802063 0.34635525941848755\n",
            "tcost icost -0.12262596189975739 0.3453417718410492\n",
            "tcost icost -0.18189123272895813 0.3435114920139313\n",
            "tcost icost 0.003094621002674103 0.3429109454154968\n",
            "tcost icost -0.5187948942184448 0.3477359712123871\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.1677, -0.8561, -0.7694],\n",
            "         [-0.3762, -0.7011, -0.5516],\n",
            "         [-0.4667, -1.0000, -0.7469],\n",
            "         [-1.0000, -0.5569, -1.0000],\n",
            "         [-0.5348, -0.8808,  0.3365],\n",
            "         [-1.0000, -0.6763, -0.5562]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377925992012024 0.348086953163147\n",
            "tcost icost -0.06960180401802063 0.34183865785598755\n",
            "tcost icost -0.12262621521949768 0.34525638818740845\n",
            "tcost icost -0.27136802673339844 0.34347161650657654\n",
            "tcost icost 0.013390962034463882 0.35178589820861816\n",
            "tcost icost -0.5807248950004578 0.3477517366409302\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.2648, -0.9134, -0.7747],\n",
            "         [-0.4598, -0.7646, -0.6286],\n",
            "         [-0.5551, -1.0000, -0.7758],\n",
            "         [-1.0000, -0.6466, -1.0000],\n",
            "         [-0.5200, -0.8759,  0.3946],\n",
            "         [-1.0000, -0.6416, -0.6076]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377925992012024 0.3431445062160492\n",
            "tcost icost -0.06960184872150421 0.34611257910728455\n",
            "tcost icost -0.2619767189025879 0.3440931737422943\n",
            "tcost icost -0.2395925223827362 0.3423229455947876\n",
            "tcost icost 0.013330306857824326 0.3475189208984375\n",
            "tcost icost -0.564521074295044 0.34764835238456726\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.3627, -0.9639, -0.7671],\n",
            "         [-0.5465, -0.8247, -0.7047],\n",
            "         [-0.6440, -1.0000, -0.8161],\n",
            "         [-1.0000, -0.7304, -1.0000],\n",
            "         [-0.5076, -0.8705,  0.4565],\n",
            "         [-1.0000, -0.6023, -0.6578]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377925992012024 0.34806546568870544\n",
            "tcost icost -0.06960184872150421 0.34651073813438416\n",
            "tcost icost -0.2619767189025879 0.3438820540904999\n",
            "tcost icost -0.23959273099899292 0.3427883982658386\n",
            "tcost icost 0.013330306857824326 0.3463081121444702\n",
            "tcost icost -0.564521074295044 0.34346693754196167\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.4610, -1.0000, -0.7486],\n",
            "         [-0.6355, -0.8819, -0.7798],\n",
            "         [-0.7329, -1.0000, -0.8651],\n",
            "         [-1.0000, -0.8087, -1.0000],\n",
            "         [-0.4977, -0.8647,  0.5215],\n",
            "         [-1.0000, -0.5584, -0.7068]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.4377932548522949 0.3479471802711487\n",
            "tcost icost -0.12637795507907867 0.34579387307167053\n",
            "tcost icost -0.26815181970596313 0.3436594009399414\n",
            "tcost icost -0.2283061146736145 0.3470664322376251\n",
            "tcost icost 0.013273246586322784 0.3465414047241211\n",
            "tcost icost -0.558178186416626 0.34301674365997314\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.5595, -1.0000, -0.7196],\n",
            "         [-0.7259, -0.9376, -0.8584],\n",
            "         [-0.8215, -1.0000, -0.9208],\n",
            "         [-1.0000, -0.8793, -1.0000],\n",
            "         [-0.4898, -0.8575,  0.5893],\n",
            "         [-1.0000, -0.5101, -0.7546]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8038927316665649 0.34386393427848816\n",
            "tcost icost -0.1263805627822876 0.3401592969894409\n",
            "tcost icost -0.2816199064254761 0.33841168880462646\n",
            "tcost icost -0.22109609842300415 0.34663039445877075\n",
            "tcost icost 0.01320890337228775 0.3512815535068512\n",
            "tcost icost -0.519466757774353 0.34309062361717224\n",
            "15 Parameter containing:\n",
            "tensor([[[-0.6582, -1.0000, -0.6776],\n",
            "         [-0.8182, -0.9922, -0.9400],\n",
            "         [-0.9092, -1.0000, -0.9811],\n",
            "         [-1.0000, -0.9431, -1.0000],\n",
            "         [-0.4725, -0.8430,  0.6615],\n",
            "         [-1.0000, -0.4948, -0.8144]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8038927316665649 0.34873947501182556\n",
            "tcost icost -0.12638059258460999 0.34479066729545593\n",
            "tcost icost -0.2816195487976074 0.3429207503795624\n",
            "tcost icost -0.22109633684158325 0.3468611240386963\n",
            "tcost icost 0.013208907097578049 0.34177646040916443\n",
            "tcost icost -0.5194666385650635 0.3477426767349243\n",
            "16 Parameter containing:\n",
            "tensor([[[-0.7567, -1.0000, -0.6252],\n",
            "         [-0.9122, -1.0000, -1.0000],\n",
            "         [-0.9956, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.4467, -0.8217,  0.7369],\n",
            "         [-1.0000, -0.5024, -0.8824]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8038927316665649 0.3426249027252197\n",
            "tcost icost -0.1263805627822876 0.339873731136322\n",
            "tcost icost -0.2816199064254761 0.3430061340332031\n",
            "tcost icost -0.22109642624855042 0.3466833829879761\n",
            "tcost icost 0.013208914548158646 0.34655752778053284\n",
            "tcost icost -0.5194668769836426 0.3523956537246704\n",
            "17 Parameter containing:\n",
            "tensor([[[-0.8545, -0.9956, -0.5642],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.4133, -0.7942,  0.8146],\n",
            "         [-1.0000, -0.5268, -0.9563]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8038928508758545 0.3474143445491791\n",
            "tcost icost -0.12638026475906372 0.33977338671684265\n",
            "tcost icost -0.28161999583244324 0.33867576718330383\n",
            "tcost icost -0.22109615802764893 0.3515971004962921\n",
            "tcost icost 0.013208892196416855 0.34138840436935425\n",
            "tcost icost -0.5194663405418396 0.3427792489528656\n",
            "18 Parameter containing:\n",
            "tensor([[[-0.9512, -0.9803, -0.4959],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.3730, -0.7606,  0.8937],\n",
            "         [-1.0000, -0.5639, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.8038929104804993 0.34298306703567505\n",
            "tcost icost -0.12638048827648163 0.34476354718208313\n",
            "tcost icost -0.2816203534603119 0.34319815039634705\n",
            "tcost icost -0.22109627723693848 0.3467821776866913\n",
            "tcost icost 0.01320890337228775 0.3418646454811096\n",
            "tcost icost -0.5544621348381042 0.3557366132736206\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9552, -0.4217],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.3368, -0.7275,  0.9718],\n",
            "         [-1.0000, -0.5918, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search -0.1829049289226532\n",
            "Parameter containing:\n",
            "tensor([[[ 0.0959, -0.5083, -0.4273],\n",
            "         [-0.2256,  0.1041, -0.1618],\n",
            "         [ 0.2372, -0.2254, -0.0388],\n",
            "         [ 0.0633, -0.4485, -0.2250],\n",
            "         [ 0.3457, -0.4792,  0.1968],\n",
            "         [-0.0301, -0.5139, -0.0347]]], requires_grad=True)\n",
            "tcost icost -0.08539833128452301 0.34984448552131653\n",
            "tcost icost -0.040948908776044846 0.354198694229126\n",
            "tcost icost -0.038411956280469894 0.35785382986068726\n",
            "tcost icost -0.056642044335603714 0.355137437582016\n",
            "tcost icost 0.15087778866291046 0.3489556312561035\n",
            "tcost icost -0.3977051377296448 0.3487222492694855\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.0042, -0.6078, -0.3269],\n",
            "         [-0.3254,  0.0040, -0.2616],\n",
            "         [ 0.1370, -0.3251, -0.1387],\n",
            "         [-0.0367, -0.5480, -0.3248],\n",
            "         [ 0.2453, -0.5787,  0.0966],\n",
            "         [-0.1300, -0.6134, -0.1347]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.10131683945655823 0.3543330132961273\n",
            "tcost icost -0.038427744060754776 0.35402610898017883\n",
            "tcost icost -0.03923625126481056 0.35674288868904114\n",
            "tcost icost -0.05679004266858101 0.34555017948150635\n",
            "tcost icost 0.007273804396390915 0.3482059836387634\n",
            "tcost icost -0.22307133674621582 0.35384514927864075\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.0766, -0.7049, -0.2301],\n",
            "         [-0.4244, -0.0957, -0.3610],\n",
            "         [ 0.0371, -0.4245, -0.2386],\n",
            "         [-0.1118, -0.6455, -0.4212],\n",
            "         [ 0.1716, -0.5749,  0.1305],\n",
            "         [-0.2297, -0.6783, -0.2177]]], requires_grad=True)\n",
            "tensor([[[ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  1.],\n",
            "         [ 0., -1.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.10131683945655823 0.35440725088119507\n",
            "tcost icost -0.038427744060754776 0.34934720396995544\n",
            "tcost icost -0.03923625126481056 0.36168909072875977\n",
            "tcost icost -0.13475948572158813 0.34566181898117065\n",
            "tcost icost 0.009223219007253647 0.3530365824699402\n",
            "tcost icost -0.23579323291778564 0.35890501737594604\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.1347, -0.8028, -0.1322],\n",
            "         [-0.5227, -0.1952, -0.4600],\n",
            "         [-0.0617, -0.5227, -0.3367],\n",
            "         [-0.1794, -0.7289, -0.5128],\n",
            "         [ 0.1130, -0.5314,  0.1940],\n",
            "         [-0.3293, -0.7256, -0.2966]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.10131683945655823 0.3495330512523651\n",
            "tcost icost -0.038427744060754776 0.35445013642311096\n",
            "tcost icost -0.03923625126481056 0.3518480956554413\n",
            "tcost icost -0.13475961983203888 0.3550986349582672\n",
            "tcost icost 0.16322408616542816 0.3407370448112488\n",
            "tcost icost -0.3529735803604126 0.35409271717071533\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.1830, -0.9007, -0.0336],\n",
            "         [-0.6201, -0.2943, -0.5585],\n",
            "         [-0.1599, -0.6203, -0.4346],\n",
            "         [-0.2582, -0.8026, -0.6005],\n",
            "         [ 0.0390, -0.5667,  0.1810],\n",
            "         [-0.4289, -0.7413, -0.3105]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.10131683945655823 0.35470589995384216\n",
            "tcost icost -0.09499393403530121 0.3486618995666504\n",
            "tcost icost -0.09524768590927124 0.3468901515007019\n",
            "tcost icost -0.11893415451049805 0.35442259907722473\n",
            "tcost icost 0.009053070098161697 0.35294201970100403\n",
            "tcost icost -0.23322343826293945 0.3492973744869232\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.2235, -0.9976,  0.0655],\n",
            "         [-0.7172, -0.3931, -0.6552],\n",
            "         [-0.2408, -0.7171, -0.5281],\n",
            "         [-0.3428, -0.8693, -0.6853],\n",
            "         [-0.0248, -0.5810,  0.1924],\n",
            "         [-0.5277, -0.7521, -0.3322]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2289777398109436 0.3501744866371155\n",
            "tcost icost -0.0910765677690506 0.35347580909729004\n",
            "tcost icost -0.09648020565509796 0.3513709604740143\n",
            "tcost icost -0.11858120560646057 0.35007262229919434\n",
            "tcost icost 0.009057305753231049 0.3434796631336212\n",
            "tcost icost -0.23311546444892883 0.3536045551300049\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.2810, -1.0000,  0.1645],\n",
            "         [-0.8150, -0.4920, -0.7526],\n",
            "         [-0.3259, -0.8131, -0.6228],\n",
            "         [-0.4308, -0.9308, -0.7678],\n",
            "         [-0.0809, -0.5794,  0.2206],\n",
            "         [-0.6255, -0.7591, -0.3602]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.22897768020629883 0.3541073799133301\n",
            "tcost icost -0.09107658267021179 0.3488118648529053\n",
            "tcost icost -0.09648032486438751 0.36097225546836853\n",
            "tcost icost -0.11858153343200684 0.3498542606830597\n",
            "tcost icost 0.009057320654392242 0.34440121054649353\n",
            "tcost icost -0.5427871942520142 0.3527345061302185\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.3503, -1.0000,  0.2638],\n",
            "         [-0.9131, -0.5907, -0.8500],\n",
            "         [-0.4144, -0.9080, -0.7187],\n",
            "         [-0.5214, -0.9884, -0.8481],\n",
            "         [-0.1420, -0.5563,  0.2645],\n",
            "         [-0.7174, -0.7450, -0.3933]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.22897768020629883 0.35418230295181274\n",
            "tcost icost -0.18492580950260162 0.3483125567436218\n",
            "tcost icost -0.08597496151924133 0.36028027534484863\n",
            "tcost icost -0.11967933177947998 0.3500266671180725\n",
            "tcost icost 0.009120270609855652 0.3527509868144989\n",
            "tcost icost -0.5448755025863647 0.3428909480571747\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.4268, -1.0000,  0.3633],\n",
            "         [-1.0000, -0.6833, -0.9476],\n",
            "         [-0.5052, -1.0000, -0.8147],\n",
            "         [-0.6135, -1.0000, -0.9264],\n",
            "         [-0.2070, -0.5178,  0.3191],\n",
            "         [-0.8044, -0.7153, -0.4307]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.22897768020629883 0.34956133365631104\n",
            "tcost icost -0.18492592871189117 0.35375267267227173\n",
            "tcost icost -0.08597506582736969 0.34645840525627136\n",
            "tcost icost -0.2520763874053955 0.35343217849731445\n",
            "tcost icost 0.20290443301200867 0.33681097626686096\n",
            "tcost icost -0.7525294423103333 0.3558982312679291\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.5084, -1.0000,  0.4630],\n",
            "         [-1.0000, -0.7705, -1.0000],\n",
            "         [-0.5973, -1.0000, -0.9095],\n",
            "         [-0.7071, -1.0000, -1.0000],\n",
            "         [-0.2802, -0.5098,  0.3503],\n",
            "         [-0.8940, -0.6683, -0.4687]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.22897785902023315 0.3542584478855133\n",
            "tcost icost -0.1849260926246643 0.3487018644809723\n",
            "tcost icost -0.17460384964942932 0.3506280779838562\n",
            "tcost icost -0.254146933555603 0.3438081443309784\n",
            "tcost icost 0.21229317784309387 0.35035261511802673\n",
            "tcost icost -0.7510278224945068 0.3505000174045563\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.5935, -1.0000,  0.5624],\n",
            "         [-1.0000, -0.8528, -1.0000],\n",
            "         [-0.6911, -1.0000, -1.0000],\n",
            "         [-0.8013, -1.0000, -1.0000],\n",
            "         [-0.3588, -0.5239,  0.3631],\n",
            "         [-0.9856, -0.6091, -0.4990]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3589448928833008\n",
            "tcost icost -0.18275992572307587 0.3534797132015228\n",
            "tcost icost -0.17991520464420319 0.3598238229751587\n",
            "tcost icost -0.25709789991378784 0.3481422960758209\n",
            "tcost icost 0.21403682231903076 0.35019615292549133\n",
            "tcost icost -0.7506088018417358 0.34639954566955566\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.6601, -1.0000,  0.6612],\n",
            "         [-1.0000, -0.9306, -1.0000],\n",
            "         [-0.7861, -1.0000, -1.0000],\n",
            "         [-0.8956, -1.0000, -1.0000],\n",
            "         [-0.4415, -0.5544,  0.3603],\n",
            "         [-1.0000, -0.5412, -0.5226]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3541346490383148\n",
            "tcost icost -0.18275992572307587 0.35312142968177795\n",
            "tcost icost -0.17991520464420319 0.34523627161979675\n",
            "tcost icost -0.25709789991378784 0.3484525680541992\n",
            "tcost icost 0.0132119320333004 0.3465413451194763\n",
            "tcost icost -0.5374546647071838 0.3472968339920044\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.7116, -1.0000,  0.7604],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8819, -1.0000, -1.0000],\n",
            "         [-0.9901, -1.0000, -1.0000],\n",
            "         [-0.4869, -0.5680,  0.3779],\n",
            "         [-1.0000, -0.5257, -0.5697]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3541346490383148\n",
            "tcost icost -0.18275992572307587 0.3531271517276764\n",
            "tcost icost -0.17991504073143005 0.34996333718299866\n",
            "tcost icost -0.2570977210998535 0.35231533646583557\n",
            "tcost icost 0.0132119320333004 0.3561203181743622\n",
            "tcost icost -0.5374544262886047 0.352034330368042\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.7501, -1.0000,  0.8600],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9778, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5062, -0.5676,  0.4103],\n",
            "         [-1.0000, -0.5387, -0.6294]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3491705656051636\n",
            "tcost icost -0.18275992572307587 0.3483390808105469\n",
            "tcost icost -0.17991510033607483 0.34996309876441956\n",
            "tcost icost -0.257097989320755 0.34803295135498047\n",
            "tcost icost 0.01321195438504219 0.3558790683746338\n",
            "tcost icost -0.5374549627304077 0.3520611822605133\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.7776, -1.0000,  0.9596],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5059, -0.5552,  0.4538],\n",
            "         [-1.0000, -0.5699, -0.6976]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.35402268171310425\n",
            "tcost icost -0.18275992572307587 0.34816989302635193\n",
            "tcost icost -0.17991510033607483 0.35485050082206726\n",
            "tcost icost -0.257097989320755 0.3478134572505951\n",
            "tcost icost 0.013211946934461594 0.34227481484413147\n",
            "tcost icost -0.5812482237815857 0.3513900339603424\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.7953, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5100, -0.5433,  0.5012],\n",
            "         [-1.0000, -0.5925, -0.7611]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3540332615375519\n",
            "tcost icost -0.18275992572307587 0.3484776020050049\n",
            "tcost icost -0.17991510033607483 0.35006213188171387\n",
            "tcost icost -0.257097989320755 0.3487686812877655\n",
            "tcost icost 0.21403692662715912 0.34074169397354126\n",
            "tcost icost -0.7506096363067627 0.3467569947242737\n",
            "15 Parameter containing:\n",
            "tensor([[[-0.8041, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5253, -0.5495,  0.5340],\n",
            "         [-1.0000, -0.6011, -0.8183]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3492547571659088\n",
            "tcost icost -0.18275992572307587 0.34845882654190063\n",
            "tcost icost -0.17991510033607483 0.35010480880737305\n",
            "tcost icost -0.257097989320755 0.34274721145629883\n",
            "tcost icost 0.21403692662715912 0.33696839213371277\n",
            "tcost icost -0.7506093978881836 0.34662163257598877\n",
            "16 Parameter containing:\n",
            "tensor([[[-0.8050, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5502, -0.5702,  0.5543],\n",
            "         [-1.0000, -0.5977, -0.8699]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3496183156967163\n",
            "tcost icost -0.18275992572307587 0.35354894399642944\n",
            "tcost icost -0.17991510033607483 0.350297212600708\n",
            "tcost icost -0.257097989320755 0.3430621922016144\n",
            "tcost icost 0.005587209016084671 0.3521357774734497\n",
            "tcost icost -0.5319013595581055 0.3470901846885681\n",
            "17 Parameter containing:\n",
            "tensor([[[-0.7989, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5361, -0.5787,  0.5827],\n",
            "         [-1.0000, -0.5871, -0.9193]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.3544946610927582\n",
            "tcost icost -0.18275992572307587 0.3574850559234619\n",
            "tcost icost -0.17991510033607483 0.34535202383995056\n",
            "tcost icost -0.257097989320755 0.3480098247528076\n",
            "tcost icost 0.013211946934461594 0.35997915267944336\n",
            "tcost icost -0.5812480449676514 0.34718838334083557\n",
            "18 Parameter containing:\n",
            "tensor([[[-0.7861, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5261, -0.5860,  0.6157],\n",
            "         [-1.0000, -0.5719, -0.9656]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2670551836490631 0.35436075925827026\n",
            "tcost icost -0.18275992572307587 0.35785508155822754\n",
            "tcost icost -0.17991510033607483 0.35491642355918884\n",
            "tcost icost -0.257097989320755 0.34271976351737976\n",
            "tcost icost 0.013211946934461594 0.34680575132369995\n",
            "tcost icost -0.5812480449676514 0.34244731068611145\n",
            "19 Parameter containing:\n",
            "tensor([[[-0.7671, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.5200, -0.5922,  0.6526],\n",
            "         [-1.0000, -0.5522, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.37129610776901245\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2532,  0.1162, -0.3855],\n",
            "         [-0.0218, -0.2114, -0.0118],\n",
            "         [-0.1045,  0.1162, -0.1510],\n",
            "         [ 0.0995, -0.4791, -0.1801],\n",
            "         [ 0.0896, -0.1816, -0.3523],\n",
            "         [ 0.4354, -0.3911,  0.1381]]], requires_grad=True)\n",
            "tcost icost -0.11486060917377472 0.3588661849498749\n",
            "tcost icost -0.032310325652360916 0.35218414664268494\n",
            "tcost icost -0.05895833298563957 0.35015377402305603\n",
            "tcost icost -0.054880540817976 0.3498005270957947\n",
            "tcost icost -0.06076892837882042 0.35415521264076233\n",
            "tcost icost 0.16846466064453125 0.35269254446029663\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.1529,  0.0161, -0.4851],\n",
            "         [-0.1217, -0.3112, -0.1118],\n",
            "         [-0.2044,  0.0161, -0.2509],\n",
            "         [-0.0006, -0.5787, -0.2799],\n",
            "         [-0.0105, -0.2814, -0.4519],\n",
            "         [ 0.3349, -0.4907,  0.0380]]], requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11486060917377472 0.349351704120636\n",
            "tcost icost -0.032310325652360916 0.35216039419174194\n",
            "tcost icost -0.05895833298563957 0.350826233625412\n",
            "tcost icost -0.11886832118034363 0.34495165944099426\n",
            "tcost icost -0.04923457279801369 0.35885393619537354\n",
            "tcost icost 0.16339361667633057 0.3481932282447815\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.0527, -0.0839, -0.5844],\n",
            "         [-0.2216, -0.4108, -0.2117],\n",
            "         [-0.3039, -0.0838, -0.3494],\n",
            "         [-0.0750, -0.6461, -0.3685],\n",
            "         [-0.1012, -0.3808, -0.5514],\n",
            "         [ 0.2355, -0.5897, -0.0620]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11486060917377472 0.3493807911872864\n",
            "tcost icost -0.032310325652360916 0.3476671874523163\n",
            "tcost icost -0.05895833298563957 0.34591251611709595\n",
            "tcost icost -0.11886855959892273 0.3495551347732544\n",
            "tcost icost -0.04923456534743309 0.34483879804611206\n",
            "tcost icost -0.10064613819122314 0.3543454706668854\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.0474, -0.1838, -0.6832],\n",
            "         [-0.3212, -0.5100, -0.3113],\n",
            "         [-0.4035, -0.1835, -0.4474],\n",
            "         [-0.1602, -0.6997, -0.4538],\n",
            "         [-0.1946, -0.4798, -0.6494],\n",
            "         [ 0.1429, -0.6648, -0.1435]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11486060917377472 0.3491589426994324\n",
            "tcost icost -0.032310325652360916 0.3521336317062378\n",
            "tcost icost -0.05895833298563957 0.35036614537239075\n",
            "tcost icost -0.11886832118034363 0.3492508828639984\n",
            "tcost icost -0.04923457279801369 0.3508304953575134\n",
            "tcost icost -0.1006460040807724 0.34926432371139526\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.1475, -0.2836, -0.7813],\n",
            "         [-0.4206, -0.6087, -0.4107],\n",
            "         [-0.5030, -0.2830, -0.5448],\n",
            "         [-0.2502, -0.7448, -0.5377],\n",
            "         [-0.2895, -0.5782, -0.7463],\n",
            "         [ 0.0484, -0.7249, -0.2140]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11486060917377472 0.3540906310081482\n",
            "tcost icost -0.0882468968629837 0.3474902808666229\n",
            "tcost icost -0.048346687108278275 0.34577617049217224\n",
            "tcost icost -0.1222282350063324 0.35444149374961853\n",
            "tcost icost -0.09088408946990967 0.349458783864975\n",
            "tcost icost -0.08902865648269653 0.35972821712493896\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.2472, -0.3828, -0.8777],\n",
            "         [-0.5098, -0.7062, -0.5051],\n",
            "         [-0.6018, -0.3818, -0.6410],\n",
            "         [-0.3426, -0.7858, -0.6184],\n",
            "         [-0.3477, -0.6694, -0.8369],\n",
            "         [-0.0404, -0.7778, -0.2800]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11486060917377472 0.3541451394557953\n",
            "tcost icost -0.08824712038040161 0.34746304154396057\n",
            "tcost icost -0.13875001668930054 0.34513333439826965\n",
            "tcost icost -0.10132145881652832 0.34938758611679077\n",
            "tcost icost -0.08947449922561646 0.3539191484451294\n",
            "tcost icost -0.08706952631473541 0.3546786308288574\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.3467, -0.4813, -0.9723],\n",
            "         [-0.6014, -0.8014, -0.6009],\n",
            "         [-0.6588, -0.4770, -0.7346],\n",
            "         [-0.4356, -0.8231, -0.6995],\n",
            "         [-0.4181, -0.7543, -0.9224],\n",
            "         [-0.1298, -0.8237, -0.3398]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.11486060917377472 0.35394537448883057\n",
            "tcost icost -0.15458355844020844 0.34651774168014526\n",
            "tcost icost -0.13862524926662445 0.3490890860557556\n",
            "tcost icost -0.09176671504974365 0.35385721921920776\n",
            "tcost icost -0.08689495921134949 0.34905728697776794\n",
            "tcost icost -0.08667367696762085 0.3451644480228424\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.4457, -0.5788, -1.0000],\n",
            "         [-0.6949, -0.8970, -0.6929],\n",
            "         [-0.7275, -0.5727, -0.8292],\n",
            "         [-0.5288, -0.8575, -0.7803],\n",
            "         [-0.4958, -0.8341, -1.0000],\n",
            "         [-0.2196, -0.8641, -0.3948]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.15704640746116638 0.34880921244621277\n",
            "tcost icost -0.14332641661167145 0.3559238910675049\n",
            "tcost icost -0.23918572068214417 0.3543390929698944\n",
            "tcost icost -0.07369667291641235 0.3445490896701813\n",
            "tcost icost -0.08861136436462402 0.3534514605998993\n",
            "tcost icost -0.08484125137329102 0.3584006726741791\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.5446, -0.6691, -1.0000],\n",
            "         [-0.7894, -0.9918, -0.7866],\n",
            "         [-0.8035, -0.6636, -0.9246],\n",
            "         [-0.6194, -0.8940, -0.8582],\n",
            "         [-0.5739, -0.9055, -1.0000],\n",
            "         [-0.3102, -0.9001, -0.4462]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.15704625844955444 0.34882107377052307\n",
            "tcost icost -0.14332610368728638 0.3514917492866516\n",
            "tcost icost -0.23918581008911133 0.34884828329086304\n",
            "tcost icost -0.2435816526412964 0.3519284725189209\n",
            "tcost icost -0.22384005784988403 0.3465140759944916\n",
            "tcost icost -0.05345753952860832 0.3532687723636627\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.6439, -0.7533, -1.0000],\n",
            "         [-0.8840, -1.0000, -0.8816],\n",
            "         [-0.8846, -0.7494, -1.0000],\n",
            "         [-0.7120, -0.9359, -0.9389],\n",
            "         [-0.6539, -0.9612, -1.0000],\n",
            "         [-0.3982, -0.9325, -0.4938]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2945374846458435 0.348600834608078\n",
            "tcost icost -0.14349891245365143 0.3506380617618561\n",
            "tcost icost -0.2546946704387665 0.3443475663661957\n",
            "tcost icost -0.23358780145645142 0.3472527861595154\n",
            "tcost icost -0.22514483332633972 0.35122525691986084\n",
            "tcost icost -0.0530281625688076 0.3624884784221649\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.7434, -0.8265, -1.0000],\n",
            "         [-0.9797, -1.0000, -0.9769],\n",
            "         [-0.9691, -0.8308, -1.0000],\n",
            "         [-0.8058, -0.9809, -1.0000],\n",
            "         [-0.7380, -0.9963, -1.0000],\n",
            "         [-0.4837, -0.9617, -0.5381]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.2945374846458435 0.34837645292282104\n",
            "tcost icost -0.14349891245365143 0.3462052643299103\n",
            "tcost icost -0.2546946406364441 0.348114550113678\n",
            "tcost icost -0.23358842730522156 0.34709295630455017\n",
            "tcost icost -0.22514432668685913 0.350678026676178\n",
            "tcost icost -0.05302814021706581 0.34819895029067993\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.8432, -0.8903, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9084, -1.0000],\n",
            "         [-0.9000, -1.0000, -1.0000],\n",
            "         [-0.8253, -1.0000, -1.0000],\n",
            "         [-0.5670, -0.9884, -0.5796]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.34872815012931824\n",
            "tcost icost -0.14349862933158875 0.35082152485847473\n",
            "tcost icost -0.2546951472759247 0.3529321551322937\n",
            "tcost icost -0.23358774185180664 0.34700486063957214\n",
            "tcost icost -0.22514450550079346 0.3459840714931488\n",
            "tcost icost -0.22397968173027039 0.34668591618537903\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.9428, -0.9459, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9823, -1.0000],\n",
            "         [-0.9942, -1.0000, -1.0000],\n",
            "         [-0.9140, -1.0000, -1.0000],\n",
            "         [-0.6501, -1.0000, -0.6314]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453766345977783 0.34840625524520874\n",
            "tcost icost -0.14349842071533203 0.34590959548950195\n",
            "tcost icost -0.2546950578689575 0.343826025724411\n",
            "tcost icost -0.23358765244483948 0.3518688976764679\n",
            "tcost icost -0.22514453530311584 0.34635692834854126\n",
            "tcost icost -0.22398003935813904 0.3511987030506134\n",
            "12 Parameter containing:\n",
            "tensor([[[-1.0000, -0.9944, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9923, -1.0000],\n",
            "         [-0.7363, -1.0000, -0.6908]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453766345977783 0.34859752655029297\n",
            "tcost icost -0.14349842071533203 0.3518780767917633\n",
            "tcost icost -0.25469502806663513 0.34373921155929565\n",
            "tcost icost -0.23358803987503052 0.3559289872646332\n",
            "tcost icost -0.2251443862915039 0.3514194190502167\n",
            "tcost icost -0.2239801287651062 0.34658166766166687\n",
            "13 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9740, -1.0000],\n",
            "         [-0.8252, -1.0000, -0.7558]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.3532269299030304\n",
            "tcost icost -0.14349862933158875 0.3507976233959198\n",
            "tcost icost -0.2546948790550232 0.34938690066337585\n",
            "tcost icost -0.23358777165412903 0.34722650051116943\n",
            "tcost icost -0.2251448631286621 0.3466823101043701\n",
            "tcost icost -0.22397977113723755 0.3510463237762451\n",
            "14 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9464, -1.0000],\n",
            "         [-0.9163, -1.0000, -0.8250]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.3533194959163666\n",
            "tcost icost -0.14349862933158875 0.3458803594112396\n",
            "tcost icost -0.2546948790550232 0.3577656149864197\n",
            "tcost icost -0.23358777165412903 0.34670519828796387\n",
            "tcost icost -0.2251448631286621 0.3466871976852417\n",
            "tcost icost -0.22397977113723755 0.3553817570209503\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9102, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.8973]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.3485914170742035\n",
            "tcost icost -0.14349862933158875 0.34599366784095764\n",
            "tcost icost -0.2546948790550232 0.34809061884880066\n",
            "tcost icost -0.23358777165412903 0.3566036820411682\n",
            "tcost icost -0.2251448631286621 0.3461185097694397\n",
            "tcost icost -0.2239796221256256 0.3464299738407135\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8663, -1.0000],\n",
            "         [-1.0000, -0.9998, -0.9717]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.353451669216156\n",
            "tcost icost -0.14349862933158875 0.3506600260734558\n",
            "tcost icost -0.2546948790550232 0.3530629575252533\n",
            "tcost icost -0.23358777165412903 0.34707316756248474\n",
            "tcost icost -0.22514483332633972 0.34636807441711426\n",
            "tcost icost -0.22397994995117188 0.3560016453266144\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8152, -1.0000],\n",
            "         [-1.0000, -0.9963, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.34865355491638184\n",
            "tcost icost -0.14349862933158875 0.3506558835506439\n",
            "tcost icost -0.2546948790550232 0.3486051857471466\n",
            "tcost icost -0.23358777165412903 0.3464615046977997\n",
            "tcost icost -0.2251448631286621 0.34194642305374146\n",
            "tcost icost -0.2239796221256256 0.36038994789123535\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.7574, -1.0000],\n",
            "         [-1.0000, -0.9895, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.29453781247138977 0.34857138991355896\n",
            "tcost icost -0.14349862933158875 0.35074886679649353\n",
            "tcost icost -0.2546948790550232 0.3531075716018677\n",
            "tcost icost -0.23358777165412903 0.3420933187007904\n",
            "tcost icost -0.22514483332633972 0.3422292172908783\n",
            "tcost icost -0.22397994995117188 0.35142767429351807\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.6936, -1.0000],\n",
            "         [-1.0000, -0.9797, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.3340804874897003\n",
            "Parameter containing:\n",
            "tensor([[[ 0.0822,  0.3248,  0.2801],\n",
            "         [-0.5146,  0.0619, -0.3170],\n",
            "         [ 0.2640,  0.1932,  0.1256],\n",
            "         [-0.2901,  0.0207,  0.2160],\n",
            "         [-0.1798,  0.4392,  0.2571],\n",
            "         [ 0.1450,  0.4219,  0.5315]]], requires_grad=True)\n",
            "tcost icost -0.0001947842538356781 0.3499792814254761\n",
            "tcost icost -0.12299063801765442 0.3489035367965698\n",
            "tcost icost 0.17271122336387634 0.33823251724243164\n",
            "tcost icost 0.0825800970196724 0.3391134440898895\n",
            "tcost icost 0.12556874752044678 0.3423618674278259\n",
            "tcost icost 0.11944065988063812 0.3466038703918457\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.0179,  0.4245,  0.3798],\n",
            "         [-0.6140, -0.0381, -0.4166],\n",
            "         [ 0.1638,  0.0930,  0.0255],\n",
            "         [-0.3898, -0.0794,  0.1158],\n",
            "         [-0.2796,  0.3387,  0.1568],\n",
            "         [ 0.0448,  0.3214,  0.4309]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.0001947842538356781 0.34556934237480164\n",
            "tcost icost -0.3181086778640747 0.34831953048706055\n",
            "tcost icost 0.19647467136383057 0.346770703792572\n",
            "tcost icost 0.08072681725025177 0.3528652489185333\n",
            "tcost icost 0.12870101630687714 0.341680109500885\n",
            "tcost icost 0.11957061290740967 0.3379700779914856\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.1116,  0.5200,  0.4735],\n",
            "         [-0.6951, -0.1364, -0.5162],\n",
            "         [ 0.0650, -0.0071, -0.0745],\n",
            "         [-0.4811, -0.1793,  0.0157],\n",
            "         [-0.3793,  0.2384,  0.0566],\n",
            "         [-0.0552,  0.2211,  0.3305]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.0001947842538356781 0.3548460304737091\n",
            "tcost icost -0.3181086778640747 0.3433716893196106\n",
            "tcost icost -0.03587191179394722 0.34780651330947876\n",
            "tcost icost 0.1642744243144989 0.34319013357162476\n",
            "tcost icost 0.09085582196712494 0.34835273027420044\n",
            "tcost icost 0.1257820725440979 0.3516569137573242\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.2075,  0.6169,  0.5694],\n",
            "         [-0.7837, -0.2352, -0.6154],\n",
            "         [-0.0320, -0.0917, -0.1623],\n",
            "         [-0.5709, -0.2790, -0.0843],\n",
            "         [-0.4789,  0.1381, -0.0433],\n",
            "         [-0.1441,  0.1208,  0.2301]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.061659447848796844 0.34277498722076416\n",
            "tcost icost -0.5738505125045776 0.34703677892684937\n",
            "tcost icost -0.02677956596016884 0.3520947992801666\n",
            "tcost icost -0.284518301486969 0.3471991717815399\n",
            "tcost icost -0.034599754959344864 0.3476351201534271\n",
            "tcost icost 0.172433003783226 0.35211804509162903\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.3033,  0.7111,  0.6584],\n",
            "         [-0.8753, -0.3326, -0.7143],\n",
            "         [-0.1118, -0.1606, -0.2329],\n",
            "         [-0.6355, -0.3788, -0.1834],\n",
            "         [-0.5783,  0.0518, -0.1307],\n",
            "         [-0.2231,  0.0207,  0.1299]]], requires_grad=True)\n",
            "tensor([[[ 0.,  1.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.061659447848796844 0.3477145731449127\n",
            "tcost icost -0.5738505125045776 0.3469853401184082\n",
            "tcost icost -0.02677956596016884 0.3469938337802887\n",
            "tcost icost -0.284518301486969 0.3474081754684448\n",
            "tcost icost -0.1507333368062973 0.3416307866573334\n",
            "tcost icost 0.20551007986068726 0.33708083629608154\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.3988,  0.8031,  0.7424],\n",
            "         [-0.9681, -0.4305, -0.8134],\n",
            "         [-0.1817, -0.2191, -0.2921],\n",
            "         [-0.7107, -0.4782, -0.2827],\n",
            "         [-0.6509, -0.0375, -0.2215],\n",
            "         [-0.3062, -0.0794,  0.0296]]], requires_grad=True)\n",
            "tensor([[[ 0.,  1.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.061659447848796844 0.3475028872489929\n",
            "tcost icost -0.5738505125045776 0.3426182270050049\n",
            "tcost icost -0.02677956596016884 0.3520730137825012\n",
            "tcost icost -0.28451815247535706 0.34695303440093994\n",
            "tcost icost -0.1507335603237152 0.35088151693344116\n",
            "tcost icost 0.2055101841688156 0.35066866874694824\n",
            "5 Parameter containing:\n",
            "tensor([[[-0.4940,  0.8930,  0.8227],\n",
            "         [-1.0000, -0.5290, -0.9122],\n",
            "         [-0.2443, -0.2696, -0.3428],\n",
            "         [-0.7920, -0.5771, -0.3822],\n",
            "         [-0.7305, -0.1287, -0.3143],\n",
            "         [-0.3920, -0.1796, -0.0707]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.061659324914216995 0.34303730726242065\n",
            "tcost icost -0.5738509893417358 0.35177919268608093\n",
            "tcost icost -0.02677951380610466 0.3426554799079895\n",
            "tcost icost -0.36900320649147034 0.35133516788482666\n",
            "tcost icost -0.11872568726539612 0.34643858671188354\n",
            "tcost icost -0.04457652196288109 0.3523249626159668\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.5884,  0.9797,  0.8986],\n",
            "         [-1.0000, -0.6275, -1.0000],\n",
            "         [-0.3099, -0.3149, -0.3842],\n",
            "         [-0.8723, -0.6606, -0.4777],\n",
            "         [-0.8149, -0.2210, -0.4080],\n",
            "         [-0.4808, -0.2702, -0.1628]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  1.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726734921336174 0.35071802139282227\n",
            "tcost icost -0.6295842528343201 0.3420313894748688\n",
            "tcost icost -0.021887633949518204 0.3512720465660095\n",
            "tcost icost -0.3666081726551056 0.34658166766166687\n",
            "tcost icost -0.1184266209602356 0.35191449522972107\n",
            "tcost icost -0.04440915212035179 0.3530041575431824\n",
            "7 Parameter containing:\n",
            "tensor([[[-0.6830,  1.0000,  0.9612],\n",
            "         [-1.0000, -0.7065, -1.0000],\n",
            "         [-0.3709, -0.3567, -0.4192],\n",
            "         [-0.9569, -0.7302, -0.5690],\n",
            "         [-0.9026, -0.3140, -0.5021],\n",
            "         [-0.5721, -0.3531, -0.2482]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.3465197682380676\n",
            "tcost icost -0.629584550857544 0.34639954566955566\n",
            "tcost icost -0.021887656301259995 0.34221336245536804\n",
            "tcost icost -0.366607666015625 0.3513927161693573\n",
            "tcost icost -0.11842679977416992 0.35010895133018494\n",
            "tcost icost -0.18800227344036102 0.34182238578796387\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.7775,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.7696, -1.0000],\n",
            "         [-0.4281, -0.3955, -0.4485],\n",
            "         [-1.0000, -0.7883, -0.6569],\n",
            "         [-0.9886, -0.4060, -0.5949],\n",
            "         [-0.6547, -0.4394, -0.3368]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726734176278114 0.34175190329551697\n",
            "tcost icost -0.6295839548110962 0.34185168147087097\n",
            "tcost icost -0.021887656301259995 0.34216147661209106\n",
            "tcost icost -0.36660778522491455 0.34706756472587585\n",
            "tcost icost -0.11842693388462067 0.3561118543148041\n",
            "tcost icost -0.18800216913223267 0.3561182916164398\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.8712,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.8196, -1.0000],\n",
            "         [-0.4819, -0.4319, -0.4729],\n",
            "         [-1.0000, -0.8367, -0.7416],\n",
            "         [-1.0000, -0.4972, -0.6861],\n",
            "         [-0.7401, -0.5281, -0.4277]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726734176278114 0.34644076228141785\n",
            "tcost icost -0.6295843720436096 0.3418716788291931\n",
            "tcost icost -0.021887656301259995 0.34204092621803284\n",
            "tcost icost -0.3666079044342041 0.35589393973350525\n",
            "tcost icost -0.11842693388462067 0.3419550955295563\n",
            "tcost icost -0.1880025416612625 0.3465464413166046\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.9638,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.8585, -1.0000],\n",
            "         [-0.5328, -0.4662, -0.4931],\n",
            "         [-1.0000, -0.8768, -0.8233],\n",
            "         [-1.0000, -0.5873, -0.7758],\n",
            "         [-0.8285, -0.6184, -0.5202]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.3464859426021576\n",
            "tcost icost -0.629584550857544 0.35121867060661316\n",
            "tcost icost -0.021887656301259995 0.3421608805656433\n",
            "tcost icost -0.366607666015625 0.35079702734947205\n",
            "tcost icost -0.19829434156417847 0.3507543206214905\n",
            "tcost icost -0.23010414838790894 0.341564416885376\n",
            "11 Parameter containing:\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.8879, -1.0000],\n",
            "         [-0.5816, -0.4988, -0.5097],\n",
            "         [-1.0000, -0.9097, -0.9020],\n",
            "         [-1.0000, -0.6661, -0.8629],\n",
            "         [-0.9072, -0.6985, -0.6113]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.3512202501296997\n",
            "tcost icost -0.6295844316482544 0.34659698605537415\n",
            "tcost icost -0.09056848287582397 0.341068297624588\n",
            "tcost icost -0.28137776255607605 0.34628647565841675\n",
            "tcost icost -0.2126401960849762 0.3458099365234375\n",
            "tcost icost -0.2242472767829895 0.3460458815097809\n",
            "12 Parameter containing:\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.9090, -1.0000],\n",
            "         [-0.6416, -0.5409, -0.5385],\n",
            "         [-1.0000, -0.9367, -0.9772],\n",
            "         [-1.0000, -0.7349, -0.9479],\n",
            "         [-0.9822, -0.7701, -0.6988]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.34653332829475403\n",
            "tcost icost -0.629584550857544 0.3463028073310852\n",
            "tcost icost -0.0905686616897583 0.34575706720352173\n",
            "tcost icost -0.281377911567688 0.35549917817115784\n",
            "tcost icost -0.21263986825942993 0.35071972012519836\n",
            "tcost icost -0.22424724698066711 0.3425014317035675\n",
            "13 Parameter containing:\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.9228, -1.0000],\n",
            "         [-0.7103, -0.5904, -0.5769],\n",
            "         [-1.0000, -0.9584, -1.0000],\n",
            "         [-1.0000, -0.7951, -1.0000],\n",
            "         [-1.0000, -0.8344, -0.7831]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.346736878156662\n",
            "tcost icost -0.629584550857544 0.3461891710758209\n",
            "tcost icost -0.16072189807891846 0.3455791771411896\n",
            "tcost icost -0.2416253685951233 0.34070372581481934\n",
            "tcost icost -0.2187861204147339 0.3457084894180298\n",
            "tcost icost -0.2196369767189026 0.35526490211486816\n",
            "14 Parameter containing:\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -0.9300, -1.0000],\n",
            "         [-0.7831, -0.6319, -0.6215],\n",
            "         [-1.0000, -0.9762, -1.0000],\n",
            "         [-1.0000, -0.8476, -1.0000],\n",
            "         [-1.0000, -0.8921, -0.8641]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.3416818678379059\n",
            "tcost icost -0.6295844316482544 0.34738799929618835\n",
            "tcost icost -0.16072207689285278 0.34556320309638977\n",
            "tcost icost -0.24162551760673523 0.3502286970615387\n",
            "tcost icost -0.21878618001937866 0.35528579354286194\n",
            "tcost icost -0.2196369767189026 0.3508920669555664\n",
            "15 Parameter containing:\n",
            "tensor([[[-1.0000,  0.9973,  0.9957],\n",
            "         [-1.0000, -0.9313, -1.0000],\n",
            "         [-0.8612, -0.6664, -0.6711],\n",
            "         [-1.0000, -0.9903, -1.0000],\n",
            "         [-1.0000, -0.8933, -1.0000],\n",
            "         [-1.0000, -0.9440, -0.9420]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726732313632965 0.3421463668346405\n",
            "tcost icost -0.6295841336250305 0.3464897871017456\n",
            "tcost icost -0.16072191298007965 0.34535977244377136\n",
            "tcost icost -0.24162566661834717 0.35528141260147095\n",
            "tcost icost -0.21878594160079956 0.34066468477249146\n",
            "tcost icost -0.21963727474212646 0.34630638360977173\n",
            "16 Parameter containing:\n",
            "tensor([[[-1.0000,  0.9876,  0.9851],\n",
            "         [-1.0000, -0.9271, -1.0000],\n",
            "         [-0.9437, -0.6944, -0.7248],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9329, -1.0000],\n",
            "         [-1.0000, -0.9905, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726730823516846 0.34179651737213135\n",
            "tcost icost -0.629584550857544 0.35140398144721985\n",
            "tcost icost -0.1607222855091095 0.34070661664009094\n",
            "tcost icost -0.24162545800209045 0.3504678010940552\n",
            "tcost icost -0.2187860906124115 0.34532827138900757\n",
            "tcost icost -0.2196369767189026 0.35512104630470276\n",
            "17 Parameter containing:\n",
            "tensor([[[-1.0000,  0.9715,  0.9684],\n",
            "         [-1.0000, -0.9178, -1.0000],\n",
            "         [-1.0000, -0.7167, -0.7818],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9670, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726732313632965 0.3512202501296997\n",
            "tcost icost -0.6295841336250305 0.3417491316795349\n",
            "tcost icost -0.16072195768356323 0.35029929876327515\n",
            "tcost icost -0.24162566661834717 0.35441890358924866\n",
            "tcost icost -0.21878576278686523 0.3506707549095154\n",
            "tcost icost -0.21963733434677124 0.3461682200431824\n",
            "18 Parameter containing:\n",
            "tensor([[[-1.0000,  0.9494,  0.9462],\n",
            "         [-1.0000, -0.9037, -1.0000],\n",
            "         [-1.0000, -0.7337, -0.8414],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9962, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost 0.05726732313632965 0.3467082679271698\n",
            "tcost icost -0.6295841336250305 0.3464754521846771\n",
            "tcost icost -0.16072189807891846 0.34068387746810913\n",
            "tcost icost -0.2416253685951233 0.35012584924697876\n",
            "tcost icost -0.2187862992286682 0.34605273604393005\n",
            "tcost icost -0.2196369767189026 0.3412216901779175\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000,  0.9214,  0.9186],\n",
            "         [-1.0000, -0.8850, -1.0000],\n",
            "         [-1.0000, -0.7458, -0.9029],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.38218796253204346\n",
            "Parameter containing:\n",
            "tensor([[[-0.3133,  0.0706,  0.2184],\n",
            "         [-0.0812,  0.4464,  0.3548],\n",
            "         [ 0.1691, -0.2188,  0.3332],\n",
            "         [ 0.2472, -0.4389, -0.5184],\n",
            "         [-0.2871, -0.1346, -0.0932],\n",
            "         [ 0.1654,  0.4398,  0.1176]]], requires_grad=True)\n",
            "tcost icost -0.02740955725312233 0.3549838960170746\n",
            "tcost icost 0.008903693407773972 0.35286033153533936\n",
            "tcost icost 0.04918714612722397 0.3488032817840576\n",
            "tcost icost -0.26486945152282715 0.3489146828651428\n",
            "tcost icost -0.03512894734740257 0.3440724015235901\n",
            "tcost icost 0.16416627168655396 0.34795376658439636\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.2130, -0.0295,  0.1182],\n",
            "         [ 0.0189,  0.3460,  0.2545],\n",
            "         [ 0.0690, -0.3186,  0.4329],\n",
            "         [ 0.1469, -0.5385, -0.6178],\n",
            "         [-0.3868, -0.2344, -0.1931],\n",
            "         [ 0.0653,  0.3393,  0.0174]]], requires_grad=True)\n",
            "tensor([[[0., 0., 1.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740955725312233 0.3548823595046997\n",
            "tcost icost 0.008903693407773972 0.3575814366340637\n",
            "tcost icost 0.04918714612722397 0.34384849667549133\n",
            "tcost icost -0.26486945152282715 0.3496328890323639\n",
            "tcost icost -0.03512894734740257 0.353455126285553\n",
            "tcost icost 0.16416627168655396 0.3445107042789459\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.1127, -0.1294,  0.0180],\n",
            "         [ 0.1189,  0.2456,  0.1542],\n",
            "         [-0.0311, -0.4181,  0.5323],\n",
            "         [ 0.0467, -0.6377, -0.7170],\n",
            "         [-0.4862, -0.3341, -0.2929],\n",
            "         [-0.0348,  0.2390, -0.0826]]], requires_grad=True)\n",
            "tensor([[[0., 0., 1.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740955725312233 0.35497888922691345\n",
            "tcost icost 0.008903693407773972 0.3529433310031891\n",
            "tcost icost 0.049187254160642624 0.3484213352203369\n",
            "tcost icost -0.3268568515777588 0.3540533185005188\n",
            "tcost icost -0.03462553396821022 0.3536178171634674\n",
            "tcost icost -0.06901784241199493 0.3542930781841278\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.0126, -0.2293, -0.0820],\n",
            "         [ 0.0960,  0.1485,  0.0563],\n",
            "         [-0.1304, -0.5078,  0.5164],\n",
            "         [-0.0309, -0.7098, -0.7991],\n",
            "         [-0.5823, -0.4335, -0.3926],\n",
            "         [-0.1319,  0.1517, -0.1692]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06168564036488533 0.35514315962791443\n",
            "tcost icost 0.008725076913833618 0.35377368330955505\n",
            "tcost icost 0.04075951129198074 0.3488418757915497\n",
            "tcost icost -0.3114122152328491 0.3493160009384155\n",
            "tcost icost -0.14523813128471375 0.3531076908111572\n",
            "tcost icost -0.04472075775265694 0.3535785377025604\n",
            "3 Parameter containing:\n",
            "tensor([[[ 0.0539, -0.2925, -0.0669],\n",
            "         [ 0.1303,  0.0542, -0.0413],\n",
            "         [-0.2294, -0.5805,  0.5062],\n",
            "         [-0.1162, -0.7630, -0.8696],\n",
            "         [-0.6510, -0.5182, -0.4719],\n",
            "         [-0.2257,  0.0747, -0.2471]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06168564036488533 0.3499802052974701\n",
            "tcost icost -0.03596355393528938 0.3541366457939148\n",
            "tcost icost 0.00074009969830513 0.3466014266014099\n",
            "tcost icost -0.20099397003650665 0.3600224256515503\n",
            "tcost icost -0.16566303372383118 0.34889286756515503\n",
            "tcost icost -0.04349992796778679 0.3447817862033844\n",
            "4 Parameter containing:\n",
            "tensor([[[ 0.0953, -0.3304, -0.0227],\n",
            "         [ 0.0799, -0.0309, -0.1299],\n",
            "         [-0.3237, -0.6059,  0.5378],\n",
            "         [-0.2055, -0.8177, -0.9353],\n",
            "         [-0.7291, -0.6058, -0.5571],\n",
            "         [-0.3202,  0.0033, -0.3198]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  1.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06168564036488533 0.34988918900489807\n",
            "tcost icost -0.03596355393528938 0.3590543866157532\n",
            "tcost icost 0.00074009969830513 0.3513200283050537\n",
            "tcost icost -0.20099397003650665 0.35579729080200195\n",
            "tcost icost -0.2539063096046448 0.34868937730789185\n",
            "tcost icost -0.03366173431277275 0.34903886914253235\n",
            "5 Parameter containing:\n",
            "tensor([[[ 0.1180, -0.3494,  0.0369],\n",
            "         [ 0.0140, -0.1190, -0.2205],\n",
            "         [-0.4146, -0.6063,  0.5875],\n",
            "         [-0.2973, -0.8740, -0.9967],\n",
            "         [-0.8129, -0.6873, -0.6459],\n",
            "         [-0.4123, -0.0625, -0.3869]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  1.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740955725312233 0.35493162274360657\n",
            "tcost icost -0.043304044753313065 0.35862937569618225\n",
            "tcost icost 0.0025191381573677063 0.34611430764198303\n",
            "tcost icost -0.20582881569862366 0.3598666787147522\n",
            "tcost icost -0.25413936376571655 0.34833788871765137\n",
            "tcost icost -0.03350292518734932 0.35814598202705383\n",
            "6 Parameter containing:\n",
            "tensor([[[ 0.1542, -0.3828,  0.0835],\n",
            "         [-0.0604, -0.2083, -0.3121],\n",
            "         [-0.5038, -0.5839,  0.6497],\n",
            "         [-0.3910, -0.9281, -1.0000],\n",
            "         [-0.9002, -0.7640, -0.7368],\n",
            "         [-0.5025, -0.1240, -0.4496]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  1.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740953490138054 0.354914128780365\n",
            "tcost icost -0.04330405220389366 0.35414835810661316\n",
            "tcost icost 0.0025191493332386017 0.3512950837612152\n",
            "tcost icost -0.20582887530326843 0.355006605386734\n",
            "tcost icost -0.2541394531726837 0.34344378113746643\n",
            "tcost icost -0.03350294753909111 0.3493821918964386\n",
            "7 Parameter containing:\n",
            "tensor([[[ 0.2005, -0.4270,  0.1193],\n",
            "         [-0.1408, -0.2999, -0.4054],\n",
            "         [-0.5913, -0.5455,  0.7197],\n",
            "         [-0.4861, -0.9804, -1.0000],\n",
            "         [-0.9897, -0.8366, -0.8287],\n",
            "         [-0.5910, -0.1822, -0.5089]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740953490138054 0.35524922609329224\n",
            "tcost icost -0.04330405220389366 0.3630846440792084\n",
            "tcost icost 0.03810412064194679 0.3440629243850708\n",
            "tcost icost -0.33012616634368896 0.3450643718242645\n",
            "tcost icost -0.22135567665100098 0.34820356965065\n",
            "tcost icost -0.14449946582317352 0.34668299555778503\n",
            "8 Parameter containing:\n",
            "tensor([[[ 0.2545, -0.4792,  0.1459],\n",
            "         [-0.2256, -0.3934, -0.5002],\n",
            "         [-0.6746, -0.5045,  0.7880],\n",
            "         [-0.5812, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8959, -0.9206],\n",
            "         [-0.6749, -0.2494, -0.5765]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740955725312233 0.3500276505947113\n",
            "tcost icost -0.043304044753313065 0.35418495535850525\n",
            "tcost icost 0.03810413181781769 0.3533940315246582\n",
            "tcost icost -0.5932573080062866 0.3532150089740753\n",
            "tcost icost -0.16966578364372253 0.35189303755760193\n",
            "tcost icost -0.15104569494724274 0.35599982738494873\n",
            "9 Parameter containing:\n",
            "tensor([[[ 0.3131, -0.5374,  0.1657],\n",
            "         [-0.3137, -0.4884, -0.5960],\n",
            "         [-0.7606, -0.4475,  0.8612],\n",
            "         [-0.6700, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9504, -1.0000],\n",
            "         [-0.7602, -0.3240, -0.6505]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02740955725312233 0.3549044728279114\n",
            "tcost icost -0.043304044753313065 0.34953388571739197\n",
            "tcost icost 0.03810413181781769 0.34387892484664917\n",
            "tcost icost -0.5932573080062866 0.3534677028656006\n",
            "tcost icost -0.16966578364372253 0.3558002710342407\n",
            "tcost icost -0.15104569494724274 0.3566073775291443\n",
            "10 Parameter containing:\n",
            "tensor([[[ 0.3752, -0.6002,  0.1795],\n",
            "         [-0.4043, -0.5844, -0.6924],\n",
            "         [-0.8483, -0.3802,  0.9377],\n",
            "         [-0.7533, -0.9853, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.8462, -0.4039, -0.7289]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06092488393187523 0.3500974178314209\n",
            "tcost icost -0.09771876037120819 0.35366198420524597\n",
            "tcost icost 0.04788730666041374 0.3527335822582245\n",
            "tcost icost -0.6163550615310669 0.3533487021923065\n",
            "tcost icost -0.1663065105676651 0.3424791991710663\n",
            "tcost icost -0.15168344974517822 0.34689319133758545\n",
            "11 Parameter containing:\n",
            "tensor([[[ 0.3733, -0.6686,  0.1683],\n",
            "         [-0.4906, -0.6738, -0.7895],\n",
            "         [-0.9359, -0.3148,  0.9936],\n",
            "         [-0.8303, -0.9526, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9322, -0.4877, -0.8104]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06092488393187523 0.3548315465450287\n",
            "tcost icost -0.09771867096424103 0.3490050733089447\n",
            "tcost icost 0.04788722097873688 0.3482082784175873\n",
            "tcost icost -0.6163554787635803 0.3486316502094269\n",
            "tcost icost -0.16630619764328003 0.35167789459228516\n",
            "tcost icost -0.15168389678001404 0.35633113980293274\n",
            "12 Parameter containing:\n",
            "tensor([[[ 0.3450, -0.7435,  0.1395],\n",
            "         [-0.5790, -0.7573, -0.8868],\n",
            "         [-1.0000, -0.2507,  1.0000],\n",
            "         [-0.9018, -0.9062, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.5743, -0.8938]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06092480942606926 0.3548036515712738\n",
            "tcost icost -0.19266244769096375 0.3579767346382141\n",
            "tcost icost 0.07043606787919998 0.35193926095962524\n",
            "tcost icost -0.6654232740402222 0.35285094380378723\n",
            "tcost icost -0.15829622745513916 0.35165420174598694\n",
            "tcost icost -0.24298271536827087 0.3649654984474182\n",
            "13 Parameter containing:\n",
            "tensor([[[ 0.3014, -0.8231,  0.1001],\n",
            "         [-0.6688, -0.8386, -0.9841],\n",
            "         [-1.0000, -0.2403,  0.9983],\n",
            "         [-0.9685, -0.8490, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.6506, -0.9771]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06092488393187523 0.3548036515712738\n",
            "tcost icost -0.19266222417354584 0.34862956404685974\n",
            "tcost icost 0.07043600082397461 0.3520412743091583\n",
            "tcost icost -0.6654230952262878 0.3530270457267761\n",
            "tcost icost -0.15829643607139587 0.36084505915641785\n",
            "tcost icost -0.24298259615898132 0.3565487265586853\n",
            "14 Parameter containing:\n",
            "tensor([[[ 0.2466, -0.9058,  0.0519],\n",
            "         [-0.7594, -0.9177, -1.0000],\n",
            "         [-1.0000, -0.2573,  0.9734],\n",
            "         [-1.0000, -0.7832, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.7176, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.06092480942606926 0.35975906252861023\n",
            "tcost icost -0.19266235828399658 0.3532501459121704\n",
            "tcost icost 0.07043591886758804 0.3470008969306946\n",
            "tcost icost -0.6654228568077087 0.3527757227420807\n",
            "tcost icost -0.15829631686210632 0.34789976477622986\n",
            "tcost icost -0.2429826557636261 0.3561059534549713\n",
            "15 Parameter containing:\n",
            "tensor([[[ 0.1831, -0.9908, -0.0035],\n",
            "         [-0.8502, -0.9943, -1.0000],\n",
            "         [-1.0000, -0.2920,  0.9323],\n",
            "         [-1.0000, -0.7105, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.7766, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.060347821563482285 0.34985750913619995\n",
            "tcost icost -0.17728687822818756 0.3533725440502167\n",
            "tcost icost 0.06184648722410202 0.34792640805244446\n",
            "tcost icost -0.64866703748703 0.35303249955177307\n",
            "tcost icost -0.16105568408966064 0.35194119811058044\n",
            "tcost icost -0.24225503206253052 0.34261777997016907\n",
            "16 Parameter containing:\n",
            "tensor([[[ 0.1146, -1.0000, -0.0426],\n",
            "         [-0.9400, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.3362,  0.8807],\n",
            "         [-1.0000, -0.6322, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8283, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.060347821563482285 0.35502979159355164\n",
            "tcost icost -0.17728686332702637 0.35817885398864746\n",
            "tcost icost 0.06184649467468262 0.3482223153114319\n",
            "tcost icost -0.6486666202545166 0.353270024061203\n",
            "tcost icost -0.16105583310127258 0.34694740176200867\n",
            "tcost icost -0.2422550916671753 0.35135331749916077\n",
            "17 Parameter containing:\n",
            "tensor([[[ 0.0417, -1.0000, -0.0672],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.3880,  0.8203],\n",
            "         [-1.0000, -0.5493, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8735, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.060347821563482285 0.3499529957771301\n",
            "tcost icost -0.17728686332702637 0.3533748984336853\n",
            "tcost icost 0.06184649467468262 0.348084419965744\n",
            "tcost icost -0.6356390118598938 0.34322935342788696\n",
            "tcost icost -0.17506751418113708 0.35625314712524414\n",
            "tcost icost -0.23983758687973022 0.3564712703227997\n",
            "18 Parameter containing:\n",
            "tensor([[[-0.0352, -1.0000, -0.0791],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.4325,  0.7577],\n",
            "         [-1.0000, -0.5373, -1.0000],\n",
            "         [-1.0000, -0.9992, -1.0000],\n",
            "         [-1.0000, -0.9129, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.060347821563482285 0.35040050745010376\n",
            "tcost icost -0.17728686332702637 0.3535653352737427\n",
            "tcost icost 0.06184649467468262 0.35230204463005066\n",
            "tcost icost -0.6356390118598938 0.353022038936615\n",
            "tcost icost -0.17506751418113708 0.3470529019832611\n",
            "tcost icost -0.23983749747276306 0.3473569452762604\n",
            "19 Parameter containing:\n",
            "tensor([[[-0.1154, -1.0000, -0.0796],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.4703,  0.6926],\n",
            "         [-1.0000, -0.5548, -1.0000],\n",
            "         [-1.0000, -0.9951, -1.0000],\n",
            "         [-1.0000, -0.9471, -1.0000]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.5788072943687439\n",
            "Parameter containing:\n",
            "tensor([[[-0.4680,  0.0958,  0.4894],\n",
            "         [-0.2918,  0.0292, -0.1638],\n",
            "         [ 0.1176, -0.0918,  0.3279],\n",
            "         [-0.2669,  0.3002, -0.5289],\n",
            "         [-0.1461,  0.0745, -0.3840],\n",
            "         [ 0.5042,  0.4141,  0.1543]]], requires_grad=True)\n",
            "tcost icost -0.026828180998563766 0.3551389276981354\n",
            "tcost icost -0.043902862817049026 0.34913453459739685\n",
            "tcost icost 0.06917840242385864 0.34962525963783264\n",
            "tcost icost -0.32684463262557983 0.35499757528305054\n",
            "tcost icost -0.03169770911335945 0.34569236636161804\n",
            "tcost icost 0.1599729359149933 0.34486016631126404\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.3675, -0.0043,  0.3889],\n",
            "         [-0.3915, -0.0708, -0.2637],\n",
            "         [ 0.0175, -0.1917,  0.2276],\n",
            "         [-0.3667,  0.1999, -0.6284],\n",
            "         [-0.2460, -0.0255, -0.4837],\n",
            "         [ 0.4037,  0.3137,  0.0541]]], requires_grad=True)\n",
            "tensor([[[0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.026828180998563766 0.35048583149909973\n",
            "tcost icost -0.043902862817049026 0.349214643239975\n",
            "tcost icost 0.06917840242385864 0.36335939168930054\n",
            "tcost icost -0.32684463262557983 0.35508856177330017\n",
            "tcost icost -0.03169770911335945 0.34905096888542175\n",
            "tcost icost 0.1599729359149933 0.33949556946754456\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.2671, -0.1043,  0.2885],\n",
            "         [-0.4910, -0.1708, -0.3633],\n",
            "         [-0.0826, -0.2915,  0.1273],\n",
            "         [-0.4662,  0.0997, -0.7275],\n",
            "         [-0.3456, -0.1255, -0.5830],\n",
            "         [ 0.3032,  0.2134, -0.0459]]], requires_grad=True)\n",
            "tensor([[[0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 1.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02682819589972496 0.3510260581970215\n",
            "tcost icost -0.04390281066298485 0.3497585654258728\n",
            "tcost icost 0.06917832046747208 0.34947070479393005\n",
            "tcost icost -0.3268440067768097 0.3502306640148163\n",
            "tcost icost -0.03169776126742363 0.35308945178985596\n",
            "tcost icost -0.07070870697498322 0.350035160779953\n",
            "2 Parameter containing:\n",
            "tensor([[[-1.6675e-01, -2.0415e-01,  1.8808e-01],\n",
            "         [-5.9003e-01, -2.7054e-01, -4.6268e-01],\n",
            "         [-1.8252e-01, -3.9092e-01,  2.7122e-02],\n",
            "         [-5.6537e-01, -5.0423e-04, -8.2587e-01],\n",
            "         [-4.4396e-01, -2.2347e-01, -6.7923e-01],\n",
            "         [ 2.1019e-01,  1.2598e-01, -1.3308e-01]]], requires_grad=True)\n",
            "tensor([[[0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.02682819589972496 0.3505356013774872\n",
            "tcost icost -0.11200001835823059 0.34896308183670044\n",
            "tcost icost 0.09492120146751404 0.343811959028244\n",
            "tcost icost -0.6545212268829346 0.35341838002204895\n",
            "tcost icost -0.02480597421526909 0.3535182476043701\n",
            "tcost icost -0.07473482191562653 0.3541998863220215\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.1051, -0.2957,  0.1149],\n",
            "         [-0.6827, -0.3667, -0.5563],\n",
            "         [-0.2816, -0.4769, -0.0728],\n",
            "         [-0.6463, -0.0818, -0.9238],\n",
            "         [-0.5379, -0.3137, -0.7671],\n",
            "         [ 0.1165,  0.0452, -0.2141]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.026828180998563766 0.35014134645462036\n",
            "tcost icost -0.11200031638145447 0.3539799451828003\n",
            "tcost icost -0.034503985196352005 0.3564096987247467\n",
            "tcost icost -0.19924968481063843 0.3452773690223694\n",
            "tcost icost -0.0419650636613369 0.3493189811706543\n",
            "tcost icost -0.064713254570961 0.3642618954181671\n",
            "4 Parameter containing:\n",
            "tensor([[[-0.0664, -0.3821,  0.0559],\n",
            "         [-0.7773, -0.4637, -0.6514],\n",
            "         [-0.3809, -0.5543, -0.1613],\n",
            "         [-0.7326, -0.1633, -1.0000],\n",
            "         [-0.6333, -0.4061, -0.8582],\n",
            "         [ 0.0234, -0.0298, -0.2910]]], requires_grad=True)\n",
            "tensor([[[ 0.,  0.,  1.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.026828180998563766 0.35518357157707214\n",
            "tcost icost -0.11200036108493805 0.3547525107860565\n",
            "tcost icost -0.09547245502471924 0.35204747319221497\n",
            "tcost icost -0.16388869285583496 0.34476524591445923\n",
            "tcost icost -0.18533587455749512 0.35338732600212097\n",
            "tcost icost -0.040798891335725784 0.344666063785553\n",
            "5 Parameter containing:\n",
            "tensor([[[-3.7253e-02, -4.6677e-01,  8.6206e-04],\n",
            "         [-8.7269e-01, -5.6130e-01, -7.4747e-01],\n",
            "         [-4.5883e-01, -6.3261e-01, -2.4678e-01],\n",
            "         [-8.1952e-01, -2.4225e-01, -1.0000e+00],\n",
            "         [-6.9443e-01, -4.7728e-01, -9.3800e-01],\n",
            "         [-6.7049e-02, -9.9205e-02, -3.6293e-01]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.026828180998563766 0.35020342469215393\n",
            "tcost icost -0.22027522325515747 0.34857937693595886\n",
            "tcost icost -0.0847775936126709 0.3561389148235321\n",
            "tcost icost -0.1711738556623459 0.3504234552383423\n",
            "tcost icost -0.18209442496299744 0.3576454818248749\n",
            "tcost icost -0.040968600660562515 0.3491811156272888\n",
            "6 Parameter containing:\n",
            "tensor([[[-0.0454, -0.5409, -0.0343],\n",
            "         [-0.9673, -0.6528, -0.8444],\n",
            "         [-0.5422, -0.7068, -0.3358],\n",
            "         [-0.9072, -0.3208, -1.0000],\n",
            "         [-0.7659, -0.5556, -1.0000],\n",
            "         [-0.1557, -0.1643, -0.4310]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.059707652777433395 0.3505251407623291\n",
            "tcost icost -0.1824844628572464 0.3535350561141968\n",
            "tcost icost -0.08821409940719604 0.3515948951244354\n",
            "tcost icost -0.16489538550376892 0.349854975938797\n",
            "tcost icost -0.27957695722579956 0.3442550003528595\n",
            "tcost icost -0.03168107196688652 0.3491749167442322\n",
            "7 Parameter containing:\n",
            "tensor([[[-6.5543e-02, -5.8162e-01,  4.8890e-04],\n",
            "         [-1.0000e+00, -7.3808e-01, -9.4063e-01],\n",
            "         [-6.2926e-01, -7.8081e-01, -4.2729e-01],\n",
            "         [-9.9356e-01, -3.9745e-01, -1.0000e+00],\n",
            "         [-8.4377e-01, -6.2445e-01, -1.0000e+00],\n",
            "         [-2.4106e-01, -2.2471e-01, -4.9451e-01]]], requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.055159006267786026 0.350178062915802\n",
            "tcost icost -0.19719983637332916 0.35848093032836914\n",
            "tcost icost -0.18380235135555267 0.3461509346961975\n",
            "tcost icost -0.16543442010879517 0.34900274872779846\n",
            "tcost icost -0.2682534456253052 0.3431547284126282\n",
            "tcost icost -0.0317244715988636 0.34802520275115967\n",
            "8 Parameter containing:\n",
            "tensor([[[-0.1134, -0.6388, -0.0032],\n",
            "         [-1.0000, -0.8185, -1.0000],\n",
            "         [-0.7186, -0.8540, -0.5177],\n",
            "         [-1.0000, -0.4742, -1.0000],\n",
            "         [-0.9264, -0.6829, -1.0000],\n",
            "         [-0.3239, -0.2812, -0.5542]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.05558222159743309 0.34998324513435364\n",
            "tcost icost -0.18265783786773682 0.35361164808273315\n",
            "tcost icost -0.1833033263683319 0.3552970886230469\n",
            "tcost icost -0.16235442459583282 0.3582034111022949\n",
            "tcost icost -0.2702675461769104 0.34799492359161377\n",
            "tcost icost -0.031690556555986404 0.3435637652873993\n",
            "9 Parameter containing:\n",
            "tensor([[[-0.1739, -0.6893,  0.0132],\n",
            "         [-1.0000, -0.8940, -1.0000],\n",
            "         [-0.8102, -0.9261, -0.6098],\n",
            "         [-1.0000, -0.5507, -1.0000],\n",
            "         [-1.0000, -0.7288, -1.0000],\n",
            "         [-0.4045, -0.3344, -0.6106]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.05515897646546364 0.3502339720726013\n",
            "tcost icost -0.19719989597797394 0.34864071011543274\n",
            "tcost icost -0.18380241096019745 0.35563740134239197\n",
            "tcost icost -0.2638581395149231 0.3531125485897064\n",
            "tcost icost -0.22487592697143555 0.3471602499485016\n",
            "tcost icost -0.033038947731256485 0.34365999698638916\n",
            "10 Parameter containing:\n",
            "tensor([[[-0.2435, -0.7514,  0.0043],\n",
            "         [-1.0000, -0.9657, -1.0000],\n",
            "         [-0.9033, -0.9970, -0.7036],\n",
            "         [-1.0000, -0.6196, -1.0000],\n",
            "         [-1.0000, -0.7682, -1.0000],\n",
            "         [-0.4830, -0.3859, -0.6644]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.05515896901488304 0.35024493932724\n",
            "tcost icost -0.1972000002861023 0.3487493097782135\n",
            "tcost icost -0.1838025152683258 0.3502982258796692\n",
            "tcost icost -0.263857901096344 0.34843915700912476\n",
            "tcost icost -0.2248760461807251 0.3527285158634186\n",
            "tcost icost -0.03303894028067589 0.34413158893585205\n",
            "11 Parameter containing:\n",
            "tensor([[[-0.3195, -0.8214, -0.0224],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-0.9971, -1.0000, -0.7985],\n",
            "         [-1.0000, -0.6819, -1.0000],\n",
            "         [-1.0000, -0.8020, -1.0000],\n",
            "         [-0.5594, -0.4360, -0.7159]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.055582206696271896 0.3549900949001312\n",
            "tcost icost -0.18265773355960846 0.3535996675491333\n",
            "tcost icost -0.18330320715904236 0.3612729609012604\n",
            "tcost icost -0.26090008020401 0.34859663248062134\n",
            "tcost icost -0.22665554285049438 0.34285199642181396\n",
            "tcost icost -0.13994146883487701 0.36141109466552734\n",
            "12 Parameter containing:\n",
            "tensor([[[-0.3993, -0.8845, -0.0308],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.8938],\n",
            "         [-1.0000, -0.7383, -1.0000],\n",
            "         [-1.0000, -0.8297, -1.0000],\n",
            "         [-0.6378, -0.4962, -0.7755]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.05558222159743309 0.3500686287879944\n",
            "tcost icost -0.182657852768898 0.3486047685146332\n",
            "tcost icost -0.1833033263683319 0.3507937788963318\n",
            "tcost icost -0.26089996099472046 0.3441634774208069\n",
            "tcost icost -0.22665566205978394 0.3474990427494049\n",
            "tcost icost -0.13994136452674866 0.3516104817390442\n",
            "13 Parameter containing:\n",
            "tensor([[[-0.4820, -0.9415, -0.0242],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -0.9889],\n",
            "         [-1.0000, -0.7896, -1.0000],\n",
            "         [-1.0000, -0.8520, -1.0000],\n",
            "         [-0.7203, -0.5637, -0.8411]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.055582206696271896 0.3549244701862335\n",
            "tcost icost -0.18265773355960846 0.3488447070121765\n",
            "tcost icost -0.18330320715904236 0.3505290150642395\n",
            "tcost icost -0.26090008020401 0.3439296782016754\n",
            "tcost icost -0.22665554285049438 0.35235705971717834\n",
            "tcost icost -0.22590488195419312 0.3612300455570221\n",
            "14 Parameter containing:\n",
            "tensor([[[-0.5667, -0.9931, -0.0050],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8362, -1.0000],\n",
            "         [-1.0000, -0.8695, -1.0000],\n",
            "         [-0.8006, -0.6215, -0.9102]]], requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.08191341161727905 0.3499606251716614\n",
            "tcost icost -0.17257924377918243 0.35819411277770996\n",
            "tcost icost -0.19149740040302277 0.35039466619491577\n",
            "tcost icost -0.26321136951446533 0.34369781613349915\n",
            "tcost icost -0.2243192493915558 0.34345534443855286\n",
            "tcost icost -0.22616931796073914 0.36146706342697144\n",
            "15 Parameter containing:\n",
            "tensor([[[-0.6541, -1.0000,  0.0277],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.8786, -1.0000],\n",
            "         [-1.0000, -0.8828, -1.0000],\n",
            "         [-0.8844, -0.6706, -0.9819]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.09667772054672241 0.3550201952457428\n",
            "tcost icost -0.18322212994098663 0.34874144196510315\n",
            "tcost icost -0.1899701952934265 0.35048291087150574\n",
            "tcost icost -0.26480597257614136 0.3525853157043457\n",
            "tcost icost -0.22353795170783997 0.3618933856487274\n",
            "tcost icost -0.226283460855484 0.3472162187099457\n",
            "16 Parameter containing:\n",
            "tensor([[[-0.7442, -1.0000,  0.0196],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9172, -1.0000],\n",
            "         [-1.0000, -0.8922, -1.0000],\n",
            "         [-0.9715, -0.7120, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.09667788445949554 0.3500015437602997\n",
            "tcost icost -0.18322235345840454 0.3536495268344879\n",
            "tcost icost -0.1899702548980713 0.35497429966926575\n",
            "tcost icost -0.2648061215877533 0.34372571110725403\n",
            "tcost icost -0.22353783249855042 0.3425554931163788\n",
            "tcost icost -0.22628328204154968 0.35577183961868286\n",
            "17 Parameter containing:\n",
            "tensor([[[-0.8364, -1.0000, -0.0105],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9523, -1.0000],\n",
            "         [-1.0000, -0.8981, -1.0000],\n",
            "         [-1.0000, -0.7465, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.08191335201263428 0.35000962018966675\n",
            "tcost icost -0.17257902026176453 0.35321056842803955\n",
            "tcost icost -0.19149726629257202 0.3503245711326599\n",
            "tcost icost -0.26321136951446533 0.34428340196609497\n",
            "tcost icost -0.22431936860084534 0.34851834177970886\n",
            "tcost icost -0.22616934776306152 0.35213592648506165\n",
            "18 Parameter containing:\n",
            "tensor([[[-0.9284, -1.0000, -0.0276],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9842, -1.0000],\n",
            "         [-1.0000, -0.9006, -1.0000],\n",
            "         [-1.0000, -0.7747, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "tcost icost -0.08191332221031189 0.3499831259250641\n",
            "tcost icost -0.1725790947675705 0.34967857599258423\n",
            "tcost icost -0.19149748980998993 0.35526344180107117\n",
            "tcost icost -0.26321154832839966 0.3532507121562958\n",
            "tcost icost -0.22431927919387817 0.35219675302505493\n",
            "tcost icost -0.2261694073677063 0.34750640392303467\n",
            "19 Parameter containing:\n",
            "tensor([[[-1.0000, -1.0000, -0.0332],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -0.9000, -1.0000],\n",
            "         [-1.0000, -0.7973, -1.0000]]], requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], grad_fn=<DivBackward0>)\n",
            "search 0.5542647242546082\n",
            "ded\n",
            "time\n",
            "[18, 24, 21, 24, 10, 24, 9, 24, 24, 9, 12, 24, 22, 24, 18, 18, 9, 18, 22, 24, 24, 24, 9, 24, 24, 24, 24, 24, 9, 9, 18, 9, 21, 9, 24, 9, 9, 12, 9, 9, 9, 9, 9, 18, 24, 21, 22, 24, 9, 9, 9, 22, 24, 9, 12, 21, 12, 9, 21, 9, 19, 19, 18, 9, 9, 18, 9, 9, 12, 9, 18, 9, 9, 9, 22, 9, 9, 9, 9, 9, 23, 9, 9, 9, 21, 12, 9, 9, 9, 9, 18, 9, 24, 10, 9]\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    agent.eval()\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # out = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    act_list=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        # print(i, 'act: ',action, 'reward: ',reward)\n",
        "        act_list.append(action)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    print(act_list)\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fabaf37-6a9b-467b-8e2c-ba9901b76442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: early reset ignored\n",
            "Parameter containing:\n",
            "tensor([[[-0.4263, -0.1490,  0.1602],\n",
            "         [-0.1528,  0.3636, -0.4428],\n",
            "         [-0.4659,  0.1355, -0.2273],\n",
            "         [-0.5261, -0.3488, -0.2947],\n",
            "         [-0.1598, -0.2991,  0.2599],\n",
            "         [-0.5336, -0.1101,  0.2567]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.0086, -1.4420,  0.0571],\n",
            "         [-0.1016, -1.1860, -0.3124],\n",
            "         [ 0.0271, -1.2466, -0.1523],\n",
            "         [-0.2378, -1.1738, -0.2514],\n",
            "         [ 0.0492, -0.8939,  0.2688],\n",
            "         [-0.4315, -0.4925,  0.2617]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-0.2938, -2.2776,  0.0104],\n",
            "         [-1.0092, -2.7194, -0.2815],\n",
            "         [-0.5465, -2.1830, -0.1005],\n",
            "         [-0.6747, -1.9193, -0.2124],\n",
            "         [-0.2805, -1.6842,  0.2809],\n",
            "         [-0.1154, -0.6061,  0.2583]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-0.5059, -2.4435, -0.0378],\n",
            "         [-3.5914, -2.8069, -0.2934],\n",
            "         [-1.0525, -2.3504, -0.0650],\n",
            "         [-1.8963, -2.0990, -0.2892],\n",
            "         [-0.5775, -1.8872,  0.2920],\n",
            "         [-0.3035, -1.2459,  0.2647]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-0.6862, -2.5632, -0.0905],\n",
            "         [-3.6102, -2.8799, -0.3107],\n",
            "         [-2.0745, -2.4639, -0.1351],\n",
            "         [-2.0572, -2.2248, -0.3763],\n",
            "         [-1.4800, -2.0151,  0.2718],\n",
            "         [-0.4688, -1.4979,  0.2719]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-3.4284, -2.7017, -0.1404],\n",
            "         [-3.6235, -2.9461, -0.4366],\n",
            "         [-2.2356, -2.5547, -0.2145],\n",
            "         [-2.1747, -2.3233, -0.4769],\n",
            "         [-1.7118, -2.1162,  0.2510],\n",
            "         [-0.6157, -1.6608,  0.2792]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-3.4462, -2.8071, -0.1948],\n",
            "         [-3.6364, -3.0042, -0.5922],\n",
            "         [-2.3538, -2.6306, -0.3062],\n",
            "         [-2.2688, -2.4043, -0.5961],\n",
            "         [-1.8633, -2.1979,  0.2288],\n",
            "         [-1.0822, -1.7801,  0.2659]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-776fa543b0ee>:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.4784, -2.0578,  0.4074],\n",
            "         [ 2.3868, -1.7322,  0.4680],\n",
            "         [ 2.2268, -0.4209,  0.1677],\n",
            "         [ 2.2209,  0.1687,  0.5016],\n",
            "         [ 1.3514, -1.4955,  0.2712],\n",
            "         [ 1.3227, -0.0091, -0.2834]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.6296, -2.1797,  0.5361],\n",
            "         [ 2.5347, -1.9503,  0.5248],\n",
            "         [ 2.3985, -0.4410,  0.2682],\n",
            "         [ 2.3384,  0.2080,  0.5378],\n",
            "         [ 1.5980, -1.7231,  0.3032],\n",
            "         [ 1.5802, -0.0264, -0.2201]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.7421, -2.2711,  0.6392],\n",
            "         [ 2.6446, -2.0829,  0.5771],\n",
            "         [ 2.5238, -0.4415,  0.3545],\n",
            "         [ 2.4315,  0.2457,  0.5715],\n",
            "         [ 1.7563, -1.8725,  0.3337],\n",
            "         [ 1.7399, -0.0579, -0.1654]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.8320, -2.3517,  0.7217],\n",
            "         [ 2.7334, -2.2008,  0.6216],\n",
            "         [ 2.6199, -0.4548,  0.4254],\n",
            "         [ 2.5089,  0.2934,  0.6031],\n",
            "         [ 1.8723, -1.9829,  0.3626],\n",
            "         [ 1.8604, -0.0787, -0.1140]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.9070, -2.4199,  0.7917],\n",
            "         [ 2.8078, -2.2859,  0.6644],\n",
            "         [ 2.6992, -0.4660,  0.4871],\n",
            "         [ 2.5761,  0.3585,  0.6336],\n",
            "         [ 1.9672, -2.0743,  0.3895],\n",
            "         [ 1.9561, -0.0988, -0.0673]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.9719, -2.4793,  0.8532],\n",
            "         [ 2.8722, -2.3622,  0.7030],\n",
            "         [ 2.7671, -0.4858,  0.5416],\n",
            "         [ 2.6340,  0.3543,  0.6607],\n",
            "         [ 2.0460, -2.1506,  0.4149],\n",
            "         [ 2.0367, -0.1094, -0.0232]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.0286, -2.5347,  0.9059],\n",
            "         [ 2.9291, -2.4291,  0.7386],\n",
            "         [ 2.8258, -0.5157,  0.5897],\n",
            "         [ 2.6855,  0.3348,  0.6862],\n",
            "         [ 2.1147, -2.2175,  0.4395],\n",
            "         [ 2.1037, -0.1459,  0.0147]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.0794, -2.5824,  0.9546],\n",
            "         [ 2.9795, -2.4848,  0.7722],\n",
            "         [ 2.8789, -0.5245,  0.6352],\n",
            "         [ 2.7328,  0.3908,  0.7118],\n",
            "         [ 2.1739, -2.2751,  0.4629],\n",
            "         [ 2.1633, -0.1721,  0.0512]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.1254, -2.6246,  0.9995],\n",
            "         [ 3.0249, -2.5330,  0.8040],\n",
            "         [ 2.9273, -0.5222,  0.6777],\n",
            "         [ 2.7758,  0.4472,  0.7363],\n",
            "         [ 2.2267, -2.3268,  0.4853],\n",
            "         [ 2.2163, -0.1987,  0.0851]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.7744140625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2160,  0.0096,  0.0860],\n",
            "         [ 0.4735,  0.2686, -0.2143],\n",
            "         [-0.4245, -0.4294,  0.0329],\n",
            "         [ 0.4501, -0.4643,  0.3512],\n",
            "         [-0.3642,  0.4586,  0.3746],\n",
            "         [-0.4000, -0.4202,  0.3948]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.8221, -0.9233,  0.1227],\n",
            "         [ 2.5033, -0.5271, -0.2612],\n",
            "         [ 0.8761, -0.8416,  0.0133],\n",
            "         [ 1.4426, -0.7694,  0.3440],\n",
            "         [ 0.3533,  0.2521,  0.3697],\n",
            "         [-0.1580, -0.7849,  0.4009]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.8859, -2.8105,  0.2542],\n",
            "         [ 2.6421, -0.8589,  0.0258],\n",
            "         [ 2.6554, -1.9399,  0.0866],\n",
            "         [ 1.7710, -1.9060,  0.3867],\n",
            "         [ 1.1015, -0.0079,  0.3645],\n",
            "         [-0.3242, -1.2916,  0.4093]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.9426, -2.8674,  0.3622],\n",
            "         [ 2.7309, -1.9374,  0.1483],\n",
            "         [ 2.7237, -2.1005,  0.1503],\n",
            "         [ 1.9415, -2.0598,  0.4252],\n",
            "         [ 1.7822, -0.1175,  0.3971],\n",
            "         [-0.4761, -1.5269,  0.4201]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 0., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.9937, -2.9181,  0.4532],\n",
            "         [ 2.8053, -2.1001,  0.2469],\n",
            "         [ 2.7833, -2.2175,  0.2071],\n",
            "         [ 2.0643, -2.1737,  0.4610],\n",
            "         [ 1.9833, -0.2291,  0.4271],\n",
            "         [-0.6106, -1.6821,  0.4313]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.0391, -2.9643,  0.5244],\n",
            "         [ 2.8702, -2.2224,  0.3294],\n",
            "         [ 2.8362, -2.3161,  0.2566],\n",
            "         [ 2.1645, -2.2692,  0.4939],\n",
            "         [ 2.1190, -0.3534,  0.4544],\n",
            "         [-1.0370, -1.8103,  0.4218]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.0813, -3.0061,  0.5909],\n",
            "         [ 2.9269, -2.3134,  0.4011],\n",
            "         [ 2.8841, -2.3950,  0.3028],\n",
            "         [ 2.2459, -2.3470,  0.5247],\n",
            "         [ 2.2254, -0.4641,  0.4814],\n",
            "         [-1.2770, -1.9114,  0.4122]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.1198, -3.0446,  0.6478],\n",
            "         [ 2.9775, -2.3920,  0.4627],\n",
            "         [ 2.9274, -2.4625,  0.3447],\n",
            "         [ 2.3147, -2.4130,  0.5541],\n",
            "         [ 2.3105, -0.5685,  0.5063],\n",
            "         [-1.4360, -1.9976,  0.4024]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.1554, -3.0804,  0.6981],\n",
            "         [ 3.0234, -2.4611,  0.5168],\n",
            "         [ 2.9673, -2.5220,  0.3835],\n",
            "         [ 2.3755, -2.4716,  0.5812],\n",
            "         [ 2.3524, -1.5399,  0.5258],\n",
            "         [-1.5617, -2.0695,  0.3923]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.1886, -3.1136,  0.7440],\n",
            "         [ 3.0651, -2.5204,  0.5654],\n",
            "         [ 3.0041, -2.5740,  0.4197],\n",
            "         [ 2.4286, -2.5227,  0.6070],\n",
            "         [ 2.3904, -1.7593,  0.5448],\n",
            "         [-1.6633, -2.1303,  0.3820]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.2191, -3.1450,  0.7825],\n",
            "         [ 3.1038, -2.5756,  0.6092],\n",
            "         [ 3.0380, -2.6223,  0.4525],\n",
            "         [ 2.4769, -2.5695,  0.6318],\n",
            "         [ 2.4268, -1.9090,  0.5631],\n",
            "         [-1.7480, -2.1836,  0.3715]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.75927734375\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3466, -0.4089, -0.3657],\n",
            "         [-0.1096, -0.3057, -0.2643],\n",
            "         [ 0.1801, -0.4764,  0.1859],\n",
            "         [ 0.1995, -0.2156, -0.5220],\n",
            "         [ 0.0239,  0.2225, -0.0598],\n",
            "         [-0.2165, -0.3351, -0.3953]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.0480, -1.5657, -0.3182],\n",
            "         [ 2.3662, -1.0731, -0.3144],\n",
            "         [ 1.8797, -0.9051,  0.1720],\n",
            "         [ 1.3168, -0.5648, -0.5567],\n",
            "         [ 0.8571, -0.0196, -0.0706],\n",
            "         [ 0.0319, -0.7137, -0.3710]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.3500e+00, -2.0613e+00,  5.6104e-02],\n",
            "         [ 2.5193e+00, -1.8536e+00, -9.0338e-02],\n",
            "         [ 2.1911e+00, -1.8883e+00,  2.2655e-01],\n",
            "         [ 1.7102e+00, -1.9233e+00, -3.5170e-01],\n",
            "         [ 1.8342e+00, -1.3208e-01,  1.8290e-03],\n",
            "         [-1.3704e-01, -1.2739e+00, -3.2901e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.5194, -2.2516,  0.2583],\n",
            "         [ 2.6324, -2.0371,  0.0665],\n",
            "         [ 2.3611, -2.0665,  0.2754],\n",
            "         [ 1.9015, -2.0726, -0.2047],\n",
            "         [ 2.0190, -0.2409,  0.0665],\n",
            "         [-0.3018, -1.5151, -0.2891]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.6404, -2.3830,  0.3953],\n",
            "         [ 2.7226, -2.1626,  0.1850],\n",
            "         [ 2.4842, -2.1911,  0.3211],\n",
            "         [ 2.0370, -2.1868, -0.0880],\n",
            "         [ 2.1434, -0.3629,  0.1190],\n",
            "         [-0.4570, -1.6718, -0.2578]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.7357, -2.4849,  0.5009],\n",
            "         [ 2.7984, -2.2648,  0.2791],\n",
            "         [ 2.5804, -2.2904,  0.3624],\n",
            "         [ 2.1412, -2.2782,  0.0052],\n",
            "         [ 2.2432, -0.4655,  0.1688],\n",
            "         [-0.5942, -1.7899, -0.2232]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.8138, -2.5688,  0.5842],\n",
            "         [ 2.8634, -2.3455,  0.3591],\n",
            "         [ 2.6599, -2.3719,  0.4006],\n",
            "         [ 2.2261, -2.3541,  0.0840],\n",
            "         [ 2.3246, -0.5723,  0.2132],\n",
            "         [-1.0201, -1.8982, -0.2550]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.8816, -2.6388,  0.6584],\n",
            "         [ 2.9208, -2.4134,  0.4287],\n",
            "         [ 2.7274, -2.4425,  0.4352],\n",
            "         [ 2.2974, -2.4186,  0.1513],\n",
            "         [ 2.3655, -1.5452,  0.2483],\n",
            "         [-1.2827, -1.9773, -0.2885]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.9401, -2.7012,  0.7191],\n",
            "         [ 2.9719, -2.4773,  0.4872],\n",
            "         [ 2.7865, -2.5036,  0.4678],\n",
            "         [ 2.3592, -2.4752,  0.2099],\n",
            "         [ 2.4022, -1.7607,  0.2807],\n",
            "         [-1.4479, -2.0513, -0.3244]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.9913, -2.7574,  0.7698],\n",
            "         [ 3.0184, -2.5353,  0.5393],\n",
            "         [ 2.8390, -2.5593,  0.4980],\n",
            "         [ 2.4151, -2.5272,  0.2623],\n",
            "         [ 2.4373, -1.9085,  0.3110],\n",
            "         [-1.5726, -2.1140, -0.3622]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.0381, -2.8068,  0.8180],\n",
            "         [ 3.0606, -2.5849,  0.5869],\n",
            "         [ 2.8867, -2.6081,  0.5273],\n",
            "         [ 2.4651, -2.5740,  0.3096],\n",
            "         [ 2.4699, -2.0196,  0.3397],\n",
            "         [-1.6718, -2.1699, -0.4026]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search 0.78564453125\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2177, -0.3615, -0.0343],\n",
            "         [-0.1317,  0.5221,  0.1232],\n",
            "         [-0.1555,  0.0062,  0.4052],\n",
            "         [-0.1286, -0.3048, -0.4818],\n",
            "         [-0.1815,  0.2649, -0.4269],\n",
            "         [ 0.4788,  0.0915, -0.2152]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.7219, -1.3926, -0.0258],\n",
            "         [ 2.9138, -0.4484,  0.1172],\n",
            "         [ 1.7163, -0.6178,  0.3956],\n",
            "         [ 1.1283, -0.6498, -0.5130],\n",
            "         [ 0.2714, -0.4013, -0.3807],\n",
            "         [ 0.6955, -0.3313, -0.1970]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.8150, -1.9794,  0.1412],\n",
            "         [ 2.9745, -0.5788,  0.2579],\n",
            "         [ 2.1336, -1.6867,  0.4351],\n",
            "         [ 1.7720, -2.1429, -0.2549],\n",
            "         [ 1.0964, -0.6395, -0.3984],\n",
            "         [ 1.3731, -0.3858, -0.1390]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.8922, -2.1715,  0.2652],\n",
            "         [ 3.0196, -1.7817,  0.3426],\n",
            "         [ 2.3244, -1.9381,  0.4688],\n",
            "         [ 1.9388, -2.2372, -0.1307],\n",
            "         [ 1.4761, -1.4768, -0.2900],\n",
            "         [ 1.6186, -0.4198, -0.0919]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.9578, -2.3111,  0.3588],\n",
            "         [ 3.0611, -1.9799,  0.4122],\n",
            "         [ 2.4563, -2.0967,  0.5004],\n",
            "         [ 2.0631, -2.3182, -0.0306],\n",
            "         [ 1.6799, -1.7167, -0.2016],\n",
            "         [ 1.7762, -0.4534, -0.0485]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.0154, -2.4150,  0.4386],\n",
            "         [ 3.0990, -2.1097,  0.4736],\n",
            "         [ 2.5584, -2.2110,  0.5305],\n",
            "         [ 2.1599, -2.3863,  0.0532],\n",
            "         [ 1.8196, -1.8702, -0.1246],\n",
            "         [ 1.8913, -0.4983, -0.0101]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.0668, -2.5004,  0.5063],\n",
            "         [ 3.1344, -2.2073,  0.5295],\n",
            "         [ 2.6414, -2.3055,  0.5583],\n",
            "         [ 2.2408, -2.4466,  0.1231],\n",
            "         [ 1.9248, -1.9820, -0.0564],\n",
            "         [ 1.9844, -0.5377,  0.0262]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.1135, -2.5698,  0.5681],\n",
            "         [ 3.1672, -2.2859,  0.5795],\n",
            "         [ 2.7120, -2.3815,  0.5851],\n",
            "         [ 2.3088, -2.4990,  0.1861],\n",
            "         [ 2.0120, -2.0737,  0.0034],\n",
            "         [ 2.0622, -0.5757,  0.0602]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.1556, -2.6339,  0.6198],\n",
            "         [ 3.1981, -2.3582,  0.6244],\n",
            "         [ 2.7732, -2.4494,  0.6100],\n",
            "         [ 2.3692, -2.5473,  0.2415],\n",
            "         [ 2.0859, -2.1504,  0.0559],\n",
            "         [ 2.1019, -1.1378,  0.0878]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.1947, -2.6881,  0.6687],\n",
            "         [ 3.2271, -2.4192,  0.6657],\n",
            "         [ 2.8277, -2.5079,  0.6341],\n",
            "         [ 2.4230, -2.5912,  0.2908],\n",
            "         [ 2.1486, -2.2147,  0.1036],\n",
            "         [ 2.1371, -1.3885,  0.1145]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.2307, -2.7370,  0.7126],\n",
            "         [ 3.2543, -2.4696,  0.7046],\n",
            "         [ 2.8766, -2.5594,  0.6572],\n",
            "         [ 2.4709, -2.6310,  0.3363],\n",
            "         [ 2.2045, -2.2720,  0.1471],\n",
            "         [ 2.1704, -1.5540,  0.1397]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.78125\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3136,  0.3145,  0.2985],\n",
            "         [ 0.0198,  0.3364, -0.0574],\n",
            "         [ 0.1274,  0.4260, -0.0464],\n",
            "         [-0.0093,  0.1538, -0.4068],\n",
            "         [ 0.3767, -0.3514, -0.3906],\n",
            "         [-0.0628,  0.0209,  0.1933]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 3.0181, -0.9453,  0.3250],\n",
            "         [ 2.4102, -0.3953, -0.0922],\n",
            "         [ 1.7913, -0.0194, -0.0681],\n",
            "         [ 1.2613, -0.2172, -0.4329],\n",
            "         [ 1.1096, -0.5778, -0.4092],\n",
            "         [ 0.1875, -0.3988,  0.2017]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 3.0471, -3.4013,  0.4999],\n",
            "         [ 2.5847, -0.6770,  0.1412],\n",
            "         [ 2.2213, -0.2390,  0.0926],\n",
            "         [ 2.0017, -0.2042, -0.2363],\n",
            "         [ 1.4763, -1.4723, -0.2921],\n",
            "         [ 0.7378, -0.5523,  0.1981]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 3.0741, -3.4251,  0.6179],\n",
            "         [ 2.6884, -2.4904,  0.2422],\n",
            "         [ 2.4059, -0.4590,  0.2082],\n",
            "         [ 2.1931, -0.2287, -0.0949],\n",
            "         [ 1.6665, -1.6942, -0.2015],\n",
            "         [ 1.1004, -1.0870,  0.2207]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 3.0996, -3.4474,  0.7158],\n",
            "         [ 2.7722, -2.5631,  0.3267],\n",
            "         [ 2.5393, -0.6285,  0.3080],\n",
            "         [ 2.3255, -0.2530,  0.0154],\n",
            "         [ 1.8021, -1.8443, -0.1241],\n",
            "         [ 1.3188, -1.3547,  0.2422]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.1241, -3.4691,  0.7966],\n",
            "         [ 2.8443, -2.6298,  0.3972],\n",
            "         [ 2.6176, -1.8483,  0.3267],\n",
            "         [ 2.4258, -0.4537,  0.1178],\n",
            "         [ 1.9106, -1.9618, -0.0579],\n",
            "         [ 1.4671, -1.5255,  0.2624]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.1475e+00, -3.4902e+00,  8.6285e-01],\n",
            "         [ 2.9063e+00, -2.6892e+00,  4.5632e-01],\n",
            "         [ 2.6847e+00, -2.0070e+00,  3.4408e-01],\n",
            "         [ 2.5087e+00, -6.3031e-01,  2.0393e-01],\n",
            "         [ 2.0001e+00, -2.0575e+00,  1.1826e-03],\n",
            "         [ 1.5860e+00, -1.6559e+00,  2.8149e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.1698, -3.5103,  0.9216],\n",
            "         [ 2.9614, -2.7419,  0.5102],\n",
            "         [ 2.7426, -2.1282,  0.3608],\n",
            "         [ 2.5492, -1.9452,  0.2513],\n",
            "         [ 2.0743, -2.1369,  0.0533],\n",
            "         [ 1.6804, -1.7574,  0.3000]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.1911, -3.5297,  0.9728],\n",
            "         [ 3.0107, -2.7903,  0.5572],\n",
            "         [ 2.7941, -2.2221,  0.3766],\n",
            "         [ 2.5866, -2.0948,  0.2943],\n",
            "         [ 2.1382, -2.2048,  0.1013],\n",
            "         [ 1.7625, -1.8439,  0.3177]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.2115, -3.5483,  1.0180],\n",
            "         [ 3.0553, -2.8319,  0.6026],\n",
            "         [ 2.8409, -2.2979,  0.3918],\n",
            "         [ 2.6220, -2.2088,  0.3338],\n",
            "         [ 2.1948, -2.2644,  0.1452],\n",
            "         [ 1.8323, -1.9168,  0.3347]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.2310, -3.5663,  1.0585],\n",
            "         [ 3.0962, -2.8709,  0.6440],\n",
            "         [ 2.8836, -2.3660,  0.4070],\n",
            "         [ 2.6550, -2.3000,  0.3705],\n",
            "         [ 2.2453, -2.3173,  0.1856],\n",
            "         [ 1.8932, -1.9799,  0.3513]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.7822265625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3310, -0.2489, -0.2674],\n",
            "         [ 0.3514,  0.4661,  0.1453],\n",
            "         [ 0.1399, -0.2796, -0.2417],\n",
            "         [ 0.5082, -0.0222, -0.2025],\n",
            "         [ 0.3228,  0.1950, -0.0334],\n",
            "         [ 0.3553,  0.4139, -0.0999]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 4.1049, -1.8450, -0.1963],\n",
            "         [ 3.4472, -0.5574,  0.1447],\n",
            "         [ 2.3437, -0.7790, -0.2498],\n",
            "         [ 1.5920, -0.4179, -0.2200],\n",
            "         [ 0.7458, -0.4901, -0.0099],\n",
            "         [ 0.6179,  0.0414, -0.0839]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 4.1086, -2.2884,  0.2778],\n",
            "         [ 3.4669, -2.0653,  0.2376],\n",
            "         [ 2.4392, -2.5394, -0.0087],\n",
            "         [ 1.9926, -0.4310, -0.0773],\n",
            "         [ 1.8794, -0.4755,  0.0580],\n",
            "         [ 1.3389,  0.0461, -0.0384]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 4.1123, -2.4711,  0.4835],\n",
            "         [ 3.4858, -2.1856,  0.3164],\n",
            "         [ 2.5181, -2.6140,  0.1515],\n",
            "         [ 2.1831, -0.4255,  0.0366],\n",
            "         [ 2.0455, -0.4731,  0.1165],\n",
            "         [ 1.5896,  0.0681,  0.0047]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 4.1159, -2.6038,  0.6133],\n",
            "         [ 3.5040, -2.2830,  0.3834],\n",
            "         [ 2.5853, -2.6782,  0.2698],\n",
            "         [ 2.3146, -0.4091,  0.1295],\n",
            "         [ 2.1678, -0.4457,  0.1707],\n",
            "         [ 1.7497,  0.0918,  0.0448]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 4.1195, -2.7051,  0.7172],\n",
            "         [ 3.5214, -2.3675,  0.4413],\n",
            "         [ 2.6444, -2.7352,  0.3636],\n",
            "         [ 2.4162, -0.4065,  0.2068],\n",
            "         [ 2.2641, -0.4413,  0.2190],\n",
            "         [ 1.8661,  0.0777,  0.0796]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 4.1231, -2.7881,  0.8021],\n",
            "         [ 3.5385, -2.4396,  0.4938],\n",
            "         [ 2.6977, -2.7870,  0.4406],\n",
            "         [ 2.4985, -0.4440,  0.2714],\n",
            "         [ 2.3432, -0.4684,  0.2616],\n",
            "         [ 1.9578,  0.0351,  0.1104]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 4.1267, -2.8584,  0.8731],\n",
            "         [ 3.5549, -2.4990,  0.5418],\n",
            "         [ 2.7450, -2.8330,  0.5080],\n",
            "         [ 2.5695, -0.4386,  0.3308],\n",
            "         [ 2.4113, -0.4680,  0.3019],\n",
            "         [ 2.0364,  0.0297,  0.1416]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 4.1302, -2.9193,  0.9357],\n",
            "         [ 3.5708, -2.5531,  0.5852],\n",
            "         [ 2.7885, -2.8754,  0.5671],\n",
            "         [ 2.6304, -0.4623,  0.3824],\n",
            "         [ 2.4705, -0.4815,  0.3386],\n",
            "         [ 2.1037,  0.0172,  0.1708]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 4.1337, -2.9730,  0.9911],\n",
            "         [ 3.5861, -2.6008,  0.6251],\n",
            "         [ 2.8283, -2.9141,  0.6212],\n",
            "         [ 2.6840, -0.4938,  0.4284],\n",
            "         [ 2.5230, -0.4886,  0.3728],\n",
            "         [ 2.1637,  0.0309,  0.1997]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 4.1372, -3.0212,  1.0409],\n",
            "         [ 3.6010, -2.6440,  0.6622],\n",
            "         [ 2.8649, -2.9499,  0.6692],\n",
            "         [ 2.7329, -0.5014,  0.4719],\n",
            "         [ 2.5703, -0.5023,  0.4047],\n",
            "         [ 2.2168,  0.0357,  0.2266]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.802734375\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3643, -0.5321, -0.4410],\n",
            "         [ 0.4288, -0.3007, -0.3153],\n",
            "         [-0.4639, -0.4455, -0.2658],\n",
            "         [-0.3412,  0.3929, -0.3343],\n",
            "         [-0.2465, -0.0591, -0.1522],\n",
            "         [-0.0533,  0.0593, -0.0324]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.5621, -0.9427, -0.3159],\n",
            "         [ 2.3415, -1.3225, -0.3270],\n",
            "         [ 0.8294, -0.9909, -0.2492],\n",
            "         [ 1.0791,  0.0692, -0.3415],\n",
            "         [ 0.2906, -0.8091, -0.1189],\n",
            "         [ 0.2495, -0.3792, -0.0178]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.7291, -2.3280, -0.2061],\n",
            "         [ 2.5143, -1.7778, -0.1673],\n",
            "         [ 2.6456, -1.5376, -0.1129],\n",
            "         [ 2.0300,  0.0893, -0.1718],\n",
            "         [ 0.0386, -1.6668, -0.0666],\n",
            "         [ 0.7539, -0.5292, -0.0237]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.8478, -2.4410, -0.1161],\n",
            "         [ 2.6373, -1.9507, -0.0455],\n",
            "         [ 2.7127, -1.7367, -0.0037],\n",
            "         [ 2.2015,  0.1318, -0.0421],\n",
            "         [-0.2177, -1.8692, -0.0148],\n",
            "         [ 1.3912, -0.5620,  0.0142]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.9425, -2.5310, -0.0384],\n",
            "         [ 2.7341, -2.0838,  0.0527],\n",
            "         [ 2.7715, -1.8893,  0.0831],\n",
            "         [ 2.3223,  0.1512,  0.0569],\n",
            "         [-0.4512, -2.0031,  0.0298],\n",
            "         [ 1.5209, -1.1026,  0.0443]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.0221, -2.6046,  0.0313],\n",
            "         [ 2.8141, -2.1858,  0.1350],\n",
            "         [ 2.8241, -2.0028,  0.1581],\n",
            "         [ 2.4167,  0.1529,  0.1375],\n",
            "         [-0.6590, -2.1084,  0.0699],\n",
            "         [ 1.6310, -1.3793,  0.0723]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.0888, -2.6705,  0.0900],\n",
            "         [ 2.8822, -2.2730,  0.2050],\n",
            "         [ 2.8713, -2.0937,  0.2230],\n",
            "         [ 2.4957,  0.1442,  0.2070],\n",
            "         [-1.4056, -2.2003,  0.0467],\n",
            "         [ 1.7186, -1.5461,  0.0998]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.1478, -2.7272,  0.1440],\n",
            "         [ 2.9419, -2.3444,  0.2670],\n",
            "         [ 2.9143, -2.1724,  0.2798],\n",
            "         [ 2.5634,  0.1278,  0.2676],\n",
            "         [-1.6450, -2.2748,  0.0221],\n",
            "         [ 1.7908, -1.6666,  0.1261]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.2002, -2.7780,  0.1928],\n",
            "         [ 2.9949, -2.4068,  0.3220],\n",
            "         [ 2.9539, -2.2398,  0.3310],\n",
            "         [ 2.6228,  0.1103,  0.3220],\n",
            "         [-1.8027, -2.3388, -0.0045],\n",
            "         [ 1.8562, -1.7662,  0.1509]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.2475, -2.8235,  0.2375],\n",
            "         [ 3.0424, -2.4599,  0.3715],\n",
            "         [ 2.9905, -2.2947,  0.3787],\n",
            "         [ 2.6747,  0.0885,  0.3697],\n",
            "         [-1.9171, -2.3979, -0.0306],\n",
            "         [ 1.9129, -1.8473,  0.1748]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.2898, -2.8661,  0.2771],\n",
            "         [ 3.0858, -2.5058,  0.4168],\n",
            "         [ 3.0243, -2.3459,  0.4212],\n",
            "         [ 2.7224,  0.0909,  0.4151],\n",
            "         [-2.0090, -2.4498, -0.0582],\n",
            "         [ 1.9625, -1.9157,  0.1977]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.80322265625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4732,  0.5341, -0.2451],\n",
            "         [-0.1238, -0.4804,  0.3209],\n",
            "         [-0.0360,  0.4219,  0.2886],\n",
            "         [-0.2716,  0.3998, -0.5044],\n",
            "         [-0.1933,  0.2848,  0.3049],\n",
            "         [ 0.2168,  0.2294, -0.4296]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 3.4109, -0.1469, -0.0713],\n",
            "         [ 2.2746, -1.2727,  0.3229],\n",
            "         [ 2.2630, -0.0349,  0.2862],\n",
            "         [ 1.0581,  0.0609, -0.5312],\n",
            "         [ 0.3225, -0.3968,  0.3186],\n",
            "         [ 0.4935, -0.1821, -0.4015]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 3.4358, -0.8788,  0.2028],\n",
            "         [ 2.4765, -1.7778,  0.3916],\n",
            "         [ 2.4196, -0.1301,  0.3637],\n",
            "         [ 2.0456, -0.0103, -0.3002],\n",
            "         [ 1.2993, -0.6711,  0.3146],\n",
            "         [ 0.9316, -0.3232, -0.4073]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 3.4551, -1.8565,  0.3282],\n",
            "         [ 2.5974, -1.9270,  0.4633],\n",
            "         [ 2.5384, -0.0253,  0.4374],\n",
            "         [ 2.2111,  0.0892, -0.1350],\n",
            "         [ 1.5659, -1.4777,  0.3449],\n",
            "         [ 1.4041, -0.3442, -0.3317]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 3.4737, -2.0409,  0.4263],\n",
            "         [ 2.6932, -2.0477,  0.5249],\n",
            "         [ 2.6321,  0.0550,  0.5007],\n",
            "         [ 2.3294,  0.1187, -0.0169],\n",
            "         [ 1.7314, -1.7080,  0.3730],\n",
            "         [ 1.6264, -0.3394, -0.2610]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.4917, -2.1710,  0.5080],\n",
            "         [ 2.7730, -2.1491,  0.5789],\n",
            "         [ 2.7090,  0.0978,  0.5549],\n",
            "         [ 2.4231,  0.1117,  0.0768],\n",
            "         [ 1.8559, -1.8630,  0.3993],\n",
            "         [ 1.7749, -0.3341, -0.1983]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.5089, -2.2719,  0.5773],\n",
            "         [ 2.8403, -2.2274,  0.6276],\n",
            "         [ 2.7766,  0.2134,  0.6067],\n",
            "         [ 2.5026,  0.2005,  0.1609],\n",
            "         [ 1.9536, -1.9777,  0.4250],\n",
            "         [ 1.8844, -0.3667, -0.1466]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.5257, -2.3505,  0.6399],\n",
            "         [ 2.8993, -2.2915,  0.6729],\n",
            "         [ 2.8352,  0.3010,  0.6525],\n",
            "         [ 2.5701,  0.2560,  0.2313],\n",
            "         [ 2.0348, -2.0701,  0.4492],\n",
            "         [ 1.9737, -0.3917, -0.0987]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.5418, -2.4204,  0.6943],\n",
            "         [ 2.9518, -2.3525,  0.7132],\n",
            "         [ 2.8873,  0.3931,  0.6945],\n",
            "         [ 2.6292,  0.3464,  0.2942],\n",
            "         [ 2.1024, -2.1448,  0.4724],\n",
            "         [ 2.0503, -0.3948, -0.0525]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.5575, -2.4774,  0.7451],\n",
            "         [ 2.9991, -2.4043,  0.7511],\n",
            "         [ 2.9346,  0.4827,  0.7336],\n",
            "         [ 2.6819,  0.3892,  0.3489],\n",
            "         [ 2.1639, -2.2124,  0.4942],\n",
            "         [ 2.1160, -0.4030, -0.0105]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.5727, -2.5377,  0.7865],\n",
            "         [ 3.0427, -2.4589,  0.7851],\n",
            "         [ 2.9759,  0.4965,  0.7666],\n",
            "         [ 2.7295,  0.4545,  0.3989],\n",
            "         [ 2.2180, -2.2710,  0.5155],\n",
            "         [ 2.1732, -0.4289,  0.0271]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search 0.798828125\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4644,  0.3363,  0.4261],\n",
            "         [-0.3867,  0.3366, -0.0853],\n",
            "         [ 0.2368,  0.2507,  0.2440],\n",
            "         [-0.2609, -0.3293,  0.1709],\n",
            "         [ 0.4913,  0.0494, -0.3977],\n",
            "         [ 0.2152,  0.2495,  0.3593]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.8655,  0.1184,  0.4737],\n",
            "         [ 1.4534, -0.4381, -0.1042],\n",
            "         [ 1.7261, -0.2344,  0.2464],\n",
            "         [ 0.6698, -1.3073,  0.2036],\n",
            "         [ 0.8973, -0.6794, -0.3505],\n",
            "         [ 0.4779, -0.1519,  0.3659]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.9448, -2.1059,  0.5824],\n",
            "         [ 2.4430, -0.3288,  0.0904],\n",
            "         [ 2.1307, -0.1019,  0.3161],\n",
            "         [ 1.8059, -1.7342,  0.2749],\n",
            "         [ 1.5056, -1.6370, -0.2151],\n",
            "         [ 0.9409, -0.3270,  0.3634]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 3.0080, -2.1704,  0.6758],\n",
            "         [ 2.5938, -0.2019,  0.2272],\n",
            "         [ 2.3192,  0.0460,  0.3780],\n",
            "         [ 1.9856, -1.9379,  0.3369],\n",
            "         [ 1.7299, -1.8433, -0.1095],\n",
            "         [ 1.4026, -0.3635,  0.3815]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 3.0637, -2.2303,  0.7528],\n",
            "         [ 2.7051, -0.0984,  0.3324],\n",
            "         [ 2.4498,  0.2100,  0.4333],\n",
            "         [ 2.1123, -2.0752,  0.3917],\n",
            "         [ 1.8772, -1.9815, -0.0209],\n",
            "         [ 1.6225, -0.3776,  0.3999]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.1136, -2.2837,  0.8191],\n",
            "         [ 2.7942, -0.0082,  0.4180],\n",
            "         [ 2.5500,  0.3622,  0.4825],\n",
            "         [ 2.2107, -2.1779,  0.4420],\n",
            "         [ 1.9886, -2.0872,  0.0568],\n",
            "         [ 1.7691, -0.4014,  0.4173]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.1587, -2.3369,  0.8760],\n",
            "         [ 2.8686,  0.0275,  0.4899],\n",
            "         [ 2.6313,  0.4622,  0.5262],\n",
            "         [ 2.2918, -2.2613,  0.4885],\n",
            "         [ 2.0785, -2.1736,  0.1236],\n",
            "         [ 1.8805, -0.4249,  0.4341]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.1999, -2.3813,  0.9275],\n",
            "         [ 2.9331,  0.1620,  0.5534],\n",
            "         [ 2.7021,  0.6342,  0.5682],\n",
            "         [ 2.3617, -2.3332,  0.5309],\n",
            "         [ 2.1544, -2.2472,  0.1807],\n",
            "         [ 1.9710, -0.4428,  0.4506]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.2377, -2.4217,  0.9738],\n",
            "         [ 2.9898,  0.3180,  0.6102],\n",
            "         [ 2.7700,  0.8974,  0.6118],\n",
            "         [ 2.4222, -2.3962,  0.5686],\n",
            "         [ 2.2194, -2.3099,  0.2341],\n",
            "         [ 2.0476, -0.4507,  0.4670]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.2729, -2.4585,  1.0165],\n",
            "         [ 3.0400,  0.3978,  0.6600],\n",
            "         [ 2.8300,  1.0845,  0.6527],\n",
            "         [ 2.4766, -2.4531,  0.6033],\n",
            "         [ 2.2771, -2.3663,  0.2812],\n",
            "         [ 2.1128, -0.4771,  0.4821]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.3056, -2.4926,  1.0557],\n",
            "         [ 3.0859,  0.5264,  0.7060],\n",
            "         [ 2.8823,  1.2297,  0.6887],\n",
            "         [ 2.5249, -2.5027,  0.6365],\n",
            "         [ 2.3283, -2.4161,  0.3247],\n",
            "         [ 2.1710, -0.4857,  0.4974]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8056640625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4479, -0.1787,  0.0480],\n",
            "         [ 0.0299,  0.1623, -0.2066],\n",
            "         [ 0.3497,  0.5284, -0.1024],\n",
            "         [-0.2205, -0.0880,  0.1111],\n",
            "         [ 0.3473, -0.3925, -0.2880],\n",
            "         [ 0.1056,  0.1691, -0.3713]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 3.2447, -0.9811,  0.0971],\n",
            "         [ 2.4929, -0.5802, -0.2461],\n",
            "         [ 1.8455,  0.1255, -0.1259],\n",
            "         [ 0.8888, -0.4484,  0.0997],\n",
            "         [ 0.6869, -0.9715, -0.2548],\n",
            "         [ 0.3546, -0.2361, -0.3477]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 3.2621, -2.7012,  0.3074],\n",
            "         [ 2.5793, -3.2890,  0.0088],\n",
            "         [ 2.2335, -0.0967,  0.0522],\n",
            "         [ 2.2133, -0.4763,  0.1750],\n",
            "         [ 1.3838, -1.5443, -0.1685],\n",
            "         [ 0.8042, -0.3933, -0.3581]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 3.2791, -2.7730,  0.4480],\n",
            "         [ 2.6524, -3.3097,  0.1715],\n",
            "         [ 2.4146, -0.3309,  0.1779],\n",
            "         [ 2.3375, -0.5175,  0.2396],\n",
            "         [ 1.6222, -1.7579, -0.0972],\n",
            "         [ 1.4030, -0.4301, -0.2894]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 3.2958, -2.8363,  0.5552],\n",
            "         [ 2.7167, -3.3301,  0.2899],\n",
            "         [ 2.5404, -0.5421,  0.2761],\n",
            "         [ 2.4356, -0.5281,  0.2980],\n",
            "         [ 1.7757, -1.9000, -0.0332],\n",
            "         [ 1.6301, -0.4764, -0.2306]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.3117, -2.8914,  0.6417],\n",
            "         [ 2.7721, -3.3491,  0.3859],\n",
            "         [ 2.6401, -0.7130,  0.3601],\n",
            "         [ 2.5162, -0.5436,  0.3501],\n",
            "         [ 1.8901, -2.0078,  0.0233],\n",
            "         [ 1.7834, -0.5113, -0.1754]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.3273, -2.9412,  0.7149],\n",
            "         [ 2.8219, -3.3674,  0.4631],\n",
            "         [ 2.6852, -2.3901,  0.4177],\n",
            "         [ 2.5875, -0.6541,  0.3990],\n",
            "         [ 1.9832, -2.0957,  0.0756],\n",
            "         [ 1.8984, -0.5447, -0.1254]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.3423, -2.9860,  0.7782],\n",
            "         [ 2.8665, -3.3848,  0.5298],\n",
            "         [ 2.7257, -2.4763,  0.4681],\n",
            "         [ 2.6223, -1.8957,  0.4358],\n",
            "         [ 2.0630, -2.1727,  0.1223],\n",
            "         [ 1.9893, -0.6053, -0.0813]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.3567, -3.0268,  0.8349],\n",
            "         [ 2.9077, -3.4018,  0.5878],\n",
            "         [ 2.7628, -2.5488,  0.5138],\n",
            "         [ 2.6541, -2.0524,  0.4695],\n",
            "         [ 2.1273, -2.2349,  0.1643],\n",
            "         [ 2.0334, -1.1336, -0.0447]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.3709, -3.0647,  0.8854],\n",
            "         [ 2.9458, -3.4183,  0.6405],\n",
            "         [ 2.7985, -2.6135,  0.5555],\n",
            "         [ 2.6848, -2.1713,  0.5012],\n",
            "         [ 2.1859, -2.2917,  0.2028],\n",
            "         [ 2.0741, -1.3885, -0.0104]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.3848, -3.1002,  0.9304],\n",
            "         [ 2.9810, -3.4343,  0.6877],\n",
            "         [ 2.8313, -2.6697,  0.5938],\n",
            "         [ 2.7131, -2.2637,  0.5311],\n",
            "         [ 2.2371, -2.3414,  0.2388],\n",
            "         [ 2.1113, -1.5523,  0.0218]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.80517578125\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2215,  0.2283, -0.4502],\n",
            "         [-0.3179, -0.2249, -0.0019],\n",
            "         [-0.4819, -0.5121, -0.1913],\n",
            "         [ 0.3782, -0.2559, -0.1773],\n",
            "         [-0.2123,  0.4765,  0.5300],\n",
            "         [ 0.4774, -0.3004, -0.2771]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.4347,  0.0983, -0.6441],\n",
            "         [ 0.1328, -0.9487, -0.0207],\n",
            "         [-0.0244, -1.0923, -0.2083],\n",
            "         [ 0.8986, -0.7515, -0.1902],\n",
            "         [ 0.2586,  0.1608,  0.5281],\n",
            "         [ 0.6409, -0.6638, -0.2594]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.7113, -0.0899, -0.8988],\n",
            "         [-1.3287, -3.1333, -0.0381],\n",
            "         [-0.9867, -2.3526, -0.1606],\n",
            "         [ 1.7121, -1.9896, -0.0950],\n",
            "         [ 1.0099, -0.0649,  0.5249],\n",
            "         [ 1.0678, -1.1873, -0.2174]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 4.8417, -1.3019, -0.3007],\n",
            "         [-2.2558, -3.1685, -0.1651],\n",
            "         [-2.0253, -2.4754, -0.2586],\n",
            "         [ 1.9837, -2.0897, -0.0703],\n",
            "         [ 1.7622, -0.2025,  0.5501],\n",
            "         [ 1.3030, -1.4257, -0.1738]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 4.8428, -2.6941,  0.0125],\n",
            "         [-2.4207, -3.2009, -0.3311],\n",
            "         [-2.1890, -2.5708, -0.3755],\n",
            "         [ 2.1465, -2.1723, -0.0468],\n",
            "         [ 1.9670, -0.3734,  0.5733],\n",
            "         [ 1.4639, -1.5862, -0.1360]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 4.8439, -2.7926,  0.1934],\n",
            "         [-2.5402, -3.2309, -0.5523],\n",
            "         [-2.3085, -2.6506, -0.5177],\n",
            "         [ 2.2663, -2.2446, -0.0233],\n",
            "         [ 2.1038, -0.5303,  0.5944],\n",
            "         [ 1.5869, -1.7084, -0.1014]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 4.8450e+00, -2.8733e+00,  3.2221e-01],\n",
            "         [-2.6343e+00, -3.2594e+00, -8.6682e-01],\n",
            "         [-2.4028e+00, -2.7185e+00, -6.9592e-01],\n",
            "         [ 2.3604e+00, -2.3058e+00, -1.5260e-03],\n",
            "         [ 2.2095e+00, -6.6546e-01,  6.1539e-01],\n",
            "         [ 1.6831e+00, -1.8032e+00, -6.7736e-02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 4.8461, -2.9423,  0.4236],\n",
            "         [-2.7128, -3.2862, -1.3552],\n",
            "         [-2.4812, -2.7771, -0.9272],\n",
            "         [ 2.4381, -2.3592,  0.0186],\n",
            "         [ 2.2618, -1.5664,  0.6292],\n",
            "         [ 1.7657, -1.8854, -0.0373]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 4.8472, -3.0019,  0.5085],\n",
            "         [-2.7794, -3.3118, -2.0827],\n",
            "         [-2.5477, -2.8301, -1.2365],\n",
            "         [ 2.5047, -2.4060,  0.0373],\n",
            "         [ 2.3093, -1.7857,  0.6426],\n",
            "         [ 1.8366, -1.9559, -0.0085]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 4.8483, -3.0550,  0.5786],\n",
            "         [-2.8451, -3.3349, -2.5813],\n",
            "         [-2.6060, -2.8779, -1.6427],\n",
            "         [ 2.5630, -2.4488,  0.0553],\n",
            "         [ 2.3518, -1.9290,  0.6557],\n",
            "         [ 1.8971, -2.0165,  0.0191]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 4.8494, -3.1033,  0.6409],\n",
            "         [-2.9033, -3.3566, -2.8581],\n",
            "         [-2.6684, -2.9158, -2.0739],\n",
            "         [ 2.6153, -2.4905,  0.0744],\n",
            "         [ 2.3911, -2.0384,  0.6684],\n",
            "         [ 1.9510, -2.0703,  0.0454]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8125\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1213,  0.1684,  0.2939],\n",
            "         [-0.0039, -0.3904,  0.2633],\n",
            "         [-0.1228, -0.2075, -0.1747],\n",
            "         [-0.3114, -0.1890,  0.1854],\n",
            "         [-0.2153, -0.4374,  0.4669],\n",
            "         [ 0.1971,  0.4094,  0.3458]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.6574,  1.3794,  0.1585],\n",
            "         [-0.1724, -0.4017,  0.2004],\n",
            "         [ 0.0948, -0.5760, -0.2014],\n",
            "         [-0.0034, -0.6287,  0.1825],\n",
            "         [ 0.1100, -0.7861,  0.4655],\n",
            "         [ 0.4927,  0.2080,  0.3442]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-3.9548,  2.1274, -0.0595],\n",
            "         [-0.3123, -0.4246,  0.1316],\n",
            "         [-1.0837, -2.8498, -0.2519],\n",
            "         [-0.6536, -2.2892,  0.1823],\n",
            "         [-0.3441, -1.7788,  0.4770],\n",
            "         [ 0.7534,  0.0238,  0.3429]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.,  1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-3.9615,  2.3098, -0.4084],\n",
            "         [-0.4059, -0.5221,  0.0597],\n",
            "         [-2.1646, -2.8866, -0.3305],\n",
            "         [-1.9486, -2.3772,  0.1542],\n",
            "         [-0.6543, -1.9678,  0.4828],\n",
            "         [ 1.4028, -0.0923,  0.3636]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-3.9685,  2.4390, -1.0198],\n",
            "         [-0.5387, -0.5188, -0.0332],\n",
            "         [-2.3162, -2.9205, -0.4255],\n",
            "         [-2.0997, -2.4484,  0.1223],\n",
            "         [-1.4090, -2.0943,  0.4687],\n",
            "         [ 1.6313, -0.2056,  0.3816]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.,  1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-3.9756,  2.5383, -2.3671],\n",
            "         [-0.6249, -0.5828, -0.1330],\n",
            "         [-2.4295, -2.9533, -0.5276],\n",
            "         [-2.2131, -2.5118,  0.0891],\n",
            "         [-1.6471, -2.1909,  0.4544],\n",
            "         [ 1.7869, -0.3175,  0.4008]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-3.9816,  2.6679, -4.2317],\n",
            "         [-3.2589, -2.6731, -0.2695],\n",
            "         [-2.5128, -2.9806, -0.6582],\n",
            "         [-2.3028, -2.5653,  0.0528],\n",
            "         [-1.7989, -2.2720,  0.4382],\n",
            "         [ 1.8966, -0.3143,  0.4254]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-3.9879,  2.7687, -4.2955],\n",
            "         [-3.2812, -2.7262, -0.4469],\n",
            "         [-2.5841, -3.0068, -0.8147],\n",
            "         [-2.3790, -2.6135,  0.0132],\n",
            "         [-1.9162, -2.3392,  0.4214],\n",
            "         [ 1.9826, -0.3262,  0.4453]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-3.9942,  2.8508, -4.3509],\n",
            "         [-3.3028, -2.7765, -0.6744],\n",
            "         [-2.6464, -3.0318, -1.0107],\n",
            "         [-2.4445, -2.6564, -0.0306],\n",
            "         [-2.0106, -2.3983,  0.4039],\n",
            "         [ 2.0546, -0.3433,  0.4634]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-4.0001,  2.9202, -4.4009],\n",
            "         [-3.3234, -2.8221, -0.9943],\n",
            "         [-2.7016, -3.0560, -1.2494],\n",
            "         [-2.5023, -2.6960, -0.0781],\n",
            "         [-2.0895, -2.4496,  0.3859],\n",
            "         [ 2.1182, -0.3550,  0.4821]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.,  1., -1.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-4.0059,  2.9808, -4.4463],\n",
            "         [-3.3433, -2.8636, -1.4757],\n",
            "         [-2.7502, -3.0781, -1.5528],\n",
            "         [-2.5537, -2.7337, -0.1275],\n",
            "         [-2.1560, -2.4974,  0.3672],\n",
            "         [ 2.1750, -0.3608,  0.5012]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.81005859375\n",
            "0 act:  6 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4930, -0.0225,  0.4205],\n",
            "         [ 0.0714,  0.1678,  0.5259],\n",
            "         [ 0.0952, -0.1658,  0.3773],\n",
            "         [-0.5128,  0.2677,  0.2699],\n",
            "         [ 0.4305,  0.4751, -0.0769],\n",
            "         [ 0.3842, -0.0162, -0.2113]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.0791, -3.0411,  0.4849],\n",
            "         [ 2.2112, -0.7441,  0.5140],\n",
            "         [ 1.0517, -1.6224,  0.4007],\n",
            "         [-0.0061, -0.6942,  0.2894],\n",
            "         [ 0.7976, -0.0868, -0.0520],\n",
            "         [ 0.6136, -0.4395, -0.1926]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.4460, -3.0820,  0.5778],\n",
            "         [ 2.3646, -3.1606,  0.5633],\n",
            "         [ 1.8958, -2.0039,  0.4524],\n",
            "         [-0.4235, -2.1535,  0.3270],\n",
            "         [ 1.8262, -0.1760,  0.0278],\n",
            "         [ 1.3660, -0.4765, -0.1406]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.7456, -3.1197,  0.6553],\n",
            "         [ 2.4788, -3.1897,  0.6081],\n",
            "         [ 2.0867, -2.1919,  0.4994],\n",
            "         [-0.7746, -2.2728,  0.3595],\n",
            "         [ 2.0049, -0.2626,  0.0947],\n",
            "         [ 1.6169, -0.4933, -0.0908]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.5732, -3.1587,  0.7154],\n",
            "         [ 2.5691, -3.2167,  0.6504],\n",
            "         [ 2.2205, -2.3291,  0.5371],\n",
            "         [-1.6722, -2.3841,  0.3327],\n",
            "         [ 2.1390, -0.3622,  0.1508],\n",
            "         [ 1.7787, -0.5163, -0.0447]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.6382e+00, -3.1935e+00,  7.7139e-01],\n",
            "         [ 2.6444e+00, -3.2421e+00,  6.8918e-01],\n",
            "         [ 2.3229e+00, -2.4336e+00,  5.7247e-01],\n",
            "         [-1.8778e+00, -2.4714e+00,  3.0478e-01],\n",
            "         [ 2.2431e+00, -4.5173e-01,  2.0194e-01],\n",
            "         [ 1.8989e+00, -5.3710e-01, -2.0849e-03]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.6998, -3.2274,  0.8202],\n",
            "         [ 2.7116, -3.2671,  0.7251],\n",
            "         [ 2.4099, -2.5213,  0.6058],\n",
            "         [-2.0231, -2.5432,  0.2749],\n",
            "         [ 2.3231, -0.5519,  0.2435],\n",
            "         [ 1.9949, -0.5552,  0.0378]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.7528, -3.2585,  0.8649],\n",
            "         [ 2.7693, -3.2905,  0.7588],\n",
            "         [ 2.4833, -2.5953,  0.6373],\n",
            "         [-2.1331, -2.6038,  0.2438],\n",
            "         [ 2.3775, -1.1154,  0.2562],\n",
            "         [ 2.0372, -1.0977,  0.0676]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.8015, -3.2880,  0.9054],\n",
            "         [ 2.8213, -3.3131,  0.7905],\n",
            "         [ 2.5483, -2.6604,  0.6672],\n",
            "         [-2.2245, -2.6564,  0.2105],\n",
            "         [ 2.4274, -1.4054,  0.2694],\n",
            "         [ 2.0782, -1.3716,  0.0953]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.8445, -3.3154,  0.9430],\n",
            "         [ 2.8672, -3.3342,  0.8201],\n",
            "         [ 2.6029, -2.7154,  0.6949],\n",
            "         [-2.2973, -2.7072,  0.1750],\n",
            "         [ 2.4718, -1.5654,  0.2814],\n",
            "         [ 2.1148, -1.5391,  0.1219]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 2.8846, -3.3417,  0.9781],\n",
            "         [ 2.9104, -3.3549,  0.8480],\n",
            "         [ 2.6536, -2.7662,  0.7214],\n",
            "         [-2.3626, -2.7510,  0.1371],\n",
            "         [ 2.5130, -1.6926,  0.2936],\n",
            "         [ 2.1497, -1.6658,  0.1471]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.822265625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.5071,  0.4752,  0.1926],\n",
            "         [-0.3934,  0.3476,  0.1310],\n",
            "         [ 0.0284, -0.2225,  0.1460],\n",
            "         [-0.3917,  0.2372,  0.3907],\n",
            "         [-0.3435, -0.4548, -0.0316],\n",
            "         [-0.2864,  0.3736,  0.0270]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.7029e+00, -1.5592e+00,  4.2703e-01],\n",
            "         [ 7.1266e-01, -1.5756e+00,  2.1440e-01],\n",
            "         [ 5.8117e-01, -1.7611e+00,  1.9626e-01],\n",
            "         [-8.6958e-03, -6.9141e-01,  4.1898e-01],\n",
            "         [ 1.9852e-01, -1.0349e+00, -1.1851e-03],\n",
            "         [-1.8466e-02, -3.0095e-03,  3.9799e-02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.7391, -1.8759,  0.5650],\n",
            "         [ 3.3134, -2.0305,  0.3385],\n",
            "         [ 2.4623, -2.0547,  0.2982],\n",
            "         [-0.3773, -2.1105,  0.4500],\n",
            "         [-0.0591, -1.6487,  0.0449],\n",
            "         [ 0.5625, -0.1513,  0.0377]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.7736, -2.0588,  0.6701],\n",
            "         [ 3.3356, -2.2301,  0.4371],\n",
            "         [ 2.5377, -2.2296,  0.3795],\n",
            "         [-0.6975, -2.2350,  0.4749],\n",
            "         [-0.3149, -1.8578,  0.0878],\n",
            "         [ 1.3592, -0.1891,  0.0720]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.8066, -2.1934,  0.7552],\n",
            "         [ 3.3567, -2.3705,  0.5177],\n",
            "         [ 2.6025, -2.3557,  0.4467],\n",
            "         [-1.7105, -2.3450,  0.4639],\n",
            "         [-0.5666, -1.9998,  0.1222],\n",
            "         [ 1.6083, -0.2299,  0.1040]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.8404, -2.3167,  0.8238],\n",
            "         [ 3.3769, -2.4793,  0.5862],\n",
            "         [ 2.6599, -2.4546,  0.5070],\n",
            "         [-1.9096, -2.4306,  0.4511],\n",
            "         [-1.4149, -2.1115,  0.1004],\n",
            "         [ 1.7594, -0.2536,  0.1319]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.8688, -2.3958,  0.8869],\n",
            "         [ 3.3963, -2.5632,  0.6469],\n",
            "         [ 2.7107, -2.5351,  0.5604],\n",
            "         [-2.0437, -2.5048,  0.4389],\n",
            "         [-1.6566, -2.2032,  0.0777],\n",
            "         [ 1.8726, -0.2782,  0.1580]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.8975, -2.4727,  0.9409],\n",
            "         [ 3.4150, -2.6359,  0.7004],\n",
            "         [ 2.7568, -2.6037,  0.6093],\n",
            "         [-2.1491, -2.5682,  0.4257],\n",
            "         [-1.8133, -2.2772,  0.0537],\n",
            "         [ 1.9654, -0.3008,  0.1837]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.9244, -2.5378,  0.9895],\n",
            "         [ 3.4330, -2.6970,  0.7490],\n",
            "         [ 2.7987, -2.6633,  0.6535],\n",
            "         [-2.2337, -2.6248,  0.4127],\n",
            "         [-1.9293, -2.3432,  0.0290],\n",
            "         [ 2.0417, -0.3259,  0.2073]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.9485e+00, -2.5894e+00,  1.0350e+00],\n",
            "         [ 3.4505e+00, -2.7518e+00,  7.9338e-01],\n",
            "         [ 2.8375e+00, -2.7174e+00,  6.9301e-01],\n",
            "         [-2.3060e+00, -2.6756e+00,  3.9918e-01],\n",
            "         [-2.0232e+00, -2.4002e+00,  2.8276e-03],\n",
            "         [ 2.1072e+00, -3.5272e-01,  2.2955e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 2.9715, -2.6358,  1.0765],\n",
            "         [ 3.4674, -2.7997,  0.8344],\n",
            "         [ 2.8734, -2.7659,  0.7299],\n",
            "         [-2.3690, -2.7207,  0.3850],\n",
            "         [-2.1008, -2.4514, -0.0243],\n",
            "         [ 2.1666, -0.3727,  0.2522]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.822265625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.0135, -0.0379,  0.2398],\n",
            "         [-0.2449, -0.0254, -0.1568],\n",
            "         [-0.3557,  0.3620, -0.4268],\n",
            "         [-0.1230,  0.0551,  0.2854],\n",
            "         [-0.5183,  0.4583, -0.3563],\n",
            "         [-0.1399,  0.2696, -0.1000]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.5378, -3.7196,  0.3264],\n",
            "         [ 1.9671, -0.7592, -0.1950],\n",
            "         [ 0.3308, -0.8877, -0.3376],\n",
            "         [ 0.3691, -0.9019,  0.3017],\n",
            "         [-0.1694, -0.1181, -0.3144],\n",
            "         [ 0.0931, -0.1106, -0.0855]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 1.7276, -3.7292,  0.4698],\n",
            "         [ 2.2107, -3.0807,  0.0254],\n",
            "         [-0.2286, -2.5153, -0.1996],\n",
            "         [-0.0275, -2.0440,  0.3332],\n",
            "         [ 0.6680, -0.3442, -0.3225],\n",
            "         [ 0.5358, -0.2547, -0.0923]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.0021, -3.7388,  0.5570],\n",
            "         [ 2.3575, -3.1128,  0.1723],\n",
            "         [-0.7855, -2.5985, -0.0727],\n",
            "         [-0.4410, -2.1920,  0.3676],\n",
            "         [ 1.9479, -0.3903, -0.2022],\n",
            "         [ 0.9137, -0.4099, -0.0989]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.1700, -3.7484,  0.6300],\n",
            "         [ 2.4710, -3.1441,  0.2845],\n",
            "         [-2.0810, -2.6745, -0.1588],\n",
            "         [-0.7769, -2.3019,  0.3987],\n",
            "         [ 2.0944, -0.4303, -0.1088],\n",
            "         [ 1.4376, -0.4226, -0.0523]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.2922, -3.7579,  0.6929],\n",
            "         [ 2.5615, -3.1733,  0.3750],\n",
            "         [-2.2195, -2.7418, -0.2625],\n",
            "         [-1.7124, -2.3988,  0.3742],\n",
            "         [ 2.2046, -0.5348, -0.0320],\n",
            "         [ 1.6474, -0.4781, -0.0149]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.3921, -3.7674,  0.7477],\n",
            "         [ 2.6385, -3.2013,  0.4506],\n",
            "         [-2.3249, -2.8007, -0.3867],\n",
            "         [-1.9100, -2.4798,  0.3484],\n",
            "         [ 2.2927, -0.6268,  0.0340],\n",
            "         [ 1.7938, -0.5183,  0.0219]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.4700, -3.7765,  0.7986],\n",
            "         [ 2.7045, -3.2277,  0.5164],\n",
            "         [-2.4112, -2.8527, -0.5397],\n",
            "         [-2.0460, -2.5478,  0.3216],\n",
            "         [ 2.3516, -1.1597,  0.0536],\n",
            "         [ 1.9080, -0.5730,  0.0576]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.5405, -3.7857,  0.8430],\n",
            "         [ 2.7622, -3.2528,  0.5746],\n",
            "         [-2.4847, -2.8994, -0.7356],\n",
            "         [-2.1514, -2.6057,  0.2935],\n",
            "         [ 2.4032, -1.4059,  0.0718],\n",
            "         [ 1.9590, -1.1132,  0.0862]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.5979, -3.7944,  0.8854],\n",
            "         [ 2.8138, -3.2766,  0.6267],\n",
            "         [-2.5484, -2.9415, -0.9952],\n",
            "         [-2.2373, -2.6583,  0.2636],\n",
            "         [ 2.4503, -1.5749,  0.0900],\n",
            "         [ 2.0062, -1.3774,  0.1132]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 2.6516, -3.8032,  0.9235],\n",
            "         [ 2.8606, -3.2995,  0.6736],\n",
            "         [-2.6045, -2.9801, -1.3494],\n",
            "         [-2.3100, -2.7065,  0.2318],\n",
            "         [ 2.4935, -1.7034,  0.1078],\n",
            "         [ 2.0492, -1.5462,  0.1387]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.83349609375\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2898, -0.4028, -0.2779],\n",
            "         [ 0.3685,  0.0005, -0.1492],\n",
            "         [ 0.2039, -0.3752, -0.1388],\n",
            "         [-0.0198,  0.2412, -0.2064],\n",
            "         [ 0.3745,  0.3078,  0.1803],\n",
            "         [-0.1050, -0.2701, -0.3695]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.3781, -0.7236, -0.4934],\n",
            "         [ 3.1986,  0.6882, -0.1009],\n",
            "         [ 0.9067, -1.6154, -0.0401],\n",
            "         [ 0.3230, -0.7582, -0.1457],\n",
            "         [ 0.5121, -0.2759,  0.2009],\n",
            "         [ 0.2130, -0.6447, -0.3414]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.5011, -2.5038, -0.7249],\n",
            "         [ 3.2354,  0.5920,  0.2185],\n",
            "         [ 2.3298, -1.9405,  0.1028],\n",
            "         [ 0.4816, -2.0118, -0.0750],\n",
            "         [ 0.9946, -0.5598,  0.2013],\n",
            "         [ 0.1043, -1.2367, -0.2934]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.5971, -2.5802, -1.0464],\n",
            "         [ 3.2699,  0.4484,  0.4006],\n",
            "         [ 2.4396, -2.1093,  0.2145],\n",
            "         [ 0.6030, -2.1493, -0.0219],\n",
            "         [ 1.5074, -1.6354,  0.2469],\n",
            "         [-0.0471, -1.4879, -0.2556]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.6770, -2.6457, -1.5209],\n",
            "         [ 3.2994,  1.1116,  0.4876],\n",
            "         [ 2.5270, -2.2274,  0.3045],\n",
            "         [ 1.8928, -2.2489,  0.0799],\n",
            "         [ 1.7274, -1.8424,  0.2882],\n",
            "         [-0.2105, -1.6507, -0.2242]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.7446, -2.7039, -2.1157],\n",
            "         [ 3.3297,  1.0299,  0.5973],\n",
            "         [ 2.6008, -2.3151,  0.3814],\n",
            "         [ 2.0426, -2.3214,  0.1662],\n",
            "         [ 1.8707, -1.9603,  0.3290],\n",
            "         [-0.3575, -1.7711, -0.1909]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.7983, -2.7269, -1.3038],\n",
            "         [ 3.3582,  0.9296,  0.6866],\n",
            "         [ 2.6643, -2.3932,  0.4470],\n",
            "         [ 2.1613, -2.3924,  0.2382],\n",
            "         [ 1.9811, -2.0569,  0.3659],\n",
            "         [-0.4920, -1.8662, -0.1625]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.8517, -2.7753, -1.8828],\n",
            "         [ 3.3849,  0.8537,  0.7591],\n",
            "         [ 2.7208, -2.4593,  0.5055],\n",
            "         [ 2.2518, -2.4495,  0.3008],\n",
            "         [ 2.0702, -2.1371,  0.3999],\n",
            "         [-0.6137, -1.9461, -0.1340]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.8959, -2.7970, -0.9622],\n",
            "         [ 3.4100,  0.7859,  0.8204],\n",
            "         [ 2.7706, -2.5196,  0.5565],\n",
            "         [ 2.3305, -2.5038,  0.3579],\n",
            "         [ 2.1451, -2.2061,  0.4316],\n",
            "         [-1.0571, -2.0186, -0.1481]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.9401, -2.8403, -1.3878],\n",
            "         [ 3.4339,  0.7446,  0.8737],\n",
            "         [ 2.8160, -2.5758,  0.6025],\n",
            "         [ 2.3958, -2.5500,  0.4080],\n",
            "         [ 2.2102, -2.2678,  0.4602],\n",
            "         [-1.3000, -2.0818, -0.1626]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 2.9804, -2.8787, -1.9906],\n",
            "         [ 3.4572,  0.6129,  0.9251],\n",
            "         [ 2.8576, -2.6242,  0.6452],\n",
            "         [ 2.4530, -2.5918,  0.4534],\n",
            "         [ 2.2680, -2.3220,  0.4887],\n",
            "         [-1.4665, -2.1348, -0.1793]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.85302734375\n",
            "0 act:  2 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.0912,  0.1225, -0.2311],\n",
            "         [-0.0296,  0.4106, -0.4515],\n",
            "         [ 0.4740,  0.0600, -0.3040],\n",
            "         [ 0.3189, -0.1108, -0.3851],\n",
            "         [-0.1105, -0.1799, -0.0479],\n",
            "         [-0.4314, -0.5230,  0.2022]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.1426, -3.7233, -0.0926],\n",
            "         [ 2.8784,  0.4647, -0.4174],\n",
            "         [ 1.8739, -0.4022, -0.3045],\n",
            "         [ 0.5721, -1.2019, -0.3120],\n",
            "         [ 0.1666, -0.8153, -0.0058],\n",
            "         [-0.1734, -0.8295,  0.2121]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 0.4736, -3.7275, -0.1831],\n",
            "         [ 2.9398,  1.4502, -0.0117],\n",
            "         [ 2.1868, -0.3284, -0.1163],\n",
            "         [ 1.9143, -1.7852, -0.1401],\n",
            "         [-0.0118, -1.6118,  0.0419],\n",
            "         [-0.3202, -1.2995,  0.2276]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 0.9896, -3.7313, -0.2897],\n",
            "         [ 3.0026,  1.3543,  0.1370],\n",
            "         [ 2.3596, -0.1993,  0.0220],\n",
            "         [ 2.0681, -1.9925, -0.0127],\n",
            "         [-0.2017, -1.8256,  0.0813],\n",
            "         [-0.4574, -1.5237,  0.2415]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.5606, -3.7388, -0.3252],\n",
            "         [ 3.0571,  1.2751,  0.2414],\n",
            "         [ 2.4823, -0.0820,  0.1283],\n",
            "         [ 2.1763, -2.1174,  0.0896],\n",
            "         [-0.3750, -1.9694,  0.1232],\n",
            "         [-0.5820, -1.6747,  0.2553]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.6480, -3.7456, -0.3734],\n",
            "         [ 3.1064,  1.1685,  0.3301],\n",
            "         [ 2.5793,  0.0310,  0.2163],\n",
            "         [ 2.2657, -2.2192,  0.1733],\n",
            "         [-0.5473, -2.0789,  0.1538],\n",
            "         [-1.0428, -1.7938,  0.2482]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.7215, -3.7524, -0.4255],\n",
            "         [ 3.1516,  1.0193,  0.4078],\n",
            "         [ 2.6599,  0.1737,  0.2917],\n",
            "         [ 2.3410, -2.3039,  0.2436],\n",
            "         [-0.6972, -2.1677,  0.1831],\n",
            "         [-1.2924, -1.8887,  0.2410]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.7849, -3.7591, -0.4825],\n",
            "         [ 3.1929,  0.8289,  0.4746],\n",
            "         [ 2.7284,  0.2801,  0.3567],\n",
            "         [ 2.4056, -2.3766,  0.3035],\n",
            "         [-1.3954, -2.2485,  0.1684],\n",
            "         [-1.4629, -1.9679,  0.2310]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.8410, -3.7658, -0.5428],\n",
            "         [ 3.2306,  0.6182,  0.5313],\n",
            "         [ 2.7877,  0.3467,  0.4131],\n",
            "         [ 2.4622, -2.4387,  0.3572],\n",
            "         [-1.6326, -2.3189,  0.1538],\n",
            "         [-1.5895, -2.0353,  0.2208]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.8911, -3.7723, -0.6117],\n",
            "         [ 3.2658,  0.2992,  0.5839],\n",
            "         [ 2.8409,  0.4780,  0.4647],\n",
            "         [ 2.5130, -2.4932,  0.4071],\n",
            "         [-1.7902, -2.3787,  0.1378],\n",
            "         [-1.6910, -2.0931,  0.2102]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 2.9370, -3.7791, -0.6819],\n",
            "         [ 3.2941,  1.4375,  0.6489],\n",
            "         [ 2.8883,  0.5850,  0.5110],\n",
            "         [ 2.5607, -2.5456,  0.4526],\n",
            "         [-1.9064, -2.4330,  0.1220],\n",
            "         [-1.7752, -2.1444,  0.1993]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8466796875\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.2383,  0.0205, -0.3121],\n",
            "         [ 0.4207, -0.0643, -0.0908],\n",
            "         [-0.2612,  0.1757, -0.3476],\n",
            "         [ 0.3236, -0.1629,  0.0365],\n",
            "         [-0.1464,  0.1964, -0.3046],\n",
            "         [ 0.3992, -0.2995, -0.0233]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-2.4223,  2.1097, -0.8452],\n",
            "         [ 0.4367,  0.1574, -0.2144],\n",
            "         [-0.1248, -0.1431, -0.3889],\n",
            "         [ 0.5815, -0.5700,  0.0218],\n",
            "         [ 0.1346, -0.1555, -0.3122],\n",
            "         [ 0.6419, -0.5045, -0.0269]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-2.5011,  2.1757, -1.4204],\n",
            "         [ 0.4783,  0.2998, -0.3554],\n",
            "         [ 0.1044, -0.4838, -0.4240],\n",
            "         [ 2.0222, -1.9720,  0.0906],\n",
            "         [ 0.5071, -0.4769, -0.3237],\n",
            "         [ 1.3216, -0.5105,  0.0218]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.,  1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-2.5681,  2.2336, -2.3511],\n",
            "         [ 0.4945,  0.4873, -0.5486],\n",
            "         [ 0.2405, -0.6886, -0.4706],\n",
            "         [ 2.1554, -2.1131,  0.1504],\n",
            "         [ 0.8537, -0.7667, -0.3339],\n",
            "         [ 1.5741, -0.5096,  0.0701]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-2.6415,  2.4146, -4.1235],\n",
            "         [ 0.3872,  0.4636, -0.7944],\n",
            "         [-0.8267, -2.7147, -0.5306],\n",
            "         [ 2.2566, -2.2162,  0.2016],\n",
            "         [ 1.4414, -1.5790, -0.2531],\n",
            "         [ 1.7473, -0.6006,  0.1055]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-2.7048,  2.5423, -4.1978],\n",
            "         [ 0.2519,  0.4674, -1.1617],\n",
            "         [-2.3220, -2.7619, -0.6712],\n",
            "         [ 2.3619, -2.2723,  0.2192],\n",
            "         [ 1.6652, -1.7925, -0.1836],\n",
            "         [ 1.8194, -1.1616,  0.1280]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-2.7598,  2.6415, -4.2623],\n",
            "         [ 0.1099,  0.4703, -1.6965],\n",
            "         [-2.4262, -2.8046, -0.8418],\n",
            "         [ 2.4479, -2.3217,  0.2360],\n",
            "         [ 1.8164, -1.9376, -0.1221],\n",
            "         [ 1.8832, -1.4208,  0.1494]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-2.8050,  2.7241, -4.3209],\n",
            "         [-0.9803,  0.4655, -2.9102],\n",
            "         [-2.5162, -2.8431, -1.0413],\n",
            "         [ 2.5214, -2.3687,  0.2537],\n",
            "         [ 1.9675, -2.0115, -0.1048],\n",
            "         [ 1.9395, -1.5868,  0.1700]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [ 0.0000,  0.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-2.8469,  2.7935, -4.3719],\n",
            "         [-3.0004,  0.5201, -3.2977],\n",
            "         [-2.5920, -2.8787, -1.3032],\n",
            "         [ 2.5857, -2.4139,  0.2717],\n",
            "         [ 2.0805, -2.0778, -0.0871],\n",
            "         [ 1.9888, -1.7074,  0.1901]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000,  0.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-2.8858,  2.8540, -4.4181],\n",
            "         [-3.0464,  0.6451, -3.4880],\n",
            "         [-2.6572, -2.9118, -1.6138],\n",
            "         [ 2.6418, -2.4545,  0.2888],\n",
            "         [ 2.1713, -2.1340, -0.0708],\n",
            "         [ 2.0344, -1.8050,  0.2093]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000,  0.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-2.9222,  2.9072, -4.4597],\n",
            "         [-3.0824,  3.1476, -3.6382],\n",
            "         [-2.7222, -2.9417, -2.2200],\n",
            "         [ 2.6922, -2.4929,  0.3058],\n",
            "         [ 2.2478, -2.1865, -0.0542],\n",
            "         [ 2.0762, -1.8861,  0.2279]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000,  1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.84423828125\n",
            "0 act:  6 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3598,  0.4968, -0.3564],\n",
            "         [ 0.0670, -0.4367,  0.0914],\n",
            "         [-0.4845, -0.2863, -0.0086],\n",
            "         [ 0.5281, -0.3109, -0.4444],\n",
            "         [-0.4716,  0.3632, -0.4307],\n",
            "         [-0.1853,  0.1256,  0.0940]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.6848, -1.1967,  0.4001],\n",
            "         [ 1.5335, -2.2600,  0.2034],\n",
            "         [ 0.0422, -1.6758,  0.0583],\n",
            "         [ 0.7848, -1.2021, -0.3375],\n",
            "         [ 0.0190, -0.2433, -0.3742],\n",
            "         [ 0.1519, -0.2883,  0.1079]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.7241, -1.6657,  0.4984],\n",
            "         [ 2.2981, -2.3739,  0.3478],\n",
            "         [ 0.2591, -2.0602,  0.1254],\n",
            "         [ 1.8417, -1.8678, -0.1467],\n",
            "         [ 1.0398, -0.5724, -0.3713],\n",
            "         [ 0.6570, -0.4161,  0.1056]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.7608, -1.8785,  0.5794],\n",
            "         [ 2.4751, -2.4665,  0.4564],\n",
            "         [ 0.4575, -2.2425,  0.1835],\n",
            "         [ 2.0106, -2.0536, -0.0156],\n",
            "         [ 1.5333, -1.6499, -0.2361],\n",
            "         [ 1.3270, -0.4453,  0.1355]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.7950, -2.0260,  0.6480],\n",
            "         [ 2.6003, -2.5414,  0.5453],\n",
            "         [ 0.6404, -2.3706,  0.2369],\n",
            "         [ 2.1328, -2.1837,  0.0884],\n",
            "         [ 1.7456, -1.8517, -0.1290],\n",
            "         [ 1.5743, -0.4713,  0.1640]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.8266, -2.1298,  0.7085],\n",
            "         [ 2.6965, -2.6048,  0.6191],\n",
            "         [ 2.3960, -2.4596,  0.3307],\n",
            "         [ 2.2290, -2.2714,  0.1738],\n",
            "         [ 1.8899, -1.9895, -0.0372],\n",
            "         [ 1.7316, -0.5088,  0.1903]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.8561, -2.2140,  0.7623],\n",
            "         [ 2.7761, -2.6603,  0.6830],\n",
            "         [ 2.4800, -2.5339,  0.4091],\n",
            "         [ 2.3088, -2.3449,  0.2481],\n",
            "         [ 1.9994, -2.0954,  0.0392],\n",
            "         [ 1.8496, -0.5399,  0.2156]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.8836, -2.2810,  0.8110],\n",
            "         [ 2.8447, -2.7087,  0.7406],\n",
            "         [ 2.5519, -2.5997,  0.4753],\n",
            "         [ 2.3777, -2.4098,  0.3118],\n",
            "         [ 2.0884, -2.1824,  0.1042],\n",
            "         [ 1.9438, -0.5719,  0.2396]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.9099, -2.3420,  0.8552],\n",
            "         [ 2.9041, -2.7531,  0.7915],\n",
            "         [ 2.6137, -2.6561,  0.5347],\n",
            "         [ 2.4372, -2.4657,  0.3688],\n",
            "         [ 2.1619, -2.2537,  0.1616],\n",
            "         [ 1.9927, -1.1175,  0.2599]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.9346, -2.3935,  0.8958],\n",
            "         [ 2.9571, -2.7922,  0.8379],\n",
            "         [ 2.6684, -2.7063,  0.5884],\n",
            "         [ 2.4901, -2.5161,  0.4192],\n",
            "         [ 2.2256, -2.3156,  0.2136],\n",
            "         [ 2.0373, -1.3778,  0.2794]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 2.9581, -2.4411,  0.9330],\n",
            "         [ 3.0047, -2.8281,  0.8800],\n",
            "         [ 2.7172, -2.7509,  0.6372],\n",
            "         [ 2.5378, -2.5613,  0.4661],\n",
            "         [ 2.2823, -2.3710,  0.2605],\n",
            "         [ 2.0791, -1.5502,  0.2977]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8759765625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.0824,  0.3552,  0.2747],\n",
            "         [-0.4372,  0.2988, -0.2273],\n",
            "         [ 0.2866, -0.1173,  0.1439],\n",
            "         [-0.0320,  0.3060,  0.2780],\n",
            "         [-0.4165, -0.1498, -0.4701],\n",
            "         [ 0.1379,  0.5157, -0.1811]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 0.6604, -0.1205,  0.2491],\n",
            "         [ 0.0051, -0.4036, -0.2371],\n",
            "         [ 0.7901, -0.8209,  0.1352],\n",
            "         [ 0.5527, -0.1631,  0.2730],\n",
            "         [-0.0060, -0.5260, -0.4807],\n",
            "         [ 0.3616,  0.2038, -0.1645]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 4.1302, -0.4221,  0.2583],\n",
            "         [ 0.7994, -1.0077, -0.2469],\n",
            "         [ 2.3537, -2.2387,  0.2144],\n",
            "         [ 2.5769, -0.3945,  0.3304],\n",
            "         [ 0.7686, -0.7069, -0.4999],\n",
            "         [ 0.7787,  0.0592, -0.1720]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 4.1356, -0.6455,  0.2813],\n",
            "         [ 3.4154, -2.2820, -0.1736],\n",
            "         [ 2.4406, -2.3723,  0.2784],\n",
            "         [ 2.6367, -0.5664,  0.3801],\n",
            "         [ 1.4027, -1.5450, -0.3901],\n",
            "         [ 1.4096, -0.0084, -0.1202]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 4.1397, -4.0268,  0.3621],\n",
            "         [ 3.4357, -2.4130, -0.1023],\n",
            "         [ 2.5370, -2.4434,  0.2973],\n",
            "         [ 2.6701, -2.0535,  0.4124],\n",
            "         [ 1.6447, -1.7764, -0.2996],\n",
            "         [ 1.6282, -0.0995, -0.0751]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 4.1437, -4.0331,  0.4341],\n",
            "         [ 3.4551, -2.5118, -0.0415],\n",
            "         [ 2.6167, -2.5041,  0.3153],\n",
            "         [ 2.7016, -2.1821,  0.4424],\n",
            "         [ 1.7984, -1.9248, -0.2215],\n",
            "         [ 1.7764, -0.1891, -0.0320]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 4.1477, -4.0393,  0.4954],\n",
            "         [ 3.4738, -2.5944,  0.0132],\n",
            "         [ 2.6847, -2.5574,  0.3322],\n",
            "         [ 2.7312, -2.2821,  0.4707],\n",
            "         [ 1.9131, -2.0358, -0.1539],\n",
            "         [ 1.8914, -0.2765,  0.0119]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 4.1516, -4.0455,  0.5515],\n",
            "         [ 3.4918, -2.6654,  0.0640],\n",
            "         [ 2.7443, -2.6067,  0.3492],\n",
            "         [ 2.7589, -2.3641,  0.4975],\n",
            "         [ 2.0052, -2.1261, -0.0927],\n",
            "         [ 1.9805, -0.3610,  0.0470]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 4.1555, -4.0514,  0.6033],\n",
            "         [ 3.5093, -2.7256,  0.1091],\n",
            "         [ 2.7975, -2.6515,  0.3657],\n",
            "         [ 2.7857, -2.4351,  0.5229],\n",
            "         [ 2.0833, -2.2023, -0.0386],\n",
            "         [ 2.0568, -0.4391,  0.0817]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 4.1595, -4.0575,  0.6447],\n",
            "         [ 3.5260, -2.7802,  0.1513],\n",
            "         [ 2.8450, -2.6910,  0.3809],\n",
            "         [ 2.8107, -2.4962,  0.5474],\n",
            "         [ 2.1513, -2.2691,  0.0108],\n",
            "         [ 2.1205, -0.5132,  0.1103]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 4.1632, -4.0633,  0.6882],\n",
            "         [ 3.5422, -2.8279,  0.1892],\n",
            "         [ 2.8881, -2.7276,  0.3959],\n",
            "         [ 2.8343, -2.5500,  0.5708],\n",
            "         [ 2.2103, -2.3267,  0.0555],\n",
            "         [ 2.1794, -0.5830,  0.1429]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.876953125\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4943, -0.4659,  0.3687],\n",
            "         [ 0.0415,  0.1773,  0.1264],\n",
            "         [ 0.5169, -0.3488, -0.1473],\n",
            "         [-0.3337, -0.2578,  0.1266],\n",
            "         [-0.4949, -0.0016,  0.4976],\n",
            "         [-0.2343,  0.3974,  0.1242]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.7569,  1.1921,  0.2651],\n",
            "         [-0.0411,  0.0844,  0.0939],\n",
            "         [ 0.7100, -0.7203, -0.1701],\n",
            "         [-0.0411, -0.6743,  0.1188],\n",
            "         [-0.2418, -0.3958,  0.4965],\n",
            "         [ 0.0173,  0.2136,  0.1214]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-3.5259e+00,  1.8966e+00,  1.9093e-01],\n",
            "         [-1.1479e-01,  5.4792e-02,  6.0939e-02],\n",
            "         [ 2.5620e+00, -2.3455e+00, -7.2357e-02],\n",
            "         [-6.9028e-01, -2.3407e+00,  1.2349e-01],\n",
            "         [ 1.5664e-01, -7.0246e-01,  4.9431e-01],\n",
            "         [ 3.0537e-01, -2.6020e-03,  1.1889e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-3.5421,  2.0938,  0.1012],\n",
            "         [-0.3128,  0.1456,  0.0208],\n",
            "         [ 2.6317, -2.4410,  0.0097],\n",
            "         [-1.7755, -2.4232,  0.0784],\n",
            "         [-0.1391, -1.6981,  0.5071],\n",
            "         [ 0.6112, -0.1937,  0.1172]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.,  1.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-3.5576,  2.2293, -0.0112],\n",
            "         [-0.5281,  0.2640, -0.0239],\n",
            "         [ 2.6927, -2.5201,  0.0780],\n",
            "         [-1.9602, -2.4952,  0.0287],\n",
            "         [-0.4370, -1.8869,  0.5161],\n",
            "         [ 1.3479, -0.2792,  0.1471]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-3.5728,  2.3318, -0.1315],\n",
            "         [-0.5436,  0.1956, -0.0622],\n",
            "         [ 2.7451, -2.5867,  0.1423],\n",
            "         [-2.0846, -2.5597, -0.0245],\n",
            "         [-0.6656, -2.0236,  0.5300],\n",
            "         [ 1.6020, -0.3608,  0.1779]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-3.5875,  2.4162, -0.2886],\n",
            "         [-0.6388,  0.2140, -0.1087],\n",
            "         [ 2.7935, -2.6457,  0.1962],\n",
            "         [-2.1850, -2.6145, -0.0842],\n",
            "         [-1.3951, -2.1376,  0.5176],\n",
            "         [ 1.7609, -0.4421,  0.2069]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-3.6014,  2.4879, -0.5070],\n",
            "         [-3.8624, -0.9326, -0.2090],\n",
            "         [ 2.8470, -2.6818,  0.2126],\n",
            "         [-2.2677, -2.6637, -0.1509],\n",
            "         [-1.6371, -2.2302,  0.5047],\n",
            "         [ 1.8760, -0.5179,  0.2320]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-3.6150,  2.5494, -0.7934],\n",
            "         [-3.8692, -2.5101, -0.3278],\n",
            "         [ 2.8916, -2.7153,  0.2410],\n",
            "         [-2.3399, -2.7065, -0.2268],\n",
            "         [-1.7946, -2.3029,  0.4917],\n",
            "         [ 1.9702, -0.5889,  0.2576]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-3.6288,  2.6038, -1.1620],\n",
            "         [-3.8759, -2.5992, -0.4686],\n",
            "         [ 2.9319, -2.7459,  0.2679],\n",
            "         [-2.4013, -2.7474, -0.3127],\n",
            "         [-1.9111, -2.3691,  0.4782],\n",
            "         [ 2.0350, -0.9679,  0.2633]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-3.6419,  2.6529, -1.7908],\n",
            "         [-3.8825, -2.6707, -0.6649],\n",
            "         [ 2.9689, -2.7755,  0.2921],\n",
            "         [-2.4548, -2.7856, -0.4114],\n",
            "         [-2.0027, -2.4282,  0.4645],\n",
            "         [ 2.0918, -1.1892,  0.2684]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.875\n",
            "0 act:  6 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.2529,  0.1569,  0.2361],\n",
            "         [ 0.3261, -0.4026, -0.1520],\n",
            "         [ 0.0873, -0.5029, -0.3093],\n",
            "         [-0.3766,  0.0995,  0.0524],\n",
            "         [-0.0414,  0.0273, -0.2921],\n",
            "         [ 0.4762, -0.3211, -0.2369]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 1.1523, -0.9233,  0.2474],\n",
            "         [ 2.4254, -1.0814, -0.1912],\n",
            "         [ 1.5032, -0.8817, -0.3452],\n",
            "         [ 0.4866, -0.2294,  0.0387],\n",
            "         [ 0.2974, -0.6284, -0.2598],\n",
            "         [ 0.6332, -0.6708, -0.2201]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.4651, -2.2869,  0.2868],\n",
            "         [ 2.5690, -2.1768, -0.0125],\n",
            "         [ 2.0809, -1.7471, -0.2571],\n",
            "         [ 1.4878, -0.5996,  0.0269],\n",
            "         [ 0.0458, -1.6668, -0.1908],\n",
            "         [ 1.0417, -1.1541, -0.1739]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.5758, -2.3961,  0.3245],\n",
            "         [ 2.6769, -2.3209,  0.1215],\n",
            "         [ 2.2700, -1.9420, -0.1859],\n",
            "         [ 1.7793, -1.9560,  0.1000],\n",
            "         [-0.2347, -1.8668, -0.1393],\n",
            "         [ 1.2795, -1.3965, -0.1304]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.6660, -2.4892,  0.3581],\n",
            "         [ 2.7635, -2.4283,  0.2254],\n",
            "         [ 2.3995, -2.0675, -0.1244],\n",
            "         [ 1.9444, -2.0991,  0.1641],\n",
            "         [-0.5042, -2.0054, -0.0887],\n",
            "         [ 1.4440, -1.5595, -0.0905]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.7399, -2.5616,  0.3909],\n",
            "         [ 2.8363, -2.5142,  0.3114],\n",
            "         [ 2.5000, -2.1633, -0.0700],\n",
            "         [ 2.0655, -2.2080,  0.2213],\n",
            "         [-0.7234, -2.1103, -0.0462],\n",
            "         [ 1.5646, -1.6788, -0.0528]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.8056, -2.6304,  0.4202],\n",
            "         [ 2.8998, -2.5876,  0.3851],\n",
            "         [ 2.5837, -2.2495, -0.0186],\n",
            "         [ 2.1668, -2.3013,  0.2721],\n",
            "         [-1.4058, -2.2045, -0.0839],\n",
            "         [ 1.7024, -1.7417, -0.0386]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.8624, -2.6872,  0.4488],\n",
            "         [ 2.9556, -2.6511,  0.4491],\n",
            "         [ 2.6538, -2.3213,  0.0273],\n",
            "         [ 2.2463, -2.3761,  0.3181],\n",
            "         [-1.6372, -2.2867, -0.1246],\n",
            "         [ 1.8092, -1.7971, -0.0247]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.9126, -2.7367,  0.4758],\n",
            "         [ 3.0055, -2.7062,  0.5058],\n",
            "         [ 2.7149, -2.3817,  0.0694],\n",
            "         [ 2.3147, -2.4408,  0.3601],\n",
            "         [-1.7873, -2.3563, -0.1681],\n",
            "         [ 1.8953, -1.8429, -0.0119]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.9584e+00, -2.7826e+00,  5.0144e-01],\n",
            "         [ 3.0508e+00, -2.7561e+00,  5.5683e-01],\n",
            "         [ 2.7695e+00, -2.4370e+00,  1.0879e-01],\n",
            "         [ 2.3767e+00, -2.4998e+00,  3.9945e-01],\n",
            "         [-1.9056e+00, -2.4133e+00, -2.1512e-01],\n",
            "         [ 1.9695e+00, -1.8890e+00,  1.4103e-03]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.0001, -2.8240,  0.5261],\n",
            "         [ 3.0923, -2.8018,  0.6027],\n",
            "         [ 2.8185, -2.4878,  0.1459],\n",
            "         [ 2.4318, -2.5523,  0.4355],\n",
            "         [-1.9984, -2.4654, -0.2660],\n",
            "         [ 2.0335, -1.9295,  0.0141]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search 0.88134765625\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.5127, -0.3049, -0.3633],\n",
            "         [ 0.4487,  0.1678,  0.0975],\n",
            "         [ 0.1571,  0.3871, -0.1374],\n",
            "         [-0.2447, -0.4217,  0.1290],\n",
            "         [-0.0119,  0.4206, -0.2619],\n",
            "         [ 0.3629,  0.3411,  0.5140]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 1.2258, -1.3259, -0.3969],\n",
            "         [ 1.6227, -0.8148,  0.0749],\n",
            "         [ 1.1204, -0.3151, -0.1507],\n",
            "         [ 0.7732, -0.7142,  0.1184],\n",
            "         [ 0.7549,  0.2195, -0.2767],\n",
            "         [ 0.5676, -0.0206,  0.5185]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.4440, -2.1555, -0.3051],\n",
            "         [ 2.3003, -2.5929,  0.1729],\n",
            "         [ 2.4037, -0.5775,  0.0201],\n",
            "         [ 1.7111, -1.9430,  0.1763],\n",
            "         [ 1.8797,  0.1179, -0.1696],\n",
            "         [ 1.3611, -0.0563,  0.5325]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.5675, -2.3347, -0.2342],\n",
            "         [ 2.4834, -2.6631,  0.2540],\n",
            "         [ 2.5038, -1.8723,  0.0453],\n",
            "         [ 1.8995, -2.0939,  0.2253],\n",
            "         [ 2.0448, -0.0324, -0.0649],\n",
            "         [ 1.6172, -0.0842,  0.5467]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.6650, -2.4662, -0.1818],\n",
            "         [ 2.6122, -2.7262,  0.3222],\n",
            "         [ 2.5876, -2.0450,  0.0718],\n",
            "         [ 2.0377, -2.2115,  0.2700],\n",
            "         [ 2.1605, -0.1829,  0.0110],\n",
            "         [ 1.7793, -0.1090,  0.5607]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.7452, -2.5626, -0.1187],\n",
            "         [ 2.7119, -2.7814,  0.3828],\n",
            "         [ 2.6587, -2.1682,  0.0965],\n",
            "         [ 2.1438, -2.3050,  0.3103],\n",
            "         [ 2.2554, -0.3298,  0.0827],\n",
            "         [ 1.8971, -0.1443,  0.5738]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.8134, -2.6407, -0.0585],\n",
            "         [ 2.7939, -2.8301,  0.4378],\n",
            "         [ 2.7206, -2.2644,  0.1201],\n",
            "         [ 2.2315, -2.3842,  0.3483],\n",
            "         [ 2.3320, -0.4663,  0.1385],\n",
            "         [ 1.9901, -0.1875,  0.5864]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.8732e+00, -2.7074e+00, -1.3746e-03],\n",
            "         [ 2.8636e+00, -2.8750e+00,  4.8660e-01],\n",
            "         [ 2.7751e+00, -2.3452e+00,  1.4258e-01],\n",
            "         [ 2.3038e+00, -2.4508e+00,  3.8375e-01],\n",
            "         [ 2.3981e+00, -5.8886e-01,  1.8983e-01],\n",
            "         [ 2.0687e+00, -2.2431e-01,  5.9880e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 2.9262, -2.7682,  0.0405],\n",
            "         [ 2.9242, -2.9161,  0.5308],\n",
            "         [ 2.8242, -2.4141,  0.1645],\n",
            "         [ 2.3671, -2.5087,  0.4156],\n",
            "         [ 2.4337, -1.5656,  0.2243],\n",
            "         [ 2.1325, -0.3104,  0.6106]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 2.9740, -2.8214,  0.0818],\n",
            "         [ 2.9782, -2.9539,  0.5718],\n",
            "         [ 2.8691, -2.4759,  0.1860],\n",
            "         [ 2.4237, -2.5609,  0.4454],\n",
            "         [ 2.4671, -1.7831,  0.2563],\n",
            "         [ 2.1901, -0.3933,  0.6230]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.0173, -2.8696,  0.1179],\n",
            "         [ 3.0266, -2.9886,  0.6103],\n",
            "         [ 2.9101, -2.5296,  0.2065],\n",
            "         [ 2.4747, -2.6084,  0.4739],\n",
            "         [ 2.4992, -1.9313,  0.2865],\n",
            "         [ 2.2408, -0.4706,  0.6345]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8740234375\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2574,  0.5280, -0.0247],\n",
            "         [ 0.3694,  0.5299, -0.1776],\n",
            "         [-0.3122,  0.2080,  0.4966],\n",
            "         [ 0.0026, -0.5205,  0.3281],\n",
            "         [-0.3034, -0.3460,  0.4254],\n",
            "         [ 0.1341,  0.0029, -0.1192]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 1.9962,  0.1582, -0.1872],\n",
            "         [ 3.3666, -0.0996, -0.1823],\n",
            "         [ 0.9959, -0.3619,  0.4926],\n",
            "         [ 1.0422, -0.7190,  0.3333],\n",
            "         [ 0.2393, -0.9676,  0.4382],\n",
            "         [ 0.4073, -0.4204, -0.1025]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.2986, -0.9703, -0.4371],\n",
            "         [ 3.3924,  0.3903,  0.0744],\n",
            "         [ 2.4433, -0.3053,  0.5352],\n",
            "         [ 1.7621, -1.8948,  0.3871],\n",
            "         [-0.0116, -1.6457,  0.4576],\n",
            "         [ 0.8658, -0.5618, -0.1084]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.5631, -1.7115, -0.8858],\n",
            "         [ 3.4168,  0.7552,  0.2330],\n",
            "         [ 2.5461, -0.2385,  0.5759],\n",
            "         [ 1.9633, -2.0628,  0.4347],\n",
            "         [-0.2516, -1.8455,  0.4732],\n",
            "         [ 1.1671, -1.1003, -0.0705]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.7188, -1.9135, -1.7261],\n",
            "         [ 3.4410,  1.0117,  0.3164],\n",
            "         [ 2.6285, -0.2120,  0.6115],\n",
            "         [ 2.1001, -2.1781,  0.4796],\n",
            "         [-0.4781, -1.9849,  0.4914],\n",
            "         [ 1.3602, -1.3647, -0.0352]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.8263e+00, -1.9288e+00, -1.5621e+00],\n",
            "         [ 3.4643e+00,  1.0697e+00,  3.9361e-01],\n",
            "         [ 2.6993e+00, -1.3118e-01,  6.4549e-01],\n",
            "         [ 2.2045e+00, -2.2721e+00,  5.2107e-01],\n",
            "         [-6.7870e-01, -2.0925e+00,  5.0761e-01],\n",
            "         [ 1.5026e+00, -1.5380e+00, -2.2991e-03]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 2.9127, -1.9554, -1.4356],\n",
            "         [ 3.4864,  1.1420,  0.4570],\n",
            "         [ 2.7610, -0.1710,  0.6769],\n",
            "         [ 2.2922, -2.3581,  0.5550],\n",
            "         [-1.3882, -2.1825,  0.4999],\n",
            "         [ 1.6313, -1.6829,  0.0384]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 2.9905, -2.0775, -2.7182],\n",
            "         [ 3.5082,  1.2581,  0.5170],\n",
            "         [ 2.8149, -0.1704,  0.7060],\n",
            "         [ 2.3652, -2.4253,  0.5895],\n",
            "         [-1.6271, -2.2628,  0.4927],\n",
            "         [ 1.7346, -1.7949,  0.0743]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.0531, -2.0896, -2.6651],\n",
            "         [ 3.5286,  1.2912,  0.5701],\n",
            "         [ 2.8636, -0.1068,  0.7340],\n",
            "         [ 2.4275, -2.4839,  0.6227],\n",
            "         [-1.7819, -2.3304,  0.4853],\n",
            "         [ 1.8191, -1.8853,  0.1085]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.1084, -2.1017, -2.6071],\n",
            "         [ 3.5483,  1.3248,  0.6178],\n",
            "         [ 2.9078, -0.1115,  0.7603],\n",
            "         [ 2.4829, -2.5379,  0.6518],\n",
            "         [-1.8967, -2.3896,  0.4779],\n",
            "         [ 1.8904, -1.9608,  0.1419]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.1576, -2.1219, -2.5597],\n",
            "         [ 3.5668,  1.3781,  0.6574],\n",
            "         [ 2.9480, -0.1485,  0.7849],\n",
            "         [ 2.5322, -2.5859,  0.6795],\n",
            "         [-1.9876, -2.4428,  0.4708],\n",
            "         [ 1.9520, -2.0256,  0.1743]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.89208984375\n",
            "0 act:  2 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.3930, -0.4261, -0.0584],\n",
            "         [-0.4691, -0.4462, -0.2502],\n",
            "         [ 0.2261, -0.3437, -0.2011],\n",
            "         [ 0.4795, -0.0695, -0.0434],\n",
            "         [ 0.4161, -0.2039, -0.0479],\n",
            "         [-0.2401, -0.0810, -0.5055]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 1.3974, -1.4984, -0.5731],\n",
            "         [ 1.9327,  0.6527, -0.5101],\n",
            "         [ 2.6622, -0.6683, -0.1815],\n",
            "         [ 0.8726, -1.1148,  0.0076],\n",
            "         [ 0.5726, -0.9272, -0.0196],\n",
            "         [-0.1175, -0.4508, -0.4576]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.9087, -1.4311, -1.1213],\n",
            "         [ 2.3491,  1.1163, -0.3898],\n",
            "         [ 2.7435, -1.6181, -0.1909],\n",
            "         [ 1.9011, -1.6745,  0.0948],\n",
            "         [ 1.5120, -1.5639,  0.0528],\n",
            "         [ 0.3411, -0.6293, -0.4611]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.9911, -1.3430, -2.1848],\n",
            "         [ 2.5344,  1.3505, -0.2890],\n",
            "         [ 2.8141, -1.8043, -0.2084],\n",
            "         [ 2.0755, -1.8808,  0.1700],\n",
            "         [ 1.7367, -1.7828,  0.1133],\n",
            "         [ 0.2052, -1.2169, -0.4284]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 3.0546, -1.6813, -2.5045],\n",
            "         [ 2.6510,  1.4242, -0.2685],\n",
            "         [ 2.8749, -1.9444, -0.2224],\n",
            "         [ 2.1993, -2.0230,  0.2345],\n",
            "         [ 1.8814, -1.9251,  0.1654],\n",
            "         [ 0.0647, -1.4759, -0.3723]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.1101, -1.8708, -2.7312],\n",
            "         [ 2.7433,  1.4965, -0.2493],\n",
            "         [ 2.9287, -2.0538, -0.2353],\n",
            "         [ 2.2966, -2.1337,  0.2914],\n",
            "         [ 1.9924, -2.0350,  0.2131],\n",
            "         [-0.0830, -1.6392, -0.3302]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.1601, -1.9995, -2.8801],\n",
            "         [ 2.8196,  1.5626, -0.2319],\n",
            "         [ 2.9773, -2.1351, -0.2543],\n",
            "         [ 2.3769, -2.2155,  0.3431],\n",
            "         [ 2.0810, -2.1201,  0.2589],\n",
            "         [-0.2279, -1.7607, -0.2864]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.2044, -2.1080, -3.0171],\n",
            "         [ 2.8852,  1.6281, -0.2169],\n",
            "         [ 3.0208, -2.2145, -0.2638],\n",
            "         [ 2.4457, -2.2915,  0.3894],\n",
            "         [ 2.1567, -2.1957,  0.2987],\n",
            "         [-0.3693, -1.8570, -0.2500]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.2452, -2.1937, -3.1188],\n",
            "         [ 2.9428,  1.6820, -0.2011],\n",
            "         [ 3.0609, -2.2787, -0.2781],\n",
            "         [ 2.5058, -2.3543,  0.4322],\n",
            "         [ 2.2215, -2.2598,  0.3362],\n",
            "         [-0.4980, -1.9377, -0.2130]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.2839, -2.2605, -3.1891],\n",
            "         [ 2.9948,  1.7218, -0.1818],\n",
            "         [ 3.0979, -2.3355, -0.2923],\n",
            "         [ 2.5592, -2.4096,  0.4716],\n",
            "         [ 2.2786, -2.3162,  0.3710],\n",
            "         [-0.6134, -2.0070, -0.1762]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.3197, -2.3191, -3.2511],\n",
            "         [ 3.0419,  1.7560, -0.1623],\n",
            "         [ 3.1325, -2.3869, -0.3064],\n",
            "         [ 2.6072, -2.4619,  0.5077],\n",
            "         [ 2.3303, -2.3683,  0.4031],\n",
            "         [-1.0623, -2.0692, -0.1925]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.88623046875\n",
            "0 act:  2 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1865,  0.0757,  0.2917],\n",
            "         [-0.0669, -0.5233, -0.2229],\n",
            "         [-0.3933, -0.0855,  0.1788],\n",
            "         [-0.0529, -0.0307, -0.3032],\n",
            "         [ 0.2008, -0.2612, -0.0880],\n",
            "         [-0.1598,  0.2498,  0.0822]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.7473, -1.1344,  0.0521],\n",
            "         [ 2.1003,  0.1033, -0.5832],\n",
            "         [ 1.3897, -0.0500,  0.2060],\n",
            "         [ 0.3171, -1.0087, -0.2230],\n",
            "         [ 0.3547, -0.9608, -0.0594],\n",
            "         [-0.0403, -0.0950,  0.0991]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.8204, -0.8621, -0.0552],\n",
            "         [ 2.3214,  1.7706, -1.1461],\n",
            "         [ 2.1950,  0.2042,  0.2865],\n",
            "         [ 0.5517, -1.8216, -0.1699],\n",
            "         [ 0.3605, -1.6500, -0.0254],\n",
            "         [ 0.3099, -0.2708,  0.0992]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1., -1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.8846, -0.4452, -0.1878],\n",
            "         [ 2.5196,  1.8409, -1.2257],\n",
            "         [ 2.3680,  0.5310,  0.3562],\n",
            "         [ 2.0968, -1.9838, -0.0437],\n",
            "         [ 0.4224, -1.8424,  0.0054],\n",
            "         [ 0.6664, -0.4348,  0.1005]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.9398,  1.4125, -0.2625],\n",
            "         [ 2.6536,  1.9011, -1.3006],\n",
            "         [ 2.4919,  0.7947,  0.4177],\n",
            "         [ 2.2176, -2.1081,  0.0558],\n",
            "         [ 0.4739, -1.9762,  0.0328],\n",
            "         [ 1.2615, -0.4774,  0.1243]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 2.9750,  1.0763, -0.8728],\n",
            "         [ 2.7547,  1.9476, -1.3688],\n",
            "         [ 2.5965,  0.6989,  0.4639],\n",
            "         [ 2.3184, -2.1959,  0.1453],\n",
            "         [ 0.5310, -2.0822,  0.0632],\n",
            "         [ 1.5114, -0.5080,  0.1476]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.0081,  0.4909, -2.3872],\n",
            "         [ 2.8367,  1.9951, -1.4601],\n",
            "         [ 2.6804,  0.6561,  0.5033],\n",
            "         [ 2.4015, -2.2736,  0.2211],\n",
            "         [ 0.5628, -2.1681,  0.0877],\n",
            "         [ 1.6697, -0.5563,  0.1691]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.0196,  1.4363, -2.1260],\n",
            "         [ 2.9073,  2.0331, -1.5238],\n",
            "         [ 2.7518,  0.5427,  0.5426],\n",
            "         [ 2.4677, -2.3348,  0.2837],\n",
            "         [ 1.4549, -2.2315,  0.1419],\n",
            "         [ 1.7639, -1.1337,  0.1974]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.0749,  1.7223, -0.6951],\n",
            "         [ 2.9692,  2.0722, -1.6011],\n",
            "         [ 2.8097,  0.8893,  0.5870],\n",
            "         [ 2.5256, -2.3906,  0.3387],\n",
            "         [ 1.6914, -2.2874,  0.1914],\n",
            "         [ 1.8431, -1.3999,  0.2238]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.1028,  1.5462, -1.8984],\n",
            "         [ 2.9926,  1.9858,  0.4178],\n",
            "         [ 2.8647,  0.8201,  0.6198],\n",
            "         [ 2.5774, -2.4396,  0.3886],\n",
            "         [ 1.8440, -2.3373,  0.2363],\n",
            "         [ 1.9110, -1.5674,  0.2494]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.1494,  1.7787, -0.1903],\n",
            "         [ 3.0449,  2.0218,  0.4136],\n",
            "         [ 2.9145,  0.6723,  0.6491],\n",
            "         [ 2.6270, -2.4804,  0.4374],\n",
            "         [ 1.9570, -2.3812,  0.2779],\n",
            "         [ 1.9703, -1.6865,  0.2752]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.88232421875\n",
            "0 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.5079, -0.4922,  0.1597],\n",
            "         [-0.1951,  0.4109,  0.3026],\n",
            "         [ 0.5054, -0.2064,  0.5287],\n",
            "         [-0.0240,  0.2431, -0.4557],\n",
            "         [ 0.3968, -0.2287,  0.4546],\n",
            "         [-0.3896, -0.1797, -0.0720]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-1.1396, -1.0290, -0.1767],\n",
            "         [ 2.7519,  0.6246,  0.2392],\n",
            "         [ 1.8371, -0.6305,  0.5305],\n",
            "         [ 0.3034, -0.7509, -0.3657],\n",
            "         [ 0.5173, -0.8240,  0.4665],\n",
            "         [-0.1175, -0.5649, -0.0552]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-1.8434, -2.5110, -0.0567],\n",
            "         [ 2.8267,  0.7439,  0.2526],\n",
            "         [ 2.1249, -2.2016,  0.5799],\n",
            "         [ 0.3686, -2.0077, -0.2846],\n",
            "         [ 0.3556, -1.6073,  0.4801],\n",
            "         [-0.2696, -1.2085, -0.0315]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-2.0430, -2.6072,  0.0402],\n",
            "         [ 2.8911,  0.8838,  0.2652],\n",
            "         [ 2.2899, -2.3129,  0.6246],\n",
            "         [ 0.4218, -2.1521, -0.2183],\n",
            "         [ 0.1846, -1.8236,  0.4975],\n",
            "         [-0.4131, -1.4692, -0.0104]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-2.1852, -2.6876,  0.1199],\n",
            "         [ 2.9479,  0.9832,  0.2778],\n",
            "         [ 2.4103, -2.4005,  0.6661],\n",
            "         [ 0.4659, -2.2618, -0.1607],\n",
            "         [-0.0122, -1.9683,  0.5123],\n",
            "         [-0.5463, -1.6353,  0.0083]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-2.2937, -2.7562,  0.1884],\n",
            "         [ 2.9986,  1.0684,  0.2903],\n",
            "         [ 2.5049, -2.4730,  0.7042],\n",
            "         [ 0.5233, -2.3507, -0.1047],\n",
            "         [-0.2105, -2.0776,  0.5273],\n",
            "         [-0.6645, -1.7581,  0.0278]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-2.3803, -2.8158,  0.2491],\n",
            "         [ 3.0443,  1.1368,  0.3024],\n",
            "         [ 2.5834, -2.5340,  0.7397],\n",
            "         [ 0.5907, -2.4256, -0.0511],\n",
            "         [-0.4019, -2.1670,  0.5421],\n",
            "         [-1.0903, -1.8577,  0.0165]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-2.4478, -2.8676,  0.3045],\n",
            "         [ 3.0862,  1.1755,  0.3150],\n",
            "         [ 2.6502, -2.5885,  0.7727],\n",
            "         [ 1.8985, -2.4841,  0.0541],\n",
            "         [-0.5841, -2.2423,  0.5539],\n",
            "         [-1.3260, -1.9379,  0.0045]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-2.5092, -2.9148,  0.3536],\n",
            "         [ 3.1248,  1.2197,  0.3274],\n",
            "         [ 2.7088, -2.6384,  0.8035],\n",
            "         [ 2.0552, -2.5376,  0.1382],\n",
            "         [-1.4076, -2.3091,  0.5458],\n",
            "         [-1.4900, -2.0063, -0.0116]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [-1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-2.5639, -2.9578,  0.3979],\n",
            "         [ 3.1605,  1.2633,  0.3395],\n",
            "         [ 2.7606, -2.6814,  0.8325],\n",
            "         [ 2.1683, -2.5832,  0.2118],\n",
            "         [-1.6427, -2.3706,  0.5385],\n",
            "         [-1.6114, -2.0681, -0.0278]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-2.6104, -2.9968,  0.4398],\n",
            "         [ 3.1937,  1.3025,  0.3513],\n",
            "         [ 2.8075, -2.7212,  0.8599],\n",
            "         [ 2.2597, -2.6252,  0.2768],\n",
            "         [-1.7995, -2.4243,  0.5306],\n",
            "         [-1.7102, -2.1207, -0.0450]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8876953125\n",
            "0 act:  9 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3880,  0.0882,  0.2076],\n",
            "         [ 0.0026, -0.5151,  0.1151],\n",
            "         [ 0.4904,  0.3612, -0.2868],\n",
            "         [-0.4946, -0.2338,  0.4015],\n",
            "         [ 0.3993,  0.3808, -0.0817],\n",
            "         [-0.4293, -0.2708,  0.3043]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-2.1565, -0.1593, -0.1133],\n",
            "         [ 2.2415, -0.0104, -0.0893],\n",
            "         [ 1.1924, -0.9845, -0.1438],\n",
            "         [-0.2551, -1.1780,  0.4220],\n",
            "         [ 0.4773, -0.2637, -0.0564],\n",
            "         [-0.3466, -0.6031,  0.3144]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-2.0854, -4.1840,  0.1265],\n",
            "         [ 2.4318,  1.3816, -0.3169],\n",
            "         [ 2.1827, -1.8550,  0.0501],\n",
            "         [ 0.0380, -1.8132,  0.4383],\n",
            "         [ 0.7775, -0.5734, -0.0652],\n",
            "         [-0.4610, -1.2167,  0.3246]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-2.5550e+00, -4.1848e+00,  1.1055e-01],\n",
            "         [ 2.5811e+00,  1.5519e+00, -4.1756e-01],\n",
            "         [ 2.3287e+00, -2.0701e+00,  1.6881e-01],\n",
            "         [ 3.5675e-01, -2.0081e+00,  4.5226e-01],\n",
            "         [ 1.5092e+00, -1.6105e+00,  3.2360e-03],\n",
            "         [-5.8268e-01, -1.4719e+00,  3.3477e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-2.7431, -4.1857,  0.0936],\n",
            "         [ 2.6917,  1.6875, -0.5375],\n",
            "         [ 2.4386, -2.2244,  0.2627],\n",
            "         [ 0.6411, -2.1433,  0.4645],\n",
            "         [ 1.7357, -1.8222,  0.0625],\n",
            "         [-1.0488, -1.6414,  0.3284]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-2.8723, -4.1865,  0.0767],\n",
            "         [ 2.7799,  1.7933, -0.6810],\n",
            "         [ 2.5251, -2.3305,  0.3397],\n",
            "         [ 2.0251, -2.2413,  0.5004],\n",
            "         [ 1.8863, -1.9659,  0.1168],\n",
            "         [-1.3051, -1.7581,  0.3212]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-2.9723, -4.1874,  0.0590],\n",
            "         [ 2.8539,  1.8786, -0.8576],\n",
            "         [ 2.5977, -2.4147,  0.4062],\n",
            "         [ 2.1617, -2.3185,  0.5341],\n",
            "         [ 1.9980, -2.0717,  0.1671],\n",
            "         [-1.4698, -1.8565,  0.3146]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-3.0538, -4.1881,  0.0414],\n",
            "         [ 2.9186,  1.9446, -1.0790],\n",
            "         [ 2.6607, -2.4859,  0.4647],\n",
            "         [ 2.2671, -2.3855,  0.5659],\n",
            "         [ 2.0888, -2.1601,  0.2115],\n",
            "         [-1.5939, -1.9365,  0.3076]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-3.1233, -4.1890,  0.0229],\n",
            "         [ 2.9747,  2.0096, -1.3625],\n",
            "         [ 2.7166, -2.5458,  0.5179],\n",
            "         [ 2.3521, -2.4461,  0.5952],\n",
            "         [ 2.1645, -2.2335,  0.2528],\n",
            "         [-1.6920, -2.0067,  0.3007]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-3.1837e+00, -4.1898e+00,  3.5522e-03],\n",
            "         [ 3.0254e+00,  2.0604e+00, -1.7035e+00],\n",
            "         [ 2.7664e+00, -2.6001e+00,  5.6517e-01],\n",
            "         [ 2.4245e+00, -2.4980e+00,  6.2336e-01],\n",
            "         [ 2.2299e+00, -2.2971e+00,  2.9097e-01],\n",
            "         [-1.7738e+00, -2.0684e+00,  2.9386e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-3.2392, -4.1908, -0.0198],\n",
            "         [ 3.0486,  2.0007, -0.7174],\n",
            "         [ 2.8118, -2.6494,  0.6088],\n",
            "         [ 2.4870, -2.5464,  0.6496],\n",
            "         [ 2.2872, -2.3521,  0.3279],\n",
            "         [-1.8466, -2.1172,  0.2856]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.87939453125\n",
            "0 act:  9 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2672, -0.2431, -0.1908],\n",
            "         [ 0.0134,  0.2570, -0.3079],\n",
            "         [-0.3024, -0.1426,  0.3712],\n",
            "         [-0.1474,  0.5173,  0.5057],\n",
            "         [ 0.2721, -0.3707,  0.4311],\n",
            "         [-0.4466, -0.2898, -0.3296]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 4.4399, -0.2297, -0.8530],\n",
            "         [ 2.2602,  1.3520, -0.6280],\n",
            "         [ 1.1854, -0.1642,  0.3655],\n",
            "         [ 0.0280, -0.2642,  0.5202],\n",
            "         [ 0.3336, -0.9839,  0.4404],\n",
            "         [-0.3921, -0.6324, -0.3026]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 4.4433,  0.6242, -1.2805],\n",
            "         [ 2.5135,  1.4850, -0.8508],\n",
            "         [ 2.2975,  0.5262,  0.3705],\n",
            "         [ 0.9050, -0.6571,  0.5166],\n",
            "         [ 0.1707, -1.6671,  0.4436],\n",
            "         [-0.5125, -1.2225, -0.2804]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 4.4475,  1.1211, -2.2778],\n",
            "         [ 2.6664,  1.5827, -1.1488],\n",
            "         [ 2.4333,  1.1036,  0.3742],\n",
            "         [ 1.9603, -1.7728,  0.5537],\n",
            "         [ 0.1933, -1.8553,  0.4544],\n",
            "         [-0.6097, -1.4679, -0.2534]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 4.4497,  0.1642, -1.0117],\n",
            "         [ 2.7878,  1.7687, -1.4529],\n",
            "         [ 2.5362,  1.1812,  0.3981],\n",
            "         [ 2.1266, -1.9556,  0.5881],\n",
            "         [ 0.2019, -1.9851,  0.4638],\n",
            "         [-1.1716, -1.6558, -0.2698]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 4.4531,  1.0679, -1.5155],\n",
            "         [ 2.8746,  1.8338, -1.8961],\n",
            "         [ 2.6204,  1.2451,  0.4211],\n",
            "         [ 2.2468, -2.0881,  0.6201],\n",
            "         [ 0.2082, -2.0868,  0.4731],\n",
            "         [-1.4273, -1.7856, -0.2876]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 4.4572,  1.3679, -2.6131],\n",
            "         [ 2.9137,  1.7719, -0.6612],\n",
            "         [ 2.6903,  1.3445,  0.4401],\n",
            "         [ 2.3370, -2.2000,  0.6478],\n",
            "         [ 0.2076, -2.1702,  0.4813],\n",
            "         [-1.5625, -1.8779, -0.3110]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 4.4594,  0.7322, -1.8117],\n",
            "         [ 2.9865,  1.9060, -0.8376],\n",
            "         [ 2.7526,  1.3964,  0.4614],\n",
            "         [ 2.4166, -2.2864,  0.6760],\n",
            "         [ 0.1956, -2.2406,  0.4889],\n",
            "         [-1.6915, -1.9633, -0.3303]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 4.4615, -1.0029,  0.2059],\n",
            "         [ 3.0501,  2.0080, -1.0591],\n",
            "         [ 2.8078,  1.4340,  0.4826],\n",
            "         [ 2.4850, -2.3549,  0.7031],\n",
            "         [ 0.1997, -2.3024,  0.4975],\n",
            "         [-1.7930, -2.0355, -0.3501]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000,  1.0000, -1.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 4.4639, -0.8095,  0.0859],\n",
            "         [ 3.1060,  2.0937, -1.3450],\n",
            "         [ 2.8567,  1.4852,  0.5013],\n",
            "         [ 2.5445, -2.4161,  0.7286],\n",
            "         [ 0.2042, -2.3571,  0.5060],\n",
            "         [-1.8767, -2.0991, -0.3704]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 4.4663, -0.5340, -0.0641],\n",
            "         [ 3.1554,  2.1673, -1.6966],\n",
            "         [ 2.9011,  1.5365,  0.5190],\n",
            "         [ 2.5969, -2.4723,  0.7523],\n",
            "         [ 0.2202, -2.4065,  0.5151],\n",
            "         [-1.9483, -2.1557, -0.3911]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.8740234375\n",
            "0 act:  14 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1989, -0.4163, -0.4253],\n",
            "         [ 0.2316,  0.4149, -0.2282],\n",
            "         [-0.2285, -0.3332,  0.1689],\n",
            "         [-0.1067,  0.4942,  0.4321],\n",
            "         [-0.1374, -0.4727,  0.1005],\n",
            "         [-0.2497,  0.0785, -0.0405]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 2.5599, -1.5563, -0.4072],\n",
            "         [ 1.6081, -0.5300, -0.2517],\n",
            "         [ 0.4449, -1.0220,  0.1524],\n",
            "         [ 0.7157,  0.2763,  0.4265],\n",
            "         [ 0.0823, -0.9652,  0.1139],\n",
            "         [-0.1372, -0.2719, -0.0309]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 2.7227, -2.1553, -0.2869],\n",
            "         [ 2.3336, -0.8973, -0.0287],\n",
            "         [ 0.2193, -2.3944,  0.1749],\n",
            "         [ 2.1425,  0.0935,  0.4569],\n",
            "         [-0.1560, -1.6441,  0.1407],\n",
            "         [ 0.1871, -0.3986, -0.0385]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 2.8384, -2.3502, -0.1898],\n",
            "         [ 2.5201, -2.1314,  0.0858],\n",
            "         [-0.2111, -2.4983,  0.2256],\n",
            "         [ 2.2661, -0.1166,  0.4866],\n",
            "         [-0.4443, -1.8597,  0.1604],\n",
            "         [ 0.5201, -0.5170, -0.0460]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 2.9324, -2.4778, -0.1049],\n",
            "         [ 2.6497, -2.2733,  0.1788],\n",
            "         [-0.6560, -2.5828,  0.2658],\n",
            "         [ 2.3628, -0.3258,  0.5144],\n",
            "         [-0.6848, -2.0027,  0.1806],\n",
            "         [ 0.8339, -0.6313, -0.0529]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.0095, -2.5765, -0.0332],\n",
            "         [ 2.7490, -2.3705,  0.2554],\n",
            "         [-2.3121, -2.6582,  0.2378],\n",
            "         [ 2.4472, -0.4116,  0.5445],\n",
            "         [-1.4492, -2.1046,  0.1594],\n",
            "         [ 1.1869, -1.1742, -0.0189]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.0746, -2.6612,  0.0278],\n",
            "         [ 2.8304, -2.4540,  0.3211],\n",
            "         [-2.4083, -2.7235,  0.2079],\n",
            "         [ 2.5169, -0.5252,  0.5711],\n",
            "         [-1.6846, -2.1872,  0.1370],\n",
            "         [ 1.3939, -1.4267,  0.0130]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.1329, -2.7304,  0.0842],\n",
            "         [ 2.8999, -2.5274,  0.3791],\n",
            "         [-2.4892, -2.7799,  0.1748],\n",
            "         [ 2.5755, -0.6565,  0.5943],\n",
            "         [-1.8370, -2.2588,  0.1141],\n",
            "         [ 1.5400, -1.5914,  0.0429]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.1847, -2.7908,  0.1346],\n",
            "         [ 2.9602, -2.5884,  0.4312],\n",
            "         [-2.5557, -2.8291,  0.1403],\n",
            "         [ 2.6197, -2.1923,  0.6240],\n",
            "         [-1.9477, -2.3217,  0.0860],\n",
            "         [ 1.6499, -1.7108,  0.0715]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.2313, -2.8444,  0.1806],\n",
            "         [ 3.0142, -2.6419,  0.4790],\n",
            "         [-2.6149, -2.8730,  0.1020],\n",
            "         [ 2.6603, -2.3043,  0.6512],\n",
            "         [-2.0371, -2.3791,  0.0559],\n",
            "         [ 1.7424, -1.8091,  0.0983]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.2732, -2.8939,  0.2219],\n",
            "         [ 3.0623, -2.6898,  0.5221],\n",
            "         [-2.6669, -2.9141,  0.0626],\n",
            "         [ 2.6980, -2.3949,  0.6781],\n",
            "         [-2.1147, -2.4268,  0.0243],\n",
            "         [ 1.8195, -1.8901,  0.1238]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.89990234375\n",
            "0 act:  11 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3351, -0.3129, -0.4713],\n",
            "         [ 0.2570, -0.3459,  0.3760],\n",
            "         [-0.2246, -0.2708, -0.0340],\n",
            "         [-0.4197,  0.2620,  0.4340],\n",
            "         [ 0.2612,  0.4918, -0.4153],\n",
            "         [ 0.2232,  0.5137,  0.3316]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.3905, -1.3295, -1.2743],\n",
            "         [ 2.7202, -0.3411,  0.3205],\n",
            "         [ 0.9354, -0.7576, -0.0424],\n",
            "         [-0.3841, -0.7228,  0.4472],\n",
            "         [ 0.2919,  0.0261, -0.3719],\n",
            "         [ 0.3842,  0.2474,  0.3374]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-3.2025, -2.2518, -1.4566],\n",
            "         [ 2.8198,  1.1112,  0.3092],\n",
            "         [ 2.3996, -2.1803,  0.1120],\n",
            "         [-0.3541, -2.0512,  0.4640],\n",
            "         [ 0.7189, -0.3035, -0.3800],\n",
            "         [ 0.6744,  0.1443,  0.3347]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-3.2307, -2.4825, -0.0147],\n",
            "         [ 2.8828,  1.2108,  0.3286],\n",
            "         [ 2.5021, -2.3050,  0.2274],\n",
            "         [-0.3436, -2.1870,  0.4782],\n",
            "         [ 1.6725, -0.4612, -0.2906],\n",
            "         [ 1.2496,  0.0568,  0.3491]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-3.2581, -2.6305,  0.2236],\n",
            "         [ 2.9381,  1.3257,  0.3456],\n",
            "         [ 2.5859, -2.4051,  0.3200],\n",
            "         [-0.3447, -2.2911,  0.4910],\n",
            "         [ 1.8752, -0.6106, -0.2138],\n",
            "         [ 1.4908, -0.0613,  0.3623]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-3.2832, -2.7394,  0.3795],\n",
            "         [ 2.9879,  1.3864,  0.3644],\n",
            "         [ 2.6566, -2.4826,  0.3981],\n",
            "         [-0.3219, -2.3733,  0.5041],\n",
            "         [ 1.9908, -1.6117, -0.1212],\n",
            "         [ 1.6485, -0.1734,  0.3751]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-3.3077, -2.8284,  0.4933],\n",
            "         [ 3.0326,  1.4676,  0.3806],\n",
            "         [ 2.7176, -2.5506,  0.4642],\n",
            "         [-0.2821, -2.4432,  0.5180],\n",
            "         [ 2.0828, -1.8157, -0.0392],\n",
            "         [ 1.7675, -0.2780,  0.3879]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-3.3308, -2.9023,  0.5851],\n",
            "         [ 3.0737,  1.5176,  0.3980],\n",
            "         [ 2.7723, -2.6082,  0.5239],\n",
            "         [-0.2540, -2.5051,  0.5313],\n",
            "         [ 2.1609, -1.9633,  0.0250],\n",
            "         [ 1.8612, -0.3862,  0.3998]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-3.3533, -2.9667,  0.6608],\n",
            "         [ 3.1115,  1.5787,  0.4133],\n",
            "         [ 2.8210, -2.6616,  0.5762],\n",
            "         [-0.2345, -2.5590,  0.5432],\n",
            "         [ 2.2271, -2.0708,  0.0840],\n",
            "         [ 1.9437, -0.4649,  0.4132]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-3.3741, -3.0227,  0.7284],\n",
            "         [ 3.1467,  1.6290,  0.4287],\n",
            "         [ 2.8651, -2.7098,  0.6231],\n",
            "         [-0.2029, -2.6075,  0.5556],\n",
            "         [ 2.2853, -2.1574,  0.1385],\n",
            "         [ 2.0127, -0.5471,  0.4255]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-3.3946, -3.0732,  0.7860],\n",
            "         [ 3.1795,  1.6732,  0.4440],\n",
            "         [ 2.9058, -2.7539,  0.6665],\n",
            "         [-0.2120, -2.6513,  0.5654],\n",
            "         [ 2.3377, -2.2325,  0.1864],\n",
            "         [ 2.0717, -0.6326,  0.4367]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.919921875\n",
            "0 act:  9 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4263,  0.5039, -0.4963],\n",
            "         [-0.3803, -0.0823, -0.4218],\n",
            "         [-0.3061,  0.5252,  0.5269],\n",
            "         [-0.3972, -0.1936, -0.0675],\n",
            "         [ 0.0602, -0.5181,  0.1015],\n",
            "         [ 0.4783, -0.5217,  0.3039]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-0.6080, -0.2273, -1.3670],\n",
            "         [ 2.0021,  0.0159, -0.6545],\n",
            "         [ 0.1630, -0.6582,  0.5526],\n",
            "         [-0.3099, -1.2090, -0.0305],\n",
            "         [ 0.1012, -0.9689,  0.1192],\n",
            "         [ 0.5972, -0.7800,  0.3097]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-5.1817e+00, -3.8321e+00,  9.0111e-01],\n",
            "         [ 2.3524e+00,  1.0529e+00, -6.2033e-01],\n",
            "         [ 1.4448e-01, -2.7374e+00,  5.6271e-01],\n",
            "         [-3.2937e-01, -1.8377e+00,  2.0302e-03],\n",
            "         [-1.2928e-01, -1.6168e+00,  1.3827e-01],\n",
            "         [ 1.0638e+00, -1.2349e+00,  3.2672e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-5.1823, -3.8415,  0.9459],\n",
            "         [ 2.5118,  1.1402, -0.5214],\n",
            "         [ 0.0996, -2.7882,  0.5742],\n",
            "         [-0.3337, -2.0394,  0.0354],\n",
            "         [-0.3407, -1.8293,  0.1620],\n",
            "         [ 1.3216, -1.4677,  0.3431]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-5.1828, -3.8508,  0.9859],\n",
            "         [ 2.6284,  1.2110, -0.4335],\n",
            "         [ 0.0589, -2.8341,  0.5854],\n",
            "         [-0.3433, -2.1763,  0.0664],\n",
            "         [-0.5299, -1.9704,  0.1838],\n",
            "         [ 1.4832, -1.6175,  0.3591]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-5.1833, -3.8599,  1.0234],\n",
            "         [ 2.7208,  1.2878, -0.3609],\n",
            "         [ 0.0156, -2.8762,  0.5964],\n",
            "         [-0.3523, -2.2817,  0.0954],\n",
            "         [-0.6974, -2.0796,  0.2034],\n",
            "         [ 1.6116, -1.7371,  0.3744]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-5.1838, -3.8689,  1.0579],\n",
            "         [ 2.7979,  1.3444, -0.2945],\n",
            "         [-0.0076, -2.9148,  0.6068],\n",
            "         [-0.3676, -2.3666,  0.1220],\n",
            "         [-1.5891, -2.1787,  0.1901],\n",
            "         [ 1.7207, -1.8402,  0.3922]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [ 0., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 1., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-5.1844, -3.8776,  1.0905],\n",
            "         [ 2.8638,  1.3962, -0.2344],\n",
            "         [-0.0725, -2.9502,  0.6177],\n",
            "         [-0.3624, -2.4389,  0.1507],\n",
            "         [-1.8049, -2.2622,  0.1767],\n",
            "         [ 1.8102, -1.9255,  0.4090]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-5.1849, -3.8862,  1.1216],\n",
            "         [ 2.9217,  1.4523, -0.1829],\n",
            "         [-0.1187, -2.9835,  0.6281],\n",
            "         [-0.3807, -2.5015,  0.1743],\n",
            "         [-1.9500, -2.3306,  0.1620],\n",
            "         [ 1.8858, -1.9979,  0.4252]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-5.1854, -3.8946,  1.1505],\n",
            "         [ 2.9730,  1.4891, -0.1329],\n",
            "         [-0.2156, -3.0142,  0.6391],\n",
            "         [-0.3693, -2.5572,  0.2014],\n",
            "         [-2.0596, -2.3920,  0.1475],\n",
            "         [ 1.9514, -2.0608,  0.4409]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-5.1859, -3.9029,  1.1779],\n",
            "         [ 3.0197,  1.5299, -0.0877],\n",
            "         [-0.2622, -3.0434,  0.6490],\n",
            "         [-0.3829, -2.6065,  0.2233],\n",
            "         [-2.1477, -2.4460,  0.1326],\n",
            "         [ 2.0088, -2.1163,  0.4565]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.93212890625\n",
            "0 act:  9 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.1789, -0.2470, -0.2225],\n",
            "         [ 0.1443,  0.0119, -0.1149],\n",
            "         [-0.5157, -0.0482, -0.3827],\n",
            "         [ 0.4215, -0.2155, -0.4685],\n",
            "         [-0.3169, -0.0928,  0.2659],\n",
            "         [-0.2070, -0.3138,  0.1341]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[-2.5299, -0.5458, -0.4898],\n",
            "         [-0.1071, -0.0495, -0.1840],\n",
            "         [-0.4913, -0.2769, -0.4409],\n",
            "         [ 0.5062, -0.4362, -0.5083],\n",
            "         [-0.1491, -0.3484,  0.2592],\n",
            "         [-0.0484, -0.4165,  0.1273]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[-2.6803, -0.5395, -0.7143],\n",
            "         [-0.3619, -0.1017, -0.2617],\n",
            "         [-0.4502, -0.4922, -0.4832],\n",
            "         [ 0.6412, -0.6847, -0.5451],\n",
            "         [ 0.0821, -0.5931,  0.2531],\n",
            "         [ 0.2201, -0.5357,  0.1211]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.],\n",
            "         [ 0.,  0.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[-2.7928, -0.5905, -1.0211],\n",
            "         [-0.7155, -0.0139, -0.3605],\n",
            "         [-0.4365, -0.6205, -0.5311],\n",
            "         [ 2.1247, -1.9866, -0.3737],\n",
            "         [-0.2344, -1.6867,  0.2597],\n",
            "         [ 0.5453, -0.6253,  0.1159]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[-2.8801, -3.7306, -1.7456],\n",
            "         [-3.9407, -1.1850, -0.5671],\n",
            "         [-1.5453, -2.6691, -0.6498],\n",
            "         [ 2.2293, -2.1525, -0.2506],\n",
            "         [-0.5282, -1.8813,  0.2684],\n",
            "         [ 0.4130, -1.2267,  0.1246]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[-2.9588, -3.7386, -2.9462],\n",
            "         [-3.9472, -2.1675, -0.8764],\n",
            "         [-2.0118, -2.7187, -0.8992],\n",
            "         [ 2.3372, -2.2495, -0.2069],\n",
            "         [-0.8027, -2.0134,  0.2727],\n",
            "         [ 0.2642, -1.4743,  0.1273]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[-3.0261, -3.7465, -3.2172],\n",
            "         [-3.9537, -2.3334, -1.3462],\n",
            "         [-2.2062, -2.7633, -1.2440],\n",
            "         [ 2.4263, -2.3312, -0.1657],\n",
            "         [-1.5105, -2.1013,  0.2511],\n",
            "         [ 0.0753, -1.6303,  0.1298]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[-3.0851, -3.7544, -3.3824],\n",
            "         [-3.9600, -2.4515, -2.0396],\n",
            "         [-2.3387, -2.8043, -1.7139],\n",
            "         [ 2.4996, -2.3997, -0.1288],\n",
            "         [-1.7264, -2.1831,  0.2286],\n",
            "         [-0.1154, -1.7512,  0.1366]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[-3.1376, -3.7620, -3.5069],\n",
            "         [-3.9665, -2.5451, -2.8063],\n",
            "         [-2.4507, -2.8395, -2.2616],\n",
            "         [ 2.5606, -2.4582, -0.0887],\n",
            "         [-1.8681, -2.2512,  0.2069],\n",
            "         [-0.3099, -1.8459,  0.1410]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[-3.1846, -3.7695, -3.6026],\n",
            "         [-3.9729, -2.6280, -3.0629],\n",
            "         [-2.5412, -2.8725, -2.6198],\n",
            "         [ 2.6147, -2.5119, -0.0515],\n",
            "         [-1.9732, -2.3137,  0.1845],\n",
            "         [-0.4800, -1.9270,  0.1490]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[-3.2275, -3.7770, -3.6823],\n",
            "         [-3.9793, -2.6984, -3.2275],\n",
            "         [-2.6174, -2.9034, -2.8403],\n",
            "         [ 2.6650, -2.5624, -0.0150],\n",
            "         [-2.0645, -2.3614,  0.1608],\n",
            "         [-0.6373, -1.9949,  0.1535]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[-1., -1., -1.],\n",
            "         [-1., -1., -1.],\n",
            "         [-1., -1., -1.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [-1., -1.,  0.],\n",
            "         [ 0., -1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search 0.91357421875\n",
            "0 act:  0 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4158, -0.0921,  0.2176],\n",
            "         [-0.0828, -0.0034,  0.3532],\n",
            "         [-0.2171, -0.4224, -0.2673],\n",
            "         [ 0.1380,  0.4490,  0.2194],\n",
            "         [-0.3262,  0.2599, -0.1643],\n",
            "         [ 0.1484, -0.2576,  0.5268]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 3.1396, -2.2153,  0.1852],\n",
            "         [ 0.9645, -1.0210,  0.3382],\n",
            "         [ 1.0808, -0.7638, -0.2592],\n",
            "         [ 0.5791, -0.2805,  0.2391],\n",
            "         [-0.1305, -0.3060, -0.1432],\n",
            "         [ 0.2893, -0.5983,  0.5302]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 3.1786, -2.2798,  0.1734],\n",
            "         [ 2.6868, -2.7258,  0.4394],\n",
            "         [ 2.1111, -2.7155, -0.0411],\n",
            "         [ 2.3456, -0.4089,  0.2892],\n",
            "         [ 0.4631, -0.5275, -0.1601],\n",
            "         [ 0.1276, -1.2117,  0.5327]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 3.2148, -2.3411,  0.1610],\n",
            "         [ 2.7588, -2.7985,  0.5214],\n",
            "         [ 2.2713, -2.7741,  0.1057],\n",
            "         [ 2.4305, -0.5652,  0.3312],\n",
            "         [ 0.8687, -0.6968, -0.1783],\n",
            "         [-0.0423, -1.4744,  0.5384]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 3.2485, -2.3893,  0.1498],\n",
            "         [ 2.8211, -2.8620,  0.5901],\n",
            "         [ 2.3845, -2.8243,  0.2108],\n",
            "         [ 2.4888, -2.2448,  0.3801],\n",
            "         [ 1.4728, -1.6158, -0.1078],\n",
            "         [-0.2123, -1.6370,  0.5417]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 3.2801, -2.4387,  0.1376],\n",
            "         [ 2.8761, -2.9185,  0.6479],\n",
            "         [ 2.4749, -2.8695,  0.2997],\n",
            "         [ 2.5410, -2.3454,  0.4252],\n",
            "         [ 1.7017, -1.8310, -0.0459],\n",
            "         [-0.3746, -1.7569,  0.5440]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 3.3098, -2.4824,  0.1253],\n",
            "         [ 2.9255, -2.9690,  0.7006],\n",
            "         [ 2.5508, -2.9111,  0.3728],\n",
            "         [ 2.5878, -2.4274,  0.4658],\n",
            "         [ 1.8492, -1.9713,  0.0098],\n",
            "         [-0.5220, -1.8535,  0.5474]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 3.3376, -2.5175,  0.1131],\n",
            "         [ 2.9700, -3.0133,  0.7506],\n",
            "         [ 2.6160, -2.9493,  0.4365],\n",
            "         [ 2.6302, -2.4968,  0.5030],\n",
            "         [ 1.9585, -2.0760,  0.0602],\n",
            "         [-0.6523, -1.9348,  0.5521]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 0.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 3.3640, -2.5514,  0.1009],\n",
            "         [ 3.0109, -3.0546,  0.7942],\n",
            "         [ 2.6736, -2.9848,  0.4936],\n",
            "         [ 2.6696, -2.5582,  0.5379],\n",
            "         [ 2.0510, -2.1662,  0.1051],\n",
            "         [-1.0993, -1.9992,  0.5450]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 3.3890, -2.5840,  0.0877],\n",
            "         [ 3.0486, -3.0923,  0.8355],\n",
            "         [ 2.7251, -3.0181,  0.5439],\n",
            "         [ 2.7060, -2.6124,  0.5697],\n",
            "         [ 2.1271, -2.2404,  0.1469],\n",
            "         [-1.3359, -2.0572,  0.5378]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 3.4129, -2.6214,  0.0728],\n",
            "         [ 3.0838, -3.1284,  0.8716],\n",
            "         [ 2.7715, -3.0491,  0.5898],\n",
            "         [ 2.7398, -2.6610,  0.5998],\n",
            "         [ 2.1925, -2.3044,  0.1856],\n",
            "         [-1.4952, -2.1091,  0.5306]]], device='cuda:0', requires_grad=True)\n",
            "tensor([[[ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [ 1.0000, -1.0000,  0.0000],\n",
            "         [-1.0000, -1.0000,  0.0000]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n",
            "search 0.93212890625\n",
            "0 act:  11 reward:  0.0\n",
            "ded\n",
            "time\n",
            "0 #### train ####\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-776fa543b0ee>:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(): # automatic mixed percision\n",
            "<ipython-input-11-a5e320619cc7>:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -477.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4898, -0.4642, -0.2972],\n",
            "         [-0.0943, -0.2354,  0.1163],\n",
            "         [ 0.3443,  0.1897, -0.5026],\n",
            "         [-0.3768,  0.3398,  0.3708],\n",
            "         [ 0.5117, -0.3061,  0.4075],\n",
            "         [-0.1690, -0.2720, -0.4580]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[510020.3438, 535424.9375, 154739.7031],\n",
            "         [ 28815.6074,   4778.7617,   3383.1699],\n",
            "         [200516.6562, 193830.9531, 114956.3906],\n",
            "         [ 17748.0039,   5945.3755,   1211.7136],\n",
            "         [ 95379.3594, 126250.7266,   9682.0879],\n",
            "         [  3773.9004,   3778.8345,    972.8732]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -497.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1672, -0.1983, -0.4752],\n",
            "         [ 0.4214, -0.2018, -0.3872],\n",
            "         [-0.2190,  0.0081,  0.3970],\n",
            "         [-0.3744, -0.1426, -0.2118],\n",
            "         [-0.3637, -0.0412,  0.2826],\n",
            "         [-0.2040,  0.0098,  0.1602]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[6.2850e+05, 6.0826e+05, 2.1090e+05],\n",
            "         [2.4563e+04, 4.9373e+03, 8.2880e+03],\n",
            "         [2.1522e+05, 2.0119e+05, 2.2999e+04],\n",
            "         [1.6775e+04, 8.0495e+03, 3.4943e+03],\n",
            "         [1.0759e+05, 1.3869e+05, 1.2243e+04],\n",
            "         [3.7255e+03, 4.0654e+03, 3.2725e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -503.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1405, -0.0703, -0.2505],\n",
            "         [ 0.5116,  0.1953, -0.4888],\n",
            "         [ 0.3725,  0.0038,  0.4134],\n",
            "         [ 0.1473, -0.5154, -0.1306],\n",
            "         [-0.0241, -0.4435,  0.3598],\n",
            "         [-0.0580,  0.0624, -0.4448]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[581293.0000, 626577.7500, 139107.3750],\n",
            "         [ 21268.1289,   1999.7083,   9847.6494],\n",
            "         [209475.7969, 216342.7969,  22227.7559],\n",
            "         [ 19428.5781,   4722.1953,   3061.4656],\n",
            "         [124100.7344, 110433.2891,  10372.9209],\n",
            "         [  3906.2222,   4183.6699,    966.0827]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -487.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3079, -0.0309,  0.2795],\n",
            "         [-0.3668, -0.1990,  0.1488],\n",
            "         [-0.1468, -0.4135, -0.0078],\n",
            "         [-0.3803, -0.5011, -0.1964],\n",
            "         [ 0.3955, -0.0245, -0.3594],\n",
            "         [-0.3216,  0.2556,  0.4876]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.3888e+05, 6.6682e+05, 5.1001e+04],\n",
            "         [2.6513e+04, 5.6791e+03, 3.6386e+03],\n",
            "         [2.3115e+05, 1.7090e+05, 4.7024e+04],\n",
            "         [1.6483e+04, 3.5541e+03, 3.5203e+03],\n",
            "         [1.0668e+05, 1.3338e+05, 3.8304e+04],\n",
            "         [3.5401e+03, 3.9373e+03, 1.7813e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -478.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.5000,  0.3869, -0.1619],\n",
            "         [-0.3792, -0.4821, -0.4579],\n",
            "         [-0.0860, -0.4312, -0.0241],\n",
            "         [ 0.4565,  0.0078,  0.0461],\n",
            "         [ 0.1255,  0.5210, -0.1655],\n",
            "         [ 0.0298, -0.3231,  0.0269]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[4.2378e+05, 6.0803e+05, 1.1156e+05],\n",
            "         [2.6025e+04, 4.6864e+03, 1.0491e+04],\n",
            "         [2.3195e+05, 1.6682e+05, 4.7939e+04],\n",
            "         [1.5424e+04, 4.1997e+03, 2.2736e+03],\n",
            "         [1.2231e+05, 1.0290e+05, 2.7438e+04],\n",
            "         [3.9160e+03, 3.7899e+03, 4.2511e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -470.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.0082, -0.1009,  0.1897],\n",
            "         [-0.1644,  0.1422,  0.4999],\n",
            "         [ 0.0067, -0.0918,  0.5330],\n",
            "         [ 0.2531,  0.2722, -0.4601],\n",
            "         [ 0.1362,  0.1912, -0.3204],\n",
            "         [-0.0250,  0.1900,  0.4878]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[6.3183e+05, 6.2146e+05, 5.9484e+04],\n",
            "         [2.8319e+04, 4.9577e+03, 1.6295e+03],\n",
            "         [2.2508e+05, 1.9921e+05, 1.7642e+04],\n",
            "         [1.9119e+04, 6.1887e+03, 5.3901e+03],\n",
            "         [1.2037e+05, 1.3352e+05, 3.6742e+04],\n",
            "         [3.8804e+03, 3.9226e+03, 1.7556e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -502.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2280, -0.4973, -0.2302],\n",
            "         [ 0.4028,  0.3163,  0.0597],\n",
            "         [ 0.0104, -0.3592, -0.4137],\n",
            "         [-0.0919,  0.2742, -0.3752],\n",
            "         [ 0.0323,  0.2132,  0.0299],\n",
            "         [-0.4897, -0.1003, -0.2967]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[578790.1875, 489812.4375, 127962.7344],\n",
            "         [ 24923.5840,   4650.8291,   3766.3062],\n",
            "         [225375.0312, 177182.0469,  99799.4219],\n",
            "         [ 20179.7051,   6082.5562,   4684.1216],\n",
            "         [122327.7188, 132795.7031,  19658.5898],\n",
            "         [  3082.1030,   4025.0464,    744.8622]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -501.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1212,  0.2499, -0.4113],\n",
            "         [ 0.5174,  0.3040,  0.2020],\n",
            "         [-0.2609,  0.2236, -0.3075],\n",
            "         [-0.3291,  0.1356, -0.0094],\n",
            "         [-0.4678,  0.2120, -0.5062],\n",
            "         [ 0.2435, -0.5087, -0.3711]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[578379.4375, 589006.8750, 169851.8438],\n",
            "         [ 24367.3691,   7892.1021,   3232.1333],\n",
            "         [215254.5156, 196519.8438,  84917.3906],\n",
            "         [ 18313.4277,   6240.6436,   2486.7273],\n",
            "         [102227.2891, 130849.2891,  49674.5664],\n",
            "         [  3689.2136,   3272.0820,    854.8066]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -489.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.0752, -0.3750,  0.2782],\n",
            "         [ 0.3950,  0.1113, -0.5015],\n",
            "         [ 0.2015,  0.0960, -0.1991],\n",
            "         [ 0.3558, -0.2924, -0.4060],\n",
            "         [ 0.4920,  0.3657,  0.0797],\n",
            "         [ 0.2611,  0.3291, -0.3769]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[628932.7500, 559433.6875,  49923.9375],\n",
            "         [ 27048.6016,   8518.3496,  11144.9375],\n",
            "         [221286.1094, 204776.5000,  70449.2422],\n",
            "         [ 17995.3145,   5850.7021,   4966.2646],\n",
            "         [100045.9375, 120036.7188,  17972.1230],\n",
            "         [  3659.6558,   3771.7935,    862.9762]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -491.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4231,  0.3257, -0.3701],\n",
            "         [-0.0675, -0.4322,  0.4588],\n",
            "         [ 0.1427, -0.1202, -0.2612],\n",
            "         [ 0.4752, -0.0536,  0.4263],\n",
            "         [-0.1696,  0.4987, -0.1768],\n",
            "         [ 0.2289,  0.2342, -0.1202]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.4203e+05, 5.9011e+05, 1.7435e+05],\n",
            "         [2.8999e+04, 4.2519e+03, 1.7656e+03],\n",
            "         [2.2072e+05, 1.9802e+05, 7.7156e+04],\n",
            "         [1.6400e+04, 6.6344e+03, 1.0885e+03],\n",
            "         [1.1915e+05, 1.0902e+05, 2.8664e+04],\n",
            "         [3.6866e+03, 3.8508e+03, 5.4723e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -500.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.2095, -0.2997, -0.0793],\n",
            "         [-0.0837, -0.0896, -0.1940],\n",
            "         [ 0.2189, -0.4241, -0.5308],\n",
            "         [ 0.2376, -0.2367, -0.0164],\n",
            "         [ 0.0442, -0.2400, -0.3141],\n",
            "         [ 0.3506,  0.4094,  0.0106]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[6.0342e+05, 5.9662e+05, 1.0622e+05],\n",
            "         [2.8870e+04, 5.0034e+03, 5.9423e+03],\n",
            "         [2.1479e+05, 1.6869e+05, 1.2012e+05],\n",
            "         [1.9281e+04, 6.2986e+03, 2.5058e+03],\n",
            "         [1.2237e+05, 1.3078e+05, 3.6357e+04],\n",
            "         [3.4425e+03, 3.4543e+03, 4.3179e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -494.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.1081, -0.5265,  0.2362],\n",
            "         [ 0.0683, -0.2298,  0.1811],\n",
            "         [-0.3470,  0.3176, -0.3309],\n",
            "         [ 0.0778,  0.5076, -0.0501],\n",
            "         [ 0.0594, -0.4043,  0.3058],\n",
            "         [-0.4583, -0.3509,  0.1238]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.8350e+05, 4.9615e+05, 5.6800e+04],\n",
            "         [3.2142e+04, 4.5779e+03, 3.1068e+03],\n",
            "         [2.0723e+05, 1.9082e+05, 8.7933e+04],\n",
            "         [2.0151e+04, 5.0478e+03, 2.6606e+03],\n",
            "         [1.2374e+05, 1.1395e+05, 1.1501e+04],\n",
            "         [3.1987e+03, 3.7243e+03, 3.5532e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -482.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.1806,  0.0044, -0.3502],\n",
            "         [ 0.1101,  0.3202, -0.2640],\n",
            "         [ 0.3912,  0.0173, -0.1109],\n",
            "         [-0.4523,  0.3749,  0.1596],\n",
            "         [-0.4559,  0.0127,  0.0103],\n",
            "         [-0.4565,  0.4151,  0.2103]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[6.6369e+05, 6.5059e+05, 1.5837e+05],\n",
            "         [2.8954e+04, 4.6089e+03, 6.6819e+03],\n",
            "         [1.9387e+05, 2.0083e+05, 5.9241e+04],\n",
            "         [1.6728e+04, 5.8082e+03, 1.8090e+03],\n",
            "         [1.0028e+05, 1.3843e+05, 2.0465e+04],\n",
            "         [3.1738e+03, 3.4388e+03, 2.9789e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -501.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2634, -0.2052, -0.0636],\n",
            "         [ 0.0662,  0.0903, -0.5066],\n",
            "         [-0.5273,  0.5082, -0.4744],\n",
            "         [-0.4953, -0.2158,  0.4435],\n",
            "         [ 0.2370,  0.0958, -0.5041],\n",
            "         [ 0.3952,  0.3404,  0.4452]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[6.0980e+05, 6.2335e+05, 9.7748e+04],\n",
            "         [2.9004e+04, 5.0755e+03, 1.0022e+04],\n",
            "         [1.7262e+05, 1.5680e+05, 1.0996e+05],\n",
            "         [1.6105e+04, 6.3574e+03, 1.0531e+03],\n",
            "         [1.1598e+05, 1.3719e+05, 4.9630e+04],\n",
            "         [3.3348e+03, 3.6292e+03, 1.9051e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -502.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4791, -0.1665, -0.3859],\n",
            "         [ 0.5014, -0.0927, -0.4933],\n",
            "         [-0.3850, -0.1944,  0.3963],\n",
            "         [-0.2580,  0.1503,  0.3194],\n",
            "         [ 0.0256, -0.4155,  0.1000],\n",
            "         [ 0.2217, -0.4173,  0.0884]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.2346e+05, 6.0009e+05, 1.7104e+05],\n",
            "         [2.2834e+04, 5.0103e+03, 9.8075e+03],\n",
            "         [1.9490e+05, 1.9349e+05, 2.2982e+04],\n",
            "         [1.9072e+04, 6.5008e+03, 1.3360e+03],\n",
            "         [1.2253e+05, 1.1705e+05, 1.7341e+04],\n",
            "         [3.6983e+03, 3.4320e+03, 3.7412e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -498.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1365,  0.2894, -0.0940],\n",
            "         [ 0.2069, -0.2391,  0.0493],\n",
            "         [ 0.0243, -0.1726,  0.3845],\n",
            "         [ 0.2777, -0.1320, -0.2191],\n",
            "         [-0.1553,  0.0596, -0.1717],\n",
            "         [-0.1242,  0.1708, -0.2597]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[570596.1250, 565384.1875, 102901.5078],\n",
            "         [ 27807.1777,   4779.5903,   3819.2322],\n",
            "         [224330.0312, 194420.0156,  23434.7559],\n",
            "         [ 18858.6113,   6232.0249,   3616.3096],\n",
            "         [123207.6875, 136253.9531,  28340.6152],\n",
            "         [  3861.8428,   4084.6477,    709.7000]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -494.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.2715,  0.3722,  0.0222],\n",
            "         [ 0.4751, -0.3075,  0.0508],\n",
            "         [-0.3474, -0.0381, -0.2876],\n",
            "         [ 0.2493, -0.0113, -0.2316],\n",
            "         [ 0.4499,  0.0580,  0.0672],\n",
            "         [-0.0193, -0.0042,  0.1379]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.4947e+05, 5.6001e+05, 8.7762e+04],\n",
            "         [2.3276e+04, 4.5638e+03, 3.8034e+03],\n",
            "         [1.9928e+05, 1.9982e+05, 8.0394e+04],\n",
            "         [1.9045e+04, 6.3454e+03, 3.6816e+03],\n",
            "         [1.0304e+05, 1.3535e+05, 1.8260e+04],\n",
            "         [3.8814e+03, 4.0657e+03, 3.4118e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -495.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4941,  0.4986, -0.4321],\n",
            "         [-0.5268,  0.1741, -0.2043],\n",
            "         [ 0.3733, -0.4094,  0.2954],\n",
            "         [ 0.0740,  0.2307, -0.1012],\n",
            "         [-0.1893,  0.1618, -0.4798],\n",
            "         [ 0.5083, -0.2889,  0.1224]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[4.1152e+05, 5.3395e+05, 1.7622e+05],\n",
            "         [2.2770e+04, 5.3817e+03, 6.8423e+03],\n",
            "         [2.0609e+05, 1.7224e+05, 2.6616e+04],\n",
            "         [1.8911e+04, 4.3036e+03, 2.9784e+03],\n",
            "         [1.1990e+05, 1.3003e+05, 4.6608e+04],\n",
            "         [3.0593e+03, 3.8677e+03, 3.5625e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -477.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.3833,  0.2194,  0.0279],\n",
            "         [ 0.2403,  0.2004, -0.1050],\n",
            "         [ 0.5178,  0.3780, -0.3152],\n",
            "         [ 0.4262, -0.4297, -0.3783],\n",
            "         [-0.2192,  0.3325,  0.2703],\n",
            "         [-0.3303, -0.0183,  0.0693]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[4.5655e+05, 5.9615e+05, 7.8392e+04],\n",
            "         [2.8323e+04, 5.6435e+03, 5.7539e+03],\n",
            "         [1.8121e+05, 1.7418e+05, 8.0296e+04],\n",
            "         [1.5735e+04, 3.4246e+03, 4.7781e+03],\n",
            "         [1.1846e+05, 1.1973e+05, 1.2289e+04],\n",
            "         [3.5207e+03, 4.1985e+03, 3.9311e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -473.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1364,  0.1180, -0.3130],\n",
            "         [-0.3448, -0.2622, -0.2969],\n",
            "         [ 0.1492,  0.0360, -0.0754],\n",
            "         [ 0.2358, -0.2913,  0.4796],\n",
            "         [ 0.3998, -0.1247, -0.2891],\n",
            "         [ 0.0906, -0.4928, -0.3630]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[493992.9062, 623765.6250, 152013.8438],\n",
            "         [ 22573.6777,   1122.5486,   6785.8599],\n",
            "         [227782.2344, 206400.0156,  52385.3398],\n",
            "         [ 17995.4512,   4176.5166,   1002.0073],\n",
            "         [106328.6641, 131406.9844,  34020.5156],\n",
            "         [  3885.0850,   3324.4036,    844.8173]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -479.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 4.0675e-01, -2.4809e-01,  1.0718e-04],\n",
            "         [-2.5698e-01, -3.6700e-01,  1.4724e-01],\n",
            "         [-1.6807e-01, -5.3366e-01, -2.8273e-01],\n",
            "         [ 2.4270e-02, -2.8706e-01, -3.4672e-01],\n",
            "         [ 5.1619e-01,  2.5742e-02,  2.3245e-01],\n",
            "         [-2.6039e-01,  7.1988e-02,  1.6554e-01]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[4.6850e+05, 5.7513e+05, 8.8253e+04],\n",
            "         [2.7800e+04, 4.8355e+03, 3.6111e+03],\n",
            "         [2.2962e+05, 1.5444e+05, 7.6437e+04],\n",
            "         [1.9003e+04, 4.1865e+03, 4.5654e+03],\n",
            "         [9.6246e+04, 1.3337e+05, 1.3204e+04],\n",
            "         [3.6650e+03, 4.1783e+03, 3.2866e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -480.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3652,  0.1583, -0.4901],\n",
            "         [-0.1481, -0.3245,  0.5259],\n",
            "         [-0.3604,  0.4787, -0.0878],\n",
            "         [ 0.0752, -0.1472,  0.0608],\n",
            "         [ 0.2022,  0.3195, -0.2398],\n",
            "         [ 0.1253,  0.1958,  0.0838]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[4.9180e+05, 5.8462e+05, 2.0748e+05],\n",
            "         [2.8291e+04, 4.3959e+03, 1.5393e+03],\n",
            "         [1.9491e+05, 1.6095e+05, 5.6177e+04],\n",
            "         [2.0236e+04, 6.2057e+03, 2.1842e+03],\n",
            "         [1.2126e+05, 1.2375e+05, 3.1946e+04],\n",
            "         [3.8466e+03, 4.0337e+03, 3.8135e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -493.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2669, -0.4750, -0.1120],\n",
            "         [ 0.4694,  0.4657,  0.1308],\n",
            "         [-0.2606, -0.5195, -0.3379],\n",
            "         [-0.4777, -0.4978, -0.0261],\n",
            "         [-0.4973,  0.1022,  0.2384],\n",
            "         [ 0.5163, -0.2350,  0.5110]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.0105e+05, 5.2035e+05, 1.0646e+05],\n",
            "         [2.4197e+04, 4.5814e+03, 3.7513e+03],\n",
            "         [2.2186e+05, 1.5730e+05, 8.4350e+04],\n",
            "         [1.5165e+04, 3.5035e+03, 2.5851e+03],\n",
            "         [9.7959e+04, 1.3208e+05, 1.3057e+04],\n",
            "         [3.0362e+03, 3.9760e+03, 1.7029e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -477.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2106,  0.2030, -0.1965],\n",
            "         [ 0.0284,  0.3889, -0.3641],\n",
            "         [-0.4771, -0.0722, -0.1133],\n",
            "         [ 0.2828, -0.2366,  0.3162],\n",
            "         [ 0.4547,  0.0178, -0.0524],\n",
            "         [-0.1806, -0.1748,  0.1760]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[ 5.0966e+05,  5.1274e+05,  1.2382e+05],\n",
            "         [ 2.5052e+04, -8.7116e+03,  7.7194e+03],\n",
            "         [ 1.9890e+05,  2.1910e+05,  5.9927e+04],\n",
            "         [ 1.8734e+04,  6.1190e+03,  1.3433e+03],\n",
            "         [ 1.0166e+05,  1.3357e+05,  2.2431e+04],\n",
            "         [ 3.7942e+03,  4.0740e+03,  3.2226e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -484.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.3286, -0.2181, -0.4182],\n",
            "         [ 0.3270,  0.0087, -0.1321],\n",
            "         [-0.4619, -0.0096,  0.2044],\n",
            "         [ 0.4794,  0.1214,  0.4039],\n",
            "         [-0.2012,  0.1309, -0.0083],\n",
            "         [ 0.1612,  0.4583,  0.0726]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.2221e+05, 5.4169e+05, 1.8065e+05],\n",
            "         [2.6173e+04, 5.0532e+03, 5.3259e+03],\n",
            "         [1.8329e+05, 2.0087e+05, 3.3128e+04],\n",
            "         [1.6338e+04, 6.5613e+03, 1.1365e+03],\n",
            "         [1.1786e+05, 1.3611e+05, 2.1187e+04],\n",
            "         [3.7838e+03, 3.3171e+03, 3.8526e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -495.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.1552, -0.3336, -0.3662],\n",
            "         [-0.3042,  0.1461,  0.5007],\n",
            "         [ 0.2585, -0.4541,  0.4848],\n",
            "         [ 0.0484, -0.4798,  0.2476],\n",
            "         [-0.4914,  0.1038,  0.4991],\n",
            "         [-0.1509,  0.0335, -0.3273]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[555926.9375, 574298.6250, 160551.2812],\n",
            "         [ 26182.6172,   4689.4448,   1612.3501],\n",
            "         [210106.3281, 163416.1719,  19256.9414],\n",
            "         [ 20303.1133,   5079.1348,   1539.2924],\n",
            "         [100097.6953, 135351.6562,   8098.7700],\n",
            "         [  3819.4580,   4183.0396,    792.9179]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -491.25\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.4445,  0.5015,  0.2279],\n",
            "         [ 0.0070,  0.1507, -0.3383],\n",
            "         [-0.2788,  0.0794, -0.1394],\n",
            "         [-0.1630,  0.5109,  0.1736],\n",
            "         [ 0.3435, -0.0189, -0.3555],\n",
            "         [-0.5280,  0.2044, -0.2796]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[486234.7188, 480320.8125,  61029.6484],\n",
            "         [ 29656.3535,   5388.8350,   8613.9492],\n",
            "         [218717.5312, 201493.4531,  59507.6445],\n",
            "         [ 18517.3379,   3531.9973,   1796.4602],\n",
            "         [110670.4688, 133412.3750,  38058.9727],\n",
            "         [  3001.2969,   4031.8164,    733.7831]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -477.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4080,  0.1420, -0.2344],\n",
            "         [-0.0967,  0.3102,  0.4296],\n",
            "         [ 0.2385,  0.3532, -0.5126],\n",
            "         [ 0.0033,  0.0266, -0.0559],\n",
            "         [-0.3214, -0.2700,  0.1701],\n",
            "         [ 0.0260,  0.1944,  0.0552]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.0655e+05, 5.6238e+05, 1.2898e+05],\n",
            "         [2.8802e+04, 4.5971e+03, 1.8665e+03],\n",
            "         [2.1290e+05, 1.7778e+05, 1.1677e+05],\n",
            "         [2.0390e+04, 6.6537e+03, 2.6907e+03],\n",
            "         [1.1077e+05, 1.2883e+05, 1.5218e+04],\n",
            "         [3.8802e+03, 3.9161e+03, 3.9783e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -495.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.1542,  0.1856,  0.1854],\n",
            "         [-0.0369, -0.4655,  0.3505],\n",
            "         [-0.4529, -0.4552,  0.0037],\n",
            "         [ 0.4999, -0.0716, -0.2628],\n",
            "         [-0.4101,  0.3000,  0.4637],\n",
            "         [-0.5189, -0.3616, -0.1207]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[5.6709e+05, 5.6655e+05, 6.9019e+04],\n",
            "         [2.8643e+04, 3.8831e+03, 2.1529e+03],\n",
            "         [1.8406e+05, 1.6325e+05, 4.7824e+04],\n",
            "         [1.6006e+04, 6.3040e+03, 3.9010e+03],\n",
            "         [1.0721e+05, 1.2521e+05, 8.6723e+03],\n",
            "         [3.0184e+03, 3.6862e+03, 5.5354e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -491.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4994,  0.0630, -0.4903],\n",
            "         [-0.1948,  0.4636, -0.4459],\n",
            "         [ 0.3551, -0.2527,  0.0092],\n",
            "         [-0.3860, -0.3687, -0.2304],\n",
            "         [-0.0306,  0.4786,  0.5216],\n",
            "         [-0.4185, -0.4529,  0.1149]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[4.3285e+05, 6.2781e+05, 2.1939e+05],\n",
            "         [2.9631e+04, 4.9663e+03, 9.4629e+03],\n",
            "         [2.0101e+05, 1.9050e+05, 4.7696e+04],\n",
            "         [1.7612e+04, 5.5729e+03, 3.6928e+03],\n",
            "         [1.2616e+05, 1.0971e+05, 7.7540e+03],\n",
            "         [3.2993e+03, 3.4395e+03, 3.6060e+02]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -492.0\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.2851, -0.4676,  0.2278],\n",
            "         [ 0.3946, -0.3538, -0.4677],\n",
            "         [ 0.2519,  0.4473, -0.4355],\n",
            "         [-0.0624, -0.0153,  0.0893],\n",
            "         [-0.1768, -0.0318, -0.4619],\n",
            "         [ 0.0703,  0.0150, -0.2907]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[507954.6875, 492653.9375,  56415.5234],\n",
            "         [ 24810.8184,   3406.3286,  10607.9492],\n",
            "         [221946.6094, 168602.9062,  98767.3281],\n",
            "         [ 18823.5391,   4442.7417,   2090.6860],\n",
            "         [120445.8438, 133325.0156,  45295.4922],\n",
            "         [  3900.1936,   4198.9722,    747.7911]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -481.5\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[-0.0169, -0.2221,  0.2117],\n",
            "         [ 0.0153,  0.3229, -0.0499],\n",
            "         [-0.1647,  0.3541, -0.5159],\n",
            "         [-0.3110, -0.2255,  0.4189],\n",
            "         [-0.4900,  0.0298,  0.1309],\n",
            "         [ 0.3678,  0.3521, -0.0627]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[427574.9062, 387659.7188,  55674.0000],\n",
            "         [ 37024.6016,  11605.8516,   5586.3203],\n",
            "         [236867.3281, 209835.9219, 100311.5859],\n",
            "         [ 16701.4023,   4241.1992,   1094.7209],\n",
            "         [ 98303.3125, 123048.3672,  15833.5098],\n",
            "         [  3433.9587,   3719.7942,    500.5744]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.],\n",
            "         [1., 1., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -416.75\n",
            "29 act:  17 reward:  0.0\n",
            "Parameter containing:\n",
            "tensor([[[ 0.0914, -0.2489,  0.4838],\n",
            "         [-0.3977, -0.0349,  0.1418],\n",
            "         [-0.2120,  0.1021, -0.3031],\n",
            "         [ 0.4963,  0.0044, -0.4903],\n",
            "         [ 0.2200, -0.2623,  0.4978],\n",
            "         [ 0.2803,  0.1131,  0.0092]]], device='cuda:0', requires_grad=True)\n",
            "0 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 Parameter containing:\n",
            "tensor([[[313466.0625, 292144.5625,  22904.6250],\n",
            "         [  3747.9807, -12560.0508,   2152.8364],\n",
            "         [233332.6719, 282077.1250,  70584.1172],\n",
            "         [ 14220.1836,   3468.1448,   5504.7173],\n",
            "         [118424.6250, 124683.5312,   7942.4253],\n",
            "         [  3627.2349,   4146.7012,    439.0998]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "tensor([[[ 1.,  1.,  0.],\n",
            "         [ 1., -1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.],\n",
            "         [ 1.,  1.,  0.]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "search -344.75\n",
            "29 act:  17 reward:  0.0\n",
            "ded\n",
            "time\n",
            "29 #### train ####\n",
            "repr, std, cov, closslb 0.007701843976974487 0.475830078125 0.00014883163385093212 9.835202945396304e-06 2.2533336959895678e-05\n",
            "0.005631372807430086 0.024771809635798604 1.0\n",
            "repr, std, cov, closslb 0.013954783789813519 0.47509765625 0.0001560740638524294 0.011141045019030571 6.229298014659435e-05\n",
            "0.005569797772201169 0.024378809529572488 1.0\n",
            "repr, std, cov, closslb 0.009103711694478989 0.475341796875 0.00016841641627252102 0.00033659025211818516 0.0001165793655673042\n",
            "0.00547048753134027 0.023658661462058077 1.0\n",
            "repr, std, cov, closslb 0.0184787567704916 0.475341796875 0.00016878172755241394 0.007118469104170799 0.00014079303946346045\n",
            "0.005421498415567548 0.023236824356953463 1.0\n",
            "repr, std, cov, closslb 0.02959836646914482 0.4736328125 0.0002223472110927105 0.004409129731357098 0.015229765325784683\n",
            "0.0053836992743443645 0.02250537717960831 1.0\n",
            "repr, std, cov, closslb 0.03192267566919327 0.475341796875 0.0001790954265743494 0.00010543895768932998 0.00030698132468387485\n",
            "0.005351509835572896 0.022104103287847423 1.0\n",
            "repr, std, cov, closslb 0.03151563182473183 0.474853515625 0.0002214664127677679 0.00011661197640933096 0.00017456858768127859\n",
            "0.0053675804249606295 0.021971941619239172 1.0\n",
            "repr, std, cov, closslb 0.03542603552341461 0.477294921875 0.00013600336387753487 0.004236323293298483 0.00011573050142033026\n",
            "0.0053675804249606295 0.022082021266580844 1.0\n",
            "repr, std, cov, closslb 0.018520381301641464 0.477294921875 0.00014612986706197262 0.00440275389701128 0.002169043757021427\n",
            "0.005416082333234314 0.022686051609483945 1.0\n",
            "repr, std, cov, closslb 0.03624032065272331 0.478759765625 0.00010433676652610302 0.004157158546149731 0.00012154387513874099\n",
            "0.005497894728604515 0.02309789008578309 1.0\n",
            "repr, std, cov, closslb 0.02494080923497677 0.479248046875 8.409633301198483e-05 5.668042285833508e-05 0.015546404756605625\n",
            "0.005569797772201169 0.023848594522817932 1.0\n",
            "repr, std, cov, closslb 0.06710885465145111 0.479736328125 7.702037692070007e-05 0.007728031370788813 4.079111386090517e-05\n",
            "0.005670910873206314 0.024281537592825208 1.0\n",
            "repr, std, cov, closslb 0.05936988443136215 0.479248046875 9.933067485690117e-05 0.0044350652024149895 3.50270165654365e-05\n",
            "0.00579698966766377 0.02507071175294392 1.0\n",
            "repr, std, cov, closslb 0.0898502767086029 0.47900390625 8.193426765501499e-05 0.008144517429172993 0.00012090884411009029\n",
            "0.005861076346858769 0.025347872616325047 1.0\n",
            "repr, std, cov, closslb 0.051523659378290176 0.479248046875 8.935504592955112e-05 3.43585415976122e-05 0.015269104391336441\n",
            "0.0058435282257533055 0.025756494563952875 1.0\n",
            "repr, std, cov, closslb 0.05663829296827316 0.47705078125 0.0001554577611386776 0.014621740207076073 0.012269859202206135\n",
            "0.005820212431466185 0.025859675184227795 1.0\n",
            "repr, std, cov, closslb 0.05094165727496147 0.47705078125 0.00015975465066730976 0.00376161839812994 0.00027528003556653857\n",
            "0.005727875854629292 0.025937331814665697 1.0\n",
            "repr, std, cov, closslb 0.04393661394715309 0.4775390625 0.00015492364764213562 0.01951211877167225 5.678605521097779e-05\n",
            "0.005722153700928365 0.026145558168781457 1.0\n",
            "repr, std, cov, closslb 0.041328586637973785 0.478271484375 0.00012069800868630409 0.0026067476719617844 0.015438307076692581\n",
            "0.005750821748220166 0.026807101257370416 1.0\n",
            "repr, std, cov, closslb 0.030430937185883522 0.478271484375 0.00011131260544061661 0.004484635312110186 0.00027171167312189937\n",
            "0.005779633422715724 0.02718484990586049 1.0\n",
            "repr, std, cov, closslb 0.018961237743496895 0.479248046875 8.930405601859093e-05 0.0048789968714118 0.0007660441333428025\n",
            "0.005733603730483921 0.027844844634336646 1.0\n",
            "repr, std, cov, closslb 0.019964629784226418 0.4775390625 0.00013521034270524979 0.003886497812345624 3.794902659137733e-05\n",
            "0.005693628564853691 0.028152673995370244 1.0\n",
            "repr, std, cov, closslb 0.017223818227648735 0.478515625 0.00010207644663751125 9.758275155036245e-06 0.007382568903267384\n",
            "0.005553121742056653 0.02835033490582124 1.0\n",
            "repr, std, cov, closslb 0.019293032586574554 0.477783203125 0.00012052664533257484 2.43695958488388e-05 0.000296414626063779\n",
            "0.005519919316884379 0.028692416297924416 1.0\n",
            "repr, std, cov, closslb 0.020911335945129395 0.477783203125 0.00010638637468218803 0.007890088483691216 0.0004274085513316095\n",
            "0.0053675804249606295 0.028577932984050015 1.0\n",
            "repr, std, cov, closslb 0.019591156393289566 0.474365234375 0.00023781275376677513 1.6831249013193883e-05 0.00010399257007520646\n",
            "0.005271875746506492 0.028265453720034535 1.0\n",
            "repr, std, cov, closslb 0.023824799805879593 0.474365234375 0.0002228135708719492 0.007937107235193253 1.6348274584743194e-05\n",
            "0.005121261107058567 0.027567921548435834 1.0\n",
            "repr, std, cov, closslb 0.018872100859880447 0.4736328125 0.0002133455127477646 2.6358991817687638e-05 0.0006023855530656874\n",
            "0.005029948335059569 0.02707638181198907 1.0\n",
            "repr, std, cov, closslb 0.02453695982694626 0.474365234375 0.00017523206770420074 0.012228813022375107 0.0031181522645056248\n",
            "0.004896022808048036 0.026302824224470167 1.0\n",
            "repr, std, cov, closslb 0.02188599854707718 0.47314453125 0.00019077188335359097 0.005145339295268059 0.00012496643466874957\n",
            "0.004823166674293869 0.025859675184227795 1.0\n",
            "repr, std, cov, closslb 0.025016888976097107 0.47412109375 0.0001998692750930786 0.012035882100462914 2.890190080506727e-05\n",
            "0.004727708820637915 0.02509578246469686 1.0\n",
            "repr, std, cov, closslb 0.02013067901134491 0.473388671875 0.0001927441917359829 0.0040346719324588776 4.7894212912069634e-05\n",
            "0.0047088451680546 0.024920812566565833 1.0\n",
            "repr, std, cov, closslb 0.018802043050527573 0.47509765625 0.00015755975618958473 2.2531632566824555e-05 0.0021319871302694082\n",
            "0.004690056781821708 0.02474706257322538 1.0\n",
            "repr, std, cov, closslb 0.02105497196316719 0.474365234375 0.00020077661611139774 4.672189970733598e-05 0.00010075588943436742\n",
            "0.0047088451680546 0.02472234023299239 1.0\n",
            "repr, std, cov, closslb 0.03065749816596508 0.4755859375 0.00014289305545389652 0.012027342803776264 4.227286990499124e-05\n",
            "0.0047656631321328895 0.024846199404906708 1.0\n",
            "repr, std, cov, closslb 0.019780796021223068 0.475830078125 0.00012594601139426231 3.471125819487497e-05 0.015552417375147343\n",
            "0.004784754397707629 0.024920812566565833 1.0\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "for i in range(30):\n",
        "    # # buffer=[]\n",
        "    # print(\"#### simulate ####\")\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n",
        "\n",
        "    # state = buffer[7][80][0]\n",
        "    # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "    # out= agent.deconv(sx_).squeeze(0)\n",
        "    # # print(out.shape)\n",
        "    # imshow(state.detach().cpu())\n",
        "    # imshow(out.detach().cpu())\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len)\n",
        "    train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "    c_loader = make_weighted(buffer)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    # train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    # agent.train_jepa(train_loader, optim)\n",
        "    agent.train_jepa(train_loader, c_loader, optim)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "b8zxYU9jpE8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "f28e138d-fc36-4c63-a28d-c477ec87bc16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*4 -2\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*3 -1.5\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "1a14d93a-4450-4db4-80c2-86289a6b4a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wandb/analytics/sentry.py:90: SentryHubDeprecationWarning: `sentry_sdk.Hub` is deprecated and will be removed in a future major release. Please consult our 1.x to 2.x migration guide for details on how to migrate `Hub` usage to the new API: https://docs.sentry.io/platforms/python/migration/1.x-to-2.x\n",
            "  self.hub = sentry_sdk.Hub(client)\n",
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240827_045813-4ao4qjt7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/4ao4qjt7' target=\"_blank\">serene-elevator-23</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/4ao4qjt7' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/4ao4qjt7</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(\n",
        "    project=\"procgen\",\n",
        "    config={\n",
        "        \"model\": \"res18\",\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.cuda.amp.autocast():\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.cuda.amp.autocast():\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjm2kV3H7ZVR",
        "outputId": "d4040132-28f1-4347-8028-2e951476da85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6872065\n"
          ]
        }
      ],
      "source": [
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad))\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko5qJO7Et09L",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "# !pip install -qq vector-quantize-pytorch\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK5u500Vad2P",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title FSQ jax\n",
        "# https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "Codeword = jax.Array\n",
        "Indices = jax.Array\n",
        "\n",
        "def round_ste(z):\n",
        "  \"\"\"Round with straight through gradients.\"\"\"\n",
        "  zhat = jnp.round(z)\n",
        "  return z + jax.lax.stop_gradient(zhat - z)\n",
        "\n",
        "class FSQ:\n",
        "  \"\"\"Quantizer.\"\"\"\n",
        "  def __init__(self, levels: list[int], eps: float = 1e-3):\n",
        "    self._levels = levels\n",
        "    self._eps = eps\n",
        "    self._levels_np = np.asarray(levels)\n",
        "    self._basis = np.concatenate(([1], np.cumprod(self._levels_np[:-1]))).astype(np.uint32)\n",
        "    self._implicit_codebook = self.indexes_to_codes(np.arange(self.codebook_size))\n",
        "    print(\"self._basis\",self._basis)\n",
        "    print(\"self._implicit_codebook\",self._implicit_codebook)\n",
        "\n",
        "  @property\n",
        "  def num_dimensions(self):\n",
        "    \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
        "    return len(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook_size(self):\n",
        "    \"\"\"Size of the codebook.\"\"\"\n",
        "    return np.prod(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook(self):\n",
        "    \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
        "    return self._implicit_codebook\n",
        "\n",
        "  def bound(self, z: jax.Array) -> jax.Array:\n",
        "    \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "    half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
        "    offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
        "    shift = jnp.tan(offset / half_l)\n",
        "    return jnp.tanh(z + shift) * half_l - offset\n",
        "\n",
        "  def quantize(self, z: jax.Array) -> Codeword:\n",
        "    \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
        "    quantized = round_ste(self.bound(z))\n",
        "\n",
        "    # Renormalize to [-1, 1].\n",
        "    half_width = self._levels_np // 2\n",
        "    return quantized / half_width\n",
        "\n",
        "  def _scale_and_shift(self, zhat_normalized):\n",
        "    # Scale and shift to range [0, ..., L-1]\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "  def _scale_and_shift_inverse(self, zhat):\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat - half_width) / half_width\n",
        "\n",
        "  def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
        "    \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
        "    assert zhat.shape[-1] == self.num_dimensions\n",
        "    zhat = self._scale_and_shift(zhat)\n",
        "    return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
        "\n",
        "  def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
        "    \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
        "    indices = indices[..., jnp.newaxis]\n",
        "    print(indices, self._basis, self._levels_np)\n",
        "    print(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    codes_non_centered = np.mod(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    return self._scale_and_shift_inverse(codes_non_centered)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title FSQ torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module): # https://colab.research.google.com/github/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "    def __init__(self, levels, eps = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cat([torch.ones(1, device=device), torch.cumprod(self.levels[:-1], dim=0)]).long()\n",
        "        self.num_dimensions = len(levels)\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        # self.mean = self.codebook.mean(dim=0)\n",
        "        # self.max = self.codebook.max(dim=0).values\n",
        "        # self.min = self.codebook.min(dim=0).values\n",
        "\n",
        "    def bound(self, z):\n",
        "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "        half_l = (self.levels - 1) * (1 - self.eps) / 2 # [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "        # half_l = (self.levels-1)/2 # me ?\n",
        "        offset = torch.where(self.levels % 2 == 1, 0.0, 0.5) # [0.0000, 0.0000, 0.5000] mean?\n",
        "        # print(\"half_l\", half_l)\n",
        "        # shift = torch.tan(offset / half_l) # [0.0000, 0.0000, 1.5608] < tan(1)\n",
        "\n",
        "        # print(\"shift\", shift)\n",
        "        # print(\"bound\", torch.tanh(z + shift) * half_l - offset)\n",
        "\n",
        "        # print(f'half_l {half_l}, shift {shift}, bound {torch.tanh(z + shift) * half_l - offset}')\n",
        "        # return torch.tanh(z + shift) * half_l - offset\n",
        "        # return torch.tanh(z - shift) * half_l + offset\n",
        "        return torch.tanh(z) * half_l + offset\n",
        "\n",
        "    def forward(self, z):\n",
        "        quantized = ste_round(self.bound(z))\n",
        "        # print(\"quantized\", quantized)\n",
        "        half_width = self.levels // 2 # Renormalize to [-1, 1]\n",
        "        return quantized / half_width\n",
        "\n",
        "    def _scale_and_shift(self, zhat_normalized): # Scale and shift to range [0, ..., L-1]\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "    def _scale_and_shift_inverse(self, zhat):\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat - half_width) / half_width\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        assert zhat.shape[-1] == self.num_dimensions\n",
        "        zhat = self._scale_and_shift(zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).long()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes_non_centered = torch.fmod(indices // self.basis, self.levels)\n",
        "        return self._scale_and_shift_inverse(codes_non_centered)\n",
        "\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "# print(fsq.codebook)\n",
        "\n",
        "# batch_size, seq_len = 1, 1\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xHxv7ptuwVHX"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test fsq\n",
        "fsq = FSQ(levels = [4])\n",
        "\n",
        "# 2: 1.6 half_l tensor([0.4995]), shift tensor([1.5608]), bound tensor([-0.5195])\n",
        "# 3: 0.6 # half_l tensor([0.9990]), shift tensor([0.]), bound tensor([-0.9207])\n",
        "# 4: 0.4, 1.3 # half_l tensor([1.4985]), shift tensor([0.3466]), bound tensor([-1.7726])\n",
        "# 5: 0.5, 1 # half_l [1.9980], shift [0.], bound [-1.8415]\n",
        "x = torch.tensor([.9],device=device)\n",
        "# x = torch.tensor([-1.6],device=device)\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.tensor([-0.6,0.6,-1.6],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,-1.5],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,1.6],device=device)\n",
        "x = torch.tensor([-0.5,0.6,-0.1],device=device)\n",
        "\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "round emb\n",
        "\n",
        "# half_l [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "# offset [0.0000, 0.0000, 0.5000] mean?\n",
        "# shift [0.0000, 0.0000, 1.5608] torch.tan(offset / half_l)\n",
        "# bound [-0.5365,  0.5365, -0.4696] tanh(z + shift) * half_l - offset\n",
        "\n",
        "\n",
        "\n",
        "levels = torch.tensor([3,3,2])\n",
        "eps = 1e-3\n",
        "\n",
        "half_l = (levels - 1) * (1 - eps) / 2\n",
        "offset = torch.where(levels % 2 == 1, 0.0, 0.5)\n",
        "# print(\"half_l\", half_l)\n",
        "shift = torch.tan(offset / half_l)\n",
        "# print(\"shift\", shift)\n",
        "# print(\"bound\", torch.tanh(x + shift) * half_l - offset)\n",
        "# return torch.tanh(x + shift) * half_l - offset\n",
        "out = torch.tanh(x) * half_l + offset\n",
        "print(out)\n",
        "\n",
        "shift=torch.tan(torch.tensor([1.]))\n",
        "print(shift)\n",
        "bound = torch.tanh(x - shift)\n",
        "print(bound)\n",
        "\n",
        "print(torch.tanh(torch.tensor([0.])))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "0SnfcKPses5X",
        "outputId": "7c50a3e3-281a-4375-b86f-ece58f6775c9"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "half_l tensor([0.9990, 0.9990, 0.4995]), shift tensor([0.0000, 0.0000, 1.5608]), bound tensor([-0.4617,  0.5365, -0.0515])\n",
            "quantized tensor([0., 1., 0.])\n",
            "tensor([0., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test rnn_pred symlog\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # xx = fsq(x)\n",
        "    # xx = fsq(x.clone())\n",
        "    # print(xx)\n",
        "    # x = torch.tanh(x)\n",
        "    # loss = x.sum()\n",
        "    # loss = model(xx)\n",
        "    loss = model(x)\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    # x = torch.clamp(x, min=-1, max=1)\n",
        "    # x = torch.clamp(x.clone(), min=-1, max=1)\n",
        "    with torch.no_grad():\n",
        "        x.clamp_(min=-1, max=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # model = nn.Sequential(nn.Linear(3,1))\n",
        "# model = nn.Sequential(nn.Linear(3*2,1))\n",
        "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# batch_size = 1\n",
        "# seq_len = 3\n",
        "# x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# # torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "\n",
        "# def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "#     batch, seq_len, dim_a = la.shape\n",
        "#     cost = 0\n",
        "#     lsx=sx\n",
        "#     for t in range(seq_len): # simple single layer\n",
        "#         a = la[:,t] # [1, dim_a]\n",
        "#         sxaz = torch.cat([sx, a], dim=-1)\n",
        "#         # with torch.cuda.amp.autocast():\n",
        "#         cost = cost + model(sxaz)\n",
        "#         lsx = torch.cat([lsx, sx], dim=0)\n",
        "#     return cost, sx\n",
        "\n",
        "\n",
        "# # def ste_clamp(input, min=-1, max=1):\n",
        "# #     clamped_output = torch.clamp(input, min, max)\n",
        "# #     clamp_mask = (input < min) | (input > max)\n",
        "# #     return torch.where(clamp_mask, input, clamped_output)\n",
        "\n",
        "# def ste_clamp(x, min=-1, max=1):\n",
        "#     return torch.clamp(x, min, max).detach() + x - x.detach()\n",
        "\n",
        "# def ste_abs(x): return x.sign() * x\n",
        "# def symlog(x): return torch.sign(x) * torch.log(ste_abs(x) + 1.0)\n",
        "# def symexp(x): return torch.sign(x) * torch.exp(ste_abs(x) - 1.0)\n",
        "\n",
        "\n",
        "# sx = torch.rand((batch_size,3),device=device)\n",
        "# sx_ = sx.detach()\n",
        "# for i in range(10): # num epochs\n",
        "#     # la = fsq(x.clone())\n",
        "#     la = fsq(x)\n",
        "#     print(i)\n",
        "#     print(x,x.requires_grad)\n",
        "#     print(la,la.requires_grad)\n",
        "#     loss, sx_ = rnn_pred(sx_, la)\n",
        "#     # loss.backward()\n",
        "#     loss.backward(retain_graph=True) # retain_graph bec fsq got tanh that creates new graph?\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     # x = torch.tanh(x)\n",
        "#     # x = torch.clamp(x, min=-1, max=1)\n",
        "#     # x = ste_clamp(x.clone(), min=-1, max=1)\n",
        "#     # x = symlog(x.clone())\n",
        "#     # sx_ = sx_.detach()\n",
        "\n",
        "\n",
        "# # print(xx)\n",
        "# print(x)\n",
        "# # print(xhat)\n",
        "# print(la)\n"
      ],
      "metadata": {
        "id": "7z_VgsenYLpM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test bptt\n",
        "\n",
        "x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    loss=0\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        # loss = loss -stcost(xxx.clone()).sum()\n",
        "        loss = loss -stcost(xxx).sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "# RuntimeError: Output 1 of SplitBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size, T = 1,6\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "# optim = torch.optim.SGD([x], lr=1e-3)\n",
        "# # xx = torch.split(x, bptt, dim=1)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    loss=0\n",
        "    # xx = torch.split(x, bptt, dim=1)\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        loss = loss -stcost(xxx.clone()).sum()\n",
        "        # loss = loss -stcost(xxx).sum()\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jepapred = nn.Sequential(nn.Linear(3*2,3))\n",
        "stcost = nn.Sequential(nn.Linear(3,1))\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    for t in range(seq_len): # simple single layer\n",
        "        # print(la.shape)\n",
        "        a = la[:,t,:].clone() # [1, dim_a]\n",
        "        # sxaz = torch.cat([sx, a], dim=-1)\n",
        "        sxaz = torch.cat([sx.clone(), a.clone()], dim=-1)\n",
        "        # sxaz = torch.cat([sx.clone(), a], dim=-1)\n",
        "        sx = jepapred(sxaz)\n",
        "        tcost = -stcost(sx).sum()\n",
        "        lsx = torch.cat([lsx, sx], dim=0)\n",
        "        # print(lsx.requires_grad, sx.requires_grad)\n",
        "        # icost = 0.5*icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(icost.requires_grad)\n",
        "        cost += tcost# + icost\n",
        "    return cost, sx#, z\n",
        "\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "sx = torch.rand((batch_size,3),device=device)\n",
        "T = 6\n",
        "bptt = 3\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device)) # FSQ 3 levels\n",
        "x = torch.empty((batch_size, T, 3),device=device) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "# optim = torch.optim.SGD([x], lr=1e-3) #, maximize=True)\n",
        "# print(x.shape)\n",
        "# print(len(xx))\n",
        "# print(xx[0].shape)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    sx_ = sx.detach()\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "\n",
        "        # xxx=x\n",
        "        # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        la = fsq(xxx)\n",
        "        # la = xxx\n",
        "        # print(x,x.requires_grad)\n",
        "        # print(la,la.requires_grad)\n",
        "        # loss, sx_ = rnn_pred(sx_, la)\n",
        "        loss = -stcost(la).sum()\n",
        "\n",
        "        print(\"loss\",loss)\n",
        "        loss.backward()\n",
        "        # loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # sx_ = sx_.detach()\n",
        "        # print(loss.item(), lact)\n",
        "\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    x = torch.tanh(x) # clamp\n",
        "    print(x)\n",
        "    # print(x)\n",
        "print(\"search\",loss.item())\n",
        "# print(lact)\n",
        "# return la, lact # [batch_size, T]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pGZld_gLH1RA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.cuda.amp.autocast(): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ],
      "metadata": {
        "id": "gJ3X_hQelW2x",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi4ODp-XlZoU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "QYbOgNoZn6JL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kcajtpjr7Io",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.cuda.amp.autocast(): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mhkK_9AQm8_q",
        "wUhKd009Qvk3"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}