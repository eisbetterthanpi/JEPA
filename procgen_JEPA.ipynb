{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WkwnVjJTrW1",
        "outputId": "83e80fbb-6417-4e38-a03a-7398ff0cf965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -qq procgen\n",
        "# !pip install -qq procgen faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEY9MmwZhA8a",
        "outputId": "8fbeac2c-826f-4610-925a-cc55deaa0801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1278976\n",
            "torch.Size([4, 256])\n",
            "1278979\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model=256, drop=0.5):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278976\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Dropout(p=drop),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278979\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "conv = Conv().to(device)\n",
        "print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = conv(input)\n",
        "print(out.shape)\n",
        "\n",
        "deconv = Deconv(256).to(device)\n",
        "print(sum(p.numel() for p in deconv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,256), device=device)\n",
        "out = deconv(input)\n",
        "print(out.shape)\n",
        "\n",
        "# print(conv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "Bos81kQf1dwh"
      },
      "outputs": [],
      "source": [
        "# @title transfer_sd store_sd load_sd\n",
        "\n",
        "def transfer_sd(tgt_sd, src_sd): #\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            # print(wht_name, tgt_wht.shape, src_wht.shape)\n",
        "            if tgt_wht.shape==src_wht.shape:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "                continue\n",
        "            if tgt_wht.shape[0] != src_wht.shape[0]: continue # output dim diff\n",
        "            if len(tgt_wht.shape)==2: tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "    return tgt_sd\n",
        "\n",
        "def store_sd(all_sd, new_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in new_sd.keys():\n",
        "            if not wht_name in all_sd.keys():\n",
        "                # print(wht_name, new_sd[wht_name].shape)\n",
        "                all_sd[wht_name] = (new_sd[wht_name],)\n",
        "                continue\n",
        "            all_tpl, new_wht = all_sd[wht_name], new_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                print(wht_name, all_wht.shape, new_wht.shape)\n",
        "                if all_wht.shape==new_wht.shape:\n",
        "                    all_wht = new_wht\n",
        "                    break\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: continue # diff output shape\n",
        "                if len(all_wht.shape)==2: all_wht[:, :new_wht.shape[1]] = new_wht[:, :all_wht.shape[1]]\n",
        "                break\n",
        "            if len(all_wht.shape)>=2 and len(all_wht.shape)>=2:\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: all_tpl = all_tpl + (new_wht,) # wht not in all_wht\n",
        "    return all_sd\n",
        "\n",
        "def load_sd(tgt_sd, all_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in all_sd.keys(): continue\n",
        "            tgt_wht, all_tpl = tgt_sd[wht_name], all_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                # try: print(wht_name, tgt_wht.shape, all_wht.shape)\n",
        "                # except: print(wht_name, tgt_wht, all_wht)\n",
        "                if tgt_wht.shape==all_wht.shape:\n",
        "                    tgt_wht.copy_(all_wht)\n",
        "                    break\n",
        "                if tgt_wht.shape[0] != all_wht.shape[0]: continue # output dim diff\n",
        "                if len(tgt_wht.shape)==2: tgt_wht[:, :all_wht.shape[1]].copy_(all_wht[:, :tgt_wht.shape[1]])\n",
        "                break\n",
        "    return tgt_sd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# modelsd = torch.load('agent.pkl', map_location=device).values()\n",
        "# tgt_sd = transfer_sd(agent.state_dict(), modelsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = {}\n",
        "# all_sd = store_sd(all_sd, agent1.state_dict())\n",
        "# print(all_sd.keys())\n",
        "# checkpoint = {'model': all_sd}\n",
        "# torch.save(checkpoint, 'all_sd.pkl')\n",
        "\n",
        "# agent3 = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "# agent3.tcost = tcost3\n",
        "# tgt_sd = load_sd(agent3.state_dict(), all_sd)\n",
        "# agent3.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "# for x,y in zip(agent1.state_dict().values(), agent3.state_dict().values()):\n",
        "#     print((x==y).all())\n",
        "\n",
        "# print(agent1.jepa.enc.cnn[1].num_batches_tracked)\n",
        "# jepa.enc.cnn.0.weight\n",
        "# print(agent1.jepa.enc.cnn[0].weight.shape)\n",
        "# print(agent1.jepa.enc.cnn[0].weight[0][0])\n",
        "# print(agent3.jepa.enc.cnn[0].weight[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "SFVbGqMDqcDR"
      },
      "outputs": [],
      "source": [
        "# @title rename_sd\n",
        "def rename_sd(agent_sd):\n",
        "    sd_={}\n",
        "    convert={}\n",
        "    na_=''\n",
        "    for wht_name, wht in agent_sd.items():\n",
        "        o=wht_name.split('.')\n",
        "        # print(\"####\", wht_name)\n",
        "        name=wht_name\n",
        "        for i in range(len(o)):\n",
        "            c = o[i]\n",
        "            if c.isnumeric():\n",
        "                na, me = '.'.join(o[:i]), '.'.join(o[i+1:])\n",
        "                c=int(c)\n",
        "                if na!=na_: # param name diff\n",
        "                    j=0 # reset num\n",
        "                    c_=c # track wht_name num\n",
        "                    na_=na # track param name\n",
        "                elif c_<c: # same param name, diff num\n",
        "                    j+=1\n",
        "                    c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "        # print(name)\n",
        "        sd_[name] = wht\n",
        "        convert[name] = wht_name\n",
        "    return sd_, convert\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# # modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, _ = rename_sd(modelsd)\n",
        "\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# agent.load_state_dict(modelsd, strict=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "riBHnAAkkzrd"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim me\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# def transfer_optim(tgt_sd, src_sd, tgt_optim, src_optim): #\n",
        "def transfer_optim(tgt_sd, src_sd, tgt_optim_sd, src_optim_sd): #\n",
        "    non_lst = ['running_mean', 'running_var', 'num_batches_tracked', 'num_batches_tracked', 'loss_fn']\n",
        "    tgt_lst, src_lst = [], []\n",
        "    for i, (k,v) in enumerate(tgt_sd.items()):\n",
        "        # print(i, k, v.shape, any(s in k for s in non_lst))\n",
        "        if not any(s in k for s in non_lst): tgt_lst.append(k)\n",
        "    for i, (k,v) in enumerate(src_sd.items()):\n",
        "        if not any(s in k for s in non_lst): src_lst.append(k)\n",
        "\n",
        "    # tgt_optim_st, src_optim_st = tgt_optim.state_dict()['state'], src_optim.state_dict()['state']\n",
        "    tgt_optim_st, src_optim_st = tgt_optim_sd['state'], src_optim_sd['state']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, wht_name in enumerate(tgt_lst):\n",
        "            if not wht_name in src_lst: continue\n",
        "            tgt_wht, src_wht = tgt_optim_st[tgt_lst.index(wht_name)], src_optim_st[src_lst.index(wht_name)]\n",
        "            # print(wht_name, tgt_wht, src_wht)\n",
        "            tgt_shp, src_shp = tgt_wht['exp_avg'].shape, src_wht['exp_avg'].shape\n",
        "            if tgt_shp==src_shp:\n",
        "                tgt_wht = src_wht\n",
        "                continue\n",
        "            if tgt_shp[0] != src_shp[0]: continue # output dim diff\n",
        "            if len(tgt_shp)==2:\n",
        "                tgt_wht['step'] = src_wht['step']\n",
        "                tgt_wht['exp_avg'][:, :src_shp[1]] = src_wht['exp_avg'][:, :tgt_shp[1]]\n",
        "                tgt_wht['exp_avg_sq'][:, :src_shp[1]] = src_wht['exp_avg_sq'][:, :tgt_shp[1]]\n",
        "    # return tgt_optim.state_dict()\n",
        "    return tgt_optim_sd\n",
        "\n",
        "# model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "# model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "# source_optimizer = optim.AdamW(model_src.parameters())\n",
        "# target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "# dummy_input = torch.randn(3, 10)\n",
        "# dummy_target = torch.randn(3, 5)\n",
        "# criterion = torch.nn.MSELoss()\n",
        "# output = model_src(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# source_optimizer.step()\n",
        "\n",
        "# dummy_input = torch.randn(3, 20)\n",
        "# output = model_tgt(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# target_optimizer.step()\n",
        "\n",
        "\n",
        "# print(source_optimizer.state_dict())\n",
        "# print(target_optimizer.state_dict())\n",
        "\n",
        "# optimsd = transfer_optim(model_tgt.state_dict(), model_src.state_dict(), target_optimizer, source_optimizer)\n",
        "# target_optimizer.load_state_dict(optimsd)\n",
        "# print(target_optimizer.state_dict())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AfjFbveH64Io",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title TCost\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TCost(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=256): # in_dim=(1+self.jepa.pred.num_layers)*d_model\n",
        "        super().__init__()\n",
        "        self.tc = torch.tensor([-1., 0.], device=device).unsqueeze(-1) # unsqueeze(0).T\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Dropout(p=0.),\n",
        "            nn.Linear(in_dim, 2, bias=False), nn.Softmax(dim=-1),\n",
        "            # nn.Linear(in_dim, d_model), nn.LeakyReLU(),\n",
        "            # # nn.Dropout(p=0.5),\n",
        "            # nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "            # nn.Linear(d_model, 2), nn.Softmax(),\n",
        "            )\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def update_loss_weight(self, train_data):\n",
        "        a = len(buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tcost(x)@self.tc\n",
        "\n",
        "    def loss(self, x, y):\n",
        "        out = self.tcost(x)\n",
        "        y = torch.where(y < -0.5, 0, 1)\n",
        "        return self.loss_fn(out, y)\n",
        "\n",
        "\n",
        "# tcost=TCost(1024)\n",
        "# x=torch.rand(256,1024)\n",
        "# import time\n",
        "# start = time.time()\n",
        "# out=tcost(x)\n",
        "# # out=F.gumbel_softmax(out)\n",
        "# print(time.time()-start)\n",
        "# # nn.AdaptiveLogSoftmaxWithLoss(in_features=2, n_classes=2, cutoffs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o0UHSueqx9W8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9affa4a-3b8e-431f-dbbc-b71d8c6ca439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-b20720e54f0e>:5: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred tensor([-0.9065, -0.9503, -0.8922, -0.8784, -0.8300, -0.9326, -0.9012, -0.8968,\n",
            "        -0.8397, -0.8236, -0.6494, -0.9033, -0.8178, -0.1345, -0.0572, -0.0022,\n",
            "        -0.2381, -0.0379, -0.0400, -0.0525, -0.0721, -0.1442, -0.1354, -0.2275,\n",
            "        -0.2425, -0.0261, -0.1565, -0.1476, -0.1326, -0.1335, -0.2210, -0.1987,\n",
            "        -0.2970, -0.1985, -0.2819, -0.1936, -0.5464, -0.0905, -0.3438, -0.3489,\n",
            "        -0.2093, -0.0594, -0.5009, -0.3977, -0.4156, -0.2535, -0.4324, -0.6285,\n",
            "        -0.5767, -0.5588], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.18088741600513458 4.019855499267578 0.6002451181411743 1111\n",
            "pred tensor([-0.7504, -0.2370, -0.4876, -0.5241, -0.3017, -0.5826, -0.4879, -0.4526,\n",
            "        -0.4134, -0.4340, -0.4155, -0.7401, -0.6483, -0.5276, -0.6794, -0.5105,\n",
            "        -0.6974, -0.5355, -0.8163, -0.7559, -0.9371, -0.5835, -0.7910, -0.4169,\n",
            "        -0.5289, -0.7179, -0.6833, -0.8340, -0.8284, -0.8281, -0.9324, -0.9670,\n",
            "        -0.8899, -0.9737, -0.9642, -0.9792, -0.9810, -0.9496, -0.9600, -0.9906,\n",
            "        -0.9773, -0.0075, -0.0195, -0.0295, -0.0413, -0.0050, -0.0958, -0.1698,\n",
            "        -0.2755, -0.7606], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.18057098984718323 4.386312007904053 0.6232972741127014 1230\n",
            "pred tensor([-0.9890, -0.9754, -0.9951, -0.2801, -0.1410, -0.2126, -0.1740, -0.1574,\n",
            "        -0.1804, -0.3171, -0.1209, -0.1400, -0.1074, -0.4561, -0.0565, -0.1624,\n",
            "        -0.2835, -0.1060, -0.2254, -0.0639, -0.0629, -0.1548, -0.1555, -0.0422,\n",
            "        -0.1986, -0.1847, -0.1285, -0.3027, -0.0762, -0.0674, -0.1938, -0.1201,\n",
            "        -0.1130, -0.4551, -0.2831, -0.3791, -0.2804, -0.3125, -0.4582, -0.6550,\n",
            "        -0.3818, -0.3506, -0.2458, -0.6402, -0.8663, -0.8306, -0.8494, -0.8326,\n",
            "        -0.4101, -0.5377], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1805240511894226 4.154450416564941 0.5848540663719177 1083\n",
            "pred tensor([-0.4567, -0.6803, -0.5581, -0.3034, -0.1354, -0.2428, -0.1874, -0.1953,\n",
            "        -0.1062, -0.1381, -0.2811, -0.3780, -0.3499, -0.0561, -0.1979, -0.1444,\n",
            "        -0.4081, -0.2497, -0.3863, -0.1227, -0.0726, -0.0650, -0.0538, -0.1259,\n",
            "        -0.2371, -0.5672, -0.5609, -0.2011, -0.6331, -0.2622, -0.0743, -0.0391,\n",
            "        -0.1069, -0.2084, -0.2261, -0.9637, -0.9713, -0.0696, -0.0739, -0.0280,\n",
            "        -0.1339, -0.0416, -0.0421, -0.3083, -0.3411, -0.1667, -0.1150, -0.3312,\n",
            "        -0.1779, -0.4595], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.18767759203910828 3.812788724899292 0.5698578953742981 1045\n",
            "pred tensor([-0.8376, -0.6212, -0.5302, -0.8512, -0.7903, -0.7178, -0.6684, -0.9803,\n",
            "        -0.6680, -0.8661, -0.0086, -0.0233, -0.0205, -0.2367, -0.0328, -0.4444,\n",
            "        -0.3386, -0.0448, -0.1522, -0.0481, -0.0272, -0.1361, -0.4666, -0.0806,\n",
            "        -0.4679, -0.3151, -0.4590, -0.8157, -0.9818, -0.9506, -0.8953, -0.0127,\n",
            "        -0.0025, -0.0026, -0.0088, -0.0072, -0.0061, -0.0055, -0.0064, -0.1025,\n",
            "        -0.0027, -0.0155, -0.0020, -0.0057, -0.0030, -0.0077, -0.0031, -0.0088,\n",
            "        -0.0127, -0.0198], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.19173578917980194 3.3529880046844482 0.5938904881477356 912\n",
            "pred tensor([-0.0243, -0.0071, -0.0841, -0.0400, -0.0157, -0.7717, -0.7924, -0.8528,\n",
            "        -0.8399, -0.1083, -0.4058, -0.2553, -0.0854, -0.4138, -0.0490, -0.1383,\n",
            "        -0.0468, -0.0646, -0.0210, -0.0420, -0.0714, -0.0755, -0.0372, -0.0301,\n",
            "        -0.1453, -0.0386, -0.0280, -0.0449, -0.0809, -0.0160, -0.1368, -0.1193,\n",
            "        -0.0334, -0.0548, -0.0260, -0.0275, -0.1255, -0.2616, -0.0601, -0.0277,\n",
            "        -0.0680, -0.0692, -0.0530, -0.1042, -0.0810, -0.0296, -0.0338, -0.0807,\n",
            "        -0.1153, -0.1520], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.19146625697612762 3.4231972694396973 0.5573042035102844 854\n",
            "pred tensor([-0.5372, -0.4808, -0.3258, -0.5964, -0.1814, -0.0271, -0.1930, -0.1364,\n",
            "        -0.0062, -0.0271, -0.0028, -0.1152, -0.0426, -0.0550, -0.1101, -0.1038,\n",
            "        -0.1400, -0.1984, -0.0433, -0.2006, -0.1868, -0.1361, -0.7541, -0.7681,\n",
            "        -0.5635, -0.6477, -0.5644, -0.4446, -0.8796, -0.4872, -0.3651, -0.4222,\n",
            "        -0.0725, -0.4789, -0.2639, -0.6564, -0.6782, -0.4154, -0.6476, -0.1269,\n",
            "        -0.1687, -0.0104, -0.0115, -0.1062, -0.1864, -0.1564, -0.1138, -0.0870,\n",
            "        -0.0476, -0.7834], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.185664564371109 3.7074382305145264 0.5765419006347656 826\n",
            "pred tensor([-5.8089e-02, -5.8396e-01, -7.1409e-01, -7.8698e-01, -4.8297e-01,\n",
            "        -6.3733e-01, -8.4849e-01, -1.9588e-01, -3.0562e-01, -6.9436e-01,\n",
            "        -9.2255e-02, -2.0144e-01, -2.6264e-01, -4.0989e-01, -3.3192e-01,\n",
            "        -2.4252e-01, -2.6841e-01, -7.0976e-01, -9.4667e-02, -1.8452e-01,\n",
            "        -3.4943e-01, -1.3745e-01, -2.5114e-01, -4.5937e-01, -1.4067e-01,\n",
            "        -1.8154e-01, -8.0046e-02, -3.4952e-02, -1.3434e-02, -1.7201e-03,\n",
            "        -1.0216e-02, -2.3158e-03, -6.7343e-04, -2.2705e-03, -5.4383e-03,\n",
            "        -1.5012e-01, -1.1093e-02, -8.0607e-02, -2.0934e-01, -2.8349e-01,\n",
            "        -1.0471e-01, -3.6919e-03, -2.1347e-02, -1.9532e-03, -2.8542e-03,\n",
            "        -9.1268e-04, -1.0479e-04, -1.2343e-03, -2.4237e-03, -2.4401e-02],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.18515951931476593 3.626903533935547 0.6110240817070007 926\n",
            "pred tensor([-0.0623, -0.0788, -0.0734, -0.4519, -0.0886, -0.4377, -0.2470, -0.5843,\n",
            "        -0.3855, -0.2495, -0.7859, -0.5685, -0.6980, -0.9235, -0.7588, -0.7845,\n",
            "        -0.8338, -0.5273, -0.6775, -0.7730, -0.7084, -0.3728, -0.4785, -0.3979,\n",
            "        -0.3472, -0.1959, -0.5282, -0.8436, -0.6456, -0.7213, -0.8235, -0.2970,\n",
            "        -0.1839, -0.0574, -0.0856, -0.0138, -0.0077, -0.0530, -0.3184, -0.6115,\n",
            "        -0.6363, -0.8353, -0.5449, -0.5842, -0.6459, -0.8399, -0.3668, -0.9295,\n",
            "        -0.9988, -0.9887], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.18303810060024261 3.7623040676116943 0.5972366333007812 1220\n",
            "pred tensor([-0.8722, -0.9607, -0.8248, -0.9059, -0.7629, -0.7680, -0.4608, -0.7346,\n",
            "        -0.7889, -0.6248, -0.5325, -0.8047, -0.9424, -0.8090, -0.6970, -0.2259,\n",
            "        -0.2648, -0.1277, -0.0503, -0.1270, -0.0453, -0.1503, -0.0611, -0.2934,\n",
            "        -0.4333, -0.0781, -0.0623, -0.1750, -0.5959, -0.3642, -0.2653, -0.3815,\n",
            "        -0.2776, -0.5746, -0.1392, -0.2370, -0.3222, -0.2000, -0.5727, -0.6069,\n",
            "        -0.4928, -0.3768, -0.1556, -0.0683, -0.0105, -0.0042, -0.0244, -0.0576,\n",
            "        -0.0073, -0.2995], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1843157261610031 3.646416425704956 0.6025171279907227 1293\n",
            "pred tensor([-9.2927e-01, -8.9020e-01, -9.6159e-01, -9.8358e-01, -9.1119e-01,\n",
            "        -9.4725e-01, -9.4053e-01, -9.9616e-01, -9.8838e-01, -4.6619e-03,\n",
            "        -1.3264e-01, -1.1149e-02, -2.6218e-02, -1.3147e-01, -5.0769e-03,\n",
            "        -1.4564e-02, -1.5577e-01, -6.0861e-02, -1.0838e-01, -2.8259e-01,\n",
            "        -8.9751e-02, -7.1478e-02, -2.0672e-02, -1.0333e-02, -9.6229e-03,\n",
            "        -2.7672e-03, -8.0714e-03, -5.6384e-03, -1.3054e-02, -4.6675e-02,\n",
            "        -2.2505e-02, -4.8017e-01, -8.9210e-01, -5.1213e-01, -5.5086e-01,\n",
            "        -1.5268e-01, -1.2849e-03, -7.2900e-03, -1.6575e-03, -7.1009e-04,\n",
            "        -3.0111e-03, -3.0314e-03, -1.6078e-02, -1.4791e-03, -1.2730e-01,\n",
            "        -5.1697e-01, -1.7559e-01, -6.3332e-02, -2.0644e-03, -1.1098e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.17829492688179016 3.8621554374694824 0.6013215184211731 1408\n",
            "pred tensor([-0.0284, -0.1512, -0.2275, -0.8828, -0.9425, -0.8809, -0.3672, -0.8019,\n",
            "        -0.9377, -0.9625, -0.9922, -0.9881, -0.9965, -0.9976, -0.9998, -0.9986,\n",
            "        -0.9999, -0.9998, -0.9972, -1.0000, -0.9994, -0.9997, -0.4630, -0.3453,\n",
            "        -0.2195, -0.4736, -0.2636, -0.1156, -0.4491, -0.2718, -0.2542, -0.1880,\n",
            "        -0.2272, -0.2039, -0.1660, -0.2566, -0.2665, -0.2589, -0.5205, -0.2667,\n",
            "        -0.3736, -0.1004, -0.2158, -0.2552, -0.1328, -0.3080, -0.0857, -0.3045,\n",
            "        -0.4728, -0.1344], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.176496222615242 3.9664976596832275 0.6004307270050049 1348\n",
            "pred tensor([-0.0003, -0.0001, -0.0016, -0.0007, -0.0003, -0.0220, -0.0065, -0.0012,\n",
            "        -0.0007, -0.0004, -0.0005, -0.0022, -0.0003, -0.0036, -0.0096, -0.0014,\n",
            "        -0.0025, -0.0504, -0.0010, -0.0333, -0.0104, -0.0022, -0.0104, -0.0036,\n",
            "        -0.0894, -0.0383, -0.0105, -0.0014, -0.0021, -0.0237, -0.0029, -0.0034,\n",
            "        -0.0023, -0.0006, -0.0010, -0.0006, -0.0118, -0.0038, -0.0078, -0.0064,\n",
            "        -0.0161, -0.0067, -0.0228, -0.0026, -0.0290, -0.0450, -0.0679, -0.0341,\n",
            "        -0.0082, -0.0047], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.17772535979747772 3.836000442504883 0.5765274167060852 1101\n",
            "pred tensor([-2.4665e-01, -6.9211e-01, -4.4664e-01, -8.1848e-01, -7.8828e-01,\n",
            "        -7.6320e-01, -4.1048e-01, -6.5495e-01, -4.8408e-01, -9.4133e-01,\n",
            "        -5.2690e-01, -4.2912e-01, -8.0841e-01, -8.0498e-01, -9.1893e-01,\n",
            "        -8.7258e-01, -9.3793e-01, -8.1291e-01, -6.2378e-01, -7.6699e-01,\n",
            "        -8.1298e-01, -8.2941e-01, -9.5254e-03, -2.7361e-03, -2.2492e-03,\n",
            "        -3.3563e-03, -3.3043e-03, -9.7524e-03, -1.4435e-03, -3.3116e-03,\n",
            "        -7.1988e-03, -3.0446e-03, -4.0262e-03, -8.1565e-03, -1.7040e-02,\n",
            "        -9.2656e-04, -1.6468e-03, -3.7834e-03, -9.4885e-04, -9.0396e-04,\n",
            "        -3.2192e-03, -1.1819e-03, -1.3142e-02, -1.2027e-02, -3.8949e-03,\n",
            "        -3.5900e-03, -6.2847e-03, -4.9277e-02, -3.5811e-02, -3.7528e-02],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1762528419494629 3.874025344848633 0.5756525993347168 968\n",
            "pred tensor([-0.0660, -0.0373, -0.0603, -0.0004, -0.0009, -0.0024, -0.0180, -0.0270,\n",
            "        -0.0006, -0.0124, -0.0017, -0.0205, -0.0054, -0.0121, -0.0602, -0.0286,\n",
            "        -0.0044, -0.0112, -0.0621, -0.0092, -0.0046, -0.0096, -0.0149, -0.0038,\n",
            "        -0.0360, -0.0297, -0.0054, -0.0199, -0.0130, -0.0019, -0.0009, -0.0061,\n",
            "        -0.0047, -0.0019, -0.0009, -0.0021, -0.0044, -0.0062, -0.0371, -0.0012,\n",
            "        -0.0222, -0.0175, -0.0016, -0.0963, -0.0055, -0.0056, -0.0140, -0.0549,\n",
            "        -0.0231, -0.0759], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.17937469482421875 3.6620612144470215 0.5834903717041016 809\n",
            "pred tensor([-1.3424e-04, -4.8052e-04, -4.6023e-01, -9.0873e-01, -9.9119e-01,\n",
            "        -9.9952e-01, -9.9841e-01, -9.9054e-01, -9.9716e-01, -9.9649e-01,\n",
            "        -9.7648e-01, -9.9409e-01, -9.9199e-01, -9.6325e-01, -9.9761e-01,\n",
            "        -9.9798e-01, -9.9963e-01, -9.9976e-01, -9.9977e-01, -9.9989e-01,\n",
            "        -9.9869e-01, -9.9921e-01, -9.9978e-01, -9.9634e-01, -9.9779e-01,\n",
            "        -9.9700e-01, -9.8647e-01, -9.9795e-01, -9.9697e-01, -1.9070e-03,\n",
            "        -2.6356e-02, -2.1669e-03, -4.4526e-03, -9.0143e-02, -3.1756e-01,\n",
            "        -7.9740e-02, -1.9341e-02, -1.1029e-02, -1.7923e-03, -8.9503e-03,\n",
            "        -7.4668e-04, -1.5180e-02, -4.5510e-02, -2.8458e-03, -5.5414e-04,\n",
            "        -9.2559e-03, -3.4119e-04, -1.9668e-03, -9.3500e-04, -1.8831e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.18058040738105774 3.57930850982666 0.5756503939628601 823\n",
            "pred tensor([-3.3835e-03, -1.0133e-02, -4.8589e-03, -2.8096e-03, -2.2330e-02,\n",
            "        -2.0459e-02, -2.7518e-02, -2.5555e-01, -7.7043e-01, -9.9330e-01,\n",
            "        -9.9967e-01, -9.9308e-01, -9.9956e-01, -9.9709e-01, -9.9985e-01,\n",
            "        -9.9953e-01, -2.0265e-03, -1.1127e-03, -3.9834e-04, -5.0397e-04,\n",
            "        -3.3197e-04, -3.7807e-04, -2.3612e-04, -5.3708e-04, -1.2905e-03,\n",
            "        -3.6604e-04, -6.5700e-04, -1.6734e-04, -1.8982e-04, -3.7340e-04,\n",
            "        -8.6417e-05, -5.1206e-04, -6.6439e-04, -4.7800e-03, -1.0818e-02,\n",
            "        -7.8779e-03, -5.4447e-02, -1.0162e-02, -3.8896e-02, -2.1736e-02,\n",
            "        -2.6001e-01, -1.9418e-01, -2.0111e-01, -7.3238e-02, -3.9715e-02,\n",
            "        -1.8258e-01, -3.1210e-01, -8.9886e-01, -4.6930e-01, -8.2578e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.])\n",
            "std, cov, clossl, wrong 0.17763645946979523 3.7045722007751465 0.6137166619300842 688\n",
            "pred tensor([-1.8540e-02, -1.8333e-03, -2.3487e-03, -3.2905e-04, -1.2987e-03,\n",
            "        -3.8816e-03, -3.8246e-03, -3.4860e-02, -4.6899e-03, -3.2564e-02,\n",
            "        -1.4922e-02, -2.4361e-03, -1.6086e-03, -1.3634e-02, -1.8701e-02,\n",
            "        -8.9823e-03, -2.0495e-03, -1.6243e-02, -5.2389e-03, -7.6430e-03,\n",
            "        -1.1765e-01, -7.6982e-02, -3.4952e-02, -1.6197e-02, -2.7728e-03,\n",
            "        -1.4376e-02, -5.7458e-02, -1.9392e-02, -2.4690e-01, -2.2958e-02,\n",
            "        -5.8928e-03, -1.8022e-02, -7.1448e-04, -9.8540e-04, -2.6640e-03,\n",
            "        -3.2065e-03, -9.8701e-04, -2.8558e-03, -2.6158e-04, -2.2967e-04,\n",
            "        -2.7072e-04, -6.7699e-05, -4.2193e-03, -8.5460e-02, -3.5704e-02,\n",
            "        -4.7753e-02, -1.9719e-01, -1.2726e-02, -8.4621e-03, -1.7310e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.17784830927848816 3.649545431137085 0.5498744249343872 980\n",
            "1\n",
            "pred tensor([-4.4584e-01, -9.8326e-01, -9.4058e-01, -9.9068e-01, -8.4861e-01,\n",
            "        -8.8994e-01, -6.5724e-01, -4.0914e-01, -7.9938e-01, -5.8744e-01,\n",
            "        -2.4694e-01, -5.9361e-01, -7.5751e-01, -1.3055e-01, -1.2779e-02,\n",
            "        -7.9337e-02, -8.1314e-03, -5.2615e-03, -1.8844e-01, -6.2798e-01,\n",
            "        -5.2165e-01, -2.2252e-01, -3.1395e-01, -9.8972e-02, -1.6747e-01,\n",
            "        -8.8074e-01, -7.1388e-01, -2.6190e-01, -9.9313e-01, -5.3720e-01,\n",
            "        -9.1434e-01, -7.1903e-01, -5.7259e-02, -3.0451e-01, -3.9211e-01,\n",
            "        -9.5683e-01, -9.9912e-01, -9.9810e-01, -2.6442e-03, -4.3553e-05,\n",
            "        -5.6297e-02, -1.3427e-02, -2.3832e-04, -1.6624e-01, -4.7940e-03,\n",
            "        -4.5876e-01, -1.0260e-01, -7.5356e-01, -4.0646e-02, -2.3594e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1753469556570053 3.66524338722229 0.5377745032310486 1057\n",
            "pred tensor([-3.7729e-02, -2.7144e-03, -1.0346e-01, -2.3690e-04, -2.3583e-02,\n",
            "        -4.5140e-03, -3.0386e-01, -7.5934e-01, -6.2114e-01, -3.3481e-03,\n",
            "        -1.0100e-02, -1.9001e-04, -3.6310e-03, -1.3421e-03, -1.7254e-03,\n",
            "        -3.9773e-04, -1.0084e-03, -9.4415e-04, -2.1588e-04, -1.0133e-03,\n",
            "        -1.0756e-02, -2.7067e-04, -2.5619e-03, -2.1850e-04, -1.2392e-02,\n",
            "        -5.6631e-01, -9.7044e-01, -8.8647e-01, -9.3025e-01, -9.7398e-01,\n",
            "        -9.9547e-01, -9.7244e-01, -9.9213e-01, -9.9198e-01, -9.9687e-01,\n",
            "        -9.9871e-01, -9.7723e-01, -9.9686e-01, -9.2992e-01, -9.9709e-01,\n",
            "        -9.8273e-01, -9.0382e-01, -9.2571e-01, -9.7093e-01, -4.8174e-01,\n",
            "        -7.6499e-01, -2.0776e-01, -8.2823e-01, -6.7279e-01, -6.6001e-02],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1703847497701645 3.8847193717956543 0.5552557706832886 1132\n",
            "pred tensor([-0.2160, -0.2399, -0.1044, -0.2205, -0.2035, -0.5519, -0.2603, -0.1628,\n",
            "        -0.0588, -0.1043, -0.1992, -0.4056, -0.2283, -0.1071, -0.2364, -0.2334,\n",
            "        -0.1695, -0.5156, -0.1620, -0.3841, -0.3220, -0.4716, -0.3824, -0.7418,\n",
            "        -0.1348, -0.5118, -0.7513, -0.6142, -0.4531, -0.0222, -0.1001, -0.0114,\n",
            "        -0.0047, -0.0020, -0.0080, -0.0173, -0.0091, -0.0058, -0.0261, -0.0074,\n",
            "        -0.0121, -0.0712, -0.0202, -0.0441, -0.0151, -0.0270, -0.0203, -0.0162,\n",
            "        -0.0367, -0.0846], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.16679224371910095 4.079782485961914 0.5515531301498413 1063\n",
            "pred tensor([-0.9874, -0.9845, -0.9949, -0.9929, -0.9971, -0.9810, -0.9947, -0.1208,\n",
            "        -0.0285, -0.0175, -0.0186, -0.0502, -0.0159, -0.0225, -0.1117, -0.0248,\n",
            "        -0.1392, -0.2969, -0.0719, -0.0603, -0.0933, -0.0608, -0.0432, -0.0548,\n",
            "        -0.0442, -0.0063, -0.1569, -0.0277, -0.1039, -0.1628, -0.3636, -0.8701,\n",
            "        -0.9619, -0.6773, -0.0056, -0.0189, -0.0509, -0.3311, -0.0106, -0.0407,\n",
            "        -0.0509, -0.0410, -0.0147, -0.0356, -0.0237, -0.0300, -0.0126, -0.0125,\n",
            "        -0.0559, -0.0152], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.16068196296691895 4.386377334594727 0.5677096843719482 1009\n",
            "pred tensor([-4.6534e-04, -7.4598e-05, -4.0829e-05, -7.0339e-04, -4.8902e-04,\n",
            "        -2.7415e-04, -1.1497e-03, -3.6610e-04, -1.1734e-01, -1.6373e-03,\n",
            "        -1.1393e-02, -7.0871e-04, -1.8111e-04, -4.5730e-03, -8.0299e-05,\n",
            "        -8.8486e-05, -3.5073e-05, -4.5585e-06, -1.6708e-04, -2.0925e-04,\n",
            "        -1.5151e-03, -1.2209e-04, -3.9528e-05, -1.1426e-03, -2.5374e-04,\n",
            "        -2.2601e-04, -5.6763e-04, -1.3986e-01, -2.4698e-01, -2.1848e-01,\n",
            "        -9.0390e-01, -2.1887e-01, -9.9976e-01, -9.9952e-01, -9.9975e-01,\n",
            "        -9.9966e-01, -9.9393e-01, -5.3032e-01, -1.4313e-01, -5.4278e-03,\n",
            "        -1.4892e-01, -8.7495e-01, -2.0707e-02, -6.1373e-04, -8.3312e-03,\n",
            "        -2.2499e-02, -1.0990e-01, -9.0380e-01, -9.0758e-01, -5.6388e-02],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1600271761417389 4.316946506500244 0.5596861839294434 839\n",
            "pred tensor([-4.1619e-01, -5.0136e-01, -1.9167e-01, -9.4730e-01, -9.7322e-01,\n",
            "        -9.6344e-01, -9.8084e-01, -9.9260e-01, -3.6217e-04, -1.1992e-04,\n",
            "        -1.2954e-04, -1.7898e-03, -1.4450e-04, -5.2267e-04, -1.3408e-03,\n",
            "        -4.5429e-04, -8.2009e-04, -1.1092e-03, -5.7513e-04, -3.2266e-04,\n",
            "        -1.1133e-04, -3.8603e-05, -2.8772e-04, -1.7551e-03, -8.9337e-03,\n",
            "        -4.7396e-04, -1.1602e-03, -5.1021e-04, -4.2696e-03, -2.5699e-03,\n",
            "        -7.9131e-04, -3.6304e-04, -4.3569e-04, -1.5091e-04, -2.3740e-05,\n",
            "        -1.0700e-04, -4.5120e-03, -8.0428e-05, -5.4616e-03, -2.1953e-03,\n",
            "        -3.0012e-01, -9.6036e-01, -9.7987e-01, -9.7536e-01, -9.9062e-01,\n",
            "        -9.9877e-01, -9.9664e-01, -9.9925e-01, -9.9626e-01, -9.9922e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1607685536146164 4.188794136047363 0.5628721117973328 788\n",
            "pred tensor([-8.3071e-04, -1.0450e-03, -9.2611e-04, -3.1391e-03, -2.2858e-03,\n",
            "        -3.0950e-03, -3.2471e-02, -6.1822e-04, -3.8784e-01, -4.4110e-02,\n",
            "        -4.2516e-02, -1.1698e-03, -2.3755e-02, -2.7964e-02, -2.1007e-03,\n",
            "        -1.7444e-02, -2.4476e-01, -2.0819e-04, -5.7722e-02, -1.5816e-02,\n",
            "        -7.7628e-02, -4.1156e-02, -3.2832e-01, -2.9811e-01, -3.8245e-01,\n",
            "        -4.7760e-01, -1.6071e-01, -6.6894e-01, -3.8307e-03, -1.2158e-01,\n",
            "        -2.7937e-03, -1.3050e-03, -4.3515e-05, -1.3624e-03, -1.0127e-03,\n",
            "        -1.0067e-04, -1.2648e-05, -1.0978e-03, -4.1853e-04, -1.9796e-02,\n",
            "        -3.0752e-02, -6.1866e-02, -2.8816e-01, -3.7244e-02, -1.2278e-01,\n",
            "        -4.2597e-02, -6.3662e-02, -4.9961e-02, -6.7247e-02, -4.2784e-04],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.16110801696777344 4.167418479919434 0.5457649230957031 1092\n",
            "pred tensor([-0.9924, -0.9822, -0.9901, -0.9707, -0.9070, -0.9882, -0.9980, -0.9875,\n",
            "        -0.9961, -0.9919, -0.9976, -0.9924, -0.9954, -0.9994, -0.9990, -0.9997,\n",
            "        -0.9999, -1.0000, -1.0000, -0.9997, -1.0000, -0.9999, -0.9996, -0.9998,\n",
            "        -0.9990, -0.9995, -0.9991, -0.9948, -0.9949, -0.9994, -0.9967, -0.9979,\n",
            "        -0.9994, -0.9982, -0.9976, -0.9958, -0.9990, -0.9997, -0.9989, -0.9995,\n",
            "        -0.9998, -0.9993, -0.9948, -0.9961, -0.9990, -0.9953, -0.8886, -0.9699,\n",
            "        -0.2670, -0.3369], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1610977053642273 4.1333537101745605 0.5633345246315002 1290\n",
            "pred tensor([-8.8137e-04, -4.1849e-01, -6.4304e-01, -1.0994e-01, -1.0195e-02,\n",
            "        -1.2268e-02, -1.6305e-01, -3.1013e-04, -1.5865e-03, -1.5647e-03,\n",
            "        -2.8255e-02, -1.8781e-01, -9.5750e-01, -9.9335e-01, -9.8033e-01,\n",
            "        -1.1840e-01, -3.4915e-02, -3.8565e-04, -1.3181e-03, -3.6621e-04,\n",
            "        -4.3870e-04, -5.3566e-03, -7.8183e-03, -8.5182e-03, -2.2509e-02,\n",
            "        -1.9823e-03, -1.6103e-03, -3.9606e-02, -6.1306e-03, -9.6091e-01,\n",
            "        -8.8161e-01, -9.7541e-01, -9.9961e-01, -9.9993e-01, -9.9928e-01,\n",
            "        -9.5360e-01, -9.8281e-01, -9.3499e-01, -9.0203e-01, -9.5571e-01,\n",
            "        -9.3167e-01, -2.5913e-01, -2.8598e-02, -9.5396e-02, -3.1147e-03,\n",
            "        -2.3754e-03, -1.5765e-03, -1.5900e-01, -1.9797e-01, -8.5668e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.16138723492622375 4.018349647521973 0.5644260048866272 1221\n",
            "pred tensor([-3.5998e-05, -4.3131e-05, -1.7061e-04, -6.1959e-06, -9.8655e-07,\n",
            "        -1.7010e-07, -6.4748e-07, -6.7996e-07, -1.8627e-06, -2.2543e-05,\n",
            "        -6.5518e-07, -5.2438e-06, -7.1166e-07, -1.8224e-07, -8.5301e-06,\n",
            "        -2.4522e-05, -3.0356e-04, -2.5559e-04, -5.2860e-01, -5.3266e-02,\n",
            "        -1.5132e-01, -4.6579e-01, -9.9651e-01, -9.6593e-01, -3.7532e-01,\n",
            "        -1.7074e-02, -2.9064e-01, -2.2136e-04, -4.0077e-03, -3.0499e-02,\n",
            "        -6.9734e-03, -2.6160e-03, -2.6911e-02, -6.6692e-01, -8.9098e-01,\n",
            "        -9.8204e-01, -8.4567e-01, -9.2696e-01, -9.7851e-01, -9.5469e-01,\n",
            "        -1.1247e-01, -9.5251e-04, -2.3288e-03, -1.1015e-03, -3.8997e-03,\n",
            "        -1.1287e-02, -2.1705e-01, -1.7660e-02, -8.3682e-01, -2.9474e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.16318121552467346 3.9282588958740234 0.546697199344635 912\n",
            "pred tensor([-2.7677e-03, -8.5198e-05, -5.4420e-06, -3.4509e-05, -1.2426e-05,\n",
            "        -4.4059e-06, -2.6477e-05, -3.9722e-06, -2.0687e-05, -1.0325e-05,\n",
            "        -8.4733e-04, -7.6660e-07, -4.3956e-06, -4.7243e-06, -7.0002e-06,\n",
            "        -8.6194e-05, -4.2211e-04, -8.4427e-05, -5.3441e-04, -4.1070e-03,\n",
            "        -3.8755e-03, -2.6413e-03, -1.7573e-04, -2.3221e-03, -2.8103e-04,\n",
            "        -6.4989e-03, -1.4756e-01, -5.0229e-02, -1.7905e-01, -4.6108e-04,\n",
            "        -3.6461e-03, -4.4042e-02, -4.7401e-03, -8.3500e-06, -4.4550e-06,\n",
            "        -2.2019e-05, -7.9975e-05, -1.6057e-05, -2.2087e-06, -5.1610e-06,\n",
            "        -5.1799e-06, -1.6201e-06, -1.8294e-05, -2.0041e-05, -7.3066e-06,\n",
            "        -2.4646e-06, -4.7941e-06, -1.2996e-04, -8.0943e-06, -4.2876e-06],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.15841291844844818 4.238447189331055 0.6010740399360657 836\n",
            "pred tensor([-0.0137, -0.0423, -0.0224, -0.1032, -0.0371, -0.0238, -0.1774, -0.0448,\n",
            "        -0.3974, -0.0584, -0.0408, -0.2489, -0.1953, -0.0958, -0.1733, -0.0161,\n",
            "        -0.5332, -0.1102, -0.3689, -0.0285, -0.5543, -0.9327, -0.8303, -0.7901,\n",
            "        -0.9574, -0.9264, -0.8662, -0.6215, -0.6140, -0.0059, -0.0191, -0.1173,\n",
            "        -0.0115, -0.0474, -0.0675, -0.0443, -0.0022, -0.0026, -0.0110, -0.0841,\n",
            "        -0.1741, -0.8467, -0.4665, -0.8361, -0.9641, -0.8897, -0.8606, -0.7051,\n",
            "        -0.8958, -0.0207], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.16088640689849854 3.970449209213257 0.5570454597473145 623\n",
            "pred tensor([-1.0093e-03, -1.6561e-03, -1.3072e-02, -3.3533e-03, -3.2144e-03,\n",
            "        -2.3987e-02, -6.8125e-03, -2.0677e-03, -4.4556e-04, -3.0668e-03,\n",
            "        -4.5654e-02, -5.4268e-03, -2.8956e-03, -1.6239e-02, -8.6639e-03,\n",
            "        -4.9976e-03, -6.0721e-03, -2.0759e-03, -1.3170e-03, -4.4790e-03,\n",
            "        -1.5067e-03, -5.6927e-02, -5.2730e-03, -2.0325e-02, -1.1447e-04,\n",
            "        -2.1279e-02, -7.4800e-01, -9.9427e-01, -9.9780e-01, -9.9963e-01,\n",
            "        -9.9979e-01, -9.9943e-01, -9.9955e-01, -9.9998e-01, -9.9996e-01,\n",
            "        -9.9994e-01, -9.9971e-01, -9.9977e-01, -9.9952e-01, -9.9987e-01,\n",
            "        -9.9855e-01, -9.9836e-01, -9.7428e-01, -9.5548e-01, -2.8440e-01,\n",
            "        -3.0136e-01, -9.6968e-01, -3.5679e-01, -9.9737e-01, -9.6938e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.1573372185230255 4.14188814163208 0.6172025799751282 783\n",
            "pred tensor([-0.0217, -0.0050, -0.3597, -0.9220, -0.8254, -0.1994, -0.0059, -0.1825,\n",
            "        -0.0062, -0.0034, -0.0039, -0.0037, -0.0125, -0.0053, -0.0139, -0.0636,\n",
            "        -0.0730, -0.0024, -0.0109, -0.0057, -0.0016, -0.0035, -0.0199, -0.3432,\n",
            "        -0.7787, -0.5028, -0.2656, -0.4393, -0.8730, -0.8210, -0.0021, -0.0031,\n",
            "        -0.0021, -0.0055, -0.0242, -0.3274, -0.3062, -0.9172, -0.8675, -0.7963,\n",
            "        -0.7269, -0.3771, -0.3830, -0.1736, -0.0868, -0.0209, -0.0597, -0.0024,\n",
            "        -0.0676, -0.0225], grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15884001553058624 4.141117095947266 0.5673794746398926 800\n",
            "pred tensor([-9.9843e-01, -2.5242e-04, -3.6299e-04, -5.2580e-05, -8.7817e-05,\n",
            "        -1.1625e-04, -5.4903e-05, -7.8817e-04, -1.2847e-04, -1.0306e-04,\n",
            "        -1.9184e-04, -2.4811e-04, -7.9388e-05, -1.2940e-04, -2.0069e-03,\n",
            "        -1.7715e-03, -1.7709e-03, -2.8927e-04, -2.3242e-04, -4.9121e-04,\n",
            "        -1.1720e-03, -5.9017e-04, -7.7039e-04, -7.7057e-04, -1.6206e-03,\n",
            "        -6.7340e-04, -7.2974e-05, -7.8107e-04, -3.3942e-04, -3.3253e-04,\n",
            "        -1.4156e-03, -9.6799e-04, -3.9110e-03, -1.2648e-03, -3.0838e-03,\n",
            "        -7.9624e-03, -3.8191e-04, -9.0124e-03, -4.0740e-03, -1.1554e-02,\n",
            "        -9.7312e-02, -2.4727e-01, -1.4078e-02, -7.9828e-02, -7.2132e-01,\n",
            "        -9.6457e-02, -1.9750e-01, -4.9656e-02, -9.1782e-03, -1.7751e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15922723710536957 4.075213432312012 0.5755332112312317 880\n",
            "pred tensor([-6.5645e-06, -6.7216e-08, -1.1468e-04, -6.0912e-06, -7.8458e-05,\n",
            "        -4.3789e-05, -3.7707e-06, -5.7747e-05, -4.4292e-05, -7.2134e-05,\n",
            "        -5.1261e-05, -4.5065e-04, -6.5093e-04, -2.6022e-03, -1.2698e-02,\n",
            "        -1.7016e-01, -4.9170e-01, -5.5918e-02, -1.6269e-02, -2.6071e-01,\n",
            "        -1.5832e-03, -1.0428e-04, -3.8346e-03, -1.8426e-03, -6.4535e-04,\n",
            "        -3.6005e-03, -1.7088e-02, -1.9654e-02, -6.2771e-03, -3.1320e-02,\n",
            "        -6.9322e-01, -5.3368e-01, -1.8928e-01, -1.3145e-02, -6.7129e-02,\n",
            "        -2.1037e-02, -7.0773e-03, -3.9821e-02, -6.0909e-01, -3.1701e-02,\n",
            "        -5.4778e-01, -1.1018e-02, -5.7611e-03, -2.9413e-02, -2.9205e-01,\n",
            "        -1.6663e-01, -2.7162e-01, -9.3511e-01, -7.5776e-01, -8.4061e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.])\n",
            "std, cov, clossl, wrong 0.15899723768234253 4.016711711883545 0.5669180154800415 779\n",
            "pred tensor([-1.2655e-02, -3.5351e-02, -5.9108e-05, -6.2091e-05, -3.3112e-06,\n",
            "        -2.4057e-03, -2.0537e-04, -4.2043e-03, -1.2831e-03, -4.8523e-03,\n",
            "        -1.8896e-03, -4.4079e-04, -4.9051e-04, -6.7329e-04, -7.2097e-05,\n",
            "        -3.1944e-03, -1.0782e-02, -9.9008e-04, -4.8556e-04, -6.8872e-04,\n",
            "        -7.5816e-03, -1.3826e-03, -1.1925e-03, -1.3335e-03, -2.9511e-03,\n",
            "        -2.8291e-02, -1.3615e-03, -9.6292e-02, -8.3575e-01, -7.6035e-01,\n",
            "        -1.1002e-01, -4.2106e-01, -4.3360e-02, -2.2249e-01, -2.0032e-01,\n",
            "        -7.0110e-01, -9.0969e-01, -4.5701e-01, -8.1354e-01, -3.7085e-01,\n",
            "        -8.2085e-01, -5.5917e-01, -9.5893e-01, -3.3033e-01, -9.7448e-01,\n",
            "        -8.3238e-01, -6.4199e-01, -9.3026e-02, -3.6585e-01, -4.8708e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1605706810951233 3.911815881729126 0.572817325592041 785\n",
            "pred tensor([-3.8711e-04, -4.9362e-04, -2.8800e-04, -1.9024e-04, -5.4521e-04,\n",
            "        -3.4053e-05, -7.8693e-05, -7.8752e-05, -1.5526e-05, -2.9584e-05,\n",
            "        -2.2241e-05, -3.0482e-05, -3.7499e-04, -2.5715e-04, -8.9898e-04,\n",
            "        -1.3367e-04, -5.8573e-04, -2.9345e-05, -2.3520e-04, -9.3579e-05,\n",
            "        -5.8188e-05, -1.6301e-03, -5.0376e-05, -1.4414e-04, -2.3587e-05,\n",
            "        -6.3471e-05, -3.5498e-04, -2.9089e-04, -4.2549e-04, -2.1397e-04,\n",
            "        -1.6334e-04, -1.5045e-04, -9.8409e-06, -2.0841e-03, -3.7909e-05,\n",
            "        -2.4715e-05, -4.7391e-05, -1.3850e-04, -8.2169e-06, -1.6425e-05,\n",
            "        -8.4080e-04, -1.0486e-05, -2.4602e-05, -3.1155e-04, -2.8978e-04,\n",
            "        -3.0332e-05, -1.4515e-05, -3.9416e-05, -2.3865e-05, -2.7975e-04],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.15669076144695282 4.168125629425049 0.5651790499687195 888\n",
            "2\n",
            "pred tensor([-4.5519e-04, -5.2140e-01, -5.4960e-02, -8.0303e-01, -9.3164e-01,\n",
            "        -3.2120e-01, -3.5344e-01, -2.2418e-02, -2.0542e-03, -1.4324e-04,\n",
            "        -4.0599e-03, -6.8966e-05, -4.5106e-05, -1.8614e-05, -1.6356e-06,\n",
            "        -9.4044e-06, -1.3209e-02, -4.7466e-05, -1.9518e-03, -5.0828e-03,\n",
            "        -1.7814e-03, -8.4163e-06, -9.3225e-05, -2.3124e-04, -1.7180e-03,\n",
            "        -7.0902e-04, -5.7251e-01, -1.3934e-01, -4.9729e-01, -6.3465e-01,\n",
            "        -2.5914e-04, -5.8422e-04, -5.7881e-04, -4.5140e-05, -1.6515e-05,\n",
            "        -5.6935e-06, -1.2622e-04, -1.4903e-06, -2.7550e-07, -8.6529e-05,\n",
            "        -3.0302e-03, -1.7418e-02, -2.7131e-02, -1.0273e-02, -4.2726e-01,\n",
            "        -5.5360e-01, -8.6894e-01, -9.7709e-01, -6.7442e-02, -9.5440e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15489833056926727 4.1289167404174805 0.5360528826713562 866\n",
            "pred tensor([-9.9899e-01, -9.8528e-01, -9.9731e-01, -8.7040e-01, -5.0630e-01,\n",
            "        -4.7731e-01, -8.7215e-01, -7.7821e-01, -8.2109e-01, -9.1224e-02,\n",
            "        -5.4862e-01, -4.7730e-01, -4.0747e-01, -1.0695e-01, -4.4963e-01,\n",
            "        -5.5684e-01, -9.7089e-01, -9.1851e-01, -9.9381e-01, -9.5156e-01,\n",
            "        -9.9237e-01, -9.5613e-01, -9.8822e-01, -9.8529e-01, -9.4075e-01,\n",
            "        -8.9021e-01, -9.6881e-01, -9.5871e-01, -9.3617e-01, -9.6626e-01,\n",
            "        -9.3357e-01, -9.1089e-01, -9.0677e-01, -9.4481e-01, -8.3630e-01,\n",
            "        -6.4714e-01, -9.1146e-01, -2.8957e-03, -2.1552e-01, -1.2172e-04,\n",
            "        -9.2150e-02, -5.8828e-05, -6.3432e-02, -8.8389e-01, -9.9769e-01,\n",
            "        -9.9854e-01, -9.9564e-01, -3.5526e-07, -1.5352e-05, -4.1552e-05],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15562377870082855 4.0534515380859375 0.5337702035903931 922\n",
            "pred tensor([-3.5899e-04, -4.1469e-03, -3.3190e-04, -2.1261e-03, -2.6211e-03,\n",
            "        -1.5753e-02, -2.0019e-03, -1.3424e-02, -4.1129e-02, -7.3703e-03,\n",
            "        -6.0025e-01, -2.1957e-03, -1.5246e-02, -1.8075e-02, -6.6269e-03,\n",
            "        -8.6309e-03, -1.0179e-01, -6.9319e-01, -1.0535e-01, -4.1157e-02,\n",
            "        -9.0958e-04, -7.8313e-04, -9.6877e-03, -1.1463e-04, -1.6798e-05,\n",
            "        -2.9101e-05, -1.1802e-03, -3.0874e-03, -5.5770e-02, -9.3354e-01,\n",
            "        -9.6650e-01, -4.1866e-03, -2.5345e-02, -4.8883e-04, -2.8879e-03,\n",
            "        -7.0813e-04, -1.7824e-02, -8.1420e-02, -7.5085e-03, -4.7392e-01,\n",
            "        -2.3250e-01, -4.1645e-01, -1.4318e-01, -6.2466e-02, -6.1754e-01,\n",
            "        -9.1603e-02, -2.9016e-03, -8.6232e-04, -3.3600e-03, -2.4177e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.15442559123039246 4.096947193145752 0.5690451860427856 948\n",
            "pred tensor([-7.1214e-01, -5.0295e-01, -3.4417e-01, -9.4374e-01, -8.8180e-01,\n",
            "        -7.3299e-01, -4.0236e-01, -1.5134e-06, -3.2861e-07, -2.0172e-06,\n",
            "        -3.6223e-07, -3.9932e-06, -5.0493e-07, -1.1374e-07, -3.0179e-07,\n",
            "        -5.2518e-07, -3.2658e-08, -1.3976e-06, -6.5176e-08, -1.6085e-07,\n",
            "        -8.0914e-07, -1.9501e-06, -2.6470e-07, -6.3202e-06, -3.9030e-06,\n",
            "        -8.4852e-06, -1.8277e-07, -1.2406e-06, -1.4736e-06, -4.9780e-06,\n",
            "        -2.0317e-07, -3.2088e-06, -1.0774e-05, -3.4446e-04, -4.2702e-06,\n",
            "        -2.5227e-05, -5.3100e-06, -4.3428e-07, -9.8219e-04, -1.2237e-04,\n",
            "        -1.6389e-04, -5.5963e-05, -5.7387e-05, -1.8525e-03, -6.1200e-02,\n",
            "        -1.8015e-03, -3.3468e-02, -7.9884e-02, -3.4871e-03, -1.1191e-04],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15243440866470337 4.1193318367004395 0.5718936324119568 894\n",
            "pred tensor([-9.8915e-01, -2.3570e-02, -8.4396e-03, -6.0481e-03, -6.7212e-05,\n",
            "        -1.5940e-04, -3.8427e-04, -5.3024e-04, -1.1917e-03, -4.7817e-04,\n",
            "        -1.8900e-04, -6.9808e-04, -1.0792e-03, -7.5807e-04, -2.4612e-03,\n",
            "        -4.1046e-02, -1.6299e-01, -1.7560e-01, -2.6841e-03, -2.1345e-04,\n",
            "        -3.5805e-05, -3.3836e-04, -1.5884e-04, -8.4722e-04, -7.6428e-01,\n",
            "        -2.0497e-01, -6.2628e-01, -5.2541e-01, -9.6523e-01, -6.1715e-01,\n",
            "        -6.5164e-01, -9.5792e-01, -4.9044e-04, -5.8336e-04, -5.6495e-04,\n",
            "        -5.4074e-04, -1.0977e-03, -5.2061e-05, -5.3770e-04, -4.0139e-04,\n",
            "        -7.2704e-04, -1.3127e-04, -3.0722e-03, -2.2595e-04, -5.5406e-04,\n",
            "        -6.5114e-04, -7.1849e-03, -1.8524e-03, -3.4227e-03, -3.5972e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1531830132007599 4.139013290405273 0.5673630237579346 852\n",
            "pred tensor([-5.2664e-03, -8.1484e-03, -6.0105e-01, -1.5849e-02, -8.8838e-02,\n",
            "        -1.0157e-03, -2.2413e-03, -3.7355e-04, -5.2478e-04, -6.2082e-03,\n",
            "        -3.7753e-04, -8.3771e-04, -1.5854e-04, -3.4038e-03, -1.1968e-03,\n",
            "        -3.2932e-04, -5.4311e-04, -4.3971e-05, -2.1149e-05, -1.0049e-05,\n",
            "        -3.7659e-05, -1.6716e-05, -1.1462e-06, -8.1194e-05, -4.0809e-05,\n",
            "        -7.3265e-05, -7.7913e-04, -6.9878e-04, -1.6880e-03, -2.8942e-02,\n",
            "        -1.6375e-01, -9.2529e-02, -5.8640e-01, -1.4971e-01, -5.9033e-01,\n",
            "        -4.8696e-01, -8.8559e-01, -8.4021e-01, -9.4445e-01, -8.2640e-01,\n",
            "        -9.8554e-01, -9.5279e-01, -9.2491e-01, -9.1598e-01, -7.8017e-01,\n",
            "        -3.6965e-02, -8.8042e-03, -6.9580e-01, -9.7143e-01, -6.9866e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15178760886192322 4.122339248657227 0.5873954892158508 690\n",
            "pred tensor([-9.2033e-01, -6.0334e-01, -6.8803e-01, -5.5769e-01, -4.9903e-01,\n",
            "        -3.4252e-01, -2.7288e-01, -8.0856e-01, -5.5139e-01, -8.8752e-01,\n",
            "        -7.6223e-01, -8.6763e-01, -1.0923e-01, -8.6140e-03, -2.3528e-04,\n",
            "        -1.6263e-04, -4.6755e-03, -4.1330e-02, -9.0390e-01, -9.9538e-01,\n",
            "        -9.5225e-01, -9.9423e-01, -9.9572e-01, -9.3426e-01, -9.9430e-01,\n",
            "        -7.5079e-01, -9.8473e-01, -9.9852e-01, -9.8787e-01, -9.9967e-01,\n",
            "        -9.9999e-01, -1.0000e+00, -9.9993e-01, -1.0000e+00, -8.9125e-01,\n",
            "        -9.9191e-01, -7.9239e-01, -9.2823e-01, -1.3558e-01, -8.7779e-04,\n",
            "        -7.3289e-02, -1.1210e-02, -7.0551e-03, -4.0625e-01, -2.3240e-01,\n",
            "        -8.3470e-01, -8.4229e-01, -5.2407e-01, -2.3290e-01, -9.6585e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1488920897245407 4.255673408508301 0.5412857532501221 827\n",
            "pred tensor([-9.9725e-01, -9.9870e-01, -9.9902e-01, -9.9299e-01, -9.8526e-01,\n",
            "        -9.9423e-01, -9.9550e-01, -7.0775e-02, -5.7873e-01, -1.2329e-01,\n",
            "        -8.7926e-01, -1.8450e-02, -8.7127e-01, -1.5622e-02, -1.5382e-03,\n",
            "        -1.9961e-01, -2.7128e-01, -3.8650e-01, -9.7210e-01, -9.9080e-01,\n",
            "        -9.0270e-01, -9.9265e-01, -9.9721e-01, -9.9127e-01, -9.9658e-01,\n",
            "        -9.9960e-01, -9.9865e-01, -9.9929e-01, -9.3559e-01, -7.9702e-01,\n",
            "        -8.7041e-03, -8.0465e-01, -1.1326e-01, -1.4485e-01, -3.5149e-01,\n",
            "        -1.7812e-01, -9.0867e-01, -9.6787e-01, -8.5829e-01, -6.9520e-05,\n",
            "        -3.5183e-05, -3.6762e-06, -7.4377e-05, -4.2669e-04, -2.0423e-04,\n",
            "        -9.9469e-05, -1.4854e-04, -8.3370e-04, -2.8428e-04, -3.4351e-04],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.15089605748653412 4.145450592041016 0.6028704047203064 1006\n",
            "pred tensor([-1.6290e-06, -2.5059e-07, -6.6902e-05, -3.2901e-04, -8.1992e-02,\n",
            "        -9.4035e-04, -1.1116e-01, -2.2390e-02, -4.5717e-03, -3.4545e-04,\n",
            "        -1.4764e-03, -9.3260e-03, -1.8343e-02, -5.0955e-02, -6.5719e-01,\n",
            "        -5.3526e-01, -9.9821e-01, -9.9776e-01, -9.9204e-01, -9.9895e-01,\n",
            "        -9.9858e-01, -9.9935e-01, -9.9995e-01, -9.9993e-01, -9.9982e-01,\n",
            "        -9.9879e-01, -9.9895e-01, -9.9488e-01, -9.9712e-01, -9.7431e-01,\n",
            "        -9.9345e-01, -6.8017e-01, -7.0206e-01, -1.9458e-01, -3.5303e-02,\n",
            "        -1.3779e-01, -2.8172e-02, -5.0605e-03, -3.1742e-01, -7.2615e-01,\n",
            "        -8.2426e-01, -9.8688e-01, -9.7020e-01, -3.0968e-04, -5.0442e-03,\n",
            "        -4.4566e-03, -5.8981e-04, -4.5822e-03, -9.4499e-04, -7.7474e-04],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.1507333517074585 4.259433269500732 0.6486077904701233 1076\n",
            "pred tensor([-1.8598e-01, -2.3285e-01, -2.2820e-01, -2.9250e-01, -5.0629e-01,\n",
            "        -8.0324e-01, -3.9922e-01, -2.7083e-01, -2.0101e-01, -8.4333e-02,\n",
            "        -3.1686e-01, -3.4585e-02, -9.3912e-02, -5.0519e-03, -3.4918e-02,\n",
            "        -3.8844e-01, -1.8925e-01, -1.0845e-01, -5.9837e-01, -4.7387e-01,\n",
            "        -7.9615e-01, -4.7000e-01, -2.7513e-01, -7.0417e-01, -6.3009e-01,\n",
            "        -8.4128e-01, -2.7854e-01, -2.4697e-01, -3.7519e-01, -4.7009e-01,\n",
            "        -1.2887e-01, -4.0689e-02, -1.6964e-02, -7.2141e-02, -3.0770e-02,\n",
            "        -1.0440e-01, -9.2951e-02, -1.2885e-01, -8.1420e-01, -8.5877e-01,\n",
            "        -9.0940e-01, -9.7587e-01, -9.9194e-01, -1.2518e-01, -3.1304e-01,\n",
            "        -4.6358e-01, -1.1731e-02, -1.9043e-03, -3.6988e-04, -1.3091e-04],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
            "std, cov, clossl, wrong 0.14372731745243073 4.452498912811279 0.6091197729110718 847\n",
            "pred tensor([-1.3780e-03, -1.0668e-06, -4.0403e-08, -3.8776e-09, -1.9330e-06,\n",
            "        -1.9123e-07, -2.6267e-07, -1.3043e-07, -8.9193e-08, -1.3179e-07,\n",
            "        -5.7198e-06, -1.0054e-07, -4.6286e-05, -1.3773e-05, -6.0237e-05,\n",
            "        -1.9502e-04, -2.8456e-04, -8.5472e-05, -8.3574e-05, -2.2860e-05,\n",
            "        -3.9358e-04, -1.1320e-04, -2.3083e-02, -3.5364e-02, -3.7309e-02,\n",
            "        -1.5273e-05, -2.1847e-03, -2.6800e-05, -9.3168e-06, -2.5746e-06,\n",
            "        -5.3925e-07, -7.6873e-07, -4.1808e-08, -1.4275e-06, -1.1576e-05,\n",
            "        -2.2664e-05, -1.7815e-06, -8.4980e-04, -2.3005e-04, -3.9673e-04,\n",
            "        -1.0719e-03, -3.7063e-06, -2.6425e-04, -5.3867e-02, -1.9064e-02,\n",
            "        -5.5874e-01, -8.6502e-01, -4.3848e-02, -9.3977e-01, -9.8987e-01],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "std, cov, clossl, wrong 0.14321812987327576 4.539114475250244 0.6177532076835632 929\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b20720e54f0e>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrain_jepa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-b20720e54f0e>\u001b[0m in \u001b[0;36mtrain_jepa\u001b[0;34m(self, dataloader, optim, bptt)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"std, cov, clossl, wrong\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclossl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "    self.train()\n",
        "    for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "        state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            lsy = self.jepa.enc(state.flatten(end_dim=1)) # [batch_size, bptt, d_model]\n",
        "            # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "            # lsy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy))\n",
        "            jloss = self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "            clossl = self.tcost.loss(lsy, reward.flatten(end_dim=1))\n",
        "            closs = self.closs_coeff * clossl\n",
        "\n",
        "            pred = self.tcost(lsy).squeeze(-1).unflatten(0, reward.shape) # [batch_size, bptt]\n",
        "            print(\"pred\",pred[0])\n",
        "            print(\"rwd\",reward[0])\n",
        "            mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "            # # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "            # try: imshow(torchvision.utils.make_grid(st[0].cpu(), nrow=10))\n",
        "            # # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "            # except ZeroDivisionError: pass\n",
        "\n",
        "        loss = jloss + closs\n",
        "\n",
        "        print(\"std, cov, clossl, wrong\", std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "        # print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "        scaler.scale(loss).backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "        except: pass\n",
        "\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "    train_jepa(agent, train_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuA25qQknUAX",
        "outputId": "b39ce449-f8ec-4fab-dd92-94b0930388e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-9b3493e3f0c0>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model) # pixel\n",
        "        # self.enc = ConvEnc(d_model) #\n",
        "        # self.enc = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.enc.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "        # self.pred = nn.Sequential(\n",
        "        #     nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.3)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=3e3, h0=None): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95))\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        for i in range(5): # 10\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sy_ = self.pred(sxaz)\n",
        "                sy_, _ = self.pred(sxaz, h0)\n",
        "                loss = lossfn(sy_, sy)# + self.z_coeff * torch.norm(z)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"argm\",i,loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "# torch.norm(z, dim=-1)\n",
        "# -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "# in RL, distribution of action, if certainty is high, entropy is low\n",
        "\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkI44ygzfxu",
        "outputId": "be74c48b-47d0-4c8c-d4ed-8026fd4478eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-2f08d6d8256a>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=8, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=50. # 50 # 50 # 10 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=50. # 50 # 20 # 50 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 1 # 0.001 # 1 # ν cov Covariance\n",
        "        self.closs_coeff=100. # 100 # 100 # 100\n",
        "        self.zloss_coeff=10. # 10 # 20 # 1\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        self.lx, self.lz = torch.empty((0,dim_a),device=device), torch.empty((0,dim_z),device=device) # [T,dim_az]\n",
        "        self.sx = self.jepa.enc(torch.zeros((1, 3,64,64)))\n",
        "        self.la = torch.empty(0,device=device)\n",
        "\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        if len(self.la)>1 or laction!=None:\n",
        "            self.update_h0(lstate, laction)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                self.sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(self.sx, T=8, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.la, self.lx, self.lz = lact, lx, lz\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx - torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    self.la = torch.cat([torch.tensor(laction, device=device), self.la[len(laction):]], dim=-1)\n",
        "                la = self.emb(self.la[:seq_len])\n",
        "\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5) # torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        optim_z = torch.optim.SGD([lz], lr=1e1) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e0 ; 3e-2 1e-1\n",
        "        lsx, la = lsx.detach(), la.detach() # [T, d_model], [T, dim_a]\n",
        "        # print(\"update_h0 lz\", lz.data)\n",
        "        self.jepa.pred.train()\n",
        "        for i in range(1): # 1?\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                loss = F.mse_loss(out_, out.squeeze(0))\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            # print(\"update_h0 loss, lz\",i,loss.item(), lz.data)\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1].unsqueeze(0)\n",
        "        # print(\"update_h0\", self.lx.data)\n",
        "        # print(self.la.shape, self.lx.shape, self.lz.shape, self.la[seq_len:].shape, self.lx[seq_len:].shape, self.lz[seq_len:].shape)\n",
        "        self.la, self.lx, self.lz = self.la[seq_len:], self.lx[seq_len:], self.lz[seq_len:] # [T, dim_a], [T, dim_z]\n",
        "        return h0\n",
        "\n",
        "    def argm_s(self, sx, x, h0): # batch argm z for search\n",
        "        T, _ = x.shape\n",
        "        batch = 64 # 16\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        optim_z = torch.optim.SGD([z], lr=1e4, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        with torch.no_grad():\n",
        "            z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_z]\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, seq_len, dim_a]\n",
        "        # print(\"argm\", z[0].squeeze())\n",
        "        for i in range(2): # 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm z loss\", z[0].squeeze().data, loss[0].squeeze().data)\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return z[idx]\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        x = nn.Parameter(torch.empty((T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        optim_x = torch.optim.SGD([x], lr=1e3) # 1e-1,1e-0,1e4 ; 1e2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        with torch.no_grad(): x[:self.lx.shape[0]] = self.lx[:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        # print(\"search x\",x.squeeze().data)\n",
        "        for i in range(2): # 5\n",
        "            dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0) # [T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_.unsqueeze(0), z.unsqueeze(0), h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i, \"search x loss\", x.squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        return lact, lh0, x.data, z # [T], [T, num_layers, batch, d_model], [T, dim_a], [T, dim_z]\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lsx = torch.empty((batch, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1) # [batch, 1, d_model+dim_a/z]\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        syh0 = torch.cat([lsx, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,T,d_model], [T,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "        tcost = -self.tcost(syh0).unflatten(0, (batch, seq_len)).squeeze(-1)\n",
        "        c = (tcost + icost)*gamma**torch.arange(seq_len, device=device)\n",
        "        # if len(c.shape) == 1: print(\"rnn_pred c\", [f'{cc.item():g}' for cc in c.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        if len(tcost.shape) == 1: print(\"rnn_pred tcost\", [f'{cc.item():g}' for cc in tcost.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        return c.sum(), lh0\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd):\n",
        "        self.tcost.eval()\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "            lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "                for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                    syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                    out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                    lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                    lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "                repr_loss = F.mse_loss(lsy, lsy_)\n",
        "                syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "                clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "                # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "                cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            # sx=sy_\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "                lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_, h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    # with torch.no_grad(): lz.mul_(torch.rand_like(lz)).mul_((torch.rand_like(lz)>0.5).bool()) # dropout without scailing\n",
        "\n",
        "                    for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                        syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                        out_, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                        # sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                        sy_ = out_[:, -1, :].unsqueeze(1)\n",
        "                        lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                        lh0 = torch.cat((lh0, h0.unsqueeze(0)), dim=0)\n",
        "\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "\n",
        "                    pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "                    print(\"pred\",pred[0])\n",
        "                    print(\"rwd\",rwd[0])\n",
        "                    mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "                    # # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[0].cpu(), nrow=10))\n",
        "                    # # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "                loss = jloss + closs\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                # norm = torch.norm(lsy, dim=-1)[0][0].item()\n",
        "                # z_norm = torch.norm(z)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                # print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                scaler.scale(loss).backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.999)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "# !pip show torch triton\n",
        "# # !pip install --upgrade torch\n",
        "# !pip install --upgrade triton\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "# print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "# print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "# print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwgWasBjZ04u"
      },
      "outputs": [],
      "source": [
        "# print(agent.tcost._parameters['weight'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RERFWFMgA_",
        "outputId": "7614b6db-c4b7-467a-f4fc-7869ae3f7548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0229, -0.0159, -0.0247,  ...,  0.0336,  0.0319, -0.0009],\n",
            "        [-0.0306, -0.0346, -0.0081,  ..., -0.0064,  0.0082,  0.0179]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# print(agent.jepa.enc.parameters().values()[0].requires_grad)\n",
        "# for name, param in agent.tcost.named_parameters():\n",
        "# # # for name, param in agent.named_parameters():\n",
        "# #     # print(name, param.requires_grad)\n",
        "#     print(name, param)\n",
        "\n",
        "for name, param in agent.tcost.named_parameters(): print(param.data)\n",
        "\n",
        "# print(agent.tcost.1.weight.data)\n",
        "\n",
        "# print(agent.tcost.named_parameters()['tcost.1.weight'])\n",
        "\n",
        "# print(vars(agent.jepa.exp.named_parameters()['exp.1.weight']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "UEH1P802JkHU",
        "outputId": "31b3efd5-1338-4f55-9345-76a8d9371905"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'state' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2eab810ffe5c>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# sx = agent.jepa.enc(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# lact, lh0, lx, lz = agent.search(sx, T=6, h0=h0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# dim_a, dim_z = 3, 8\n",
        "# batch, T = 4,6\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_a),device=device))\n",
        "# torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "# dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# x = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "# z = nn.Parameter(torch.zeros((batch, T, dim_z),device=device))\n",
        "# torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# state = torch.zeros((1, 3,64,64))\n",
        "# # state = torch.rand((1, 3,64,64), device=device)\n",
        "# sx = agent.jepa.enc(state)\n",
        "\n",
        "act = agent([state], k=4)\n",
        "# h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "# lact, lh0, lx, lz = agent.search(sx, T=6, h0=h0)\n",
        "# loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "# print(loss,c)\n",
        "# print(lact, lh0, lx, lz)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4_b7ZSW6IF1-"
      },
      "outputs": [],
      "source": [
        "# !gdown 1bGWBbcKUgHESkbD3NfYt1WWikScVSFOj -O agentoptim.pkl # M1 gru3 tcost1\n",
        "# !gdown 1XBDhD2efIFW9lnewGRLrb362w47a8b1q -O agentoptim.pkl # B2 gru3 tcost1\n",
        "# !gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3\n",
        "# !gdown 1zoZ52jctM0jed6TgD7kAwrtnuDMeA5II -O agentoptim.pkl # T4 gru1 tcost1 drop\n",
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "# !gdown 1UDgNtFsWGAhvqR9lwA0QbMLhUtmip4ne -O agentoptim.pkl # M1 agentoptimgru3tcost1\n",
        "# !gdown 1-0oc6yucS5JXLHX1zqbYe3NTVMuhP_5r -O agentoptim.pkl # A2 agentoptim25251c25z3\n",
        "# !gdown 1U1CuCU1FugkrzPXsvTPpIX-wzWz6szl2 -O agentoptim.pkl # T4 agentoptimargm\n",
        "# !gdown 1CWZAtiEwSnglClJbq2LJTYlKhPN10gfo -O agentoptim.pkl # S3 agentoptimargm\n",
        "# !gdown 1XAbr6l1pCmcUCKR6kYlQ_dSDsOBqRg_j -O agentoptim.pkl # B2 argm2search2\n",
        "# !gdown 1UkQuf-IC2LYErSapkF6rZM1dv3svGI5P -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1-4sNf6mINCiD5YsBdQvCrlyqzzfS64si -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1MV9Qj_53Vu6wpe7nOFn47M5vDj7F7-gv -O agentoptim.pkl # S3 agentoptimargm2\n",
        "# !gdown 1--1Vl3337zugQng-j1qbptFY8EvhZA-T -O agentoptim.pkl # T4 agentoptimargm3 online\n",
        "# !gdown 1XHFBVPSH4T4FpUOBKN8X20xDQLNmL7go -O agentoptim.pkl # M1 agentoptimargm4\n",
        "# !gdown 1fFXsee_cSZxhTRewD7ZkGT68NXeq8OcH -O agentoptim.pkl # B2 agentoptimargm4\n",
        "\n",
        "# !gdown 1sCW9uvcdCJkCH5HQDdISLws5rMvmkmFR -O all_sd.pkl # M1 all_sd\n",
        "\n",
        "import pickle\n",
        "# !gdown 1j9hOq8_752duPB0PMYUJqabNvYoGLysX -O buffer512down.pkl # S\n",
        "# with open('buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY -O buffer512.pkl # S\n",
        "# with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB -O buffergo.pkl # S3\n",
        "# !gdown 1egXy0t_kn0M0oL6sbwixoVr7bqMfcB8j -O buffergo.pkl # T4\n",
        "# !gdown 1-34fhOMTdMvtuAeHuL28Y4taSINvOejQ -O buffergo.pkl # B2\n",
        "with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "45336c5e-115d-478b-c38c-4d79dca19610",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "# with open(folder+'buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptimargm4.pkl', map_location=device).values()\n",
        "modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# modelsd = transfer_sd(agent.state_dict(), modelsd)\n",
        "agent.load_state_dict(modelsd, strict=False)\n",
        "# # optimsd = transfer_optim(agent.state_dict(), modelsd, optim.state_dict(), optimsd)\n",
        "optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = torch.load(folder+'all_sd.pkl', map_location=device)\n",
        "# # all_sd = torch.load('all_sd.pkl', map_location=device)\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in all_sd.items())\n",
        "# allsd = {}\n",
        "# for (k, v) in all_sd.items():\n",
        "#     try: allsd[convert[k]] = v\n",
        "#     except Exception as e: print('dict err', e)\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# tgt_sd = load_sd(agent.state_dict(), allsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# for i, (k,v) in enumerate(modelsd.items()):\n",
        "# for i, (k,v) in enumerate(agent.state_dict().items()):\n",
        "#     print(i,k,v.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "# buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# checkpoint = {'model': agentsd, 'optimizer': optim.state_dict(),}\n",
        "checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "torch.save(checkpoint, folder+'agent_nores.pkl')\n",
        "# torch.save(checkpoint, 'agentoptim.pkl')\n",
        "\n",
        "# all_sd = {}\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# all_sd = store_sd(all_sd, agentsd)\n",
        "# # torch.save(all_sd, 'all_sd.pkl')\n",
        "# torch.save(all_sd, folder+'all_sd.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "NVcknabHMxH6"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in self.process(buffer) for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def process(self, buffer):\n",
        "        cleaned = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "        cleaned = [episode[-random.randint(20, 100):] for episode in cleaned]\n",
        "        random.shuffle(cleaned)\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "\n",
        "    # def pop_unif(self, buffer_, n=3):\n",
        "    #     buffer_.pop(random.randrange(len(buffer_)))\n",
        "    #     return buffer_\n",
        "\n",
        "# while len(train_data.data)>10000:\n",
        "#     buffer.pop(random.randrange(len(buffer)))\n",
        "#     train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 64 #512\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True)\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # # [3,T,batch]\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "1e3fpbtNOiz1",
        "outputId": "7cfa3448-644d-4210-b4e6-8c4ab93839ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.,  0., -1., -1., -1.,  0.,  0., -1., -1.,  0.])\n",
            "tensor([ 0., -1., -1., -1., -1., -1., -1.,  0.,  0., -1.])\n",
            "tensor([-1.,  0., -1., -1.,  0., -1.,  0., -1., -1.,  0.])\n",
            "tensor([ 0., -1., -1., -1., -1., -1.,  0., -1., -1., -1.])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (40x512 and 256x256)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b23656e238b2>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0msyh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_loss_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0bdec6730e58>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (40x512 and 256x256)"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "ctrain_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    ctrain_data=list(zip(state,reward))\n",
        "    ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "trainiter = iter(c_loader)\n",
        "images, labels = next(trainiter)\n",
        "# images, labels = images.to(device), labels.to(device)\n",
        "batch=40\n",
        "images, labels = images[:batch], labels[:batch]\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# print(labels)\n",
        "for x in range(len(labels)//10):\n",
        "    print(labels[10*x:10*x+10])\n",
        "\n",
        "# # try:\n",
        "with torch.no_grad():\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "    # _, world_state = agent.get(images.to(device))\n",
        "    # pred = agent.tcost(agent.jepa.enc(world_state.unsqueeze(1))).squeeze(-1).cpu()\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch, agent.d_model), device=device)\n",
        "    # h0 = torch.empty((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device)\n",
        "    # torch.nn.init.xavier_normal_(h0)\n",
        "    sy = agent.jepa.enc(images.to(device)) # [batch_size, d_model]\n",
        "    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "    pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "\n",
        "    # print(pred)\n",
        "    for x in range(len(pred)//10):\n",
        "        print(pred[10*x:10*x+10])\n",
        "    # print((labels==pred).sum())\n",
        "# except: pass\n",
        "print(agent.tcost.loss(syh0, labels.to(device)).squeeze(-1))\n",
        "print(F.mse_loss(labels, pred))\n",
        "\n",
        "# torch.where(abs(labels- pred)>0.5,1,0)\n",
        "for x in range(len(pred)//10):\n",
        "    print(torch.where(abs(labels- pred)>0.5,1,0)[10*x:10*x+10])\n",
        "\n",
        "mask = torch.where(abs(labels- pred)>0.5,1,0).bool()\n",
        "print(\"reward, pred\", labels[mask].data, pred[mask].data)\n",
        "try: imshow(torchvision.utils.make_grid(images[mask], nrow=10))\n",
        "except ZeroDivisionError: pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viimAIpYSJq_"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels = torch.tensor([0])\n",
        "# pred = torch.tensor([[.999,.001]])\n",
        "pred = torch.tensor([[1.,0.]])\n",
        "pred = torch.tensor([[5.,-5.]])\n",
        "# pred = torch.tensor([[.5,.5]])\n",
        "# pred = torch.tensor([[1/a, 1/(1-a)]])\n",
        "# pred = torch.tensor([[1/(1-a), 1/a]])\n",
        "# print(F.mse_loss(labels, pred))\n",
        "\n",
        "pred = torch.rand(10,2)\n",
        "pred = nn.Softmax(dim=-1)(pred)\n",
        "print(pred)\n",
        "labels = torch.where(torch.rand(10)>0.5,1,0)\n",
        "\n",
        "\n",
        "a=10\n",
        "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)]))\n",
        "print(loss_fn(pred, labels))\n",
        "\n",
        "# print((pred@torch.log(pred).T).sum())\n",
        "# print(pred,torch.log(pred).T)\n",
        "\n",
        "# 0.6931\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksm4ha7XA-BN"
      },
      "outputs": [],
      "source": [
        "# optim = torch.optim.SGD(agent.parameters(), 1e-1, momentum=0.9, dampening=0, weight_decay=0)\n",
        "# print(optim.param_groups[0][\"lr\"])\n",
        "# print(optim)\n",
        "optim.param_groups[0][\"lr\"] = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OksdjCeJYpYh",
        "outputId": "3d976578-917a-4306-8bc9-211df18f7571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-2f08d6d8256a>:237: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-28-2f08d6d8256a>:203: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        -1.1639e-01, -1.8969e-03, -3.5548e-04, -3.0518e-03, -1.5308e-01,\n",
            "        -8.4457e-03, -9.5010e-05, -4.3726e-04, -4.3726e-04, -1.9562e-04,\n",
            "        -3.6068e-03, -9.3311e-01, -4.0192e-02, -1.3405e-02, -1.2695e-01,\n",
            "        -9.9561e-01, -4.7266e-01, -4.4220e-02, -1.4524e-03, -4.1504e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0658985897898674 0.00589752197265625 1.5666611194610596 0.3593037724494934 57\n",
            "pred tensor([-1.8909e-01, -2.3270e-02, -2.9945e-04, -3.6836e-04, -1.8206e-03,\n",
            "        -7.8392e-04, -1.8668e-04, -1.1277e-04, -4.7455e-03, -3.9490e-02,\n",
            "        -9.4748e-04, -1.3709e-04, -8.5068e-04, -5.0697e-03, -3.9160e-05,\n",
            "        -2.9469e-04, -1.2982e-04, -3.7336e-04, -1.0973e-04, -3.1853e-03,\n",
            "        -5.4216e-04, -7.3195e-04, -1.8024e-04, -2.2629e-02, -9.1064e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04750586301088333 0.0037479400634765625 1.618835687637329 0.342301607131958 81\n",
            "pred tensor([-9.9468e-04, -1.3123e-02, -8.9493e-03, -3.5942e-05, -4.0531e-06,\n",
            "        -2.0862e-06, -7.1526e-07, -1.1921e-07, -1.7679e-04, -7.7486e-06,\n",
            "        -1.2398e-05, -2.6798e-04, -8.3780e-04, -3.8671e-04, -6.7353e-05,\n",
            "        -4.7150e-02, -3.0823e-03, -1.0231e-02, -1.7181e-02, -1.3304e-03,\n",
            "        -5.2490e-03, -6.1083e-04, -1.8060e-05, -3.3319e-05, -8.4162e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06105462834239006 0.003498077392578125 1.589723825454712 0.32699069380760193 43\n",
            "pred tensor([-2.2054e-05, -2.4724e-04, -1.8740e-04, -4.7755e-04, -2.8801e-04,\n",
            "        -3.7551e-04, -1.0973e-04, -6.9332e-04, -2.0351e-03, -4.1161e-03,\n",
            "        -5.9426e-05, -4.0674e-04, -5.3072e-04, -2.3508e-04, -9.3877e-05,\n",
            "        -7.5161e-05, -5.3263e-04, -4.7660e-04, -2.9926e-03, -1.0000e+00,\n",
            "        -3.9429e-01, -3.5591e-03, -4.6825e-04, -5.2686e-01, -8.2970e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04648524522781372 0.0008730888366699219 1.7465898990631104 0.3441516160964966 62\n",
            "pred tensor([-6.2037e-04, -9.1732e-05, -6.8426e-05, -7.0870e-05,  0.0000e+00,\n",
            "        -1.4365e-05, -2.9802e-07, -1.4889e-04, -3.4571e-06, -1.8477e-06,\n",
            "        -9.0003e-06, -2.9445e-05, -1.0192e-05, -5.7220e-06, -9.8348e-06,\n",
            "        -3.5346e-05, -5.5194e-05, -3.2187e-05, -6.2525e-05, -9.1016e-05,\n",
            "        -3.0220e-05, -1.1325e-06, -1.5736e-03, -9.7156e-06, -4.3809e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05984538048505783 0.0003857612609863281 1.80649995803833 0.32819488644599915 44\n",
            "pred tensor([-3.7909e-05, -4.9472e-06, -1.9729e-05, -4.6134e-05, -4.0531e-04,\n",
            "        -1.0073e-04, -1.2100e-05, -6.0141e-05, -5.1618e-05, -2.7704e-04,\n",
            "        -9.5367e-06, -1.8001e-05, -1.0147e-03, -1.6069e-03, -3.0780e-04,\n",
            "        -6.2370e-04, -1.6737e-04, -9.8765e-05, -2.3594e-03, -8.8215e-05,\n",
            "        -1.3456e-03, -5.2273e-05, -1.5295e-04, -2.6131e-04, -2.5129e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.049444589763879776 0.0009150505065917969 1.7532970905303955 0.3663884103298187 71\n",
            "pred tensor([-8.5592e-04, -7.2899e-03, -1.6266e-02, -2.1696e-05, -5.9662e-02,\n",
            "        -1.0000e+00, -1.2696e-05, -5.9605e-08, -6.5565e-06, -5.9605e-08,\n",
            "         0.0000e+00, -2.3365e-05, -2.4855e-05, -3.7289e-03, -1.1921e-07,\n",
            "        -1.4901e-06, -1.0431e-05, -2.0862e-06, -1.8525e-04, -2.3594e-03,\n",
            "        -1.1158e-03, -7.8392e-04, -2.0587e-04, -4.4107e-06, -3.0935e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06260998547077179 0.001079559326171875 1.7614781856536865 0.328294038772583 51\n",
            "pred tensor([-3.5906e-04, -1.4150e-04, -3.7551e-06, -1.0848e-05, -3.0220e-05,\n",
            "        -2.4199e-05, -1.1269e-02, -4.6783e-02, -3.3691e-01, -4.3726e-04,\n",
            "        -1.4816e-02, -3.1796e-03, -1.9252e-05, -6.7592e-05, -6.3002e-05,\n",
            "        -2.7370e-04, -8.3113e-04, -2.2423e-04, -5.6362e-04, -4.8103e-03,\n",
            "        -8.5735e-04, -9.5010e-05, -2.5690e-05, -9.9182e-05, -2.6846e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04846831038594246 0.00121307373046875 1.6436543464660645 0.3554215729236603 76\n",
            "pred tensor([-7.0267e-03, -1.7130e-04, -8.5831e-06, -5.9605e-08,  0.0000e+00,\n",
            "        -4.4107e-06, -1.1915e-04, -4.3511e-05, -3.6621e-02, -4.2496e-03,\n",
            "        -2.9683e-05, -4.0352e-05, -1.3137e-04, -3.0112e-04, -2.9984e-03,\n",
            "        -1.0000e+00, -1.0109e-04, -2.3842e-07, -3.3975e-06, -5.5194e-05,\n",
            "        -1.1063e-04, -5.5850e-05, -6.2764e-05, -5.1856e-05, -4.9114e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06052856892347336 0.001766204833984375 1.6573827266693115 0.34582701325416565 57\n",
            "pred tensor([-1.8716e-05, -6.3753e-04, -2.6464e-05, -2.4247e-04, -5.3287e-05,\n",
            "        -5.1022e-05, -1.4048e-03, -2.0790e-03, -1.2379e-03, -1.1425e-03,\n",
            "        -9.6985e-02, -6.0844e-03, -4.4518e-03, -1.0920e-03, -1.5221e-02,\n",
            "        -2.3139e-04, -5.5933e-04, -1.1768e-03, -1.1820e-04, -3.0688e-01,\n",
            "        -9.0408e-03, -5.1123e-01, -2.8467e-01, -3.9363e-04, -6.1417e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05050958693027496 0.00386810302734375 1.5646377801895142 0.3530929684638977 79\n",
            "pred tensor([-8.4305e-03, -2.3689e-03, -1.8274e-01, -5.2738e-04, -9.9561e-01,\n",
            "        -1.0000e+00, -5.9605e-08, -1.1921e-07, -6.6161e-06, -6.3248e-03,\n",
            "        -9.7217e-01, -1.0000e+00, -1.0133e-06, -3.2783e-06,  0.0000e+00,\n",
            "        -4.3511e-06, -1.4901e-06, -8.6427e-06, -5.9605e-08, -4.2498e-05,\n",
            "        -5.8413e-06, -2.0862e-06, -3.1710e-05, -3.5763e-07, -2.4319e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.059405367821455 0.00823974609375 1.4676904678344727 0.32836511731147766 51\n",
            "pred tensor([-3.9935e-06, -1.6093e-06, -1.2636e-05, -5.3644e-07, -2.0564e-05,\n",
            "        -2.9802e-06, -8.9407e-07, -3.8147e-06, -9.2850e-03, -9.9731e-02,\n",
            "        -3.5346e-05, -2.5749e-05, -5.1003e-03, -1.2517e-06, -1.2290e-04,\n",
            "        -1.9014e-05, -3.2067e-04, -2.7776e-05, -1.8143e-02, -4.0454e-01,\n",
            "        -1.0000e+00, -8.9586e-05, -3.9983e-04, -1.3340e-04, -7.0930e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050742123275995255 0.003414154052734375 1.6336638927459717 0.3516994118690491 73\n",
            "pred tensor([-1.1894e-02, -2.7370e-04, -2.2736e-03, -4.2498e-05, -1.5497e-06,\n",
            "        -1.8530e-03, -1.0841e-02, -1.3661e-04, -1.6999e-04, -1.3173e-05,\n",
            "        -2.4498e-05, -3.6955e-06, -5.9605e-08, -9.9468e-04, -5.9605e-08,\n",
            "        -1.0000e+00,  0.0000e+00, -5.9605e-08, -1.1921e-07,  0.0000e+00,\n",
            "        -2.9087e-05, -1.1921e-06, -1.2517e-06, -2.0337e-04, -1.0610e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.061583660542964935 0.001789093017578125 1.6670384407043457 0.33049872517585754 52\n",
            "pred tensor([-7.1669e-04, -6.1249e-02, -1.2386e-04, -8.6427e-06, -2.8458e-03,\n",
            "        -8.8120e-04, -5.2738e-04, -1.5080e-05, -1.1005e-03, -4.1986e-04,\n",
            "        -2.4872e-03, -3.5286e-04, -4.7565e-05, -6.0201e-06, -5.1117e-04,\n",
            "        -1.2636e-05, -8.3506e-05, -5.6028e-06, -1.7762e-05, -6.9046e-04,\n",
            "        -9.3520e-05, -1.1625e-03, -3.9506e-04, -3.8965e-01, -7.4585e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.051401328295469284 0.0006184577941894531 1.7528233528137207 0.3416734039783478 63\n",
            "pred tensor([-1.9669e-02, -2.9182e-03, -1.7204e-03, -1.5497e-06, -3.4070e-04,\n",
            "        -2.7418e-06, -1.7881e-07, -1.8568e-03, -3.0994e-06, -9.9540e-06,\n",
            "        -1.0073e-05, -4.0829e-05, -1.5199e-05, -6.3002e-05, -9.0301e-05,\n",
            "        -1.6689e-06, -3.8815e-04, -1.2815e-05, -2.5902e-03, -4.9472e-05,\n",
            "        -2.4021e-05, -1.2398e-05, -8.1062e-06, -2.9087e-05, -7.2002e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.057385556399822235 0.002552032470703125 1.6760001182556152 0.3222846984863281 23\n",
            "pred tensor([-3.4153e-05, -3.3855e-04, -2.9697e-03, -5.6505e-05, -1.9646e-04,\n",
            "        -9.1839e-04, -7.2217e-01, -1.0000e+00, -8.5235e-06, -6.7329e-04,\n",
            "        -1.2934e-05, -1.0133e-06, -3.8087e-05, -3.8090e-03, -2.1000e-03,\n",
            "        -1.0109e-02, -7.7705e-03, -1.5764e-03, -3.6068e-03, -2.8014e-04,\n",
            "        -2.7370e-04, -1.0099e-03, -3.0098e-03, -2.0659e-04, -1.1635e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050364598631858826 0.0013599395751953125 1.6890376806259155 0.3583875298500061 62\n",
            "pred tensor([-8.5735e-04, -1.2112e-03, -8.2970e-04, -5.0664e-06, -1.3113e-06,\n",
            "        -2.1398e-04, -5.9605e-07, -4.5919e-04, -5.7220e-06, -2.3193e-03,\n",
            "        -9.4235e-05, -1.2215e-02, -4.3809e-05, -6.4373e-06, -3.6478e-05,\n",
            "        -4.4107e-06, -3.2158e-03, -8.5473e-05, -1.8954e-05, -7.3471e-03,\n",
            "        -1.0147e-03, -1.2338e-05, -1.5080e-05, -1.3828e-05, -1.2219e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05971662327647209 0.0006279945373535156 1.7314515113830566 0.3216491639614105 20\n",
            "pred tensor([-3.4153e-05, -2.3234e-04, -4.8780e-04, -7.0286e-04, -3.6895e-05,\n",
            "        -1.3709e-05, -1.2457e-05, -1.6153e-04, -7.5817e-04, -3.5167e-06,\n",
            "        -1.6689e-06, -1.8179e-05, -2.5415e-04, -1.4889e-04, -1.9014e-05,\n",
            "        -1.0431e-04, -5.2490e-03, -2.3544e-05, -9.4235e-05, -1.2865e-03,\n",
            "        -2.5451e-05, -2.2340e-04, -2.3365e-03, -2.6727e-04, -1.6928e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05110649764537811 0.0005359649658203125 1.7507630586624146 0.3472186326980591 56\n",
            "pred tensor([-2.8114e-03, -4.8859e-02, -1.7414e-03, -8.5498e-01, -2.3849e-02,\n",
            "        -1.0000e+00, -5.9605e-08, -1.0729e-05, -2.3651e-03, -6.3181e-06,\n",
            "        -2.7156e-04, -1.1539e-03, -2.3468e-02, -6.2180e-03, -8.1205e-04,\n",
            "        -4.1127e-06, -1.2636e-04, -4.8280e-06, -1.1921e-06, -2.7418e-06,\n",
            "        -7.6294e-06, -1.6632e-02, -1.5221e-02, -1.6868e-04, -6.2048e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06427975744009018 0.0019216537475585938 1.6573047637939453 0.32591959834098816 40\n",
            "pred tensor([-3.8391e-02, -9.8801e-03, -2.3723e-05, -4.8697e-05, -5.7399e-05,\n",
            "        -5.4836e-06, -2.1338e-05, -9.0771e-01, -2.4158e-01, -9.2139e-01,\n",
            "        -1.0000e+00, -8.4639e-06, -2.9802e-07, -1.2159e-05, -6.5565e-05,\n",
            "        -1.8096e-04, -3.1829e-05, -2.2141e-02, -2.2423e-04, -3.2783e-06,\n",
            "        -3.9744e-04, -2.8488e-02, -5.6744e-05, -8.2550e-03, -2.8782e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04666648432612419 0.002048492431640625 1.7008085250854492 0.3417232632637024 26\n",
            "pred tensor([-7.3891e-03, -1.0986e-03, -7.1239e-04, -2.5034e-06,  0.0000e+00,\n",
            "        -7.7486e-07, -1.0073e-04, -1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -5.9605e-08,  0.0000e+00, -7.1526e-06, -3.1590e-06, -1.9670e-06,\n",
            "        -3.2067e-05, -3.9339e-06, -8.2254e-06, -5.9605e-08, -4.1723e-07,\n",
            "        -8.3447e-07, -2.4378e-05, -9.5367e-07, -2.0266e-06, -3.2067e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0637897253036499 0.002777099609375 1.6389222145080566 0.322854220867157 22\n",
            "pred tensor([-6.6817e-05, -5.9319e-04, -2.3317e-04, -1.4439e-03, -2.0172e-02,\n",
            "        -9.7656e-03, -2.4927e-01, -2.3842e-05, -8.6927e-04, -4.1127e-06,\n",
            "        -1.3185e-04, -7.3318e-03, -8.1253e-03, -7.5758e-05, -9.1016e-05,\n",
            "        -6.1417e-04, -1.3046e-03, -5.9605e-08, -1.0192e-05, -5.9605e-08,\n",
            "        -1.7881e-07, -1.9872e-04, -5.2214e-04, -4.9889e-05, -1.4889e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04543285444378853 0.003154754638671875 1.6392232179641724 0.32951053977012634 36\n",
            "pred tensor([-9.9951e-01, -5.1308e-04, -1.6284e-04, -9.3877e-05, -9.7156e-06,\n",
            "        -2.3102e-02, -3.3200e-05, -4.9927e-02, -7.2384e-04, -5.0545e-04,\n",
            "        -2.4819e-04, -9.7990e-05, -4.4942e-04, -1.8606e-03, -4.1187e-05,\n",
            "        -1.4484e-05, -1.1139e-03, -5.1641e-04, -1.8597e-04, -2.0027e-04,\n",
            "        -2.4033e-02, -1.4931e-02, -1.4999e-02, -7.1383e-04, -2.7776e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06599389016628265 0.0026092529296875 1.6664247512817383 0.3550835847854614 39\n",
            "pred tensor([-2.0764e-01, -4.3297e-03, -4.2801e-03, -9.7900e-01, -3.6469e-02,\n",
            "        -4.0531e-06, -1.8525e-04, -3.2783e-06, -2.6722e-03, -2.1994e-04,\n",
            "        -8.0750e-02, -7.2837e-05, -8.3466e-03, -8.7769e-02, -5.6028e-06,\n",
            "        -9.5725e-05, -1.4186e-05, -1.0590e-02, -6.6280e-04, -1.9336e-04,\n",
            "        -2.1660e-04, -1.2650e-02, -1.2481e-04, -1.6518e-03, -2.1565e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04899488389492035 0.00273895263671875 1.6562758684158325 0.3792896866798401 49\n",
            "pred tensor([-2.7490e-04, -4.0460e-04, -3.7651e-03, -2.3842e-06,  0.0000e+00,\n",
            "         0.0000e+00, -5.9605e-08, -1.5378e-05, -1.9670e-05, -4.7684e-06,\n",
            "        -7.7486e-07, -3.1948e-05, -2.3484e-05, -9.8348e-06, -3.2759e-04,\n",
            "        -1.0000e+00, -9.3579e-06, -5.9605e-07, -3.8743e-06, -4.6670e-05,\n",
            "        -3.1590e-06, -2.6405e-05, -1.4246e-05, -2.2054e-06, -1.5736e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06590081006288528 0.0011081695556640625 1.7326018810272217 0.36887750029563904 38\n",
            "pred tensor([-5.9605e-07, -4.0531e-06, -8.8318e-02, -1.4439e-03, -3.6068e-03,\n",
            "        -3.0212e-03, -1.6797e-04, -1.9670e-05, -7.9651e-03, -9.3269e-04,\n",
            "        -4.1842e-05, -1.7004e-03, -2.0742e-04, -2.0584e-02, -4.7207e-05,\n",
            "        -3.3975e-06, -3.4666e-04, -8.8215e-05, -2.5129e-04, -3.5000e-04,\n",
            "        -3.0100e-05, -6.7997e-04, -3.6144e-03, -6.0463e-04, -2.2369e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04720587655901909 0.0016155242919921875 1.6682888269424438 0.32820925116539 34\n",
            "pred tensor([-2.5690e-05, -1.3769e-04, -1.1867e-04, -3.5763e-07, -5.9605e-07,\n",
            "         0.0000e+00, -6.2764e-05, -8.8184e-01, -1.0000e+00, -1.1921e-06,\n",
            "         0.0000e+00, -3.5763e-06, -6.5517e-04, -8.6486e-05, -1.6451e-05,\n",
            "        -1.0529e-03, -6.3133e-03, -5.2826e-02, -6.4790e-05, -1.3227e-03,\n",
            "        -9.1309e-01, -1.2493e-03, -1.1620e-02, -7.0381e-03, -9.5654e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06055621802806854 0.004207611083984375 1.5148029327392578 0.3246672451496124 34\n",
            "pred tensor([-6.0498e-01, -1.6144e-02, -8.1885e-01, -1.0000e+00, -1.0000e+00,\n",
            "        -5.5850e-05, -6.2637e-03, -6.5899e-04, -1.9159e-03, -2.2697e-04,\n",
            "        -3.5167e-06, -3.2842e-05, -3.9597e-03, -2.2697e-04, -7.3135e-05,\n",
            "        -4.1306e-05, -1.1377e-03, -3.7003e-03, -2.1148e-04, -1.0780e-02,\n",
            "        -2.1152e-03, -1.4091e-04, -2.1954e-03, -4.3821e-04, -7.4883e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04863125830888748 0.002872467041015625 1.5957446098327637 0.35062044858932495 48\n",
            "pred tensor([-4.0841e-04, -2.5375e-02, -4.2000e-03, -2.8610e-05, -1.6153e-04,\n",
            "        -6.6042e-04, -2.2411e-05, -1.3399e-04, -1.3053e-05, -1.9073e-06,\n",
            "        -5.1439e-05, -1.7285e-05, -1.0431e-05, -2.6226e-06, -9.8419e-03,\n",
            "        -8.7786e-04, -9.7752e-06, -3.6049e-04, -1.2517e-06, -1.4544e-04,\n",
            "        -5.9664e-05, -1.6797e-04, -1.5602e-02, -1.3590e-05, -2.6822e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.062184471637010574 0.001468658447265625 1.6658343076705933 0.3742946684360504 39\n",
            "pred tensor([-1.0000e+00, -4.5419e-05, -2.3842e-07, -2.3842e-07, -1.1504e-05,\n",
            "        -1.4473e-02, -5.3453e-04, -8.0585e-05, -4.7684e-07, -3.5763e-07,\n",
            "        -3.9935e-06, -2.0182e-04, -8.5115e-05, -6.6817e-05, -6.6578e-05,\n",
            "        -1.8024e-04, -3.3081e-05, -1.3709e-05, -1.9092e-01, -1.3863e-02,\n",
            "        -1.0000e+00, -6.4015e-05, -2.2888e-05, -3.4070e-04, -1.2941e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04977143183350563 0.0013599395751953125 1.6312590837478638 0.36995476484298706 67\n",
            "pred tensor([-3.0351e-04, -5.3287e-05, -4.8280e-06, -4.4518e-03, -2.8312e-05,\n",
            "        -1.3351e-05, -4.4525e-05, -1.6689e-06, -1.0014e-05, -7.5459e-05,\n",
            "        -1.8299e-05, -5.4836e-06, -2.6584e-05, -2.8133e-04, -3.2961e-05,\n",
            "        -5.1022e-05, -2.0266e-06, -1.2994e-05,  0.0000e+00, -5.9605e-08,\n",
            "        -3.4571e-06, -6.2764e-05, -1.0000e+00, -2.9802e-07,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06452064961194992 1.52587890625e-05 1.9435354471206665 0.33378639817237854 61\n",
            "pred tensor([-2.9697e-03, -9.6191e-02, -1.1803e-02, -1.3089e-04, -1.2040e-05,\n",
            "        -6.3019e-03, -6.7890e-05, -6.8545e-06, -7.2241e-04, -1.8631e-02,\n",
            "        -1.3151e-03, -4.5654e-01, -6.4746e-01, -5.9521e-01, -5.0049e-01,\n",
            "        -1.2146e-02, -2.5368e-03, -2.0623e-05, -1.6356e-03, -2.8563e-04,\n",
            "        -9.9951e-01, -1.0000e+00, -1.0000e+00, -5.5850e-05, -5.3048e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05109797418117523 0.0005140304565429688 1.7595704793930054 0.35490164160728455 79\n",
            "pred tensor([-5.2490e-03, -1.9159e-03, -5.1079e-03, -2.9802e-07, -5.3644e-07,\n",
            "        -1.6689e-06,  0.0000e+00, -5.4955e-05, -1.5335e-03, -1.3292e-04,\n",
            "        -2.5034e-06, -1.4424e-04, -5.1856e-06, -1.0550e-05, -8.2850e-06,\n",
            "        -2.2054e-06, -5.0640e-04, -2.9802e-07, -1.6630e-05, -1.6093e-06,\n",
            "        -8.2195e-05, -9.8133e-04, -2.8896e-03, -8.4162e-05, -6.7592e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06416545063257217 0.0021820068359375 1.6194099187850952 0.34543395042419434 86\n",
            "pred tensor([-1.0192e-04, -2.1076e-04, -3.3855e-05, -1.0192e-04, -9.5844e-04,\n",
            "        -8.2016e-04, -9.2387e-06, -1.4484e-05, -1.3100e-02, -1.3709e-05,\n",
            "        -1.6689e-06, -4.3988e-04, -5.5599e-04, -6.2764e-05, -1.7881e-04,\n",
            "        -2.8725e-03, -1.4091e-04, -6.1572e-05, -2.1225e-02, -4.5657e-04,\n",
            "        -1.8969e-03, -8.6441e-03, -1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05612577497959137 0.0016736984252929688 1.5948357582092285 0.3601844012737274 112\n",
            "3\n",
            "pred tensor([-4.0674e-04, -4.2963e-04, -1.0729e-05, -7.9989e-05, -8.0252e-04,\n",
            "        -5.2357e-04, -9.1370e-02, -6.0380e-05, -2.8634e-04, -1.8425e-03,\n",
            "        -3.5591e-03, -4.5227e-02, -1.3709e-05, -1.8358e-05, -3.6955e-06,\n",
            "        -5.0664e-06,  0.0000e+00, -4.6134e-05, -1.0548e-03, -1.1504e-05,\n",
            "        -7.4863e-05, -1.6630e-05, -1.5795e-05, -3.8004e-04, -3.0541e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.061937473714351654 0.001056671142578125 1.6516079902648926 0.33399543166160583 65\n",
            "pred tensor([-2.5034e-06, -3.9339e-06, -5.0664e-06, -1.0431e-04, -4.7088e-06,\n",
            "        -9.9659e-04, -8.7158e-01, -3.3970e-03, -8.6572e-01, -3.0853e-02,\n",
            "        -8.8623e-01, -9.4873e-01, -1.0000e+00, -1.0000e+00, -2.6822e-06,\n",
            "        -1.8716e-05, -1.7345e-05, -1.1820e-04, -3.3736e-05, -8.8871e-05,\n",
            "        -4.4861e-03, -6.7353e-05, -2.6846e-04, -1.1820e-04, -2.0111e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05295184627175331 0.0036773681640625 1.5447133779525757 0.3431413173675537 102\n",
            "pred tensor([-5.7268e-04, -8.8501e-03, -4.0430e-01, -1.9592e-01, -5.7411e-03,\n",
            "        -1.2722e-03, -5.0426e-05, -2.0790e-03, -3.6776e-05, -2.2430e-02,\n",
            "        -6.5039e-01, -9.3066e-01, -2.9443e-01, -1.0000e+00, -1.2875e-05,\n",
            "        -1.1921e-07, -2.0266e-06, -1.3709e-06, -7.2122e-06, -5.0449e-04,\n",
            "        -2.9981e-05, -8.2850e-05, -1.3709e-06, -2.2054e-06, -1.5020e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0588003508746624 0.005306243896484375 1.572074055671692 0.3321951925754547 58\n",
            "pred tensor([-2.6703e-05, -2.4533e-04, -7.7844e-05, -2.4498e-05, -1.6332e-05,\n",
            "        -8.3447e-07, -9.9850e-04, -1.4696e-03, -8.6486e-05, -5.1022e-05,\n",
            "        -1.1921e-05, -1.0639e-04, -1.4076e-03, -6.4621e-03, -1.2770e-03,\n",
            "        -5.8055e-05, -1.7536e-04, -4.1485e-04, -7.4506e-06, -4.8304e-04,\n",
            "        -1.0806e-04, -3.3200e-05, -1.0765e-04, -7.8082e-06, -6.2287e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05214383453130722 0.005462646484375 1.6683924198150635 0.3382537364959717 77\n",
            "pred tensor([-1.7679e-04, -8.2195e-05, -4.6730e-03, -2.5630e-06,  0.0000e+00,\n",
            "        -2.1219e-05, -1.0669e-05, -3.2187e-06, -9.2983e-06, -1.3709e-06,\n",
            "        -5.3644e-07, -1.3647e-03, -9.9182e-05, -1.6797e-04, -2.3305e-05,\n",
            "        -1.5497e-05, -3.4273e-05, -1.0729e-06, -4.5300e-04, -4.8399e-04,\n",
            "        -4.1723e-07, -1.1883e-03, -3.3627e-03, -2.7905e-03, -2.5864e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05728905647993088 0.0091705322265625 1.4963041543960571 0.3684057295322418 43\n",
            "pred tensor([-7.1350e-02, -3.3569e-03, -3.4131e-01, -1.0366e-03, -9.0933e-04,\n",
            "        -1.0729e-06, -2.9802e-07, -3.5801e-03, -3.2234e-03, -9.7949e-01,\n",
            "        -1.1133e-01, -1.0000e+00, -2.3842e-07,  0.0000e+00, -3.1805e-04,\n",
            "        -1.9073e-05, -4.6492e-06, -1.9312e-05, -2.5630e-06, -3.6359e-06,\n",
            "        -1.9073e-06, -3.5763e-07, -1.3232e-05, -1.5278e-03, -3.7932e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0497400276362896 0.001407623291015625 1.7427215576171875 0.33189815282821655 53\n",
            "pred tensor([-7.8106e-04, -3.8166e-03, -7.1168e-05, -5.8770e-05, -4.2319e-06,\n",
            "        -7.7486e-07, -1.0042e-03, -4.4703e-05, -7.5459e-05, -2.6405e-05,\n",
            "        -3.2306e-04, -1.0431e-05, -9.8765e-05, -4.4703e-06, -1.9717e-04,\n",
            "        -1.2755e-05, -1.9684e-03, -9.1457e-04, -3.6764e-04, -1.9133e-05,\n",
            "        -3.5763e-07, -4.0221e-04, -1.0000e+00, -2.6822e-06,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05619575083255768 0.000804901123046875 1.8066679239273071 0.3428781032562256 43\n",
            "pred tensor([-2.6226e-06, -2.3842e-07, -5.3644e-07, -7.5758e-05, -2.9206e-06,\n",
            "        -1.7881e-06, -2.1660e-04, -3.5691e-04, -9.6512e-03, -1.0567e-02,\n",
            "        -1.6342e-02, -1.2684e-04, -1.1997e-03, -4.2801e-03, -5.0831e-04,\n",
            "        -5.3787e-04, -1.1444e-05, -9.9951e-01, -1.2994e-05, -4.9114e-05,\n",
            "        -7.1526e-07, -9.5963e-06, -3.9062e-03, -4.2057e-04, -1.2350e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.041398487985134125 0.0007500648498535156 1.7984981536865234 0.37467917799949646 44\n",
            "pred tensor([-7.9775e-04, -3.5357e-04, -1.3293e-01, -8.0585e-05, -2.1782e-03,\n",
            "        -5.9668e-01, -5.1546e-04, -4.2432e-01, -7.2900e-01, -9.9658e-01,\n",
            "        -9.9951e-01, -1.0514e-04, -2.6941e-04, -2.7905e-03, -9.0659e-05,\n",
            "        -7.1526e-07, -3.0398e-06, -6.6340e-05, -3.7336e-04, -1.1820e-04,\n",
            "        -5.7638e-05, -2.4438e-06, -3.2723e-05, -4.0531e-05, -7.4244e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052948854863643646 0.00012731552124023438 1.837017297744751 0.3481292128562927 55\n",
            "pred tensor([-9.7754e-01, -8.1658e-06, -1.1921e-07,  0.0000e+00, -7.5493e-03,\n",
            "        -5.6922e-05, -1.2032e-02, -4.3144e-03, -3.9825e-03, -1.3542e-03,\n",
            "        -4.5824e-04, -6.7329e-04, -4.2319e-05, -1.1921e-07,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -2.9802e-06, -1.0000e+00, -1.0000e+00,\n",
            "        -1.6093e-06, -7.4506e-06, -2.6882e-05, -8.9407e-07, -1.3113e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.048864152282476425 0.00021219253540039062 1.7534620761871338 0.3569177985191345 74\n",
            "pred tensor([-2.3508e-04, -7.5493e-03, -4.6463e-03, -9.7370e-04, -3.2687e-04,\n",
            "        -9.4833e-03, -2.3193e-03, -1.7059e-04, -4.1962e-05, -1.6093e-06,\n",
            "        -1.2338e-05, -8.4043e-06, -1.1921e-07, -3.5167e-06,  0.0000e+00,\n",
            "        -2.3842e-07, -5.6922e-05, -9.8682e-01, -1.0000e+00, -9.7990e-05,\n",
            "        -1.1921e-07, -1.3709e-06, -2.9802e-07, -1.7285e-06, -2.6822e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05751229077577591 0.0012416839599609375 1.7266342639923096 0.33464351296424866 70\n",
            "pred tensor([-2.0862e-06, -7.7486e-07, -4.0531e-06, -5.6028e-06, -1.3709e-06,\n",
            "        -5.7220e-06, -5.9605e-07, -3.5226e-05, -5.6624e-06, -1.0431e-05,\n",
            "        -1.8740e-04, -1.9944e-04, -3.7659e-02, -3.1257e-04, -5.7227e-01,\n",
            "        -9.7900e-01, -9.1016e-01, -4.3988e-04, -1.0229e-01, -2.6169e-03,\n",
            "        -2.5320e-04, -2.7704e-04, -1.1711e-02, -2.0993e-04, -3.8815e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05474118888378143 0.0010747909545898438 1.7571983337402344 0.35857725143432617 122\n",
            "pred tensor([-1.0080e-03, -7.0667e-04, -5.9748e-04, -7.9870e-06, -3.5763e-07,\n",
            "        -1.1921e-07, -5.9605e-08, -1.6093e-06, -1.1963e-04, -1.9729e-05,\n",
            "        -2.5010e-04, -6.9737e-06, -2.2054e-06, -2.8610e-06, -1.0133e-05,\n",
            "        -1.1921e-06, -9.9540e-06, -6.0225e-04, -1.2665e-03, -2.6264e-03,\n",
            "        -1.2331e-03, -7.8082e-06, -1.6415e-04, -8.2159e-04, -1.7464e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05685367435216904 0.002719879150390625 1.569612979888916 0.3332473635673523 65\n",
            "pred tensor([-3.5143e-04, -1.1768e-03, -1.1981e-05, -1.1504e-05, -6.8665e-04,\n",
            "        -3.3021e-04, -7.3373e-05, -5.4836e-04, -7.7009e-04, -1.3752e-03,\n",
            "        -8.9169e-04, -5.9605e-07, -9.1934e-03, -1.4336e-02, -1.1456e-04,\n",
            "        -4.1008e-05, -1.0806e-04, -4.2319e-06, -4.7684e-07, -8.1062e-06,\n",
            "        -1.7309e-03, -3.3188e-03, -8.4591e-04, -2.2522e-01, -2.0466e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04784872382879257 0.003875732421875 1.6035815477371216 0.3450651168823242 77\n",
            "pred tensor([-1.6663e-02, -2.2354e-02, -6.3133e-03, -1.5724e-04, -2.8849e-05,\n",
            "        -1.5736e-05, -1.2398e-05, -8.0643e-03, -6.0225e-04, -1.6665e-04,\n",
            "        -9.6500e-05, -9.8944e-06, -1.2732e-04, -1.8591e-01, -1.5888e-03,\n",
            "        -1.9264e-03, -1.4038e-02, -1.5724e-04, -2.7176e-02, -2.1076e-03,\n",
            "        -2.2221e-03, -1.3245e-02, -2.5010e-04, -3.6359e-06, -4.0703e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05163509398698807 0.01044464111328125 1.4201210737228394 0.33886241912841797 49\n",
            "pred tensor([-1.0632e-01, -9.3918e-03, -5.8746e-04, -6.1178e-04, -1.1820e-04,\n",
            "        -1.5516e-03, -1.4656e-02, -9.8975e-01, -9.2627e-01, -1.0000e+00,\n",
            "        -1.0598e-04, -7.2539e-05, -1.1921e-07, -1.1921e-07, -2.3842e-07,\n",
            "         0.0000e+00, -5.7459e-04, -3.0458e-05, -4.1723e-07, -3.8147e-06,\n",
            "        -1.2517e-06, -1.1921e-07, -1.1921e-07, -4.1723e-07, -2.8610e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04126116260886192 0.00301361083984375 1.6030423641204834 0.34835079312324524 47\n",
            "pred tensor([-9.0027e-04, -2.1040e-05, -3.3970e-03, -1.4710e-04, -2.6360e-03,\n",
            "        -9.8267e-02, -5.3444e-03, -9.8486e-01, -2.9826e-04, -5.4836e-06,\n",
            "        -5.3644e-07, -1.7881e-07, -3.6359e-06, -6.5565e-06, -4.8280e-06,\n",
            "        -2.3880e-03, -3.1796e-03, -2.5725e-04, -3.2115e-04, -9.6083e-05,\n",
            "        -7.1526e-07, -1.2779e-04, -8.4639e-06, -1.1325e-05, -9.7156e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05197109282016754 0.0020885467529296875 1.6536872386932373 0.32933351397514343 50\n",
            "pred tensor([-9.9915e-02, -1.1915e-04, -5.9748e-04, -1.1593e-04, -1.6809e-05,\n",
            "        -1.4811e-03, -1.0000e+00, -1.0000e+00, -2.5392e-05, -3.6359e-06,\n",
            "        -2.2054e-06, -8.9407e-07, -1.4150e-04, -2.5630e-06, -3.6359e-05,\n",
            "        -6.8140e-04, -1.2372e-01, -1.8177e-03, -4.0674e-04, -2.0142e-03,\n",
            "        -4.6021e-02, -9.7561e-04, -3.2196e-02, -1.9379e-02, -1.7548e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04849554970860481 0.0003838539123535156 1.843075156211853 0.34647151827812195 84\n",
            "pred tensor([-1.5764e-03, -5.1928e-04, -7.3969e-05, -9.7427e-03, -5.0201e-03,\n",
            "        -3.6987e-02, -8.0943e-05, -4.5300e-06, -1.9264e-04, -3.2961e-05,\n",
            "        -2.5511e-04, -9.8348e-06, -9.4175e-06, -2.7776e-05, -1.6153e-04,\n",
            "        -3.7551e-06, -1.4582e-03, -1.6534e-04, -1.8167e-04, -3.0303e-04,\n",
            "        -8.9943e-05, -1.0605e-03, -3.5934e-03, -2.0126e-02, -2.3178e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05922064185142517 0.0002446174621582031 1.8395328521728516 0.3506007790565491 52\n",
            "pred tensor([-3.0493e-01, -2.6413e-02, -1.7738e-04, -4.4167e-05, -6.1798e-04,\n",
            "        -8.3590e-04, -6.8903e-04, -7.8440e-05, -3.1018e-04, -7.9870e-06,\n",
            "        -6.5517e-04, -7.0667e-04, -3.7789e-05, -1.6093e-04, -5.8055e-05,\n",
            "        -7.5996e-05, -1.5402e-03, -2.2202e-02, -1.9646e-04, -1.5192e-03,\n",
            "        -4.3058e-04, -8.4448e-04, -1.2741e-03, -7.8738e-05, -2.9683e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.043664224445819855 0.00023603439331054688 1.8289904594421387 0.34377092123031616 82\n",
            "pred tensor([-8.1062e-04, -2.0767e-02, -6.5269e-03, -1.9798e-03, -2.4021e-05,\n",
            "        -5.3048e-05, -1.7226e-05, -9.6560e-06, -1.0967e-05, -2.1458e-06,\n",
            "        -1.8024e-04, -4.2224e-04, -2.3842e-06, -2.1458e-06, -2.0146e-05,\n",
            "        -1.9038e-04, -1.7881e-06, -5.9986e-04, -8.5831e-05, -2.6112e-03,\n",
            "        -8.2254e-06, -1.8120e-05, -5.3704e-05, -2.3782e-04, -5.4216e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.055865172296762466 0.000553131103515625 1.7587099075317383 0.3336690068244934 66\n",
            "pred tensor([-4.2140e-05, -2.1315e-04, -7.8082e-06, -5.5075e-04, -9.1016e-05,\n",
            "        -6.7711e-04, -1.1559e-03, -9.9540e-06, -1.4997e-04, -3.8290e-04,\n",
            "        -7.1955e-04, -4.9448e-04, -3.1357e-03, -5.1308e-04, -2.1148e-04,\n",
            "        -2.1315e-04, -2.7585e-04, -2.6846e-04, -2.2471e-05, -1.2188e-03,\n",
            "        -1.6422e-03, -4.4946e-01, -2.1591e-02, -1.3222e-02, -1.4198e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04862678423523903 0.00011539459228515625 1.789901852607727 0.3743792176246643 97\n",
            "pred tensor([-3.3703e-03, -5.8603e-04, -1.4755e-02, -6.4507e-03, -1.5318e-05,\n",
            "        -1.7583e-05, -4.6005e-03, -9.1374e-05, -1.9729e-05, -1.7464e-04,\n",
            "        -1.4663e-05, -1.2243e-04, -5.5194e-05, -2.6321e-04, -2.1076e-03,\n",
            "        -1.6136e-03, -1.1915e-04, -2.1565e-04, -3.5357e-04, -1.8749e-03,\n",
            "        -4.8161e-05, -1.4186e-05, -3.5346e-05, -6.9141e-06, -2.9373e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05177228897809982 0.003925323486328125 1.6107418537139893 0.36991438269615173 78\n",
            "pred tensor([-1.8835e-05, -4.2677e-05, -6.4552e-05, -9.9414e-01, -9.9951e-01,\n",
            "        -1.0000e+00, -2.4068e-04, -5.8532e-05, -2.3484e-05, -7.6950e-05,\n",
            "        -5.4240e-06, -8.3506e-05, -5.9605e-07, -1.8477e-06, -1.6987e-05,\n",
            "        -9.7632e-05, -1.8477e-06, -3.3081e-05, -5.6934e-04, -1.5533e-04,\n",
            "        -2.8133e-04, -8.3447e-04, -1.2522e-03, -2.8061e-02, -3.9887e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0488196536898613 0.00368499755859375 1.6313273906707764 0.35194551944732666 107\n",
            "pred tensor([-3.3736e-05, -5.8842e-04, -4.9925e-04, -5.3704e-05, -3.0100e-05,\n",
            "        -3.0708e-04, -1.2243e-04, -5.9605e-07, -1.7345e-05, -4.8399e-04,\n",
            "        -9.5367e-05, -5.1117e-04, -2.5749e-05, -5.5265e-04, -6.4552e-05,\n",
            "        -1.4842e-05, -1.6606e-04, -7.8535e-04, -1.8418e-05, -1.8206e-03,\n",
            "        -9.7561e-04, -2.3973e-04, -1.5056e-04, -1.8635e-03, -2.8133e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05133694037795067 0.00988006591796875 1.523615837097168 0.33981940150260925 77\n",
            "pred tensor([-1.5855e-05, -2.6822e-05, -6.7890e-05, -3.8683e-05, -1.4725e-03,\n",
            "        -2.4855e-05, -1.2684e-04, -2.1148e-04, -1.7029e-02, -6.4373e-04,\n",
            "        -7.3969e-05, -6.9714e-04, -1.6034e-05, -8.1682e-04, -3.1495e-04,\n",
            "        -2.5120e-03, -1.1820e-04, -3.6836e-04, -2.4152e-04, -7.5161e-05,\n",
            "        -1.9133e-05, -1.1545e-04, -2.1332e-02, -6.7329e-04, -2.8801e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04443790391087532 0.0066070556640625 1.594423770904541 0.3796929121017456 120\n",
            "pred tensor([-1.5662e-01, -6.8893e-03, -1.0204e-03, -8.6260e-04, -1.7376e-03,\n",
            "        -4.8697e-05, -1.4870e-02, -1.9379e-03, -8.9502e-04, -6.1279e-01,\n",
            "        -9.9072e-01, -1.0000e+00, -9.9951e-01, -1.0000e+00, -2.3007e-05,\n",
            "        -1.3447e-04, -2.5034e-06, -3.0398e-06, -1.4424e-05, -7.9691e-05,\n",
            "        -1.4544e-05, -1.2159e-05, -3.8981e-04, -1.5664e-04, -1.2457e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05415360629558563 0.0008897781372070312 1.8240474462509155 0.3490050435066223 65\n",
            "pred tensor([-7.9870e-06, -1.5764e-03, -1.9989e-03, -1.2100e-02, -2.0421e-04,\n",
            "        -5.1439e-05, -1.4961e-05, -1.0481e-03, -1.4889e-04, -4.3654e-04,\n",
            "        -1.3816e-04, -1.0312e-05, -4.5319e-02, -9.9902e-01, -1.0000e+00,\n",
            "        -1.0931e-04, -6.8545e-06, -1.1265e-05, -8.3780e-04, -8.5235e-06,\n",
            "        -1.8311e-04, -9.6500e-05, -5.6744e-05, -1.8537e-05, -1.0312e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.042040739208459854 0.0004801750183105469 1.894585371017456 0.35681867599487305 79\n",
            "pred tensor([-7.0557e-02, -9.1124e-04, -7.9775e-04, -4.6492e-06, -3.6061e-05,\n",
            "        -7.7486e-06, -5.9605e-08, -7.2002e-05, -7.5996e-05, -3.2482e-03,\n",
            "        -3.6430e-03, -5.5611e-05, -1.1339e-03, -1.7138e-03, -7.9498e-03,\n",
            "        -1.3943e-03, -2.9526e-03, -2.6417e-04, -1.9073e-05, -6.0797e-06,\n",
            "        -1.5593e-04, -2.5320e-04, -4.8041e-04, -9.6359e-03, -3.5864e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0492442324757576 0.00018310546875 1.8718000650405884 0.3322843611240387 52\n",
            "pred tensor([-5.2051e-01, -1.5198e-01, -6.4888e-03, -2.1954e-03, -2.2831e-03,\n",
            "        -4.2295e-04, -6.2287e-05, -1.4725e-03, -7.1383e-04, -1.4067e-05,\n",
            "        -5.0735e-04, -2.8551e-05, -5.1079e-03, -2.1744e-03, -5.0201e-03,\n",
            "        -2.1231e-04, -3.7498e-03, -6.0043e-03, -2.4247e-04, -9.7656e-03,\n",
            "        -2.4338e-02, -5.6763e-02, -9.3750e-02, -1.2825e-02, -6.4611e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04289444535970688 0.00183868408203125 1.6666401624679565 0.3542548716068268 71\n",
            "pred tensor([-3.1357e-03, -1.3030e-04, -7.5996e-05, -3.1710e-05, -6.2585e-06,\n",
            "        -3.2187e-06, -7.3910e-06, -2.4855e-05, -3.8743e-06, -5.9605e-06,\n",
            "        -3.3617e-05, -2.2054e-05, -2.9981e-05, -4.3511e-05, -3.0696e-05,\n",
            "        -1.0550e-05, -1.0765e-04, -3.8803e-05, -1.9646e-04, -3.5524e-05,\n",
            "        -3.2306e-05, -1.4365e-04, -2.2697e-03, -1.4770e-04, -3.8207e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05220514163374901 0.002063751220703125 1.6536451578140259 0.3314236104488373 53\n",
            "pred tensor([-5.5237e-03, -2.8400e-03, -2.2297e-03, -2.8610e-03, -1.2188e-03,\n",
            "        -2.1458e-05, -1.0777e-03, -5.2299e-03, -1.1339e-03, -6.4125e-03,\n",
            "        -1.5724e-04, -1.3709e-06, -7.7486e-07, -1.4305e-05, -1.7738e-04,\n",
            "        -1.3709e-06, -2.6405e-05, -3.4928e-04, -3.1054e-05, -1.7271e-03,\n",
            "        -1.2550e-03, -1.4191e-03, -3.3436e-03, -1.7824e-03, -9.2285e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0458197183907032 0.0027923583984375 1.5712835788726807 0.34034308791160583 67\n",
            "pred tensor([-1.4257e-04, -1.3199e-02, -5.1832e-04, -2.4338e-03, -1.3025e-01,\n",
            "        -4.0710e-05, -3.3975e-06, -6.2048e-05, -7.7486e-06, -4.3225e-04,\n",
            "        -3.9756e-05, -2.9755e-03, -1.1835e-03, -2.0206e-05, -2.2602e-04,\n",
            "        -9.8705e-04, -1.1146e-04, -1.3137e-04, -7.2510e-02, -1.3695e-03,\n",
            "        -5.9875e-02, -3.6430e-03, -1.3351e-02, -4.6005e-03, -9.1211e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05179647356271744 0.0005922317504882812 1.7965155839920044 0.3349859118461609 57\n",
            "pred tensor([-9.2041e-02, -6.1157e-02, -1.0565e-01, -2.6306e-02, -1.3199e-03,\n",
            "        -3.7048e-02, -9.6741e-03, -1.1559e-03, -1.0109e-04, -1.7041e-01,\n",
            "        -4.4897e-01, -9.9805e-01, -9.9609e-01, -1.0000e+00, -3.8207e-05,\n",
            "        -4.0829e-05, -1.0431e-05, -1.0073e-04, -3.5226e-05, -1.2934e-05,\n",
            "        -5.0426e-05, -1.6987e-05, -3.1054e-05, -6.6280e-04, -1.0133e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04789610579609871 0.00470733642578125 1.5708502531051636 0.34730687737464905 67\n",
            "pred tensor([-2.0444e-05, -2.4819e-04, -2.2078e-04, -6.0938e-01, -1.3901e-02,\n",
            "        -1.0000e+00, -6.9618e-04, -1.5497e-06, -3.1590e-06, -1.0192e-05,\n",
            "        -5.9605e-07, -3.8700e-03, -1.8826e-03, -1.6747e-03, -5.5432e-06,\n",
            "        -2.9802e-07, -1.8835e-05, -5.3704e-05, -1.0133e-06, -1.1325e-06,\n",
            "        -1.8477e-06, -2.1696e-05, -1.1683e-05, -4.5240e-05, -6.7353e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.051009662449359894 0.0040130615234375 1.5889995098114014 0.33375316858291626 34\n",
            "pred tensor([-2.8133e-04, -4.4942e-04, -1.1593e-04, -2.7001e-05, -6.3992e-04,\n",
            "        -8.3113e-04, -6.4993e-04, -3.6335e-04, -7.3586e-03, -3.3760e-03,\n",
            "        -6.0844e-04, -6.1417e-04, -1.2493e-03, -5.2035e-05, -2.9826e-04,\n",
            "        -2.0909e-04, -4.8218e-03, -1.3876e-04, -5.6171e-04, -1.8775e-05,\n",
            "        -2.0027e-04, -2.3234e-04, -3.0220e-05, -1.0429e-02, -9.9219e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04887471720576286 0.003093719482421875 1.5776875019073486 0.3361929655075073 67\n",
            "pred tensor([-3.5942e-05, -1.7262e-04, -2.4586e-03, -1.0312e-04, -1.1340e-01,\n",
            "        -7.1907e-03, -1.0000e+00, -1.1325e-06,  0.0000e+00, -1.9670e-06,\n",
            "        -5.9605e-07, -5.9605e-08, -4.1723e-07, -8.3447e-06, -6.5565e-05,\n",
            "        -4.7684e-07, -1.7881e-06, -1.5497e-06, -1.1325e-06, -5.9605e-08,\n",
            "        -1.1325e-06, -2.3842e-07, -1.0729e-05, -1.4901e-06, -1.2517e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058333758264780045 0.0015716552734375 1.7488526105880737 0.3377001881599426 52\n",
            "pred tensor([-1.0133e-06, -1.4671e-02, -1.1182e-01, -1.1121e-01, -9.7705e-01,\n",
            "        -8.3154e-01, -1.0073e-04, -3.6776e-05, -1.0371e-05, -4.1246e-04,\n",
            "        -5.3644e-06, -5.7125e-04, -1.0796e-03, -7.5996e-05, -4.9114e-05,\n",
            "        -9.0218e-04, -6.8665e-05, -2.8193e-05, -1.4126e-05, -9.8765e-05,\n",
            "        -2.4438e-06, -1.3709e-06, -2.6822e-06, -3.8743e-06, -4.6825e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04671267420053482 0.0011234283447265625 1.7150349617004395 0.3677840232849121 56\n",
            "4\n",
            "pred tensor([-4.9866e-02, -9.9304e-02, -3.6621e-02, -2.9373e-04, -1.1102e-01,\n",
            "        -1.3257e-01, -1.1177e-02, -8.1348e-04, -8.5235e-06, -4.2462e-04,\n",
            "        -3.6591e-02, -4.9927e-01, -9.6631e-01, -1.0000e+00, -5.6028e-04,\n",
            "        -1.2827e-04, -4.3631e-05, -2.8849e-05, -1.0473e-04, -4.1723e-07,\n",
            "        -7.3969e-05, -1.0073e-05, -2.3003e-03, -9.5010e-05, -7.9691e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05245758965611458 0.0012683868408203125 1.7118961811065674 0.334127277135849 44\n",
            "pred tensor([-9.9277e-04, -2.2650e-05, -1.4544e-05, -3.6359e-06, -4.3654e-04,\n",
            "        -2.8563e-04, -1.6153e-04, -3.6865e-02, -9.4629e-01, -9.9951e-01,\n",
            "        -1.9491e-04, -3.9291e-04, -8.0395e-04, -3.9577e-04, -1.3173e-05,\n",
            "        -6.2895e-04, -2.5272e-05, -9.2447e-05, -1.4424e-05, -7.3910e-06,\n",
            "        -7.1168e-05, -2.0087e-05, -2.4533e-04, -2.8348e-04, -1.9944e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.046755123883485794 0.0007333755493164062 1.7133958339691162 0.38473206758499146 56\n",
            "pred tensor([-9.2447e-05, -6.1333e-05, -2.2650e-06, -1.1384e-05, -1.6415e-04,\n",
            "        -1.6284e-04, -3.6049e-04, -6.6340e-05, -3.6049e-04, -4.7684e-07,\n",
            "        -5.6171e-04, -5.9652e-04, -5.6934e-04, -1.3709e-06, -1.0481e-03,\n",
            "        -5.8413e-06, -5.9903e-05, -7.3910e-06, -1.1921e-07, -6.1572e-05,\n",
            "        -1.4603e-02, -5.5611e-05, -1.1854e-03, -1.4305e-06, -1.0598e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05305348336696625 0.0016231536865234375 1.6230272054672241 0.32731005549430847 42\n",
            "pred tensor([-2.5034e-06, -3.8087e-05, -1.8024e-04, -8.2850e-06, -7.3910e-06,\n",
            "        -1.5306e-03, -1.2994e-05, -5.5599e-04, -1.1625e-03, -5.5611e-05,\n",
            "        -1.0192e-04, -2.1076e-04, -4.5466e-04, -6.8903e-04, -1.4901e-05,\n",
            "        -5.4121e-05, -2.2411e-05, -1.4365e-05, -9.8407e-05, -4.8876e-05,\n",
            "        -2.3823e-03, -1.7681e-03, -6.7353e-05, -9.0659e-05, -2.6894e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.047936514019966125 0.004730224609375 1.5706744194030762 0.3520708680152893 60\n",
            "pred tensor([-2.3239e-02, -4.4084e-04, -1.1277e-04, -5.4216e-04, -3.0696e-05,\n",
            "        -7.9691e-05, -3.2783e-06, -4.7684e-07, -2.9802e-07,  0.0000e+00,\n",
            "        -1.2827e-04, -1.4717e-02, -1.0000e+00, -1.8206e-03, -1.1921e-07,\n",
            "        -2.3842e-07, -7.6890e-06, -2.0905e-03, -7.8738e-05, -5.9891e-04,\n",
            "        -1.8024e-04, -2.3723e-05, -5.9557e-04, -3.0398e-06, -6.7353e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05463212728500366 0.0008020401000976562 1.663920521736145 0.33590686321258545 42\n",
            "pred tensor([-4.2969e-02, -3.2115e-04, -1.9951e-03, -3.6359e-06, -1.1683e-05,\n",
            "        -4.6492e-06, -2.9802e-07, -9.8348e-06, -1.2040e-05, -1.3329e-02,\n",
            "        -9.7705e-01, -9.8779e-01, -1.0000e+00, -4.2000e-03, -6.7444e-03,\n",
            "        -9.6035e-04, -1.9789e-04, -2.1191e-03, -5.8031e-04, -2.1315e-04,\n",
            "        -5.1928e-04, -4.3297e-03, -3.4912e-02, -1.2817e-03, -3.5038e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04872383177280426 0.0008211135864257812 1.705209493637085 0.33809542655944824 52\n",
            "pred tensor([-2.2526e-03, -5.4359e-03, -1.1091e-03, -5.2452e-04, -1.9014e-05,\n",
            "        -9.3651e-04, -6.0463e-04, -9.9512e-01, -1.0000e+00, -3.6359e-05,\n",
            "        -5.9605e-06, -1.1921e-07, -3.8147e-06, -1.4901e-06, -1.2934e-05,\n",
            "        -2.2423e-04, -2.0266e-06, -2.6226e-06, -2.3842e-06, -6.7949e-06,\n",
            "        -1.7607e-04, -4.8971e-04, -7.3891e-03, -6.2990e-04, -3.5214e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05533860623836517 0.001800537109375 1.6714437007904053 0.3318064212799072 54\n",
            "pred tensor([-1.5295e-04, -5.2673e-02, -2.4872e-03, -5.0831e-04, -9.6858e-05,\n",
            "        -1.7881e-04, -6.6161e-06, -1.3530e-05, -6.6161e-06, -3.0458e-05,\n",
            "        -6.9618e-04, -2.0742e-04, -1.8525e-04, -4.4417e-04, -1.0262e-03,\n",
            "        -3.9062e-03, -2.1155e-01, -5.2295e-01, -9.8145e-01, -8.7842e-01,\n",
            "        -9.8877e-01, -2.0142e-03, -4.2915e-06, -8.8871e-05, -1.8454e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0507911778986454 0.0025386810302734375 1.5970585346221924 0.34927624464035034 59\n",
            "pred tensor([-5.2910e-03, -6.7177e-03, -3.1433e-02, -2.6531e-03, -9.5463e-04,\n",
            "        -2.9862e-05, -5.1439e-05, -2.3139e-04, -1.0462e-03, -9.6083e-05,\n",
            "        -5.4240e-06, -4.3726e-04, -2.8682e-04, -3.4904e-03, -1.9944e-04,\n",
            "        -8.0585e-05, -1.0490e-05, -1.1384e-05, -2.6226e-06, -2.8551e-05,\n",
            "        -1.4582e-03, -1.9014e-05, -7.3671e-05, -1.6870e-03, -4.5753e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.057592637836933136 0.0017747879028320312 1.5920559167861938 0.3298463821411133 39\n",
            "pred tensor([-1.9252e-05, -3.5763e-05, -6.0272e-03, -4.5955e-05, -1.6510e-05,\n",
            "        -2.0504e-04, -3.9816e-04, -1.6108e-03, -2.1148e-04, -2.7418e-06,\n",
            "        -1.8954e-05, -2.6417e-04, -8.0585e-05, -3.7193e-05, -9.4938e-04,\n",
            "        -2.3327e-03, -2.6989e-03, -1.9119e-02, -9.5963e-06, -8.6069e-04,\n",
            "        -1.1780e-02, -9.7803e-01, -9.4531e-01, -1.6495e-02, -2.1398e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050049252808094025 0.0025634765625 1.505442500114441 0.3508986234664917 61\n",
            "pred tensor([-3.2377e-04, -7.4158e-03, -9.7427e-03, -1.6797e-04, -3.7372e-05,\n",
            "        -5.3644e-07, -2.5320e-04, -3.5644e-05, -1.2934e-05, -5.3644e-06,\n",
            "        -6.1393e-06, -4.0054e-05, -1.1921e-07, -1.7881e-07, -8.7142e-05,\n",
            "        -4.1413e-04, -6.4392e-03, -6.6042e-04, -4.1008e-04, -1.7607e-04,\n",
            "        -2.0337e-04, -5.6267e-05, -4.8399e-04, -6.6064e-01, -9.4629e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06075891852378845 0.0010156631469726562 1.6641736030578613 0.34566211700439453 52\n",
            "pred tensor([-9.9463e-01, -2.5558e-03, -1.5414e-04, -1.9165e-01, -3.9434e-04,\n",
            "        -5.0426e-05, -5.4836e-06, -3.9339e-06, -1.1921e-07, -3.7074e-05,\n",
            "        -9.8348e-06, -2.2522e-02, -8.5571e-02, -5.3369e-01, -2.3987e-02,\n",
            "        -2.6882e-05, -1.9038e-04, -3.9756e-05, -3.5107e-05, -4.1962e-05,\n",
            "        -8.8215e-05, -1.9083e-03, -9.5963e-06, -4.7088e-06, -1.2827e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05129684880375862 0.001308441162109375 1.612162470817566 0.35218584537506104 74\n",
            "pred tensor([-6.9332e-04, -9.3269e-04, -1.9372e-05, -4.4703e-06, -5.0664e-06,\n",
            "        -1.6642e-03, -4.7386e-05, -1.1921e-06, -4.7088e-06, -2.9802e-07,\n",
            "        -2.6464e-05, -5.1260e-05, -1.6093e-06, -4.4107e-06, -8.5999e-02,\n",
            "        -9.9902e-01, -1.0000e+00, -4.4584e-04, -1.2646e-03, -3.3736e-05,\n",
            "        -3.0184e-04, -1.6251e-02, -1.3602e-04, -5.2643e-04, -1.6451e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06281659007072449 0.0034027099609375 1.5159316062927246 0.3505273759365082 69\n",
            "pred tensor([-1.8811e-04, -1.8826e-03, -1.4591e-04, -2.3592e-04, -3.0518e-03,\n",
            "        -6.2513e-04, -4.2319e-05, -1.9073e-06, -1.1854e-03, -6.0201e-06,\n",
            "        -1.6510e-05, -5.0020e-04, -2.9755e-03, -6.9141e-06, -9.7990e-05,\n",
            "        -1.5235e-04, -2.2697e-04, -1.7345e-05, -3.8147e-04, -2.8467e-04,\n",
            "        -1.0973e-04, -2.9812e-03, -2.7776e-05, -6.6805e-04, -4.0710e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05306310951709747 0.0042266845703125 1.5039868354797363 0.35185450315475464 60\n",
            "pred tensor([-1.2426e-03, -4.7722e-03, -3.1433e-02, -1.0931e-04, -9.5367e-07,\n",
            "         0.0000e+00, -5.9605e-08,  0.0000e+00, -5.9605e-08, -3.9339e-06,\n",
            "        -1.7226e-05, -3.4161e-03, -7.1704e-05, -1.9014e-05, -2.2829e-05,\n",
            "        -2.7657e-05, -1.9951e-03, -5.6534e-03, -4.8971e-04, -2.6166e-05,\n",
            "        -2.3842e-07, -9.7752e-06, -2.5034e-06, -6.5029e-05, -9.0599e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06091681867837906 0.0004525184631347656 1.7237558364868164 0.3249812126159668 36\n",
            "pred tensor([-8.4114e-04, -5.3644e-06, -2.4014e-03, -4.6492e-05, -9.4748e-04,\n",
            "        -1.1444e-05, -3.7193e-05, -5.0664e-06, -6.5565e-07, -6.6161e-06,\n",
            "        -3.2187e-05, -5.7640e-03, -3.3436e-03, -7.7553e-03, -6.5267e-05,\n",
            "        -2.0182e-04, -2.1683e-02, -2.9922e-02, -1.5056e-04, -3.3975e-06,\n",
            "        -4.6492e-06, -1.6344e-04, -3.3736e-05, -1.0514e-04, -6.2048e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04965006187558174 0.00043582916259765625 1.7690975666046143 0.3387157618999481 66\n",
            "pred tensor([-3.5644e-05, -3.3283e-04, -5.2643e-04, -4.1723e-07, -1.1921e-07,\n",
            "         0.0000e+00, -2.8015e-02, -6.1377e-01, -1.0000e+00, -1.1921e-06,\n",
            "        -3.5763e-07, -3.0398e-06, -4.2975e-05, -2.8849e-05, -5.9605e-08,\n",
            "        -5.3644e-07, -1.1921e-06, -5.9605e-08, -5.9605e-08, -2.0266e-06,\n",
            "        -1.9550e-05, -2.3842e-07, -4.1127e-06,  0.0000e+00,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06587675213813782 0.0011463165283203125 1.6272661685943604 0.33375853300094604 67\n",
            "pred tensor([-1.1683e-04, -1.1921e-06, -2.5225e-04, -1.3405e-02, -6.2042e-02,\n",
            "        -1.9272e-02, -2.3234e-04, -8.0109e-04, -6.7062e-03, -1.8034e-03,\n",
            "        -3.0065e-04, -1.3304e-03, -1.0550e-05, -1.8656e-05, -2.5988e-05,\n",
            "        -1.8930e-03, -1.1635e-04, -2.8682e-04, -9.7632e-05, -2.8968e-05,\n",
            "        -3.6621e-04, -6.5565e-07, -3.3593e-04, -1.5235e-04, -4.5061e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052483491599559784 0.0012054443359375 1.6567937135696411 0.37535494565963745 73\n",
            "pred tensor([-1.0391e-02, -7.8857e-02, -5.7459e-04, -1.1325e-06, -7.0333e-06,\n",
            "        -1.5438e-05, -1.6689e-06, -7.3682e-01, -1.0000e+00, -3.8743e-06,\n",
            "        -1.7881e-07, -4.7684e-07, -1.1921e-06, -3.0696e-05, -1.4782e-05,\n",
            "        -2.3842e-07, -7.7486e-07, -5.9605e-08, -1.7881e-07, -4.1664e-05,\n",
            "        -6.1393e-06, -3.4738e-04, -6.2585e-06, -2.5034e-06, -8.5831e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.059770021587610245 0.0012807846069335938 1.5997711420059204 0.3293765187263489 52\n",
            "pred tensor([-1.3340e-04, -4.6825e-04, -4.8399e-04, -3.4928e-05, -1.6665e-04,\n",
            "        -8.0395e-04, -3.7789e-05, -1.5473e-04, -5.0426e-05, -6.7592e-05,\n",
            "        -6.4254e-05, -9.8348e-06, -2.3592e-04, -4.3809e-05, -4.7565e-04,\n",
            "        -2.5215e-03, -5.0545e-04, -2.6428e-02, -3.6621e-04, -1.7464e-04,\n",
            "        -1.6876e-02, -1.1963e-02, -3.9816e-04, -6.0730e-03, -2.0337e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0463285930454731 0.00461578369140625 1.4996986389160156 0.3746315836906433 48\n",
            "pred tensor([-5.4980e-01, -9.9951e-01, -1.0000e+00, -1.0000e+00, -9.5010e-05,\n",
            "        -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -2.9802e-07,  0.0000e+00,  0.0000e+00, -5.9605e-08, -5.9605e-08,\n",
            "        -5.9605e-08, -5.3048e-06, -2.3842e-07, -4.1723e-07, -5.3644e-07,\n",
            "        -4.7684e-07, -1.8477e-05, -1.3113e-06, -3.2723e-05, -1.2030e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06527852267026901 0.00347137451171875 1.4967858791351318 0.34581682085990906 62\n",
            "pred tensor([-9.9707e-01, -9.9854e-01, -9.2090e-01, -3.3975e-05, -9.5367e-06,\n",
            "        -2.9588e-04, -2.4719e-03, -3.3736e-04, -1.2054e-02, -2.1482e-04,\n",
            "        -1.4467e-03, -1.0529e-03, -3.8087e-05, -3.7289e-03, -3.1877e-04,\n",
            "        -6.8140e-04, -2.3127e-05, -2.1398e-04, -1.2338e-05, -4.9889e-05,\n",
            "        -2.3413e-04, -6.7568e-04, -5.7399e-05, -7.3338e-04, -4.3726e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05724608153104782 0.002330780029296875 1.5490411520004272 0.40214619040489197 111\n",
            "pred tensor([-4.2140e-05, -6.9580e-03, -1.4503e-02, -5.4836e-04, -1.1384e-05,\n",
            "        -2.6703e-05, -1.3494e-04, -6.0606e-04, -1.1200e-02, -3.0899e-04,\n",
            "        -1.2004e-04, -2.6822e-05, -3.8147e-06, -4.9472e-06, -6.6772e-02,\n",
            "        -6.5374e-04, -1.6928e-04, -1.3828e-03, -5.4932e-04, -7.0000e-03,\n",
            "        -1.8282e-03, -3.4511e-05, -2.1458e-06, -2.3544e-05, -7.5459e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07096409797668457 0.0008020401000976562 1.6511352062225342 0.33459076285362244 67\n",
            "pred tensor([-3.5763e-07, -1.5354e-04, -6.1684e-03, -3.3569e-02, -5.0354e-04,\n",
            "        -6.0201e-06, -3.0994e-06, -6.7854e-04, -3.8290e-04, -5.7411e-03,\n",
            "        -2.1279e-05, -6.6578e-05, -2.8610e-05, -2.9802e-07, -1.3046e-02,\n",
            "        -6.1798e-03, -1.5747e-02, -1.0431e-05, -6.3133e-04, -1.1456e-04,\n",
            "        -2.1572e-03, -1.6006e-02, -9.8877e-01, -1.0000e+00, -7.9346e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.054502036422491074 0.001453399658203125 1.5795118808746338 0.3528002202510834 92\n",
            "pred tensor([-5.1260e-06, -4.5896e-06, -1.1969e-03, -1.1623e-05, -1.5497e-06,\n",
            "        -7.6890e-06, -2.7962e-03, -1.1206e-03, -2.1279e-05, -4.2677e-05,\n",
            "        -6.1810e-05, -5.0020e-04, -8.9228e-05, -4.8971e-04, -2.6727e-04,\n",
            "        -3.2306e-04, -1.9745e-02, -1.1021e-04, -1.2636e-05, -5.8532e-05,\n",
            "        -1.1578e-03, -3.7336e-04, -3.5644e-05, -5.2452e-06, -1.4019e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07318531721830368 0.00016117095947265625 1.830003261566162 0.3527860641479492 60\n",
            "pred tensor([-2.7686e-01, -3.0303e-04, -4.2877e-03, -8.6523e-01, -6.4062e-01,\n",
            "        -1.0000e+00, -1.0000e+00, -1.0000e+00, -1.6518e-03, -2.3305e-05,\n",
            "        -7.0667e-04, -5.1856e-06, -1.5855e-05, -3.2187e-06, -2.5415e-04,\n",
            "        -1.0353e-04,  0.0000e+00,  0.0000e+00, -5.9605e-08, -1.1921e-07,\n",
            "        -1.2398e-05, -9.6359e-03, -1.4246e-05, -1.8179e-05, -5.9187e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05751412361860275 0.0007262229919433594 1.6754016876220703 0.360321044921875 77\n",
            "pred tensor([-8.3447e-01, -9.9854e-01, -9.9805e-01, -9.1553e-01, -1.7163e-01,\n",
            "        -2.1915e-03, -6.1810e-05, -4.1723e-07, -3.6907e-04, -1.9083e-03,\n",
            "        -1.5961e-02, -2.8343e-03, -9.5725e-05, -6.8092e-03, -8.1982e-01,\n",
            "        -3.1829e-05, -3.5942e-05, -1.1325e-05, -3.2783e-06, -2.5988e-05,\n",
            "        -1.4937e-04, -9.1374e-05, -6.2275e-04, -7.4072e-01, -9.9756e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07348421961069107 0.0014095306396484375 1.5934407711029053 0.3392576277256012 82\n",
            "pred tensor([-7.3242e-02, -1.0672e-03, -7.1754e-03, -5.9080e-04, -3.0403e-03,\n",
            "        -1.3113e-05, -3.2187e-06, -4.4167e-05, -1.9670e-06, -2.8729e-05,\n",
            "        -2.3317e-04, -7.3181e-02, -5.4817e-03, -3.7212e-03, -2.2964e-03,\n",
            "        -1.1467e-02, -4.4441e-03, -9.2957e-02, -7.3195e-04, -1.4668e-03,\n",
            "        -5.0247e-05, -1.0353e-04, -4.4167e-05, -3.4511e-05, -6.7890e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05759553611278534 0.002227783203125 1.5728129148483276 0.3628405034542084 77\n",
            "pred tensor([-4.8561e-03, -1.9789e-04, -5.8670e-03, -5.6028e-06, -8.6427e-06,\n",
            "        -1.1683e-05, -2.3842e-07, -2.9802e-07, -7.7486e-07, -3.6955e-06,\n",
            "        -5.4688e-02, -2.1439e-03, -1.6739e-02, -6.9580e-03, -1.9848e-05,\n",
            "        -5.9080e-04, -6.7186e-04, -5.8293e-05, -3.5620e-04, -5.6624e-06,\n",
            "        -7.6294e-06, -2.0862e-06, -6.1655e-04, -1.6136e-03, -1.3137e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07605484873056412 0.001956939697265625 1.6171510219573975 0.33704254031181335 75\n",
            "pred tensor([-2.1219e-05, -7.2718e-06, -4.1723e-07, -5.3864e-03, -8.2169e-03,\n",
            "        -1.2529e-04, -1.3876e-04, -3.6359e-06, -9.7632e-05, -1.2243e-04,\n",
            "        -4.2892e-04, -2.1076e-03, -6.0387e-03, -6.7997e-04, -9.3651e-04,\n",
            "        -2.3193e-01, -8.4763e-03, -1.8341e-02, -5.1697e-02, -3.2787e-03,\n",
            "        -3.7280e-01, -6.5613e-02, -5.2299e-03, -8.9844e-01, -1.9875e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06644593924283981 0.00518798828125 1.5063178539276123 0.35458627343177795 88\n",
            "pred tensor([-1.2505e-02, -9.0027e-03, -2.5129e-04, -3.6180e-05, -5.3704e-05,\n",
            "        -2.3246e-06, -1.7881e-07, -2.3246e-06, -1.0133e-06, -2.8133e-04,\n",
            "        -4.2224e-04, -5.2910e-03, -4.9472e-06, -5.9605e-08, -1.1921e-06,\n",
            "        -2.6405e-05, -7.7248e-03, -3.4928e-05, -7.6294e-06, -4.5598e-05,\n",
            "        -9.6560e-06, -1.1654e-03, -1.0000e+00, -5.5933e-04, -1.2474e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07810128480195999 0.0035400390625 1.5091246366500854 0.33174964785575867 53\n",
            "pred tensor([-8.2254e-06, -2.6703e-05, -7.1526e-07, -3.8743e-06, -5.3644e-07,\n",
            "         0.0000e+00, -1.7881e-07, -3.5763e-07, -7.1526e-07, -1.7881e-07,\n",
            "        -7.9036e-05, -5.7220e-06, -7.4506e-06, -1.6332e-05, -1.7464e-05,\n",
            "        -1.1104e-04, -1.6809e-05, -1.7881e-07, -2.9802e-07, -3.5763e-07,\n",
            "        -2.0862e-06, -1.7810e-04, -2.0370e-02, -1.5843e-04, -4.8518e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06446995586156845 0.0028362274169921875 1.5940864086151123 0.35014989972114563 60\n",
            "pred tensor([-7.3969e-05, -1.7345e-05, -1.6570e-05, -2.5153e-05, -1.5497e-06,\n",
            "        -1.1325e-06, -1.4305e-05, -7.7486e-07, -3.9744e-04, -1.9670e-06,\n",
            "        -1.1921e-07, -2.3842e-07,  0.0000e+00, -2.9206e-06, -7.5607e-03,\n",
            "        -4.4594e-03, -5.2452e-05, -5.9557e-04, -3.7622e-04, -9.3985e-04,\n",
            "        -6.9201e-05, -2.7275e-04, -3.8391e-02, -1.9908e-05, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08057819306850433 0.002101898193359375 1.6405624151229858 0.3279259502887726 48\n",
            "pred tensor([-2.1458e-05, -3.8743e-06, -5.6934e-04, -1.7881e-07, -3.5763e-07,\n",
            "        -6.1989e-06, -1.6868e-04, -4.3884e-02, -8.6927e-04, -1.0099e-03,\n",
            "        -5.8055e-05, -4.1187e-05, -1.4931e-02, -6.2895e-04, -3.4771e-03,\n",
            "        -9.9854e-01, -1.0000e+00, -9.1648e-04, -1.8382e-04, -4.5776e-05,\n",
            "        -4.3988e-05, -1.3292e-04, -1.3292e-04, -1.0920e-03, -3.4273e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05988305062055588 0.0017795562744140625 1.5957362651824951 0.32994383573532104 45\n",
            "pred tensor([-1.7471e-02, -3.4881e-04, -1.7333e-04, -2.4438e-04, -1.0556e-04,\n",
            "        -3.8743e-06,  0.0000e+00, -1.8477e-06, -2.0554e-02, -1.0000e+00,\n",
            "        -3.3498e-05, -1.3113e-06, -4.3631e-05, -2.3901e-05, -3.2306e-05,\n",
            "        -1.3340e-04, -3.1352e-05, -1.6093e-04, -5.4955e-05, -7.7486e-07,\n",
            "        -1.6737e-04, -4.5776e-05, -1.8024e-04, -2.0564e-05, -3.5524e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08175554871559143 0.0012407302856445312 1.597377061843872 0.33264654874801636 56\n",
            "pred tensor([-7.5996e-05, -1.3876e-04, -4.3511e-06, -2.6727e-04, -2.1315e-04,\n",
            "        -8.4591e-04, -1.0848e-05, -1.4901e-06, -9.5725e-05, -1.3709e-05,\n",
            "        -7.1812e-04, -4.9651e-05, -1.7202e-04, -4.7684e-06, -1.8597e-04,\n",
            "        -1.7345e-05, -1.0729e-06, -3.5763e-07, -2.6822e-05, -4.8208e-04,\n",
            "        -2.4951e-01, -2.7710e-02, -3.5644e-05, -9.4175e-06, -2.1458e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07165876775979996 0.0009527206420898438 1.6703280210494995 0.3530515432357788 68\n",
            "pred tensor([-5.6171e-04, -3.4237e-03, -9.3555e-01, -9.4043e-01, -9.9902e-01,\n",
            "        -1.7881e-07, -5.9605e-08, -3.6359e-05, -4.7684e-07, -8.7857e-05,\n",
            "        -9.6560e-06, -2.0385e-05, -1.2970e-03, -1.0406e-02, -6.4373e-06,\n",
            "        -1.0192e-04, -1.3292e-04, -3.8004e-04, -4.8280e-06, -5.9605e-08,\n",
            "         0.0000e+00, -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08062519878149033 0.0008687973022460938 1.6658406257629395 0.340929239988327 41\n",
            "pred tensor([-9.6191e-02, -6.9189e-01, -6.6650e-01, -9.9756e-01, -9.9121e-01,\n",
            "        -1.0000e+00, -7.8678e-06, -3.5107e-05, -1.4842e-05, -9.4175e-06,\n",
            "        -1.1772e-04, -9.3877e-05, -8.9359e-04, -7.0035e-05, -2.2650e-05,\n",
            "        -8.2195e-05, -1.9014e-05, -4.0531e-06, -1.1921e-07, -1.9073e-06,\n",
            "        -3.5763e-07, -1.1339e-03, -2.1994e-04, -1.7338e-03, -4.7922e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06576099246740341 0.001953125 1.6369562149047852 0.3388665020465851 51\n",
            "5\n",
            "pred tensor([-2.1610e-03, -3.0112e-04, -5.8949e-05, -9.5367e-07,  0.0000e+00,\n",
            "        -3.0994e-06, -6.5565e-07, -2.5034e-06,  0.0000e+00,  0.0000e+00,\n",
            "        -1.0729e-06, -9.8348e-06, -1.1921e-07,  0.0000e+00, -8.9407e-07,\n",
            "        -6.4790e-05, -4.6005e-03, -4.7386e-05, -4.1246e-04, -6.8665e-04,\n",
            "        -1.0848e-05, -3.0696e-05, -1.7881e-07, -1.2457e-05, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08163123577833176 0.005718231201171875 1.462827444076538 0.325423002243042 32\n",
            "pred tensor([-8.7549e-01, -4.5068e-01, -3.8981e-04, -2.1458e-05, -1.4889e-04,\n",
            "        -2.3139e-04, -1.7881e-06, -3.8683e-05, -4.6313e-05, -2.5570e-05,\n",
            "        -6.5565e-07,  0.0000e+00, -2.3842e-07, -2.5034e-06, -1.1921e-06,\n",
            "        -7.5102e-06, -1.0319e-03, -4.5240e-05, -2.2602e-04, -1.4496e-03,\n",
            "        -4.7088e-06, -8.3447e-07,  0.0000e+00, -7.7486e-07,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06575427949428558 0.00389862060546875 1.5489025115966797 0.37390685081481934 43\n",
            "pred tensor([-4.4336e-01, -1.8115e-01, -7.2327e-03, -1.0133e-06, -1.1921e-07,\n",
            "        -4.1723e-07, -1.1921e-07, -5.9605e-08, -4.7684e-07, -1.1921e-07,\n",
            "        -7.4565e-05, -1.1921e-07,  0.0000e+00,  0.0000e+00, -2.1458e-06,\n",
            "        -1.0073e-05, -6.7353e-05, -4.1723e-07, -8.6427e-06,  0.0000e+00,\n",
            "        -5.9605e-08, -1.1802e-05, -9.3579e-06, -3.6955e-06, -3.5167e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08117035031318665 0.002880096435546875 1.5479592084884644 0.3208020329475403 20\n",
            "pred tensor([-9.9121e-01, -6.8176e-02, -4.4107e-06, -6.0797e-06, -5.9605e-08,\n",
            "         0.0000e+00,  0.0000e+00, -2.3842e-07, -8.7646e-01, -1.0000e+00,\n",
            "        -9.9854e-01, -9.9658e-01, -9.9512e-01, -1.7993e-01, -1.4710e-04,\n",
            "        -7.7486e-06, -5.9605e-08, -9.9902e-01, -5.9605e-08, -5.9605e-08,\n",
            "        -1.2517e-06, -4.5204e-04, -2.0111e-04, -1.2934e-04, -1.7285e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07389936596155167 0.0007963180541992188 1.6364699602127075 0.3666341006755829 56\n",
            "pred tensor([-4.1187e-05, -3.3966e-02, -1.5192e-03, -1.4007e-05, -1.1504e-05,\n",
            "        -9.7156e-06, -5.9605e-08, -5.5122e-03, -5.9605e-08,  0.0000e+00,\n",
            "        -1.1325e-06, -3.0696e-05, -6.6578e-05, -1.8060e-05, -1.1921e-07,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -2.9802e-07, -1.0364e-01, -1.0000e+00, -1.0000e+00, -1.7881e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08878634124994278 0.0005717277526855469 1.700878381729126 0.3378225564956665 29\n",
            "pred tensor([-3.9756e-05, -4.1187e-05, -1.1921e-07, -7.2718e-06, -2.3365e-05,\n",
            "        -2.2054e-06, -2.3842e-07, -5.9605e-08,  0.0000e+00, -2.9802e-07,\n",
            "         0.0000e+00, -4.4703e-06,  0.0000e+00, -9.3579e-06, -5.9605e-08,\n",
            "        -1.1593e-04, -8.3447e-07, -3.2978e-03, -3.3736e-04, -2.8348e-04,\n",
            "        -4.4167e-05, -1.9073e-06, -5.9605e-07, -2.3842e-07, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06636638194322586 0.0003566741943359375 1.7409589290618896 0.3432592451572418 49\n",
            "pred tensor([-7.8142e-05, -6.0368e-04, -3.9506e-04, -2.9802e-07, -1.1921e-07,\n",
            "         0.0000e+00, -1.5497e-06, -1.7285e-06, -1.1325e-06, -9.5367e-07,\n",
            "        -4.7088e-06, -1.6093e-06, -1.1921e-07,  0.0000e+00,  0.0000e+00,\n",
            "        -2.3842e-06, -2.4140e-05, -4.1664e-05, -5.4297e-01, -7.5439e-01,\n",
            "        -7.3242e-01, -1.0000e+00, -1.3471e-05, -1.0371e-05, -8.9228e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0832236185669899 0.0003008842468261719 1.7243530750274658 0.3281233012676239 37\n",
            "pred tensor([-1.6534e-04, -6.6578e-05, -9.6035e-04, -4.1664e-05, -7.0648e-03,\n",
            "        -4.3988e-04, -3.1796e-03, -1.5930e-02, -1.3292e-04, -1.8597e-04,\n",
            "        -3.5167e-06, -2.3842e-07, -5.0011e-03, -1.0000e+00, -1.9872e-04,\n",
            "        -1.1063e-04, -7.5996e-05, -4.1306e-05, -4.3559e-04, -5.9080e-04,\n",
            "        -1.5783e-04, -3.4273e-05, -8.3804e-05, -8.2636e-04, -1.6689e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06801100820302963 0.0006194114685058594 1.6240119934082031 0.35848715901374817 56\n",
            "pred tensor([-9.2725e-01, -9.3604e-01, -5.1422e-02, -3.5400e-01, -3.8207e-05,\n",
            "        -2.8348e-04, -9.6798e-04, -7.0870e-05, -4.6313e-05, -2.0266e-06,\n",
            "        -2.9640e-03, -1.4842e-05, -1.1683e-05, -4.3988e-05, -4.8876e-05,\n",
            "        -4.8409e-03, -1.8299e-05, -4.8518e-05, -1.2243e-04, -1.7262e-04,\n",
            "        -5.6648e-03, -9.9951e-01, -8.0908e-01, -8.1055e-01, -9.9902e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08307076245546341 0.0021076202392578125 1.58272385597229 0.33340802788734436 57\n",
            "pred tensor([-9.9512e-01, -9.9951e-01, -9.9951e-01, -1.5354e-04, -4.8208e-04,\n",
            "        -3.9196e-04, -5.5428e-03, -1.7881e-06, -3.4332e-04, -7.5996e-05,\n",
            "        -3.0816e-05, -2.7001e-05, -2.3317e-04, -1.2290e-04, -3.6068e-03,\n",
            "        -1.5335e-02, -5.4121e-05, -1.2846e-03, -1.7536e-04, -2.9373e-04,\n",
            "        -1.1768e-01, -6.3232e-01, -1.9012e-02, -1.0718e-01, -4.9133e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0703035444021225 0.0033416748046875 1.5255972146987915 0.3720908463001251 85\n",
            "pred tensor([-3.6221e-03, -1.9791e-02, -2.8667e-03, -2.2173e-04, -5.5432e-05,\n",
            "        -1.1772e-04, -1.5497e-05, -4.8339e-05, -7.0996e-01, -9.9268e-01,\n",
            "        -5.6419e-03, -1.3281e-01, -1.0000e+00, -8.4639e-06, -1.3709e-06,\n",
            "        -2.3842e-07, -6.5565e-07, -1.0080e-03, -3.1996e-04, -4.2152e-04,\n",
            "        -5.3704e-05, -4.2319e-06, -5.8441e-03, -6.9737e-05, -1.7285e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08028191328048706 0.00689697265625 1.444324254989624 0.33795174956321716 79\n",
            "pred tensor([-2.4438e-06, -8.1658e-06, -1.0073e-05, -1.4770e-04, -4.2892e-04,\n",
            "        -5.6267e-05, -9.5010e-05, -7.0810e-04, -1.1353e-02, -3.6499e-02,\n",
            "        -1.2817e-03, -2.3317e-04, -5.4407e-04, -2.1782e-03, -3.9434e-04,\n",
            "        -1.9646e-04, -2.6627e-02, -2.1994e-04, -2.3232e-03, -1.6451e-03,\n",
            "        -9.4235e-05, -9.9540e-06, -7.7629e-04, -1.0353e-04, -4.5776e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0680464431643486 0.0006756782531738281 1.6811789274215698 0.39043503999710083 130\n",
            "pred tensor([-1.9159e-03, -6.1321e-04, -7.3318e-03, -7.0333e-05, -2.5272e-05,\n",
            "        -4.1723e-07, -2.9802e-07, -4.1723e-07, -1.3828e-05, -1.3292e-04,\n",
            "        -7.5996e-05, -8.0287e-05, -6.3753e-04, -1.6034e-04, -1.0133e-06,\n",
            "        -2.3842e-07, -4.6635e-04, -5.3048e-05, -2.0087e-05, -1.2517e-06,\n",
            "        -1.6797e-04, -4.5738e-03, -4.4670e-03, -5.9664e-05, -6.8626e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0746520608663559 0.0014858245849609375 1.6266177892684937 0.3366270661354065 69\n",
            "pred tensor([-5.1260e-06, -5.1260e-05, -5.4240e-06, -7.9274e-06, -4.4942e-04,\n",
            "        -4.3144e-03, -6.3904e-02, -1.6870e-03, -2.6631e-04, -5.4443e-01,\n",
            "        -4.3823e-01, -9.7852e-01, -3.1830e-02, -1.0000e+00, -3.4809e-05,\n",
            "        -1.2517e-06, -7.1526e-07, -1.3709e-05, -3.5226e-05, -7.3671e-05,\n",
            "        -4.5240e-05, -1.6272e-05, -1.6606e-04, -6.5804e-05, -1.0192e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06284157931804657 0.0014295578002929688 1.610302448272705 0.36049455404281616 98\n",
            "pred tensor([-5.9937e-02, -1.0796e-02, -2.7790e-03, -2.0421e-04, -9.1797e-01,\n",
            "        -1.0000e+00, -3.9935e-06,  0.0000e+00, -9.4235e-05, -5.8413e-06,\n",
            "        -1.2517e-05, -4.7922e-05, -6.0380e-05, -2.6727e-04, -3.1638e-04,\n",
            "        -1.5080e-05, -6.2656e-04, -3.7880e-03, -3.0398e-06, -2.5034e-06,\n",
            "        -2.7704e-04, -3.3630e-02, -4.1161e-03, -5.5611e-05, -6.6817e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07866152375936508 0.002964019775390625 1.5233758687973022 0.33754900097846985 81\n",
            "pred tensor([-8.2195e-05, -1.1139e-03, -1.1187e-03, -1.4133e-03, -2.0862e-05,\n",
            "        -7.0035e-05, -1.7607e-04, -1.2922e-03, -6.9847e-03, -4.7660e-04,\n",
            "        -3.8981e-05, -2.2650e-05, -1.9109e-04, -1.4696e-03, -5.0342e-01,\n",
            "        -9.9854e-01, -1.0000e+00, -1.0000e+00, -1.0000e+00, -7.5459e-05,\n",
            "        -4.7088e-06, -9.5010e-05, -8.9407e-06, -4.7755e-04, -2.3594e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05826310068368912 0.0035877227783203125 1.4722583293914795 0.35077154636383057 106\n",
            "pred tensor([-1.4753e-03, -3.9756e-05, -1.1235e-04, -8.9407e-07, -1.3030e-04,\n",
            "        -5.6028e-06, -1.7881e-07, -9.5367e-07, -2.0146e-05, -7.7486e-07,\n",
            "        -1.4317e-04, -9.9182e-05, -1.1683e-04, -2.1696e-05, -5.4955e-05,\n",
            "        -5.0843e-05, -6.8903e-04, -4.8161e-05, -8.8811e-06, -5.9319e-04,\n",
            "        -6.3848e-04, -3.0212e-03, -2.4109e-03, -3.7694e-04, -2.5511e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07377146184444427 0.0019359588623046875 1.60160231590271 0.35486891865730286 93\n",
            "pred tensor([-2.9037e-02, -1.7346e-01, -4.1113e-01, -9.8682e-01, -9.9170e-01,\n",
            "        -7.9785e-01, -1.3086e-01, -1.0000e+00, -7.0333e-05, -6.7711e-04,\n",
            "        -5.2452e-06, -7.8738e-05, -8.3447e-07, -7.9155e-04, -6.9580e-01,\n",
            "        -4.7646e-03, -8.0872e-04, -1.4954e-03, -3.2425e-05, -2.3687e-04,\n",
            "        -2.7370e-04, -2.8312e-05, -4.0054e-05, -8.7619e-06, -1.5962e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05497662350535393 0.0014429092407226562 1.587273359298706 0.36275118589401245 112\n",
            "pred tensor([-2.1484e-02, -3.0136e-02, -5.8270e-04, -2.1997e-01, -6.5565e-06,\n",
            "        -2.0659e-04, -8.9407e-07, -3.3081e-05, -3.5644e-05, -1.3340e-04,\n",
            "        -3.2961e-05, -5.6877e-03, -3.4153e-05, -7.9691e-05, -6.3181e-06,\n",
            "        -3.2783e-06, -6.5756e-04, -1.2684e-04, -3.5548e-04, -2.8014e-06,\n",
            "        -3.0541e-04, -1.1867e-04, -7.9012e-04, -6.3002e-05, -8.0585e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07633505761623383 0.0017833709716796875 1.650428295135498 0.33427727222442627 71\n",
            "pred tensor([-6.9046e-04, -3.5834e-04, -4.2796e-04, -5.2452e-05, -1.3247e-03,\n",
            "        -1.0691e-03, -5.6791e-04, -9.4366e-04, -1.9638e-02, -3.6716e-03,\n",
            "        -1.0319e-03, -2.5606e-04, -1.1528e-02, -6.6423e-04, -7.4816e-04,\n",
            "        -5.4216e-04, -1.1005e-03, -3.6359e-05, -4.1351e-03, -7.3957e-04,\n",
            "        -1.7029e-01, -9.9902e-01, -1.0000e+00, -1.0000e+00, -1.9989e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050924573093652725 0.00189971923828125 1.5698223114013672 0.3878534138202667 82\n",
            "pred tensor([-1.0000e+00, -1.0000e+00, -3.2349e-03, -1.5855e-05, -7.1526e-07,\n",
            "        -1.4305e-06, -6.7444e-03, -1.7881e-07, -2.9802e-07, -5.3644e-07,\n",
            "        -2.3842e-07, -1.6510e-05, -1.2517e-06, -2.3842e-07, -4.1723e-07,\n",
            "        -6.8521e-04, -1.2815e-05, -7.2718e-06, -5.4240e-06, -4.6372e-04,\n",
            "        -1.2815e-05, -7.5698e-06, -1.2934e-05, -6.7949e-06, -1.4198e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07083350419998169 0.0012540817260742188 1.6063441038131714 0.3342161774635315 65\n",
            "pred tensor([-1.3113e-06, -4.8280e-06, -3.3319e-05, -1.3709e-06, -1.5497e-06,\n",
            "        -6.6137e-04, -8.3374e-02, -9.3896e-01, -7.6172e-01, -6.5231e-04,\n",
            "        -6.1829e-02, -1.7941e-05, -1.7197e-02, -3.3808e-04, -6.0844e-03,\n",
            "        -2.7001e-05, -6.8808e-04, -5.3883e-04, -1.0729e-03, -2.4152e-04,\n",
            "        -1.5857e-01, -8.4229e-01, -9.6729e-01, -9.9463e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04522724822163582 0.001796722412109375 1.6406798362731934 0.38223668932914734 65\n",
            "pred tensor([-9.6240e-01, -9.9854e-01, -1.0000e+00, -5.9605e-08, -7.2122e-06,\n",
            "        -5.9605e-08, -4.5896e-06, -3.0398e-06, -5.1260e-06, -8.0943e-05,\n",
            "        -9.2447e-05, -4.7684e-07, -7.4267e-05, -1.1921e-07, -7.7486e-07,\n",
            "        -3.9339e-06, -3.0828e-04, -2.5864e-03, -2.5511e-04, -4.4250e-03,\n",
            "        -1.3232e-05, -2.3842e-07, -9.6858e-05, -3.4523e-04, -9.7215e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06971012055873871 0.001850128173828125 1.6036714315414429 0.3258931338787079 36\n",
            "pred tensor([-1.1009e-02, -1.8387e-03, -7.2241e-04, -2.3139e-04, -2.0921e-05,\n",
            "        -7.8440e-05, -1.7822e-05, -9.9957e-05, -2.9206e-06, -1.1692e-03,\n",
            "        -1.1325e-05, -5.3644e-07, -5.9605e-06, -1.2887e-04, -5.0068e-06,\n",
            "        -1.7047e-05, -2.1315e-04, -1.2636e-05, -3.8087e-05, -6.1178e-04,\n",
            "        -1.0014e-05, -1.2941e-03, -4.3488e-04, -9.3002e-03, -4.8401e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04833642765879631 0.0011491775512695312 1.6250605583190918 0.35528165102005005 57\n",
            "pred tensor([-3.4027e-03, -2.6684e-03, -4.3654e-04, -1.1063e-04, -1.7881e-07,\n",
            "         0.0000e+00, -1.3113e-06, -5.9605e-08, -2.4199e-05, -2.9802e-07,\n",
            "        -1.0431e-05, -9.5312e-01, -8.0029e-01, -1.0000e+00, -4.1723e-07,\n",
            "         0.0000e+00,  0.0000e+00, -3.5763e-07, -7.1526e-07, -8.9407e-07,\n",
            "        -8.9407e-07, -3.5167e-06, -2.5034e-06, -6.7353e-06, -1.9848e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07693976163864136 0.0009684562683105469 1.6187705993652344 0.3309386670589447 52\n",
            "pred tensor([-2.8193e-05, -9.6500e-05, -2.1040e-05, -1.5295e-04, -2.2292e-05,\n",
            "        -1.6093e-06, -2.1482e-04, -2.4343e-04, -3.8683e-05, -9.1732e-05,\n",
            "        -2.6882e-05, -2.6405e-05, -3.9749e-03, -9.8133e-04, -7.2384e-04,\n",
            "        -2.9469e-04, -4.8876e-06, -8.3447e-06, -1.7881e-07, -2.8431e-05,\n",
            "        -2.5864e-03, -9.9540e-06, -8.1062e-06, -4.8339e-05, -6.0940e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04611732438206673 0.005279541015625 1.4661979675292969 0.33499184250831604 61\n",
            "pred tensor([-8.0943e-05, -4.2140e-05, -9.0301e-05, -1.9073e-06, -5.9605e-08,\n",
            "        -3.2783e-06,  0.0000e+00, -7.6950e-05, -5.9748e-04, -2.5451e-05,\n",
            "        -4.3130e-04, -7.1704e-05, -1.1593e-04, -8.3447e-07, -2.4819e-04,\n",
            "        -2.6836e-03, -1.3137e-04, -1.3888e-05, -2.6417e-04, -8.7744e-01,\n",
            "        -1.0000e+00, -1.0000e+00, -1.0389e-04, -4.1723e-06, -5.2452e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0739077553153038 0.0016012191772460938 1.5566391944885254 0.3339152932167053 62\n",
            "pred tensor([-3.5620e-04, -1.1820e-04, -1.4770e-04, -2.1100e-05, -6.1333e-05,\n",
            "        -1.0023e-03, -4.0829e-05, -1.9670e-06, -3.9756e-05, -1.3723e-03,\n",
            "        -5.8770e-05, -3.9363e-04, -1.0973e-04, -3.7611e-05, -7.0333e-06,\n",
            "        -1.2684e-04, -2.3127e-05, -2.6464e-05, -9.4147e-03, -1.6999e-04,\n",
            "        -6.7329e-04, -3.1567e-04, -1.8701e-01, -3.7079e-03, -1.2064e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04871772229671478 0.002849578857421875 1.540745735168457 0.35809624195098877 85\n",
            "pred tensor([-5.1003e-03, -5.1613e-03, -3.8004e-04, -6.5029e-05, -1.7881e-07,\n",
            "        -1.8179e-05, -7.2718e-06, -3.3508e-02, -6.8140e-04, -1.0757e-03,\n",
            "        -8.1299e-02, -1.4915e-02, -1.5459e-03, -7.6890e-06, -2.6226e-04,\n",
            "        -3.2597e-03, -3.8075e-04, -1.4484e-05, -1.2279e-05, -5.2035e-05,\n",
            "        -1.2517e-06, -2.2054e-06, -8.6427e-06, -1.7738e-04, -1.8525e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07257271558046341 0.0018100738525390625 1.5802433490753174 0.3311458230018616 29\n",
            "pred tensor([-9.8828e-01, -1.9038e-04, -7.6592e-05, -3.6907e-04, -4.3457e-02,\n",
            "        -3.0212e-03, -2.2163e-03, -1.5669e-03, -4.3411e-03, -4.9651e-05,\n",
            "        -1.0777e-03, -2.5024e-03, -3.8544e-02, -1.5747e-02, -3.2687e-04,\n",
            "        -3.3808e-04, -8.0287e-05, -2.3365e-05, -1.1072e-03, -9.8682e-01,\n",
            "        -1.0000e+00, -3.2187e-06, -3.1590e-06, -3.3545e-04, -9.1791e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0554187186062336 0.0005717277526855469 1.6650563478469849 0.3596630096435547 96\n",
            "pred tensor([-3.5648e-03, -1.3405e-02, -6.2895e-04, -2.3842e-07, -2.3842e-07,\n",
            "        -1.0729e-06, -1.7881e-07, -1.1921e-06, -1.8597e-04, -1.8477e-06,\n",
            "        -2.5034e-06, -6.6817e-05, -3.5620e-04, -4.6849e-05, -7.8869e-04,\n",
            "        -1.9646e-04, -1.0099e-03, -7.4530e-04, -1.0133e-06, -7.8440e-05,\n",
            "        -1.6415e-04, -1.3816e-04, -1.2636e-05, -6.1226e-03, -1.4007e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07911501824855804 0.0019683837890625 1.5823290348052979 0.3292498290538788 51\n",
            "pred tensor([-1.2402e-01, -4.6082e-03, -3.0346e-03, -4.4250e-04, -3.1173e-05,\n",
            "        -6.5660e-04, -5.0664e-06, -6.7353e-05, -1.7712e-01, -9.9854e-01,\n",
            "        -1.0000e+00, -3.8743e-06, -5.3644e-07, -2.9802e-07, -3.3498e-05,\n",
            "        -4.5896e-06, -1.1146e-05, -2.7835e-05, -1.5497e-06, -9.0003e-06,\n",
            "        -2.0504e-04, -1.9729e-05, -5.9903e-05, -8.3148e-05, -5.6458e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.049642547965049744 0.0018701553344726562 1.5460331439971924 0.3517589271068573 66\n",
            "pred tensor([-9.9564e-03, -2.4152e-04, -1.2934e-04, -5.3048e-06, -5.3644e-07,\n",
            "        -7.8082e-06, -8.3447e-07, -5.3644e-07, -5.6267e-04, -1.2817e-03,\n",
            "        -1.0729e-06, -2.9206e-06, -1.6630e-05, -1.8775e-05, -3.5167e-06,\n",
            "        -8.3447e-06, -5.3644e-06, -1.0548e-03, -5.3048e-06, -5.9605e-07,\n",
            "        -5.5432e-05, -9.5010e-05, -7.9989e-05, -2.1875e-05, -1.1772e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07421126216650009 0.0009202957153320312 1.5995231866836548 0.3260078430175781 34\n",
            "pred tensor([-7.3373e-05, -2.8014e-04, -3.2187e-05, -4.2915e-06, -4.3333e-05,\n",
            "        -1.2064e-03, -2.0385e-05, -2.3139e-04, -1.6937e-03, -1.6289e-03,\n",
            "        -8.6260e-04, -4.3983e-03, -1.9610e-05, -5.6088e-05, -1.3723e-03,\n",
            "        -3.3617e-05, -6.2048e-05, -2.5749e-05, -1.8568e-03, -1.6680e-03,\n",
            "        -3.6354e-03, -6.2500e-02, -5.3596e-04, -7.0429e-04, -9.6741e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050815533846616745 0.000457763671875 1.6274443864822388 0.3732575476169586 83\n",
            "pred tensor([-4.4775e-04, -5.3692e-04, -1.6327e-03,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00, -2.3842e-06, -4.7684e-07, -5.3329e-03, -2.7955e-05,\n",
            "        -7.8535e-04, -5.3644e-06, -1.1921e-07, -9.9805e-01, -1.0000e+00,\n",
            "        -2.2411e-05, -1.0490e-05, -2.6941e-04, -6.1393e-06, -4.6313e-05,\n",
            "        -2.2292e-05, -1.2064e-03, -1.4901e-05, -2.4152e-04, -3.0065e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07860821485519409 0.0018596649169921875 1.5238862037658691 0.32321029901504517 36\n",
            "pred tensor([-2.3186e-05, -1.0473e-04, -3.6469e-02, -1.7891e-03, -3.7789e-05,\n",
            "        -5.9903e-05, -2.0351e-03, -1.3168e-02, -3.2377e-04, -1.2934e-04,\n",
            "        -5.6744e-05, -3.8910e-04, -1.9073e-06, -2.6474e-03, -1.2732e-01,\n",
            "        -5.5573e-02, -1.1635e-04, -7.1487e-03, -6.4015e-05, -4.3809e-05,\n",
            "        -1.5821e-03, -1.8096e-04, -2.2354e-02, -2.0587e-04, -4.0942e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05273227393627167 0.0005235671997070312 1.6688432693481445 0.3551483452320099 68\n",
            "6\n",
            "pred tensor([-1.9073e-05, -4.6492e-05, -5.4121e-05, -3.5763e-07,  0.0000e+00,\n",
            "        -2.2054e-06, -2.9325e-05,  0.0000e+00, -3.5763e-07, -1.1969e-03,\n",
            "        -3.5763e-07, -1.4901e-06, -2.1636e-05, -3.8505e-05, -3.6621e-04,\n",
            "        -4.1127e-06, -2.9564e-05, -2.6505e-02, -7.3314e-06, -4.4525e-05,\n",
            "        -1.3292e-04, -1.4043e-04, -7.7486e-07, -5.9605e-08, -4.4525e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07920551300048828 0.002197265625 1.522542119026184 0.324423611164093 32\n",
            "pred tensor([-2.8564e-02, -3.9673e-03, -4.5300e-06, -4.8161e-05, -1.9407e-04,\n",
            "        -2.6727e-04, -1.2147e-04, -2.8253e-04, -1.1623e-05, -5.9605e-08,\n",
            "        -2.9802e-07, -5.7068e-03, -1.0000e+00, -8.1658e-06,  0.0000e+00,\n",
            "         0.0000e+00, -5.9605e-08, -1.7881e-07, -5.9605e-08, -3.5763e-07,\n",
            "        -2.3842e-07, -1.1921e-07, -3.6061e-05, -7.1526e-07, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.051934387534856796 0.004913330078125 1.4378701448440552 0.3385608494281769 79\n",
            "pred tensor([-9.0723e-01, -2.0251e-01, -6.3599e-02, -8.3447e-07,  0.0000e+00,\n",
            "        -5.9605e-08, -3.4809e-05, -1.3113e-06, -2.6722e-03, -1.6451e-05,\n",
            "         0.0000e+00, -2.2650e-06, -1.1921e-07, -5.9605e-08, -6.7115e-05,\n",
            "        -4.7722e-03, -3.5763e-07, -2.5225e-04, -2.3246e-06, -1.4246e-05,\n",
            "        -1.1921e-07, -8.3447e-07, -1.2517e-06, -1.7762e-05, -3.6297e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08204751461744308 0.0013599395751953125 1.5628725290298462 0.33716970682144165 28\n",
            "pred tensor([-1.7204e-03, -7.4267e-05, -1.7607e-04, -6.6340e-05, -3.6359e-06,\n",
            "        -1.3173e-05, -1.0371e-05, -5.7399e-05, -1.5974e-05, -5.4646e-04,\n",
            "        -1.6956e-01, -1.7319e-02, -7.0740e-02, -9.7363e-01, -4.2915e-06,\n",
            "        -8.2850e-05, -1.1578e-03, -8.3506e-05, -6.8521e-04, -8.4639e-06,\n",
            "        -4.8208e-04, -1.7166e-05, -2.1744e-04, -3.5167e-06, -7.4387e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04710694029927254 0.00104522705078125 1.5561519861221313 0.3462888300418854 59\n",
            "pred tensor([-1.4429e-01, -4.1351e-03, -2.7275e-04, -4.0531e-06,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1856e-05, -2.2049e-03,\n",
            "        -3.5763e-07, -1.2636e-05, -1.4043e-04, -2.5916e-04, -1.0000e+00,\n",
            "        -5.9605e-08,  0.0000e+00,  0.0000e+00, -2.3842e-07, -1.7881e-07,\n",
            "        -1.5855e-05, -5.3644e-07, -1.0031e-04, -1.8060e-05, -2.3842e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08255080878734589 0.004306793212890625 1.4549012184143066 0.3351062536239624 22\n",
            "pred tensor([-1.5497e-06, -5.1212e-04, -3.9935e-06, -5.6088e-05, -3.3379e-06,\n",
            "        -1.5402e-03, -5.2869e-05, -1.1504e-04, -2.7370e-04, -2.0504e-03,\n",
            "        -6.2048e-05, -8.8835e-04, -3.5431e-02, -1.0109e-04, -2.7637e-03,\n",
            "        -5.8212e-03, -2.5988e-05, -1.3199e-03, -8.5473e-05, -2.8275e-02,\n",
            "        -7.6294e-04, -3.4237e-03, -1.4610e-03, -1.9109e-04, -3.6850e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050987713038921356 0.001796722412109375 1.5464434623718262 0.36616089940071106 58\n",
            "pred tensor([-2.3878e-04, -2.0659e-04, -1.6749e-05, -5.9605e-08, -1.1921e-07,\n",
            "        -5.0664e-06, -1.8063e-03, -8.2195e-05, -5.9605e-08, -1.7107e-05,\n",
            "        -3.8743e-06, -8.3447e-07, -1.9073e-06, -3.0398e-06, -3.2187e-06,\n",
            "        -7.2594e-03, -9.9463e-01, -1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00, -1.0729e-06, -5.9605e-08, -2.5094e-05, -5.3644e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08102359622716904 0.00281524658203125 1.4929531812667847 0.3374082148075104 25\n",
            "pred tensor([-5.7220e-06, -2.3842e-07, -5.9605e-08, -1.1921e-07, -7.7486e-06,\n",
            "        -5.4538e-05, -4.0233e-05, -1.7703e-05, -8.5831e-06, -4.8339e-05,\n",
            "        -9.9957e-05, -4.9829e-04, -2.9802e-06, -1.2684e-04, -2.6536e-04,\n",
            "        -4.1260e-01, -8.4162e-05, -3.3998e-04, -1.0681e-04, -6.2048e-05,\n",
            "        -4.9293e-05, -2.1827e-04, -3.4928e-05, -9.3651e-04, -2.8553e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.048604898154735565 0.00146484375 1.5410761833190918 0.33265092968940735 50\n",
            "pred tensor([-1.6870e-03, -1.0307e-02, -4.6492e-05, -1.7762e-05,  0.0000e+00,\n",
            "        -1.0014e-05, -5.3704e-05, -2.3842e-06, -1.9670e-06, -8.3771e-03,\n",
            "        -2.0862e-06, -1.7881e-06, -8.9407e-07, -4.1723e-07, -4.5896e-06,\n",
            "        -5.9605e-08, -5.9009e-06, -5.9605e-08, -3.4729e-02, -2.4247e-04,\n",
            "        -9.6560e-06, -3.1054e-05, -3.8147e-06, -3.1829e-05, -1.9944e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08013466745615005 0.0008649826049804688 1.596235990524292 0.33491918444633484 37\n",
            "pred tensor([-2.0554e-02, -1.5402e-03, -2.5654e-03, -4.1306e-05, -1.0371e-05,\n",
            "        -7.8142e-05, -2.0862e-06, -8.2016e-04, -2.4796e-05, -8.0872e-04,\n",
            "        -2.0921e-05, -1.9550e-05, -2.0862e-06, -2.9802e-06, -7.7486e-07,\n",
            "        -1.9121e-03, -3.2495e-01, -9.4528e-03, -2.5415e-04, -1.1235e-04,\n",
            "        -1.5593e-04, -2.9663e-01, -9.9854e-01, -9.9902e-01, -1.1854e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04998057335615158 0.0007939338684082031 1.6196213960647583 0.3383443355560303 55\n",
            "pred tensor([-3.8013e-03, -3.6640e-03, -5.4893e-03, -9.5367e-07, -5.9605e-08,\n",
            "        -8.9407e-07, -3.9339e-06, -5.9605e-08, -4.3154e-05, -9.4175e-06,\n",
            "        -3.5763e-07, -5.3644e-06, -5.3453e-04, -2.0027e-03, -2.4438e-06,\n",
            "        -2.6727e-04, -1.3340e-04, -3.0398e-06, -9.6083e-05, -1.8597e-04,\n",
            "        -3.6776e-05, -3.3081e-05, -8.8644e-04, -2.3127e-05, -1.4651e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0701480358839035 0.0005998611450195312 1.5978275537490845 0.32852914929389954 31\n",
            "pred tensor([-8.3923e-04, -2.9343e-02, -3.3894e-03, -6.3379e-01, -8.1250e-01,\n",
            "        -1.0000e+00, -4.0233e-05, -2.6226e-06, -1.7285e-06, -3.1757e-04,\n",
            "        -8.6486e-05, -5.0664e-06, -4.1127e-06, -1.2770e-03, -9.5367e-05,\n",
            "        -1.0262e-03, -3.5429e-04, -1.5736e-03, -1.4553e-03, -4.3821e-04,\n",
            "        -5.9903e-05, -2.0905e-03, -5.7602e-04, -4.5300e-04, -5.9814e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05215194448828697 0.00019741058349609375 1.653846025466919 0.34121137857437134 78\n",
            "pred tensor([-4.0054e-05, -8.5473e-05, -4.1485e-05, -3.5763e-07, -1.1665e-02,\n",
            "        -1.9670e-06, -2.0587e-04, -3.2687e-04, -8.3804e-05, -1.7614e-03,\n",
            "        -3.5038e-03, -4.6492e-05, -1.5616e-05, -3.1257e-04, -5.7817e-06,\n",
            "        -3.9744e-04, -8.6451e-04, -6.3992e-04, -1.5163e-03, -7.2060e-03,\n",
            "        -3.4738e-04, -6.0701e-04, -2.1696e-05, -8.6784e-04, -3.2783e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06885835528373718 0.0012760162353515625 1.5666577816009521 0.35558128356933594 48\n",
            "pred tensor([-2.1756e-05, -2.9564e-05, -6.6414e-03, -1.4317e-04, -7.3338e-04,\n",
            "        -5.0664e-06, -1.0967e-05, -5.7793e-04, -8.4114e-04, -1.0270e-04,\n",
            "        -3.5217e-02, -1.0000e+00, -5.9605e-07, -1.0610e-05, -3.1590e-06,\n",
            "        -2.9802e-06, -4.8518e-05, -7.6294e-06, -2.6941e-04, -7.9989e-05,\n",
            "        -4.2319e-05, -5.6601e-04, -2.7537e-05, -7.0953e-03, -1.7762e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05063590034842491 0.0045928955078125 1.5149890184402466 0.34629279375076294 89\n",
            "pred tensor([-6.0205e-01, -3.1982e-01, -2.0447e-01, -3.3970e-03, -3.6597e-05,\n",
            "        -1.7881e-07, -7.1526e-06, -5.9605e-08, -1.1027e-05, -3.2949e-04,\n",
            "        -1.1915e-04, -9.0742e-04, -2.4915e-04, -5.4538e-05, -4.1842e-05,\n",
            "        -5.3704e-05, -4.5395e-04, -4.4417e-04, -4.0497e-02, -3.0899e-04,\n",
            "        -1.0674e-02, -4.1901e-02, -4.3732e-02, -6.8213e-01, -7.1777e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0739702433347702 0.00323486328125 1.5157076120376587 0.3428221046924591 81\n",
            "pred tensor([-1.4305e-05, -5.9414e-04, -3.3627e-03, -1.4091e-04, -7.9632e-04,\n",
            "        -1.0633e-03, -4.2057e-04, -1.9531e-01, -1.0000e+00, -5.2273e-05,\n",
            "        -2.1696e-05, -1.6272e-05, -7.4883e-03, -7.8392e-04, -7.4673e-04,\n",
            "        -1.6108e-03, -2.3401e-01, -6.2904e-03, -1.1528e-02, -3.1109e-03,\n",
            "        -1.4925e-03, -9.2041e-02, -6.2294e-03, -9.5508e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04724690690636635 0.001659393310546875 1.5348105430603027 0.360444039106369 71\n",
            "pred tensor([-7.6065e-03, -5.5933e-04, -5.6505e-05, -1.7643e-05, -1.5497e-06,\n",
            "        -2.5034e-06, -1.9073e-06, -8.4639e-06, -2.5749e-05, -5.9009e-06,\n",
            "        -4.7207e-05, -5.4836e-04, -2.7275e-04, -7.6950e-05, -2.3055e-04,\n",
            "        -2.3975e-03, -6.0141e-05, -1.3075e-03, -4.7646e-03, -1.9610e-05,\n",
            "        -8.5235e-06, -7.7486e-07, -1.4450e-02, -3.4261e-04, -1.0973e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06881707161664963 0.0025634765625 1.5041694641113281 0.3456991910934448 49\n",
            "pred tensor([-6.2585e-06, -1.0862e-03, -2.5129e-04, -1.2457e-05, -1.4410e-03,\n",
            "        -1.2457e-05, -1.1473e-03, -2.6941e-04, -3.1357e-03, -4.1485e-04,\n",
            "        -5.9128e-03, -1.7204e-03, -1.4238e-03, -2.5392e-05, -9.1732e-05,\n",
            "        -5.6076e-03, -1.6422e-03, -4.8971e-04, -9.9945e-03, -8.2552e-05,\n",
            "        -1.5473e-04, -3.0339e-05, -2.4629e-04, -2.2476e-02, -7.3338e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05033008009195328 0.002185821533203125 1.474151849746704 0.3509995937347412 75\n",
            "pred tensor([-1.5039e-03, -8.8453e-04, -5.8174e-04, -6.0618e-05, -2.4438e-04,\n",
            "        -1.5335e-03, -5.3048e-06, -1.8966e-04, -1.9516e-02, -9.9414e-01,\n",
            "        -1.0000e+00, -3.4571e-06, -5.3314e-02, -9.8584e-01, -1.4816e-02,\n",
            "        -4.8208e-04, -5.4538e-05, -6.9714e-04, -5.2977e-04, -1.9073e-06,\n",
            "        -3.1471e-05, -3.3379e-06, -9.8572e-03, -6.5660e-04, -1.4198e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06525864452123642 0.0008311271667480469 1.5923864841461182 0.3283888101577759 45\n",
            "pred tensor([-3.6061e-05, -2.8253e-04, -1.9760e-03, -5.1079e-03, -9.5062e-03,\n",
            "        -5.4240e-06, -5.1022e-04, -7.7343e-04, -1.4901e-05, -2.9926e-03,\n",
            "        -9.7412e-02, -7.5388e-04, -5.1439e-05, -1.1593e-04, -2.0752e-03,\n",
            "        -6.9499e-05, -1.8883e-04, -8.0957e-01, -4.4458e-01, -7.2479e-03,\n",
            "        -8.3303e-04, -9.9540e-05, -1.7614e-03, -1.2004e-04, -6.3539e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050942372530698776 0.0011463165283203125 1.563273310661316 0.35573604702949524 89\n",
            "pred tensor([-7.0333e-05, -8.5735e-04, -7.5674e-04, -4.0474e-03, -1.2934e-05,\n",
            "        -4.4937e-03, -1.8167e-04, -6.0129e-04, -3.9279e-05, -5.7817e-06,\n",
            "        -4.9472e-06, -2.5630e-06, -3.3498e-05, -4.9639e-04, -2.0087e-05,\n",
            "        -4.5240e-05, -4.4346e-05, -2.6011e-04, -5.9175e-04, -1.0147e-03,\n",
            "        -2.8086e-04, -3.9355e-01, -1.0000e+00, -1.7607e-04, -1.8477e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06569211930036545 0.00113677978515625 1.5906766653060913 0.3441544771194458 42\n",
            "pred tensor([-7.2174e-03, -5.7602e-04, -2.8931e-02, -3.3736e-05, -8.8811e-06,\n",
            "        -2.2233e-05, -2.2650e-06, -1.7881e-07, -1.9431e-05, -3.6955e-06,\n",
            "        -2.9826e-04, -1.4305e-05, -1.9608e-03, -5.6190e-03, -6.3744e-03,\n",
            "        -4.3821e-04, -1.1139e-03, -1.3123e-03, -4.7183e-04, -2.5406e-03,\n",
            "        -1.7204e-03, -2.7299e-05, -2.4247e-04, -5.3287e-05, -1.1683e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05167553946375847 0.00252532958984375 1.4960236549377441 0.3371545374393463 64\n",
            "pred tensor([-9.9707e-01, -1.0000e+00, -6.1188e-02, -3.8940e-02, -3.1548e-03,\n",
            "        -3.1447e-04, -2.3499e-03, -4.3225e-04, -2.4438e-06, -4.9293e-05,\n",
            "        -4.7632e-01, -9.9951e-01, -1.0000e+00, -1.0729e-06, -1.3709e-06,\n",
            "        -8.7857e-05, -4.7684e-06, -4.9472e-06, -1.3828e-05, -1.9670e-05,\n",
            "        -4.0531e-06, -5.9426e-05, -3.5763e-07, -6.1913e-03, -5.9009e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06418292224407196 0.00949859619140625 1.4348537921905518 0.36198103427886963 44\n",
            "pred tensor([-3.5357e-04, -2.3842e-06, -2.2709e-05, -2.1994e-04, -6.1095e-05,\n",
            "        -2.6627e-02, -3.5644e-05, -1.0729e-06, -3.8319e-03, -5.6250e-01,\n",
            "        -2.3060e-03, -1.0000e+00, -8.2850e-06, -1.1921e-07, -3.7551e-06,\n",
            "        -2.3842e-07, -2.8014e-06, -1.0133e-06, -1.8477e-06, -1.8120e-05,\n",
            "        -1.4651e-04, -9.0599e-06, -1.9252e-05, -1.6630e-05, -1.0431e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05459218844771385 0.0032749176025390625 1.5539536476135254 0.33838969469070435 54\n",
            "pred tensor([-5.3358e-04, -4.0855e-03, -1.3687e-02, -1.5020e-05, -1.4961e-05,\n",
            "        -1.5378e-05, -1.5497e-06, -3.1173e-05, -1.7059e-04, -4.3809e-05,\n",
            "        -7.7248e-05, -4.8280e-06, -9.0599e-06, -4.8876e-06, -2.3842e-07,\n",
            "        -3.8743e-06, -3.0458e-05, -2.2423e-04, -1.7166e-02, -3.8815e-04,\n",
            "        -5.3692e-04, -6.7854e-04, -4.1084e-03, -3.0339e-05, -1.1963e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06325973570346832 0.0005278587341308594 1.6341605186462402 0.3271175026893616 35\n",
            "pred tensor([-2.9206e-05, -5.3048e-05, -6.9714e-04, -1.8454e-04, -3.2739e-01,\n",
            "        -8.8428e-01, -1.0000e+00, -2.4247e-04, -1.2100e-05, -2.3878e-04,\n",
            "        -1.0252e-05, -1.9562e-04, -1.8167e-04, -1.5974e-05, -5.5265e-04,\n",
            "        -9.6989e-04, -5.4359e-05, -3.9551e-02, -5.9426e-05, -1.0967e-05,\n",
            "        -4.7660e-04, -4.0054e-05, -5.8174e-04, -5.1308e-04, -2.9325e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05376037582755089 4.5299530029296875e-05 1.8091334104537964 0.348568856716156 71\n",
            "pred tensor([-1.2195e-04, -3.8853e-03, -1.1917e-02, -4.7278e-04, -5.0664e-06,\n",
            "        -1.3661e-04, -4.3511e-06, -5.2273e-05, -6.6280e-04, -1.0757e-03,\n",
            "        -6.8808e-04, -1.6451e-03, -8.0466e-06, -1.2934e-05, -8.6260e-04,\n",
            "        -6.7949e-06, -5.6088e-05, -5.4836e-06, -4.4346e-04, -6.7568e-04,\n",
            "        -2.3305e-05, -1.1265e-05, -8.5473e-05, -2.7418e-06, -5.9605e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06758337467908859 0.00037670135498046875 1.6927952766418457 0.33437061309814453 60\n",
            "pred tensor([-4.6372e-04, -4.8876e-05, -1.1307e-02, -5.9187e-05, -2.9862e-05,\n",
            "        -4.3631e-05, -7.8142e-05, -2.8193e-05, -7.2837e-05, -1.1367e-04,\n",
            "        -1.3983e-04, -3.1590e-06, -4.3809e-05, -2.3246e-06, -7.4506e-06,\n",
            "        -2.9802e-07, -1.3709e-06, -7.7486e-07, -5.6028e-06, -4.2915e-06,\n",
            "        -9.6500e-05, -5.4836e-06, -1.1545e-04, -1.7204e-03, -4.4107e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05635228380560875 0.00021791458129882812 1.6527161598205566 0.3417758345603943 75\n",
            "pred tensor([-8.4591e-04, -3.3927e-04, -2.2392e-03, -6.9189e-04, -1.1921e-06,\n",
            "        -8.7023e-06, -1.6332e-05, -1.5914e-05, -3.1948e-05, -4.2558e-04,\n",
            "        -2.8312e-05, -1.2004e-04, -6.9201e-05, -1.9875e-03, -2.7955e-05,\n",
            "        -1.2732e-04, -3.1173e-05, -1.1492e-03, -6.0141e-05, -8.5068e-04,\n",
            "        -2.5821e-04, -1.5056e-04, -4.4167e-05, -4.1723e-07, -1.8477e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06629883497953415 0.0005602836608886719 1.64132821559906 0.34485530853271484 63\n",
            "pred tensor([-7.3969e-05, -7.0930e-06, -1.1456e-04, -2.1696e-05, -4.2319e-05,\n",
            "        -8.3506e-05, -1.3983e-04, -7.3135e-05, -6.3300e-05, -3.7611e-05,\n",
            "        -2.5010e-04, -1.3185e-04, -1.6928e-05, -6.3300e-05, -4.3396e-02,\n",
            "        -6.8665e-04, -4.4312e-02, -5.0293e-01, -1.0000e+00, -1.4901e-06,\n",
            "        -6.8545e-06, -9.4593e-05, -6.8665e-05, -1.6391e-05, -1.0312e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05752776563167572 0.003940582275390625 1.443704605102539 0.3443641662597656 61\n",
            "pred tensor([-1.5015e-01, -9.9951e-01, -9.9805e-01, -1.0000e+00, -1.1997e-03,\n",
            "        -2.6011e-04, -1.9038e-04, -5.3465e-05, -1.3113e-05, -1.2338e-04,\n",
            "        -2.9802e-06, -3.3512e-03, -4.3631e-05, -8.4591e-04, -7.1239e-04,\n",
            "        -7.5459e-05, -3.3319e-05, -7.9036e-05, -4.3988e-05, -3.2187e-06,\n",
            "        -1.0948e-03, -5.7869e-03, -9.7942e-04, -1.2159e-05, -7.7486e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0670359656214714 0.0035858154296875 1.4670960903167725 0.3300834894180298 62\n",
            "pred tensor([-2.5630e-06, -1.9789e-04, -1.2100e-05, -4.5471e-03, -5.9009e-06,\n",
            "        -4.6134e-05, -1.3030e-04, -2.1315e-04, -4.9162e-04, -1.6415e-04,\n",
            "        -2.8849e-05, -4.0054e-05, -5.1022e-05, -1.3590e-05, -3.0470e-04,\n",
            "        -1.0605e-03, -1.2338e-04, -8.9943e-05, -1.4439e-03, -5.0068e-05,\n",
            "        -1.3447e-04, -1.4424e-04, -6.6042e-05, -6.1455e-03, -7.1812e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05241180211305618 0.004413604736328125 1.4779551029205322 0.3348810076713562 52\n",
            "pred tensor([-5.8603e-04, -1.8158e-02, -1.2481e-04, -6.5234e-01, -2.3499e-03,\n",
            "        -8.4448e-04, -4.4167e-05, -7.6294e-05, -1.8454e-04, -8.4152e-03,\n",
            "        -7.4267e-05, -2.9981e-05, -4.8876e-06, -2.4872e-03, -4.2796e-05,\n",
            "        -2.6631e-04, -4.7386e-05, -1.1683e-04, -3.4595e-04, -6.5804e-05,\n",
            "        -8.3113e-04, -6.2525e-05, -6.5660e-04, -2.3422e-03, -7.3682e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0692540854215622 0.004703521728515625 1.4324982166290283 0.34742310643196106 64\n",
            "pred tensor([-5.2917e-02, -1.0828e-01, -3.3997e-02, -5.2032e-02, -1.5503e-01,\n",
            "        -4.9829e-04, -7.3314e-06, -2.3139e-04, -2.4819e-04, -1.4313e-02,\n",
            "        -8.5926e-04, -5.3635e-03, -3.5675e-02, -1.5516e-03, -5.0507e-03,\n",
            "        -3.3276e-01, -1.2865e-03, -2.5311e-03, -5.1689e-03, -5.3358e-04,\n",
            "        -3.5524e-05, -8.1711e-03, -9.9463e-01, -9.9951e-01, -9.9951e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.055983975529670715 0.002872467041015625 1.5221811532974243 0.34683239459991455 47\n",
            "pred tensor([-6.1893e-04, -1.3222e-02, -6.1913e-03, -4.1127e-06, -2.2411e-05,\n",
            "        -5.5432e-06, -2.2650e-06, -3.2687e-04, -1.4007e-05, -1.7576e-03,\n",
            "        -1.7786e-03, -5.0621e-03, -1.7958e-03, -6.0141e-05, -5.8055e-05,\n",
            "        -4.4513e-04, -1.5378e-05, -2.8839e-03, -1.3709e-05, -2.1744e-03,\n",
            "        -1.7443e-03, -2.9981e-05, -2.9206e-06, -2.9206e-06, -4.1723e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06434072554111481 0.00033664703369140625 1.7422994375228882 0.3268912434577942 36\n",
            "pred tensor([-7.6890e-06, -9.4235e-05, -1.1787e-03, -2.8467e-04, -3.2842e-05,\n",
            "        -3.0994e-03, -5.9175e-04, -7.2539e-05, -1.9872e-04, -1.7071e-03,\n",
            "        -1.1292e-02, -9.8389e-01, -1.0000e+00, -1.4997e-04, -2.6822e-06,\n",
            "        -4.1485e-05, -6.1393e-06, -1.3983e-04, -5.1856e-06, -4.9472e-06,\n",
            "        -1.1563e-05, -2.3484e-05, -1.3374e-02, -1.2100e-04, -1.1414e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05835426226258278 0.00044918060302734375 1.6587212085723877 0.3499412536621094 46\n",
            "pred tensor([-1.6813e-03, -9.1400e-03, -2.9469e-04, -2.7847e-03, -8.8215e-06,\n",
            "        -2.0564e-05, -1.1034e-03, -8.7142e-05, -6.9857e-04, -7.1907e-03,\n",
            "        -5.9891e-04, -6.3777e-06, -1.1325e-06, -3.5167e-06, -8.5907e-03,\n",
            "        -2.4438e-06, -2.5501e-03, -5.1117e-04, -3.1605e-03, -6.1560e-04,\n",
            "        -8.9407e-07, -6.5029e-05, -5.9013e-03, -3.1567e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06723364442586899 0.0006465911865234375 1.602574110031128 0.3572767376899719 42\n",
            "pred tensor([-1.0000e+00, -2.0266e-04, -1.1625e-03, -2.2519e-04, -6.0577e-02,\n",
            "        -7.2670e-04, -7.2813e-04, -2.8610e-05, -8.1539e-05, -4.4525e-05,\n",
            "        -4.0531e-06, -2.4557e-05, -5.5432e-05, -2.9445e-05, -1.8120e-05,\n",
            "        -2.2650e-06, -1.7285e-06, -2.3246e-06, -5.6624e-06, -5.8413e-06,\n",
            "        -9.6560e-06, -2.3365e-05, -1.2878e-01, -1.8673e-03, -1.6749e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052498068660497665 0.0002541542053222656 1.6687958240509033 0.3495911955833435 38\n",
            "7\n",
            "pred tensor([-2.2411e-05, -2.6405e-05, -1.7536e-04, -1.5914e-05, -2.3842e-07,\n",
            "        -5.9605e-08, -3.5763e-07, -2.7847e-03, -1.7822e-05, -9.2804e-05,\n",
            "        -1.3709e-06, -1.7679e-04, -1.7881e-07, -1.7881e-07,  0.0000e+00,\n",
            "        -5.9605e-08, -1.3145e-02, -4.1723e-07, -3.4690e-05, -2.3842e-06,\n",
            "        -1.2517e-06, -2.9802e-07, -1.5175e-04, -5.7161e-05, -1.5497e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06283196061849594 0.0013141632080078125 1.6236693859100342 0.3285212516784668 34\n",
            "pred tensor([-6.0129e-04, -6.0387e-03, -8.7500e-05, -7.1812e-04, -9.3848e-01,\n",
            "        -9.9951e-01, -2.7418e-06, -2.6360e-03, -7.9274e-06, -5.9426e-05,\n",
            "        -8.5235e-06, -1.2994e-05, -1.9670e-05, -3.5763e-06, -3.9935e-06,\n",
            "        -5.9605e-08, -6.3181e-06, -1.2517e-06, -1.1921e-07, -4.5300e-06,\n",
            "        -5.0926e-04, -4.8485e-03, -1.0967e-05, -3.4273e-05, -1.1921e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05555175617337227 0.00138092041015625 1.6357120275497437 0.3848704695701599 44\n",
            "pred tensor([-1.3245e-01, -5.6458e-04, -1.0556e-04, -6.6161e-06, -5.9605e-08,\n",
            "        -1.7881e-06, -1.4722e-05, -3.2544e-05, -2.8181e-04, -1.4937e-04,\n",
            "        -1.0270e-04, -3.0899e-04, -6.4790e-05, -1.8954e-05, -2.2519e-04,\n",
            "        -1.8656e-05, -1.0431e-05, -1.5335e-03, -7.8678e-06, -1.1921e-07,\n",
            "         0.0000e+00, -7.8678e-06, -5.4688e-02, -9.9951e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06847939640283585 0.003917694091796875 1.5311217308044434 0.35278674960136414 58\n",
            "pred tensor([-3.7789e-05, -2.4140e-05, -9.1457e-04, -1.1921e-06, -5.7638e-05,\n",
            "        -1.7583e-05, -6.6757e-06, -1.7881e-06, -9.0933e-04, -1.2040e-05,\n",
            "        -6.5267e-05, -2.8729e-05, -2.0142e-03, -4.4346e-05, -1.8101e-03,\n",
            "        -2.9826e-04, -7.2718e-06, -1.0192e-05, -1.7138e-03, -1.3170e-03,\n",
            "        -7.5500e-02, -9.7803e-01, -8.8428e-01, -4.6492e-06, -1.7881e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05619821324944496 0.0040435791015625 1.5697687864303589 0.36196210980415344 53\n",
            "pred tensor([-1.9264e-04, -2.9240e-03, -1.4651e-04, -1.3590e-05, -1.3332e-03,\n",
            "        -2.3842e-07, -1.6689e-06, -4.8280e-06, -6.5029e-05, -1.9073e-05,\n",
            "        -1.1921e-07, -1.7285e-06, -2.5034e-06, -7.7486e-06, -2.3842e-07,\n",
            "        -1.9717e-04, -1.4651e-04, -6.5565e-07, -1.1593e-04, -1.6332e-05,\n",
            "        -2.8312e-05, -8.0943e-05, -1.0431e-05, -2.4343e-04, -7.3099e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07438843697309494 0.0025463104248046875 1.577074408531189 0.3321516215801239 66\n",
            "pred tensor([-4.6492e-06, -4.5061e-05, -1.7881e-07, -1.7285e-06, -4.9472e-05,\n",
            "        -1.1504e-04, -4.2915e-06, -1.2693e-03, -1.4544e-04, -7.5996e-05,\n",
            "        -4.5133e-04, -1.9670e-06, -7.9489e-04, -9.1016e-05, -9.0742e-04,\n",
            "        -5.4359e-03, -4.1275e-03, -9.0967e-01, -9.7168e-01, -1.5175e-04,\n",
            "        -9.5703e-01, -9.9902e-01, -9.9951e-01, -4.9829e-04, -7.8249e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058980878442525864 0.0009441375732421875 1.5782077312469482 0.34677281975746155 54\n",
            "pred tensor([-2.9981e-05, -4.3654e-04, -1.6327e-03, -1.0270e-04, -2.7490e-04,\n",
            "        -1.4007e-05, -1.4544e-05, -1.3113e-06, -1.0848e-05, -1.3018e-03,\n",
            "        -3.7932e-04, -3.2067e-05, -3.9339e-06, -4.3809e-05, -1.6475e-04,\n",
            "        -9.8877e-01, -3.6499e-01, -7.3535e-01, -1.7487e-02, -1.6190e-02,\n",
            "        -5.7459e-04, -1.5888e-03, -8.2195e-05, -4.3988e-05, -1.4961e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07546474039554596 0.0004353523254394531 1.7457443475723267 0.3359861373901367 74\n",
            "pred tensor([-1.4753e-03, -4.0531e-05, -5.2023e-04, -2.7418e-06, -4.8339e-05,\n",
            "        -6.3181e-06, -7.9041e-03, -1.6699e-01, -1.6687e-01, -4.6112e-02,\n",
            "        -2.0447e-02, -5.9814e-02, -2.2144e-01, -9.0866e-03, -8.1100e-03,\n",
            "        -1.7004e-01, -9.8779e-01, -2.1399e-01, -2.4147e-03, -1.8425e-03,\n",
            "        -1.5306e-03, -2.0676e-03, -6.1111e-03, -2.0182e-04, -1.4782e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05253250151872635 0.0007824897766113281 1.6926419734954834 0.3692591190338135 62\n",
            "pred tensor([-1.1730e-04, -5.2273e-05, -2.8014e-04, -3.2425e-05, -5.3883e-05,\n",
            "        -7.0035e-05, -8.8215e-06, -7.1526e-07, -6.6895e-01, -1.0729e-06,\n",
            "        -3.5156e-02, -9.5337e-02, -3.4119e-02, -9.3506e-01, -4.3511e-05,\n",
            "        -1.5795e-05, -4.2319e-06, -4.0221e-04, -4.1306e-05, -1.2100e-04,\n",
            "        -3.5620e-04, -4.7386e-05, -1.7047e-05, -1.4365e-05, -1.7822e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07879945635795593 0.0007205009460449219 1.619105339050293 0.3575971722602844 67\n",
            "pred tensor([-2.2340e-04, -3.4809e-05, -1.0133e-06, -1.4526e-01, -1.0431e-04,\n",
            "        -7.6592e-05, -1.8477e-06, -3.2234e-03, -4.4703e-06, -1.0986e-03,\n",
            "        -1.6327e-03, -8.1897e-05, -1.7941e-05, -1.2517e-06, -1.8966e-04,\n",
            "        -3.1677e-02, -1.0000e+00, -1.0000e+00, -6.2637e-03, -8.0872e-04,\n",
            "        -1.4424e-05, -2.2709e-05, -1.6153e-05, -6.8426e-05, -1.7762e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06241587921977043 0.00234222412109375 1.5123322010040283 0.3553352355957031 73\n",
            "pred tensor([-1.8005e-02, -3.0420e-01, -2.7344e-02, -1.2291e-02, -1.7138e-03,\n",
            "        -2.4962e-04, -7.7698e-02, -1.5930e-01, -1.1467e-02, -1.1053e-03,\n",
            "        -1.7614e-03, -6.3300e-05, -9.0027e-03, -7.0930e-06, -1.2934e-05,\n",
            "        -1.0133e-06, -5.7161e-05,  0.0000e+00,  0.0000e+00, -1.0718e-01,\n",
            "        -2.0410e-01, -7.6221e-01, -1.0000e+00, -2.9206e-06, -4.7684e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07360342144966125 0.004894256591796875 1.4986376762390137 0.3437809646129608 50\n",
            "pred tensor([-4.5896e-06, -3.5620e-04, -2.8729e-05, -1.3411e-05, -7.7248e-05,\n",
            "        -5.8532e-05, -1.8477e-06, -1.9968e-05, -2.6169e-03, -2.1100e-05,\n",
            "        -2.3878e-04, -1.9848e-05, -7.8125e-03, -6.9201e-05, -8.9407e-06,\n",
            "        -8.8818e-01, -9.8779e-01, -1.0000e+00, -1.0000e+00, -8.7061e-01,\n",
            "        -1.4198e-02, -1.2188e-03, -8.9943e-05, -1.5900e-02, -1.8295e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06349080801010132 0.00496673583984375 1.500526785850525 0.35326656699180603 73\n",
            "pred tensor([-5.1003e-03, -2.5725e-04, -2.8348e-04, -1.0353e-04, -3.1137e-04,\n",
            "        -2.9683e-05, -1.6809e-05, -1.4925e-03, -2.1458e-06, -8.4817e-05,\n",
            "        -2.3842e-07, -1.6570e-05, -2.1231e-04, -1.0406e-02, -4.6005e-03,\n",
            "        -4.4847e-04, -5.4359e-05, -1.0133e-06, -1.6373e-02, -9.5367e-07,\n",
            "        -1.3494e-04, -5.4216e-04, -7.5459e-05, -4.6492e-06, -9.9540e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06974182277917862 0.0095367431640625 1.402587890625 0.3281126916408539 50\n",
            "pred tensor([-1.8387e-02, -3.0220e-05, -2.1362e-03, -1.7107e-05, -4.5240e-05,\n",
            "        -1.5962e-04, -3.7909e-05, -5.9605e-08, -8.0729e-04, -1.0000e+00,\n",
            "        -1.7881e-07, -1.7881e-06, -2.3413e-04, -1.1921e-06, -6.2287e-05,\n",
            "        -1.8382e-04, -1.9646e-04, -1.4305e-05, -1.1162e-02, -1.0986e-03,\n",
            "        -6.9618e-04, -6.3181e-06, -2.1482e-04, -4.0233e-05, -2.2078e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.054780881851911545 0.001338958740234375 1.6549549102783203 0.35130438208580017 54\n",
            "pred tensor([-1.7414e-03, -4.7836e-03, -3.4511e-05, -9.5367e-07, -2.3842e-07,\n",
            "        -3.5763e-07, -2.7142e-03, -6.9201e-05, -3.5763e-07, -6.4254e-05,\n",
            "        -2.2471e-05, -3.4928e-05, -3.3617e-05, -1.1861e-05, -7.2122e-06,\n",
            "        -2.9564e-05, -3.2187e-06, -7.2241e-05, -4.9472e-06, -4.7684e-07,\n",
            "        -1.7881e-07, -5.3644e-07, -6.6817e-05, -4.0293e-04, -1.1623e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07547464966773987 0.00018167495727539062 1.7797077894210815 0.33534133434295654 70\n",
            "pred tensor([-2.0266e-06, -4.4937e-03, -1.0099e-03, -2.8610e-05, -2.7061e-04,\n",
            "        -1.1146e-04, -1.1005e-03, -1.3275e-03, -2.5320e-04, -5.1832e-04,\n",
            "        -8.1934e-01, -2.4586e-03, -9.9023e-01, -9.3115e-01, -1.0000e+00,\n",
            "        -6.5565e-07, -3.5167e-06,  0.0000e+00, -6.5565e-07, -1.4901e-05,\n",
            "        -7.6294e-04, -2.8348e-04, -1.0729e-03, -1.6689e-05, -1.0223e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05898689106106758 0.00011920928955078125 1.770437479019165 0.3519153296947479 81\n",
            "pred tensor([-6.2012e-01, -1.3330e-01, -5.1994e-03, -1.0880e-02, -1.1578e-03,\n",
            "        -6.6817e-05, -7.0143e-04, -2.3556e-03, -1.0723e-04, -6.7329e-04,\n",
            "        -1.7285e-06, -8.3148e-05,  0.0000e+00, -4.2915e-06, -5.3644e-07,\n",
            "        -2.5153e-05, -1.1504e-05, -1.7881e-07, -6.0380e-05, -7.6592e-05,\n",
            "        -1.2159e-03, -4.2496e-03, -1.4114e-02, -1.3709e-06, -8.5235e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07910425215959549 8.821487426757812e-05 1.7235960960388184 0.3330802619457245 65\n",
            "pred tensor([-2.6011e-04, -2.4557e-05, -1.4937e-04, -2.4855e-05, -1.3170e-03,\n",
            "        -8.4460e-05, -3.5834e-04, -2.5690e-05, -2.5272e-05, -1.1861e-05,\n",
            "        -1.7881e-07, -6.5804e-05, -2.5034e-06, -5.7755e-03, -1.0269e-02,\n",
            "        -4.3311e-01, -8.4961e-01, -7.5758e-05, -1.0042e-03, -2.6131e-04,\n",
            "        -3.0823e-03, -2.5415e-04, -2.9709e-02, -2.3594e-03, -2.4536e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0544329397380352 0.0012531280517578125 1.5622999668121338 0.3543996214866638 82\n",
            "pred tensor([-6.7592e-05, -1.4931e-02, -1.1867e-04, -9.4593e-05, -9.7752e-06,\n",
            "        -4.5204e-04, -2.3842e-07, -5.9605e-08, -3.0398e-06, -3.8087e-05,\n",
            "        -8.7500e-05, -3.9673e-03, -6.2370e-04, -1.8787e-03, -3.1471e-05,\n",
            "        -3.3021e-04, -1.7881e-07, -4.2319e-06, -4.3831e-03, -4.5532e-01,\n",
            "        -1.0000e+00, -1.3137e-04, -1.4305e-06, -2.9802e-06, -5.9605e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07120627909898758 0.0015964508056640625 1.6095081567764282 0.3309318721294403 56\n",
            "pred tensor([-0.1146, -0.0032, -0.0093, -0.0716, -0.0018, -0.1737, -0.8613, -0.1915,\n",
            "        -0.0481, -0.0210, -0.0333, -0.0022, -0.0138, -0.0593, -0.0016, -0.5825,\n",
            "        -0.5015, -0.0874, -0.0781, -0.0024, -0.0717, -0.1125, -0.9556, -0.3999,\n",
            "        -0.0013], device='cuda:0', dtype=torch.float16,\n",
            "       grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05126742273569107 0.002109527587890625 1.4724318981170654 0.3386983573436737 69\n",
            "pred tensor([-3.4103e-03, -2.4994e-02, -1.9080e-01, -2.2697e-03, -1.4050e-01,\n",
            "        -3.6061e-05, -3.9816e-04, -1.1683e-05, -1.4130e-02, -7.1640e-03,\n",
            "        -2.6417e-04, -1.8656e-05, -4.7684e-07, -9.3460e-04, -1.3245e-02,\n",
            "        -9.4681e-03, -2.6822e-05, -7.2956e-04, -3.8207e-05, -1.4685e-01,\n",
            "        -2.2602e-03, -2.1820e-03, -4.8485e-03, -4.4403e-02, -6.1417e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07208555936813354 0.0052337646484375 1.4380066394805908 0.34552493691444397 51\n",
            "pred tensor([-4.7836e-03, -4.9651e-05, -4.6143e-01, -8.4473e-02, -4.6191e-01,\n",
            "        -9.5703e-01, -1.2922e-03, -1.3800e-03, -3.2544e-01, -5.7666e-01,\n",
            "        -6.3623e-01, -1.0193e-02, -7.8125e-02, -3.6907e-04, -8.6182e-01,\n",
            "        -2.7252e-02, -8.1885e-01, -1.2772e-02, -3.5691e-04, -5.4047e-02,\n",
            "        -1.8604e-01, -1.8616e-02, -3.7003e-03, -6.0387e-03, -1.6748e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04985768347978592 0.007419586181640625 1.3533586263656616 0.3530270755290985 77\n",
            "pred tensor([-3.4619e-01, -6.0254e-01, -5.0391e-01, -1.0791e-01, -1.0000e+00,\n",
            "        -8.3447e-07, -1.9670e-06, -1.7881e-06, -4.2975e-05, -5.9605e-06,\n",
            "        -1.1921e-07, -5.5432e-06, -2.9802e-06, -1.0890e-04, -1.0796e-02,\n",
            "        -9.1791e-06, -1.4424e-05, -1.3113e-06, -5.5432e-06, -7.1526e-07,\n",
            "         0.0000e+00, -9.2983e-06, -1.3113e-06, -7.7486e-07, -4.8876e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07124309986829758 0.0030517578125 1.4669923782348633 0.3428589701652527 41\n",
            "pred tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.3644e-07, -5.9605e-08,\n",
            "        -1.0000e+00, -5.3883e-05, -7.4267e-05, -4.1413e-04, -1.5473e-04,\n",
            "        -2.0206e-05, -7.3910e-06, -1.1921e-07, -5.9605e-08,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -7.2656e-01, -2.1911e-04, -1.7071e-03,\n",
            "        -1.5116e-04, -2.2590e-05, -3.3975e-06, -3.8727e-02, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05281923711299896 0.002895355224609375 1.5403342247009277 0.3407182991504669 68\n",
            "pred tensor([-6.3599e-02, -2.7557e-02, -2.7800e-04, -5.0426e-05, -5.9557e-04,\n",
            "        -1.7881e-07,  0.0000e+00, -5.9605e-08, -1.1921e-07,  0.0000e+00,\n",
            "         0.0000e+00, -1.7881e-07, -5.7030e-04, -2.3474e-01, -1.4591e-04,\n",
            "        -3.6955e-06,  0.0000e+00, -4.1723e-07, -1.7285e-06, -5.0068e-06,\n",
            "        -5.3644e-07, -2.9802e-07, -1.2517e-06, -6.5565e-07, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07083302736282349 0.0005097389221191406 1.6467777490615845 0.32368773221969604 31\n",
            "pred tensor([ 0.0000e+00, -1.7881e-06, -5.0247e-05, -1.9073e-05, -5.9605e-08,\n",
            "        -1.8835e-05, -5.1260e-06, -2.6226e-06, -1.5427e-02, -1.7914e-02,\n",
            "        -1.1116e-02, -1.8969e-03, -9.9659e-04, -8.8120e-04, -7.7844e-05,\n",
            "        -5.4359e-05, -2.5034e-06, -5.1308e-04, -1.0000e+00, -1.4553e-03,\n",
            "         0.0000e+00, -1.1921e-07, -1.1921e-07, -2.3842e-07, -1.6093e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.049156203866004944 0.0005626678466796875 1.6237108707427979 0.35658058524131775 59\n",
            "pred tensor([-1.2650e-02, -5.6419e-03, -1.7202e-04, -3.2783e-06, -5.9009e-06,\n",
            "        -2.7418e-06, -1.2875e-05, -2.1458e-06, -5.9605e-07, -1.1742e-05,\n",
            "        -5.9009e-06, -8.9228e-05, -9.4528e-03, -3.1548e-03, -3.3212e-04,\n",
            "        -4.3988e-05, -5.9605e-08, -1.0133e-06, -3.5763e-07, -3.5763e-07,\n",
            "        -5.9605e-08, -7.8678e-06, -1.0848e-05, -1.0669e-05, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07196282595396042 0.0004591941833496094 1.7911779880523682 0.32564088702201843 33\n",
            "pred tensor([-1.7517e-02, -1.6999e-04, -2.5916e-04, -1.5318e-05, -3.0935e-05,\n",
            "        -6.8545e-06, -9.9540e-06, -4.5776e-05, -1.2398e-05, -2.8014e-06,\n",
            "        -7.8678e-06, -7.5698e-06, -6.5267e-05, -1.4710e-04, -8.2254e-06,\n",
            "        -1.6327e-03, -6.0141e-05, -2.0313e-03, -7.4072e-01, -9.6512e-03,\n",
            "        -6.1178e-04, -1.4603e-05, -5.8770e-05, -5.0545e-04, -6.4373e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.047672614455223083 0.0005640983581542969 1.7098586559295654 0.35412466526031494 60\n",
            "pred tensor([-1.4770e-04, -8.7595e-04, -1.2350e-03, -1.3504e-02, -5.7399e-05,\n",
            "        -2.1756e-05, -1.1325e-06, -2.0862e-06, -1.1921e-07,  0.0000e+00,\n",
            "        -4.2140e-05, -1.7881e-07, -1.6689e-06, -5.9605e-08, -5.7220e-06,\n",
            "        -1.5914e-05, -3.5167e-06, -4.8697e-05, -2.5630e-06, -8.9407e-07,\n",
            "        -7.6294e-05, -1.1921e-06, -5.3644e-07, -4.1723e-07, -1.7881e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07112397253513336 0.0015811920166015625 1.5987298488616943 0.3274630308151245 43\n",
            "pred tensor([-8.7500e-05, -8.5831e-06, -1.3888e-05, -4.0531e-06, -5.6763e-02,\n",
            "        -4.1008e-05, -6.7568e-04, -6.4790e-05, -7.2837e-05, -6.5565e-07,\n",
            "        -1.4007e-05, -1.1504e-05, -5.5771e-03, -9.4175e-04, -1.0890e-04,\n",
            "        -3.6895e-05, -1.6689e-06, -6.1393e-06, -3.6895e-05, -7.5758e-05,\n",
            "        -4.8876e-05, -2.5654e-03, -5.1260e-05, -7.5161e-05, -2.2292e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.048901431262493134 0.0005850791931152344 1.6002638339996338 0.33381393551826477 65\n",
            "pred tensor([-1.3023e-02, -2.1935e-05, -1.2529e-04, -2.7418e-06, -3.9339e-06,\n",
            "        -3.5763e-07, -2.7924e-02, -7.0667e-04, -2.7676e-03, -6.5565e-07,\n",
            "        -1.1921e-07, -7.7486e-07, -7.1526e-07, -1.1867e-04, -1.0073e-04,\n",
            "        -2.2471e-05, -9.6560e-06, -1.0729e-06, -7.8678e-06, -7.2122e-06,\n",
            "        -2.8610e-06, -1.7881e-07, -1.1921e-07, -1.2052e-04, -3.3975e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06920347362756729 0.0010967254638671875 1.6138594150543213 0.3408963084220886 31\n",
            "pred tensor([-1.9372e-05, -1.4305e-06, -9.5367e-07, -1.0133e-06, -3.2187e-06,\n",
            "        -5.3644e-07, -1.1683e-05, -7.7343e-04, -1.3590e-05, -7.2002e-05,\n",
            "        -1.5850e-03, -4.7455e-03, -3.2101e-03, -2.4731e-01, -4.0054e-04,\n",
            "        -8.2159e-04, -1.5335e-03, -8.4668e-01, -6.4502e-01, -9.9951e-01,\n",
            "        -9.9268e-01, -5.2452e-05, -7.5912e-03, -5.8670e-03, -1.9181e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.048664357513189316 0.0035533905029296875 1.4926495552062988 0.3355395793914795 73\n",
            "pred tensor([-2.2519e-04, -1.7509e-03, -1.9073e-06, -1.1921e-05, -1.1921e-07,\n",
            "        -2.0266e-06, -4.1842e-05, -2.5630e-06,  0.0000e+00,  0.0000e+00,\n",
            "        -4.2319e-06, -3.0816e-05, -5.9605e-07, -1.7881e-07, -5.9605e-08,\n",
            "        -1.6034e-05, -1.5557e-05, -1.2100e-05, -7.6592e-05, -1.5140e-05,\n",
            "        -7.1955e-04, -2.4343e-04, -2.7905e-03, -5.2452e-04, -1.1820e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0656571090221405 0.004955291748046875 1.4586668014526367 0.32856014370918274 26\n",
            "pred tensor([ 0.0000e+00,  0.0000e+00, -2.5988e-05, -2.6822e-05, -2.0065e-02,\n",
            "        -9.9564e-03, -2.1315e-04, -2.6727e-04, -3.1109e-03, -2.9469e-04,\n",
            "        -2.0587e-04, -2.7008e-02, -6.7890e-05, -3.4332e-04, -5.9605e-07,\n",
            "        -5.0316e-03, -1.0000e+00, -5.0116e-04, -3.3970e-03, -5.1260e-05,\n",
            "        -2.8610e-03, -1.2481e-04, -1.8966e-04, -2.9297e-03, -1.5764e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.044932086020708084 0.004886627197265625 1.440138816833496 0.33056169748306274 50\n",
            "pred tensor([-2.9325e-05, -2.3317e-04, -1.5664e-04, -5.0831e-04, -1.2779e-04,\n",
            "        -1.6928e-05, -4.6849e-05, -4.5824e-04, -6.5804e-05, -6.8426e-05,\n",
            "        -2.3880e-03, -9.2822e-01, -6.1328e-01, -1.0000e+00, -1.0000e+00,\n",
            "        -1.6093e-06, -5.4240e-06, -3.5763e-05, -7.6294e-05, -4.7088e-06,\n",
            "        -1.7881e-07, -7.1526e-07, -2.9802e-07, -1.1325e-06, -4.2796e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.061645280569791794 0.00194549560546875 1.6901817321777344 0.35406550765037537 33\n",
            "pred tensor([-1.9670e-05, -2.1744e-04, -5.9187e-05, -1.0389e-04, -1.3709e-05,\n",
            "        -4.7088e-06, -1.1921e-06, -4.3392e-04, -3.3402e-04, -2.5558e-03,\n",
            "        -3.1052e-03, -1.5295e-04, -4.0741e-02, -5.0201e-03, -4.0985e-02,\n",
            "        -1.5190e-02, -1.6586e-02, -2.2675e-02, -1.4210e-03, -9.6798e-04,\n",
            "        -3.0098e-03, -2.4582e-02, -7.8735e-03, -1.3878e-02, -1.1731e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.041143808513879776 0.0014209747314453125 1.654352068901062 0.3490453362464905 53\n",
            "pred tensor([-8.4043e-06, -2.7120e-05, -8.8215e-06, -5.9605e-08, -5.9605e-08,\n",
            "        -5.9605e-08,  0.0000e+00,  0.0000e+00, -5.9605e-08, -2.9802e-07,\n",
            "        -7.8678e-06, -6.7592e-05, -4.5419e-05, -3.3855e-05, -2.3139e-04,\n",
            "        -1.7822e-01, -9.9902e-01, -1.2283e-03, -6.1393e-06, -5.0247e-05,\n",
            "        -2.4319e-05, -1.7345e-05, -1.7929e-03, -4.3130e-04, -9.1267e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06837166845798492 0.0013036727905273438 1.6258927583694458 0.34580177068710327 41\n",
            "pred tensor([-1.3292e-05, -2.2423e-04, -9.7215e-05, -3.5553e-02, -1.0986e-03,\n",
            "        -5.8770e-05, -6.6040e-02, -1.0429e-02, -3.8727e-02, -5.8075e-02,\n",
            "        -8.4668e-01, -8.9795e-01, -1.0797e-01, -3.5083e-01, -5.4736e-01,\n",
            "        -2.3218e-01, -9.8193e-01, -9.6680e-01, -9.9658e-01, -1.0000e+00,\n",
            "        -1.0000e+00, -6.3300e-05, -7.8142e-05, -2.9707e-04, -1.2338e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04287486523389816 0.0010118484497070312 1.6535307168960571 0.3334318995475769 57\n",
            "8\n",
            "pred tensor([-8.5297e-03, -6.5899e-04, -5.3955e-02, -2.6536e-04, -1.0881e-03,\n",
            "        -2.4199e-05, -4.0531e-06, -1.6689e-06, -1.7881e-07, -7.1526e-07,\n",
            "         0.0000e+00, -4.7684e-07, -1.4305e-06, -2.0266e-06, -6.5565e-07,\n",
            "        -2.5392e-05, -1.1921e-07, -7.7486e-07, -3.0994e-06, -2.9802e-07,\n",
            "        -1.6093e-04, -2.4338e-03, -1.1545e-04, -5.4836e-04, -4.3988e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06401001662015915 0.0006427764892578125 1.623334288597107 0.3302180767059326 40\n",
            "pred tensor([-8.5068e-04, -1.2636e-04, -2.3865e-02, -9.9951e-01, -1.0000e+00,\n",
            "        -4.9472e-05, -1.6093e-06, -5.1856e-05, -1.6630e-05, -7.0667e-04,\n",
            "        -2.5129e-04, -9.0408e-04, -3.8803e-05, -5.8949e-05, -9.2804e-05,\n",
            "        -1.6434e-02, -5.6877e-03, -4.4861e-03, -1.3983e-04, -1.4591e-04,\n",
            "        -8.0585e-04, -9.4748e-04, -5.1403e-04, -3.5524e-05, -1.5427e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04618764668703079 0.0008769035339355469 1.5759248733520508 0.347615122795105 78\n",
            "pred tensor([-2.8149e-01, -3.8743e-04, -1.9007e-03, -9.3579e-06, -5.8270e-04,\n",
            "        -9.0179e-03, -2.3127e-05, -1.0073e-05, -1.5497e-05, -5.9605e-08,\n",
            "        -8.3447e-07,  0.0000e+00, -1.1563e-05, -1.9646e-04, -3.7074e-05,\n",
            "        -5.7638e-05, -9.9540e-06, -3.0184e-04, -4.7684e-07, -1.8525e-04,\n",
            "        -5.3287e-05, -9.7534e-02, -9.9561e-01, -1.0000e+00, -1.5616e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06519842147827148 0.001949310302734375 1.5412859916687012 0.3396519720554352 47\n",
            "pred tensor([-1.3914e-03, -8.2159e-04, -1.3332e-03, -3.8385e-05, -1.0550e-05,\n",
            "        -1.1504e-05, -3.0994e-06, -4.4107e-06, -1.2789e-03, -1.5438e-05,\n",
            "        -4.2677e-05, -1.9968e-05, -5.5432e-05, -4.8399e-04, -4.5471e-03,\n",
            "        -2.6054e-03, -5.7459e-04, -2.9541e-01, -8.9209e-01, -9.9951e-01,\n",
            "        -9.9951e-01, -9.5410e-01, -3.4515e-02, -1.9007e-03, -5.3048e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050191666930913925 0.00180816650390625 1.5706300735473633 0.35679078102111816 88\n",
            "pred tensor([-3.1066e-04, -1.7288e-02, -4.1485e-04, -1.5235e-04, -2.9802e-07,\n",
            "        -1.7881e-07,  0.0000e+00, -1.7838e-02, -3.6895e-05, -4.4703e-05,\n",
            "        -4.1723e-06, -1.5378e-05, -2.7418e-06, -5.9605e-08, -2.3007e-05,\n",
            "        -3.2496e-04, -1.1325e-06, -1.9670e-06, -2.5725e-04, -4.5896e-06,\n",
            "        -2.6727e-04, -2.7239e-05, -1.6212e-05, -1.8001e-05, -1.9848e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0677429661154747 0.003925323486328125 1.4512038230895996 0.3301108777523041 54\n",
            "pred tensor([-1.5945e-03, -1.8206e-03, -1.1921e-07, -1.1867e-04, -4.6492e-06,\n",
            "        -5.9605e-07, -5.9605e-08, -2.4438e-04, -7.1526e-07, -1.2067e-01,\n",
            "        -8.5602e-03, -1.8311e-04, -1.7881e-06, -3.3283e-04, -1.6068e-02,\n",
            "        -2.2675e-02, -1.2459e-02, -4.0210e-01, -9.3933e-02, -6.6992e-01,\n",
            "        -9.7754e-01, -1.0000e+00, -9.6798e-04, -1.2243e-04, -5.2869e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05053907260298729 0.0019512176513671875 1.5328102111816406 0.3364836871623993 72\n",
            "pred tensor([-4.3907e-03, -2.2602e-04, -6.7353e-05, -1.7583e-05, -1.7881e-07,\n",
            "        -9.5367e-07, -5.7399e-05, -4.8103e-03, -1.1367e-04, -2.3246e-06,\n",
            "        -2.4140e-05, -3.5763e-07, -4.1723e-07, -1.1921e-07, -4.3154e-05,\n",
            "        -3.3020e-02, -3.8505e-05, -4.2140e-05, -5.8055e-05, -4.0398e-03,\n",
            "        -1.4484e-04, -1.3816e-04, -6.0856e-05, -1.6928e-05, -1.0729e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06446676701307297 0.0036907196044921875 1.4551565647125244 0.3261463940143585 40\n",
            "pred tensor([-2.7239e-05, -2.3139e-04, -8.7619e-06, -3.7074e-05, -2.8000e-03,\n",
            "        -4.5061e-05, -7.8106e-04, -6.5374e-04, -5.9080e-04, -1.6093e-04,\n",
            "        -2.8610e-05, -3.2440e-02, -4.9408e-02, -4.1175e-04, -1.3447e-04,\n",
            "        -8.6069e-04, -1.7202e-04, -8.7142e-05, -1.3409e-03, -3.6907e-04,\n",
            "        -1.1104e-04, -1.9014e-05, -6.2525e-05, -6.6414e-03, -2.1827e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04587647691369057 0.001575469970703125 1.5557892322540283 0.3453947603702545 66\n",
            "pred tensor([-2.2526e-03, -7.8738e-05, -2.1231e-04, -8.2850e-06, -1.1921e-07,\n",
            "        -1.1921e-07, -3.2306e-05, -1.9073e-06, -1.1921e-07, -1.6928e-04,\n",
            "        -4.3154e-05, -8.9502e-04, -1.2934e-05, -1.8418e-05, -1.5488e-03,\n",
            "        -8.3447e-06, -2.7418e-06, -7.2098e-04, -4.7684e-07, -1.1921e-06,\n",
            "        -4.4882e-05, -2.7537e-05, -1.3501e-01, -1.1730e-04, -3.4511e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06975829601287842 0.0009708404541015625 1.579298973083496 0.3312870264053345 45\n",
            "pred tensor([-4.4107e-06, -1.1683e-05, -7.7486e-07, -4.9889e-05, -1.6093e-04,\n",
            "        -6.3610e-04, -4.7922e-05, -9.8407e-05, -1.3590e-05, -6.5565e-07,\n",
            "        -2.9802e-07, -3.1137e-04, -4.1652e-04, -4.8876e-06, -1.0192e-05,\n",
            "        -1.9014e-05, -3.7551e-06, -2.1152e-03, -1.3816e-04, -1.0431e-05,\n",
            "        -4.8161e-05, -7.2098e-04, -5.6610e-02, -1.0729e-03, -2.3975e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04561440274119377 0.0009560585021972656 1.618072748184204 0.34305572509765625 61\n",
            "pred tensor([-2.1565e-04, -1.9417e-03, -1.4842e-05, -5.9605e-08, -1.3113e-06,\n",
            "        -9.2983e-06, -3.0351e-04, -3.2759e-04, -9.3877e-05, -1.2934e-04,\n",
            "        -1.4496e-03, -1.3709e-06, -1.1921e-07, -2.7418e-06, -6.9737e-06,\n",
            "        -3.2067e-04, -1.6093e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -1.1921e-06, -2.9206e-06, -1.4305e-06, -2.8014e-04, -2.1148e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06594466418027878 0.0036468505859375 1.4690585136413574 0.33062049746513367 46\n",
            "pred tensor([-3.3276e-01, -1.5845e-01, -9.4141e-01, -1.1212e-01, -1.0586e-03,\n",
            "        -1.0818e-02, -9.4938e-04, -8.3984e-01, -2.5916e-04, -3.0103e-01,\n",
            "        -4.5037e-04, -1.2505e-02, -1.0000e+00, -8.1897e-05, -3.2687e-04,\n",
            "        -8.5831e-06, -8.0252e-04, -5.6362e-04, -7.2837e-05, -8.0729e-04,\n",
            "        -1.5056e-04, -1.4043e-04, -1.7130e-04, -1.4162e-03, -3.0518e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04943007230758667 0.003688812255859375 1.5356693267822266 0.35545381903648376 63\n",
            "pred tensor([-2.6627e-03, -4.4937e-03, -2.8682e-04, -1.3113e-06, -5.9605e-08,\n",
            "        -1.3709e-06, -3.9756e-05, -8.1658e-06, -4.2796e-05, -6.4969e-06,\n",
            "        -9.5963e-06, -3.5763e-07, -7.6890e-06, -1.6749e-05, -9.5367e-06,\n",
            "        -1.9670e-06, -3.7372e-05, -3.0994e-06, -2.3842e-07, -1.8167e-04,\n",
            "        -8.1062e-06, -2.9683e-05, -2.4438e-06, -6.5565e-07, -2.5988e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06959229707717896 0.0011615753173828125 1.5664799213409424 0.32963651418685913 48\n",
            "pred tensor([-4.9067e-04, -6.5565e-06, -7.7200e-04, -2.6226e-04, -1.1921e-06,\n",
            "        -3.7804e-03, -1.9531e-03, -1.7891e-03, -3.8075e-04, -3.3498e-05,\n",
            "        -3.9160e-05, -2.9445e-05, -5.9605e-07, -6.8545e-06, -1.0109e-04,\n",
            "        -6.0129e-04, -2.4338e-03, -7.9298e-04, -3.7766e-04, -1.2589e-04,\n",
            "        -5.7817e-05, -1.5497e-06, -9.3269e-04, -5.6190e-03, -7.7772e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05123722925782204 0.0007781982421875 1.604121446609497 0.334024578332901 52\n",
            "pred tensor([-6.8903e-04, -2.6321e-04, -1.0109e-04, -7.8440e-05, -5.3644e-06,\n",
            "        -1.8120e-05, -4.7684e-07, -3.7551e-06, -2.5225e-04, -2.0683e-05,\n",
            "        -7.8738e-05, -4.7386e-05, -5.1856e-06, -2.1458e-06, -7.1526e-07,\n",
            "         0.0000e+00, -3.5763e-07, -5.9605e-08, -8.5235e-06, -1.1325e-06,\n",
            "        -2.6882e-05, -4.9629e-03, -1.0000e+00, -1.0270e-04, -6.0797e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07254219055175781 0.001689910888671875 1.5078487396240234 0.34239497780799866 40\n",
            "pred tensor([-9.9540e-05, -5.9009e-06, -3.7611e-05, -5.7817e-06, -4.9353e-04,\n",
            "        -4.1306e-05, -5.3644e-07, -7.1526e-06, -8.1062e-06, -3.5458e-03,\n",
            "        -1.5318e-05, -1.6510e-05, -6.6161e-06, -2.5630e-06, -2.1458e-06,\n",
            "        -5.3644e-07, -5.8413e-06, -1.0133e-06, -8.3804e-05, -1.3709e-04,\n",
            "        -1.4997e-04, -1.5616e-05, -5.0068e-06, -1.7679e-04, -3.2783e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05899106711149216 0.0007576942443847656 1.5116651058197021 0.34230777621269226 52\n",
            "pred tensor([-5.7129e-01, -9.6240e-01, -5.7281e-02, -1.7899e-02, -1.7881e-06,\n",
            "        -6.9737e-06, -1.2636e-05, -5.3174e-01, -1.0000e+00, -1.7285e-06,\n",
            "        -1.1027e-05, -9.8348e-06, -5.9605e-07, -2.9802e-07, -1.1921e-07,\n",
            "        -4.1723e-07, -1.1921e-07, -8.3447e-07, -3.6693e-04, -8.7976e-04,\n",
            "        -4.7455e-03, -2.6321e-03, -1.6928e-05, -4.6492e-06, -2.3234e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07680809497833252 0.0005102157592773438 1.5712132453918457 0.3272518217563629 51\n",
            "pred tensor([-1.0208e-02, -3.7479e-04, -8.7023e-06, -2.7776e-05, -3.4103e-03,\n",
            "        -4.2319e-06, -3.5763e-06, -2.8431e-05, -8.5831e-05, -4.4775e-04,\n",
            "        -1.3428e-03, -2.2335e-03, -7.2241e-05, -3.3545e-04, -4.7188e-03,\n",
            "        -5.1880e-03, -3.8981e-05, -8.8871e-05, -3.7551e-06, -6.8665e-05,\n",
            "        -2.0862e-06, -6.1393e-06, -1.8024e-04, -6.4373e-06, -1.4901e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05643226578831673 0.0022449493408203125 1.472898244857788 0.34981632232666016 58\n",
            "pred tensor([-1.5039e-03, -2.8343e-03, -3.6564e-03, -1.3113e-06, -1.7881e-07,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00, -8.1250e-01, -1.0000e+00, -5.9605e-08, -1.1921e-07,\n",
            "        -1.7881e-07, -1.7881e-07, -5.9605e-08,  0.0000e+00,  0.0000e+00,\n",
            "        -4.1723e-07, -1.7881e-07, -1.6212e-05, -5.0068e-05, -1.0431e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07188983261585236 0.006114959716796875 1.4306120872497559 0.3419361710548401 30\n",
            "pred tensor([-2.1458e-06, -4.1723e-06, -1.1635e-04, -3.5763e-06, -8.9407e-07,\n",
            "        -1.7881e-06,  0.0000e+00, -4.7684e-07, -1.0848e-04, -2.9802e-07,\n",
            "        -1.5962e-04, -7.5758e-05, -2.5094e-05, -5.5771e-03, -7.8308e-02,\n",
            "        -9.3213e-01, -9.7266e-01, -1.0000e+00, -1.0653e-03, -2.3823e-03,\n",
            "        -3.6764e-04, -3.4882e-02, -1.4091e-04, -1.6534e-04, -2.7537e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05543191730976105 0.0021724700927734375 1.5254584550857544 0.337313711643219 39\n",
            "pred tensor([-2.1753e-01, -4.5300e-04, -3.3212e-04, -4.2915e-06,  0.0000e+00,\n",
            "        -2.4974e-05, -1.4305e-06, -1.4246e-05, -6.6042e-05, -1.1027e-05,\n",
            "        -1.3888e-05, -2.5272e-05, -5.7638e-05, -5.8055e-05, -1.7464e-04,\n",
            "        -4.0293e-04, -9.0332e-02, -7.3891e-03, -9.3579e-06, -2.6822e-06,\n",
            "        -5.9605e-08,  0.0000e+00, -1.7285e-06, -1.0443e-03, -1.6037e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07646536827087402 0.001018524169921875 1.550105333328247 0.3391720652580261 41\n",
            "pred tensor([-1.0000e+00, -9.9219e-01, -9.7803e-01, -1.0000e+00, -2.0027e-04,\n",
            "        -4.2558e-04, -6.8963e-05, -5.3940e-03, -1.4198e-04, -9.9540e-06,\n",
            "        -5.7125e-04, -1.6987e-05, -1.9908e-05, -6.5565e-07, -6.7711e-03,\n",
            "        -2.3224e-02, -1.4591e-04, -6.4507e-03, -1.0252e-05, -1.1444e-03,\n",
            "        -2.8920e-04, -1.6760e-01, -2.8946e-02, -1.0901e-01, -4.3893e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06004312261939049 0.0005578994750976562 1.5649621486663818 0.35802701115608215 64\n",
            "pred tensor([-1.0586e-03, -3.9363e-04, -8.9228e-05, -1.5736e-05, -7.0333e-05,\n",
            "        -5.9605e-08, -1.0729e-06, -8.9407e-07, -3.0994e-06, -5.9605e-08,\n",
            "         0.0000e+00,  0.0000e+00, -9.1195e-06, -1.7881e-07, -5.9605e-08,\n",
            "        -2.3842e-07,  0.0000e+00, -1.6689e-06, -7.4506e-06, -1.6809e-05,\n",
            "         0.0000e+00, -4.1723e-07, -3.1590e-06, -2.3842e-06, -5.3644e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07404816150665283 0.0004515647888183594 1.5549089908599854 0.3304692208766937 50\n",
            "pred tensor([-5.4550e-04, -1.4267e-03, -5.9891e-04, -1.9302e-03, -6.1417e-04,\n",
            "        -4.4346e-05, -1.0338e-03, -8.0287e-05, -4.3154e-05, -1.0729e-06,\n",
            "        -2.3246e-06, -5.0449e-04, -8.8835e-04, -5.6267e-05, -7.9274e-06,\n",
            "        -1.6689e-06, -1.4591e-04, -3.5034e-01, -1.2827e-04, -1.7130e-04,\n",
            "        -4.3154e-05, -1.7047e-05, -4.8113e-04, -2.9802e-07, -7.4267e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05945151299238205 0.0019502639770507812 1.4961885213851929 0.3633861839771271 82\n",
            "pred tensor([-2.6840e-02, -2.4929e-03, -2.5821e-04, -1.2636e-04, -5.5432e-05,\n",
            "        -5.7220e-06, -1.3709e-05, -1.1921e-07,  0.0000e+00,  0.0000e+00,\n",
            "        -1.7345e-05, -2.3842e-05, -9.5010e-05, -3.2961e-05, -4.0054e-05,\n",
            "        -2.3663e-05, -1.0133e-06, -1.1921e-05, -8.3447e-07, -3.9279e-05,\n",
            "        -7.2122e-06, -8.3447e-06, -7.7486e-07, -1.4544e-04, -8.2159e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07453349232673645 0.00386810302734375 1.4787240028381348 0.32449468970298767 34\n",
            "pred tensor([-2.6245e-01, -1.2924e-02, -2.2141e-02, -4.9114e-05, -7.9632e-04,\n",
            "        -8.3313e-03, -2.3365e-03, -3.6693e-04, -2.4438e-06, -6.7890e-05,\n",
            "        -2.8610e-05, -2.6112e-03, -1.7130e-04, -1.3145e-02, -1.4185e-01,\n",
            "        -5.8441e-03, -4.1580e-03, -8.7128e-03, -1.0723e-04, -4.1565e-02,\n",
            "        -2.7919e-04, -3.5477e-04, -1.2314e-02, -1.2517e-06, -5.8098e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0524464026093483 0.0045318603515625 1.4585838317871094 0.3589431047439575 57\n",
            "pred tensor([-3.4666e-04, -3.9339e-06, -1.1325e-06, -2.3842e-07, -8.3447e-07,\n",
            "        -2.9802e-07, -2.2650e-06, -1.6689e-06, -1.1625e-03, -6.8779e-03,\n",
            "        -1.0551e-02, -1.4811e-03, -5.3263e-04, -1.5318e-05, -1.7212e-02,\n",
            "        -6.4850e-04, -9.5844e-04, -1.2434e-04, -2.2650e-05, -4.1723e-07,\n",
            "        -8.9407e-07, -5.9605e-08, -1.9610e-05, -6.5029e-05, -1.4162e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07405010610818863 0.0019435882568359375 1.4697468280792236 0.3738322854042053 46\n",
            "pred tensor([-1.3828e-03, -9.3877e-05, -3.4571e-06, -5.1856e-05, -1.9646e-04,\n",
            "        -1.0729e-05, -2.8312e-05, -3.3617e-05, -7.9870e-06, -2.8968e-05,\n",
            "        -6.5565e-07, -1.4305e-06, -1.0073e-05, -9.6560e-06, -5.3644e-06,\n",
            "        -2.3918e-03, -3.5763e-06, -1.8811e-04, -6.8545e-06, -1.3769e-04,\n",
            "        -6.1178e-04, -4.3988e-05, -8.5235e-06, -3.0780e-04, -4.5738e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05778871476650238 0.0007376670837402344 1.5817064046859741 0.34686464071273804 84\n",
            "pred tensor([-9.6375e-02, -2.7637e-03, -7.3528e-04, -7.5102e-06,  0.0000e+00,\n",
            "        -9.3162e-05, -2.9114e-02, -1.8382e-04, -3.1590e-06, -1.2338e-05,\n",
            "        -4.4346e-05, -5.9187e-05, -1.3173e-05, -2.2411e-05, -6.7592e-05,\n",
            "        -4.6313e-05, -2.3365e-03, -1.0151e-04, -2.5988e-05, -4.1723e-07,\n",
            "        -6.9141e-06, -1.2827e-04, -5.3287e-05, -4.4703e-06, -1.8096e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07643528282642365 0.0008053779602050781 1.5577340126037598 0.3313567638397217 56\n",
            "pred tensor([-1.2040e-05, -2.0862e-06, -2.9802e-07, -4.8876e-06, -7.6437e-04,\n",
            "        -1.6747e-03, -4.5654e-01, -7.4959e-04, -6.3133e-04, -9.3079e-04,\n",
            "        -1.7929e-03, -6.1111e-03, -2.8687e-02, -9.9087e-04, -3.1018e-04,\n",
            "        -1.0742e-01, -9.8975e-01, -1.0000e+00, -1.0000e+00, -1.0000e+00,\n",
            "        -1.0000e+00, -1.0723e-04, -2.4557e-05, -2.4819e-04, -2.4533e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052776217460632324 0.0005674362182617188 1.5671892166137695 0.34380194544792175 76\n",
            "pred tensor([-1.4591e-04, -2.7790e-03, -4.0364e-04, -5.9605e-07,  0.0000e+00,\n",
            "         0.0000e+00, -3.5167e-06, -1.0133e-06, -1.5318e-05, -1.0133e-06,\n",
            "         0.0000e+00, -1.0610e-05, -5.9605e-08, -3.5167e-06, -1.4305e-06,\n",
            "        -2.0421e-04, -7.7486e-06, -1.1921e-07, -5.9605e-08, -1.7881e-06,\n",
            "        -1.0133e-06,  0.0000e+00, -3.7551e-06, -8.5235e-06, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07432328909635544 0.0012044906616210938 1.5728225708007812 0.336741179227829 57\n",
            "pred tensor([-9.5725e-05, -6.6817e-05, -1.2434e-04, -3.0589e-04, -8.4043e-06,\n",
            "        -6.5565e-06, -2.6727e-04, -2.0921e-05, -1.7464e-04, -2.2054e-05,\n",
            "        -3.9196e-04, -2.0909e-04, -1.6332e-05, -7.1526e-06, -2.2054e-06,\n",
            "        -2.2926e-03, -3.2425e-05, -7.3910e-06, -2.0921e-05, -1.1325e-06,\n",
            "        -1.3447e-04, -1.4043e-04, -4.2498e-05, -6.3181e-06, -1.0848e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.048590198159217834 0.0031490325927734375 1.5107090473175049 0.36428624391555786 79\n",
            "pred tensor([-7.8106e-04, -3.8319e-03, -5.6458e-04, -1.2934e-05, -7.7486e-07,\n",
            "        -6.5565e-07, -8.9407e-07, -1.6689e-06, -7.1526e-07, -5.9605e-08,\n",
            "        -5.9605e-08, -6.5565e-06, -1.1623e-05, -6.5565e-07, -3.9279e-05,\n",
            "        -1.0848e-05, -6.7353e-06, -2.8467e-04, -4.9257e-04, -1.5724e-04,\n",
            "        -1.7464e-05, -6.3400e-03, -1.8477e-06, -3.0696e-05, -4.7684e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07734277844429016 0.0018482208251953125 1.53518545627594 0.35985392332077026 56\n",
            "pred tensor([-2.4094e-02, -3.1586e-02, -2.6360e-03, -9.2089e-05, -2.3007e-05,\n",
            "        -2.3842e-06,  0.0000e+00, -2.3842e-07,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -7.1526e-07, -5.4054e-03, -7.0605e-01,\n",
            "        -4.7168e-01, -9.9707e-01, -9.9951e-01, -9.9951e-01, -9.9951e-01,\n",
            "        -1.0000e+00, -1.4753e-03, -4.1187e-05, -3.3617e-05, -1.5497e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05406252667307854 0.0018157958984375 1.5026248693466187 0.36124980449676514 103\n",
            "pred tensor([-1.3983e-04, -2.7523e-03, -3.3975e-06,  0.0000e+00, -1.1921e-07,\n",
            "        -5.9605e-08, -8.9407e-07, -2.8968e-05, -4.1723e-07, -2.1458e-06,\n",
            "        -1.8477e-05, -4.8399e-04, -1.2875e-05, -5.7638e-05, -1.0765e-04,\n",
            "        -5.7697e-04, -1.2100e-05, -4.6563e-04, -1.4889e-04, -2.3007e-05,\n",
            "        -1.8775e-05, -3.7441e-03, -4.7791e-02, -4.2319e-05, -2.7418e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07312023639678955 0.00666046142578125 1.3804761171340942 0.34561511874198914 66\n",
            "pred tensor([-1.3257e-01, -1.1272e-03, -6.6032e-03, -1.1070e-02, -4.7073e-03,\n",
            "        -2.5345e-02, -2.2602e-04, -1.9798e-03, -3.1662e-03, -4.6173e-02,\n",
            "        -9.0088e-01, -3.9444e-03, -7.6050e-02, -1.3151e-03, -4.6468e-04,\n",
            "        -2.6846e-04, -7.2837e-05, -5.9700e-03, -1.1950e-03, -1.6846e-01,\n",
            "        -1.4732e-02, -1.5736e-03, -1.1835e-03, -2.2173e-04, -8.4817e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04436928778886795 0.0040435791015625 1.4398778676986694 0.3570820689201355 59\n",
            "pred tensor([-1.6689e-05, -3.6764e-04, -3.6907e-04, -4.5776e-05, -4.6492e-06,\n",
            "        -2.1458e-06, -5.9605e-08, -1.7881e-07, -3.5763e-07, -1.7881e-07,\n",
            "        -5.9605e-08, -5.9605e-08, -1.2732e-04, -5.3644e-06, -3.0541e-04,\n",
            "        -1.7607e-04, -1.1921e-06, -4.1723e-07, -3.6776e-05, -7.8142e-05,\n",
            "        -1.4043e-04, -2.9802e-06, -7.2837e-05, -1.3769e-04, -7.7486e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07338210940361023 0.0009403228759765625 1.5285990238189697 0.33813101053237915 55\n",
            "pred tensor([-6.6817e-05, -2.7585e-04, -2.1517e-05, -8.6129e-05, -1.2817e-03,\n",
            "        -5.1260e-06, -9.6560e-06, -6.0201e-06, -3.8743e-06, -4.8280e-06,\n",
            "        -5.9605e-07, -4.9472e-06, -1.3709e-05, -3.1376e-04, -9.6607e-04,\n",
            "        -1.8668e-04, -4.0770e-04, -1.3954e-02, -2.2233e-05, -1.1325e-04,\n",
            "        -1.6708e-03, -1.0514e-04, -1.5888e-03, -1.5930e-02, -2.4719e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04844974726438522 0.0006542205810546875 1.5677428245544434 0.36987999081611633 96\n",
            "9\n",
            "pred tensor([-7.7858e-03, -2.2926e-03, -1.0270e-04, -3.5763e-07, -1.7285e-06,\n",
            "        -5.1260e-06, -2.0266e-06, -6.5565e-07, -3.3379e-06, -1.7881e-07,\n",
            "        -5.3644e-06, -1.0729e-06, -1.0806e-04, -7.5102e-06, -1.3113e-05,\n",
            "        -5.9605e-06, -8.3447e-07, -1.7881e-06, -5.9605e-08, -4.3809e-05,\n",
            "        -5.9605e-08, -2.4378e-05, -3.1471e-05, -8.6129e-05, -1.5199e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.065967857837677 0.0016422271728515625 1.5556665658950806 0.32775819301605225 40\n",
            "pred tensor([-2.5988e-05, -2.9373e-04, -1.4544e-04, -3.2759e-04, -7.3314e-06,\n",
            "        -1.6534e-04, -1.0669e-05, -8.1897e-05, -1.5593e-04, -2.6047e-05,\n",
            "        -8.0872e-04, -4.6313e-05, -7.7486e-07, -7.7248e-05, -9.0003e-06,\n",
            "        -1.1593e-04, -8.6844e-05, -3.5167e-06, -1.1921e-07,  0.0000e+00,\n",
            "        -9.6729e-01, -1.0000e+00, -1.1921e-07, -2.9802e-07, -8.3447e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04422154277563095 0.0007653236389160156 1.5143640041351318 0.3582281768321991 85\n",
            "pred tensor([-9.9087e-04, -4.1733e-03, -8.1539e-05, -4.8697e-05, -1.7881e-07,\n",
            "        -5.9605e-08, -1.0073e-05, -2.3842e-07, -1.1921e-07, -2.9993e-04,\n",
            "        -3.4576e-02, -3.8147e-06,  0.0000e+00, -6.5565e-07, -7.7486e-07,\n",
            "        -2.0206e-05, -9.9854e-01, -1.0000e+00, -2.3305e-05, -9.6560e-06,\n",
            "        -8.7142e-05, -1.2100e-04, -1.9109e-04, -3.7727e-03, -2.0087e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06409997493028641 0.0009446144104003906 1.547358751296997 0.336983859539032 24\n",
            "pred tensor([-1.2589e-04, -1.7881e-07, -2.8682e-04, -7.4244e-04, -1.7853e-03,\n",
            "        -4.0054e-04, -2.0742e-04, -3.3736e-05, -5.7817e-06, -1.3168e-02,\n",
            "        -2.7905e-03, -1.0118e-03, -5.2214e-04, -3.5214e-04, -2.4815e-03,\n",
            "        -1.6391e-05, -9.0003e-06, -1.3554e-04, -1.0147e-03, -7.1487e-03,\n",
            "        -1.5354e-04, -2.5158e-03, -6.9618e-04, -2.1400e-03, -3.8457e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04474634677171707 0.001811981201171875 1.4716864824295044 0.37358883023262024 74\n",
            "pred tensor([-1.6937e-02, -4.2992e-03, -2.0909e-04, -1.5497e-06,  0.0000e+00,\n",
            "        -1.2517e-06, -2.3842e-07, -1.3876e-04, -2.2960e-04, -2.0828e-03,\n",
            "        -7.6437e-04, -3.1967e-03, -7.3135e-05, -2.7156e-04, -5.9605e-08,\n",
            "         0.0000e+00,  0.0000e+00, -4.1772e-01, -1.0000e+00, -2.8849e-05,\n",
            "        -5.3048e-06, -5.9605e-08, -5.9605e-08, -7.5102e-06, -1.3709e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.059450048953294754 0.0009512901306152344 1.5459060668945312 0.3532590866088867 56\n",
            "pred tensor([-1.2875e-05, -8.5235e-06, -3.3081e-05, -4.0293e-04, -9.0218e-04,\n",
            "        -6.4790e-05, -4.4937e-03, -5.2452e-04, -1.7868e-02, -6.0701e-04,\n",
            "        -6.2585e-06, -5.0020e-04, -1.1683e-04, -4.4518e-03, -3.4370e-03,\n",
            "        -3.7727e-03, -2.7676e-03, -7.2539e-05, -9.8705e-04, -7.6950e-05,\n",
            "        -1.6708e-03, -1.7703e-05, -8.2970e-04, -2.1820e-03, -3.9215e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.042732954025268555 0.000640869140625 1.5762252807617188 0.3525444567203522 78\n",
            "pred tensor([-9.1732e-05, -4.7660e-04, -4.7743e-05, -1.0109e-04, -7.5758e-05,\n",
            "        -5.0354e-04, -8.9586e-05, -1.5438e-05, -1.5020e-05, -9.7990e-05,\n",
            "        -3.9458e-05, -8.1241e-05, -3.5977e-04, -4.1008e-05, -2.4140e-05,\n",
            "        -1.6479e-02, -4.7684e-07, -2.3842e-07, -3.2783e-06, -1.9252e-05,\n",
            "        -8.1658e-06, -1.2207e-03, -2.9826e-04, -3.0458e-05, -1.0270e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058220695704221725 0.00542449951171875 1.4014631509780884 0.33251073956489563 51\n",
            "pred tensor([-7.2122e-06, -5.4283e-03, -1.0000e+00, -1.0000e+00, -1.3781e-03,\n",
            "        -3.8385e-05, -9.8765e-05, -2.6131e-04, -5.7399e-05, -6.2048e-05,\n",
            "        -4.8518e-05, -1.2004e-04, -1.4868e-03, -7.4267e-05, -1.3447e-04,\n",
            "        -7.3528e-04, -2.5253e-03, -5.2023e-04, -1.1826e-02, -1.1665e-02,\n",
            "        -3.6560e-02, -3.8166e-03, -1.3535e-02, -1.0944e-01, -9.1064e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04193883761763573 0.0013484954833984375 1.4885129928588867 0.3783620297908783 97\n",
            "pred tensor([-2.1114e-03, -7.7772e-04, -8.9943e-05, -1.3494e-04, -4.5598e-05,\n",
            "        -9.1732e-05, -6.9141e-06, -9.9540e-06, -6.6042e-05, -1.9336e-04,\n",
            "        -1.4937e-04, -8.3804e-05, -1.6689e-06, -5.2869e-05, -5.3644e-07,\n",
            "        -2.6226e-06, -1.2934e-05, -2.7417e-01, -9.9805e-01, -1.0000e+00,\n",
            "        -2.3365e-05, -1.0109e-04, -2.6536e-04, -1.2100e-04, -7.9036e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06145886331796646 0.003910064697265625 1.4391884803771973 0.3336767554283142 66\n",
            "pred tensor([-4.3488e-03, -6.1321e-04, -6.7043e-04, -2.1398e-04, -6.5565e-05,\n",
            "        -5.4121e-04, -3.4738e-04, -7.1669e-04, -3.3402e-04, -8.7280e-03,\n",
            "        -3.0346e-03, -1.6289e-03, -1.9798e-03, -1.5199e-05, -2.1148e-04,\n",
            "        -6.0201e-06, -7.6580e-04, -2.3317e-04, -1.5295e-04, -2.0752e-03,\n",
            "        -1.3151e-03, -1.6909e-03, -1.1072e-03, -1.4162e-03, -6.2287e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04552677646279335 0.0009622573852539062 1.5824744701385498 0.35569900274276733 88\n",
            "pred tensor([-2.7008e-02, -9.0723e-01, -7.2746e-03, -8.6260e-04, -3.0908e-01,\n",
            "        -2.5558e-03, -1.7333e-04, -2.2876e-04, -1.9608e-03, -1.8656e-05,\n",
            "        -1.8716e-05, -3.7372e-05, -1.8063e-03, -4.7207e-05, -3.0994e-06,\n",
            "        -1.0729e-03, -4.2975e-05, -7.1526e-06, -7.7441e-01, -7.4506e-06,\n",
            "        -5.0316e-03, -3.7750e-02, -7.8738e-05, -6.4552e-05, -1.4889e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06103913113474846 0.000484466552734375 1.5680824518203735 0.3344741761684418 59\n",
            "pred tensor([-3.5763e-07, -1.0371e-05, -4.2498e-05, -1.0192e-04, -1.3089e-04,\n",
            "        -7.0870e-05, -1.5235e-04, -6.8903e-04, -1.9014e-05, -2.0111e-04,\n",
            "        -1.2646e-03, -1.9562e-04, -1.2195e-04, -4.4525e-05, -4.4346e-04,\n",
            "        -1.5116e-04, -1.0729e-03, -1.0796e-03, -1.1574e-02, -3.8004e-04,\n",
            "        -1.9109e-04, -7.0190e-02, -2.3331e-02, -9.9951e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04801760986447334 0.000507354736328125 1.5656895637512207 0.352527916431427 95\n",
            "pred tensor([-3.2496e-04, -1.3588e-02, -5.0259e-04, -4.7112e-04, -5.4703e-03,\n",
            "        -2.7704e-04, -2.4557e-05, -2.1100e-05, -6.6280e-04, -1.0031e-04,\n",
            "        -2.6584e-05, -2.9125e-03, -4.6372e-04, -1.5843e-04, -5.6076e-03,\n",
            "        -1.1997e-03, -5.9605e-06, -2.0569e-02, -7.4615e-03, -7.7772e-04,\n",
            "        -1.3304e-03, -5.6362e-04, -6.8848e-02, -1.1206e-03, -3.6693e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06624665856361389 0.0010118484497070312 1.5212957859039307 0.3467732071876526 62\n",
            "pred tensor([-6.8378e-04, -2.7370e-04, -3.3998e-04, -1.4937e-04, -1.9121e-03,\n",
            "        -2.0599e-02, -4.8685e-04, -3.7079e-03, -9.9850e-04, -1.4111e-01,\n",
            "        -6.7596e-03, -6.3372e-04, -9.2804e-05, -1.2887e-04, -1.5473e-04,\n",
            "        -1.0548e-03, -8.7118e-04, -2.2831e-03, -6.1798e-04, -3.7262e-02,\n",
            "        -1.6675e-01, -9.9805e-01, -1.0000e+00, -7.4310e-03, -7.0333e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04474101960659027 0.0008597373962402344 1.5365806818008423 0.38494133949279785 84\n",
            "pred tensor([-6.2752e-04, -8.8215e-05, -3.3379e-06, -1.0490e-05, -2.2256e-04,\n",
            "        -4.8291e-01, -9.9951e-01, -1.0000e+00, -3.6478e-05, -1.7881e-07,\n",
            "        -4.9472e-06, -2.6226e-06, -5.3644e-07, -1.6630e-05, -1.9908e-05,\n",
            "        -4.8113e-04, -9.2804e-05, -8.1658e-06, -3.3319e-05, -5.1260e-05,\n",
            "        -9.6045e-01, -3.5522e-02, -2.7919e-04, -6.1560e-04, -5.8949e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06529009342193604 0.00341033935546875 1.5001369714736938 0.3351665139198303 69\n",
            "pred tensor([-4.7183e-04, -2.9945e-04, -3.1376e-04, -1.0443e-03, -2.0943e-03,\n",
            "        -3.5214e-04, -8.6731e-02, -4.2163e-01, -9.8096e-01, -9.9707e-01,\n",
            "        -9.9316e-01, -1.3990e-03, -2.8979e-01, -1.7891e-03, -9.2316e-03,\n",
            "        -5.0507e-03, -7.8064e-02, -4.1650e-01, -1.3440e-01, -1.0710e-03,\n",
            "        -1.9638e-02, -1.6546e-03, -1.1539e-03, -7.4959e-04, -2.0199e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04346421733498573 0.0051116943359375 1.3882813453674316 0.34979143738746643 86\n",
            "pred tensor([-6.0158e-03, -3.0575e-03, -1.3275e-02, -1.3113e-06, -1.9417e-03,\n",
            "        -6.2513e-04, -1.6224e-04, -7.7486e-07, -3.4370e-03, -3.6478e-04,\n",
            "        -3.9458e-05, -1.2732e-01, -4.6387e-02, -2.7409e-03, -6.2294e-03,\n",
            "        -3.1250e-01, -6.6040e-02, -9.9951e-01, -2.6047e-05, -2.5690e-05,\n",
            "        -7.1640e-03, -5.1308e-04, -3.6407e-04, -1.5378e-05, -2.2471e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0670170858502388 0.0013637542724609375 1.5183489322662354 0.3340854048728943 59\n",
            "pred tensor([-2.1076e-03, -8.3804e-05, -9.1195e-06, -4.1318e-04, -1.2159e-03,\n",
            "        -6.7890e-05, -3.6354e-03, -3.2640e-04, -1.4186e-05, -4.5753e-04,\n",
            "        -1.1635e-04, -6.5651e-03, -2.1994e-04, -5.0621e-03, -1.5364e-03,\n",
            "        -2.1994e-04, -1.4710e-04, -6.1655e-04, -1.7405e-04, -4.5824e-04,\n",
            "        -6.4392e-03, -9.9850e-04, -6.2048e-05, -2.0587e-04, -4.3392e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04888151213526726 0.00272369384765625 1.5343672037124634 0.35242971777915955 77\n",
            "pred tensor([-6.4209e-01, -6.2842e-01, -5.5008e-03, -5.3287e-05, -7.0534e-03,\n",
            "        -7.0801e-03, -8.8978e-04, -9.7559e-01, -1.0000e+00, -1.0000e+00,\n",
            "        -1.7881e-07, -1.0729e-06, -5.4240e-06, -2.5034e-06, -1.9610e-05,\n",
            "        -1.8477e-06, -4.8518e-05, -6.0856e-05, -1.0431e-05, -2.5630e-06,\n",
            "        -1.9944e-04, -3.5763e-06, -2.5153e-05, -4.8518e-05, -2.0087e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06553210318088531 0.0007572174072265625 1.572235107421875 0.3297664523124695 59\n",
            "pred tensor([-1.7204e-03, -4.8518e-05, -4.1008e-04, -2.8610e-03, -1.3351e-03,\n",
            "        -1.1325e-04, -7.8011e-03, -1.7242e-03, -2.9707e-04, -9.4299e-03,\n",
            "        -3.7811e-02, -4.1580e-04, -2.9087e-05, -1.2386e-04, -5.6744e-05,\n",
            "        -3.9756e-05, -4.3333e-05, -1.9165e-02, -1.0000e+00, -6.2656e-04,\n",
            "        -1.8179e-05, -8.2850e-06, -1.5116e-04, -1.3661e-04, -4.6921e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04898720607161522 0.0006923675537109375 1.5682117938995361 0.3710145652294159 62\n",
            "pred tensor([-8.7939e-01, -1.0000e+00, -2.5153e-05, -5.0664e-06, -1.1406e-03,\n",
            "        -2.6536e-04, -1.3602e-04, -2.0921e-05, -6.6519e-04, -2.9588e-04,\n",
            "        -6.4373e-06, -4.2319e-05, -1.2302e-03, -1.8835e-05, -1.5414e-04,\n",
            "        -7.1406e-05, -1.4467e-03, -3.9339e-06, -3.5167e-06, -1.0312e-05,\n",
            "        -2.4855e-05, -1.1734e-02, -5.0831e-04, -2.8253e-04, -5.6624e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06511785089969635 0.0009102821350097656 1.5744154453277588 0.34310033917427063 48\n",
            "pred tensor([-6.7353e-06, -3.5071e-04, -4.0460e-04, -7.5674e-04, -8.6784e-04,\n",
            "        -9.6858e-05, -2.1279e-05, -1.4534e-02, -6.7115e-05, -1.6708e-02,\n",
            "        -1.4889e-04, -3.8385e-05, -3.6354e-03, -2.0742e-04, -2.0504e-04,\n",
            "        -1.4324e-03, -4.0779e-03, -4.9438e-03, -7.5817e-04, -3.7932e-04,\n",
            "        -2.3878e-04, -1.0729e-03, -1.9431e-05, -2.3842e-07, -8.8835e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04520720988512039 0.0009479522705078125 1.6061146259307861 0.3680711090564728 66\n",
            "pred tensor([-5.9229e-01, -8.3887e-01, -4.3042e-01, -8.8086e-01, -9.9756e-01,\n",
            "        -9.9854e-01, -9.8291e-01, -9.9707e-01, -5.8740e-01, -3.6743e-01,\n",
            "        -1.0000e+00, -3.9339e-06, -7.9334e-05, -4.3809e-05, -1.1963e-04,\n",
            "        -6.5565e-07, -1.3075e-03, -5.1308e-04, -3.0947e-04, -1.6344e-04,\n",
            "        -1.1146e-04, -1.6093e-06, -2.5558e-03, -3.1710e-05, -1.2215e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07029362767934799 0.0002827644348144531 1.6587116718292236 0.33445078134536743 75\n",
            "pred tensor([-7.4816e-04, -2.1482e-04, -1.0151e-04, -1.2123e-02, -1.2054e-02,\n",
            "        -7.9041e-03, -3.3855e-04, -9.4366e-04, -9.8877e-01, -1.0992e-01,\n",
            "        -2.6226e-04, -8.8513e-05, -5.2023e-04, -4.8943e-03, -3.8116e-02,\n",
            "        -3.2730e-03, -2.6550e-02, -5.3139e-03, -2.6611e-02, -8.3466e-03,\n",
            "        -9.9561e-01, -9.9707e-01, -4.7949e-01, -1.8295e-02, -1.2201e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04422249644994736 0.00293731689453125 1.4785418510437012 0.3581415116786957 70\n",
            "pred tensor([-2.0984e-01, -7.8174e-01, -2.3178e-02, -3.1021e-02, -2.5299e-02,\n",
            "        -1.0000e+00, -6.5565e-07,  0.0000e+00, -4.4703e-06, -8.5735e-04,\n",
            "        -2.4140e-05, -3.6359e-06, -1.8966e-04, -1.9562e-04, -5.3287e-05,\n",
            "        -2.5034e-06, -1.4365e-04, -5.4283e-03, -1.3709e-06, -1.2779e-04,\n",
            "        -1.9610e-05, -1.4246e-05, -2.9862e-05, -2.3663e-05, -6.3753e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06331522017717361 0.006351470947265625 1.3955152034759521 0.3308607041835785 52\n",
            "pred tensor([-1.2195e-04, -3.0220e-05, -3.6407e-04, -6.1178e-04, -7.1239e-04,\n",
            "        -3.2723e-05, -2.6138e-02, -3.5172e-03, -5.7755e-03, -4.5349e-02,\n",
            "        -4.2725e-03, -8.2031e-02, -1.8494e-01, -7.4158e-03, -2.0798e-02,\n",
            "        -5.6763e-02, -3.9429e-01, -9.7607e-01, -1.0529e-02, -8.3113e-04,\n",
            "        -5.3650e-02, -3.4839e-01, -1.1158e-03, -9.5032e-02, -2.5040e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.046717461198568344 0.003261566162109375 1.4610404968261719 0.352283775806427 78\n",
            "pred tensor([-6.4552e-05, -1.2052e-04, -2.2087e-03, -2.5094e-05, -1.0806e-04,\n",
            "        -4.3297e-04, -9.9540e-05, -6.4611e-04, -5.0812e-03, -3.1257e-04,\n",
            "        -4.8339e-05, -3.6263e-04, -2.1458e-05, -1.0806e-04, -1.4603e-05,\n",
            "        -1.6928e-04, -3.6180e-05, -1.3113e-06, -2.8610e-06, -1.1683e-05,\n",
            "        -4.0364e-04, -2.4557e-05, -1.1277e-04, -2.7103e-03, -1.1820e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06899973750114441 0.00446319580078125 1.3670213222503662 0.3377143144607544 61\n",
            "pred tensor([-6.3610e-04, -1.0890e-04, -2.3127e-05, -4.9257e-04, -2.3127e-05,\n",
            "        -5.5265e-04, -1.5855e-05, -1.4889e-04, -1.8280e-02, -4.5300e-04,\n",
            "        -8.9943e-05, -4.1723e-07, -7.1526e-06, -1.1292e-02, -6.1569e-03,\n",
            "        -5.5432e-05, -1.9908e-05, -7.2539e-05, -1.0925e-02, -2.8801e-04,\n",
            "        -1.0462e-03, -4.9591e-02, -7.9541e-01, -1.0000e+00, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.045750729739665985 0.002300262451171875 1.453284502029419 0.35610610246658325 90\n",
            "pred tensor([-1.5917e-03, -7.1812e-04, -7.0572e-05, -1.0252e-05, -3.1710e-05,\n",
            "        -3.4928e-05, -1.7881e-07, -6.1989e-06, -1.7285e-06, -1.6093e-06,\n",
            "        -3.0458e-05,  0.0000e+00, -2.3246e-06, -1.5676e-05, -5.9605e-08,\n",
            "        -4.7684e-07, -1.5526e-02, -1.0000e+00, -1.3709e-06,  0.0000e+00,\n",
            "        -4.7684e-07, -7.7486e-07, -7.9989e-05, -2.0385e-05, -7.8440e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07070120424032211 0.001003265380859375 1.5836161375045776 0.33132651448249817 58\n",
            "pred tensor([-2.4152e-04, -2.6709e-01, -5.2691e-05, -6.6578e-05, -1.2243e-04,\n",
            "        -3.9160e-05, -5.1260e-06, -1.3695e-03, -5.9080e-04, -9.3231e-03,\n",
            "        -8.0943e-05, -3.9935e-05, -1.6475e-04, -2.8343e-03, -3.6279e-01,\n",
            "        -8.5400e-01, -1.0262e-03, -3.7445e-02, -5.5885e-03, -8.0795e-03,\n",
            "        -6.5820e-01, -6.5576e-01, -9.9902e-01, -9.9219e-01, -9.9463e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.049929261207580566 3.8623809814453125e-05 1.7058041095733643 0.3468508720397949 98\n",
            "pred tensor([-5.1025e-01, -5.9277e-01, -4.3831e-03, -5.9605e-07, -2.3422e-02,\n",
            "        -3.9935e-06, -3.0098e-03, -4.7386e-05, -7.2384e-04, -6.1393e-06,\n",
            "        -7.2002e-05, -6.2752e-04, -3.4571e-06, -2.1148e-04, -1.4710e-04,\n",
            "        -9.5367e-07, -1.9491e-04, -1.1921e-06, -2.0385e-05, -7.2241e-05,\n",
            "        -4.0829e-05, -7.7486e-07, -1.7047e-05, -3.9339e-06, -1.1367e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06862333416938782 0.0005197525024414062 1.5845916271209717 0.32523342967033386 30\n",
            "pred tensor([-3.8683e-05, -1.5855e-05, -8.8835e-04, -2.3139e-04, -3.1877e-04,\n",
            "        -5.1618e-05, -1.2459e-02, -1.0147e-03, -3.5591e-03, -1.4868e-03,\n",
            "        -3.8362e-04, -9.9609e-01, -9.9854e-01, -9.9854e-01, -1.6069e-03,\n",
            "        -9.6130e-03, -1.1559e-03, -1.7176e-03, -2.6207e-03, -4.0531e-05,\n",
            "        -4.4937e-03, -1.7405e-04, -1.3983e-04, -3.1109e-03, -1.1997e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.053184542804956436 0.0004410743713378906 1.5816271305084229 0.37197792530059814 91\n",
            "pred tensor([-2.4152e-04, -1.4639e-03, -1.7285e-05, -3.2306e-05, -1.2865e-03,\n",
            "        -2.7418e-06, -3.5763e-07, -6.4373e-06, -1.9073e-06, -4.2915e-06,\n",
            "        -3.5763e-07, -5.3048e-06, -1.2598e-03, -1.2481e-04, -3.1403e-02,\n",
            "        -1.8179e-05, -1.1740e-03, -1.2846e-03, -1.4925e-03, -1.7333e-04,\n",
            "        -8.9586e-05, -1.3947e-05, -1.7426e-02, -5.2035e-05, -3.2101e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06986982375383377 0.00128936767578125 1.5240641832351685 0.3392619490623474 44\n",
            "pred tensor([-5.8301e-01, -3.2961e-05, -5.3883e-04, -1.3399e-04, -2.3484e-05,\n",
            "        -4.3726e-04, -3.8290e-04, -4.1428e-03, -8.1558e-03, -9.1648e-04,\n",
            "        -3.8319e-03, -1.7536e-04, -1.7333e-04, -1.8024e-04, -3.6192e-04,\n",
            "        -5.0323e-02, -4.5738e-03, -8.5754e-03, -2.5272e-05, -3.1242e-03,\n",
            "        -5.1022e-05, -1.7786e-03, -1.0857e-02, -6.9857e-04, -9.2363e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04830792918801308 0.00255584716796875 1.5215437412261963 0.4046223759651184 69\n",
            "pred tensor([-9.6607e-04, -3.1877e-04, -1.0185e-03, -1.2243e-04, -1.2064e-03,\n",
            "        -4.3154e-05, -5.2273e-05, -1.5914e-05, -1.7881e-06, -2.2650e-05,\n",
            "        -1.2732e-04, -2.6226e-06, -2.6464e-05, -2.5630e-06, -1.5497e-06,\n",
            "        -6.2132e-04, -2.8610e-05, -3.5763e-07, -7.2837e-05, -5.9605e-07,\n",
            "        -3.6776e-05, -7.1526e-07, -3.3617e-05, -1.3602e-04, -1.0723e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06828836351633072 0.003444671630859375 1.498361349105835 0.3331308364868164 49\n",
            "pred tensor([-8.0585e-05, -8.7500e-05, -1.1623e-05, -2.5725e-04, -3.5763e-07,\n",
            "        -5.3704e-05, -1.0228e-04, -3.5107e-05, -6.1393e-06, -7.7486e-06,\n",
            "        -2.4343e-04, -2.4395e-03, -9.4748e-04, -6.3133e-04, -2.6047e-05,\n",
            "        -1.9989e-03, -2.7657e-05, -1.4368e-01, -9.9512e-01, -5.6362e-04,\n",
            "        -5.3883e-05, -2.6882e-05, -9.3520e-05, -1.5473e-04, -5.4777e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.047132302075624466 0.002986907958984375 1.5322178602218628 0.3429882228374481 81\n",
            "pred tensor([-9.9951e-01, -1.0000e+00, -8.7463e-02, -9.8877e-01, -7.2388e-02,\n",
            "        -1.5903e-04, -2.4343e-04, -4.1127e-06, -6.3777e-06, -7.4863e-05,\n",
            "        -5.6267e-05, -7.7486e-07, -2.5034e-06, -2.3901e-05, -2.9206e-06,\n",
            "        -8.3447e-07, -1.4937e-04, -2.2650e-06, -1.5974e-05, -1.7738e-04,\n",
            "        -1.1921e-07, -6.5029e-05, -6.3181e-06, -1.7703e-05, -5.0843e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06875941157341003 0.0016622543334960938 1.594902753829956 0.3320298194885254 58\n",
            "pred tensor([-1.6909e-03, -1.2338e-04, -2.2423e-04, -5.2452e-05, -2.9802e-07,\n",
            "        -1.3709e-04, -7.4863e-05, -5.3139e-03, -1.2243e-04, -2.9206e-05,\n",
            "        -4.6849e-05, -7.4673e-04, -2.3556e-03, -8.8281e-01, -1.5511e-02,\n",
            "        -1.2854e-01, -5.4565e-02, -6.7920e-01, -1.2405e-02, -7.2899e-03,\n",
            "        -1.4091e-02, -1.1780e-01, -3.3350e-01, -9.7168e-01, -9.6240e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04749228432774544 0.000370025634765625 1.8011022806167603 0.347762793302536 105\n",
            "10\n",
            "pred tensor([-1.1325e-04, -2.0826e-04, -6.0701e-04, -1.9073e-06, -8.9943e-05,\n",
            "        -1.5140e-05, -4.9734e-04, -1.6546e-03, -3.0339e-05, -9.5367e-07,\n",
            "        -2.3186e-05, -2.1696e-05, -1.0908e-05, -6.0797e-06, -4.6134e-05,\n",
            "        -1.2815e-05, -5.5504e-04, -3.2067e-04, -5.1856e-05, -4.6492e-05,\n",
            "        -1.0473e-04, -4.8409e-03, -5.2299e-03, -8.2642e-02, -5.5599e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07237570732831955 0.0011768341064453125 1.5182642936706543 0.3336431384086609 62\n",
            "pred tensor([-2.4109e-03, -1.5100e-01, -9.5361e-01, -9.7803e-01, -1.5583e-03,\n",
            "        -3.9053e-04, -6.2895e-04, -1.1820e-04, -1.2982e-04, -7.2122e-06,\n",
            "        -4.6635e-04, -2.9526e-03, -4.7207e-05, -7.0572e-04, -1.9531e-02,\n",
            "        -5.7182e-03, -1.8854e-03, -1.4582e-03, -1.8890e-02, -8.9228e-05,\n",
            "        -4.2224e-04, -2.2415e-02, -5.6934e-04, -1.2865e-03, -3.3997e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04757130518555641 0.002349853515625 1.487516164779663 0.38989660143852234 101\n",
            "pred tensor([-3.2306e-05, -8.2855e-03, -2.1565e-04, -4.1723e-07, -3.7551e-06,\n",
            "        -5.9605e-08, -1.1384e-05, -1.3888e-05, -3.5167e-06, -1.6093e-06,\n",
            "        -1.4603e-05, -2.3842e-07, -3.5942e-05, -1.6034e-05, -1.6093e-06,\n",
            "        -2.8610e-06, -2.5749e-05, -4.5037e-04, -3.8721e-01, -8.0566e-01,\n",
            "        -1.0000e+00, -1.0000e+00, -2.9802e-07, -1.3137e-04, -6.2275e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07091046869754791 0.001708984375 1.5275490283966064 0.350384920835495 56\n",
            "pred tensor([-7.2122e-06, -1.2268e-02, -5.5933e-04, -1.7333e-04, -6.0043e-03,\n",
            "        -8.5831e-06, -1.7107e-05, -9.3872e-02, -2.8168e-02, -3.3478e-02,\n",
            "        -1.9073e-05, -9.0659e-05, -1.0729e-05, -4.1723e-07, -6.4507e-03,\n",
            "        -1.0000e+00, -5.8441e-03, -6.1417e-04, -2.5034e-06,  0.0000e+00,\n",
            "        -1.1277e-04, -8.4277e-01, -9.9219e-01, -1.0000e+00, -4.2796e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052714962512254715 0.0016994476318359375 1.5006763935089111 0.36135271191596985 105\n",
            "pred tensor([-1.2684e-04, -1.7953e-04, -2.4498e-05, -2.0683e-05, -4.7684e-07,\n",
            "        -4.7684e-07, -7.8869e-04, -1.6987e-05, -5.9605e-07, -9.3877e-05,\n",
            "        -4.0531e-06, -4.8685e-04, -6.2287e-05, -2.2259e-03, -9.4235e-05,\n",
            "        -1.9073e-06, -5.3644e-06, -4.0703e-03, -7.2122e-06, -6.3181e-06,\n",
            "        -1.3113e-06, -4.6825e-04, -2.6360e-03, -1.5306e-03, -2.6131e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07636730372905731 0.0015773773193359375 1.52199125289917 0.3330629765987396 62\n",
            "pred tensor([-8.8272e-03, -7.7486e-07, -3.5763e-07, -7.9489e-04, -8.1241e-05,\n",
            "        -5.1618e-05, -9.3457e-01, -5.3704e-05, -2.8193e-05, -1.3709e-06,\n",
            "        -1.0166e-03, -9.5215e-03, -1.7643e-05, -2.3842e-07,  0.0000e+00,\n",
            "        -3.1471e-05, -3.8815e-04, -7.9274e-06, -5.9605e-08, -5.9605e-08,\n",
            "        -1.1921e-07, -5.9605e-08, -1.0000e+00, -1.0000e+00, -1.1915e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.047810543328523636 0.00452423095703125 1.4317853450775146 0.3337099552154541 58\n",
            "pred tensor([-9.5367e-05, -3.6221e-03, -1.7376e-03, -4.7386e-05, -4.8876e-06,\n",
            "        -1.4007e-05, -3.5763e-07, -1.1325e-06, -4.2915e-06, -3.0270e-03,\n",
            "        -5.3048e-06, -2.9862e-05, -5.1117e-04, -5.9605e-07, -8.7142e-05,\n",
            "        -4.0829e-05, -1.1772e-04, -3.5648e-03, -3.5515e-03, -1.6876e-02,\n",
            "        -7.8308e-02, -8.4763e-03, -1.3227e-03, -1.5039e-03, -5.9175e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07134050875902176 0.005126953125 1.4929471015930176 0.32709139585494995 44\n",
            "pred tensor([-9.7473e-02, -7.0000e-04, -1.0133e-06, -1.3232e-04, -1.8358e-05,\n",
            "        -6.6042e-05, -4.9925e-04, -1.9875e-03, -1.2238e-02, -8.4610e-03,\n",
            "        -2.7451e-02, -5.1855e-01, -1.0000e+00, -1.0000e+00, -1.8382e-04,\n",
            "        -1.1146e-04, -5.1403e-04, -1.4889e-04, -1.3924e-04, -4.4518e-03,\n",
            "        -4.7755e-04, -1.2386e-04, -1.0765e-04, -8.0466e-06, -1.1456e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.051197633147239685 0.002948760986328125 1.5549260377883911 0.3476073443889618 65\n",
            "pred tensor([-1.2815e-05, -1.9646e-04, -1.4305e-05, -4.1723e-07, -2.8014e-06,\n",
            "        -1.7881e-07, -1.7881e-07, -7.6294e-06, -3.6693e-04, -2.9802e-07,\n",
            "        -9.7990e-05, -1.9562e-04, -1.3983e-04, -1.9789e-04, -1.8811e-04,\n",
            "        -3.6955e-06, -5.4240e-06,  0.0000e+00, -3.8004e-04, -1.2279e-05,\n",
            "        -2.2559e-01, -1.0000e+00, -1.5736e-03, -1.1623e-05, -3.2842e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07429401576519012 0.001667022705078125 1.584568977355957 0.32802945375442505 29\n",
            "pred tensor([-3.2377e-04, -6.7444e-02, -5.2930e-01, -1.6212e-05, -1.9440e-02,\n",
            "        -6.8848e-01, -9.3066e-01, -8.3303e-04, -1.7953e-04, -4.6182e-04,\n",
            "        -1.1867e-04, -1.8356e-02, -1.4901e-06, -1.9610e-05, -1.6928e-04,\n",
            "        -2.2423e-04, -3.9935e-05, -1.6489e-03, -1.0818e-02, -2.4988e-01,\n",
            "        -9.7998e-01, -1.2695e-01, -8.3447e-01, -3.2275e-01, -2.4060e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05402621999382973 0.0008945465087890625 1.6444237232208252 0.3517797291278839 80\n",
            "pred tensor([-4.4937e-03, -6.9385e-01, -9.6989e-04, -1.4186e-05, -1.2379e-03,\n",
            "        -6.5771e-01, -1.0000e+00, -1.1921e-07, -1.2147e-04, -4.5955e-05,\n",
            "        -8.3447e-06, -1.0133e-06, -5.9605e-08, -3.6478e-04, -5.9605e-08,\n",
            "        -1.7881e-07, -8.8513e-05, -3.1590e-06, -1.7881e-07, -8.9407e-07,\n",
            "        -1.7881e-07,  0.0000e+00, -1.1921e-07, -1.2732e-04, -6.2656e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08161181956529617 8.58306884765625e-06 1.7714263200759888 0.33085137605667114 62\n",
            "pred tensor([-9.2089e-05, -1.4305e-06, -6.5517e-04, -6.4373e-06, -2.0182e-04,\n",
            "        -1.7285e-06, -1.7953e-04, -2.6688e-02, -6.0547e-01, -9.7559e-01,\n",
            "        -9.0576e-01, -7.9102e-01, -2.9640e-03, -4.5598e-05, -4.2677e-05,\n",
            "        -1.5378e-05, -9.2697e-04, -3.9935e-06, -1.7703e-05, -7.6294e-06,\n",
            "        -7.3671e-04, -1.3666e-03, -5.8055e-05, -1.5855e-05, -2.1231e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05696175619959831 0.0004954338073730469 1.5717439651489258 0.40367668867111206 70\n",
            "pred tensor([-2.2173e-04, -3.3545e-04, -5.6505e-05, -2.0266e-06, -7.5102e-04,\n",
            "         0.0000e+00, -1.7881e-07, -1.4305e-06, -2.5690e-05, -2.2054e-06,\n",
            "        -1.1921e-06, -1.5676e-05, -4.4327e-03, -1.1146e-05, -2.3234e-04,\n",
            "        -1.7583e-05, -7.7486e-07, -7.7486e-07, -2.9325e-05, -2.6286e-05,\n",
            "        -3.2258e-04, -3.6955e-06, -2.7299e-05, -1.0366e-03, -1.0052e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07542990148067474 0.0011196136474609375 1.5416381359100342 0.32720354199409485 51\n",
            "pred tensor([-9.9658e-01, -8.1787e-01, -9.2387e-06, -1.1272e-03, -5.1856e-06,\n",
            "        -1.6928e-05, -1.1963e-04, -4.6849e-05, -2.6684e-03, -2.9373e-04,\n",
            "        -9.1648e-04, -1.8600e-02, -5.4932e-04, -3.3081e-05, -2.8896e-03,\n",
            "        -5.0664e-06, -1.1425e-03, -1.2934e-04, -6.7353e-05, -5.6267e-05,\n",
            "        -5.2185e-03, -5.1737e-04, -7.0000e-04, -6.1178e-04, -1.3399e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05819079652428627 0.002712249755859375 1.54566490650177 0.3514023423194885 63\n",
            "pred tensor([-7.5817e-04, -8.9693e-04, -6.7062e-03, -3.3498e-05, -3.7789e-05,\n",
            "        -1.1635e-04, -3.6955e-06, -5.0316e-03, -2.1248e-03, -3.9185e-01,\n",
            "        -9.1699e-01, -1.0000e+00, -5.9605e-08, -1.1921e-07,  0.0000e+00,\n",
            "        -2.6226e-06, -5.9605e-08, -9.5367e-07, -7.5161e-05, -2.5153e-05,\n",
            "        -8.9586e-05, -1.3876e-04, -4.4167e-05, -9.3079e-04, -2.1148e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07976303994655609 0.0010576248168945312 1.6598658561706543 0.33575326204299927 55\n",
            "pred tensor([-2.1875e-05, -4.1723e-07, -2.5010e-04, -1.0900e-03, -1.2865e-03,\n",
            "        -7.5531e-04, -1.1367e-04, -4.7016e-04, -7.8678e-06, -1.1635e-04,\n",
            "        -3.7193e-05, -6.1333e-05, -1.5914e-05, -3.9935e-05, -1.3304e-03,\n",
            "        -8.0109e-04, -5.0888e-03, -6.4373e-06, -3.0398e-06, -4.1534e-02,\n",
            "        -7.8711e-01, -9.9609e-01, -9.9951e-01, -4.0352e-05, -1.1730e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05618072301149368 0.0021915435791015625 1.6420114040374756 0.3683289885520935 82\n",
            "pred tensor([-8.1253e-03, -7.6790e-03, -4.0293e-04, -1.8120e-05, -8.1062e-06,\n",
            "        -3.5167e-06, -1.4770e-04, -2.4629e-04, -4.2796e-04, -2.5034e-06,\n",
            "        -1.0089e-01, -3.4189e-04, -1.1206e-05, -7.3314e-06, -2.9011e-03,\n",
            "        -2.5177e-02, -8.5059e-01, -6.0205e-01, -1.0000e+00, -1.5497e-06,\n",
            "        -8.3447e-07, -2.1458e-06, -7.7200e-04, -8.5926e-04, -4.0531e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07699266076087952 0.0015411376953125 1.6100130081176758 0.3565913736820221 71\n",
            "pred tensor([-1.1121e-01, -1.5175e-04, -8.9502e-04, -1.9670e-06, -2.8431e-05,\n",
            "        -2.5034e-06, -1.1325e-06, -1.1146e-05, -2.9087e-05, -5.4646e-04,\n",
            "        -5.9605e-07, -2.8610e-06, -4.1127e-06, -1.0133e-06, -1.2283e-03,\n",
            "        -5.3704e-05, -1.4544e-04, -4.2572e-03, -6.7997e-04, -5.0247e-05,\n",
            "        -2.4247e-04, -3.5357e-04, -7.2670e-04, -2.2173e-04, -3.9001e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05623163655400276 0.002716064453125 1.5460413694381714 0.365786075592041 107\n",
            "pred tensor([-1.8631e-02, -3.7842e-01, -2.3193e-01, -1.3113e-06, -1.0729e-06,\n",
            "        -3.8981e-04, -4.8876e-05, -3.5167e-06, -2.8610e-06, -3.1590e-06,\n",
            "        -2.0862e-06, -1.7881e-06, -9.9756e-01, -8.7402e-01, -1.0000e+00,\n",
            "        -1.6093e-06, -1.1921e-07, -2.2650e-06, -1.3113e-05, -5.9605e-08,\n",
            "        -4.5240e-05, -1.7285e-06, -8.4114e-04, -4.4680e-04, -1.0765e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07745938748121262 0.0018110275268554688 1.5141422748565674 0.351025253534317 73\n",
            "pred tensor([-1.2894e-03, -6.4969e-06, -1.6232e-03, -6.9737e-05, -3.5172e-03,\n",
            "        -3.7265e-04, -9.0218e-04, -2.1954e-03, -4.4882e-05, -1.1325e-04,\n",
            "        -1.1377e-03, -1.2426e-03, -4.1485e-05, -3.5763e-04, -1.9836e-02,\n",
            "        -2.6131e-04, -2.7418e-06, -4.6313e-05, -2.5606e-04, -2.1517e-05,\n",
            "        -4.3384e-01, -9.7363e-01, -1.0000e+00, -1.0000e+00, -2.7120e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052059564739465714 0.004634857177734375 1.4195911884307861 0.36504849791526794 82\n",
            "pred tensor([-2.8458e-03, -4.5738e-03, -1.7738e-04, -2.9373e-04, -2.2697e-04,\n",
            "        -8.9407e-07, -1.1325e-06, -3.4392e-05, -5.3048e-05, -8.7256e-01,\n",
            "        -1.0000e+00, -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.7881e-07,\n",
            "        -1.4305e-06, -5.3644e-06, -5.9605e-07, -2.2054e-05, -1.9407e-04,\n",
            "        -6.5267e-05, -1.6665e-04, -3.4928e-05, -2.5511e-04, -6.6137e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07258246839046478 0.0035877227783203125 1.529227375984192 0.33314889669418335 66\n",
            "pred tensor([-1.4954e-03, -8.0585e-05, -1.1034e-03, -1.2481e-04, -2.1744e-04,\n",
            "        -5.6171e-04, -4.9293e-05, -6.1095e-05, -6.6042e-05, -4.8304e-04,\n",
            "        -5.0018e-02, -1.5821e-03, -7.3135e-05, -7.3314e-06, -1.0031e-04,\n",
            "        -6.1569e-03, -4.6509e-02, -3.4717e-01, -1.1940e-02, -1.9287e-02,\n",
            "        -2.2186e-02, -1.4424e-05, -3.8743e-06, -1.4317e-04, -7.9918e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05453956499695778 0.0008435249328613281 1.644252061843872 0.3642132878303528 115\n",
            "pred tensor([-6.1321e-04, -8.2636e-04, -2.5690e-05, -1.6093e-06, -2.3842e-07,\n",
            "        -2.8610e-06, -1.1820e-04, -5.9605e-08, -1.5533e-04, -7.4506e-06,\n",
            "        -9.7942e-04, -5.5432e-06, -1.0133e-06, -1.2934e-05, -1.1623e-05,\n",
            "        -5.9426e-05, -1.9264e-04, -7.1526e-07, -8.9228e-05, -8.3447e-07,\n",
            "        -4.2558e-04, -3.5167e-06, -4.7684e-07, -9.5367e-07, -9.2173e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08326290547847748 0.00013589859008789062 1.7400398254394531 0.33565402030944824 69\n",
            "pred tensor([-2.1756e-05, -2.1636e-05, -7.9498e-03, -2.8801e-04, -1.6665e-04,\n",
            "        -1.4484e-04, -6.8245e-03, -1.0848e-04, -6.0856e-05, -2.1398e-04,\n",
            "        -2.1423e-01, -1.9989e-03, -1.4591e-04, -1.7881e-06, -1.1981e-05,\n",
            "        -3.7479e-04, -2.4147e-03, -2.8312e-05, -5.7068e-03, -1.4937e-04,\n",
            "        -3.5346e-05, -7.8535e-04, -5.8055e-05, -2.4529e-03, -6.0959e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05484350025653839 0.00019168853759765625 1.7432851791381836 0.35819315910339355 99\n",
            "pred tensor([-1.0000e+00, -1.0000e+00, -2.2693e-01, -1.1665e-02, -3.1590e-05,\n",
            "        -2.1517e-05, -1.9670e-06, -3.7551e-06, -5.3465e-05, -1.5664e-04,\n",
            "        -1.0133e-05, -5.4150e-01, -8.9407e-07, -5.6362e-04, -2.2602e-03,\n",
            "        -4.0932e-03, -2.1191e-03, -4.0088e-01, -2.0557e-01, -9.7803e-01,\n",
            "        -9.5850e-01, -9.9805e-01, -1.0000e+00, -1.6153e-04, -4.7684e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0861375480890274 0.0009012222290039062 1.6069785356521606 0.337627112865448 82\n",
            "pred tensor([-3.5763e-07, -1.4305e-06, -2.8431e-05, -6.4888e-03, -2.0909e-04,\n",
            "        -3.5548e-04, -1.7719e-03, -3.9291e-04, -6.0201e-06, -3.6478e-05,\n",
            "        -2.5988e-05, -8.2970e-04, -4.6635e-04, -5.3704e-05, -2.3842e-07,\n",
            "        -5.9605e-07, -1.8454e-04, -4.6492e-05, -4.6015e-04, -1.3199e-03,\n",
            "        -7.4816e-04, -7.4863e-05, -1.1981e-05, -4.6600e-02, -2.3592e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05767359957098961 0.00214385986328125 1.5489826202392578 0.3684702217578888 64\n",
            "pred tensor([-3.9005e-03, -3.9458e-05, -7.6580e-04, -1.9491e-04, -6.2585e-06,\n",
            "        -4.1723e-07, -1.1325e-05, -7.1526e-07, -1.7881e-07, -2.3842e-07,\n",
            "        -5.9605e-08, -5.9605e-08, -6.5565e-07, -3.9506e-04, -1.2517e-06,\n",
            "        -3.2377e-04, -9.9756e-01, -1.0000e+00, -1.0000e+00, -3.5763e-07,\n",
            "        -2.0862e-06,  0.0000e+00, -3.8743e-06, -5.4240e-06, -2.4438e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08058436214923859 0.00848388671875 1.426891803741455 0.337935209274292 58\n",
            "pred tensor([-6.9737e-06, -3.4928e-05, -3.3379e-06, -2.5690e-05, -1.0073e-05,\n",
            "        -3.5167e-06, -2.5392e-05, -1.5900e-02, -1.2732e-04, -1.9431e-05,\n",
            "        -1.4305e-06, -5.6267e-05, -3.2187e-06, -1.2159e-05, -2.9087e-05,\n",
            "        -6.2752e-04, -7.4565e-05, -3.1495e-04, -1.5175e-04, -1.5192e-03,\n",
            "        -2.3317e-04, -5.1618e-05, -3.3283e-04, -6.3777e-05, -3.5524e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05221863463521004 0.004962921142578125 1.4930336475372314 0.38710281252861023 53\n",
            "pred tensor([-4.1986e-04, -4.7922e-05, -4.3511e-06, -2.5034e-06, -1.7285e-06,\n",
            "        -5.9605e-08, -3.4511e-05, -1.1146e-05,  0.0000e+00, -1.7881e-07,\n",
            "        -4.4703e-06, -9.5367e-07, -1.4582e-03, -2.7418e-06, -1.3232e-05,\n",
            "        -4.1723e-07, -9.5367e-07, -1.1504e-05, -1.7881e-07, -3.5763e-06,\n",
            "        -2.3246e-06, -5.9605e-08, -4.7684e-07, -3.9363e-04, -2.5630e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.078572116792202 0.00579071044921875 1.4413032531738281 0.34359920024871826 50\n",
            "pred tensor([-9.8944e-06, -1.0132e-01, -6.6943e-01, -2.0444e-05, -3.4153e-05,\n",
            "        -1.9073e-06, -2.2697e-04, -2.1935e-05, -2.2423e-04, -5.2643e-04,\n",
            "        -8.0872e-04, -4.2648e-03, -1.3723e-03, -3.0422e-04, -1.7047e-05,\n",
            "        -4.7684e-07, -1.7881e-07, -3.5524e-05, -8.4778e-02, -3.0899e-04,\n",
            "        -1.1921e-07, -5.9605e-08, -2.8968e-05, -1.1325e-06, -7.0572e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058178823441267014 0.0009784698486328125 1.7197132110595703 0.3728787899017334 60\n",
            "pred tensor([-1.9336e-04, -5.8031e-04, -7.0143e-04, -4.6997e-03, -9.9854e-01,\n",
            "        -1.0000e+00,  0.0000e+00,  0.0000e+00, -1.1921e-07, -4.5300e-06,\n",
            "        -8.9407e-07, -2.2292e-05, -4.8697e-05, -1.7881e-07, -1.7285e-06,\n",
            "        -1.0073e-05, -2.7657e-05, -1.2517e-06,  0.0000e+00, -5.3048e-06,\n",
            "        -2.1458e-06, -2.6822e-06, -2.4974e-05, -3.6180e-05, -6.1310e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0750654861330986 0.0020599365234375 1.5532567501068115 0.32746851444244385 43\n",
            "pred tensor([-9.3520e-05, -2.9445e-05, -4.1723e-07, -7.8142e-05, -4.3988e-05,\n",
            "        -1.2398e-05, -3.9339e-06, -1.0890e-04, -1.9073e-06, -3.4475e-04,\n",
            "        -5.2118e-04, -1.6689e-05, -4.2319e-05, -1.7853e-03, -7.0333e-06,\n",
            "        -5.3644e-07, -5.6028e-06, -3.1710e-05, -4.3130e-04, -2.4557e-05,\n",
            "        -1.7762e-05, -2.8014e-06, -2.6226e-06, -7.6294e-05, -1.6708e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.055082958191633224 0.00019693374633789062 1.7230422496795654 0.37383463978767395 55\n",
            "pred tensor([-2.6428e-02, -5.2299e-03, -3.9279e-05, -8.2779e-04, -1.9491e-04,\n",
            "        -2.7256e-03, -9.8944e-06, -2.0266e-06, -4.8280e-06, -1.2517e-06,\n",
            "        -2.0111e-04, -5.4121e-05, -2.5010e-04, -4.4703e-06, -4.7684e-07,\n",
            "        -5.4240e-06, -3.8147e-06, -2.3842e-05, -7.8796e-02, -2.3842e-06,\n",
            "        -1.7285e-06, -3.5763e-07, -5.4836e-06, -9.3079e-04, -3.1376e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0750109925866127 0.0003886222839355469 1.6120972633361816 0.3330118656158447 33\n",
            "pred tensor([-1.3741e-02, -5.8936e-01, -9.8389e-01, -5.8603e-04, -3.8362e-04,\n",
            "        -1.1621e-01, -1.9470e-01, -3.3319e-05, -1.2236e-03, -2.3193e-03,\n",
            "        -7.0333e-06, -1.2693e-03, -3.7659e-02, -5.6592e-01, -9.9316e-01,\n",
            "        -8.5498e-01, -4.2694e-02, -2.2485e-01, -5.3072e-04, -1.5088e-01,\n",
            "        -1.7200e-01, -6.0596e-01, -2.0142e-01, -7.2479e-03, -5.9540e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.057336561381816864 0.00250244140625 1.5446975231170654 0.35564538836479187 60\n",
            "pred tensor([-2.9395e-01, -1.6052e-01, -4.5312e-01, -1.7130e-04, -3.9339e-06,\n",
            "        -1.2871e-02, -1.0000e+00, -1.1325e-06, -1.6630e-05, -2.2650e-06,\n",
            "        -2.3842e-07, -5.9605e-07, -5.3048e-06, -1.1504e-05, -2.8014e-06,\n",
            "        -6.5565e-07, -1.7881e-07, -2.3842e-07, -4.0531e-05,  0.0000e+00,\n",
            "        -1.4889e-04, -9.2447e-05, -1.1325e-06, -3.7551e-06, -1.3185e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07761909812688828 0.001049041748046875 1.6026146411895752 0.32814738154411316 45\n",
            "pred tensor([-1.7941e-05, -5.6028e-06, -5.4359e-05, -2.6226e-06, -1.1511e-03,\n",
            "        -6.6161e-06, -4.9472e-06, -2.3544e-05, -2.2340e-04, -4.5419e-05,\n",
            "        -2.3842e-05, -2.5320e-04, -4.2725e-04, -1.0815e-03, -6.2065e-03,\n",
            "        -1.4770e-04, -3.0880e-03, -1.0490e-02, -4.7803e-01, -1.2291e-02,\n",
            "        -1.1683e-04, -2.0742e-04, -5.1260e-06, -3.5942e-05, -6.3539e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04945797845721245 0.001026153564453125 1.575742483139038 0.370730996131897 54\n",
            "pred tensor([-1.9516e-02, -7.8796e-02, -2.2564e-03, -4.2677e-05, -1.1921e-07,\n",
            "        -7.1526e-07, -3.9935e-06, -3.8147e-06, -4.2140e-05, -2.9683e-05,\n",
            "        -1.5906e-01, -8.7857e-05, -8.2850e-05, -3.7408e-04, -3.0994e-06,\n",
            "        -1.0133e-06, -2.3842e-06, -1.4937e-04, -1.0371e-05, -5.0664e-06,\n",
            "        -1.3769e-05, -1.3709e-06, -2.3305e-05, -1.5724e-04, -1.5497e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08017434179782867 0.00107574462890625 1.5006818771362305 0.34534361958503723 65\n",
            "pred tensor([-7.3135e-05, -1.8463e-03, -4.1306e-05, -1.7810e-04, -2.1827e-04,\n",
            "        -1.7226e-05, -2.2423e-04, -5.0316e-03, -9.0301e-05, -1.9264e-04,\n",
            "        -1.7285e-05, -1.3113e-05, -2.2054e-06, -1.6422e-03, -2.4014e-03,\n",
            "        -9.1400e-03, -2.4433e-03, -1.8219e-02, -5.3358e-04, -4.5471e-03,\n",
            "        -8.0795e-03, -3.0458e-05, -1.5306e-03, -6.4240e-03, -1.6937e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05370898172259331 0.00345611572265625 1.4367321729660034 0.3626777231693268 84\n",
            "11\n",
            "pred tensor([-1.3635e-01, -2.1191e-03, -1.2693e-03, -4.7851e-04, -2.2430e-03,\n",
            "        -9.1211e-01, -3.3386e-02, -7.9691e-05, -3.5763e-07, -2.3246e-06,\n",
            "        -3.8683e-05, -6.5002e-03, -1.0170e-02, -3.7861e-04, -1.4191e-03,\n",
            "        -6.3744e-03, -5.1318e-01, -1.1273e-01, -1.5259e-01, -9.6680e-01,\n",
            "        -1.0000e+00, -5.2452e-06, -1.8716e-05, -5.4810e-02, -5.3467e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08291614055633545 0.0010986328125 1.5182373523712158 0.3346501886844635 65\n",
            "pred tensor([-1.4368e-01, -1.4258e-01, -8.2016e-03, -4.1723e-04, -2.9926e-03,\n",
            "        -8.2159e-04, -1.8120e-05, -1.5664e-04, -2.0826e-04, -1.0586e-03,\n",
            "        -4.5919e-04, -1.1981e-05, -2.1148e-04, -2.5225e-04, -2.4915e-04,\n",
            "        -2.9011e-03, -7.1704e-05, -7.4768e-03, -1.1854e-03, -7.7343e-04,\n",
            "        -2.3438e-02, -6.2790e-03, -2.0905e-02, -1.3123e-03, -2.7924e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.054922446608543396 0.0005159378051757812 1.6130439043045044 0.36111533641815186 99\n",
            "pred tensor([-7.4863e-05, -2.8133e-04, -2.5868e-05, -8.1658e-06, -3.5763e-07,\n",
            "        -1.2994e-05, -4.1723e-04, -7.4816e-04, -1.2147e-04, -2.3246e-06,\n",
            "         0.0000e+00,  0.0000e+00, -7.6592e-05, -8.5938e-01, -1.0000e+00,\n",
            "        -5.9605e-08,  0.0000e+00, -5.9605e-07, -5.9605e-08, -8.7619e-06,\n",
            "        -2.5225e-04, -1.7607e-04, -5.3263e-04, -3.7611e-05, -6.4969e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08025040477514267 0.00555419921875 1.3934361934661865 0.3439696133136749 50\n",
            "pred tensor([-2.5392e-05, -5.6624e-06, -4.3559e-04, -2.1231e-04, -4.2796e-05,\n",
            "        -6.0797e-06, -9.8765e-05, -1.9109e-04, -2.8133e-04, -5.4359e-05,\n",
            "        -2.9297e-03, -4.0936e-04, -3.2043e-03, -6.0701e-04, -2.7618e-02,\n",
            "        -1.2693e-03, -1.0777e-03, -4.0770e-04, -1.8966e-04, -6.0201e-06,\n",
            "        -6.3848e-04, -3.6359e-05, -8.1348e-04, -1.5414e-04, -7.3099e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.051789719611406326 0.003917694091796875 1.385920763015747 0.38973671197891235 80\n",
            "pred tensor([-8.0762e-01, -3.2373e-01, -1.0818e-02, -8.3447e-07, -3.0935e-05,\n",
            "        -1.1035e-01, -1.1311e-03, -4.5300e-06, -1.7881e-07, -3.8147e-06,\n",
            "        -5.4240e-06, -4.1723e-07, -1.8349e-03, -6.4015e-05, -9.6858e-05,\n",
            "        -6.9141e-06, -2.8551e-05, -2.9802e-07, -3.5763e-07, -1.0228e-04,\n",
            "        -1.0000e+00, -1.0000e+00, -1.4305e-06,  0.0000e+00, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07510217279195786 0.002124786376953125 1.5271022319793701 0.33002999424934387 51\n",
            "pred tensor([-3.5763e-07, -7.0870e-05, -7.8678e-06, -3.3975e-06, -6.2525e-05,\n",
            "        -4.6015e-04, -1.1367e-04, -3.9215e-03, -1.7822e-05, -3.2258e-04,\n",
            "        -1.3542e-03, -2.0182e-04, -5.3704e-05, -2.5868e-05, -2.4433e-03,\n",
            "        -3.2043e-02, -6.8378e-04, -2.6276e-02, -7.9285e-02, -8.8806e-03,\n",
            "        -5.4955e-05, -7.5607e-03, -5.3215e-03, -2.6367e-01, -2.8351e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.052474312484264374 0.0010709762573242188 1.5515923500061035 0.3634352684020996 87\n",
            "pred tensor([-1.6034e-04, -2.4300e-03, -3.2187e-06, -1.9913e-02, -1.7881e-07,\n",
            "        -5.3644e-07, -1.3113e-06, -3.1471e-05, -2.3842e-07, -1.0729e-06,\n",
            "        -3.9935e-06, -5.9903e-05, -1.2457e-05, -7.1526e-07, -9.1400e-03,\n",
            "        -8.6844e-05, -4.6635e-04, -7.2002e-05, -8.7786e-04, -1.6093e-06,\n",
            "        -1.1921e-06, -1.0319e-03, -2.8253e-04, -9.8407e-05, -1.4324e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08244071900844574 0.0007076263427734375 1.5430536270141602 0.3315494656562805 63\n",
            "pred tensor([-5.5771e-03, -2.0862e-05, -7.6294e-05, -2.0587e-04, -8.3780e-04,\n",
            "        -7.2002e-05, -1.0386e-03, -3.3627e-03, -1.3928e-01, -3.4027e-03,\n",
            "        -1.8295e-02, -1.4582e-03, -5.5194e-05, -1.4624e-01, -8.4375e-01,\n",
            "        -1.0000e+00, -1.0000e+00, -2.0103e-03, -6.4373e-06, -5.0068e-05,\n",
            "        -1.1367e-04, -1.2195e-04, -4.1084e-03, -4.1246e-04, -1.2627e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05364100635051727 0.0006656646728515625 1.5882724523544312 0.3447965085506439 93\n",
            "pred tensor([-3.8981e-05, -8.4457e-03, -5.8055e-05, -3.4571e-06, -2.5630e-06,\n",
            "        -9.8348e-06, -1.9038e-04, -1.5497e-06, -2.9802e-07, -1.3876e-04,\n",
            "        -6.5804e-05, -2.3193e-03, -1.6212e-05, -1.1921e-07, -7.1526e-07,\n",
            "        -1.1206e-05, -1.5020e-05,  0.0000e+00, -1.0014e-05, -2.0862e-06,\n",
            "        -7.7486e-07, -6.7949e-06, -4.3154e-05, -7.7248e-05, -5.4777e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0747421607375145 0.00115966796875 1.5149134397506714 0.3303605914115906 52\n",
            "pred tensor([-4.5630e-01, -2.3317e-04, -8.0585e-05, -1.7262e-04, -4.3144e-03,\n",
            "        -6.9475e-04, -4.0531e-06, -7.6890e-06, -1.7285e-06, -2.1076e-04,\n",
            "        -9.2871e-01, -8.9160e-01, -9.9951e-01, -1.0000e+00, -9.9561e-01,\n",
            "        -5.3465e-05, -1.1915e-04, -2.9135e-04, -9.3460e-04, -1.7536e-04,\n",
            "        -1.6344e-04, -1.5843e-04, -8.0729e-04, -4.7565e-04, -2.9588e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.054359644651412964 0.0012407302856445312 1.4926555156707764 0.345032274723053 89\n",
            "pred tensor([-5.3070e-02, -2.1877e-03, -1.1877e-01, -1.8628e-01, -5.8670e-03,\n",
            "        -8.4610e-03, -2.0111e-04, -2.3975e-03, -1.4901e-06, -1.4901e-06,\n",
            "        -1.6153e-05, -5.0068e-05, -3.3379e-06, -5.1856e-06, -4.8280e-06,\n",
            "        -5.9605e-07, -5.9605e-08, -5.9605e-08,  0.0000e+00, -7.1704e-05,\n",
            "        -1.0099e-03, -3.5828e-02, -6.8237e-02, -1.0000e+00,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0779457613825798 0.001033782958984375 1.5182740688323975 0.3284669816493988 44\n",
            "pred tensor([-5.3644e-07,  0.0000e+00,  0.0000e+00, -5.9605e-08, -5.9605e-08,\n",
            "        -5.9605e-08, -5.9605e-08, -5.7220e-06, -1.7881e-07, -5.3644e-07,\n",
            "        -6.5565e-06, -8.8215e-06, -8.0252e-04, -1.4365e-05, -3.5763e-07,\n",
            "        -9.7632e-05, -2.4819e-04, -1.7810e-04, -2.1338e-05, -2.7637e-03,\n",
            "        -5.4121e-05, -2.7905e-03, -1.8282e-03, -9.9659e-04, -2.1827e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.047537911683321 0.00536346435546875 1.4024124145507812 0.35158571600914 54\n",
            "pred tensor([-2.5606e-04, -5.7297e-03, -1.7583e-05, -1.2636e-05, -1.9729e-05,\n",
            "         0.0000e+00, -5.2452e-06, -5.9605e-08,  0.0000e+00, -1.2195e-04,\n",
            "        -2.2297e-03, -5.0426e-05, -6.7949e-06, -5.9605e-08, -7.7486e-07,\n",
            "         0.0000e+00, -5.2273e-05, -1.2517e-06, -3.8087e-05, -1.6630e-05,\n",
            "        -5.6362e-04, -5.3644e-07, -4.0221e-04, -1.0723e-04, -1.1683e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07566826790571213 0.002239227294921875 1.4965862035751343 0.3264659345149994 37\n",
            "pred tensor([-2.2078e-04, -5.5194e-05, -3.3855e-04, -5.1022e-05, -4.7386e-05,\n",
            "        -1.3666e-03, -6.4392e-03, -4.1809e-03, -6.7890e-05, -6.5029e-05,\n",
            "        -5.3883e-05, -3.2425e-05, -1.9073e-06, -2.4719e-03, -1.4591e-04,\n",
            "        -2.8133e-04, -5.0926e-04, -3.8207e-05, -8.9551e-01, -9.9756e-01,\n",
            "        -1.0000e+00, -9.4175e-06, -3.5346e-05, -2.9564e-05, -3.2640e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05058258771896362 0.0048828125 1.4317243099212646 0.36596357822418213 67\n",
            "pred tensor([-8.9586e-05, -1.2846e-03, -2.6464e-05, -8.5831e-06, -2.5034e-06,\n",
            "        -5.3644e-07, -6.6161e-06, -1.3232e-04, -8.1539e-05, -3.3319e-05,\n",
            "        -1.1021e-04, -1.0729e-06, -3.4273e-05, -2.6062e-02, -7.5035e-03,\n",
            "        -1.8799e-02, -1.3232e-04, -3.8147e-06, -9.6858e-05, -6.2451e-01,\n",
            "        -1.0000e+00, -1.0000e+00, -5.3644e-07, -5.9605e-08,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07604242116212845 0.0011119842529296875 1.56702721118927 0.34274059534072876 33\n",
            "pred tensor([-1.9670e-06, -3.5763e-07, -2.3842e-07, -5.0664e-06, -5.9605e-08,\n",
            "         0.0000e+00,  0.0000e+00, -5.9605e-08, -1.0133e-06, -2.2888e-05,\n",
            "        -2.5272e-05, -1.0729e-05, -4.7088e-06, -2.9981e-05, -7.8678e-06,\n",
            "        -1.1921e-06, -3.5763e-07, -8.9407e-07, -3.0816e-05, -2.9206e-06,\n",
            "        -7.4463e-03, -4.0054e-05, -1.6665e-04, -4.3511e-06, -3.5763e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05016327649354935 0.0013294219970703125 1.601754903793335 0.36575546860694885 50\n",
            "pred tensor([-4.3945e-01, -1.3928e-01, -4.8339e-05, -1.1772e-04, -3.5763e-07,\n",
            "        -1.5140e-05, -4.4346e-05, -7.1526e-07, -3.5763e-07, -3.4571e-06,\n",
            "        -5.4777e-05, -6.3777e-06, -1.9264e-03, -6.9201e-05, -2.1517e-05,\n",
            "        -3.3975e-06, -1.6570e-05, -1.1683e-05, -7.1472e-02, -1.0000e+00,\n",
            "        -1.0000e+00, -1.4424e-05, -1.0312e-05, -1.6689e-06, -1.1921e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07892068475484848 0.0011873245239257812 1.5396904945373535 0.3380228281021118 39\n",
            "pred tensor([-4.0531e-06, -2.9802e-07, -5.3644e-07, -4.1723e-07, -1.4305e-06,\n",
            "        -5.3644e-07, -2.3842e-07, -1.0312e-05, -3.7551e-06, -1.2100e-05,\n",
            "        -9.1791e-06, -4.3809e-05, -1.9073e-06, -2.5630e-06, -6.5267e-05,\n",
            "        -2.0266e-04, -5.8055e-05, -2.5630e-06, -3.0994e-06, -1.5497e-06,\n",
            "        -1.4305e-06, -9.0003e-06, -1.5724e-04, -1.1292e-03, -5.6744e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05259567126631737 0.0013179779052734375 1.5572655200958252 0.34154558181762695 57\n",
            "pred tensor([-7.7546e-05, -7.7915e-04, -1.7810e-04, -3.9339e-06, -3.3975e-06,\n",
            "        -4.1723e-07, -4.5776e-05, -2.0993e-04, -2.7962e-03, -9.5459e-01,\n",
            "        -9.7705e-01, -5.9605e-08,  0.0000e+00, -3.5763e-07,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7684e-07, -6.5565e-07,\n",
            "        -4.7684e-07, -5.9605e-08, -3.5763e-07,  0.0000e+00, -1.0133e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0776062086224556 0.00038814544677734375 1.6177901029586792 0.3231808841228485 31\n",
            "pred tensor([-7.1526e-07, -1.7881e-07, -5.9605e-08, -3.3975e-06, -3.5763e-07,\n",
            "        -8.9407e-07, -1.0729e-06, -7.7486e-07, -4.1723e-07, -2.9802e-07,\n",
            "        -3.0398e-06, -1.6534e-04, -2.7919e-04, -4.7743e-05, -1.8883e-04,\n",
            "        -8.7142e-05, -1.4305e-06, -1.0192e-05, -1.3292e-05, -9.5367e-07,\n",
            "        -1.3888e-05, -3.1590e-06, -4.7922e-05, -1.2696e-05, -4.0531e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04895938187837601 0.00251007080078125 1.4897618293762207 0.36703309416770935 48\n",
            "pred tensor([-8.5754e-03, -1.7944e-02, -1.5533e-04, -1.1027e-05, -2.3842e-07,\n",
            "         0.0000e+00, -1.4901e-06, -1.7703e-05, -9.2983e-06, -2.6047e-05,\n",
            "        -1.4782e-05, -1.0550e-05, -1.1963e-04, -6.6161e-06, -9.1839e-04,\n",
            "        -1.6689e-06, -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -2.9321e-01, -5.8289e-02, -9.9951e-01, -7.9036e-05, -4.4525e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07177311927080154 0.001739501953125 1.566287875175476 0.32412782311439514 32\n",
            "pred tensor([-2.9445e-05, -1.2846e-03, -6.3777e-05, -4.8876e-04, -3.5763e-07,\n",
            "        -2.5225e-04, -3.0220e-05, -1.0967e-05, -2.5868e-05, -1.3053e-05,\n",
            "        -7.0870e-05, -6.9189e-04, -4.1652e-04, -5.4550e-04, -6.8140e-04,\n",
            "        -3.7932e-04, -4.5898e-02, -7.3364e-02, -3.2306e-04, -2.4533e-04,\n",
            "        -8.7595e-04, -6.2764e-05, -2.5129e-04, -4.8218e-03, -1.6467e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04599924013018608 0.0009412765502929688 1.5890905857086182 0.40241289138793945 56\n",
            "pred tensor([-6.0986e-01, -7.3779e-01, -2.5749e-05, -1.1563e-05, -1.1921e-07,\n",
            "        -7.1526e-07, -3.4571e-06, -3.4809e-05, -5.9605e-07, -3.5763e-07,\n",
            "        -5.9605e-08, -4.1723e-07, -5.9605e-07, -3.4027e-03, -5.5351e-03,\n",
            "        -4.2140e-05, -2.6226e-04, -1.6630e-05, -1.0633e-03, -4.1723e-07,\n",
            "        -7.5102e-06, -1.9372e-05, -3.2234e-03, -7.2718e-06, -4.2498e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08005550503730774 0.0012416839599609375 1.511279582977295 0.3420199453830719 53\n",
            "pred tensor([-3.0816e-05, -1.4544e-05, -1.4007e-05, -1.6475e-04, -2.6286e-05,\n",
            "        -6.7997e-04, -5.5432e-06, -4.1842e-05, -7.8142e-05, -4.9472e-05,\n",
            "        -3.6564e-03, -5.2452e-05, -8.2129e-01, -7.2949e-01, -9.9902e-01,\n",
            "        -1.0000e+00, -1.0000e+00, -1.0000e+00, -9.4922e-01, -3.5429e-04,\n",
            "        -3.1719e-03, -3.9902e-03, -1.2481e-04, -4.1229e-02, -1.2100e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0510229654610157 0.0002608299255371094 1.659663200378418 0.3375382125377655 72\n",
            "pred tensor([-6.0959e-03, -5.1403e-04, -3.0184e-04, -5.9605e-08, -1.0133e-06,\n",
            "        -2.6779e-03, -1.8477e-05, -1.0550e-05, -4.2319e-06, -1.8775e-05,\n",
            "        -1.3709e-06, -5.0664e-06, -1.1325e-06, -2.1875e-05, -2.9802e-07,\n",
            "        -1.7881e-07, -3.7231e-02, -8.3923e-04, -9.9902e-01, -1.0000e+00,\n",
            "        -1.0000e+00, -8.1177e-02, -8.0585e-05, -2.5511e-04, -4.1723e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07448847591876984 0.001682281494140625 1.4678313732147217 0.33022236824035645 45\n",
            "pred tensor([-2.3842e-06, -1.1921e-07, -1.3649e-05, -1.8239e-04, -1.3590e-05,\n",
            "        -1.2100e-05, -1.4651e-04, -1.2100e-05, -6.2656e-04, -2.0421e-04,\n",
            "        -8.3590e-04, -2.4438e-04, -7.3195e-04, -5.8603e-04, -6.1178e-04,\n",
            "        -3.3970e-03, -6.6147e-03, -1.2493e-03, -9.1732e-05, -1.4365e-04,\n",
            "        -4.1008e-05, -5.1212e-04, -1.5137e-01, -9.9951e-01, -9.9756e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05388471484184265 0.00228118896484375 1.482527732849121 0.3542725741863251 81\n",
            "pred tensor([-7.0572e-04, -1.1806e-03, -1.5473e-04, -8.2850e-06, -5.9605e-08,\n",
            "        -1.1921e-07, -6.5565e-06, -2.4498e-05, -3.1590e-06, -2.3246e-06,\n",
            "        -8.9407e-07,  0.0000e+00, -2.0862e-06, -1.2755e-05, -3.5763e-06,\n",
            "        -8.4043e-06, -5.1856e-06, -7.3671e-05, -3.6793e-03, -5.0426e-05,\n",
            "        -1.6630e-05, -2.1315e-04, -7.0333e-06, -3.0994e-06, -5.9605e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07567212730646133 0.004749298095703125 1.3316631317138672 0.328653484582901 47\n",
            "pred tensor([-6.5565e-07, -2.9802e-07, -4.7684e-07, -2.5630e-06, -1.0729e-06,\n",
            "        -2.2054e-06, -4.3154e-05, -2.3234e-04, -6.7115e-05, -5.8532e-05,\n",
            "        -2.4343e-04, -1.8139e-03, -6.3002e-05, -2.4819e-04, -1.8930e-03,\n",
            "        -5.1618e-05, -3.5107e-05, -1.1683e-05, -8.1539e-05, -1.3709e-06,\n",
            "        -2.9802e-05, -4.9472e-06, -1.6570e-05, -4.9829e-04, -1.7824e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.053227681666612625 0.006683349609375 1.3493986129760742 0.35540902614593506 98\n",
            "pred tensor([-5.8670e-03, -2.5177e-02, -1.8826e-03, -1.3018e-03, -1.0133e-06,\n",
            "        -2.3842e-07, -1.9670e-06, -1.1981e-05, -1.4725e-03, -8.9228e-05,\n",
            "        -4.7836e-03, -4.2915e-06, -3.5763e-07, -1.6928e-04, -4.6463e-03,\n",
            "        -7.1526e-07, -1.1325e-06, -4.8876e-06, -1.1742e-05, -4.7660e-04,\n",
            "        -1.1194e-04, -2.4002e-02, -9.9902e-01, -1.0000e+00, -4.4703e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07591558992862701 0.0007295608520507812 1.5298492908477783 0.3389964699745178 43\n",
            "pred tensor([-5.1022e-04, -4.1723e-07, -2.4438e-04, -3.9339e-06, -1.3709e-06,\n",
            "        -1.0133e-06, -1.7166e-05, -1.3769e-04, -1.9491e-04, -3.2377e-04,\n",
            "        -7.0572e-05, -5.2691e-05, -1.9908e-05, -7.3135e-05, -5.5933e-04,\n",
            "        -1.4007e-05, -1.0073e-05, -6.4790e-05, -1.2646e-03, -4.7569e-03,\n",
            "        -6.1095e-05, -4.1924e-03, -2.0027e-04, -3.9053e-04, -8.3923e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.053307875990867615 0.0013713836669921875 1.477820634841919 0.3639703392982483 78\n",
            "pred tensor([-5.4703e-03, -6.7890e-05, -6.6042e-05, -1.2338e-04, -1.7285e-06,\n",
            "        -4.0531e-06, -1.6093e-06, -4.7684e-07, -3.9339e-06, -2.7657e-05,\n",
            "        -6.8545e-06, -7.5102e-06, -5.5432e-06, -4.7028e-05, -2.3055e-04,\n",
            "        -2.2340e-04, -7.2241e-05, -1.9789e-04, -1.1563e-05, -2.4068e-04,\n",
            "        -6.1810e-05, -6.6406e-02, -6.5565e-06, -1.0353e-04, -1.1921e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08015159517526627 0.0007309913635253906 1.531644344329834 0.355273962020874 58\n",
            "pred tensor([-2.3842e-07, -2.2650e-05, -2.4533e-04, -4.1962e-05, -5.9426e-05,\n",
            "        -9.1267e-04, -8.8215e-06, -4.5419e-05, -2.4658e-02, -7.5244e-01,\n",
            "        -2.4756e-01, -2.2449e-01, -8.2458e-02, -6.5283e-01, -8.7500e-01,\n",
            "        -6.0693e-01, -9.9219e-01, -9.2236e-01, -9.8828e-01, -9.9902e-01,\n",
            "        -9.9951e-01, -1.0000e+00, -1.0000e+00, -6.2287e-05, -1.3113e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05532991886138916 0.000286102294921875 1.5724221467971802 0.3486466407775879 89\n",
            "pred tensor([-6.9499e-05, -7.4565e-05, -5.1022e-04, -3.9983e-04, -2.3842e-06,\n",
            "        -2.5034e-06, -1.3232e-05, -3.7074e-05, -1.7881e-07, -7.3910e-06,\n",
            "        -5.9605e-08, -3.5167e-06, -6.5029e-05, -7.3135e-05, -1.3232e-04,\n",
            "        -1.7881e-07, -1.4603e-05, -1.0133e-06, -4.1127e-06, -5.3048e-06,\n",
            "        -6.4969e-06, -4.4525e-05, -3.9935e-05, -1.8418e-05, -8.4162e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07922635972499847 0.00218963623046875 1.4421746730804443 0.3336654603481293 54\n",
            "pred tensor([-8.1658e-06, -3.4690e-05, -1.3816e-04, -1.6344e-04, -6.2656e-04,\n",
            "        -1.0133e-06, -2.5821e-04, -9.6798e-04, -1.8239e-04, -1.7536e-04,\n",
            "        -1.1593e-04, -1.8668e-04, -4.6015e-04, -2.7239e-05, -5.1439e-05,\n",
            "        -1.0986e-01, -2.5345e-02, -6.3515e-03, -1.0000e+00, -1.0000e+00,\n",
            "        -1.0000e+00, -3.0303e-04, -3.1447e-04, -1.2922e-03, -2.0027e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04942674562335014 0.003353118896484375 1.4239312410354614 0.36874788999557495 60\n",
            "pred tensor([-8.4817e-05, -2.2564e-03, -9.2163e-03, -8.3643e-01, -9.9756e-01,\n",
            "        -1.0000e+00, -3.0100e-05, -5.7817e-05, -2.2054e-06, -2.0325e-05,\n",
            "        -2.0862e-06, -2.5415e-04, -2.8086e-04, -4.8697e-05, -2.4152e-04,\n",
            "        -6.4230e-04, -2.2173e-04, -1.1593e-04, -2.6822e-05, -4.9472e-06,\n",
            "        -1.8387e-03, -5.1613e-03, -1.7059e-04, -5.3596e-04, -2.2087e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07414644211530685 0.002666473388671875 1.4441184997558594 0.3279658257961273 52\n",
            "pred tensor([-9.8348e-06, -6.7592e-05, -1.6344e-04, -5.0545e-04, -3.9744e-04,\n",
            "        -5.9175e-04, -2.4915e-04, -2.9588e-04, -8.9586e-05, -4.7851e-04,\n",
            "        -7.9989e-05, -5.2547e-04, -3.9756e-05, -2.2876e-04, -8.4043e-06,\n",
            "        -4.0829e-05, -7.5996e-05, -5.9605e-06, -9.3877e-05, -1.4305e-05,\n",
            "        -1.9491e-04, -8.0466e-06, -3.3379e-06, -5.6624e-06, -3.0422e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05385822057723999 0.002719879150390625 1.4231581687927246 0.3350914716720581 64\n",
            "pred tensor([-6.6578e-05, -4.8866e-03, -5.4240e-06, -4.0531e-06, -1.8299e-05,\n",
            "        -1.5962e-04, -7.3910e-06, -1.1921e-06, -9.0003e-06, -1.7881e-07,\n",
            "        -1.1921e-07, -7.1526e-07, -2.4557e-05, -2.7676e-03, -4.8280e-06,\n",
            "        -2.4819e-04, -2.0862e-05, -1.4484e-04, -2.5034e-06, -4.0054e-05,\n",
            "        -1.4246e-05, -5.4836e-06, -1.0729e-05, -1.4544e-04, -3.2067e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07673373073339462 0.0011501312255859375 1.4466171264648438 0.32750174403190613 42\n",
            "pred tensor([-3.3539e-02, -7.8142e-05, -5.4121e-05, -8.5831e-05, -1.4381e-03,\n",
            "        -1.0681e-04, -1.7202e-04, -3.5286e-04, -1.4198e-04, -8.3303e-04,\n",
            "        -1.0371e-05, -1.4961e-05, -2.2697e-04, -3.6407e-04, -1.0468e-01,\n",
            "        -1.7868e-02, -1.0674e-02, -2.3651e-02, -9.5596e-03, -1.7407e-01,\n",
            "        -9.9365e-01, -1.0000e+00, -1.0000e+00, -2.9564e-05, -7.2122e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0516410768032074 0.0006861686706542969 1.499969482421875 0.3491062521934509 54\n",
            "12\n",
            "pred tensor([-2.2411e-05, -6.8545e-06, -9.5367e-06, -3.7909e-05, -2.1219e-05,\n",
            "        -8.1241e-05, -1.3649e-05, -1.0431e-05, -3.2783e-06, -1.9670e-06,\n",
            "        -5.9605e-08,  0.0000e+00, -2.3842e-07,  0.0000e+00, -5.9605e-08,\n",
            "        -5.2691e-05, -2.2697e-03, -1.8433e-02, -5.1641e-04, -1.3089e-04,\n",
            "        -5.3704e-05, -1.7881e-06, -1.1325e-05, -1.7822e-05, -3.3379e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07342290878295898 0.0013828277587890625 1.4477555751800537 0.35629886388778687 41\n",
            "pred tensor([-4.4703e-06, -1.1772e-04, -4.6492e-06, -4.2796e-04, -8.0466e-06,\n",
            "        -2.4498e-05, -2.1398e-04, -5.7297e-03, -1.2335e-01, -1.7166e-05,\n",
            "        -1.8597e-04, -1.3170e-03, -3.0184e-04, -2.4247e-04, -6.1393e-06,\n",
            "        -9.1374e-05, -5.9009e-06, -1.4901e-05, -1.6737e-04, -2.1076e-04,\n",
            "        -1.8597e-04, -7.7486e-06, -4.6492e-06, -2.6822e-06, -3.5763e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05432575196027756 0.0008072853088378906 1.4768316745758057 0.34943971037864685 67\n",
            "pred tensor([-2.4261e-02, -9.2041e-01, -9.9512e-01, -8.9014e-01, -9.7559e-01,\n",
            "        -1.0000e+00, -1.3113e-06, -3.0994e-06, -4.1723e-07, -7.7486e-07,\n",
            "        -5.9605e-07, -2.3842e-07, -4.1723e-07, -1.0729e-06, -2.9802e-07,\n",
            "        -5.9605e-08, -5.9605e-08, -3.0220e-05, -4.3559e-04, -1.4901e-06,\n",
            "        -5.0068e-06, -2.4676e-05, -1.3113e-06, -2.5630e-06, -6.3777e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07836873084306717 0.0022125244140625 1.4291908740997314 0.34481489658355713 60\n",
            "pred tensor([-2.1458e-06, -2.3842e-05, -2.6822e-06, -2.3127e-05, -8.3447e-06,\n",
            "        -4.7278e-04, -3.5429e-04, -2.9802e-07, -5.4240e-06, -9.4175e-06,\n",
            "        -8.8513e-05, -2.6505e-02, -4.9255e-02, -8.4817e-05, -4.4703e-06,\n",
            "        -1.1504e-04, -9.4748e-04, -1.8139e-03, -1.6224e-04, -4.5280e-03,\n",
            "        -9.9468e-04, -1.0431e-04, -1.1021e-04, -1.3914e-03, -6.7578e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05547952651977539 0.001171112060546875 1.4744375944137573 0.36795130372047424 65\n",
            "pred tensor([-3.0780e-04, -1.8311e-04, -4.1127e-06, -2.1458e-05, -5.9605e-08,\n",
            "        -2.3842e-07, -5.8532e-05,  0.0000e+00, -3.5763e-07, -2.8801e-04,\n",
            "        -1.3023e-02, -2.2519e-04, -3.1590e-06, -4.8280e-06, -3.9160e-05,\n",
            "        -1.7464e-04, -9.9182e-05, -4.8161e-05, -8.0466e-06, -1.1921e-07,\n",
            "        -3.5763e-07, -1.0133e-06, -4.5919e-04, -9.2447e-05, -1.1861e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07372511178255081 0.0025653839111328125 1.4863039255142212 0.32173821330070496 24\n",
            "pred tensor([-4.7755e-04, -8.5473e-05, -4.8876e-05, -1.0270e-04, -2.1994e-04,\n",
            "        -7.3671e-05, -3.2759e-04, -9.5010e-05, -6.9189e-04, -1.2994e-05,\n",
            "        -1.7643e-05, -3.5524e-05, -9.2173e-04, -3.5357e-04, -3.3140e-04,\n",
            "        -1.2617e-03, -1.8883e-04, -6.9046e-04, -9.6130e-03, -1.1021e-04,\n",
            "        -9.5654e-04, -2.7299e-05, -4.2915e-06, -6.0618e-05, -1.6987e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05050976201891899 0.00208282470703125 1.47785222530365 0.373185396194458 48\n",
            "pred tensor([-6.7353e-05, -9.7561e-04, -2.7374e-02, -1.8477e-06, -6.6161e-06,\n",
            "        -1.6689e-05, -1.3709e-06, -7.5102e-06, -1.5795e-05, -3.6359e-05,\n",
            "        -3.5114e-03, -9.0599e-06, -5.3704e-05, -6.8665e-05, -2.6569e-03,\n",
            "        -6.2513e-04, -6.5756e-04, -1.1867e-04, -2.0325e-05, -2.9564e-05,\n",
            "        -8.6129e-05, -1.0610e-05, -4.9472e-06, -2.0564e-05, -1.7262e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07389793545007706 0.001514434814453125 1.4940998554229736 0.3365840017795563 49\n",
            "pred tensor([-6.9857e-04, -2.3956e-02, -1.9908e-05, -1.2493e-03, -8.1539e-05,\n",
            "        -1.7996e-03, -1.3649e-05, -6.9141e-06, -5.1856e-05, -1.4043e-04,\n",
            "        -7.0870e-05, -1.8311e-04, -9.7215e-05, -1.2445e-03, -8.5115e-05,\n",
            "        -3.7611e-05, -1.0490e-05, -1.2398e-05, -2.2650e-05, -2.4247e-04,\n",
            "        -1.6153e-05, -6.8521e-04, -8.7128e-03, -2.3782e-04, -6.8665e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.050770003348588943 0.001659393310546875 1.4205596446990967 0.3713655471801758 63\n",
            "pred tensor([-2.3413e-04, -9.3794e-04, -4.8561e-03, -3.9279e-05, -9.2554e-04,\n",
            "        -2.9802e-07, -2.3842e-07, -6.7949e-06, -4.4107e-06, -2.8014e-06,\n",
            "        -1.8001e-05, -1.0133e-06, -2.4438e-06, -3.0460e-03, -4.2755e-02,\n",
            "        -7.6890e-06, -9.1791e-06, -1.4305e-05, -1.6332e-05, -1.0073e-05,\n",
            "        -2.6822e-05, -3.2115e-04, -3.1590e-05, -1.1772e-04, -7.0333e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07024628669023514 0.001605987548828125 1.4493547677993774 0.3261275291442871 37\n",
            "pred tensor([-2.1814e-01, -2.7061e-04, -2.8431e-05, -5.4054e-03, -6.3629e-03,\n",
            "        -9.4235e-05, -2.8667e-03, -1.2999e-03, -4.7743e-05, -2.9683e-05,\n",
            "        -4.3333e-05, -2.8920e-04, -1.3069e-02, -5.2691e-05, -3.5167e-06,\n",
            "        -7.2412e-01, -1.0000e+00, -1.0000e+00, -1.5274e-02, -9.4147e-03,\n",
            "        -4.6844e-02, -7.9199e-01, -2.3605e-02, -3.9978e-03, -1.2573e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05494360253214836 0.0006914138793945312 1.5472084283828735 0.3591369688510895 66\n",
            "pred tensor([-2.8214e-02, -1.6556e-02, -1.2993e-02, -6.6805e-04, -1.1194e-04,\n",
            "        -2.6584e-05, -2.2054e-06, -1.4467e-03, -2.5094e-05, -4.2796e-04,\n",
            "        -4.8279e-02, -5.0488e-01, -9.4531e-01, -9.9072e-01, -9.5367e-07,\n",
            "        -3.5763e-07, -9.5367e-06, -8.7023e-06, -2.0027e-04, -2.2602e-03,\n",
            "        -4.1723e-06, -5.4836e-06, -2.2888e-05, -5.9605e-08, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07804854959249496 0.00739288330078125 1.403902530670166 0.33041322231292725 56\n",
            "pred tensor([-1.1292e-01, -5.5504e-04, -8.3447e-07, -1.2338e-05, -2.0266e-06,\n",
            "        -1.0133e-06, -1.3709e-06, -1.3113e-06, -3.5167e-06, -9.0659e-05,\n",
            "        -2.7704e-04, -2.7466e-03, -3.2759e-04, -2.8610e-05, -1.3590e-05,\n",
            "        -1.3816e-04, -2.2650e-06, -2.9826e-04, -1.2338e-05, -8.9407e-07,\n",
            "        -2.8729e-05, -2.1148e-04, -3.4428e-03, -1.9547e-02, -1.9913e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05406424403190613 0.0025730133056640625 1.536569595336914 0.37745463848114014 99\n",
            "pred tensor([-2.6886e-02, -2.3270e-02, -2.1362e-02, -1.4439e-03, -5.4121e-04,\n",
            "        -2.6882e-05, -3.1799e-02, -1.0000e+00, -7.1406e-05, -7.9870e-06,\n",
            "        -3.4189e-04, -5.3072e-04, -7.9870e-06, -5.5933e-04, -1.3618e-03,\n",
            "        -2.9707e-04, -3.1590e-05, -4.0703e-03, -5.0232e-02, -3.6621e-04,\n",
            "        -8.6129e-05, -9.3877e-05, -1.0548e-03, -3.0398e-06, -8.5235e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0786752700805664 5.3882598876953125e-05 1.647179365158081 0.3309209644794464 56\n",
            "pred tensor([-1.5080e-05, -6.8235e-04, -1.0757e-02, -1.4925e-03, -3.0078e-01,\n",
            "        -8.9355e-01, -1.0000e+00, -9.7656e-01, -1.0000e+00, -7.0333e-06,\n",
            "        -6.5565e-07, -3.5763e-07, -1.6093e-06, -1.1194e-04, -1.6041e-03,\n",
            "        -9.6083e-05, -6.4254e-05, -7.0930e-06, -3.3927e-04, -8.2302e-04,\n",
            "        -2.3973e-04, -2.6932e-03, -2.9659e-04, -5.1260e-05, -1.6642e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05373296141624451 0.0002651214599609375 1.5680195093154907 0.35414761304855347 80\n",
            "pred tensor([-9.7266e-01, -3.0518e-03, -3.5000e-04, -9.1839e-04, -5.9605e-07,\n",
            "        -2.2054e-06, -1.6689e-06, -5.9605e-08, -6.3002e-05, -1.7881e-06,\n",
            "        -3.5107e-05, -7.8440e-05, -3.5942e-05, -6.6161e-06, -7.5161e-05,\n",
            "        -1.6093e-06, -4.1723e-07, -9.5367e-07, -2.3842e-07,  0.0000e+00,\n",
            "        -4.7684e-07, -7.2122e-06, -1.0000e+00, -8.3447e-07, -8.9407e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0814090296626091 0.00022554397583007812 1.5940628051757812 0.32979750633239746 46\n",
            "pred tensor([-1.1316e-01, -9.9463e-01, -9.9951e-01, -1.0000e+00, -2.5272e-05,\n",
            "        -3.1829e-05, -5.1260e-06, -1.5318e-05, -1.4305e-06, -2.6131e-04,\n",
            "        -1.1772e-04, -1.1950e-03, -1.0319e-03, -2.6474e-03, -1.1246e-02,\n",
            "        -8.2159e-04, -1.1021e-04, -1.8358e-05, -6.6757e-06, -2.4319e-05,\n",
            "        -1.3769e-04, -1.7738e-04, -7.3969e-05, -9.4235e-05, -4.8494e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.056091129779815674 0.0005173683166503906 1.5185080766677856 0.35453981161117554 73\n",
            "pred tensor([-3.4237e-03, -4.6372e-04, -2.1565e-04, -8.4817e-05, -2.3842e-06,\n",
            "        -2.9802e-07, -4.1723e-07,  0.0000e+00, -5.9605e-08, -1.1921e-07,\n",
            "        -7.7486e-07, -1.0729e-05, -1.0133e-06, -3.5763e-07,  0.0000e+00,\n",
            "        -4.7684e-07, -2.3842e-07, -3.5763e-07, -7.1526e-07, -5.9605e-08,\n",
            "        -1.3709e-06, -1.5149e-01, -1.0000e+00, -6.0797e-06, -2.9802e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08055851608514786 0.00286102294921875 1.4368255138397217 0.3249741494655609 38\n",
            "pred tensor([-9.4175e-06, -9.5010e-05, -4.1819e-04, -4.6539e-03, -1.8177e-03,\n",
            "        -6.6757e-06, -1.2338e-05, -2.0683e-05, -1.7107e-05, -5.8031e-04,\n",
            "        -1.4651e-04, -2.4438e-06, -3.5429e-04, -3.7506e-02, -1.2793e-01,\n",
            "        -8.5791e-01, -9.3079e-02, -1.1072e-03, -1.9116e-01, -3.1592e-01,\n",
            "        -9.6094e-01, -9.6338e-01, -1.2994e-05, -7.2241e-05, -8.6129e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05835823714733124 0.0032100677490234375 1.4619081020355225 0.3562858998775482 48\n",
            "pred tensor([-2.8133e-04, -2.1911e-04, -1.2517e-06,  0.0000e+00,  0.0000e+00,\n",
            "        -1.1772e-04, -1.0000e+00, -1.0000e+00, -2.9802e-07,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1921e-07, -2.8014e-06,\n",
            "        -5.9605e-07,  0.0000e+00,  0.0000e+00, -5.9605e-08, -1.7881e-07,\n",
            "         0.0000e+00, -6.5565e-07, -5.9605e-08, -1.9073e-06, -7.1526e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08607909083366394 0.0013294219970703125 1.5704435110092163 0.32204222679138184 26\n",
            "pred tensor([-8.3447e-07, -1.7226e-05, -3.7551e-06, -1.3828e-05, -2.4438e-06,\n",
            "        -2.1458e-05, -1.7881e-07,  0.0000e+00, -7.2122e-06, -1.7881e-07,\n",
            "        -3.6776e-05, -9.0599e-06, -1.4842e-05, -4.5300e-04, -3.9935e-05,\n",
            "        -2.2471e-05, -8.9407e-07, -4.9651e-05, -2.6822e-06, -9.5367e-06,\n",
            "        -6.6817e-05, -2.6169e-03, -5.8289e-02, -1.4982e-03, -2.2709e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05424709990620613 0.007228851318359375 1.3827605247497559 0.3593001365661621 30\n",
            "pred tensor([-5.3139e-03, -2.2110e-02, -9.9854e-01, -1.0000e+00, -1.0000e+00,\n",
            "        -1.7285e-06, -2.2054e-06, -2.2650e-06, -1.0133e-06, -2.5034e-06,\n",
            "        -6.8545e-06, -1.1921e-07, -2.2471e-05, -3.6359e-05, -2.3842e-07,\n",
            "        -5.4240e-06, -1.0133e-06, -5.3644e-06, -1.8716e-05, -1.3649e-05,\n",
            "        -1.7881e-07, -4.7684e-07, -2.0087e-05, -7.1526e-04, -2.8610e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08547025173902512 0.001804351806640625 1.471476435661316 0.3239312469959259 28\n",
            "pred tensor([-3.5167e-06, -5.1022e-04, -4.2877e-03, -1.5583e-03, -4.9133e-03,\n",
            "        -2.8729e-05, -5.8556e-03, -3.2318e-02, -2.5195e-01, -9.7942e-04,\n",
            "        -9.2804e-05, -3.9279e-05, -1.6093e-06, -1.5497e-06, -1.1921e-07,\n",
            "        -5.3644e-06, -1.0133e-06, -9.4175e-06, -3.3855e-05, -2.9588e-04,\n",
            "        -1.2195e-04, -1.1277e-04, -1.0192e-05, -5.5432e-05, -5.6744e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06025110185146332 0.0016040802001953125 1.4749484062194824 0.36369067430496216 45\n",
            "pred tensor([-3.0880e-03, -9.9854e-01, -1.0000e+00, -1.0000e+00, -4.9472e-05,\n",
            "        -1.1854e-03, -1.4424e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -1.8120e-05, -2.9802e-06, -1.7881e-06, -2.0993e-04, -8.1658e-06,\n",
            "        -1.4305e-06, -2.1458e-06, -8.1658e-06,  0.0000e+00, -5.9605e-08,\n",
            "        -5.9605e-08, -5.1856e-06, -5.6953e-03, -3.5763e-07, -2.0444e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08460960537195206 0.0009741783142089844 1.526789665222168 0.32178738713264465 27\n",
            "pred tensor([-1.3113e-06, -4.2915e-06, -7.5102e-04, -5.3644e-07, -2.6882e-05,\n",
            "        -2.9683e-05,  0.0000e+00, -4.8518e-05, -3.2759e-04, -1.1921e-06,\n",
            "        -1.8024e-04, -9.6989e-04, -1.9729e-05, -1.3709e-05, -1.1683e-04,\n",
            "        -4.0531e-06, -5.5408e-04, -2.3842e-07, -6.2048e-05, -1.0848e-05,\n",
            "        -1.1325e-06, -2.1279e-05, -1.3292e-05, -7.7486e-07, -3.6955e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05723703280091286 0.0007729530334472656 1.522040843963623 0.34396398067474365 43\n",
            "pred tensor([-1.7481e-03, -1.0765e-04, -1.6775e-03, -4.5598e-05, -7.1526e-07,\n",
            "         0.0000e+00, -4.4107e-06, -6.5660e-04, -5.6624e-06, -5.3644e-07,\n",
            "        -1.9670e-06, -2.9802e-07, -6.5565e-07, -1.0729e-06, -1.1325e-06,\n",
            "        -4.0829e-05, -2.2233e-05, -1.4305e-06, -2.7657e-05, -5.9605e-08,\n",
            "        -1.4246e-05, -8.9407e-07, -9.9023e-01, -1.0000e+00, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08603542298078537 0.0014410018920898438 1.4279873371124268 0.3392312824726105 40\n",
            "pred tensor([-1.0000e+00, -3.7611e-05, -2.5153e-05, -2.2054e-06, -4.9472e-06,\n",
            "        -2.9802e-07, -1.3709e-05, -8.3804e-05, -6.0701e-04, -3.4690e-05,\n",
            "        -6.4373e-06, -1.2755e-05, -1.3456e-03, -2.9802e-05, -5.1856e-05,\n",
            "        -9.8407e-05, -1.6689e-05, -9.9540e-06, -4.2319e-06, -7.0333e-06,\n",
            "        -7.2539e-05, -1.4038e-02, -8.1062e-06, -9.3520e-05, -5.9357e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06249643489718437 0.0006771087646484375 1.5066322088241577 0.3473683297634125 75\n",
            "pred tensor([-6.1989e-06, -1.4007e-05, -1.6093e-06, -2.4319e-05,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -1.6093e-06, -5.9605e-08, -5.9605e-07,\n",
            "        -5.9605e-07,  0.0000e+00, -3.5167e-06, -3.5763e-06, -2.2113e-05,\n",
            "        -1.5020e-05, -5.4836e-06, -1.3232e-05, -9.1732e-05, -2.2054e-05,\n",
            "        -1.5795e-05, -1.4901e-06, -6.1333e-05, -5.9664e-05, -5.9605e-08],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08121306449174881 0.0013141632080078125 1.4663652181625366 0.3302176296710968 51\n",
            "pred tensor([-1.0031e-04, -1.5588e-01, -3.8013e-01, -3.9520e-03, -4.0352e-05,\n",
            "        -7.0572e-05, -1.2147e-04, -2.4819e-04, -1.2112e-03, -7.1526e-04,\n",
            "        -2.8014e-06, -5.5432e-06, -3.7551e-04, -6.0501e-03, -1.5778e-02,\n",
            "        -1.1162e-02, -1.4270e-01, -2.3098e-03, -3.9744e-04, -5.9605e-06,\n",
            "        -2.1458e-06, -1.7309e-03, -8.9586e-05, -5.4777e-05, -2.7955e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0562843419611454 0.0012350082397460938 1.5257155895233154 0.34353095293045044 88\n",
            "pred tensor([-1.7071e-03, -1.7786e-03, -7.5188e-03, -1.1921e-07, -4.1127e-06,\n",
            "        -6.5565e-07, -8.9407e-07, -3.5763e-06, -1.4901e-06, -5.9605e-08,\n",
            "        -3.9935e-06, -4.8218e-02, -2.0206e-05, -3.0994e-06, -4.3988e-05,\n",
            "        -1.0967e-05, -4.7565e-05, -2.1744e-04, -7.0572e-04, -1.2004e-04,\n",
            "        -1.5917e-03, -7.2899e-03, -7.2656e-01, -5.0888e-03, -6.9531e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0823429748415947 0.0032253265380859375 1.433868646621704 0.3355628252029419 63\n",
            "pred tensor([-9.9902e-01, -1.0000e+00, -1.0000e+00, -3.8940e-02, -7.9651e-03,\n",
            "        -6.3896e-03, -2.3544e-05, -7.1168e-05, -2.0623e-05, -2.9802e-05,\n",
            "        -3.2759e-04, -1.4901e-06, -8.7619e-06, -6.1333e-05, -3.8147e-06,\n",
            "        -9.1267e-04, -2.7120e-05, -6.0380e-05, -2.9678e-02, -3.7611e-05,\n",
            "        -1.6034e-05, -2.8014e-06, -5.4836e-06, -2.1279e-05, -5.1022e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05106928572058678 0.005138397216796875 1.3500137329101562 0.34243935346603394 83\n",
            "pred tensor([-1.4830e-04, -1.2350e-03, -6.2286e-02, -1.7881e-07, -7.3314e-06,\n",
            "        -1.4305e-06, -6.5565e-07, -7.3910e-06, -8.5831e-06, -3.5644e-05,\n",
            "        -5.4121e-05, -5.9080e-04, -1.7130e-04, -3.3200e-05, -1.5495e-02,\n",
            "        -9.7754e-01, -1.0000e+00, -1.1528e-02, -4.2140e-05, -2.3246e-06,\n",
            "        -4.5896e-06, -1.1683e-04, -2.4185e-02, -2.4902e-01, -7.0020e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07613807171583176 0.002155303955078125 1.398986577987671 0.32916757464408875 54\n",
            "pred tensor([-4.3488e-04, -6.6284e-02, -1.4997e-04, -7.8738e-05, -3.2153e-01,\n",
            "        -5.5939e-02, -6.7825e-03, -1.8775e-05, -4.3225e-04, -3.5477e-04,\n",
            "        -2.4433e-03, -3.0100e-05, -1.5221e-03, -9.5010e-05, -1.4007e-05,\n",
            "        -3.0696e-05, -5.9605e-07, -2.6779e-03, -5.3883e-05, -1.4126e-05,\n",
            "        -1.4961e-05, -6.9141e-06, -4.9114e-05, -1.9717e-04, -5.3453e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05249948054552078 0.0009446144104003906 1.4325642585754395 0.34216493368148804 88\n",
            "pred tensor([-1.4114e-02, -7.7332e-02, -1.0269e-02, -6.5231e-04, -4.3154e-05,\n",
            "        -1.5056e-04, -2.3096e-01, -1.3983e-04, -1.0473e-04, -2.0385e-05,\n",
            "         0.0000e+00, -2.9802e-07, -1.7614e-03, -1.2934e-05, -9.8944e-06,\n",
            "        -2.3842e-07, -1.9760e-03, -5.1856e-06, -2.9469e-03, -2.3880e-03,\n",
            "        -5.0392e-03, -5.6190e-03, -1.1921e-07, -2.4438e-06, -8.5235e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07896925508975983 0.001056671142578125 1.546534538269043 0.33234286308288574 54\n",
            "pred tensor([-2.0660e-02, -4.9639e-04, -8.0948e-03, -1.0473e-04, -6.7711e-04,\n",
            "        -2.7418e-05, -4.0126e-04, -8.6129e-05, -6.4552e-05, -3.9434e-04,\n",
            "        -2.1911e-04, -4.2725e-03, -2.4681e-03, -1.0920e-03, -6.1417e-04,\n",
            "        -2.6631e-04, -2.1497e-01, -2.7733e-03, -2.0587e-04, -3.2759e-04,\n",
            "        -5.1308e-04, -6.9046e-04, -9.4366e-04, -2.3840e-01, -8.7118e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05450541526079178 0.0006775856018066406 1.4999877214431763 0.33910655975341797 81\n",
            "pred tensor([-2.7752e-04, -1.8382e-04, -1.0300e-03, -4.9324e-03, -6.1989e-06,\n",
            "        -1.1921e-07, -5.9605e-08, -1.0252e-05, -1.0729e-06, -1.3709e-04,\n",
            "        -2.3544e-05, -3.1352e-05, -6.1095e-05, -2.8849e-05, -3.5107e-05,\n",
            "        -2.1482e-04, -1.2827e-04, -6.7568e-04, -1.2457e-05, -1.2457e-05,\n",
            "        -2.8610e-05, -1.5140e-05, -1.0967e-03, -3.6359e-06, -2.8610e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08093128353357315 0.000308990478515625 1.6021034717559814 0.3405846357345581 48\n",
            "pred tensor([-1.6224e-04, -2.8610e-06, -5.9605e-08, -1.9670e-05, -1.8716e-05,\n",
            "        -9.4175e-06, -1.6809e-05, -1.1921e-05, -2.1219e-05, -7.9334e-05,\n",
            "        -2.0921e-05, -8.9943e-05, -9.2888e-04, -3.4261e-04, -2.2650e-05,\n",
            "        -3.7074e-05, -1.0073e-04, -6.8235e-04, -3.4070e-04, -2.0325e-05,\n",
            "        -9.1016e-05, -2.7173e-01, -1.0000e+00, -1.0000e+00, -1.0986e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05360865592956543 0.001155853271484375 1.4931823015213013 0.35855332016944885 78\n",
            "pred tensor([-9.7752e-06, -5.0426e-05, -2.2650e-05, -6.1989e-06, -1.7881e-07,\n",
            "         0.0000e+00,  0.0000e+00, -1.1921e-07, -3.0398e-06, -1.7881e-07,\n",
            "        -2.8849e-05, -3.5763e-07, -1.7881e-07,  0.0000e+00, -1.1921e-07,\n",
            "        -1.1921e-07, -1.1921e-07, -4.7684e-07, -5.9605e-08, -3.8743e-06,\n",
            "        -1.7285e-05, -2.7955e-05, -3.3808e-04, -4.7684e-07, -8.9407e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07653050124645233 0.0019102096557617188 1.4502179622650146 0.33668357133865356 35\n",
            "pred tensor([-2.8172e-03, -1.7881e-07, -3.6061e-05,  0.0000e+00, -3.4475e-04,\n",
            "        -4.7684e-07, -1.5497e-06, -4.2572e-02, -2.5558e-02, -9.9756e-01,\n",
            "        -1.8387e-03, -5.6305e-03, -1.7881e-06, -5.4240e-06, -2.4216e-02,\n",
            "        -1.0598e-04, -7.8392e-04, -5.0664e-06, -1.1146e-05, -1.0796e-03,\n",
            "        -1.2815e-05, -4.2558e-04, -1.3232e-05, -1.7881e-07, -2.1636e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05166430398821831 0.003498077392578125 1.404207468032837 0.3526459038257599 63\n",
            "13\n",
            "pred tensor([-3.8803e-05, -2.3484e-05, -5.0068e-06, -3.9935e-06, -1.2517e-06,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9605e-08, -1.2290e-04,\n",
            "        -4.4107e-06, -1.7881e-07, -2.6226e-06, -3.5763e-07, -3.5763e-07,\n",
            "        -5.3644e-07,  0.0000e+00, -1.4901e-06, -2.1756e-05, -9.4771e-06,\n",
            "        -3.1590e-06, -9.8348e-06, -3.1590e-05, -9.7990e-05, -4.6844e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07667581737041473 0.00574493408203125 1.3675416707992554 0.3462304472923279 29\n",
            "pred tensor([-9.5264e-01, -9.5801e-01, -9.9756e-01, -1.2040e-05, -1.6928e-04,\n",
            "        -4.5061e-05, -1.2338e-04, -1.9717e-04, -1.4553e-03, -9.8348e-06,\n",
            "        -3.9154e-02, -2.1191e-03, -3.8457e-04, -1.4544e-05, -1.1545e-04,\n",
            "        -2.0862e-06, -2.4438e-06, -1.4257e-04, -1.0729e-06, -8.9407e-07,\n",
            "        -3.9279e-05, -1.3351e-05, -1.6665e-04, -3.3081e-05, -3.9506e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04910365492105484 0.0012216567993164062 1.5283018350601196 0.35056573152542114 53\n",
            "pred tensor([-6.4993e-04, -1.5974e-03, -3.3703e-03, -4.7684e-06, -5.3644e-07,\n",
            "        -1.7881e-07, -1.1921e-07, -5.9605e-08, -5.2869e-05, -1.1921e-07,\n",
            "        -3.3379e-06, -6.5565e-07, -3.5763e-07, -5.9605e-08, -1.6689e-06,\n",
            "         0.0000e+00,  0.0000e+00, -2.7222e-02, -1.1206e-05, -1.6689e-06,\n",
            "        -2.5988e-05, -1.6534e-04, -8.2493e-04, -2.2829e-05, -1.5962e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07520109415054321 0.001750946044921875 1.5242525339126587 0.3575107157230377 43\n",
            "pred tensor([-1.9257e-02, -1.4770e-04, -1.2004e-04, -5.3465e-05, -4.6635e-04,\n",
            "        -9.0003e-06, -1.6689e-06, -3.2187e-06, -8.9943e-05, -1.0000e+00,\n",
            "        -5.9605e-08,  0.0000e+00,  0.0000e+00, -1.7881e-07, -1.4982e-03,\n",
            "        -1.1593e-04, -1.5354e-04, -5.4283e-03, -1.8179e-05, -1.9073e-05,\n",
            "        -2.4319e-05, -5.4240e-06, -9.2804e-05, -2.2926e-03, -1.0610e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04778451845049858 0.0009183883666992188 1.5338690280914307 0.3562071621417999 55\n",
            "pred tensor([-8.1100e-03, -3.0780e-04, -1.7881e-06, -5.7220e-06, -5.0426e-05,\n",
            "        -5.1193e-03, -1.0000e+00, -3.1590e-06,  0.0000e+00, -4.7684e-07,\n",
            "        -1.6391e-05, -4.7684e-07, -5.9605e-08, -8.9407e-07, -1.5497e-06,\n",
            "        -5.9605e-08, -5.3644e-07, -5.9605e-08, -1.1921e-07, -1.7822e-05,\n",
            "        -9.1648e-04, -5.4588e-03, -1.8311e-04, -9.4175e-06, -3.3736e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07033422589302063 0.0012140274047851562 1.5468670129776 0.32543063163757324 22\n",
            "pred tensor([-8.5235e-06, -7.2539e-05, -4.0233e-05, -1.1917e-02, -2.1228e-01,\n",
            "        -1.9763e-01, -2.0432e-02, -7.9736e-01, -9.6191e-01, -1.4185e-01,\n",
            "        -7.1411e-02, -1.0223e-03, -1.2337e-02, -2.2256e-04, -6.2048e-05,\n",
            "        -1.9159e-03, -3.3736e-05, -5.6624e-06, -4.4680e-04, -1.2354e-01,\n",
            "        -1.0806e-04, -6.8245e-03, -3.0212e-02, -9.3896e-01, -1.5640e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04853939265012741 0.0006661415100097656 1.49284029006958 0.33511796593666077 50\n",
            "pred tensor([-5.8365e-04, -1.6344e-04, -2.3508e-04, -1.1921e-07, -1.8477e-06,\n",
            "        -5.9605e-08, -2.5630e-06,  0.0000e+00, -5.3644e-07, -8.9586e-05,\n",
            "        -3.6499e-02, -4.9829e-04, -5.6267e-05, -1.9729e-05, -1.0729e-05,\n",
            "        -5.4836e-06, -5.2977e-04, -2.4399e-02, -9.1374e-05, -1.0862e-03,\n",
            "        -2.1744e-04, -2.9802e-06, -3.7720e-02, -2.1277e-01, -9.8145e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07118073105812073 0.0006718635559082031 1.5201340913772583 0.3247232735157013 26\n",
            "pred tensor([-9.9707e-01, -2.7657e-05, -5.1260e-06, -7.4043e-03, -1.7607e-04,\n",
            "        -1.2398e-05, -9.6560e-06, -3.0696e-05, -4.4346e-05, -1.9872e-04,\n",
            "        -6.1095e-05, -2.6684e-03, -7.1955e-04, -7.1955e-04, -1.3170e-03,\n",
            "        -3.0155e-03, -3.8940e-02, -7.0850e-01, -9.7559e-01, -2.7256e-03,\n",
            "        -2.8253e-04, -1.5414e-04, -5.8365e-04, -2.4433e-03, -1.2093e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.053947754204273224 0.003055572509765625 1.4046602249145508 0.3454238176345825 56\n",
            "pred tensor([-6.7444e-02, -2.0504e-04, -2.3270e-03, -9.0599e-06, -2.0993e-04,\n",
            "        -3.0339e-05, -2.3842e-07, -4.0352e-05, -9.9540e-06, -1.4901e-05,\n",
            "        -1.6332e-05, -7.0930e-06, -6.0201e-06, -5.0068e-06, -7.9346e-03,\n",
            "        -1.0192e-04, -1.2994e-05, -3.3975e-05, -4.6539e-03, -8.9990e-01,\n",
            "        -5.0011e-03, -1.1593e-04, -2.3687e-04, -2.5129e-04, -7.7343e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07598068565130234 0.0020694732666015625 1.3720836639404297 0.3256797194480896 41\n",
            "pred tensor([-1.1027e-05,  0.0000e+00, -3.4738e-04, -4.8339e-05, -5.6171e-04,\n",
            "        -3.9697e-01, -9.9561e-01, -1.0000e+00, -3.6564e-03, -4.2677e-05,\n",
            "        -4.1723e-07, -4.4942e-04, -1.2815e-05, -4.5300e-06, -7.0534e-03,\n",
            "        -5.3704e-05, -9.7156e-06, -9.5367e-07, -2.4378e-05, -3.0577e-05,\n",
            "        -1.2517e-05, -8.8811e-06, -1.4246e-05, -7.7546e-05, -4.2975e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04974734038114548 0.004268646240234375 1.3432815074920654 0.3436659574508667 62\n",
            "pred tensor([-2.2656e-01, -3.9053e-04, -1.9188e-03, -1.6034e-04, -1.7151e-01,\n",
            "        -2.2392e-03, -4.4584e-04, -5.8777e-02, -2.7686e-01, -2.8488e-02,\n",
            "        -7.3166e-03, -7.0648e-03, -5.7587e-02, -1.3380e-03, -3.4571e-06,\n",
            "        -1.4901e-06, -8.5115e-05, -5.9605e-08, -2.8014e-06, -3.9196e-04,\n",
            "        -1.0000e+00, -3.5763e-07,  0.0000e+00, -4.1723e-07, -5.3644e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07713723927736282 0.0011053085327148438 1.4427088499069214 0.3272869884967804 43\n",
            "pred tensor([-7.0333e-06, -9.9540e-06, -6.1393e-06, -1.2875e-05, -2.4438e-06,\n",
            "        -7.7546e-05, -6.3539e-05, -3.8910e-04, -3.3569e-03, -1.6737e-04,\n",
            "        -1.1692e-03, -2.4490e-03, -2.0623e-05, -3.0231e-04, -1.1206e-05,\n",
            "        -4.1187e-05, -2.7061e-04, -2.5129e-04, -1.7810e-04, -9.5367e-06,\n",
            "        -4.9734e-04, -2.0206e-05, -2.0111e-04, -2.0623e-05, -5.4283e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.053097523748874664 0.0010366439819335938 1.4865528345108032 0.3486153185367584 81\n",
            "pred tensor([-2.9135e-04, -1.1277e-04, -3.8700e-03, -3.6359e-06, -8.2254e-06,\n",
            "        -9.5367e-07, -8.4448e-04, -9.1457e-04, -1.2052e-04, -3.9291e-04,\n",
            "        -1.9608e-03, -3.3379e-06, -4.3335e-02, -7.1526e-04, -1.0691e-03,\n",
            "        -1.0000e+00, -1.0000e+00, -5.8055e-05, -1.2934e-05, -1.5676e-05,\n",
            "        -2.0683e-05, -1.2922e-03, -3.2187e-06, -3.8147e-04, -1.2481e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07021285593509674 0.0014743804931640625 1.368706464767456 0.3405914604663849 43\n",
            "pred tensor([ 0.0000e+00,  0.0000e+00, -1.1921e-07, -1.5335e-02, -5.3358e-04,\n",
            "        -6.8779e-03, -1.3173e-05, -3.8671e-04, -1.1902e-03, -1.5097e-03,\n",
            "        -2.8610e-06, -9.0599e-06, -2.3842e-06, -1.5430e-03, -9.9561e-01,\n",
            "        -2.1458e-06, -2.4438e-06, -3.6955e-06, -3.0575e-03, -1.8711e-03,\n",
            "        -9.3896e-01, -9.9561e-01, -1.0000e+00, -3.4738e-04, -4.7469e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06019699573516846 0.0018558502197265625 1.4820239543914795 0.35735103487968445 98\n",
            "pred tensor([-1.1272e-03, -9.0301e-05, -1.5497e-06, -3.5763e-07, -8.3447e-07,\n",
            "        -1.1921e-07, -2.6226e-06, -4.7684e-07, -5.8508e-04, -6.5804e-05,\n",
            "        -5.9605e-08, -1.3828e-05, -1.6212e-05, -7.1526e-07, -1.9073e-06,\n",
            "        -5.9605e-08, -1.3113e-06, -7.1168e-05, -7.2718e-06, -6.5029e-05,\n",
            "        -5.4836e-06, -1.4007e-05, -4.3511e-06, -8.7619e-06, -1.0042e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07556504011154175 0.0007948875427246094 1.4244714975357056 0.3315040171146393 55\n",
            "pred tensor([-6.9618e-04, -3.8385e-05, -2.9802e-07, -5.0664e-06, -3.9339e-06,\n",
            "        -7.4267e-05, -1.0185e-03, -2.9016e-04, -3.2723e-05, -3.4261e-04,\n",
            "        -1.5783e-04, -2.9206e-05, -2.5570e-05, -1.1635e-04, -3.2864e-03,\n",
            "        -3.5801e-03, -1.6034e-04, -1.1787e-03, -2.0294e-02, -8.5144e-03,\n",
            "        -5.1832e-04, -2.0087e-05, -1.5612e-03, -8.1062e-06, -1.1511e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.057043351233005524 0.0007023811340332031 1.44638991355896 0.33350449800491333 66\n",
            "pred tensor([-9.9316e-01, -4.2389e-02, -8.1863e-03, -5.9903e-05, -2.5034e-06,\n",
            "        -4.5419e-05, -5.0247e-05, -2.5725e-04, -5.9009e-06, -6.1572e-05,\n",
            "        -2.3508e-04, -1.1921e-07, -3.7861e-04, -2.2256e-04, -3.0994e-06,\n",
            "        -3.0458e-05, -3.8385e-05, -4.3511e-05, -3.3627e-03, -2.6464e-05,\n",
            "        -2.0111e-04, -2.1458e-06, -1.5843e-04, -2.3842e-06, -4.7684e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.069259874522686 0.004215240478515625 1.3473567962646484 0.32937684655189514 45\n",
            "pred tensor([-8.3804e-05, -2.5010e-04, -7.9334e-05, -7.4565e-05, -7.4506e-06,\n",
            "        -1.4317e-04, -1.9073e-05, -7.1526e-07, -1.8525e-04, -1.8454e-04,\n",
            "        -2.0337e-04, -5.5432e-05, -5.6744e-05, -2.4915e-04, -7.2813e-04,\n",
            "        -9.9277e-04, -2.6360e-03, -1.9882e-02, -1.5335e-02, -1.3456e-03,\n",
            "        -1.0506e-02, -6.1646e-02, -1.9944e-04, -1.0270e-04, -1.2481e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04588755965232849 0.0035400390625 1.352120280265808 0.33116278052330017 43\n",
            "pred tensor([-8.6523e-01, -2.2900e-01, -2.5094e-05,  0.0000e+00,  0.0000e+00,\n",
            "        -5.3644e-07, -1.3471e-05, -7.3528e-04, -1.6391e-05, -2.0421e-04,\n",
            "        -3.1590e-06, -1.7285e-06, -2.0909e-04, -4.9248e-03, -1.0000e+00,\n",
            "        -5.9605e-08,  0.0000e+00, -1.7881e-07, -2.1696e-05, -1.4901e-06,\n",
            "        -1.0118e-03, -9.7156e-06, -4.1723e-07, -4.0531e-06, -1.9038e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07385274022817612 0.0003643035888671875 1.5492169857025146 0.3273988366127014 43\n",
            "pred tensor([-1.1504e-04, -1.9252e-05, -1.9875e-03, -5.5432e-06, -2.5415e-04,\n",
            "        -8.1658e-06, -1.2169e-02, -1.2982e-04, -6.7890e-05, -1.2636e-04,\n",
            "        -1.1820e-04, -1.0651e-02, -2.6727e-04, -5.5145e-02, -1.8568e-03,\n",
            "        -9.1267e-04, -1.8775e-05, -8.3113e-04, -1.0133e-06, -7.2718e-06,\n",
            "        -1.4901e-06, -4.1008e-03, -3.7804e-03, -9.4366e-04, -1.0147e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.051613833755254745 0.000499725341796875 1.4979219436645508 0.34096309542655945 43\n",
            "pred tensor([-5.8545e-01, -9.2480e-01, -7.7002e-01, -7.2266e-02, -8.1738e-01,\n",
            "        -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3447e-07,\n",
            "        -5.9605e-08, -1.1921e-07, -6.7592e-05, -3.9935e-06, -7.9274e-06,\n",
            "        -8.0585e-05, -1.6928e-05, -1.1146e-05, -2.1935e-05, -1.3709e-06,\n",
            "        -2.3973e-04, -4.3058e-04, -2.5451e-05, -5.4836e-06, -9.3579e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07711666077375412 0.0007419586181640625 1.458673119544983 0.3362218141555786 53\n",
            "pred tensor([-3.6377e-02, -9.5010e-05, -2.4796e-02, -1.1683e-05, -3.3975e-06,\n",
            "        -8.5831e-06, -7.7486e-07, -3.6359e-05, -1.2887e-04, -3.0398e-06,\n",
            "        -1.1367e-04, -2.4438e-06, -2.0742e-04, -2.4140e-05, -1.1265e-05,\n",
            "        -1.7881e-06, -4.4942e-04, -1.2255e-03, -1.1139e-03, -1.8120e-05,\n",
            "        -1.3494e-04, -3.7074e-05, -1.5438e-05, -5.6922e-05, -9.5367e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0531357005238533 0.0012006759643554688 1.4095110893249512 0.34598851203918457 52\n",
            "pred tensor([-1.2219e-05, -1.8668e-04, -3.0994e-06, -1.0490e-05, -1.5497e-06,\n",
            "        -1.7881e-07, -1.2100e-05, -7.1526e-07, -4.1723e-07, -4.2319e-06,\n",
            "         0.0000e+00, -1.7881e-06, -1.9073e-05, -8.3447e-07, -2.3842e-07,\n",
            "        -8.0252e-04, -4.0054e-05, -7.1526e-07, -1.2982e-04, -6.5565e-07,\n",
            "         0.0000e+00, -5.4240e-06, -5.9605e-07, -2.3842e-07, -1.2457e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07406135648488998 0.006072998046875 1.3525333404541016 0.3580014407634735 29\n",
            "pred tensor([-2.0087e-05, -4.1962e-05, -9.1732e-05, -4.3511e-06, -1.9417e-03,\n",
            "        -1.7536e-04, -2.3544e-05, -4.8339e-05, -2.9445e-05, -1.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -5.9605e-08, -3.4571e-06, -1.2934e-05,\n",
            "        -2.8610e-06, -1.8060e-05, -1.7464e-04, -2.3592e-04, -2.9862e-05,\n",
            "        -1.0834e-03, -7.8011e-03, -4.7743e-05, -3.8147e-06, -1.0228e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0552813746035099 0.003143310546875 1.3485543727874756 0.3568647801876068 47\n",
            "pred tensor([-6.5136e-04, -3.6072e-02, -3.4273e-05, -1.7881e-06,  0.0000e+00,\n",
            "         0.0000e+00, -6.0501e-03, -4.1723e-07,  0.0000e+00, -1.1921e-07,\n",
            "         0.0000e+00, -8.3447e-07, -1.1921e-07, -5.0664e-06, -4.1723e-06,\n",
            "        -4.9472e-06, -1.1146e-04, -2.7008e-02, -5.4955e-05, -1.4365e-05,\n",
            "        -9.5367e-07, -2.9802e-07, -2.1911e-04, -5.3048e-05, -6.1707e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07498974353075027 0.0009465217590332031 1.4769401550292969 0.36748749017715454 31\n",
            "pred tensor([-2.0691e-01, -1.5732e-02, -1.5497e-05, -9.0659e-05, -2.8014e-06,\n",
            "        -3.7804e-03, -6.6042e-05, -9.5367e-05, -1.0729e-06, -2.7657e-05,\n",
            "        -3.6907e-04, -8.6427e-06, -2.6011e-04, -9.2188e-01, -6.6805e-04,\n",
            "        -1.9363e-02, -1.6093e-04, -1.8425e-03, -2.7344e-01, -3.5548e-04,\n",
            "        -2.9802e-07, -1.6606e-04, -4.0233e-05, -3.8743e-06, -1.2517e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05599473789334297 0.0005602836608886719 1.5348975658416748 0.36338067054748535 51\n",
            "pred tensor([-6.8963e-05, -5.0259e-04, -1.7166e-05, -2.3842e-07, -5.9605e-07,\n",
            "        -4.7088e-06, -4.5662e-03, -7.4506e-06, -2.9945e-04, -8.5473e-05,\n",
            "        -1.1921e-07, -7.9334e-05, -1.6689e-06, -1.6012e-03, -4.3831e-03,\n",
            "        -9.3985e-04, -1.9302e-03, -2.3663e-05, -9.0003e-06, -4.0352e-05,\n",
            "        -1.3170e-03, -1.5497e-06, -3.2306e-05, -7.7486e-07, -5.5432e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0752066969871521 0.00115966796875 1.4521251916885376 0.3282031714916229 44\n",
            "pred tensor([-2.9802e-06, -3.2187e-06, -1.6754e-02, -1.4811e-03, -1.2481e-04,\n",
            "        -1.0109e-04, -3.8505e-05, -2.5606e-04, -1.2577e-05, -2.1994e-04,\n",
            "        -1.1272e-03, -8.9359e-04, -9.6035e-04, -9.4748e-04, -1.7679e-04,\n",
            "        -4.4155e-04, -5.6922e-05, -1.4252e-02, -3.9749e-03, -7.4673e-04,\n",
            "        -2.3483e-02, -4.5738e-03, -1.4807e-01, -9.8828e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058201808482408524 0.0004487037658691406 1.5202564001083374 0.34712743759155273 58\n",
            "pred tensor([-4.5204e-03, -3.3379e-03, -2.2888e-05, -2.2590e-05,  0.0000e+00,\n",
            "        -1.8311e-04, -8.3447e-07, -6.1095e-05, -7.3969e-05, -6.5231e-04,\n",
            "        -1.6093e-06, -4.8876e-06, -1.0192e-05, -3.9756e-05, -1.8418e-05,\n",
            "        -1.7881e-07, -2.3842e-07, -3.5763e-07, -1.5974e-03, -1.5140e-05,\n",
            "        -2.1076e-04, -2.3842e-06, -6.5267e-05, -4.5240e-05, -1.1325e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07075976580381393 0.00159454345703125 1.4558637142181396 0.3241206109523773 31\n",
            "pred tensor([-1.7333e-04, -9.7156e-06, -1.0319e-03, -1.2941e-03, -6.2525e-05,\n",
            "        -4.0932e-03, -8.6844e-05, -1.1635e-04, -1.0004e-03, -4.9114e-05,\n",
            "        -1.2924e-02, -2.3460e-03, -5.0068e-06, -1.2100e-04, -1.4175e-02,\n",
            "        -4.7684e-07, -4.2319e-06, -9.3877e-05, -1.4901e-06, -1.7262e-04,\n",
            "        -1.1871e-02, -5.6624e-06, -8.3447e-07, -5.2834e-04, -1.8477e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05513811856508255 0.0022869110107421875 1.4575532674789429 0.3500359058380127 49\n",
            "pred tensor([-2.9411e-03, -1.4145e-02, -4.8041e-04, -6.2990e-04, -3.6955e-06,\n",
            "        -8.3447e-06, -2.4068e-04, -3.0589e-04, -1.5572e-02, -7.9346e-03,\n",
            "        -6.1810e-05, -9.0027e-03, -2.8849e-05, -5.2214e-04, -6.6042e-05,\n",
            "        -1.2064e-03, -5.0116e-04, -1.2207e-03, -2.8610e-06, -5.9605e-06,\n",
            "        -2.5122e-01, -3.9434e-04, -1.6999e-04, -3.2258e-04, -1.1963e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07610756903886795 0.004482269287109375 1.377496600151062 0.33486124873161316 42\n",
            "pred tensor([-9.8953e-03, -2.8253e-04, -3.3975e-06, -1.1325e-06, -2.3687e-04,\n",
            "        -1.2684e-04, -1.2636e-05,  0.0000e+00, -5.2691e-05, -1.1938e-01,\n",
            "        -8.3447e-07, -5.5838e-04, -1.4990e-01, -2.6286e-05,  0.0000e+00,\n",
            "         0.0000e+00, -7.9248e-01, -7.4267e-05, -7.6111e-02, -4.8737e-02,\n",
            "        -2.6059e-04, -1.5894e-01, -1.0000e+00, -4.1723e-07,  0.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05937811732292175 0.00217437744140625 1.399185299873352 0.35368508100509644 75\n",
            "pred tensor([-4.3559e-04, -6.6681e-03, -1.9407e-04, -4.6670e-05, -3.6955e-06,\n",
            "        -1.1921e-07, -3.9935e-05, -1.1325e-05, -8.1658e-06, -4.7684e-07,\n",
            "        -3.9053e-04, -1.8477e-05, -1.9670e-06, -5.5432e-06, -8.2254e-06,\n",
            "        -3.8330e-01, -3.1829e-05, -5.3644e-07, -5.9605e-08,  0.0000e+00,\n",
            "        -4.3511e-06, -4.7386e-05, -6.9737e-06, -1.3709e-06, -3.1471e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07695911079645157 0.0007257461547851562 1.4902085065841675 0.3279215693473816 49\n",
            "pred tensor([-3.8218e-04, -5.9605e-06, -7.5459e-05, -1.0193e-02, -2.8610e-06,\n",
            "        -8.5926e-04, -2.8014e-04, -3.3200e-05, -6.6340e-05, -1.0788e-05,\n",
            "        -1.1009e-02, -6.9046e-04, -1.6272e-05, -3.0339e-05, -3.2067e-04,\n",
            "        -3.1590e-06, -1.3340e-04, -8.0252e-04, -3.5000e-04, -3.2842e-05,\n",
            "        -1.1917e-02, -4.3154e-05, -2.0504e-03, -1.4830e-04, -3.6640e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0597359724342823 0.002044677734375 1.4257705211639404 0.35080164670944214 61\n",
            "pred tensor([-3.5864e-01, -8.7118e-04, -7.2510e-01, -3.7305e-01, -3.9062e-02,\n",
            "        -9.5642e-02, -9.6619e-02, -2.3878e-04, -6.2525e-05, -5.8413e-06,\n",
            "        -1.7285e-06, -4.7684e-07, -3.5763e-07, -1.7643e-05, -5.0068e-06,\n",
            "        -7.9012e-04, -5.9605e-08, -7.9274e-06, -1.0073e-05, -1.1325e-06,\n",
            "        -5.3644e-07, -4.7684e-07,  0.0000e+00, -2.0266e-06, -1.7881e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07711494714021683 0.0014238357543945312 1.456249713897705 0.327267050743103 43\n",
            "pred tensor([-2.9206e-06, -2.9206e-06, -4.7684e-07, -9.8348e-06, -2.0266e-06,\n",
            "        -1.0312e-05, -1.9670e-06, -2.9206e-06, -2.9802e-06, -1.5235e-04,\n",
            "        -3.7694e-04, -9.6130e-03, -4.3488e-04, -3.2597e-03, -1.0000e+00,\n",
            "        -5.9605e-07,  0.0000e+00, -5.3644e-07, -1.2994e-05, -2.1696e-05,\n",
            "        -2.2054e-06, -2.8610e-05, -1.1325e-05, -6.7353e-05, -1.4722e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05966982617974281 0.00023174285888671875 1.5544655323028564 0.36012619733810425 55\n",
            "pred tensor([-6.5267e-05, -5.3692e-04, -2.4343e-04, -1.2696e-05, -7.1096e-04,\n",
            "        -1.5843e-04, -2.4438e-06, -8.3804e-05, -3.1829e-05, -3.4571e-06,\n",
            "        -5.3644e-07, -1.7881e-07, -4.9472e-05,  0.0000e+00, -8.6427e-06,\n",
            "        -2.6584e-05, -2.6822e-05, -5.9605e-08, -4.7684e-07, -2.9802e-07,\n",
            "        -4.7028e-05, -2.3139e-04, -7.0572e-05, -1.2941e-03, -2.2650e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08064199984073639 0.0002636909484863281 1.6443545818328857 0.3316768705844879 43\n",
            "pred tensor([-9.4788e-02, -1.8063e-03, -1.6737e-04, -1.0973e-04, -7.2122e-06,\n",
            "        -5.2452e-06, -2.5749e-05, -1.2100e-05, -5.6267e-05, -3.7441e-03,\n",
            "        -9.9540e-05, -4.1008e-05, -4.2319e-06,  0.0000e+00, -1.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -1.1414e-04, -6.4373e-06, -2.3139e-04,\n",
            "        -4.7207e-05, -1.4842e-05, -2.9206e-05, -2.8849e-05, -1.5354e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.057535480707883835 0.0021800994873046875 1.3929896354675293 0.36107903718948364 35\n",
            "14\n",
            "pred tensor([-1.2016e-03, -2.5606e-04, -7.6294e-06, -7.2002e-05, -3.5763e-07,\n",
            "        -1.6689e-06, -2.0826e-04, -1.1325e-06, -2.4052e-03, -1.1921e-07,\n",
            "        -9.0003e-06, -1.1921e-06, -2.6727e-04, -1.5917e-03, -3.9816e-04,\n",
            "        -1.5080e-05, -5.9814e-03, -8.6486e-05, -2.3317e-04, -2.0623e-05,\n",
            "        -4.5896e-06, -1.0109e-04, -2.6846e-04, -2.8896e-03, -7.0810e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07444605976343155 0.0033721923828125 1.382047414779663 0.32782864570617676 34\n",
            "pred tensor([-9.8926e-01, -9.9951e-01, -1.0000e+00, -1.0431e-05, -2.2054e-06,\n",
            "        -6.4373e-06, -4.7028e-05, -4.0293e-04, -8.1241e-05, -9.0659e-05,\n",
            "        -5.0545e-04, -1.0228e-04, -1.1654e-03, -7.5459e-05, -1.7226e-05,\n",
            "        -1.5080e-05, -1.0777e-03, -2.5034e-06, -1.7881e-06, -2.1565e-04,\n",
            "        -1.4997e-04, -2.0266e-04, -4.9472e-05, -9.5367e-07, -2.5320e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058764874935150146 0.001560211181640625 1.4593713283538818 0.3703269064426422 47\n",
            "pred tensor([-2.2793e-03, -1.6406e-01, -1.8892e-03, -2.9206e-06, -8.3804e-05,\n",
            "        -9.9850e-04, -8.1348e-04, -1.9951e-03, -5.0888e-03, -8.3447e-07,\n",
            "        -5.9605e-06, -1.0312e-04, -9.8572e-03, -9.5844e-04, -1.4424e-05,\n",
            "        -3.3855e-05, -3.8803e-05, -9.3985e-04, -1.0567e-02, -1.2146e-02,\n",
            "        -1.9226e-03, -6.9031e-02, -1.1615e-01, -8.0908e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07504180073738098 0.00255584716796875 1.371067762374878 0.3260346055030823 37\n",
            "pred tensor([ 0.0000e+00, -5.9605e-08,  0.0000e+00, -3.6955e-06, -2.7704e-04,\n",
            "        -1.4305e-06, -9.1699e-01, -9.5367e-07, -5.9605e-08,  0.0000e+00,\n",
            "        -6.7353e-06,  0.0000e+00,  0.0000e+00, -1.9951e-03, -2.1744e-02,\n",
            "        -1.9789e-04, -5.8365e-04, -1.6212e-05,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -2.5320e-04, -1.0000e+00, -5.3644e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.055531661957502365 0.0008282661437988281 1.4776287078857422 0.3408232629299164 50\n",
            "pred tensor([-3.9978e-02, -6.6406e-01, -9.3311e-01, -9.1748e-01, -1.0000e+00,\n",
            "        -5.9605e-08, -2.2650e-06, -2.3842e-06, -4.2915e-06, -7.6294e-05,\n",
            "        -1.7285e-06, -9.6083e-05, -1.3888e-05, -3.4595e-04, -2.7156e-04,\n",
            "        -1.4467e-03, -9.6083e-05, -1.0147e-03, -8.5592e-04, -2.6703e-05,\n",
            "        -2.5768e-03, -1.2243e-04, -3.6407e-04, -1.6809e-05, -1.5793e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07942448556423187 0.0017604827880859375 1.4041399955749512 0.32944929599761963 52\n",
            "pred tensor([-7.9334e-05, -3.0696e-05, -1.2517e-06, -9.5367e-07, -9.9540e-06,\n",
            "        -9.1791e-06, -4.2796e-05, -3.2864e-03, -1.9287e-02, -1.1539e-03,\n",
            "        -2.7156e-04, -5.8899e-03, -6.4941e-02, -1.5344e-01, -1.0281e-03,\n",
            "        -3.5977e-04, -6.9141e-06, -3.2687e-04, -1.0014e-05, -6.6795e-03,\n",
            "        -2.5711e-03, -7.5912e-03, -3.4666e-04, -9.5215e-03, -4.0703e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.056815050542354584 0.0003542900085449219 1.4574652910232544 0.3409132957458496 68\n",
            "pred tensor([-4.8752e-03, -8.2493e-04, -3.4738e-04, -1.1921e-07, -2.9802e-07,\n",
            "        -5.9903e-05, -4.1723e-07, -3.5942e-05, -3.6597e-05, -4.3988e-04,\n",
            "        -5.9664e-05, -7.4506e-06, -3.1910e-03, -1.0973e-04, -2.1915e-03,\n",
            "        -6.2523e-03, -2.9984e-02, -2.2054e-05, -1.1325e-05, -4.7946e-04,\n",
            "        -1.9848e-05, -2.8849e-05, -6.5804e-05, -1.1223e-02, -6.7592e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07879509031772614 0.0004916191101074219 1.4801524877548218 0.3306349217891693 60\n",
            "pred tensor([-9.2983e-06, -3.0577e-05, -3.9673e-02, -7.0333e-05, -5.3711e-02,\n",
            "        -2.9206e-06, -1.6928e-04, -1.1623e-05, -1.0605e-03, -4.3333e-05,\n",
            "        -1.6284e-04, -5.8031e-04, -6.1798e-04, -7.4387e-04, -2.8589e-01,\n",
            "        -9.1095e-03, -1.7738e-04, -3.3436e-03, -9.2363e-04, -3.5691e-04,\n",
            "        -4.2076e-03, -2.5406e-03, -2.5415e-04, -2.9016e-04, -1.0229e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05526772513985634 0.00177764892578125 1.3776187896728516 0.3513263463973999 76\n",
            "pred tensor([-1.3983e-04, -6.7711e-04, -2.7704e-04, -3.6597e-05, -4.0531e-06,\n",
            "        -4.0779e-03, -5.3644e-06, -8.2779e-04, -1.1384e-05, -5.9605e-08,\n",
            "        -1.1606e-03, -1.7881e-07, -4.9448e-04, -3.4928e-05, -6.5565e-07,\n",
            "        -2.6226e-04, -5.3048e-06, -2.4438e-06, -1.6034e-05, -1.6224e-04,\n",
            "        -1.6093e-06, -1.6384e-03, -4.3631e-05, -1.2052e-04, -1.1146e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07786542922258377 0.003116607666015625 1.3597228527069092 0.3449743688106537 49\n",
            "pred tensor([-3.5942e-05, -4.7755e-04, -1.2159e-05, -3.6716e-03, -4.0710e-05,\n",
            "        -4.9543e-04, -3.3855e-04, -1.4467e-03, -4.2152e-04, -1.0723e-04,\n",
            "        -2.5162e-02, -3.3736e-04, -2.6941e-04, -3.8815e-04, -4.0054e-03,\n",
            "        -4.2892e-04, -5.0664e-06, -1.7941e-05, -4.7088e-06, -3.2187e-06,\n",
            "        -2.2526e-03, -3.3975e-06, -8.2493e-04, -3.5477e-04, -1.1353e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04925084859132767 0.003978729248046875 1.3437366485595703 0.39557141065597534 69\n",
            "pred tensor([-1.0000e+00, -1.0000e+00, -1.0000e+00, -6.5565e-07, -2.1458e-06,\n",
            "        -5.1022e-05, -6.0201e-06, -5.3644e-07, -1.6272e-05, -1.7285e-06,\n",
            "        -9.0003e-06, -2.3842e-07, -1.1206e-05, -1.1921e-07, -8.3447e-07,\n",
            "        -6.1560e-04, -3.5763e-07, -1.6093e-06, -2.9802e-07, -6.4790e-05,\n",
            "        -6.3181e-06, -2.4319e-05, -1.7607e-04, -2.3234e-04, -6.0501e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07556132972240448 0.0020694732666015625 1.4039045572280884 0.3253187835216522 38\n",
            "pred tensor([-5.3329e-03, -1.2634e-01, -9.5367e-07, -1.8954e-05, -1.0073e-04,\n",
            "        -5.4240e-06, -4.6730e-03, -1.4710e-04, -9.5844e-04, -1.4320e-02,\n",
            "        -9.9316e-01, -9.9951e-01, -5.5611e-05, -1.4007e-05, -2.4140e-05,\n",
            "        -1.1772e-04, -3.6693e-04, -1.0788e-05, -1.0890e-04, -1.4305e-05,\n",
            "        -6.9141e-06, -1.0729e-06, -7.3135e-05, -9.3579e-06, -3.6224e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05505691468715668 0.0016002655029296875 1.395028829574585 0.338643878698349 81\n",
            "pred tensor([-9.6338e-01, -8.4521e-01, -1.0651e-01, -3.1638e-04, -3.1414e-03,\n",
            "        -2.2888e-02, -1.0000e+00,  0.0000e+00,  0.0000e+00, -5.9605e-08,\n",
            "        -5.9605e-08, -8.7619e-06, -5.9605e-08, -5.9605e-08, -1.9717e-04,\n",
            "        -5.0926e-04, -8.4460e-05, -2.1696e-05, -3.1471e-05, -8.5402e-04,\n",
            "        -3.8319e-03, -4.0829e-05, -1.1482e-02, -3.6478e-05, -1.5783e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07742615789175034 0.00036525726318359375 1.488657832145691 0.32679903507232666 43\n",
            "pred tensor([-1.1635e-04, -2.7370e-04, -1.9133e-05, -2.0504e-03, -6.6042e-04,\n",
            "        -7.4959e-04, -1.0777e-03, -8.5473e-05, -7.9334e-05, -1.1194e-04,\n",
            "        -3.1710e-05, -8.2254e-06, -3.6359e-06, -1.1367e-04, -2.6894e-03,\n",
            "        -2.3878e-04, -1.8179e-05, -1.1938e-01, -2.5153e-05, -3.9673e-04,\n",
            "        -3.6120e-04, -2.5129e-04, -4.8685e-04, -2.5320e-04, -3.5977e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05584535375237465 0.0016765594482421875 1.3888664245605469 0.34223148226737976 76\n",
            "pred tensor([-1.2338e-04, -2.3413e-04, -8.4114e-04, -7.0333e-06, -5.9605e-08,\n",
            "        -1.7881e-07, -1.1921e-07,  0.0000e+00, -3.5763e-07, -7.0572e-05,\n",
            "        -5.9605e-08, -5.9605e-08,  0.0000e+00,  0.0000e+00, -2.9802e-06,\n",
            "        -4.1723e-07, -1.5497e-06, -5.9605e-08, -1.9670e-06, -4.9472e-06,\n",
            "        -1.8477e-06, -4.7684e-07, -3.5226e-05,  0.0000e+00, -2.9802e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07780332118272781 0.0003132820129394531 1.4934215545654297 0.32563889026641846 34\n",
            "pred tensor([-9.0933e-04, -1.4305e-06, -3.5167e-06, -4.7684e-07, -2.4529e-03,\n",
            "        -1.0000e+00, -1.0000e+00, -4.5896e-06, -3.6955e-06, -1.2481e-04,\n",
            "        -1.7941e-05, -3.7551e-06, -1.5764e-03, -6.7997e-04, -2.1315e-04,\n",
            "        -4.9072e-02, -4.1187e-05, -1.1398e-02, -3.0304e-02, -6.3777e-06,\n",
            "        -1.1325e-04, -6.1178e-04, -3.2544e-05, -1.5011e-03, -4.1275e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.057610467076301575 0.0003662109375 1.4875705242156982 0.3549749553203583 72\n",
            "pred tensor([-6.9201e-05, -2.0206e-05, -1.8239e-04, -8.3447e-07, -2.9802e-07,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1921e-07,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.5367e-07,\n",
            "        -1.5783e-04, -3.2187e-05, -5.8413e-06, -3.1376e-04, -6.4969e-06,\n",
            "        -5.9605e-08, -1.3232e-05, -4.5896e-06, -2.0921e-05, -4.4441e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07423416525125504 0.0032978057861328125 1.3741989135742188 0.32436269521713257 38\n",
            "pred tensor([-1.0000e+00, -1.0000e+00, -9.9951e-01, -1.0000e+00, -8.9943e-05,\n",
            "        -1.7881e-04, -2.9125e-03, -4.3333e-05, -6.1333e-05, -9.2089e-05,\n",
            "        -1.8525e-04, -3.6359e-06, -9.7632e-05, -3.5107e-05, -3.8087e-05,\n",
            "        -2.6011e-04, -4.5319e-02, -1.5855e-05, -1.0133e-06, -2.3234e-04,\n",
            "        -3.3760e-03, -3.6640e-03, -3.2978e-03, -1.8740e-04, -3.0441e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05150938406586647 0.0011491775512695312 1.4348005056381226 0.3860861361026764 72\n",
            "pred tensor([-1.0729e-06, -8.6129e-05, -2.1756e-05,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00, -7.4506e-06, -6.4373e-06, -2.6405e-05, -1.7285e-06,\n",
            "        -8.0287e-05, -3.0935e-05, -1.4305e-06, -1.4901e-05, -1.1325e-06,\n",
            "        -1.7822e-05, -1.4091e-04, -1.5414e-04, -1.6613e-03, -1.5855e-05,\n",
            "        -4.6492e-06, -8.4639e-06, -1.7738e-04, -5.5420e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07786350697278976 0.00095367431640625 1.4649338722229004 0.3408830165863037 50\n",
            "pred tensor([-1.0000e+00, -1.0000e+00, -4.7743e-05, -1.6510e-05, -3.4928e-05,\n",
            "        -2.7585e-04, -5.8603e-04, -6.2370e-04, -1.3227e-03, -9.6416e-04,\n",
            "        -3.9339e-06, -2.0206e-05, -3.4738e-04, -1.1456e-04, -4.7922e-05,\n",
            "        -2.8849e-05, -1.0312e-05, -1.4150e-04, -6.5267e-05, -1.3723e-03,\n",
            "        -2.5725e-04, -5.3883e-05, -5.3883e-05, -5.6267e-04, -6.1810e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04615049436688423 0.00417327880859375 1.3386285305023193 0.3392413258552551 62\n",
            "pred tensor([-1.3456e-03, -2.5620e-02, -2.1558e-01, -6.9499e-05, -9.5367e-07,\n",
            "        -5.9605e-08, -4.7028e-05, -1.6093e-06, -1.2338e-05, -3.7789e-05,\n",
            "        -8.4817e-05, -4.0531e-06, -1.2338e-04, -2.9802e-07, -5.8770e-05,\n",
            "        -5.9605e-08, -4.2319e-05, -2.8014e-06, -5.9605e-08, -5.1439e-05,\n",
            "        -1.4365e-05, -5.9319e-04, -1.3123e-03, -4.9114e-05, -1.4603e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07610864192247391 0.002399444580078125 1.3189406394958496 0.33211055397987366 40\n",
            "pred tensor([-1.0281e-03, -6.4850e-04, -9.0301e-05, -8.3008e-02, -1.7607e-04,\n",
            "        -8.4000e-03, -4.9114e-05, -1.1861e-05, -1.0900e-03, -1.0848e-04,\n",
            "        -4.5471e-02, -5.4538e-05, -5.5359e-02, -2.8133e-04, -6.4611e-04,\n",
            "        -2.4343e-04, -3.4237e-03, -8.8215e-06, -1.4770e-04, -9.5367e-07,\n",
            "        -1.9569e-03, -6.9141e-06, -3.5187e-02, -3.9577e-05, -3.4511e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05105477198958397 0.0008301734924316406 1.4560692310333252 0.35097581148147583 88\n",
            "pred tensor([-9.2888e-04, -1.5488e-02, -5.4777e-05, -1.6689e-06, -3.5763e-07,\n",
            "        -4.7684e-07, -3.8743e-06, -2.8725e-03, -2.3305e-05, -3.2783e-06,\n",
            "        -1.6689e-06, -9.7632e-05, -1.5808e-02, -2.5436e-02, -1.0548e-03,\n",
            "        -6.1188e-02, -6.1371e-02, -3.3051e-02, -2.1517e-05, -4.7028e-05,\n",
            "        -1.2934e-05, -7.3910e-06, -1.2695e-02, -6.8545e-06, -1.1921e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06730084121227264 0.00287628173828125 1.3272277116775513 0.3327336311340332 27\n",
            "pred tensor([-2.2831e-03, -1.4710e-04, -2.0444e-05, -4.1008e-04, -1.1504e-05,\n",
            "        -4.7684e-07, -4.7684e-06, -4.6372e-04, -7.2002e-05, -6.8808e-04,\n",
            "        -5.8413e-06, -4.8399e-04, -3.2723e-05, -2.7239e-05, -2.1248e-03,\n",
            "        -2.1076e-04, -3.5477e-04, -6.7825e-03, -7.0000e-04, -2.9583e-03,\n",
            "        -1.9872e-04, -2.4819e-04, -2.2519e-04, -5.6624e-06, -7.0667e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04793372005224228 0.0015087127685546875 1.3924541473388672 0.34932631254196167 75\n",
            "pred tensor([-8.6594e-03, -3.8700e-03, -3.3402e-04, -1.1545e-04, -9.8944e-06,\n",
            "        -2.9802e-07, -2.1338e-05, -1.5039e-03, -5.5615e-01, -1.0000e+00,\n",
            "        -1.7285e-05, -2.8551e-05, -1.1921e-07, -1.1086e-05, -8.8215e-06,\n",
            "        -1.2100e-05, -4.8027e-03, -1.1504e-05, -9.2387e-06, -1.5557e-05,\n",
            "        -5.4817e-03, -1.1053e-03, -2.2292e-05, -4.5466e-04, -1.1835e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06865772604942322 0.0004458427429199219 1.4701483249664307 0.3276974856853485 51\n",
            "pred tensor([-9.7656e-03, -7.0557e-02, -4.0829e-05, -4.7946e-04, -1.0848e-05,\n",
            "        -3.5114e-03, -2.5063e-03, -2.1572e-03, -1.4782e-05, -1.8883e-04,\n",
            "        -9.9716e-03, -1.2569e-03, -5.1117e-04, -3.4695e-03, -4.5204e-03,\n",
            "        -4.3654e-04, -8.8196e-02, -7.7629e-04, -4.3058e-04, -1.1504e-04,\n",
            "        -8.4000e-03, -1.2112e-03, -1.3561e-03, -1.4313e-02, -5.9175e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04673076048493385 0.00037670135498046875 1.5090785026550293 0.3768825829029083 85\n",
            "pred tensor([-4.9057e-03, -1.2331e-03, -5.4741e-04,  0.0000e+00,  0.0000e+00,\n",
            "        -1.7881e-07, -2.9802e-07, -5.9605e-08,  0.0000e+00, -1.1921e-07,\n",
            "        -5.9605e-08, -6.5029e-05, -1.4901e-06, -2.9802e-07, -1.7881e-07,\n",
            "        -4.2915e-06, -1.5497e-06, -8.7976e-04, -4.3559e-04, -1.6868e-04,\n",
            "        -8.6844e-05, -3.6597e-05, -2.4498e-05, -4.8399e-04, -3.9279e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06869057565927505 0.001232147216796875 1.4582674503326416 0.32628101110458374 44\n",
            "pred tensor([-1.1883e-03, -7.2718e-06, -1.9264e-04, -4.8518e-05, -6.1560e-04,\n",
            "        -2.1076e-04, -1.7309e-03, -6.5756e-04, -1.1854e-03, -2.1610e-03,\n",
            "        -5.1193e-03, -7.9036e-05, -3.0184e-04, -5.2035e-05, -8.7857e-05,\n",
            "        -4.5824e-04, -9.1374e-05, -7.5459e-05, -5.0449e-04, -5.6362e-04,\n",
            "        -2.3413e-04, -2.1279e-05, -1.7226e-05, -2.1219e-05, -1.0004e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04526690021157265 0.005031585693359375 1.2893954515457153 0.34651297330856323 101\n",
            "pred tensor([-6.6650e-02, -1.5076e-02, -1.3977e-01, -4.1046e-02, -2.9802e-07,\n",
            "        -7.8278e-03, -4.3488e-03, -3.5038e-03, -2.2095e-02, -2.3234e-04,\n",
            "        -9.3799e-01, -8.1396e-01, -8.3771e-03, -1.3709e-04, -2.9802e-06,\n",
            "        -1.0133e-06, -9.9540e-06, -1.2934e-05, -3.2306e-04, -1.0000e+00,\n",
            "        -2.3842e-07, -4.7684e-07, -3.5763e-07, -4.3511e-06, -2.2590e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06721917539834976 0.002597808837890625 1.3673944473266602 0.3487755358219147 66\n",
            "pred tensor([-5.7638e-05, -4.2725e-03, -2.8729e-05, -6.8521e-04, -3.9983e-04,\n",
            "        -2.5616e-03, -2.2186e-02, -5.4199e-02, -2.0027e-03, -3.1805e-04,\n",
            "        -2.2340e-04, -5.7161e-05, -5.7125e-04, -2.7120e-05, -5.9652e-04,\n",
            "        -2.3592e-04, -7.7772e-04, -1.1093e-02, -2.3484e-05, -9.5010e-05,\n",
            "        -1.0405e-03, -6.3372e-04, -3.3855e-04, -3.0460e-03, -2.3422e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0445743165910244 0.0016050338745117188 1.4264451265335083 0.343504935503006 95\n",
            "pred tensor([-1.0192e-04, -9.3651e-04, -6.2752e-04, -5.9664e-05, -2.3842e-07,\n",
            "        -7.1526e-07, -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00, -2.6822e-06, -9.7266e-01, -4.4107e-06, -3.5167e-06,\n",
            "        -8.9586e-05, -5.4836e-06, -1.7285e-06, -1.3664e-02, -1.4067e-05,\n",
            "        -4.7565e-04, -2.7418e-06, -1.2577e-05, -8.7142e-05, -6.6578e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06908363103866577 0.0005464553833007812 1.438043475151062 0.32222679257392883 27\n",
            "pred tensor([-1.0490e-02, -8.0287e-05, -4.3518e-02, -1.2842e-01, -4.1870e-01,\n",
            "        -3.4448e-01, -5.1003e-03, -7.0286e-04, -2.3689e-03, -5.0323e-02,\n",
            "        -7.7441e-01, -3.1647e-02, -1.8143e-02, -4.3411e-03, -9.3877e-05,\n",
            "        -2.0428e-03, -4.7266e-01, -1.2291e-02, -9.0137e-01, -1.7614e-03,\n",
            "        -1.5354e-04, -1.1951e-01, -3.6621e-04, -1.7130e-04, -4.3221e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04436088353395462 0.000946044921875 1.4498419761657715 0.35716140270233154 93\n",
            "pred tensor([-2.9932e-01, -3.8989e-01, -6.1095e-05, -4.9472e-06,  0.0000e+00,\n",
            "         0.0000e+00, -5.9605e-08,  0.0000e+00,  0.0000e+00, -2.8014e-06,\n",
            "         0.0000e+00, -1.3113e-06, -3.3760e-03, -5.7817e-05, -7.5102e-06,\n",
            "        -4.6313e-05, -3.3379e-06, -4.1008e-05, -1.7881e-06, -1.1146e-05,\n",
            "        -4.7684e-07, -6.0201e-06, -3.5226e-05, -6.9475e-04, -1.2577e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07511327415704727 0.001697540283203125 1.4348516464233398 0.32245275378227234 27\n",
            "pred tensor([-2.9683e-05, -1.4591e-04, -1.5438e-05, -5.4538e-05, -2.3186e-05,\n",
            "        -6.2048e-05, -4.0375e-02, -2.6264e-03, -3.7537e-02, -2.0027e-04,\n",
            "        -1.1559e-03, -1.8883e-04, -4.9651e-05, -4.2796e-05, -1.1223e-02,\n",
            "        -1.1169e-01, -4.9530e-02, -9.9951e-01, -1.0000e+00, -1.0000e+00,\n",
            "        -1.0000e+00, -6.7711e-04, -7.4219e-02, -9.9707e-01, -9.7803e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04769959673285484 0.0017328262329101562 1.424870491027832 0.36364415287971497 82\n",
            "pred tensor([-1.5160e-02, -1.2993e-02, -9.1124e-04,  0.0000e+00,  0.0000e+00,\n",
            "        -9.5367e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7684e-07,\n",
            "        -1.9073e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9605e-08,\n",
            "         0.0000e+00, -3.5763e-07, -1.1921e-07, -1.5318e-05, -1.9670e-06,\n",
            "        -5.9605e-08, -1.1921e-07, -5.9605e-08, -1.1921e-07, -9.6858e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.08283187448978424 0.0030307769775390625 1.4311609268188477 0.3746302127838135 22\n",
            "pred tensor([-1.3489e-01, -6.2180e-03, -2.0683e-05, -1.1563e-05, -1.1194e-04,\n",
            "        -9.7156e-06, -6.2275e-04, -9.9540e-06, -2.2087e-03, -1.9372e-05,\n",
            "        -2.2256e-04, -2.5749e-05, -1.4296e-03, -8.8215e-05, -1.9038e-04,\n",
            "        -2.1148e-04, -2.9087e-05, -3.0100e-05, -2.7919e-04, -5.9175e-04,\n",
            "        -2.0921e-05, -2.0542e-03, -1.0389e-04, -1.1482e-02, -3.7903e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05251895636320114 0.0018749237060546875 1.4436036348342896 0.36135053634643555 82\n",
            "pred tensor([-1.3602e-04, -3.4475e-04, -8.7619e-06, -1.1921e-07,  0.0000e+00,\n",
            "        -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00, -6.5565e-07, -5.9605e-08, -5.9605e-07, -4.7684e-07,\n",
            "         0.0000e+00, -4.7684e-06, -1.1504e-05, -3.2187e-06, -8.9407e-07,\n",
            "        -5.9605e-08, -9.5367e-07, -3.0339e-05, -1.6861e-02, -1.1757e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.07301905751228333 0.001102447509765625 1.465720772743225 0.3379024267196655 21\n",
            "pred tensor([-9.3579e-06, -1.9133e-05, -1.1721e-03, -9.3579e-06, -9.4593e-05,\n",
            "        -6.2764e-05, -1.9336e-04, -5.0426e-05, -1.0605e-03, -4.4084e-04,\n",
            "        -3.5515e-03, -1.6284e-04, -1.8206e-03, -9.6560e-06, -1.8418e-05,\n",
            "        -7.4387e-04, -1.3947e-05, -1.7822e-05, -1.0735e-02, -1.0973e-04,\n",
            "        -9.1982e-04, -6.0844e-04, -9.8515e-04, -6.4331e-02, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.046728309243917465 0.000484466552734375 1.4878664016723633 0.346576452255249 86\n",
            "15\n",
            "pred tensor([-1.1047e-02, -5.9080e-04, -1.5664e-04,  0.0000e+00, -6.1393e-06,\n",
            "        -1.4007e-05, -2.2054e-06, -4.7088e-06, -7.7486e-07, -3.4332e-04,\n",
            "        -5.6791e-04, -1.1146e-05, -3.7193e-05, -6.1989e-06, -4.8280e-06,\n",
            "        -2.2054e-06, -1.2779e-04, -4.6492e-06, -1.4091e-04, -3.9053e-04,\n",
            "        -2.5129e-04, -2.8849e-05, -2.4536e-02, -9.9854e-01, -9.9951e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0725468322634697 0.0005764961242675781 1.4588910341262817 0.3384501039981842 39\n",
            "pred tensor([-9.9951e-01, -1.0000e+00, -1.0000e+00, -1.3943e-03, -5.8603e-04,\n",
            "        -4.8518e-05, -8.2850e-05, -3.1352e-05, -9.5010e-05, -9.9850e-04,\n",
            "        -7.0810e-04, -1.2474e-03, -3.7932e-04, -1.1206e-03, -2.6531e-03,\n",
            "        -2.6169e-03, -4.6196e-03, -8.3160e-03, -2.5406e-03, -1.4755e-02,\n",
            "        -4.1008e-03, -2.1148e-04, -5.3635e-03, -1.1406e-03, -7.5674e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04267812520265579 0.0021686553955078125 1.4356611967086792 0.339184045791626 80\n",
            "pred tensor([-3.2878e-04, -5.7182e-03, -4.2496e-03, -6.1333e-05, -1.3709e-05,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -4.3511e-06, -1.2947e-02, -1.0000e+00, -3.7611e-05, -5.3644e-07,\n",
            "        -1.0389e-04, -5.0449e-04, -4.7684e-07, -5.9605e-07, -4.1723e-07,\n",
            "        -5.9605e-07, -4.1723e-07, -5.9605e-07, -6.3777e-06, -8.3447e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06867785006761551 0.0039215087890625 1.3529064655303955 0.34094154834747314 41\n",
            "pred tensor([-1.1921e-07, -1.5557e-05, -2.8610e-06, -3.0937e-03, -2.4498e-05,\n",
            "        -4.5061e-05, -5.8949e-05, -5.9903e-05, -4.9543e-04, -1.2982e-04,\n",
            "        -2.7919e-04, -9.7656e-03, -1.0723e-04, -2.5511e-04, -2.5094e-05,\n",
            "        -6.9332e-04, -1.4544e-05, -9.3162e-05, -1.8749e-03, -2.6226e-04,\n",
            "        -1.5295e-04, -3.3855e-04, -2.0266e-04, -2.0981e-02, -3.1590e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.049015503376722336 0.0009641647338867188 1.4706246852874756 0.35793235898017883 100\n",
            "pred tensor([-2.3987e-02, -2.3270e-03, -1.3943e-03, -2.8300e-04, -2.4815e-03,\n",
            "        -1.2338e-05, -5.9605e-08, -1.7285e-06, -1.7881e-07, -1.1325e-06,\n",
            "        -8.9407e-07, -3.0696e-05, -1.2573e-02, -1.6868e-04, -6.4969e-06,\n",
            "        -7.1526e-06, -3.5763e-06, -1.2550e-03, -6.9160e-03, -2.0444e-05,\n",
            "        -2.2602e-04, -3.2425e-05, -7.9155e-04, -9.7990e-05, -3.3436e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06421918421983719 0.0027751922607421875 1.4234223365783691 0.34488168358802795 46\n",
            "pred tensor([-8.5258e-04, -2.3365e-03, -1.9684e-03, -6.1670e-01, -9.9951e-01,\n",
            "        -1.0000e+00, -3.2425e-05, -3.0994e-06, -3.8743e-06, -2.9802e-07,\n",
            "        -5.1618e-05, -1.8167e-04, -2.4557e-05, -1.3409e-03, -9.2089e-05,\n",
            "        -8.4460e-05, -2.8563e-04, -1.0509e-03, -5.5237e-03, -1.2481e-04,\n",
            "        -1.0672e-03, -3.8362e-04, -4.6277e-04, -5.6934e-04, -3.1590e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04543476551771164 0.0009713172912597656 1.438051700592041 0.34640711545944214 78\n",
            "pred tensor([-2.7704e-04, -1.5764e-03, -2.2471e-05, -7.8735e-03, -9.9182e-05,\n",
            "        -1.2398e-05, -7.7486e-07, -2.3842e-06, -1.8477e-05, -2.6131e-04,\n",
            "        -2.3246e-06, -9.7156e-06, -8.7619e-06, -5.8532e-05, -8.0872e-04,\n",
            "        -1.6510e-05, -3.9577e-05, -9.9957e-05, -2.9683e-05, -2.1439e-03,\n",
            "        -2.8133e-04, -5.2124e-02, -2.2526e-03, -2.8348e-04, -1.7481e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06169235706329346 0.0012979507446289062 1.4540901184082031 0.32993385195732117 44\n",
            "pred tensor([-1.2550e-02, -6.6948e-04, -1.4997e-04, -1.1367e-04, -1.9491e-04,\n",
            "        -3.4273e-05, -1.0312e-04, -5.9605e-07, -3.3200e-05, -2.0182e-04,\n",
            "        -1.6475e-04, -3.8319e-03, -6.5002e-03, -2.5725e-04, -8.7452e-04,\n",
            "        -1.3816e-04, -3.2067e-05, -1.7583e-05, -1.1027e-05, -4.4703e-05,\n",
            "        -3.0899e-04, -3.1495e-04, -2.0742e-04, -1.3046e-03, -2.9254e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04842729493975639 0.0007648468017578125 1.4523677825927734 0.3531806170940399 100\n",
            "pred tensor([-8.2636e-04, -1.8854e-03, -5.1260e-05, -1.3709e-06, -5.9605e-08,\n",
            "        -5.9605e-08, -1.1444e-05,  0.0000e+00, -2.8014e-06, -5.9605e-08,\n",
            "        -6.3300e-05, -7.3314e-06, -3.3665e-04, -1.0908e-05, -1.5497e-06,\n",
            "        -3.3319e-05, -7.4565e-05, -9.4175e-06, -5.4359e-05, -7.8583e-03,\n",
            "        -9.6035e-04, -4.3893e-04, -3.6407e-04, -1.0004e-03, -1.6356e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06553354859352112 0.0010967254638671875 1.3895398378372192 0.32891377806663513 54\n",
            "pred tensor([-5.7793e-04, -3.3736e-05, -2.4719e-03, -1.4937e-04, -1.8749e-03,\n",
            "        -2.5916e-04, -1.0567e-03, -9.8730e-01, -1.0000e+00, -1.0000e+00,\n",
            "        -4.4107e-06, -5.3048e-06, -1.8537e-05, -3.0577e-05, -2.0266e-06,\n",
            "        -7.8738e-05, -4.8161e-05, -8.2850e-05, -8.2195e-05, -1.7681e-03,\n",
            "        -7.9489e-04, -5.3864e-03, -1.1820e-04, -2.3842e-06, -5.8770e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0477299690246582 0.00391387939453125 1.2885375022888184 0.3446039855480194 96\n",
            "pred tensor([-1.4296e-03, -4.3297e-03, -1.5545e-03, -1.1774e-01, -1.7881e-07,\n",
            "        -5.7399e-05, -4.7684e-06, -4.7684e-07, -1.3113e-06, -5.9605e-08,\n",
            "        -4.2915e-06, -1.9670e-06, -5.9605e-07, -1.7881e-07, -2.3842e-07,\n",
            "        -1.3275e-03, -2.5630e-06, -1.9073e-06, -1.5917e-03, -1.1194e-01,\n",
            "        -2.4796e-05, -1.2827e-04, -2.3007e-05, -1.7881e-06, -1.1384e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0655718445777893 0.002552032470703125 1.4163455963134766 0.32558465003967285 33\n",
            "pred tensor([-9.2236e-01, -6.1226e-03, -8.0872e-04, -5.8899e-03, -7.3471e-03,\n",
            "        -9.7705e-01, -9.9951e-01, -1.0000e+00, -9.9902e-01, -1.0000e+00,\n",
            "        -1.0000e+00, -2.3127e-05, -1.6224e-04, -1.9038e-04, -6.6414e-03,\n",
            "        -3.7551e-04, -2.0428e-03, -8.3303e-04, -2.6360e-03, -1.6153e-04,\n",
            "        -1.2589e-04, -6.9141e-06, -7.8738e-05, -4.3488e-03, -8.0729e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04779167100787163 0.003643035888671875 1.3843281269073486 0.3378905653953552 70\n",
            "pred tensor([-2.0993e-04, -3.3112e-03, -1.1027e-05,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0252e-05, -1.3199e-03,\n",
            "        -1.8537e-05, -2.4438e-06, -1.9562e-04, -1.1921e-06, -1.5843e-04,\n",
            "        -8.0287e-05, -2.2519e-04, -6.0618e-05, -8.4000e-03, -1.3990e-03,\n",
            "        -2.5690e-05, -4.2975e-05, -2.3878e-04, -6.7949e-06, -2.6822e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06544987857341766 0.0018291473388671875 1.3790364265441895 0.32726097106933594 35\n",
            "pred tensor([-5.3465e-05, -7.7486e-07, -2.0564e-05, -3.5107e-05, -5.9605e-08,\n",
            "         0.0000e+00,  0.0000e+00, -5.9605e-08,  0.0000e+00, -4.3225e-04,\n",
            "        -1.0000e+00,  0.0000e+00, -5.9605e-08, -4.1723e-06, -4.7684e-07,\n",
            "        -6.5565e-07, -9.0599e-06, -3.5107e-05, -4.3333e-05, -6.3610e-04,\n",
            "        -7.7486e-07, -2.9802e-07, -7.3314e-06, -2.7418e-06, -5.9605e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04120927304029465 0.0040283203125 1.3449156284332275 0.35067111253738403 47\n",
            "pred tensor([-1.6391e-05, -1.3554e-04, -5.9605e-08,  0.0000e+00, -1.2732e-04,\n",
            "        -1.5497e-06, -1.9073e-06, -4.7684e-07, -1.7345e-05, -2.9206e-06,\n",
            "        -1.7881e-07, -2.3842e-07, -4.1723e-07, -3.7122e-04, -8.3252e-01,\n",
            "        -1.0000e+00, -1.5438e-05, -1.7881e-07, -2.9802e-07,  0.0000e+00,\n",
            "        -1.6093e-06, -1.0133e-06, -9.5367e-07,  0.0000e+00, -5.9605e-07],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0673869326710701 0.0006208419799804688 1.4964723587036133 0.354308158159256 30\n",
            "pred tensor([-8.3069e-02, -1.2215e-02, -9.8896e-04, -4.2462e-04, -4.4250e-03,\n",
            "        -3.1109e-03, -1.1307e-02, -2.0065e-03, -6.3753e-04, -4.7028e-05,\n",
            "        -3.2306e-05, -1.6190e-02, -4.2572e-03, -2.9834e-01, -1.9264e-03,\n",
            "        -1.0223e-03, -3.2482e-03, -5.8174e-04, -1.2386e-04, -4.6492e-05,\n",
            "        -5.6922e-05, -5.6624e-06, -9.5367e-05, -1.7059e-04, -2.0862e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04613630101084709 0.00023937225341796875 1.5208282470703125 0.3388785123825073 68\n",
            "pred tensor([-1.4198e-04, -2.2256e-04, -5.4240e-06, -5.9605e-08, -5.9605e-08,\n",
            "        -5.9605e-08, -1.1921e-07, -1.7881e-07, -1.1921e-07, -5.9605e-08,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1921e-07, -6.5565e-07,\n",
            "        -1.9073e-06, -8.9407e-07, -5.9605e-08, -1.3709e-06, -5.9605e-08,\n",
            "        -5.9605e-08, -2.1696e-05, -4.6313e-05, -9.2447e-05, -8.4305e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06867379695177078 0.0005621910095214844 1.4423203468322754 0.3567199409008026 23\n",
            "pred tensor([-2.2829e-05, -3.0100e-05, -1.9670e-06, -1.6475e-04, -1.7166e-05,\n",
            "        -1.4257e-04, -7.6294e-05, -6.6772e-02, -7.1704e-05, -4.6492e-06,\n",
            "        -3.4153e-05, -1.4651e-04, -1.6510e-05, -1.3709e-05, -4.7088e-06,\n",
            "        -1.0710e-03, -1.9944e-04, -3.2187e-04, -7.1526e-07, -1.1158e-03,\n",
            "        -2.6703e-05, -1.3924e-04, -9.4938e-04, -1.4746e-01, -1.0598e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04663270711898804 0.0010051727294921875 1.4493072032928467 0.3497377932071686 56\n",
            "pred tensor([-4.4525e-05, -2.2781e-04, -9.0003e-06, -5.9605e-08,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00, -4.1723e-07, -1.6689e-06, -1.7881e-07,\n",
            "        -4.6313e-05, -4.7684e-07,  0.0000e+00,  0.0000e+00, -9.7156e-06,\n",
            "         0.0000e+00, -7.3910e-06, -6.1989e-06, -1.1921e-07, -4.1127e-06,\n",
            "        -1.9670e-06, -4.3511e-06, -3.1590e-06, -1.4524e-03, -1.3113e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0629868432879448 0.0006661415100097656 1.4406312704086304 0.3202287554740906 19\n",
            "pred tensor([-8.1006e-01, -3.6354e-03, -7.1526e-07, -4.9472e-06, -4.7684e-06,\n",
            "        -8.3447e-07,  0.0000e+00, -1.7881e-07, -3.3319e-05, -9.5367e-07,\n",
            "         0.0000e+00,  0.0000e+00, -2.3842e-07, -1.4668e-03, -1.5917e-03,\n",
            "        -6.0856e-05, -1.1325e-05, -6.4373e-06, -1.1086e-05, -2.7156e-04,\n",
            "        -6.2561e-02, -1.7130e-04, -9.9805e-01, -1.3494e-04, -4.7207e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05322062969207764 0.0010166168212890625 1.432326316833496 0.34653034806251526 69\n",
            "pred tensor([-1.8635e-03, -3.1414e-03, -2.7580e-03, -1.7703e-05, -1.4901e-06,\n",
            "        -2.5094e-05, -1.7166e-05,  0.0000e+00,  0.0000e+00, -1.9073e-06,\n",
            "        -4.1723e-07, -5.9605e-08, -9.5367e-07, -4.6492e-06, -5.1260e-06,\n",
            "        -2.3842e-07, -1.7881e-06, -6.6948e-04, -3.7551e-06, -2.3842e-06,\n",
            "        -1.9670e-06, -9.2850e-03, -4.3188e-01, -3.4888e-01, -9.9463e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06190928444266319 0.00403594970703125 1.363006830215454 0.34128305315971375 25\n",
            "pred tensor([-1.0000e+00, -2.8074e-05, -5.7602e-04, -6.3372e-04, -1.0208e-02,\n",
            "        -1.7607e-04, -1.0681e-04, -2.2829e-05, -1.8477e-06, -8.3447e-07,\n",
            "        -1.1683e-05, -1.6868e-04, -1.3709e-06, -1.2004e-04, -1.1545e-04,\n",
            "        -1.7786e-03, -3.1590e-06, -3.9673e-03, -4.1656e-02, -4.2975e-05,\n",
            "        -1.3292e-04, -6.8808e-04, -1.1339e-03, -7.2539e-05, -1.0080e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04556151106953621 0.00740814208984375 1.3460485935211182 0.3654073476791382 47\n",
            "pred tensor([-1.6327e-03, -2.1744e-04, -2.5725e-04, -2.3842e-07,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "        -2.8014e-06, -1.0000e+00, -2.0266e-06, -1.3816e-04, -7.7486e-07,\n",
            "        -2.2054e-06, -5.3465e-05, -1.6093e-06, -3.1590e-06, -3.4809e-05,\n",
            "        -7.0930e-06, -7.9274e-06, -1.7881e-06, -7.2718e-06, -2.4438e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0643269345164299 0.001918792724609375 1.4309266805648804 0.3270470201969147 24\n",
            "pred tensor([-5.2869e-05, -2.1400e-03, -2.7790e-03, -4.8685e-04, -6.9201e-05,\n",
            "        -2.7537e-05, -8.3804e-05, -8.2636e-04, -1.3351e-03, -8.5144e-03,\n",
            "        -7.8869e-04, -1.9882e-02, -7.2363e-01, -9.0527e-01, -9.8779e-01,\n",
            "        -9.9902e-01, -9.9951e-01, -6.8359e-01, -8.4619e-01, -1.4954e-02,\n",
            "        -4.9023e-01, -3.9124e-02, -3.1885e-01, -9.3652e-01, -4.4482e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04286590591073036 0.00174713134765625 1.3771165609359741 0.3727369010448456 59\n",
            "pred tensor([-1.7810e-04, -5.7459e-04, -1.7881e-07, -3.5763e-06, -5.9605e-07,\n",
            "        -5.9605e-07, -5.5432e-06,  0.0000e+00, -1.1921e-07, -1.8477e-06,\n",
            "        -4.8876e-05, -2.3842e-07, -5.9605e-07,  0.0000e+00,  0.0000e+00,\n",
            "        -3.6895e-05, -2.2781e-04, -7.2122e-06, -7.1526e-07, -6.7329e-04,\n",
            "        -5.9903e-05, -3.5763e-05, -6.7115e-05, -6.3002e-05, -1.4424e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06322459131479263 0.00022029876708984375 1.5113739967346191 0.3253522217273712 35\n",
            "pred tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3842e-07,\n",
            "        -9.9540e-06, -4.8193e-01, -4.0985e-02, -2.1130e-01, -2.8610e-06,\n",
            "        -1.8597e-04, -1.7958e-03, -3.8147e-06, -1.1146e-05, -1.0133e-05,\n",
            "         0.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3113e-06, -4.6468e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04820164665579796 1.811981201171875e-05 1.6548054218292236 0.3318364918231964 59\n",
            "pred tensor([-5.2826e-02, -1.3733e-01, -3.4180e-02, -9.8486e-01, -1.0736e-01,\n",
            "        -1.0806e-04, -5.5469e-01, -5.1193e-03, -4.0531e-06, -1.6689e-06,\n",
            "        -5.9605e-08, -1.1325e-05, -9.5020e-01, -1.0000e+00, -1.3351e-05,\n",
            "        -1.2517e-06, -3.3379e-06,  0.0000e+00, -2.3842e-07, -4.7684e-07,\n",
            "        -2.7733e-03, -2.5415e-04, -5.6088e-05, -1.1194e-04, -1.3924e-04],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06190548464655876 0.00020837783813476562 1.5269025564193726 0.3257974088191986 42\n",
            "pred tensor([-1.4305e-06, -7.2527e-04, -3.6359e-05, -2.9761e-01, -1.6785e-02,\n",
            "        -5.8770e-05, -2.6703e-05, -2.3878e-04, -1.8001e-05, -1.1086e-05,\n",
            "        -2.3246e-06, -6.3229e-04, -8.7433e-03, -2.3127e-05, -1.1244e-03,\n",
            "        -2.8920e-04, -5.8949e-05, -2.3365e-03, -1.2970e-03, -1.0319e-03,\n",
            "        -5.9426e-05, -3.2730e-03, -2.3055e-04, -7.9155e-04, -1.9252e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.045409705489873886 0.0012874603271484375 1.3858484029769897 0.33371174335479736 59\n",
            "pred tensor([-7.7486e-07, -1.6689e-05, -5.7220e-06, -7.7486e-07, -5.9605e-08,\n",
            "        -5.3358e-04, -1.5438e-05, -1.2517e-06, -1.3340e-04, -9.4175e-06,\n",
            "        -7.0930e-06, -4.2975e-05, -2.5392e-05, -2.2054e-06, -7.1526e-06,\n",
            "        -3.0696e-05, -3.9935e-06, -1.6689e-06, -2.3842e-07, -3.5763e-07,\n",
            "         0.0000e+00,  0.0000e+00, -4.6272e-03, -8.6426e-02, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06250615417957306 0.000762939453125 1.413191318511963 0.32765379548072815 48\n",
            "pred tensor([-1.2875e-05, -1.6665e-04, -1.4258e-01, -4.8877e-01, -5.1832e-04,\n",
            "        -3.5977e-04, -1.1820e-04, -9.6083e-05, -6.3777e-06, -4.5776e-05,\n",
            "        -7.1526e-07, -3.0458e-05, -5.3287e-05, -3.0100e-05, -2.6584e-05,\n",
            "        -3.0746e-03, -2.3842e-07, -6.7353e-06, -4.4882e-05, -3.4027e-03,\n",
            "        -2.3499e-03, -3.2115e-04, -5.9471e-03, -3.2961e-05, -7.7248e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04430803284049034 0.00402069091796875 1.3790807723999023 0.3300134539604187 49\n",
            "pred tensor([-1.1116e-02, -3.5248e-03, -3.3894e-03, -4.6670e-05, -8.5735e-04,\n",
            "        -3.6850e-03, -3.5167e-06, -2.5034e-06, -3.9756e-05, -8.6328e-01,\n",
            "        -1.0000e+00, -1.4722e-05, -8.9407e-07, -4.7684e-07, -2.9802e-07,\n",
            "        -5.9605e-08, -1.1921e-07, -1.2302e-03, -4.7684e-07, -1.3709e-06,\n",
            "        -1.4786e-02, -1.8382e-04, -1.4305e-06, -1.8673e-03, -2.6207e-03],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.058450307697057724 0.004779815673828125 1.3158001899719238 0.32356640696525574 29\n",
            "pred tensor([-4.3511e-06, -1.7607e-04, -7.2241e-05, -1.0723e-04, -5.9605e-06,\n",
            "        -6.5565e-07, -1.6518e-03, -1.0452e-02, -7.6294e-05, -2.9469e-04,\n",
            "        -7.9274e-06, -9.5010e-05, -1.4889e-04, -2.2163e-03, -1.2445e-03,\n",
            "        -1.5593e-04, -3.8853e-03, -1.3332e-03, -1.8930e-03, -1.1551e-02,\n",
            "        -3.4809e-05, -5.9009e-06, -4.5955e-05, -2.6882e-05, -6.6578e-05],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.040330447256565094 0.004180908203125 1.3728342056274414 0.36392566561698914 32\n",
            "pred tensor([-9.4175e-04, -2.8839e-03, -1.0598e-04, -3.7048e-02, -2.6536e-04,\n",
            "        -2.9802e-06, -3.2306e-05, -1.1444e-05, -1.4365e-05, -1.1921e-07,\n",
            "        -1.1921e-07, -2.9802e-07, -1.8239e-04, -5.9605e-08,  0.0000e+00,\n",
            "        -1.3816e-04, -1.1921e-07, -2.0683e-05, -3.9893e-01, -1.0000e+00,\n",
            "        -1.3709e-06, -7.3910e-06, -4.1723e-06, -1.5080e-05, -9.1195e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06478189677000046 0.00183868408203125 1.4392927885055542 0.3257363736629486 40\n",
            "pred tensor([-1.6928e-04, -5.2023e-04, -4.1127e-06, -2.2292e-05, -2.3901e-05,\n",
            "        -5.8293e-05, -7.1704e-05, -1.3351e-02, -6.6340e-05, -2.3071e-02,\n",
            "        -4.8943e-03, -1.8311e-03, -6.0844e-03, -3.5114e-03, -3.1300e-03,\n",
            "        -1.1593e-04, -7.4816e-04, -1.2924e-02, -2.7405e-02, -2.1497e-01,\n",
            "        -3.8086e-02, -2.1400e-03, -1.0443e-03, -2.2697e-04, -9.9023e-01],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04573890566825867 0.0011043548583984375 1.407942771911621 0.3318151533603668 49\n",
            "pred tensor([-5.5850e-05, -6.8426e-05, -1.8740e-04, -2.9802e-07, -3.4571e-06,\n",
            "        -4.7684e-07, -1.0133e-06, -1.2517e-06,  0.0000e+00, -3.2783e-06,\n",
            "        -4.7684e-07, -1.1921e-07, -4.7684e-07, -4.1842e-05, -9.5367e-07,\n",
            "        -2.4719e-03, -8.8871e-05, -3.5248e-03, -2.6001e-01, -1.0000e+00,\n",
            "        -2.1875e-05, -5.9605e-08, -7.6294e-04, -2.3723e-05, -6.3777e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.06337122619152069 0.0006618499755859375 1.4283487796783447 0.34103891253471375 42\n",
            "pred tensor([-7.2527e-04, -2.8312e-05, -4.7743e-05, -1.1206e-05, -1.4305e-06,\n",
            "        -1.0598e-04, -6.9475e-04, -2.5711e-03, -3.4404e-04, -7.3528e-04,\n",
            "        -4.1664e-05, -5.2035e-05, -1.9341e-03, -7.1907e-03, -1.1093e-02,\n",
            "        -8.4162e-05, -2.6727e-04, -3.1403e-02, -2.4612e-02, -2.6627e-02,\n",
            "        -1.7029e-01, -9.7217e-01, -9.5117e-01, -9.6777e-01, -1.0000e+00],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0.], device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.04489168897271156 0.0008459091186523438 1.4930882453918457 0.3534025549888611 49\n",
            "pred tensor([-2.0266e-04, -1.4496e-03, -7.9036e-05, -4.9114e-05, -1.0192e-05,\n",
            "        -1.3916e-01, -7.9691e-05, -5.4955e-05, -1.6689e-06, -1.0729e-06,\n",
            "        -1.7881e-07,  0.0000e+00,  0.0000e+00, -2.9540e-04, -1.0000e+00,\n",
            "        -5.9605e-08, -1.1921e-07, -7.7486e-07, -1.0133e-06, -6.0797e-06,\n",
            "        -2.7299e-05, -1.0133e-06, -6.1798e-03, -6.8665e-05, -5.9605e-06],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.05971996486186981 0.00011396408081054688 1.5653948783874512 0.3247308135032654 35\n",
            "pred tensor([-3.3975e-05, -2.7061e-04, -6.3002e-05, -4.6692e-02, -3.1590e-06,\n",
            "        -2.2888e-05, -1.0133e-06, -2.0266e-06, -6.6345e-02, -2.4724e-04,\n",
            "        -6.8378e-04, -3.3245e-03, -9.9463e-01, -9.9316e-01, -1.0000e+00,\n",
            "        -9.9951e-01, -1.0312e-04, -5.0247e-05, -1.6093e-06, -7.7200e-04,\n",
            "        -1.4365e-05, -3.8147e-06, -1.8418e-05, -6.0225e-04, -1.1711e-02],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>)\n",
            "rwd tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "         0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "       device='cuda:0')\n",
            "repr, std, cov, clossl, wrong 0.0474044606089592 0.00039196014404296875 1.5919950008392334 0.36569157242774963 69\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(100):\n",
        "    print(i)\n",
        "    train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    # checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    # torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "# batch64 28m58s 84\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "31c1755c-ef2a-4f8c-ba23-806590aaa7fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "# ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n",
        "\n",
        "\n",
        "# # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "# 2  5/11 8\n",
        "# 1/10 4 7/9\n",
        "# 0  3/12 6\n",
        "\n",
        "# 13 11 14\n",
        "# 10 12 9\n",
        "\n",
        "# from gymnasium.wrappers import TimeLimit\n",
        "from gym.wrappers import TimeLimit\n",
        "env = TimeLimit(env, max_episode_steps=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PraFUAPB3j7v",
        "outputId": "329ef0aa-3ac2-43e9-8784-567b3a45bd4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-42-ff80b479d892>:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-42-ff80b479d892>:85: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dided\n",
            "time\n",
            "[13, 13, 2, 1, 0, 4, 13, 13, 0, 13, 12, 0, 12, 13, 13, 12, 13, 13, 13, 4, 13, 13, 13, 13, 10, 10, 0, 11, 7, 12, 4, 12, 13, 12, 14, 4, 12, 4, 4, 12, 6, 1, 9, 9, 14, 4, 13, 13, 13, 13, 13, 13, 4, 13, 11, 13, 13, 0, 13, 13, 4, 4, 13, 13, 13, 13, 12, 12, 0, 12, 1, 1, 1, 1, 6, 11, 13, 12, 14, 13, 12, 4, 13, 13, 13, 12, 12, 0, 4, 1, 6, 6, 7, 13, 14, 0, 12, 13, 13, 13, 13, 12, 4, 13, 13, 4, 12, 13, 12, 13, 4, 12, 13, 13, 13, 11, 4, 13, 4, 4, 4, 13, 13, 10, 13, 0, 13, 13, 4, 13, 13, 13, 13, 4, 13, 4, 4, 13, 13, 6, 13, 4, 13, 13, 13, 13, 1, 1, 12, 13, 4, 13, 13, 13, 13, 13, 4, 10, 13, 11, 13, 13, 13, 4, 13, 13, 13, 13, 12, 4, 13, 4, 5, 1, 1, 2, 13, 0, 13, 12, 4, 13, 13, 1, 13, 12, 13, 12, 4, 13, 13, 10, 13, 4, 13, 4, 13, 13, 13, 1, 12, 13, 12, 4, 13, 12, 13, 13, 10, 6, 1, 1, 1, 6, 6, 6, 0, 13, 13, 13, 4, 12, 13, 13, 13, 13, 4, 13, 4, 4, 13, 4, 0, 13, 13, 13, 13, 4, 13, 4, 4, 13, 13, 13, 13, 13, 4, 4, 13, 4, 12, 13, 0, 12, 4, 13, 10, 6, 0, 14, 1, 1, 5, 1, 12, 13, 13, 4, 4, 13, 13, 1, 12, 0, 12, 13, 4, 12, 13, 13, 12, 13, 12, 13, 4, 4, 0, 13, 13, 4, 13, 13, 4, 13, 13, 0, 13, 13, 13, 13, 13, 7, 4, 13, 13, 13, 13, 13, 1, 1, 10, 1, 4, 4, 4, 13, 4, 10, 4, 0, 13]\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# print(env.action_space) # 15\n",
        "\n",
        "def simulate(agent, buffer=[], k=4):\n",
        "    # agent.eval()\n",
        "    out=None\n",
        "    writer = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # writer = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    act_list=[]\n",
        "    lstate=[]\n",
        "    # h0 = torch.randn((agent.jepa.pred.num_layers, agent.d_model), device=device)\n",
        "    while True:\n",
        "    # for i in range(400):\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        # if len(act)<=0: act = agent(state).cpu()[0,:4].tolist()\n",
        "        # print(act.shape, h0.shape) # [1, 6], [1, 256]\n",
        "        lstate.append(state)\n",
        "        if len(act)<=0:\n",
        "            # lact, lh0, lx, lz = agent(state, h0)\n",
        "            # act = lact.cpu()[0,:k].tolist()\n",
        "            # act = agent(state, k)\n",
        "            act = agent(lstate, k=k)\n",
        "            lstate=[]\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        # print(i, 'act: ',action, 'reward: ',reward)\n",
        "        act_list.append(action)\n",
        "        writer.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"dided\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    print(act_list)\n",
        "    env.close()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9cm6KjvBrnNO"
      },
      "outputs": [],
      "source": [
        "# @title alllll\n",
        "for i in range(30):\n",
        "    # print(\"#### simulate ####\")\n",
        "    # buffer_=[]\n",
        "    for _ in range(5):\n",
        "        buffer = simulate(agent, buffer)\n",
        "        # buffer_ = simulate(agent, buffer_)\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len)\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    # checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    # torch.save(checkpoint, folder+'agentoptim1.pkl')\n",
        "\n",
        "    # buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "    # with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "    print(\"train_data.data\",len(train_data.data))\n",
        "    while len(train_data.data)>20000: # 10000:6.9gb, 20000:5.5gb\n",
        "        buffer.pop(random.randrange(len(buffer)))\n",
        "        train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "b8zxYU9jpE8K",
        "outputId": "9a3cbf99-0034-44f6-d61c-1af446e408c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "c008b443-560f-441f-8de5-0b59abcb2842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240927_043133-r1tay1cr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/r1tay1cr' target=\"_blank\">solar-wildflower-94</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/r1tay1cr' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/r1tay1cr</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(project=\"procgen\",\n",
        "    config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xLh80kPvEzwX"
      },
      "outputs": [],
      "source": [
        "# @title agent pixel save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.emb = torch.nn.Embedding(15, dim_a) # env.action_space # 15\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        for i in range(20): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "\n",
        "            dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "\n",
        "            # loss, sx_ = self.rnn_pred(sx_, x)\n",
        "            loss, sx_ = self.rnn_pred(sx_, x_)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(syaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb #+ clossl\n",
        "\n",
        "                    loss = loss + jloss + closs #+ conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sy_ = sy_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29O1eyvhnRSD",
        "outputId": "c470e601-d5da-4b94-bb69-928dd9d823af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-77-bbc83a6aed37>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=2. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        # 0.0083 0.06 1.0 = 1, 7, 120.5\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        optim_z = torch.optim.SGD([z], lr=1e2, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.95)) #\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.data)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i,x.data, z.squeeze(), loss.item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        # print(\"search\",loss.item())\n",
        "        return lact#, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        _,T,_ = sx.shape\n",
        "        batch = 1\n",
        "        lr = 1e-1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                x[:,:self.lx.shape[1]] = self.lx[:,:T]\n",
        "                z[:,:self.lz.shape[1]] = self.lz[:,:T]\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            # print(i,x.data, z.squeeze(), loss.item())\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        return lact, lh0, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, gamma=0.9): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sx = self.jepa.pred(sxaz)\n",
        "                sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        # if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            # loss=0\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(syaz)\n",
        "                    sy_ = sy_ + self.jepa.pred(syaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # cost loss\n",
        "                    reward_ = self.tcost(sy_).squeeze(-1) # [batch_size]\n",
        "                    clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    _, st = self.get(st, world_state=world_zero)\n",
        "                    # print(\"stt\",st.shape)\n",
        "                    stt = self.tcost(self.jepa.enc(st.unsqueeze(1))).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb + clossl\n",
        "\n",
        "                    # loss = loss + jloss + closs\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    # loss=0\n",
        "                else:\n",
        "                    scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mY7BITKjSKC",
        "outputId": "cbad0ffc-e8e9-4a4d-bd3c-d6d9ddaf6e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2336301\n",
            "1278976\n",
            "399360\n",
            "1024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-76-e20d23bca149>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=3, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v, drop=0.2)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=50. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # e = d_model**-0.5\n",
        "        # self.h0 = torch.empty((self.jepa.pred.num_layers, 1, d_model), device=device).uniform_(-e, e) # [num_layers, batch, d_model]\n",
        "        # self.h0 = torch.normal(mean=0, std=e, size=(self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # torch.nn.init.xavier_uniform_(self.h0) # xavier_uniform_, kaiming_normal_\n",
        "\n",
        "        # self.lx, self.lz = torch.empty(1,0,dim_a), torch.empty(1,0,dim_z)\n",
        "        self.lx, self.lz = None, None\n",
        "        state = torch.zeros((1, 3,64,64), device=device)\n",
        "        self.sx = self.jepa.enc(state)\n",
        "\n",
        "    # def forward(self, state, k=1): # live run in env # np (64, 64, 3)\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        self.update_h0(lstate, laction)\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "            # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.h0=lh0[k].unsqueeze(1) # [num_layers, 1, d_model]\n",
        "        # self.lx, self.lz = lx[:,k:], lz[:,k:] # [batch, T, dim_a], [batch, T, dim_z]\n",
        "        self.lx, self.lz = lx[k:], lz[k:] # [T, dim_a], [T, dim_z]\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "\n",
        "                # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "                # print(torch.cat(lstate, dim=0).shape)\n",
        "                # lsx = self.jepa.enc(torch.stack(lstate, dim=0))#.unsqueeze(0)\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx-torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                # batch, seq_len, _ = lstate.shape\n",
        "                # seq_len, _ = lstate.shape\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    try: la = self.emb(self.la[:seq_len])\n",
        "                    except:\n",
        "                        print(\"err self.la\")\n",
        "                        # la = self.emb([0]*seq_len)\n",
        "                        la = self.emb(torch.zeros(seq_len, dtype=int, device=device))\n",
        "\n",
        "        # lz = nn.Parameter(torch.zeros((batch, seq_len, self.dim_z),device=device))\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        # optim_z = torch.optim.SGD([lz], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([lz], 1e0, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "\n",
        "        for i in range(20): # num epochs\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                # print(sxaz.shape, self.h0.shape)\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                # sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                loss = F.mse_loss(out_, out)\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            print(lz.data)\n",
        "            with torch.no_grad(): lz.clamp_(min=-1, max=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1]\n",
        "        self.la = la[k:]\n",
        "        return h0\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                # x[:,:self.lx.shape[1]], z[:,:self.lz.shape[1]] = self.lx[:,:T], self.lz[:,:T]\n",
        "                x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].repeat(batch,1,1), self.lz[:T].repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            # print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            # print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i, \"loss\", loss.squeeze().data)\n",
        "            # print(x.shape,torch.argmax(-dist,dim=-1).shape,z.shape,loss.shape) # [16, 6, 3], [16, 6], [16, 6, 1], [16, 1]\n",
        "            # print(i, torch.cat([x,torch.argmax(-dist,dim=-1),z],dim=-1).squeeze().data)\n",
        "            print(i, \"x act z\", torch.cat([x[0],torch.argmax(-dist,dim=-1)[0].unsqueeze(-1),z[0]],dim=-1).squeeze().data)\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, t, dim_a], [batch, t, dim_z]\n",
        "\n",
        "\n",
        "    def search_optimxz(self, sx, T=6, h0=None):\n",
        "        self.eval()\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 4 # 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1 ; sgd\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_uniform_(z) # xavier_normal_, xavier_uniform_\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        # optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e1, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].unsqueeze(0).repeat(batch,1,1), self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        print(\"search\", z[0].squeeze())\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        for i in range(10): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, lsx, lh0,c = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.sum().backward()\n",
        "            # optim_x.step(); optim_z.step()\n",
        "            # optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            print(i, \"search loss\", loss.squeeze().data)\n",
        "            # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "            print(i, \"search z\", z[0].squeeze().data)\n",
        "            # print(torch.argmin(dist,dim=-1).int())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        print(\"c\",torch.stack(c)[:,idx])\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # cost += tcost + icost\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "        c=[]\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            # print(sx.shape, a.shape, z.shape)\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            c.append(tcost)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    # imshow(state[0].cpu())\n",
        "                    # print(\"norm\", torch.norm(sy[0]-sy_[0], dim=-1))\n",
        "                    # # if torch.norm(sy[0]-sy_[0], dim=-1) > 1:\n",
        "                    # print(i, reward[0])\n",
        "                    # print(sy)\n",
        "                    # print(sy_)\n",
        "                    # print(sy[0]-sy_[0])\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "\n",
        "                    # cost loss\n",
        "                    # syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = 100*clossl\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batc h_size, d_model]\n",
        "            # sx=sy_\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "\n",
        "                    # z = self.jepa.argm(sy_, a, sy)\n",
        "                    z = self.argm(sy, sy_, h0, a, reward)\n",
        "                    with torch.no_grad(): z.mul_(torch.rand_like(z)).mul_((torch.rand_like(z)>0.5).bool()) # dropout without scailing\n",
        "\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "\n",
        "                    # cost loss\n",
        "                    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    # syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = self.closs_coeff * clossl\n",
        "\n",
        "                    # print(h0.requires_grad)\n",
        "                    # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "                    # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "                    # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # torch.norm(sy-sx, dim=-1)\n",
        "                    # sx=sy\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    norm = torch.norm(sy, dim=-1)[0].item()\n",
        "                    z_norm = torch.norm(z)\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "\n",
        "                # lh0 = torch.zeros((rwd.shape[1],)+h0.shape, device=device)\n",
        "                # lz = torch.zeros((lsy.shape[0], lsy.shape[1], self.dim_z), device=device)\n",
        "                    # for name, param in agent.tcost.named_parameters():\n",
        "                    #     print(\"param.data\",param.max().item(),param.min().item())\n",
        "                    #     print(\"agent.tcost\",param.data)\n",
        "\n",
        "\n",
        "# # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "# ema_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.999))\n",
        "# for epoch in range(300):\n",
        "#       for input, target in loader:\n",
        "#           optimizer.zero_grad()\n",
        "#           loss_fn(model(input), target).backward()\n",
        "#           optimizer.step()\n",
        "#           ema_model.update_parameters(model)\n",
        "# # Update bn statistics for the ema_model at the end\n",
        "# torch.optim.swa_utils.update_bn(loader, ema_model)\n",
        "# # Use ema_model to make predictions on test data\n",
        "# preds = ema_model(test_input)\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "\n",
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cg0BI2TwY9-p"
      },
      "outputs": [],
      "source": [
        "# @title z.grad.data = -z.grad.data\n",
        "\n",
        "# self.eval()\n",
        "batch = 4 # 16\n",
        "x = nn.Parameter(torch.empty((batch, T, agent.dim_a),device=device))\n",
        "torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# optim_ = torch.optim.SGD([x,z], lr=1e1) # 3e3\n",
        "optim_ = torch.optim.AdamW([x,z], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "print(\"search z\", z[0].squeeze())\n",
        "print(\"search x\", x[0].squeeze())\n",
        "sx, h0 = sx.detach(), h0.detach()\n",
        "for i in range(10): # num epochs\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    z.grad.data = -z.grad.data\n",
        "    optim_.step()\n",
        "    optim_.zero_grad()\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "    print(i, \"search loss\", loss.squeeze().data)\n",
        "    print(i, \"search z\", z[0].squeeze().data)\n",
        "    print(i, \"search x\", x[0].squeeze().data)\n",
        "dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "print(\"c\",torch.stack(c)[:,idx])\n",
        "# return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "# print(lact[idx], lh0[:,:,idx,:], x[idx], z[idx])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5VMebkQ1mJtD"
      },
      "outputs": [],
      "source": [
        "# @title argm agent.rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def argm(sx, x,h0, lr=3e3): # 3e3\n",
        "    # agent.eval()\n",
        "    # batch_size, T, _ = sx.shape\n",
        "    batch = 16 # 16\n",
        "    z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "    torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "    optim_z = torch.optim.SGD([z], lr=1e3, maximize=True) # 3e3\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.LBFGS([z], max_iter=5, lr=1)\n",
        "\n",
        "    # print(\"argm\", z[0].squeeze())\n",
        "    sx, h0 = sx.detach(), h0.detach()\n",
        "    x = x.detach().repeat(batch,1,1)\n",
        "    for i in range(5): # num epochs\n",
        "        # print(sx.shape, x.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "        loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "        loss.sum().backward()\n",
        "        optim_z.step()\n",
        "        optim_z.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "        # print(i, \"argm loss\", loss.squeeze().data)\n",
        "        # print(i, \"argm z\", z[0].squeeze().data)\n",
        "    idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "    return z[idx].unsqueeze(0)\n",
        "\n",
        "\n",
        "T=1\n",
        "xx = torch.empty((1, T, agent.dim_a))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "# print(x.shape)\n",
        "optim_x = torch.optim.SGD([x], lr=1e1) # 1e-1,1e-0,1e4 ; 1e2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "\n",
        "state = torch.zeros((1, 3,64,64))\n",
        "with torch.no_grad():\n",
        "    sx = agent.jepa.enc(state).detach()\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "print(time.time()-start)\n",
        "\n",
        "print(\"search\",x.squeeze().data)\n",
        "for i in range(20): # 5\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    z = argm(sx, x_,h0)\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [1, 1, 3], [1, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "    print(i, \"search loss\", x.squeeze().data, loss.item())\n",
        "    # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "\n",
        "# z sgd 1e3\n",
        "# 9 search loss tensor([0.0142, 0.0142, 0.0142, 0.0142])\n",
        "# 9 search z tensor([-0.3381, -0.7005, -0.5877, -0.0664, -0.1439,  0.0283,  0.0541, -0.1439])\n",
        "\n",
        "# x sgd 1e2\n",
        "# 1 tensor([0.3561, 0.3059, 0.8830]) 0.014148875139653683\n",
        "# 9 tensor([0.3560, 0.3064, 0.8828]) 2.328815611463142e-07\n",
        "\n",
        "# 1e0\n",
        "# 19 tensor([-0.5768,  0.5778,  0.5774]) 6.543130552927323e-07\n",
        "# 19 tensor([0.3570, 0.6689, 0.6521]) 2.474381801675918e-07\n",
        "# 19 tensor([0.5783, 0.5765, 0.5772]) 1.519319567933053e-07\n",
        "# 19 tensor([0.3427, 0.6795, 0.6487]) 4.220427456402831e-07\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gcvgdCB1h1_E"
      },
      "outputs": [],
      "source": [
        "# @title torch.optim.LBFGS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Example of a deep nonlinear model f(x)\n",
        "class DeepNonlinearModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNonlinearModel, self).__init__()\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(10, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "f = DeepNonlinearModel()\n",
        "# x = torch.randn(1, 10, requires_grad=True)\n",
        "# xx = torch.randn((1,10))\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "\n",
        "# Define loss function (mean squared error for this example)\n",
        "target = torch.tensor([[0.0]])  # Target output\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    return loss\n",
        "\n",
        "optimizer = torch.optim.LBFGS([x], lr=1.0, max_iter=5)  # Limit to 2-3 iterations for speed\n",
        "start_time = time.time()\n",
        "for _ in range(2):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step(closure)  # Perform a step of optimisation\n",
        "    print(loss.item())\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "start_time = time.time()\n",
        "optimizer = torch.optim.SGD([x], lr=1e1, maximize=True) # 3e3\n",
        "for _ in range(5):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step()  # Perform a step of optimisation\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    print(loss.item())\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "# optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "    # def argm(self, sx, a, lr=3e3): # 3e3\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "    #     optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    #     # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    #     sx, a = sx.detach(), a.detach()\n",
        "    #     for i in range(5): # 10\n",
        "    #         sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #         with torch.amp.autocast('cuda'):\n",
        "    #             # sx_ = self.jepa.pred(sxaz)\n",
        "    #             sx_ = sx + self.jepa.pred(sxaz)\n",
        "    #             cost = -self.tcost(sx_)\n",
        "\n",
        "    #         cost.backward()\n",
        "    #         optim.step()\n",
        "    #         # scaler.scale(cost).backward()\n",
        "    #         # scaler.step(optim)\n",
        "    #         # scaler.update()\n",
        "    #         optim.zero_grad()\n",
        "    #         with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "    #         print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def argm(self, sx, lr=3e3): # 3e3\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch_size, T, _ = sx.shape\n",
        "        batch = 16\n",
        "        # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "        z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "        optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "        sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "        # sx = sx.detach()\n",
        "        for i in range(20): # 10\n",
        "            # print(sx.shape,z.shape)\n",
        "            sxz = torch.cat([sx, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                cost = model(sxz)\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "            # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "            # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        # return z.detach()\n",
        "        # print(\"argm z\",z.squeeze().data)\n",
        "        # print(\"cost\",cost.squeeze())\n",
        "        idx = torch.argmax(loss)\n",
        "        # return z[idx].detach().unsqueeze(0)\n",
        "        return z[:,idx].detach()\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch=1\n",
        "        T=1\n",
        "        x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "\n",
        "        lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "        # ratio = 6e0\n",
        "        lr = 1e-1 # adamw 1e-1\n",
        "        ratio = 4\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        # optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze())\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "        for i in range(50):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            z = argm(x)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "            # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "            # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                x.clamp_(min=-1, max=1)\n",
        "            # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "        idx = torch.argmax(loss)\n",
        "        print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd):\n",
        "        self.tcost.eval()\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "            lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "                for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                    syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                    out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                    lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                    lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "                repr_loss = F.mse_loss(lsy, lsy_)\n",
        "                syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "                clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "                # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "                cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "outputs": [],
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.amp.autocast('cuda'):\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjm2kV3H7ZVR"
      },
      "outputs": [],
      "source": [
        "for name, p in agent.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(name, p.numel())\n",
        "\n",
        "\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HcOidvtW9KAH"
      },
      "outputs": [],
      "source": [
        "# @title from RNN2\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, h0=None, c0=None): # [batch_size, seq_len, input_size]\n",
        "        if h0 is None: h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        if c0 is None: c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        out, h0 = self.rnn(x, h0)\n",
        "        # out, (h0,c0) = self.lstm(x, (h0,c0))\n",
        "        # out:(batch_size, seq_length, hidden_size) (n, 28, 128)\n",
        "        out = out[:, -1, :] # out: (n, 128)\n",
        "        out = self.fc(out) # out: (n, 10)\n",
        "        return out\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "\n",
        "d_model,dim_a,dim_z = 256,3,1\n",
        "pred = nn.Sequential(\n",
        "    nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model),\n",
        "    )\n",
        "gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "\n",
        "print(sum(p.numel() for p in pred.parameters() if p.requires_grad)) # 264192\n",
        "print(sum(p.numel() for p in gru.parameters() if p.requires_grad)) # 397824\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AodVas3L4ZS",
        "outputId": "f1940ab6-b72d-4c8d-f97d-6d876f1b92e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 256])\n",
            "136960\n",
            "136960\n"
          ]
        }
      ],
      "source": [
        "# @title efficientnet\n",
        "# https://arxiv.org/pdf/2207.10318 # visualise kernal\n",
        "\n",
        "# https://pytorch.org/hub/research-models\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/shufflenetv2.py\n",
        "\n",
        "import torch\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py\n",
        "from torchvision.models.efficientnet import *\n",
        "from torchvision.models import efficientnet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # https://arxiv.org/pdf/2104.00298\n",
        "# Stage Operator Stride #Channels #Layers\n",
        "# 0 Conv3x3 2 24 1\n",
        "# 1 Fused-MBConv1, k3x3 1 24 2\n",
        "# 2 Fused-MBConv4, k3x3 2 48 4\n",
        "# 3 Fused-MBConv4, k3x3 2 64 4\n",
        "# 4 MBConv4, k3x3, SE0.25 2 128 6\n",
        "# 5 MBConv6, k3x3, SE0.25 1 160 9\n",
        "# 6 MBConv6, k3x3, SE0.25 2 256 15\n",
        "# 7 Conv1x1 & Pooling & FC - 1280 1\n",
        "\n",
        "# # elif arch.startswith(\"efficientnet_v2_s\"):\n",
        "# inverted_residual_setting = [\n",
        "#     FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
        "#     FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
        "#     FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
        "#     MBConvConfig(4, 3, 2, 64, 128, 6),\n",
        "#     MBConvConfig(6, 3, 1, 128, 160, 9),\n",
        "#     MBConvConfig(6, 3, 2, 160, 256, 15),\n",
        "# ]\n",
        "# last_channel = 1280\n",
        "\n",
        "# d_list=[24, 48, 64, 128, 160, 256] #\n",
        "d_list=[16, 32, 48, 96, 108, 172] #\n",
        "inverted_residual_setting = [\n",
        "    efficientnet.FusedMBConvConfig(1, 3, 1, d_list[0], d_list[0], 2),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[0], d_list[1], 4),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[1], d_list[2], 4),\n",
        "    efficientnet.MBConvConfig(4, 3, 2, d_list[2], d_list[3], 6),\n",
        "    efficientnet.MBConvConfig(6, 3, 1, d_list[3], d_list[4], 9),\n",
        "    efficientnet.MBConvConfig(6, 3, 2, d_list[4], d_list[5], 15),\n",
        "]\n",
        "last_channel = 512\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "\n",
        "effnet = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "effnet.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "\n",
        "#   (features): Sequential(\n",
        "#     (0): Conv2dNormActivation(\n",
        "#       (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "#       (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "#       (2): SiLU(inplace=True)\n",
        "\n",
        "input = torch.rand((1,1,256,256), device=device)\n",
        "out = effnet(input)\n",
        "print(out.shape)\n",
        "# print(effnet)\n",
        "print(sum(p.numel() for p in effnet.parameters() if p.requires_grad)) #\n",
        "print(sum(p.numel() for p in effnet.parameters())) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "# !pip install -qq vector-quantize-pytorch\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LK5u500Vad2P"
      },
      "outputs": [],
      "source": [
        "# @title FSQ jax\n",
        "# https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "Codeword = jax.Array\n",
        "Indices = jax.Array\n",
        "\n",
        "def round_ste(z):\n",
        "  \"\"\"Round with straight through gradients.\"\"\"\n",
        "  zhat = jnp.round(z)\n",
        "  return z + jax.lax.stop_gradient(zhat - z)\n",
        "\n",
        "class FSQ:\n",
        "  \"\"\"Quantizer.\"\"\"\n",
        "  def __init__(self, levels: list[int], eps: float = 1e-3):\n",
        "    self._levels = levels\n",
        "    self._eps = eps\n",
        "    self._levels_np = np.asarray(levels)\n",
        "    self._basis = np.concatenate(([1], np.cumprod(self._levels_np[:-1]))).astype(np.uint32)\n",
        "    self._implicit_codebook = self.indexes_to_codes(np.arange(self.codebook_size))\n",
        "    print(\"self._basis\",self._basis)\n",
        "    print(\"self._implicit_codebook\",self._implicit_codebook)\n",
        "\n",
        "  @property\n",
        "  def num_dimensions(self):\n",
        "    \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
        "    return len(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook_size(self):\n",
        "    \"\"\"Size of the codebook.\"\"\"\n",
        "    return np.prod(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook(self):\n",
        "    \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
        "    return self._implicit_codebook\n",
        "\n",
        "  def bound(self, z: jax.Array) -> jax.Array:\n",
        "    \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "    half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
        "    offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
        "    shift = jnp.tan(offset / half_l)\n",
        "    return jnp.tanh(z + shift) * half_l - offset\n",
        "\n",
        "  def quantize(self, z: jax.Array) -> Codeword:\n",
        "    \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
        "    quantized = round_ste(self.bound(z))\n",
        "\n",
        "    # Renormalize to [-1, 1].\n",
        "    half_width = self._levels_np // 2\n",
        "    return quantized / half_width\n",
        "\n",
        "  def _scale_and_shift(self, zhat_normalized):\n",
        "    # Scale and shift to range [0, ..., L-1]\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "  def _scale_and_shift_inverse(self, zhat):\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat - half_width) / half_width\n",
        "\n",
        "  def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
        "    \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
        "    assert zhat.shape[-1] == self.num_dimensions\n",
        "    zhat = self._scale_and_shift(zhat)\n",
        "    return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
        "\n",
        "  def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
        "    \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
        "    indices = indices[..., jnp.newaxis]\n",
        "    print(indices, self._basis, self._levels_np)\n",
        "    print(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    codes_non_centered = np.mod(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    return self._scale_and_shift_inverse(codes_non_centered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xHxv7ptuwVHX"
      },
      "outputs": [],
      "source": [
        "# @title FSQ torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module): # https://colab.research.google.com/github/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "    def __init__(self, levels, eps = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cat([torch.ones(1, device=device), torch.cumprod(self.levels[:-1], dim=0)]).long()\n",
        "        self.num_dimensions = len(levels)\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        # self.mean = self.codebook.mean(dim=0)\n",
        "        # self.max = self.codebook.max(dim=0).values\n",
        "        # self.min = self.codebook.min(dim=0).values\n",
        "\n",
        "    def bound(self, z):\n",
        "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "        half_l = (self.levels - 1) * (1 - self.eps) / 2 # [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "        # half_l = (self.levels-1)/2 # me ?\n",
        "        offset = torch.where(self.levels % 2 == 1, 0.0, 0.5) # [0.0000, 0.0000, 0.5000] mean?\n",
        "        # print(\"half_l\", half_l)\n",
        "        # shift = torch.tan(offset / half_l) # [0.0000, 0.0000, 1.5608] < tan(1)\n",
        "\n",
        "        # print(\"shift\", shift)\n",
        "        # print(\"bound\", torch.tanh(z + shift) * half_l - offset)\n",
        "\n",
        "        # print(f'half_l {half_l}, shift {shift}, bound {torch.tanh(z + shift) * half_l - offset}')\n",
        "        # return torch.tanh(z + shift) * half_l - offset\n",
        "        # return torch.tanh(z - shift) * half_l + offset\n",
        "        return torch.tanh(z) * half_l + offset\n",
        "\n",
        "    def forward(self, z):\n",
        "        quantized = ste_round(self.bound(z))\n",
        "        # print(\"quantized\", quantized)\n",
        "        half_width = self.levels // 2 # Renormalize to [-1, 1]\n",
        "        return quantized / half_width\n",
        "\n",
        "    def _scale_and_shift(self, zhat_normalized): # Scale and shift to range [0, ..., L-1]\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "    def _scale_and_shift_inverse(self, zhat):\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat - half_width) / half_width\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        assert zhat.shape[-1] == self.num_dimensions\n",
        "        zhat = self._scale_and_shift(zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).long()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes_non_centered = torch.fmod(indices // self.basis, self.levels)\n",
        "        return self._scale_and_shift_inverse(codes_non_centered)\n",
        "\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "# print(fsq.codebook)\n",
        "\n",
        "# batch_size, seq_len = 1, 1\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SnfcKPses5X",
        "outputId": "7c50a3e3-281a-4375-b86f-ece58f6775c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "half_l tensor([0.9990, 0.9990, 0.4995]), shift tensor([0.0000, 0.0000, 1.5608]), bound tensor([-0.4617,  0.5365, -0.0515])\n",
            "quantized tensor([0., 1., 0.])\n",
            "tensor([0., 1., 0.])\n"
          ]
        }
      ],
      "source": [
        "# @title test fsq\n",
        "fsq = FSQ(levels = [4])\n",
        "\n",
        "# 2: 1.6 half_l tensor([0.4995]), shift tensor([1.5608]), bound tensor([-0.5195])\n",
        "# 3: 0.6 # half_l tensor([0.9990]), shift tensor([0.]), bound tensor([-0.9207])\n",
        "# 4: 0.4, 1.3 # half_l tensor([1.4985]), shift tensor([0.3466]), bound tensor([-1.7726])\n",
        "# 5: 0.5, 1 # half_l [1.9980], shift [0.], bound [-1.8415]\n",
        "x = torch.tensor([.9],device=device)\n",
        "# x = torch.tensor([-1.6],device=device)\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.tensor([-0.6,0.6,-1.6],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,-1.5],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,1.6],device=device)\n",
        "x = torch.tensor([-0.5,0.6,-0.1],device=device)\n",
        "\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "round emb\n",
        "\n",
        "# half_l [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "# offset [0.0000, 0.0000, 0.5000] mean?\n",
        "# shift [0.0000, 0.0000, 1.5608] torch.tan(offset / half_l)\n",
        "# bound [-0.5365,  0.5365, -0.4696] tanh(z + shift) * half_l - offset\n",
        "\n",
        "\n",
        "\n",
        "levels = torch.tensor([3,3,2])\n",
        "eps = 1e-3\n",
        "\n",
        "half_l = (levels - 1) * (1 - eps) / 2\n",
        "offset = torch.where(levels % 2 == 1, 0.0, 0.5)\n",
        "# print(\"half_l\", half_l)\n",
        "shift = torch.tan(offset / half_l)\n",
        "# print(\"shift\", shift)\n",
        "# print(\"bound\", torch.tanh(x + shift) * half_l - offset)\n",
        "# return torch.tanh(x + shift) * half_l - offset\n",
        "out = torch.tanh(x) * half_l + offset\n",
        "print(out)\n",
        "\n",
        "shift=torch.tan(torch.tensor([1.]))\n",
        "print(shift)\n",
        "bound = torch.tanh(x - shift)\n",
        "print(bound)\n",
        "\n",
        "print(torch.tanh(torch.tensor([0.])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_VgsenYLpM",
        "outputId": "8c7b23ae-8cdb-4846-dae3-32fd046a4d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[0.0437, 0.3097, 0.4537]]], requires_grad=True)\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n"
          ]
        }
      ],
      "source": [
        "# @title test rnn_pred symlog\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "# fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # xx = fsq(x)\n",
        "    # xx = fsq(x.clone())\n",
        "    # print(xx)\n",
        "    # x = torch.tanh(x)\n",
        "    # loss = x.sum()\n",
        "    # loss = model(xx)\n",
        "    loss = model(x)\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    # x = torch.clamp(x, min=-1, max=1)\n",
        "    # x = torch.clamp(x.clone(), min=-1, max=1)\n",
        "    with torch.no_grad():\n",
        "        # x.clamp_(min=-1, max=1)\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # model = nn.Sequential(nn.Linear(3,1))\n",
        "# model = nn.Sequential(nn.Linear(3*2,1))\n",
        "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# batch_size = 1\n",
        "# seq_len = 3\n",
        "# x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# # torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "\n",
        "# def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "#     batch, seq_len, dim_a = la.shape\n",
        "#     cost = 0\n",
        "#     lsx=sx\n",
        "#     for t in range(seq_len): # simple single layer\n",
        "#         a = la[:,t] # [1, dim_a]\n",
        "#         sxaz = torch.cat([sx, a], dim=-1)\n",
        "#         # with torch.amp.autocast('cuda'):\n",
        "#         cost = cost + model(sxaz)\n",
        "#         lsx = torch.cat([lsx, sx], dim=0)\n",
        "#     return cost, sx\n",
        "\n",
        "\n",
        "# # def ste_clamp(input, min=-1, max=1):\n",
        "# #     clamped_output = torch.clamp(input, min, max)\n",
        "# #     clamp_mask = (input < min) | (input > max)\n",
        "# #     return torch.where(clamp_mask, input, clamped_output)\n",
        "\n",
        "# def ste_clamp(x, min=-1, max=1):\n",
        "#     return torch.clamp(x, min, max).detach() + x - x.detach()\n",
        "\n",
        "# def ste_abs(x): return x.sign() * x\n",
        "# def symlog(x): return torch.sign(x) * torch.log(ste_abs(x) + 1.0)\n",
        "# def symexp(x): return torch.sign(x) * torch.exp(ste_abs(x) - 1.0)\n",
        "\n",
        "\n",
        "# sx = torch.rand((batch_size,3),device=device)\n",
        "# sx_ = sx.detach()\n",
        "# for i in range(10): # num epochs\n",
        "#     # la = fsq(x.clone())\n",
        "#     la = fsq(x)\n",
        "#     print(i)\n",
        "#     print(x,x.requires_grad)\n",
        "#     print(la,la.requires_grad)\n",
        "#     loss, sx_ = rnn_pred(sx_, la)\n",
        "#     # loss.backward()\n",
        "#     loss.backward(retain_graph=True) # retain_graph bec fsq got tanh that creates new graph?\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     # x = torch.tanh(x)\n",
        "#     # x = torch.clamp(x, min=-1, max=1)\n",
        "#     # x = ste_clamp(x.clone(), min=-1, max=1)\n",
        "#     # x = symlog(x.clone())\n",
        "#     # sx_ = sx_.detach()\n",
        "\n",
        "\n",
        "# # print(xx)\n",
        "# print(x)\n",
        "# # print(xhat)\n",
        "# print(la)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YWmwVYhVVh5R"
      },
      "outputs": [],
      "source": [
        "# @title test ste_argmin\n",
        "import torch\n",
        "emb = torch.nn.Embedding(15, 3) # env.action_space # 15\n",
        "x = torch.rand(1,3)\n",
        "\n",
        "# def ste_argmin(x, dim=-1):\n",
        "#     idx = torch.argmin(x, dim)\n",
        "#     # out = torch.zeros_like(x)\n",
        "#     out = torch.zeros_like(idx).unsqueeze(-1)\n",
        "#     print(idx.shape, out.shape)\n",
        "#     out.scatter_(1, idx, 1)\n",
        "#     return out\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# def softargmin(x, beta=10):\n",
        "#     # Apply softmax to the negative of the input to approximate argmin\n",
        "#     weights = F.softmax(-x * beta, dim=-1)\n",
        "#     indices = torch.arange(x.size(-1), dtype=x.dtype, device=x.device)\n",
        "#     soft_argmin = torch.sum(weights * indices, dim=-1)\n",
        "#     return soft_argmin\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "# out = differentiable_argmax(-x)\n",
        "# print(out)\n",
        "\n",
        "\n",
        "# def softargmax1d(input, beta=100): # https://github.com/david-wb/softargmax/blob/master/softargmax.py\n",
        "#     *_, n = input.shape\n",
        "#     input = nn.functional.softmin(beta * input, dim=-1)\n",
        "#     indices = torch.linspace(0, 1, n)\n",
        "#     result = torch.sum((n - 1) * input * indices, dim=-1)\n",
        "#     return result\n",
        "\n",
        "# ste_round\n",
        "\n",
        "# # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "# dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "# print(lact)\n",
        "\n",
        "device='cpu'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "    dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    A=differentiable_argmax(-dist)\n",
        "    # print(A.shape)\n",
        "    print(torch.argmax(A))\n",
        "    x_=A@emb.weight.data\n",
        "    # print(\"dist\", dist.shape)\n",
        "    # lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = ste_argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = softargmin(dist)\n",
        "    # print(lact)\n",
        "    # x = emb.weight.data[lact]\n",
        "\n",
        "    # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "    print(\"x_\",x_)\n",
        "    # x = emb(x_)\n",
        "\n",
        "    loss = model(x_).sum()\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "x_ = torch.tensor([14])\n",
        "x = emb(x_)\n",
        "# print(x)\n",
        "# # print(emb.weight)\n",
        "# pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "pseudo_inverse_weight = torch.linalg.pinv(emb.weight)\n",
        "# weight_inv = torch.pinverse(emb.weight.T)\n",
        "\n",
        "dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "# print(x@pseudo_inverse_weight)\n",
        "# A=differentiable_argmax(-x@pseudo_inverse_weight)\n",
        "A=differentiable_argmax(-dist)\n",
        "print(A)\n",
        "\n",
        "# print(pseudo_inverse_weight.shape, pseudo_inverse_weight)\n",
        "# # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "# x_ = x@ pseudo_inverse_weight\n",
        "# print(\"x_\",x_)\n",
        "\n",
        "# print(emb.weight@ pseudo_inverse_weight)\n",
        "# dist=torch.dist(emb.weight@ pseudo_inverse_weight, torch.eye(15))\n",
        "# print(dist)\n",
        "# print(pseudo_inverse_weight@ emb.weight)\n",
        "\n",
        "# print(emb.weight@ weight_inv.T)\n",
        "# print(weight_inv.T@ emb.weight)\n",
        "\n",
        "# torch.linalg.lstsq(A, B).solution\n",
        "\n",
        "\n",
        "x_ = torch.tensor([4])\n",
        "embx = emb(x_) # emb.weight[x_,:]\n",
        "print(embx)\n",
        "\n",
        "Apinv = torch.linalg.pinv(A)\n",
        "x = embx@Apinv\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pGZld_gLH1RA"
      },
      "outputs": [],
      "source": [
        "# @title test bptt\n",
        "\n",
        "x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    loss=0\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        # loss = loss -stcost(xxx.clone()).sum()\n",
        "        loss = loss -stcost(xxx).sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "# RuntimeError: Output 1 of SplitBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size, T = 1,6\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "# optim = torch.optim.SGD([x], lr=1e-3)\n",
        "# # xx = torch.split(x, bptt, dim=1)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    loss=0\n",
        "    # xx = torch.split(x, bptt, dim=1)\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        loss = loss -stcost(xxx.clone()).sum()\n",
        "        # loss = loss -stcost(xxx).sum()\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jepapred = nn.Sequential(nn.Linear(3*2,3))\n",
        "stcost = nn.Sequential(nn.Linear(3,1))\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    for t in range(seq_len): # simple single layer\n",
        "        # print(la.shape)\n",
        "        a = la[:,t,:].clone() # [1, dim_a]\n",
        "        # sxaz = torch.cat([sx, a], dim=-1)\n",
        "        sxaz = torch.cat([sx.clone(), a.clone()], dim=-1)\n",
        "        # sxaz = torch.cat([sx.clone(), a], dim=-1)\n",
        "        sx = jepapred(sxaz)\n",
        "        tcost = -stcost(sx).sum()\n",
        "        lsx = torch.cat([lsx, sx], dim=0)\n",
        "        # print(lsx.requires_grad, sx.requires_grad)\n",
        "        # icost = 0.5*icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(icost.requires_grad)\n",
        "        cost += tcost# + icost\n",
        "    return cost, sx#, z\n",
        "\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "sx = torch.rand((batch_size,3),device=device)\n",
        "T = 6\n",
        "bptt = 3\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device)) # FSQ 3 levels\n",
        "x = torch.empty((batch_size, T, 3),device=device) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "# optim = torch.optim.SGD([x], lr=1e-3) #, maximize=True)\n",
        "# print(x.shape)\n",
        "# print(len(xx))\n",
        "# print(xx[0].shape)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    sx_ = sx.detach()\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "\n",
        "        # xxx=x\n",
        "        # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        la = fsq(xxx)\n",
        "        # la = xxx\n",
        "        # print(x,x.requires_grad)\n",
        "        # print(la,la.requires_grad)\n",
        "        # loss, sx_ = rnn_pred(sx_, la)\n",
        "        loss = -stcost(la).sum()\n",
        "\n",
        "        print(\"loss\",loss)\n",
        "        loss.backward()\n",
        "        # loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # sx_ = sx_.detach()\n",
        "        # print(loss.item(), lact)\n",
        "\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    x = torch.tanh(x) # clamp\n",
        "    print(x)\n",
        "    # print(x)\n",
        "print(\"search\",loss.item())\n",
        "# print(lact)\n",
        "# return la, lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # def search(self, sx, T=256, bptt=32):\n",
        "    # def search(self, sx, T=None, bptt=None):\n",
        "    #     if T==None: T = 256\n",
        "    #     if bptt==None: bptt = min(T,3)\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "    #     torch.nn.init.xavier_uniform_(x)\n",
        "    #     # optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "    #     # xx = torch.split(x, bptt, dim=1)\n",
        "    #     xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "    #     optim = torch.optim.SGD(xx, lr=1e7) #, maximize=True)\n",
        "\n",
        "    #     for _ in range(10): # num epochs\n",
        "    #         sx_ = sx.detach()\n",
        "    #         for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    #             # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "    #             la = fsq(xxx.clone())\n",
        "    #             # print(x,x.requires_grad)\n",
        "    #             # print(la,la.requires_grad)\n",
        "    #             loss, sx_ = self.rnn_pred(sx_, la)\n",
        "    #             loss.backward(retain_graph=True)\n",
        "    #             optim.step()\n",
        "    #             optim.zero_grad()\n",
        "    #             sx_ = sx_.detach()\n",
        "    #             # print(loss.item(), lact)\n",
        "    #             # xx = torch.tanh(xx) # clamp\n",
        "    #         xx = [torch.tanh(xxx) for xxx in xx]\n",
        "    #         x = torch.cat(xx,dim=1)\n",
        "    #         # x = torch.tanh(x) # clamp\n",
        "    #         print(x)\n",
        "    #     print(\"search\",loss.item())\n",
        "    #     # print(lact)\n",
        "    #     return la, lact # [batch_size, T]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jx0k_ndHOEMe"
      },
      "outputs": [],
      "source": [
        "# @title visualise kernels\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "# https://stackoverflow.com/questions/55594969/how-to-visualise-filters-in-a-cnn-with-pytorch\n",
        "\n",
        "layers = [0,3,6,9]\n",
        "layers = [0,3,6,9,12]\n",
        "layer = 9\n",
        "\n",
        "def visualise(model,layer):\n",
        "    kernels = model.cnn[layer].weight.data.clone()\n",
        "    n,c,w,h = kernels.shape\n",
        "    print(kernels.shape)\n",
        "    if c not in [1,3]:\n",
        "        # kernels = kernels.mean(dim=1, keepdim=True)\n",
        "        kernels = kernels[:,2,:,:].unsqueeze(dim=1)\n",
        "    nrow=10\n",
        "    rows = np.min((kernels.shape[0]//nrow + 1, 64))\n",
        "    grid = utils.make_grid(kernels, nrow=nrow, normalize=True, padding=1)\n",
        "    plt.figure(figsize=(nrow,rows))\n",
        "\n",
        "    kernels = kernels - kernels.min()\n",
        "    kernels = kernels / kernels.max()\n",
        "    filter_img = utils.make_grid(kernels, nrow = 12)\n",
        "    # change ordering since matplotlib requires images to\n",
        "    # be (H, W, C)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0))\n",
        "\n",
        "    # plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "# visualise(agent.sense,layer)\n",
        "visualise(agent.jepa.enc,layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "N2TGs69fnrZo",
        "outputId": "e7624553-e17a-4a9f-85a4-512720ed329a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tcost.1.weight torch.Size([2, 512])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRU(267, 256, batch_first=True, dropout=0.2)\n"
          ]
        }
      ],
      "source": [
        "# @title visualise lin\n",
        "# https://matplotlib.org/stable/plot_types/index.html\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for name, param in agent.jepa.pred.named_parameters(): # for param in model.parameters():\n",
        "# for name, param in agent.emb.named_parameters():\n",
        "for name, param in agent.tcost.named_parameters():\n",
        "    print(name, param.shape)\n",
        "    if len(param.shape)==1: param=param.unsqueeze(0)\n",
        "    Z=param.detach()#.numpy()\n",
        "\n",
        "    filter_img = utils.make_grid(Z, nrow = 12, normalize=True, padding=1)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0)) # (H, W, C)\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "    # pos=ax.imshow(Z)\n",
        "    # fig.colorbar(pos)\n",
        "    plt.show()\n",
        "\n",
        "print(agent.jepa.pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEWGq2WGi9a",
        "outputId": "649e3612-f156-496e-d8d5-fc576110e2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0015, -0.0132,  0.0280,  ...,  0.0297,  0.0289,  0.0152],\n",
            "        [ 0.0168,  0.0031, -0.0288,  ..., -0.0064, -0.0137, -0.0085]])\n"
          ]
        }
      ],
      "source": [
        "# print(vars(agent.jepa.pred.))\n",
        "# print(vars(agent.tcost.state_dict()))\n",
        "# print(agent.jepa.pred._parameters.keys())\n",
        "# print(agent.jepa.pred._parameters['weight_ih_l0'])\n",
        "# print(agent.jepa.pred._parameters['weight_hh_l2']) # weight_hh_l0, weight_hh_l2\n",
        "# print(agent.tcost.state_dict().keys())\n",
        "print(agent.tcost.state_dict()['tcost.1.weight']) # tcost.2.bias, tcost.4.bias\n",
        "# print(agent.tcost.named_parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90BTTw0Lr-t",
        "outputId": "a95870e2-bc89-43ba-d40b-febea4ce2382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 256])\n",
            "690080\n"
          ]
        }
      ],
      "source": [
        "# @title ConvEnc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ConvEnc(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[5], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[5], d_list[5], 2, 2, 0), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # 2457024\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # 685248\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 4, 2, 2), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 4, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 4, 2, 2), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 4, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # # #\n",
        "\n",
        "\n",
        "            nn.Conv2d(1, d_list[0], 4, 4, 0), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 4, 4, 0), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 4, 4, 0), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 4, 4, 0), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            #\n",
        "\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[5],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "\n",
        "convenc = ConvEnc(256).to(device)\n",
        "input = torch.rand((4,1,256,256), device=device)\n",
        "out = convenc(input)\n",
        "print(out.shape)\n",
        "print(sum(p.numel() for p in convenc.parameters() if p.requires_grad)) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S_xnBFjXVxgz"
      },
      "outputs": [],
      "source": [
        "# @title transfer weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "d = 10  # size of the first dimension\n",
        "a = 5   # size of the extra nodes to omit\n",
        "m = 8   # output dimension\n",
        "\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "target_layer = nn.Linear(d, m)\n",
        "# source_layer = nn.Linear(d, m)\n",
        "# target_layer = nn.Linear(d+a, m)\n",
        "\n",
        "def transfer(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt.weight[:, :src.weight.shape[1]].copy_(src.weight[:, :tgt.weight.shape[1]])\n",
        "        tgt.bias.copy_(src.bias)\n",
        "    return tgt,src\n",
        "\n",
        "target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "src_sd = source_layer.state_dict()\n",
        "tgt_sd = target_layer.state_dict()\n",
        "\n",
        "def transfersd(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt['weight'][:, :src['weight'].shape[1]].copy_(src['weight'][:, :tgt['weight'].shape[1]])\n",
        "        tgt['bias'].copy_(src['bias'])\n",
        "    return tgt\n",
        "\n",
        "tgt_sd = transfersd(tgt_sd, src_sd)\n",
        "target_layer.load_state_dict(tgt_sd)\n",
        "\n",
        "\n",
        "agent_src = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "\n",
        "# agent.tcost = TCost((1+agent.jepa.pred.num_layers)*agent.d_model) # replace tcost\n",
        "\n",
        "agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# agent.jepa.pred\n",
        "# target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(vars(agent.jepa.pred))\n",
        "# gru = agent.jepa.pred\n",
        "# gru = agent_src.jepa.pred\n",
        "# for wht_name in gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, gru._parameters[wht_name].shape)\n",
        "\n",
        "# weight_ih_l0 dim_z=3: [768, 262] , dim_z=1: [768, 260]\n",
        "# weight_hh_l0 torch.Size([768, 256])\n",
        "# bias_ih_l0 torch.Size([768])\n",
        "# bias_hh_l0 torch.Size([768])\n",
        "\n",
        "# tgt_gru = agent.jepa.pred\n",
        "# src_gru = agent_src.jepa.pred\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "\n",
        "tgt_gru[]\n",
        "def transfer_gru(tgt_gru, src_gru): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for i in range(min(len(tgt_gru._all_weights), len(src_gru._all_weights))):\n",
        "        # for lyr in tgt_gru._all_weights:\n",
        "            lyr = tgt_gru._all_weights[i]\n",
        "            for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "                # print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "                tgt_wht, src_wht = tgt_gru._parameters[wht_name], src_gru._parameters[wht_name]\n",
        "                if len(tgt_wht.shape)==2:\n",
        "                    tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "                elif len(tgt_wht.shape)==1:\n",
        "                    tgt_gru._parameters[wht_name] = src_wht\n",
        "    return tgt_gru\n",
        "tgt_gru = transfer_gru(tgt_gru, src_gru)\n",
        "\n",
        "# for wht_name in tgt_gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d_model=256; dim_a=3; dim_z=1; dim_v=512\n",
        "\n",
        "pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "# pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "print(pred._all_weights)\n",
        "for lyr in pred._all_weights:\n",
        "    for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "        print(wht_name, pred._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(pred.state_dict().keys())\n",
        "\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "print(tgt_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "print(src_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "\n",
        "print(tgt_gru.state_dict()['bias_ih_l0'][:10])\n",
        "print(src_gru.state_dict()['bias_ih_l0'][:10])\n",
        "tgt_gru.state_dict().keys()\n",
        "src_gru.state_dict().keys()\n",
        "\n",
        "# tgt_gru\n",
        "# src_gru\n",
        "for wht_name in tgt_gru.state_dict().keys():\n",
        "    if not wht_name in src_gru.state_dict().keys(): continue\n",
        "    print(wht_name)\n",
        "    # print(tgt_gru.state_dict()[wht_name])\n",
        "    # tgt_gru.state_dict()[wht_name].copy_(src_gru.state_dict()[wht_name])\n",
        "\n",
        "tgt_sd = tgt_gru.state_dict()\n",
        "src_sd = src_gru.state_dict()\n",
        "def transfer_sd(tgt_sd, src_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            # print(wht_name)\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            if len(tgt_wht.shape)==2:\n",
        "                tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "            elif len(tgt_wht.shape)==1:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "    return tgt_sd\n",
        "tgt_sd = transfer_sd(tgt_sd, src_sd)\n",
        "print(tgt_sd['weight_ih_l0'][0][:10])\n",
        "print(tgt_sd['bias_ih_l0'][:10])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwApoQMMKzB",
        "outputId": "98f67f91-ef5b-406f-b852-5a93130f9e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0012018680572509766\n",
            "tensor([0.2797, 0.2218, 0.2731, 0.3268, 0.2632, 0.2914, 0.3217, 0.2845])\n"
          ]
        }
      ],
      "source": [
        "# @title test init norm\n",
        "print(agent.emb.state_dict()['weight'].norm(dim=-1))\n",
        "\n",
        "# x = torch.rand(16)\n",
        "x = torch.rand(8,16)\n",
        "# print(x)\n",
        "# torch.nn.init.normal_(x, mean=0.0, std=1.0)\n",
        "# torch.nn.init.xavier_normal_(x)\n",
        "import time\n",
        "start = time.time()\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # 0.00966, 0.000602, 0.0004\n",
        "# torch.nn.init.normal_(x, mean=0.0, std=1./x.shape[-1]**0.5)\n",
        "torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "print(time.time()-start)\n",
        "# std = ((Sum (xi-mean)^2)/ N)^(1/2)\n",
        "# print(x)\n",
        "# print(((x**2).sum())**(0.5))\n",
        "print(torch.norm(x, dim=-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B1yvJkX89C_o"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein\n",
        "import torch\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    # cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    # dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # cs = (x-y).cumsum(dim=-1)\n",
        "    cs = (x-y) @ torch.tril(torch.ones(x.shape[0], x.shape[0]))\n",
        "    # dist = weight * torch.abs(cs)\n",
        "    dist = weight * cs**2\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "\n",
        "def soft_wasserstein_loss(x, y, smoothing=0.1):\n",
        "    # Normalise distributions\n",
        "    x = x / x.sum()\n",
        "    y = y / y.sum()\n",
        "    # Compute the cumulative distributions (CDFs) with a small smoothing factor\n",
        "    cdf_x = torch.cumsum(x, dim=-1) + smoothing\n",
        "    cdf_y = torch.cumsum(y, dim=-1) + smoothing\n",
        "    # Compute smooth Wasserstein distance (L2 distance between CDFs)\n",
        "    distance = torch.norm(cdf_x - cdf_y, p=2)  # L2 distance instead of L1 for smoother gradients\n",
        "    return distance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5], dtype=float))\n",
        "x = nn.Parameter(torch.tensor([-0.01, -0.0, -0.99], dtype=torch.float))\n",
        "y = torch.tensor([0.0, 0.0, -1.0], dtype=torch.float)\n",
        "\n",
        "# x = nn.Parameter(torch.rand(1024, dtype=float))\n",
        "# y = torch.rand(1024, dtype=float)\n",
        "# a = len(train_data.buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "a=1/45\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "print(weight)\n",
        "dist = wasserstein(x, y, weight=weight)\n",
        "print(time.time() - start)\n",
        "print(dist)  # Should output 0.7\n",
        "# dist.backward()\n",
        "\n",
        "# 0.0004496574401855469\n",
        "# 0.000331878662109375\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3nfZRhVc9Ssp"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein sinkhorn train\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# agent.eval()\n",
        "# batch_size, T, _ = sx.shape\n",
        "x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3) # 3e3\n",
        "# optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.999)) # ? 1e0 ; 3e-2 1e-1\n",
        "# optim = torch.optim.AdamW([x], 1e-0, (0.9, 0.95)) # ? 1e0 ; 3e-2 1e-1\n",
        "y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=torch.float)\n",
        "a=1/45\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "# print(weight)\n",
        "\n",
        "# loss = wasserstein(x, y, weight=weight)\n",
        "# loss = wasserstein(x, y)\n",
        "# loss = sinkhorn(x, y)\n",
        "# loss.backward()\n",
        "# print(x.grad)\n",
        "\n",
        "\n",
        "for i in range(50): # num epochs\n",
        "    loss = wasserstein(x, y, weight=weight)\n",
        "    # loss = sinkhorn(x, y)\n",
        "    # loss = sinkhorn(x, y,0.05,80)\n",
        "    loss.sum().backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(x.data, loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "def sinkhorn(x, y, epsilon=0.05, max_iters=100):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "\n",
        "    # Compute the cost matrix: here the cost is the squared distance between indices\n",
        "    # (|i-j|^2 for each position i, j)\n",
        "    posx = torch.arange(x.shape[-1], dtype=torch.float).unsqueeze(1)\n",
        "    posy = torch.arange(y.shape[-1], dtype=torch.float).unsqueeze(0)\n",
        "    cost_matrix = (posx - posy).pow(2)  # squared distance\n",
        "\n",
        "    # Initialize the dual variables\n",
        "    u = torch.zeros_like(x)\n",
        "    v = torch.zeros_like(y)\n",
        "\n",
        "    # Sinkhorn iterations\n",
        "    K = torch.exp(-cost_matrix / epsilon)  # Kernel matrix, regularised with epsilon\n",
        "    for _ in range(max_iters):\n",
        "        u = x / (K @ (y / (K.t() @ u + 1e-8)) + 1e-8)\n",
        "        v = y / (K.t() @ (x / (K @ v + 1e-8)) + 1e-8)\n",
        "    # print(K,u.data,v.data)\n",
        "    plan = torch.diag(u) @ K @ torch.diag(v)\n",
        "    dist = torch.sum(plan * cost_matrix)\n",
        "    return dist\n",
        "\n",
        "# Example\n",
        "x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float, requires_grad=True)\n",
        "y = torch.tensor([0.0, 0.0, 1.0], dtype=torch.float)\n",
        "# x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "# y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=float)\n",
        "\n",
        "# dist = sinkhorn(x, y)\n",
        "dist = sinkhorn(x, y, 0.05,80)\n",
        "dist.backward()  # To compute gradients with respect to x\n",
        "\n",
        "print(dist.item())\n",
        "print(x.grad)\n",
        "\n",
        "# [2.0000e+07, 3.0000e+07, 1.0000e-08]) tensor([       0.,        0., 49999996.] episodes>=80\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s1_GgDzoDyYB"
      },
      "outputs": [],
      "source": [
        "# @title torchrl.data.PrioritizedReplayBuffer\n",
        "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
        "buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
        "\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "buffer_lazymemmap = ReplayBuffer(storage=LazyMemmapStorage(size), batch_size=32, sampler=SamplerWithoutReplacement())\n",
        "\n",
        "\n",
        "from torchrl.data import ListStorage, PrioritizedReplayBuffer\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "rb = PrioritizedReplayBuffer(alpha=0.7, beta=0.9, storage=ListStorage(10))\n",
        "data = range(10)\n",
        "rb.extend(data)\n",
        "# rb.extend(buffer)\n",
        "\n",
        "\n",
        "sample = rb.sample(3)\n",
        "print(sample)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_UlGz6Xoq3"
      },
      "source": [
        "## plot 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VX5IExbRriwm"
      },
      "outputs": [],
      "source": [
        "# @title sklearn RBF\n",
        "# https://gist.github.com/eljost/2c4e1af652ef02b2989da341c5569af7\n",
        "# from nn_plot.ipynb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import scipy.stats as st\n",
        "\n",
        "# np.random.seed(1)\n",
        "def func(x):\n",
        "    # print(x.shape)\n",
        "    # x= np.sum(x**2, axis=-1)\n",
        "    x=np.random.rand(x.shape[0])\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "res = 50\n",
        "num_pts=15\n",
        "X=np.random.rand(num_pts,2)*res\n",
        "# Y = func(X)\n",
        "Y=np.random.rand(num_pts)\n",
        "# print(X);print(Y)\n",
        "\n",
        "lim = 1\n",
        "# lin = np.linspace(-lim, lim, res)\n",
        "lin = np.linspace(0, res, res)\n",
        "x1, x2 = np.meshgrid(lin, lin)\n",
        "xx = np.vstack((x1.flatten(), x2.flatten())).T\n",
        "\n",
        "kernel = RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X, Y)\n",
        "# print(\"Learned kernel\", gp.kernel_)\n",
        "y_mean, y_cov = gp.predict(xx, return_cov=True)\n",
        "\n",
        "posteriors = st.multivariate_normal.rvs(mean=y_mean, cov=y_cov, size=1)\n",
        "\n",
        "ax = plt.figure().add_subplot(projection='3d')\n",
        "Z=posteriors.reshape(-1, res)\n",
        "# ax.plot_surface(x1, x2, Z)\n",
        "ax.plot_surface(x1, x2, Z, cmap='rainbow', alpha=0.7)\n",
        "\n",
        "# ax.plot_surface(x1, x2, posteriors.reshape(-1, res))\n",
        "ax.contour(x1, x2, Z, zdir='z', offset=-1, cmap='coolwarm') # https://matplotlib.org/stable/gallery/mplot3d/contour3d_3.html#sphx-glr-gallery-mplot3d-contour3d-3-py\n",
        "# ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-0.4, 0.5))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-1, 2))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, c=zdata, cmap='Greens');\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, cmap='Greens');\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusX7gpzxFNL",
        "outputId": "9f14a9da-e188-49ba-f5f5-70192ff33134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.6321], grad_fn=<AddBackward0>)\n",
            "tensor([2.7358]) tensor([-4.7358])\n"
          ]
        }
      ],
      "source": [
        "# @title chatgpt RBFKernelLayer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RBFKernelLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(RBFKernelLayer, self).__init__()\n",
        "        self.centres = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        dists = torch.cdist(x, self.centres, p=2) ** 2\n",
        "        return torch.exp(-dists / (2 * self.sigma ** 2))\n",
        "\n",
        "class SaddlePointNetwork(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(SaddlePointNetwork, self).__init__()\n",
        "        self.rbf_layer = RBFKernelLayer(in_features, out_features, sigma)\n",
        "        self.linear = nn.Linear(out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rbf_output = self.rbf_layer(x)\n",
        "        # Introduce a saddle point structure\n",
        "        linear_output = self.linear(rbf_output)\n",
        "        # Example saddle function: x^2 - y^2\n",
        "        saddle_output = torch.sum(linear_output[:, :1]**2 - linear_output[:, 1:]**2, dim=1, keepdim=True)\n",
        "        return saddle_output\n",
        "\n",
        "# sin(ax)sin(bx)\n",
        "# (x^2 - y^2)\n",
        "import torch\n",
        "\n",
        "def rbf_saddle(x, y, gamma=1.0, a=1.0, b=1.0):\n",
        "    # RBF-like term\n",
        "    rbf_term = torch.exp(-gamma * torch.norm(x - y, p=2)**2)\n",
        "    # Saddle point term\n",
        "    saddle_term = (a * x)**2 - (b * y)**2\n",
        "    return rbf_term + saddle_term\n",
        "\n",
        "# Example usage\n",
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "output = rbf_saddle(x, y)\n",
        "print(output)\n",
        "\n",
        "# Compute gradients\n",
        "output.backward()\n",
        "print(x.grad, y.grad)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rTmCo7pm0NxL"
      },
      "outputs": [],
      "source": [
        "# @title plot 3d\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "y = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "X, Y = torch.meshgrid(x, y)\n",
        "Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7fWZaQTDFg1",
        "outputId": "4c5ced88-54f1-436e-89f9-66f1c8396373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000, -0.7231,  0.3792,  0.0000]]) tensor([0.3362])\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# @title shape NN\n",
        "num_pts=1\n",
        "\n",
        "# X=torch.rand(num_pts,4)*2-1\n",
        "# X=torch.cat([torch.tensor([0,0]).unsqueeze(0),torch.rand(num_pts,2)*2-1], dim=-1)\n",
        "X=torch.cat([torch.zeros(1,1),torch.rand(num_pts,2)*2-1,torch.zeros(1,1)], dim=-1)\n",
        "Y=torch.rand(num_pts)\n",
        "print(X,Y)\n",
        "optim = torch.optim.SGD(model.parameters(), 1e-1)\n",
        "\n",
        "# model.train()\n",
        "pred = model(X)\n",
        "# print(Y.shape,pred.shape)\n",
        "# loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "loss = F.mse_loss(Y, pred.squeeze(-1))\n",
        "loss.backward()\n",
        "optim.step()\n",
        "optim.zero_grad()\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "boDd__PE2sGy"
      },
      "outputs": [],
      "source": [
        "# @title plot NN\n",
        "\n",
        "xx = torch.linspace(-1, 1, 100)\n",
        "yy = torch.linspace(-1, 1, 100)\n",
        "X, Y = torch.meshgrid(xx, yy) # [100,100]\n",
        "xy = torch.cat([X.unsqueeze(-1), torch.zeros(X.shape+(2,)), Y.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "with torch.no_grad(): Z = model(xy).squeeze(-1)\n",
        "# print(Z)\n",
        "# print(Z.shape)\n",
        "\n",
        "# Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qW6BYoXsX57o"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle same time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def f(x, y):\n",
        "    return x ** 2 - y ** 2 + x * y\n",
        "# (x-y)(x+y)+xy\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "dim_x, dim_z = 3, 8\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "xx = torch.empty((1, T, dim_x))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "# x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "\n",
        "# tensor([[0.6478, 0.0531, 0.0861]]) tensor([[-1.,  1.]]) 0.2974517047405243\n",
        "# tensor([-0.9419, -1.0000,  0.4416, -1.0000,  1.0000,  0.2963])\n",
        "\n",
        "# x = nn.Parameter(torch.tensor([[0.6478, 0.0531, 0.0861]]))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "z = nn.Parameter(torch.empty((batch, T, dim_z)))\n",
        "# z = torch.empty((1, T, 1))\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# z = nn.Parameter(z.repeat(batch,1,1))\n",
        "# z = nn.Parameter(torch.tensor([[-1.,  1.]]))\n",
        "# optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "# optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.95), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "# .95,1e-1,3e-1\n",
        "# .99,\n",
        "\n",
        "d_model = 4\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(10): # num epochs\n",
        "    # loss = f(x,z)\n",
        "    # loss = f(x.sum(-1),z)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step(); optim_z.step()\n",
        "    optim_x.zero_grad(); optim_z.zero_grad()\n",
        "    # print(i,x.squeeze(), z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    print(i,x.squeeze()[0].data, z[0].squeeze().data, loss[0].squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "        z.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "print(loss.squeeze())\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "# idx = torch.argmax(loss)\n",
        "# print(x[idx],z[idx],loss[idx])\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GJdFpDr2wIMT"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle argm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def argm(sx, lr=3e3): # 3e3\n",
        "    # batch=sx.size(dim=0)\n",
        "    batch_size, T, _ = sx.shape\n",
        "    batch = 16\n",
        "    # z = nn.Parameter(torch.zeros((batch,1),device=device))\n",
        "    # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "    z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "    torch.nn.init.xavier_uniform_(z)\n",
        "    # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "    # sx = sx.detach()\n",
        "    for i in range(20): # 10\n",
        "        # print(sx.shape,z.shape)\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            cost = model(sxz)\n",
        "        cost.sum().backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "        # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    # return z.detach()\n",
        "    print(cost.squeeze().data)\n",
        "    idx = torch.argmax(cost.squeeze(), dim=1)\n",
        "    return z[torch.arange(z.shape[0]),idx].detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# x = nn.Parameter(xx.clone())\n",
        "x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "# ratio = 6e0\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(50):\n",
        "    z = argm(x)\n",
        "    # print(x.shape,z.shape)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "# print(\"z\",z)\n",
        "# print(loss.squeeze())\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvjIJP6RlEv2",
        "outputId": "447fdefd-452b-437d-c228-1847492b36f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.randn(16, 16)\n",
        "# print((b==torch.max(b)).nonzero())\n",
        "x = torch.randn(10, 3)\n",
        "idx = torch.randint(3,(10,))\n",
        "# print(x[:,idx].shape)\n",
        "print(x[torch.arange(x.shape[0]),idx].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gJ3X_hQelW2x"
      },
      "outputs": [],
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wi4ODp-XlZoU"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QYbOgNoZn6JL"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_kcajtpjr7Io"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "outputs": [],
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "    def get_down(self, state, world_state=None): # update world_state and mem from state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        return world_state\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    world_state = self.get_down(state, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "                    sy = self.effnet(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "\n",
        "                    world_state_ = self.deconvenc(sy).squeeze(1) # ae\n",
        "                    # loss = F.mse_loss(world_state_, world_state)\n",
        "                    loss = F.mse_loss(world_state_, world_state.detach())\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cX71EprCMSNG"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim bad?\n",
        "\n",
        "import torch\n",
        "\n",
        "def transfer_optim(src_optim, tgt_optim, param_mapping):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    tgt_sd = tgt_optim.state_dict()\n",
        "\n",
        "    # Iterate over each parameter in the target optimizer\n",
        "    for (tgt_idx, target_param) in enumerate(tgt_optim.param_groups[0]['params']):\n",
        "        target_id = id(target_param)\n",
        "\n",
        "        # Find the corresponding source parameter using param_mapping\n",
        "        if target_id in param_mapping:\n",
        "            source_param = param_mapping[target_id]\n",
        "            source_id = id(source_param)\n",
        "\n",
        "            # If there's an existing state for the source parameter, transfer it\n",
        "            if source_id in src_sd['state']:\n",
        "                source_state = src_sd['state'][source_id]\n",
        "                target_state = {}\n",
        "\n",
        "                # Handle momentum/first and second moments (e.g., `exp_avg`, `exp_avg_sq` in Adam)\n",
        "                for key in source_state.keys():\n",
        "                    if source_state[key].shape == target_param.shape: target_state[key] = source_state[key].clone()\n",
        "                    # If size doesn't match, either copy what you can or initialise new values\n",
        "                    elif key in ['exp_avg', 'exp_avg_sq']:  # Momentums (specific to Adam-like optimizers)\n",
        "                        target_state[key] = torch.zeros_like(target_param)\n",
        "                        target_state[key][:source_param.numel()] = source_state[key].flatten()[:target_param.numel()]\n",
        "                    else: target_state[key] = torch.zeros_like(target_param) # init\n",
        "                tgt_sd['state'][target_id] = target_state\n",
        "\n",
        "    # Load the updated state dict back into the target optimizer\n",
        "    tgt_optim.load_state_dict(tgt_sd)\n",
        "    return tgt_optim\n",
        "# {'state': {0: {'step': tensor(1.), 'exp_avg': tensor, 'exp_avg_sq': tensor}, 1: }}\n",
        "\n",
        "\n",
        "\n",
        "model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "source_optimizer = optim.AdamW(model_src.parameters())\n",
        "target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "dummy_input = torch.randn(3, 10)\n",
        "dummy_target = torch.randn(3, 5)\n",
        "criterion = torch.nn.MSELoss()\n",
        "output = model_src(dummy_input)\n",
        "loss = criterion(output, dummy_target)\n",
        "loss.backward()\n",
        "source_optimizer.step()\n",
        "\n",
        "param_mapping = {id(tgt_param): src_param for src_param, tgt_param in zip(model_src.parameters(), model_tgt.parameters())}\n",
        "target_optimizer = transfer_optim(source_optimizer, target_optimizer, param_mapping)\n",
        "\n",
        "print(source_optimizer.state_dict())\n",
        "print(target_optimizer.state_dict())\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "\n",
        "# optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title transfer_optim bad? 2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    opt_state_dict = optimizer.state_dict()\n",
        "    for group in opt_state_dict['param_groups']:\n",
        "        # For each parameter index (p in param group refers to the layer parameters)\n",
        "        for param_idx, p in enumerate(group['params']):\n",
        "            print(p,source_layer.weight)\n",
        "            if p == source_layer.weight:\n",
        "                # Find the corresponding target layer parameter (in this case, target_layer.weight)\n",
        "                target_param = target_layer.weight\n",
        "                source_state = optimizer.state[p]  # Get the state for the source parameter\n",
        "\n",
        "                # If the parameter is found in the optimizer's state dict\n",
        "                if 'exp_avg' in source_state and 'exp_avg_sq' in source_state:\n",
        "                    exp_avg = source_state['exp_avg']  # First moment (momentum)\n",
        "                    exp_avg_sq = source_state['exp_avg_sq']  # Second moment (variance)\n",
        "\n",
        "                    # Handle input dimension mismatch (copy/truncate or pad)\n",
        "                    source_in_dim = source_layer.weight.shape[1]\n",
        "                    target_in_dim = target_layer.weight.shape[1]\n",
        "\n",
        "                    # Copy optimizer state (exp_avg and exp_avg_sq) accordingly\n",
        "                    with torch.no_grad():\n",
        "                        # Copy the available part and initialize new dimensions to zero\n",
        "                        new_exp_avg = torch.zeros_like(target_param)\n",
        "                        new_exp_avg_sq = torch.zeros_like(target_param)\n",
        "                        # new_exp_avg[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        # new_exp_avg_sq[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        new_exp_avg[:, :source_in_dim] = exp_avg[:, :target_in_dim]\n",
        "                        new_exp_avg_sq[:, :source_in_dim] = exp_avg_sq[:, :target_in_dim]\n",
        "\n",
        "                    # Update the target layer's optimizer state\n",
        "                    optimizer.state[target_param] = {\n",
        "                        'exp_avg': new_exp_avg,\n",
        "                        'exp_avg_sq': new_exp_avg_sq,\n",
        "                        'step': source_state['step']  # Keep the same step count\n",
        "                    }\n",
        "\n",
        "                # Handle the bias (if it exists)\n",
        "                if hasattr(source_layer, 'bias') and hasattr(target_layer, 'bias'):\n",
        "                    source_bias = optimizer.state[source_layer.bias]\n",
        "                    target_bias = target_layer.bias\n",
        "\n",
        "                    optimizer.state[target_bias] = source_bias\n",
        "    return optimizer\n",
        "\n",
        "# Example usage:\n",
        "d = 10  # Input dimension of the source layer\n",
        "a = 5   # Extra nodes to be omitted or added in the target layer\n",
        "m = 8   # Output dimension (same for both)\n",
        "\n",
        "# Source layer (input dimension d+a)\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "\n",
        "# Target layer (input dimension d, or d+a, or arbitrary)\n",
        "target_layer = nn.Linear(d, m)\n",
        "\n",
        "# Optimizer (using AdamW in this case)\n",
        "optimizer = torch.optim.AdamW(source_layer.parameters())\n",
        "\n",
        "# Perform weight transfer (from d+a to d or vice versa) here (assumed done already)\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "# Transfer optimizer states\n",
        "optimizer = transfer_optimizer_state(source_layer, target_layer, optimizer)\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    state_dict = optimizer.state_dict()\n",
        "    for old_param, new_param in zip(source_layer.parameters(), target_layer.parameters()):\n",
        "        # If old_param exists in optimizer state\n",
        "        if old_param in state_dict['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = state_dict['state'][old_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                if key in ['exp_avg', 'exp_avg_sq']:  # for Adam or AdamW momentum estimates\n",
        "                    # Handle the shape adjustment (copy, shrink, or randomly initialise the extra nodes)\n",
        "                    new_state[key] = torch.zeros_like(new_param)  # Initialise with zeros\n",
        "                    new_state[key][:old_param.shape[0]] = value[:new_param.shape[0]]  # Copy old values\n",
        "                    # else:\n",
        "                    #     new_state[key] = value.clone()  # Copy directly if shapes match\n",
        "                else:\n",
        "                    new_state[key] = value  # Copy other states directly if they exist\n",
        "\n",
        "            # Set the new parameter in optimizer state\n",
        "            state_dict['state'][new_param] = new_state\n",
        "            # Remove the old parameter from the optimizer state\n",
        "            del state_dict['state'][old_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(state_dict)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optim(src_model, tgt_model, src_optim, tgt_optim):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    for src_param, tgt_param in zip(src_model.parameters(), tgt_model.parameters()):\n",
        "        # If src_param exists in optimizer state\n",
        "        if src_param in src_sd['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = src_sd['state'][src_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                new_state[key] = torch.zeros_like(tgt_param)  # Initialise with zeros\n",
        "                new_state[key][:src_param.shape[0]] = value[:tgt_param.shape[0]]  # Copy old values\n",
        "\n",
        "            src_sd['state'][tgt_param] = new_state\n",
        "            del src_sd['state'][src_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(src_sd)\n",
        "    return optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "LKUSzmYLLuRh",
        "outputId": "07ca4b89-257b-4205-c5c8-6a96474ae82a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-186620617543>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# j=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mwht_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwht_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title rename wht_name\n",
        "# wht_name='jepa.enc.cnn.0.weight'\n",
        "wht_name='jepa.pred.weight_ih_l0'\n",
        "# wht_name='emb.weight'\n",
        "# print(o.isnumeric())\n",
        "# mask = [x.isnumeric() for x in o]\n",
        "# print(o[mask])\n",
        "na_=''\n",
        "# j=0\n",
        "\n",
        "for wht_name in agent.state_dict().keys():\n",
        "    o=wht_name.split('.')\n",
        "    # print(o)\n",
        "    name=wht_name\n",
        "    print(\"####\", wht_name)\n",
        "    for i in range(len(o)):\n",
        "        c = o[i]\n",
        "        if c.isnumeric():\n",
        "            na = '.'.join(o[:i])\n",
        "            me = '.'.join(o[i+1:])\n",
        "            # print(c_,c, c_<c, )\n",
        "            c=int(c)\n",
        "            if na!=na_: # param name diff\n",
        "                j=0 # reset num\n",
        "                c_=c # track wht_name num\n",
        "                na_=na # track param name\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('1', name)\n",
        "            elif c_<c: # same param name, diff num\n",
        "                j+=1\n",
        "                c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('2', name)\n",
        "            else: # same param name, same num\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('3', name)\n",
        "    print('4', name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CACQCCaxA_Y",
        "outputId": "b5d127cd-18ce-49e5-b1e2-d883cb34125a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1746836772511624\n"
          ]
        }
      ],
      "source": [
        "# @title geomloss, Python Optimal Transport\n",
        "# !pip install geomloss[full]\n",
        "\n",
        "import torch\n",
        "from geomloss import SamplesLoss  # See also ImagesLoss, VolumesLoss\n",
        "\n",
        "# # Create some large point clouds in 3D\n",
        "# x = torch.randn(100000, 3, requires_grad=True).cuda()\n",
        "# y = torch.randn(200000, 3).cuda()\n",
        "\n",
        "# x = torch.rand(1000, 1)\n",
        "# y = torch.rand(1000, 1)\n",
        "x = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "y = torch.tensor([0, 1, 0]).float().unsqueeze(-1)\n",
        "# k=1.\n",
        "# y = torch.tensor([k, k, k]).float().unsqueeze(-1)\n",
        "\n",
        "\n",
        "\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01) # 0.05, quadratic, Wasserstein-2. low blur => closer to true Wasserstein dist but slower compute\n",
        "\n",
        "loss = loss_fn(x, y)  # By default, use constant weights = 1/number of samples\n",
        "print(loss)\n",
        "# g_x, = torch.autograd.grad(L, [x])\n",
        "\n",
        "# [0, 1, 0]: 2.4253e-12, 2.4253e-12\n",
        "# [0, 0, 0.1]: 0.1350; [0, 0, 0.5]: 0.0417; [0, 0, 1]: 0\n",
        "# k=0.: 0.1666; k=0.1: 0.1383; k=0.333: 0.1111; k=0.5: 0.1250; k=1.: 0.3333\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from geomloss import SamplesLoss\n",
        "\n",
        "# Define x and y as n-dimensional tensors representing mass distributions\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# y = torch.tensor([0, 0, 1], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# x = torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1))\n",
        "x = nn.Parameter(torch.tensor([0,1.5,0]).float().unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "\n",
        "# Create a position tensor representing the index of each element\n",
        "positions_x = torch.arange(x.shape[0], dtype=float).unsqueeze(1)\n",
        "positions_y = torch.arange(y.shape[0], dtype=float).unsqueeze(1)\n",
        "\n",
        "# Sinkhorn loss using GeomLoss\n",
        "loss_fn = SamplesLoss(\"sinkhorn\", p=1, blur=0.05)  # p=1 for Wasserstein-1\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=1, blur=0.05, scaling=0.9, debias=True)\n",
        "\n",
        "transport_cost = loss_fn(positions_x, x, positions_y, y)\n",
        "\n",
        "print(transport_cost.item())\n",
        "# 1.298424361328248\n",
        "\n",
        "transport_cost.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pip install POT\n",
        "\n",
        "import ot\n",
        "import numpy as np\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / np.sum(x)\n",
        "    # y = y / np.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = np.abs(np.arange(n)[:, None] - np.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = np.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "x = np.array([0.2, 0.3, 0.5])\n",
        "y = np.array([0, 0, 1])\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "# distance.backward()\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / torch.sum(x)\n",
        "    # y = y / torch.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = torch.abs(torch.arange(n)[:, None] - torch.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = torch.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "# x = np.array([0.2, 0.3, 0.5])\n",
        "# y = np.array([0, 0, 1])\n",
        "x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float())#.unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float()#.unsqueeze(-1)\n",
        "\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "distance.backward()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MqBL9hljvW-5"
      },
      "outputs": [],
      "source": [
        "# @title batchify argm train\n",
        "\n",
        "def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "    self.jepa.pred.train()\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "    lsx=sx.unsqueeze(1)\n",
        "    h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "    lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "    # print(lsx.shape, la.shape, lz.shape)\n",
        "    c=[]\n",
        "    for t in range(seq_len):\n",
        "        a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "        # print(sx.shape, a.shape, z.shape)\n",
        "        sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "            syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            tcost = -self.tcost(syh0)\n",
        "        c.append(tcost)\n",
        "        lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "        lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        cost += (tcost + icost)*gamma**t\n",
        "    return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "\n",
        "def argm(self, sy, sy_, h0, a, reward, lr=3e3): # 3e3\n",
        "    self.tcost.eval()\n",
        "    batch_size = sy.shape[0] # [batch_size, d_model]\n",
        "    z = nn.Parameter(torch.zeros((batch_size, self.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(z)\n",
        "    torch.nn.init.normal_(z, mean=0., std=.3/z.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([z], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    sy, sy_ = sy.detach(), sy_.detach()\n",
        "    out = sy - sy_\n",
        "    h0, a, reward = h0.detach(), a.detach(), reward.detach()\n",
        "    for i in range(10): # 10\n",
        "        with torch.amp.autocast('cuda'):\n",
        "\n",
        "\n",
        "\n",
        "            syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "            out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            repr_loss = F.mse_loss(out, out_[:, -1, :])\n",
        "            # syh0 = torch.cat([sy.flatten(1),F.dropout(h0_, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            syh0 = torch.cat([sy.flatten(1),h0_.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "            z_loss = torch.abs(z).sum() # z_loss = torch.norm(z)\n",
        "            print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def argm(lsy, sy, h0, la, rwd):\n",
        "    # lz = agent.argm(out, h0, la, reward)\n",
        "    agent.tcost.eval()\n",
        "    batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "    lz = nn.Parameter(torch.zeros((batch_size, bptt, agent.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(lz)\n",
        "    torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "    for i in range(3): # 10\n",
        "        sy_, h0_ = sy.detach(), h0.detach()\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "        with torch.cuda.amp.autocast():\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0_ = agent.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl + agent.zloss_coeff * z_loss\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    agent.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return lz.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# closs_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01)\n",
        "bptt = 25\n",
        "for batch, Sar in enumerate(train_loader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "    state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "    sy_ = agent.jepa.enc(state).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    # sx=sy_\n",
        "    state, action, reward = Sar # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "    state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "    for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "\n",
        "        with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "            lsy = agent.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "            la = agent.emb(act) # [batch_size, bptt, dim_a]\n",
        "            out = lsy - torch.cat([sy_, lsy[:,:-1]], dim=1)\n",
        "            # lz = agent.argm(out, h0, la, reward)\n",
        "            lz = argm(lsy, sy_, h0, la, rwd)\n",
        "            # lz = torch.zeros((batch_size, bptt, agent.dim_z), device=device)\n",
        "\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0 = agent.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0.unsqueeze(0)), dim=0)\n",
        "\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            std_loss, cov_loss = agent.jepa.v_creg(agent.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "            jloss = agent.jepa.sim_coeff * repr_loss + agent.jepa.std_coeff * std_loss + agent.jepa.cov_coeff * cov_loss\n",
        "\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # print(\"syh0, rwd\",syh0.shape,rwd.shape)\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            # reward_ = agent.tcost(syh0)\n",
        "            # clossl = wasserstein(rwd, reward_)#.squeeze(-1)\n",
        "            closs = agent.closs_coeff * clossl\n",
        "\n",
        "            # print(h0.requires_grad)\n",
        "            # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "            # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "            # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "            # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "            # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "            loss = jloss + closs\n",
        "\n",
        "            # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "            norm = torch.norm(lsy, dim=-1)[0][0].item()\n",
        "            z_norm = torch.norm(z)\n",
        "            # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "            # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "            print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "            scaler.scale(loss).backward()\n",
        "            # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "            optim.zero_grad()\n",
        "            sy_, h0 = sy_.detach(), h0.detach()\n",
        "    break\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Jt_UlGz6Xoq3",
        "wUhKd009Qvk3"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}