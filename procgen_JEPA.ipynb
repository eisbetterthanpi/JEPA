{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/procgen_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7WkwnVjJTrW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3bfd8e-8ae9-48b2-f6a5-db32058977b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -qq procgen\n",
        "# !pip install -qq procgen faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SKlOoBh8yHXA"
      },
      "outputs": [],
      "source": [
        "# @title faiss\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# d = 256 # dimension\n",
        "# res = faiss.StandardGpuResources()  # use a single GPU\n",
        "# nlist = 100\n",
        "# m = 8\n",
        "# index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "# index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "# # index = faiss.IndexIVFPQ(index, d, nlist, m, 8) # each sub-vector is encoded as 8 bits # 3-IVFPQ.py\n",
        "# # index = faiss.index_cpu_to_gpu(res, 0, index) # 4-GPU.py\n",
        "# # index = faiss.index_cpu_to_all_gpus(index) # 5-Multiple-GPUs.py\n",
        "\n",
        "\n",
        "# import torch\n",
        "# ltmk = torch.rand(1000,d)\n",
        "# ltmv = torch.rand(1000,d)\n",
        "\n",
        "def makefaissindex(vert_store):\n",
        "    d = vert_store.shape[-1]\n",
        "    nlist = 100\n",
        "    index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "    index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "    if not index.is_trained: index.train(vert_store)\n",
        "    index.add(vert_store)\n",
        "    return index\n",
        "# index = makefaissindex(ltmk)\n",
        "\n",
        "\n",
        "def vecsearch(query, index, k=5, treshold=36): # k nearest neighbors\n",
        "    # index.nprobe = 5 # 1\n",
        "    D, I = index.search(query, k) # dist, idx\n",
        "    D, I = D[0], I[0]\n",
        "    mask = I[D<treshold]\n",
        "    return mask\n",
        "\n",
        "# import torch\n",
        "# query = torch.rand(1,d)\n",
        "\n",
        "# mask = vecsearch(query, index, k=5, treshold=37)\n",
        "# print(mask)\n",
        "# rag = ltmk[mask]\n",
        "# print(rag)\n",
        "\n",
        "\n",
        "# removing = torch.tensor([998, 769, 643])\n",
        "# index.remove_ids(removing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXm1sGiK1oQS"
      },
      "outputs": [],
      "source": [
        "# @title mem\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self): # [batch_size, len_ltm, d_model]\n",
        "        self.stmk, self.stmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "\n",
        "    def __call__(self, query): # [batch_size, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, 1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, 1, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        return x.squeeze(1) # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, 1, d_model]\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "\n",
        "\n",
        "class Mem():\n",
        "    def __init__(self, batch_size=1):\n",
        "        self.index = None\n",
        "        self.ltmk, self.ltmv = torch.tensor([]), torch.tensor([])\n",
        "        # self.stmk, self.stmv, self.meta = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
        "        # self.ltmk, self.ltmv = torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.stmk, self.stmv, self.meta = torch.tensor([], device=device), torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __call__(self, query, a=0.5):\n",
        "        return a*self.Stm(query) + (1-a)*self.Ltm(query.cpu()).to(device)\n",
        "\n",
        "    def Stm(self, query): # [1, d_model]\n",
        "        if len(self.stmk)==0: return torch.zeros((1), device=device)\n",
        "        attn = query @ self.stmk.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ self.stmv # [1, len_ltm] @ [len_ltm, d_model] = [1, d_model]\n",
        "        self.meta = self.meta + attn.squeeze(0) # attention # [len_ltm]\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def Ltm(self, query, k=5, treshold=36): # [batch_size, d_model] or [d_model]\n",
        "        if self.index: rag = self.vecsearch(query, k, treshold)\n",
        "        else: rag = self.ltmk\n",
        "        if len(rag)==0: return torch.zeros(1)\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        attn = query @ rag.T # [1, d_model] @ [d_model, len_ltm] = [1, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [1, len_ltm]\n",
        "        x = attention @ rag\n",
        "        return x # [1, d_model]\n",
        "\n",
        "    def add(self, k, v): # [batch_size, d_model] or [d_model]\n",
        "        # print(\"add\", k.shape,self.stmk.shape)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=0)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=0)\n",
        "        self.meta = torch.cat([self.meta, torch.ones((1), device=device)], dim=-1)\n",
        "        if torch.rand(1)<0.1:\n",
        "            self.pop()\n",
        "            self.decay()\n",
        "\n",
        "    def decay(self, g=0.9, k=256): # remove unimportant mem in stm\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        if len(self.meta)>k:\n",
        "            topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "            self.meta = topk.values # cap stm size\n",
        "            self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5): # transfer from stm to ltm\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        k, v = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask] # remove from stm\n",
        "        self.meta = self.meta[~mask]\n",
        "        # print(\"pop\", k.shape, self.ltmk.shape, k)\n",
        "        k, v = k.cpu(), v.cpu()\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        self.ltmk = torch.cat([self.ltmk, k], dim=0) # add to ltm\n",
        "        self.ltmv = torch.cat([self.ltmv, v], dim=0)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.01:\n",
        "                self.index.train(self.ltmk)\n",
        "        else:\n",
        "            if len(self.ltmk)>=100:\n",
        "                self.index = makefaissindex(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        return rag\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(self, file='mem.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(self, file='mem.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv, self.stmk, self.stmv, self.meta = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "7DTSlle0RaQY"
      },
      "outputs": [],
      "source": [
        "# @title intrinsic cost\n",
        "# import faiss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ICost():\n",
        "    def __init__(self, d_model, n=100):\n",
        "        self.recent=[]\n",
        "        # self.linmul = torch.linspace(0,1/n,n).unsqueeze(-1) # 1/n so that sum to 1\n",
        "        self.linsx = torch.zeros((n, d_model), device=device)\n",
        "        self.n = n\n",
        "        self.p=(n-1)/n\n",
        "\n",
        "    def boredom(self, lsx, linsx=None): # lsx: [len_seq, d_model]; for simulate only\n",
        "        if linsx==None: linsx = self.linsx.clone()\n",
        "        lsx, linsx = F.normalize(lsx, dim=-1), F.normalize(linsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        linsx = torch.cat([linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        linsx = linsx[mask]\n",
        "        bore = (linsx[:-1]@lsx[-1].T).sum()/(self.n-1)\n",
        "        return bore#.squeeze()\n",
        "\n",
        "    def update(self, lsx): # lsx: []\n",
        "        # self.linsx = torch.cat([lsx, self.linsx[:-lsx.shape[0]]], dim=0)\n",
        "        lsx = F.normalize(lsx, dim=-1)\n",
        "        len_seq = lsx.shape[0]\n",
        "        # print(\"update\", self.linsx.shape, lsx.shape)\n",
        "        linsx = torch.cat([self.linsx, lsx], dim=0)\n",
        "        weights = 1-self.p**torch.cat([torch.ones(self.n)*len_seq, torch.linspace(len_seq-1, 0, len_seq)], dim=0).float()\n",
        "        idx = torch.multinomial(weights, len_seq)\n",
        "        mask = torch.ones(self.n+len_seq, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        self.linsx = linsx[mask]\n",
        "\n",
        "\n",
        "    # def curiousity(self, sx):\n",
        "    #     lin= nn.Linear(d_model, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "\n",
        "    #         n,d=10,2\n",
        "    #         data=torch.rand(n,d)\n",
        "\n",
        "    #         index = faiss.IndexFlatIP(d) # IndexFlatL2, IndexFlatIP\n",
        "    #         index = faiss.IndexIDMap(index)\n",
        "    #         ids=torch.arange(n)\n",
        "    #         index.add_with_ids(data,ids)\n",
        "    #         a=torch.rand(1,2)\n",
        "    #         id=torch.tensor([0])\n",
        "    #         index.remove_ids(id) # https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#supported-operations\n",
        "    #         index.add_with_ids(a,id)\n",
        "\n",
        "    #         D, I = index.search(a, 20)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         curious = 1-torch.clamp(priority, 0, 1)\n",
        "    #         D.sum(-1)\n",
        "    #         curious = 1-torch.clamp(, max=1) # IP\n",
        "\n",
        "\n",
        "    # def __call__(self, st, a): # [batch_size, d_model]\n",
        "    def __call__(self, x): # [batch_size, d_model**2]\n",
        "        return 0\n",
        "\n",
        "# pain, death, boredom, empathy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEY9MmwZhA8a",
        "outputId": "2b9b650d-5e3d-4aa9-c64c-7c4f53bcbf51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1278976\n",
            "torch.Size([4, 256])\n",
            "1278979\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, d_model=256, drop=0.5):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278976\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[4], d_model, 2, 1, 0), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Dropout(p=drop),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model = 1024):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] # 1278979\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(d_model,4*d_list[4]), nn.ReLU(),\n",
        "            # nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(x)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "conv = Conv().to(device)\n",
        "print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = conv(input)\n",
        "print(out.shape)\n",
        "\n",
        "deconv = Deconv(256).to(device)\n",
        "print(sum(p.numel() for p in deconv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,256), device=device)\n",
        "out = deconv(input)\n",
        "print(out.shape)\n",
        "\n",
        "# print(conv)\n",
        "# 1278976\n",
        "# 1278979\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "Bos81kQf1dwh"
      },
      "outputs": [],
      "source": [
        "# @title transfer_sd store_sd load_sd\n",
        "\n",
        "def transfer_sd(tgt_sd, src_sd): #\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            # print(wht_name, tgt_wht.shape, src_wht.shape)\n",
        "            if tgt_wht.shape==src_wht.shape:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "                continue\n",
        "            if tgt_wht.shape[0] != src_wht.shape[0]: continue # output dim diff\n",
        "            if len(tgt_wht.shape)==2: tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "    return tgt_sd\n",
        "\n",
        "def store_sd(all_sd, new_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in new_sd.keys():\n",
        "            if not wht_name in all_sd.keys():\n",
        "                # print(wht_name, new_sd[wht_name].shape)\n",
        "                all_sd[wht_name] = (new_sd[wht_name],)\n",
        "                continue\n",
        "            all_tpl, new_wht = all_sd[wht_name], new_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                print(wht_name, all_wht.shape, new_wht.shape)\n",
        "                if all_wht.shape==new_wht.shape:\n",
        "                    all_wht = new_wht\n",
        "                    break\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: continue # diff output shape\n",
        "                if len(all_wht.shape)==2: all_wht[:, :new_wht.shape[1]] = new_wht[:, :all_wht.shape[1]]\n",
        "                break\n",
        "            if len(all_wht.shape)>=2 and len(all_wht.shape)>=2:\n",
        "                if all_wht.shape[0] != new_wht.shape[0]: all_tpl = all_tpl + (new_wht,) # wht not in all_wht\n",
        "    return all_sd\n",
        "\n",
        "def load_sd(tgt_sd, all_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in all_sd.keys(): continue\n",
        "            tgt_wht, all_tpl = tgt_sd[wht_name], all_sd[wht_name]\n",
        "            for all_wht in all_tpl:\n",
        "                # try: print(wht_name, tgt_wht.shape, all_wht.shape)\n",
        "                # except: print(wht_name, tgt_wht, all_wht)\n",
        "                if tgt_wht.shape==all_wht.shape:\n",
        "                    tgt_wht.copy_(all_wht)\n",
        "                    break\n",
        "                if tgt_wht.shape[0] != all_wht.shape[0]: continue # output dim diff\n",
        "                if len(tgt_wht.shape)==2: tgt_wht[:, :all_wht.shape[1]].copy_(all_wht[:, :tgt_wht.shape[1]])\n",
        "                break\n",
        "    return tgt_sd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# modelsd = torch.load('agent.pkl', map_location=device).values()\n",
        "# tgt_sd = transfer_sd(agent.state_dict(), modelsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = {}\n",
        "# all_sd = store_sd(all_sd, agent1.state_dict())\n",
        "# print(all_sd.keys())\n",
        "# checkpoint = {'model': all_sd}\n",
        "# torch.save(checkpoint, 'all_sd.pkl')\n",
        "\n",
        "# agent3 = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "# agent3.tcost = tcost3\n",
        "# tgt_sd = load_sd(agent3.state_dict(), all_sd)\n",
        "# agent3.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "# for x,y in zip(agent1.state_dict().values(), agent3.state_dict().values()):\n",
        "#     print((x==y).all())\n",
        "\n",
        "# print(agent1.jepa.enc.cnn[1].num_batches_tracked)\n",
        "# jepa.enc.cnn.0.weight\n",
        "# print(agent1.jepa.enc.cnn[0].weight.shape)\n",
        "# print(agent1.jepa.enc.cnn[0].weight[0][0])\n",
        "# print(agent3.jepa.enc.cnn[0].weight[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "SFVbGqMDqcDR"
      },
      "outputs": [],
      "source": [
        "# @title rename_sd\n",
        "def rename_sd(agent_sd):\n",
        "    sd_={}\n",
        "    convert={}\n",
        "    na_=''\n",
        "    for wht_name, wht in agent_sd.items():\n",
        "        o=wht_name.split('.')\n",
        "        # print(\"####\", wht_name)\n",
        "        name=wht_name\n",
        "        for i in range(len(o)):\n",
        "            c = o[i]\n",
        "            if c.isnumeric():\n",
        "                na, me = '.'.join(o[:i]), '.'.join(o[i+1:])\n",
        "                c=int(c)\n",
        "                if na!=na_: # param name diff\n",
        "                    j=0 # reset num\n",
        "                    c_=c # track wht_name num\n",
        "                    na_=na # track param name\n",
        "                elif c_<c: # same param name, diff num\n",
        "                    j+=1\n",
        "                    c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "        # print(name)\n",
        "        sd_[name] = wht\n",
        "        convert[name] = wht_name\n",
        "    return sd_, convert\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# # modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, _ = rename_sd(modelsd)\n",
        "\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# agent.load_state_dict(modelsd, strict=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "riBHnAAkkzrd"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim me\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# def transfer_optim(tgt_sd, src_sd, tgt_optim, src_optim): #\n",
        "def transfer_optim(tgt_sd, src_sd, tgt_optim_sd, src_optim_sd): #\n",
        "    non_lst = ['running_mean', 'running_var', 'num_batches_tracked', 'num_batches_tracked', 'loss_fn']\n",
        "    tgt_lst, src_lst = [], []\n",
        "    for i, (k,v) in enumerate(tgt_sd.items()):\n",
        "        # print(i, k, v.shape, any(s in k for s in non_lst))\n",
        "        if not any(s in k for s in non_lst): tgt_lst.append(k)\n",
        "    for i, (k,v) in enumerate(src_sd.items()):\n",
        "        if not any(s in k for s in non_lst): src_lst.append(k)\n",
        "\n",
        "    # tgt_optim_st, src_optim_st = tgt_optim.state_dict()['state'], src_optim.state_dict()['state']\n",
        "    tgt_optim_st, src_optim_st = tgt_optim_sd['state'], src_optim_sd['state']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, wht_name in enumerate(tgt_lst):\n",
        "            if not wht_name in src_lst: continue\n",
        "            tgt_wht, src_wht = tgt_optim_st[tgt_lst.index(wht_name)], src_optim_st[src_lst.index(wht_name)]\n",
        "            # print(wht_name, tgt_wht, src_wht)\n",
        "            tgt_shp, src_shp = tgt_wht['exp_avg'].shape, src_wht['exp_avg'].shape\n",
        "            if tgt_shp==src_shp:\n",
        "                tgt_wht = src_wht\n",
        "                continue\n",
        "            if tgt_shp[0] != src_shp[0]: continue # output dim diff\n",
        "            if len(tgt_shp)==2:\n",
        "                tgt_wht['step'] = src_wht['step']\n",
        "                tgt_wht['exp_avg'][:, :src_shp[1]] = src_wht['exp_avg'][:, :tgt_shp[1]]\n",
        "                tgt_wht['exp_avg_sq'][:, :src_shp[1]] = src_wht['exp_avg_sq'][:, :tgt_shp[1]]\n",
        "    # return tgt_optim.state_dict()\n",
        "    return tgt_optim_sd\n",
        "\n",
        "# model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "# model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "# source_optimizer = optim.AdamW(model_src.parameters())\n",
        "# target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "# dummy_input = torch.randn(3, 10)\n",
        "# dummy_target = torch.randn(3, 5)\n",
        "# criterion = torch.nn.MSELoss()\n",
        "# output = model_src(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# source_optimizer.step()\n",
        "\n",
        "# dummy_input = torch.randn(3, 20)\n",
        "# output = model_tgt(dummy_input)\n",
        "# loss = criterion(output, dummy_target)\n",
        "# loss.backward()\n",
        "# target_optimizer.step()\n",
        "\n",
        "\n",
        "# print(source_optimizer.state_dict())\n",
        "# print(target_optimizer.state_dict())\n",
        "\n",
        "# optimsd = transfer_optim(model_tgt.state_dict(), model_src.state_dict(), target_optimizer, source_optimizer)\n",
        "# target_optimizer.load_state_dict(optimsd)\n",
        "# print(target_optimizer.state_dict())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AfjFbveH64Io",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title TCost\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class TCost(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=256, drop=0.5): # in_dim=(1+self.jepa.pred.num_layers)*d_model\n",
        "        super().__init__()\n",
        "        self.tc = torch.tensor([-1., 0.], device=device).unsqueeze(-1) # unsqueeze(0).T\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            nn.Dropout(p=0.), nn.Linear(in_dim, 2, bias=False)\n",
        "            # nn.Dropout(p=drop), nn.Linear(in_dim, d_model), nn.ReLU(),\n",
        "            # nn.Dropout(p=drop), nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            # nn.Dropout(p=drop), nn.Linear(d_model, 2)\n",
        "            )\n",
        "        self.loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def update_loss_weight(self, train_data):\n",
        "        a = len(buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "        # self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device))\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)], device=device), reduction='none')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.softmax(self.tcost(x), dim=-1)@self.tc\n",
        "\n",
        "    def loss(self, x, y, reduction='mean'):\n",
        "        out = self.tcost(x)\n",
        "        y = torch.where(y < -0.5, 0, 1)\n",
        "        if reduction=='mean': return self.loss_fn(out, y).mean()\n",
        "        return self.loss_fn(out, y)\n",
        "\n",
        "\n",
        "# tcost=TCost(1024).to(device)\n",
        "# x=torch.randn((256,1024), device=device)\n",
        "# # import time\n",
        "# # start = time.time()\n",
        "# out=tcost(x).squeeze()\n",
        "# # out=tcost.tcost(x).squeeze()\n",
        "# print(out)\n",
        "# # out=F.gumbel_softmax(out)\n",
        "# print(time.time()-start)\n",
        "# # nn.AdaptiveLogSoftmaxWithLoss(in_features=2, n_classes=2, cutoffs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuA25qQknUAX",
        "outputId": "3b5a966d-32b2-47da-9cc2-490407e860c2",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-bd344d321dd5>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc = Conv(d_model) # pixel\n",
        "        # self.enc = ConvEnc(d_model) #\n",
        "        # self.enc = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.enc.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "        # self.pred = nn.Sequential(\n",
        "        #     nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.2)\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        self.dim_z = dim_z\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "        self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        # return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        return std_loss, cov_loss\n",
        "\n",
        "    def argm(self, sx, a, sy, lr=3e3, h0=None): # 3e3\n",
        "        batch=sx.size(dim=0)\n",
        "        z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "        optim = torch.optim.SGD([z], lr=lr)\n",
        "        # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95))\n",
        "        lossfn = torch.nn.MSELoss()\n",
        "        sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "        for i in range(5): # 10\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sy_ = self.pred(sxaz)\n",
        "                sy_, _ = self.pred(sxaz, h0)\n",
        "                loss = lossfn(sy_, sy)# + self.z_coeff * torch.norm(z)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"argm\",i,loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        return z#.detach()\n",
        "\n",
        "# torch.norm(z, dim=-1)\n",
        "# -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "# in RL, distribution of action, if certainty is high, entropy is low\n",
        "\n",
        "\n",
        "    # def loss(self, x, y, a, z=None):\n",
        "    #     sx, sy = self.enc(x), self.enc(y)\n",
        "    #     z = self.argm(sx, a, sy)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     repr_loss = self.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "    #     # v_c_loss = self.v_creg(self.exp(sx))\n",
        "    #     vx, vy = self.exp(sx), self.exp(sy)\n",
        "    #     v_c_loss = self.v_creg(vx) + self.v_creg(vy)\n",
        "    #     return repr_loss + v_c_loss\n",
        "\n",
        "    # def forward(self, sx, a): # state, ctrl\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z=torch.zeros((batch,self.dim_z),device=device)\n",
        "    #     sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #     sy_ = self.pred(sxaz)\n",
        "    #     return sy_ # state1\n",
        "\n",
        "\n",
        "# d_model=16\n",
        "# dim_z= 1#-5\n",
        "# dim_v=32\n",
        "# dim_a=4\n",
        "# model = JEPA(in_dim, d_model, dim_a, dim_z, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# y=torch.rand(1, in_dimy)\n",
        "# loss = model.loss(x,y)\n",
        "# distance = torch.norm(embeddings.weight.data - my_sample, dim=-1)\n",
        "# nearest = torch.argmin(distance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "id": "YVeF35lpwqlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9e103c-ee6a-4bec-a368-2ec038155ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-348-9800ceaf3cec>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "argm lz[0] 0 tensor([ 0.1329, -0.2013,  0.0584, -0.1374,  0.1057, -0.1783, -0.0444, -0.0394])\n",
            "0 0.004164764657616615 tensor(0.0016, grad_fn=<SelectBackward0>)\n",
            "argm lz[0] 1 tensor([ 0.1429, -0.1913,  0.0684, -0.1274,  0.1157, -0.1683, -0.0344, -0.0493])\n",
            "1 0.004089081659913063 tensor(0.0013, grad_fn=<SelectBackward0>)\n",
            "argm lz[0] 2 tensor([ 0.1511, -0.1825,  0.0767, -0.1198,  0.1242, -0.1601, -0.0272, -0.0587])\n",
            "2 0.004019380081444979 tensor(0.0012, grad_fn=<SelectBackward0>)\n",
            "argm lz[0] 3 tensor([ 0.1589, -0.1742,  0.0845, -0.1133,  0.1320, -0.1529, -0.0218, -0.0662])\n",
            "3 0.003963921684771776 tensor(0.0011, grad_fn=<SelectBackward0>)\n",
            "argm lz[0] 4 tensor([ 0.1664, -0.1662,  0.0918, -0.1079,  0.1393, -0.1465, -0.0182, -0.0723])\n",
            "4 0.003923229873180389 tensor(0.0010, grad_fn=<SelectBackward0>)\n",
            "tensor([0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041, 0.0040]) tensor([0.0010, 0.0014, 0.0011, 0.0010, 0.0014, 0.0012, 0.0014, 0.0011, 0.0013])\n"
          ]
        }
      ],
      "source": [
        "# @title test batch argm\n",
        "\n",
        "def argm(lsy, sy, h0, la, rwd): # best case z for train\n",
        "    # self.tcost.eval() # disable tcost dropout\n",
        "    batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "    batch = 16 # 16\n",
        "    lsy, la, rwd = lsy.repeat(batch,1,1), la.repeat(batch,1,1), rwd.repeat(batch,1) # [batch*batch_size, bptt, d_model], [batch*batch_size, d_model, dim_a], [batch*batch_size, bptt]\n",
        "    lz = nn.Parameter(torch.zeros((batch*batch_size, bptt, agent.dim_z), device=device))\n",
        "    torch.nn.init.normal_(lz, mean=0., std=.25/lz.shape[-1]**0.5)\n",
        "    # torch.nn.init.normal_(lz, mean=0., std=.1/lz.shape[-1]**0.5)\n",
        "    optim = torch.optim.SGD([lz], lr=1e1) # 1e-2 1e3 1e2 1e1\n",
        "    # optim = torch.optim.AdamW([lz], lr=1e-0) # 1e-2\n",
        "\n",
        "    # optim = torch.optim.AdamW([{'params': z, 'lr': 1e-1} for z in lz], (0.1, 0.5)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.1, 0.5)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.6, 0.9)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.7, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.8, 0.99)) # 1e-1\n",
        "    # optim = torch.optim.AdamW([lz], 1e-0, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "    lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "    for i in range(10): # 3 10\n",
        "        sy_, h0_ = sy.detach(), h0.detach()\n",
        "        lsy_, lh0 = agent.rnn_it(sy_, la, lz, h0_)\n",
        "        # repr_loss = F.mse_loss(lsy, lsy_)\n",
        "        repr_loss = ((lsy-lsy_)**2).unflatten(0, (batch,batch_size)).flatten(1).mean(-1)\n",
        "        syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch*batch_size,bptt,d_model], [bptt,num_layers,batch*batch_size,d_model] -> [batch*batch_size*bptt, (1+num_layers)*d_model]\n",
        "        # clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "        clossl = agent.tcost.loss(syh0, rwd.flatten(), reduction='none').unflatten(0, (batch,batch_size*bptt)).mean(-1) # [batch*batch_size*bptt] -> [batch]\n",
        "        z_loss = torch.abs(lz[0][0]).sum() # z_loss = torch.norm(z)\n",
        "        # print(\"z_loss\", i, lz[0][0].data, z_loss)\n",
        "        # print(\"z_loss\", i, lz[0].data, z_loss)\n",
        "        # print(i, repr_loss[0], clossl[0])\n",
        "        print(torch.norm(lz, dim=-1))\n",
        "        print(i, repr_loss.data, clossl.data)\n",
        "        cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "        # cost = repr_loss + clossl# + self.zloss_coeff * z_loss\n",
        "        cost.sum().backward()\n",
        "        # print(lz.grad[0][0].norm())\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(i, \"repr closs, lz\", torch.cat([torch.tensor([repr_loss[0], clossl[0]]), lz[0].cpu()],dim=-1).squeeze().data)\n",
        "    print(repr_loss[0].item(), clossl[0].item())\n",
        "    # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    idx = torch.argmin(cost)\n",
        "    return lz.unflatten(0, (batch,batch_size))[idx].squeeze(0).detach()\n",
        "\n",
        "# repr_loss, clossl untrained # 0.0850 # 0.6967\n",
        "# repr_loss, clossl trained # 0.0168, 0.4233\n",
        "\n",
        "# nn.HuberLoss() # near 0 is L2, outside is L1. less sensitive to outliers than L2? use like mse\n",
        "\n",
        "\n",
        "# # for batch, (state, action, reward) in enumerate(train_loader):\n",
        "# #     imshow(torchvision.utils.make_grid(state[0].cpu(), nrow=10))\n",
        "# #     break\n",
        "# it = iter(train_loader)\n",
        "# state, action, reward = next(it)\n",
        "# # imshow(torchvision.utils.make_grid(state[0].cpu(), nrow=10))\n",
        "\n",
        "\n",
        "# for batch, (state, action, reward) in enumerate(train_loader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "sy_ = agent.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "# state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "bptt=25#25\n",
        "for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        lsy = agent.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "        la = agent.emb(act) # [batch_size, bptt, dim_a]\n",
        "        # lz = argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "        lz = agent.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "    break\n",
        "# break\n",
        "# print(lz.squeeze().data)\n",
        "\n",
        "# import torch\n",
        "# la = torch.arange(15).reshape(3, 5)\n",
        "# la = la.repeat(2,1)\n",
        "# print(la)\n",
        "# print(la.unflatten(0, (2,3)))\n",
        "# # idx = torch.argmin(loss.unflatten(0, (batch_size,batch)), dim=1) # choose best x even with greatest adv z\n",
        "\n",
        "# 0.0120, grad_fn=<SelectBackward0>) tensor(0.0026\n",
        "# 0.01625952310860157 0.006073409225791693\n",
        "# 0.012133662588894367 0.002644716529175639\n",
        "\n",
        "# 1e-1, (0.6, 0.9) 0.012200677767395973 0.0026760129258036613   0.0070, 0.0015\n",
        "# 1e0, (0.6, 0.9) 0.01657252572476864 0.006728994660079479\n",
        "# 1e-1, (0.7, 0.95) 0.01258037332445383 0.0025434442795813084   0.0079, 0.0017\n",
        "# 1e-1, (0.8, 0.99) 0.01308276318013668 0.0030850034672766924   0.0087, 0.0018\n",
        "# 1e-1, (0.9, 0.999) 0.013740073889493942 0.0036710305139422417 0.0116, 0.0020\n",
        "# 1e0, (0.9, 0.999) 0.015708010643720627 0.003271286841481924\n",
        "\n",
        "# 0.0069, 0.0780\n",
        "# 0.0071], grad_fn=<MeanBackward1>) tensor([0.0019 ; 0.0071], grad_fn=<MeanBackward1>) tensor([0.0017\n",
        "# sgd 1e2 0.013228558003902435 0.006260296329855919 0.0065, 0.0014\n",
        "# sgd 1e3 0.01344290841370821 0.003109498880803585  0.0201, 0.0300\n",
        "# sgd 1e4 0.024299193173646927 0.04469054192304611\n",
        "# sgd 1e5 0.024356722831726074 0.04473479837179184\n",
        "\n",
        "\n",
        "# 1e-1, (0.3, 0.9) 0.011701214127242565 0.0031367409974336624\n",
        "# 1e-1, (0.4, 0.9) 0.011715513654053211 0.0027481389697641134\n",
        "# 1e-1, (0.5, 0.9) 0.01180238462984562 0.002659460064023733\n",
        "# 1e-1, (0.6, 0.9) 0.012142348103225231 0.0024781511165201664\n",
        "# 1e-1, (0.7, 0.9) 0.012586873024702072 0.0027804935816675425\n",
        "\n",
        "# 1e-1, (0.6, 0.8) 0.012026924639940262 0.0027117012068629265\n",
        "\n",
        "# 1e-1, (0.5, 0.7) 0.0068, 0.0009\n",
        "# 1e-1, (0.5, 0.8) 0.0065, 0.0015\n",
        "# 1e-1, (0.5, 0.9) 0.0073, 0.0010 0.0074, 0.0013\n",
        "# 1e-1, (0.5, 0.97) 0.0067, 0.0009 0.0080, 0.0016\n",
        "\n",
        "\n",
        "\n",
        "# 1e-1, (0.1, 0.5) 0.0066,0.0011; 0.0065,0.0013; 0.0062, 0.0015\n",
        "# 0.0075], grad_fn=<MeanBackward1>) tensor([0.0019\n",
        "# 1e-1, (0.1, 0.6) 0.0065,0.0012; 0.0067,0.0014; 0.0067,0.0010\n",
        "\n",
        "# 0.0007\n",
        "\n",
        "# 1e-2 0.0847, grad_fn=<SelectBackward0>) tensor(0.6741\n",
        "\n",
        "# 1e1,.0 9 tensor(0.0041, grad_fn=<SelectBackward0>) tensor(0.0012, grad_fn=<SelectBackward0>)\n",
        "# 1e1,.5 9 tensor(0.0040, grad_fn=<SelectBackward0>) tensor(0.0011, grad_fn=<SelectBackward0>)\n",
        "# 1e1,.9 9 tensor(0.0040, grad_fn=<SelectBackward0>) tensor(0.0009, grad_fn=<SelectBackward0>)\n",
        "# 1e1,.999 9 tensor(0.0042, grad_fn=<SelectBackward0>) tensor(0.0011, grad_fn=<SelectBackward0>)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 528,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqkI44ygzfxu",
        "outputId": "8a5d5631-fd6f-43a7-9ef3-862c5f17d94b",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-528-c5291a39c442>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=8, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=1. # 10 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=3. # 50 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 1 # ν cov Covariance\n",
        "        self.closs_coeff=1. # 10\n",
        "        # self.zloss_coeff=0. # 10 1\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "        self.lx, self.lz = torch.empty((0,self.dim_a),device=device), torch.empty((0,self.dim_z),device=device) # [T,dim_az]\n",
        "        self.sx = self.jepa.enc(torch.zeros((1, 3,64,64)))\n",
        "        self.la = torch.empty(0,device=device)\n",
        "\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        if len(self.la)>1 or laction!=None:\n",
        "            self.update_h0(lstate, laction)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                self.sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(self.sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.la, self.lx, self.lz = lact, lx, lz\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                lsy = self.jepa.enc(torch.cat(lstate, dim=0))\n",
        "                # self.icost.update(sx)\n",
        "                # out_ = lsx - torch.cat([self.sx, lsx[:-1]], dim=0) # if using residual\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    self.la = torch.cat([torch.tensor(laction, device=device), self.la[len(laction):]], dim=-1)\n",
        "                la = self.emb(self.la[:seq_len])\n",
        "\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5) # torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        optim_z = torch.optim.SGD([lz], lr=1e1) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e0 ; 3e-2 1e-1\n",
        "        lsy, la = lsy.detach(), la.detach() # [T, d_model], [T, dim_a]\n",
        "        lsx = torch.cat([self.sx, lsy[:-1]], dim=0)\n",
        "        # print(\"update_h0 lz\", lz.data)\n",
        "        self.jepa.pred.train()\n",
        "        for i in range(1): # 1?\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                out = self.fc(out)\n",
        "                # loss = F.mse_loss(out_, out.squeeze(0))\n",
        "                loss = F.mse_loss(lsy, out.squeeze(0))\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            print(\"update_h0 loss, lz\",i,loss.item(), lz.data)\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1].unsqueeze(0)\n",
        "        # print(\"update_h0\", self.lx.data)\n",
        "        self.la, self.lx, self.lz = self.la[seq_len:], self.lx[seq_len:], self.lz[seq_len:] # [T, dim_a], [T, dim_z]\n",
        "        return h0\n",
        "\n",
        "    def argm_s(self, sx, x, h0, zz=None): # [1, d_model], [batch_, T, dim_a], [num_layers, 1, d_model], zz[batch_,T, dim_z] # batch argm z for search\n",
        "        batch_, T, _ = x.shape\n",
        "        batch = 16 # 16\n",
        "        z = nn.Parameter(torch.zeros((batch*batch_, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # 1.:norm~1 ; 1.\n",
        "        optim_z = torch.optim.SGD([z], lr=1e3, momentum=0.999, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-1, (0.1, 0.5), maximize=True) # 1e-1, (0.1, 0.5)\n",
        "        with torch.no_grad():\n",
        "            z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch*batch_,1,1) # [batch*batch_, seq_len, dim_z]\n",
        "            if zz != None: z[:batch_]=zz #z[::batch]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, T, dim_a]\n",
        "        # print(\"argm_s\", z[0][0].squeeze())\n",
        "        for i in range(5): # 2 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward() # [batch, T]\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm_s z\", z[0][0].squeeze().data)\n",
        "            # print(i, \"argm_s loss\", loss.sum(-1).data)\n",
        "            # # print(torch.norm(z, dim=-1)) # all 1\n",
        "        idx = torch.argmax(loss.sum(-1).unflatten(0, (batch,batch_)), dim=0) # loss [batch*batch_, T] -> [batch_]\n",
        "        # print(\"argm_s loss[idx]\", loss[idx].sum().item())\n",
        "        return z.unflatten(0, (batch,batch_))[idx, torch.arange(batch_)]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch = 16 # 16\n",
        "        x = nn.Parameter(torch.zeros((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5) # .3\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e1, momentum=.7) # 1e-1,1e-0,1e4 ; 1e2 ; 1e1,.7\n",
        "        optim_x = torch.optim.AdamW([x], 1e-1, (0.1, 0.999)) # 1e-1 (0.1, 0.999)\n",
        "        with torch.no_grad(): x[:,:self.lx.shape[0]] = self.lx.repeat(batch,1,1)[:,:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        # print(\"search x\",x[0][0].squeeze().data)\n",
        "        z=None\n",
        "        for i in range(100):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [batch, T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0,z) # [batch,T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # print(i, \"search x\", x[0][0].squeeze().data)\n",
        "            # print(i, \"search loss\", loss.sum(-1).data)\n",
        "            if i>=6: break # 5 10\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        idx = torch.argmin(loss.sum(-1)) # loss [batch, T]\n",
        "        dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2)[idx], dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        # print(lact.data)\n",
        "        # print(\"search loss[idx]\",loss[idx].sum().item())\n",
        "        return lact, lh0[:,:,idx], x.data[idx], z[idx] # [batch,T], [T, num_layers, batch, d_model], [batch,T, dim_a], [batch,T, dim_z]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz, h0, gamma=0.9): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        lsx, lh0 = self.rnn_it(sx, la, lz, h0)\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        syh0 = torch.cat([lsx, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,T,d_model], [T,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "        tcost = -self.tcost(syh0).unflatten(0, (batch, seq_len)).squeeze(-1)\n",
        "        c = (tcost + icost)*gamma**torch.arange(seq_len, device=device)\n",
        "        # if len(c.shape) == 1: print(\"rnn_pred c\", [f'{cc.item():g}' for cc in c.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        if len(tcost.shape) == 1: print(\"rnn_pred tcost\", [f'{cc.item():g}' for cc in tcost.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        return c, lh0\n",
        "\n",
        "    def rnn_it(self, sx, la, lz, h0): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        batch_ = batch//sx.shape[0]\n",
        "        sx, h0 = sx.repeat(batch_, 1), h0.repeat(1, batch_, 1)\n",
        "        lsx = torch.empty((batch, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1) # [batch, d_model+dim_a/z]\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                out = self.fc(out)\n",
        "            # sx = sx + out.squeeze(1) # [batch,seq_len,d_model] # h0 = h0 +\n",
        "            sx = out.squeeze(1) # [batch,1,d_model]\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        return lsx, lh0\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd): # best case z for train\n",
        "        # self.tcost.eval() # disable tcost dropout\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        batch = 64 # 64\n",
        "        lsy, la, rwd = lsy.repeat(batch,1,1), la.repeat(batch,1,1), rwd.repeat(batch,1) # [batch*batch_size, bptt, d_model], [batch*batch_size, d_model, dim_a], [batch*batch_size, bptt]\n",
        "        lz = nn.Parameter(torch.zeros((batch*batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.25/lz.shape[-1]**0.5) # .25?\n",
        "        # optim = torch.optim.SGD([lz], lr=1e2, momentum=.5) # 1e-2 1e3 1e2 1e1 1e2,.5\n",
        "        optim = torch.optim.AdamW([lz], 1e-2, (0.1, 0.9)) # 1e-1, (0.1, 0.5)\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(5): # 3 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lsy_, lh0 = self.rnn_it(sy_, la, lz, h0_)\n",
        "            # repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            repr_loss = ((lsy-lsy_)**2).unflatten(0, (batch,batch_size)).flatten(1).mean(-1)\n",
        "            syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch*batch_size,bptt,d_model], [bptt,num_layers,batch*batch_size,d_model] -> [batch*batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "            clossl = self.tcost.loss(syh0, rwd.flatten(), reduction='none').unflatten(0, (batch,batch_size*bptt)).mean(-1) # [batch*batch_size*bptt] -> [batch]\n",
        "            # z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"argm lz[0]\", i, lz[0][0].data)\n",
        "            # # print(i, repr_loss[0].item(), clossl[0].item())\n",
        "            # print(repr_loss.data, clossl.data)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(repr_loss.data, clossl.data)\n",
        "        # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        idx = torch.argmin(cost)\n",
        "        return lz.unflatten(0, (batch,batch_size))[idx].squeeze(0).detach()\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    # with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0.5)).mul_((torch.rand_like(lz)>0.1).bool()) # dropout without scaling\n",
        "                    with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0)).mul_((torch.rand_like(lz)>0.5).bool()) # dropout without scaling\n",
        "                    lsy_, lh0 = self.rnn_it(sy_.squeeze(1), la, lz, h0)\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                    # pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "                    # print(\"pred\",pred[0])\n",
        "                    # print(\"rwd\",rwd[0])\n",
        "                    # mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "                    # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # reprloss = ((lsy-lsy_)**2).mean(-1) # [batch_size, bptt]\n",
        "                    # print(\"reprloss\",reprloss[0])\n",
        "                    # mask = (reprloss>0.05)[0]\n",
        "                    # # imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[0][mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "                # torch.norm(lsy-torch.cat([sy_,lsy[:-1]], dim=1), dim=-1) # -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "                # prob = F.softmax(output, dim=-1)\n",
        "                # entropy = -torch.sum(prob * torch.log(prob + 1e-5), dim=-1)\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                norm = torch.norm(lsy[0][0], dim=-1).item()\n",
        "                z_norm = torch.norm(lz[0][-1], dim=-1)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                # print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                scaler.scale(loss).backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item(), \"z_norm\": z_norm.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.999)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "# !pip show torch triton\n",
        "# # !pip install --upgrade torch\n",
        "# !pip install --upgrade triton\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "# print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "# print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "# print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch, batch_ = 5,3\n",
        "idx = torch.randint(0, batch, (batch_,))\n",
        "print(idx)\n",
        "z=torch.rand(batch*batch_, 4)\n",
        "print(z)\n",
        "id= torch.arange(batch_)\n",
        "# print(z.unflatten(0, (batch,batch_))[idx, id])\n",
        "zz=torch.rand(batch_, 4)\n",
        "print(zz)\n",
        "z[::batch]=zz\n",
        "print(z)\n"
      ],
      "metadata": {
        "id": "fO_GAAWEy1v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title from charJEPA.ipynb, RNN2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, in_dim, d_model):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(in_dim, d_model, num_layers=1, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, h0=None,c0=None): # [batch_size, seq_len, in_dim]\n",
        "        out, h0 = self.rnn(x, h0) # [batch_size, seq_len, d_model], [num_layers, batch_size, d_model]\n",
        "        # out, _ = self.lstm(x, (h0,c0))\n",
        "        # out = out[:, -1, :] # [batch_size, d_model]\n",
        "        out = self.fc(out) # [batch_size, seq_len, out_dim]\n",
        "        return out, h0\n",
        "\n",
        "# model = RNN(input_size, hidden_size).to(device)\n",
        "# print(model)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ILwCZmDU5wUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49RERFWFMgA_"
      },
      "outputs": [],
      "source": [
        "# print(agent.jepa.enc.parameters().values()[0].requires_grad)\n",
        "# for name, param in agent.tcost.named_parameters():\n",
        "# # # for name, param in agent.named_parameters():\n",
        "# #     # print(name, param.requires_grad)\n",
        "#     print(name, param)\n",
        "\n",
        "# for name, param in agent.tcost.named_parameters(): print(param.data)\n",
        "# print(agent.tcost.1.weight.data)\n",
        "# print(agent.tcost.named_parameters()['tcost.1.weight'])\n",
        "# print(vars(agent.jepa.exp.named_parameters()['exp.1.weight']))\n",
        "\n",
        "for p,n in zip(rnn.parameters(),rnn._all_weights[0]):\n",
        "    if n[:6] == 'weight':\n",
        "        print('===========\\ngradient:{}\\n----------\\n{}'.format(n,p.grad))\n",
        "\n",
        "writer = torch.utils.tensorboard.SummaryWriter(\"runs/\")\n",
        "for name, param in model.named_parameters():\n",
        "        writer.add_histogram(name + '/grad', param.grad, global_step=epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 531,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEH1P802JkHU",
        "outputId": "9a36f24c-86fe-4903-bce6-c67f56f6e142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 search x tensor([-0.0852,  0.0363,  0.1152])\n",
            "0 search loss tensor([1.2877, 1.3776, 1.3466, 1.3417, 1.2907, 1.4928, 1.2987, 1.2828, 1.2824,\n",
            "        1.4704, 1.3118, 1.4971, 1.5200, 1.2938, 1.3291, 1.3495])\n",
            "1 search x tensor([0.0149, 0.1363, 0.2151])\n",
            "1 search loss tensor([1.2615, 1.3085, 1.2020, 1.3842, 1.2918, 1.4860, 1.3024, 1.2907, 1.2514,\n",
            "        1.2510, 1.2823, 1.2998, 1.5233, 1.2945, 1.3245, 1.3345])\n",
            "2 search x tensor([-0.0146,  0.0160,  0.3361])\n",
            "2 search loss tensor([1.2626, 1.2977, 1.1676, 1.3120, 1.1504, 1.3387, 1.2985, 1.2445, 1.2168,\n",
            "        1.2581, 1.2840, 1.2998, 1.2615, 1.3226, 1.2642, 1.2926])\n",
            "3 search x tensor([-0.0937, -0.0999,  0.4513])\n",
            "3 search loss tensor([1.1621, 1.2423, 1.2242, 1.2276, 1.1761, 1.3427, 1.3062, 1.2222, 1.1578,\n",
            "        1.2315, 1.2435, 1.2820, 1.2537, 1.2933, 1.2148, 1.3235])\n",
            "4 search x tensor([-0.2311, -0.2753,  0.6129])\n",
            "4 search loss tensor([1.2007, 1.2419, 1.0173, 1.1691, 1.0183, 1.3432, 1.2489, 1.1141, 1.1446,\n",
            "        1.1831, 1.1660, 1.1791, 1.2571, 1.2946, 1.1605, 1.1756])\n",
            "5 search x tensor([-0.3165, -0.2271,  0.6362])\n",
            "5 search loss tensor([1.1198, 1.1854, 0.9892, 1.1877, 1.0249, 1.3143, 1.2842, 1.2853, 1.2599,\n",
            "        1.1516, 1.1467, 1.1171, 1.2341, 1.2659, 1.0555, 1.1349])\n",
            "6 search x tensor([-0.3879, -0.1354,  0.6389])\n",
            "6 search loss tensor([1.1014, 1.1501, 0.9707, 1.2383, 1.0278, 1.2830, 1.2061, 1.2502, 1.2282,\n",
            "        1.0142, 1.1911, 1.1194, 1.2584, 1.2680, 1.2502, 1.1659])\n",
            "tensor([ 6,  5, 13,  7,  6,  2])\n",
            "search loss[idx] 0.9707098007202148\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# dim_a, dim_z = 3, 8\n",
        "# batch, T = 4,6\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_a),device=device))\n",
        "# torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "# dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# x = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "# z = nn.Parameter(torch.zeros((batch, T, dim_z),device=device))\n",
        "# torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# state = torch.zeros((1, 3,64,64))\n",
        "# # state = torch.rand((1, 3,64,64), device=device)\n",
        "# sx = agent.jepa.enc(state)\n",
        "\n",
        "# it = iter(train_loader)\n",
        "# s, a, r = next(it)\n",
        "state = s[0][0].unsqueeze(0).to(device)\n",
        "agent.reset()\n",
        "act = agent([state], k=4)\n",
        "# h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "# lact, lh0, lx, lz = agent.search(sx, T=6, h0=h0)\n",
        "# loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "# print(loss,c)\n",
        "# print(lact, lh0, lx, lz)\n",
        "\n",
        "# [6, 5, 4, 4, 6, 2] 0.9696626663208008\n",
        "# [6, 5, 4, 7, 6, 2]) 0.9663428664207458\n",
        "# [1.1180, 1.0691, 0.9897, 0.9656, 0.9760, 1.0352, 1.1865, 0.9776, 1.0289, 1.1148, 1.0500, 1.0257, 0.9723]\n",
        "# 1e-1, (0.1, 0.9) [1.1618, 0.9638, 1.0382, 1.1130, 1.0236, 0.9600, 1.0738, 1.0931, 1.0106, 0.9615, 0.9682, 0.9757, 0.9634]\n",
        "# search loss.sum tensor([1.2238, 1.1183, 1.3781, 1.1171, 1.0220, 1.3172, 1.0393, 1.1780, 1.2760])\n",
        "# search loss.sum tensor([1.1833, 1.1186, 0.9994, 1.1570, 1.1355, 1.2449, 1.1247, 1.0864, 1.1216])\n",
        "# 1e-1, (0.9, 0.999) [1.2336, 1.0372, 1.2104, 1.1552, 1.1631, 1.1355, 1.1355, 1.1828, 1.1648]\n",
        "# 1.0780, 0.9988, 0.9698, 1.0506, 0.9182, 1.0336, 1.0316, 1.0746, 1.0269]\n",
        "\n",
        "# # 1e-1, (0.1, 0.3) [0.9715, 1.0063, 1.0706, 0.9696, 0.9552, 1.0364, 0.9797, 1.0607, 1.0219]\n",
        "# [0.9764, 1.0664, 1.0225, 1.0212, 0.9708, 1.0481, 1.0137, 1.2192, 1.0950])\n",
        "# tensor([ 6, 11,  4,  7,  6,  2])\n",
        "# search loss[idx] 0.9707597494125366\n",
        "\n",
        "\n",
        "# 1e1, momentum=.0 [0.9720, 0.9751, 0.9707, 1.0203, 0.9752, 0.9754, 0.9792, 0.9843, 0.9779])\n",
        "# 1e1,.9 [0.9821, 1.0221, 1.0236, 0.9857, 1.0129, 0.9819, 1.0231, 0.9855, 0.9744]\n",
        "# 1e1,.5 [0.9750, 0.9819, 0.9720, 0.9727, 1.0492, 1.1431, 0.9818, 0.9738, 0.9724]\n",
        "# 1e1,.1 [0.9801, 1.0427, 1.0292, 0.9751, 0.9921, 1.0126, 0.9739, 0.9733, 0.9681]\n",
        "\n",
        "\n",
        "# [12,  2, 13,  6,  7,  2])# search loss[idx] 1.0242162942886353\n",
        "# 1e1,.0 tensor([12,  5, 13, 13,  0,  0]) search loss[idx] 1.0148924589157104\n",
        "\n",
        "# 1e1, (0.1, 0.3) [ 9,  5, 11,  4,  7,  5]) search loss[idx] 0.8813437223434448 [ 6,  5,  9, 11, 11, 14]) search loss[idx] 1.0106048583984375\n",
        "# [1.2524, 1.1733, 1.2672, 1.4926, 1.2828, 1.1139, 1.0241, 1.0392, 1.0212, 1.2391, 1.1198, 1.3839, 1.2508, 1.0636, 1.2459, 1.2499]\n",
        "# 1e0, (0.1, 0.9) [0.9938, 1.1715, 1.0707, 1.1385, 0.9807, 1.0192, 0.9877, 1.1334, 1.1742, 1.3075, 1.0620, 1.2562, 1.1120, 1.1075, 1.0227, 0.9718])\n",
        "# 1e-1, (0.9, 0.9) [1.2246, 1.2571, 1.2877, 1.1991, 1.0697, 1.3019, 1.1740, 1.1950, 1.2564, 1.2413, 1.2670, 1.1604, 1.2582, 1.2152, 1.2209, 1.1972])\n",
        "# tensor([ 6,  2,  7,  6, 11,  8])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4_b7ZSW6IF1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca872b3-8071-4986-897a-eee5d6885320",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY\n",
            "From (redirected): https://drive.google.com/uc?id=1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY&confirm=t&uuid=4381746a-32cb-48b9-bc4a-c423d5c0431b\n",
            "To: /content/buffer512.pkl\n",
            "100% 706M/706M [00:16<00:00, 43.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title gdown\n",
        "# !gdown 1bGWBbcKUgHESkbD3NfYt1WWikScVSFOj -O agentoptim.pkl # M1 gru3 tcost1\n",
        "# !gdown 1XBDhD2efIFW9lnewGRLrb362w47a8b1q -O agentoptim.pkl # B2 gru3 tcost1\n",
        "# !gdown 12Ez0fE8QtJ8b35zeuZQp85mrbHbWvhA_ -O agentoptim.pkl # S3\n",
        "# !gdown 1zoZ52jctM0jed6TgD7kAwrtnuDMeA5II -O agentoptim.pkl # T4 gru1 tcost1 drop\n",
        "# !gdown 1GlZxrzdH5f28Qo4olbOi0vmAK5WDV7jc -O agentoptim.pkl # A2\n",
        "# !gdown 1UDgNtFsWGAhvqR9lwA0QbMLhUtmip4ne -O agentoptim.pkl # M1 agentoptimgru3tcost1\n",
        "# !gdown 1-0oc6yucS5JXLHX1zqbYe3NTVMuhP_5r -O agentoptim.pkl # A2 agentoptim25251c25z3\n",
        "# !gdown 1U1CuCU1FugkrzPXsvTPpIX-wzWz6szl2 -O agentoptim.pkl # T4 agentoptimargm\n",
        "# !gdown 1CWZAtiEwSnglClJbq2LJTYlKhPN10gfo -O agentoptim.pkl # S3 agentoptimargm\n",
        "# !gdown 1XAbr6l1pCmcUCKR6kYlQ_dSDsOBqRg_j -O agentoptim.pkl # B2 argm2search2\n",
        "# !gdown 1UkQuf-IC2LYErSapkF6rZM1dv3svGI5P -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1-4sNf6mINCiD5YsBdQvCrlyqzzfS64si -O agentoptim.pkl # T4 gru3 argm offline\n",
        "# !gdown 1MV9Qj_53Vu6wpe7nOFn47M5vDj7F7-gv -O agentoptim.pkl # S3 agentoptimargm2\n",
        "# !gdown 1--1Vl3337zugQng-j1qbptFY8EvhZA-T -O agentoptim.pkl # T4 agentoptimargm3 online\n",
        "# !gdown 1XHFBVPSH4T4FpUOBKN8X20xDQLNmL7go -O agentoptim.pkl # M1 agentoptimargm4\n",
        "# !gdown 1fFXsee_cSZxhTRewD7ZkGT68NXeq8OcH -O agentoptim.pkl # B2 agentoptimargm4\n",
        "# !gdown 1H31OMz5YBPfmgb7yxVePGddljS9cwVOF -O agentoptim.pkl # B2 agent_nores1\n",
        "# !gdown 1tZpMKsMz7Bh3-X7WE49dsySs-2XOk6Wc -O agentoptim.pkl # T4 agentgru3tcost3\n",
        "# !gdown 1Dsz-poj8y6j_AatGvc4jSu6JWpdPzK0p -O agentoptim.pkl # S3 agentcovgru1fctcost1drop512\n",
        "\n",
        "# !gdown 1sCW9uvcdCJkCH5HQDdISLws5rMvmkmFR -O all_sd.pkl # M1 all_sd\n",
        "\n",
        "import pickle\n",
        "# !gdown 1j9hOq8_752duPB0PMYUJqabNvYoGLysX -O buffer512down.pkl # S\n",
        "# with open('buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY -O buffer512.pkl # S\n",
        "with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# !gdown 1tzlp_Yc_70XSFy2yiCliLd6Jlt1X78lB -O buffergo.pkl # S3\n",
        "# !gdown 1egXy0t_kn0M0oL6sbwixoVr7bqMfcB8j -O buffergo.pkl # T4\n",
        "# !gdown 1-34fhOMTdMvtuAeHuL28Y4taSINvOejQ -O buffergo.pkl # B2\n",
        "# with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 529,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "f7af7937-5b47-419d-cb6f-99badea42a54",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-529-e1817c0d0297>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  modelsd, optimsd = torch.load(folder+'agentcovgru1fctcost1drop.pkl', map_location=device).values()\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "# with open(folder+'buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# with open('buffergo.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'agentoptim.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load(folder+'agentgru1tcost3.pkl', map_location=device).values()\n",
        "modelsd, optimsd = torch.load(folder+'agentcovgru1fctcost1drop.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl', map_location=device).values()\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# modelsd = transfer_sd(agentsd, modelsd)\n",
        "# modelsd = transfer_sd(agent.state_dict(), modelsd)\n",
        "agent.load_state_dict(modelsd, strict=False)\n",
        "# # optimsd = transfer_optim(agent.state_dict(), modelsd, optim.state_dict(), optimsd)\n",
        "optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "# all_sd = torch.load(folder+'all_sd.pkl', map_location=device)\n",
        "# # all_sd = torch.load('all_sd.pkl', map_location=device)\n",
        "# _, convert = rename_sd(agent.state_dict())\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in all_sd.items())\n",
        "# allsd = {}\n",
        "# for (k, v) in all_sd.items():\n",
        "#     try: allsd[convert[k]] = v\n",
        "#     except Exception as e: print('dict err', e)\n",
        "# # agentsd = dict((convert[k], v) for (k, v) in modelsd.items())\n",
        "# tgt_sd = load_sd(agent.state_dict(), allsd)\n",
        "# agent.load_state_dict(tgt_sd, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "# for i, (k,v) in enumerate(modelsd.items()):\n",
        "# for i, (k,v) in enumerate(agent.state_dict().items()):\n",
        "#     print(i,k,v.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBfBomEBnJu0"
      },
      "outputs": [],
      "source": [
        "# buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "# with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# checkpoint = {'model': agentsd, 'optimizer': optim.state_dict(),}\n",
        "checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentgru3tcost3.pkl')\n",
        "torch.save(checkpoint, folder+'agentcovgru3fctcost1drop512.pkl')\n",
        "# torch.save(checkpoint, 'agentoptim.pkl')\n",
        "\n",
        "# all_sd = {}\n",
        "# agentsd, _ = rename_sd(agent.state_dict())\n",
        "# all_sd = store_sd(all_sd, agentsd)\n",
        "# # torch.save(all_sd, 'all_sd.pkl')\n",
        "# torch.save(all_sd, folder+'all_sd.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buffer1=buffer[:512]\n",
        "buffer2=buffer[512:]\n",
        "buffer=buffer1"
      ],
      "metadata": {
        "id": "3f5hTNB0f7_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NVcknabHMxH6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in self.process(buffer) for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)//self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state] # list\n",
        "        return torch.stack(state, dim=0), torch.tensor(action), torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def process(self, buffer):\n",
        "        cleaned = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "        cleaned = [episode[-random.randint(20, 100):] for episode in cleaned]\n",
        "        random.shuffle(cleaned)\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "    # def add(self, episode):\n",
        "    #     self.data.append(episode)\n",
        "\n",
        "    # def pop(self, data, p=1, k=5, n=3): # p: num eps to pop; k: knn clustered; n: ave frames\n",
        "    #     lin= nn.Linear(3*64*64, 100)#, bias=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         imgs = [[sample[0] for sample in random.sample(episode,n)] for episode in buffer] # [num_episodes, num_samples, 64, 64, 3]\n",
        "    #         data=torch.from_numpy(np.stack(imgs)).float().mean(1) # sum mean\n",
        "    #         # imshow(torchvision.utils.make_grid(data.int().permute(0,3,1,2),nrow=4))\n",
        "    #         data=data.flatten(start_dim=-3)\n",
        "    #         data=lin(data) # random projection\n",
        "    #         data = F.normalize(data, dim=-1)\n",
        "    #         idx = torch.randperm(len(data))[:100] # sample some episodes\n",
        "    #         sample = data[idx]\n",
        "    #         index = faiss.IndexFlatL2(data.shape[-1]) # 6.53 ms ± 1.23 ms\n",
        "    #         # index = faiss.IndexFlatIP(data.shape[-1]) #\n",
        "    #         index.add(data)\n",
        "    #         D, I = index.search(sample, k) # estimate clusteredness using k nearest neighbors # dist, idx\n",
        "    #         priority = (2**-D).sum(-1) # L2\n",
        "    #         # priority = -D.sum(-1) # IP\n",
        "    #         topk = torch.topk(priority, p)#, dim=None, largest=True, sorted=True\n",
        "    #         index_list = idx[topk.values] # most clustered\n",
        "    #         for i in reversed(index_list): data.pop(i)\n",
        "    #     return data\n",
        "\n",
        "\n",
        "    # def pop_unif(self, buffer_, n=3):\n",
        "    #     buffer_.pop(random.randrange(len(buffer_)))\n",
        "    #     return buffer_\n",
        "\n",
        "# while len(train_data.data)>10000:\n",
        "#     buffer.pop(random.randrange(len(buffer)))\n",
        "#     train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "def collate_fn(sar):\n",
        "    state, action, reward = zip(*sar)\n",
        "    state=torch.stack(state, dim=1) # batch first -> dim=0\n",
        "    action=torch.stack(action, dim=1)\n",
        "    reward=torch.stack(reward, dim=1)\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 14))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 2 #128\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True)\n",
        "# train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # # [3,T,batch]\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e3fpbtNOiz1",
        "outputId": "e290cab1-7ca5-48ac-a86f-e7f6bdf9824e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1., -1.,  0.,  0.,  0., -1.,  0., -1.,  0.,  0.])\n",
            "tensor([ 0.,  0., -1., -1., -1., -1.,  0., -1.,  0.,  0.])\n",
            "tensor([-1.,  0., -1.,  0.,  0.,  0., -1., -1.,  0.,  0.])\n",
            "tensor([-1.,  0., -1., -1., -1.,  0.,  0.,  0.,  0., -1.])\n",
            "tensor([-9.7976e-01, -9.9798e-01, -9.8263e-04, -1.4105e-03, -1.7848e-03,\n",
            "        -9.9381e-01, -3.1707e-03, -9.9933e-01, -3.0245e-03, -2.0124e-03])\n",
            "tensor([-2.5688e-03, -9.3872e-04, -9.9834e-01, -9.9859e-01, -9.8491e-01,\n",
            "        -9.8778e-01, -2.9584e-02, -8.8245e-01, -2.8346e-03, -1.6771e-03])\n",
            "tensor([-0.9956, -0.0031, -0.9787, -0.0429, -0.0028, -0.0019, -0.9886, -0.9938,\n",
            "        -0.0018, -0.0013])\n",
            "tensor([-0.9921, -0.0017, -0.9911, -0.9986, -0.9837, -0.0022, -0.0022, -0.0020,\n",
            "        -0.0021, -0.9863])\n",
            "tensor(0.3738, grad_fn=<SqueezeBackward1>)\n",
            "tensor(0.0005)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "reward, pred tensor([]) tensor([])\n"
          ]
        }
      ],
      "source": [
        "# @title data weighted\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "data = [step for episode in buffer for step in episode]\n",
        "state, action, reward = zip(*data)\n",
        "# print(\"reward\",type(reward))\n",
        "data_targets=(torch.tensor(reward)==0).int()\n",
        "ctrain_data=list(zip(state,reward))\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "class Datasetme(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, torch.tensor(y, dtype=torch.float)\n",
        "        # return x, y+1\n",
        "ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "class_count=torch.tensor([x[1] for x in class_count])\n",
        "weight=1./class_count\n",
        "weights = weight[data_targets]\n",
        "\n",
        "# batch_size = 64 #\n",
        "\n",
        "train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "# train_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "c_loader = torch.utils.data.DataLoader(ctrain_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "\n",
        "def make_weighted(buffer):\n",
        "    data = [step for episode in buffer for step in episode]\n",
        "    state, action, reward = zip(*data)\n",
        "    # print(\"reward\",type(reward))\n",
        "    data_targets=(torch.tensor(reward)==0).int()\n",
        "    ctrain_data=list(zip(state,reward))\n",
        "    ctrain_data = Datasetme(ctrain_data)\n",
        "\n",
        "    from collections import Counter\n",
        "    class_count = torch.tensor(list(Counter(data_targets.tolist()).values()))\n",
        "    class_count = sorted(Counter(data_targets.tolist()).items())\n",
        "    class_count=torch.tensor([x[1] for x in class_count])\n",
        "    weight=1./class_count\n",
        "    weights = weight[data_targets]\n",
        "\n",
        "    # batch_size = 64 #\n",
        "    train_sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
        "    c_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n",
        "    return c_loader\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "def imshow(img): # display img from torch tensor\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.axis('off')\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "trainiter = iter(c_loader)\n",
        "images, labels = next(trainiter)\n",
        "# images, labels = images.to(device), labels.to(device)\n",
        "batch=min(40, batch_size)\n",
        "images, labels = images[:batch], labels[:batch]\n",
        "# imshow(torchvision.utils.make_grid(images,nrow=10))\n",
        "# print(labels)\n",
        "for x in range(len(labels)//10):\n",
        "    print(labels[10*x:10*x+10])\n",
        "\n",
        "# # try:\n",
        "with torch.no_grad():\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).argmax(-1).cpu()\n",
        "    # pred = agent.tcost(agent.jepa.enc(images.to(device))).squeeze(-1).cpu()\n",
        "    # _, world_state = agent.get(images.to(device))\n",
        "    # pred = agent.tcost(agent.jepa.enc(world_state.unsqueeze(1))).squeeze(-1).cpu()\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch, agent.d_model), device=device)\n",
        "    # h0 = torch.empty((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device)\n",
        "    # torch.nn.init.xavier_normal_(h0)\n",
        "    sy = agent.jepa.enc(images.to(device)) # [batch_size, d_model]\n",
        "    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "    pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "\n",
        "    # print(pred)\n",
        "    for x in range(len(pred)//10):\n",
        "        print(pred[10*x:10*x+10])\n",
        "    # print((labels==pred).sum())\n",
        "# except: pass\n",
        "print(agent.tcost.loss(syh0, labels.to(device)).squeeze(-1))\n",
        "print(F.mse_loss(labels, pred))\n",
        "\n",
        "# torch.where(abs(labels- pred)>0.5,1,0)\n",
        "for x in range(len(pred)//10):\n",
        "    print(torch.where(abs(labels- pred)>0.5,1,0)[10*x:10*x+10])\n",
        "\n",
        "# mask = torch.where(abs(labels- pred)>0.5,1,0).bool()\n",
        "mask = (abs(labels- pred)>0.5)\n",
        "print(\"reward, pred\", labels[mask].data, pred[mask].data)\n",
        "try: imshow(torchvision.utils.make_grid(images[mask], nrow=10))\n",
        "except ZeroDivisionError: pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksm4ha7XA-BN"
      },
      "outputs": [],
      "source": [
        "# optim = torch.optim.SGD(agent.parameters(), 1e-1, momentum=0.9, dampening=0, weight_decay=0)\n",
        "# print(optim.param_groups[0][\"lr\"])\n",
        "# print(optim)\n",
        "optim.param_groups[0][\"lr\"] = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGYjyJZ5aG5z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title wwwwwwwwwwww\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    # plt.figure(figsize=(4, 4))\n",
        "    plt.figure()\n",
        "    print(npimg.shape)\n",
        "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "import torchvision.transforms.v2 as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for i in range(200):\n",
        "    print(i)\n",
        "    train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    # checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    # # # torch.save(checkpoint, folder+'agentgru3tcost3.pkl')\n",
        "    # # torch.save(checkpoint, folder+'agentcovgru1tcost3drop.pkl')\n",
        "    # torch.save(checkpoint, folder+'agentgru1tcost3goscratch.pkl')\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "# batch64 28m58s 84\n",
        "\n",
        "\n",
        "# repr, std, cov, clossl, z, norm 0.005674966610968113 0.3493117690086365 0.1219848245382309 0.11347860097885132 0.16498714685440063 1.429775595664978\n",
        "# repr, std, cov, clossl, z, norm 0.004161856137216091 0.35110002756118774 0.10768019407987595 0.14673584699630737 0.17844633758068085 8.552577018737793\n",
        "# repr, std, cov, clossl, z, norm 0.005356341600418091 0.354144811630249 0.10272272676229477 0.14740866422653198 0.1459342986345291 0.08476211130619049\n",
        "\n",
        "\n",
        "# repr, std, cov, clossl, z, norm 0.03280682861804962 0.3602587580680847 0.0940496101975441 12.544517517089844 0.0145032973960042 0.10470973700284958\n",
        "# repr, std, cov, clossl, z, norm 0.0022784259635955095 0.37327876687049866 0.12404247373342514 5.347583770751953 0.0835014060139656 0.7087528705596924\n",
        "# repr, std, cov, clossl, z, norm 0.005345265381038189 0.34533047676086426 0.4332529306411743 2.4848036766052246 0.12125874310731888 0.9996055960655212\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-_pfGZTsip",
        "outputId": "15ef3325-b7de-4ef2-d636-750d67c66619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# @title procgen\n",
        "# https://github.com/openai/procgen\n",
        "import gym\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\")\n",
        "# env = gym.make(\"procgen:procgen-coinrun-v0\", start_level=0, num_levels=1)\n",
        "\n",
        "# from procgen import ProcgenGym3Env\n",
        "# env = ProcgenGym3Env(num=1, env_name=\"coinrun\")\n",
        "\n",
        "env_name=\"procgen:procgen-{}-v0\".format(\"bigfish\") # https://github.com/openai/procgen/blob/master/procgen/gym_registration.py#L29\n",
        "env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\")\n",
        "# env = gym.make(env_name, use_sequential_levels=True, render_mode=\"rgb_array\", use_backgrounds=False, restrict_themes=True, use_monochrome_assets=True)\n",
        "\n",
        "# ENV_NAMES = [\"bigfish\", \"bossfight\", \"caveflyer\", \"chaser\", \"climber\", \"coinrun\", \"dodgeball\", \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\", \"miner\", \"ninja\", \"plunder\", \"starpilot\",]\n",
        "\n",
        "\n",
        "# # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "# 2  5/11 8\n",
        "# 1/10 4 7/9\n",
        "# 0  3/12 6\n",
        "\n",
        "# 13 11 14\n",
        "# 10 12 9\n",
        "\n",
        "# from gymnasium.wrappers import TimeLimit\n",
        "from gym.wrappers import TimeLimit\n",
        "env = TimeLimit(env, max_episode_steps=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 532,
      "metadata": {
        "cellView": "form",
        "id": "PraFUAPB3j7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb7db61-ac9c-4947-c27b-82f36f56fccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-528-c5291a39c442>:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-528-c5291a39c442>:90: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update_h0 loss, lz 0 0.028517961502075195 tensor([[-0.1155,  0.1215,  0.0685,  0.0073, -0.0453, -0.0008, -0.0008, -0.0287]])\n",
            "0 search x tensor([ 0.2473,  0.3135, -0.4726])\n",
            "0 search loss tensor([0.8468, 0.8467, 0.8522, 0.8606, 0.8569, 0.8907, 0.8451, 0.8468, 0.8535,\n",
            "        0.9102, 0.8450, 0.8083, 0.8520, 0.9378, 0.8680, 1.1037])\n",
            "1 search x tensor([ 0.1471,  0.4132, -0.3722])\n",
            "1 search loss tensor([1.0015, 1.2248, 1.3512, 1.2022, 0.8534, 1.1581, 0.8529, 0.9239, 1.2155,\n",
            "        1.3733, 0.8525, 1.0827, 1.1598, 1.1711, 1.2393, 1.3714])\n",
            "2 search x tensor([ 0.0180,  0.3911, -0.4539])\n",
            "2 search loss tensor([1.3656, 1.4049, 1.3404, 1.1364, 0.8038, 1.3778, 0.8351, 1.3706, 1.1577,\n",
            "        1.3574, 0.9698, 1.4007, 0.8477, 0.8483, 0.8529, 1.3533])\n",
            "3 search x tensor([ 0.1115,  0.4534, -0.3746])\n",
            "3 search loss tensor([1.3622, 1.3821, 1.2792, 0.9404, 0.8252, 1.3778, 1.1680, 1.3692, 0.8168,\n",
            "        1.3574, 1.3740, 1.3526, 0.8209, 1.3880, 0.8151, 1.3456])\n",
            "4 search x tensor([ 0.2248,  0.5283, -0.2762])\n",
            "4 search loss tensor([1.3184, 1.2857, 1.2340, 0.9563, 0.7605, 1.3098, 0.8078, 1.3184, 0.7539,\n",
            "        1.2747, 1.3384, 1.2374, 0.7719, 1.3880, 0.7649, 1.2851])\n",
            "5 search x tensor([ 0.1755,  0.5250, -0.1219])\n",
            "5 search loss tensor([1.2872, 1.1734, 1.2413, 0.9565, 0.7605, 1.2993, 0.8139, 1.2872, 0.7649,\n",
            "        1.2417, 1.3399, 1.1957, 0.7605, 1.3767, 0.7492, 1.2726])\n",
            "6 search x tensor([0.0420, 0.4553, 0.0589])\n",
            "6 search loss tensor([1.1299, 1.1448, 1.2416, 0.8970, 0.7605, 1.2988, 0.8526, 1.2872, 0.7538,\n",
            "        1.2148, 1.2951, 1.1595, 0.7605, 1.3740, 0.7502, 1.0834])\n",
            "tensor([11,  2, 13,  6,  9, 11])\n",
            "search loss[idx] 0.7502182126045227\n",
            "update_h0 loss, lz 0 0.016088321805000305 tensor([[-0.4113,  0.1003, -0.1374,  0.0283,  0.1294,  0.0746,  0.0286, -0.0121],\n",
            "        [-0.1102,  0.1072, -0.0771, -0.1060,  0.0619, -0.0060,  0.1924,  0.1172],\n",
            "        [ 0.1056,  0.0506,  0.0287,  0.0096, -0.0728, -0.0048,  0.0826,  0.0542],\n",
            "        [-0.0860, -0.1637, -0.0123,  0.0769, -0.1692,  0.0228, -0.1338, -0.1905]])\n",
            "0 search x tensor([ 0.4955,  0.0136, -0.4589])\n",
            "0 search loss tensor([1.1632, 1.1427, 1.1590, 1.0045, 0.9936, 1.1626, 1.0056, 0.9142, 0.9701,\n",
            "        0.9184, 0.8615, 1.1379, 0.8893, 1.1836, 0.9252, 1.0245])\n",
            "1 search x tensor([ 0.3950, -0.0864, -0.3585])\n",
            "1 search loss tensor([1.0962, 1.1134, 0.9578, 1.1493, 1.0682, 1.0894, 1.1767, 1.1868, 1.1180,\n",
            "        1.0440, 1.1526, 1.0975, 1.1733, 1.1189, 1.0030, 1.0637])\n",
            "2 search x tensor([ 0.2725, -0.1848, -0.2528])\n",
            "2 search loss tensor([0.9550, 0.9997, 1.0903, 1.1613, 1.1801, 1.0494, 1.1755, 1.1369, 1.0340,\n",
            "        1.1915, 1.0481, 1.0375, 1.1188, 0.9165, 1.0850, 1.1162])\n",
            "3 search x tensor([ 0.2502, -0.1477, -0.1930])\n",
            "3 search loss tensor([0.8947, 0.8931, 0.9897, 1.1650, 1.1644, 0.8939, 1.1094, 1.1847, 1.1313,\n",
            "        1.1876, 0.9739, 0.9144, 1.1184, 0.9183, 1.1814, 1.0263])\n",
            "4 search x tensor([ 0.2422, -0.2587, -0.1019])\n",
            "4 search loss tensor([0.8579, 0.8675, 0.9440, 1.0888, 1.0136, 0.8676, 0.9933, 1.1458, 1.0933,\n",
            "        1.1625, 0.9311, 0.9147, 0.9283, 0.8946, 0.7507, 0.8694])\n",
            "5 search x tensor([ 0.2261, -0.2285, -0.1072])\n",
            "5 search loss tensor([0.7966, 0.7607, 0.8000, 1.0494, 0.9862, 0.8017, 0.9262, 1.1477, 1.0080,\n",
            "        1.0359, 0.9322, 0.8840, 0.9027, 0.8720, 1.0806, 0.8724])\n",
            "6 search x tensor([ 0.2183, -0.2023, -0.1102])\n",
            "6 search loss tensor([0.8461, 0.8062, 0.8958, 1.0494, 0.8301, 0.8014, 0.9520, 1.0179, 0.9512,\n",
            "        0.9312, 0.7364, 0.8499, 0.9025, 0.9107, 1.0888, 0.8515])\n",
            "tensor([ 6, 11,  4,  7,  3,  5])\n",
            "search loss[idx] 0.7363643050193787\n",
            "update_h0 loss, lz 0 0.014121207408607006 tensor([[-0.0762,  0.0358, -0.0056,  0.1430, -0.1835,  0.0372, -0.0261, -0.1583],\n",
            "        [ 0.1612,  0.1234, -0.0042, -0.0273, -0.0204, -0.0341, -0.0802,  0.0562],\n",
            "        [-0.0487,  0.1022,  0.0585, -0.0391,  0.0648, -0.0585,  0.0994,  0.0309],\n",
            "        [ 0.0100, -0.1278,  0.0523,  0.0567,  0.0216,  0.1122,  0.0669, -0.0512]])\n",
            "0 search x tensor([-0.3513, -0.8331,  0.4272])\n",
            "0 search loss tensor([1.0458, 1.0428, 1.0380, 1.0457, 1.0502, 1.0351, 1.0682, 1.0293, 1.0381,\n",
            "        1.1276, 1.0566, 1.0502, 1.0405, 1.0280, 1.0495, 1.0413])\n",
            "1 search x tensor([-0.2281, -0.8477,  0.4789])\n",
            "1 search loss tensor([0.9942, 1.0091, 1.0032, 1.0119, 0.9978, 0.9640, 0.9993, 0.9838, 1.0068,\n",
            "        0.9989, 1.0037, 0.9823, 0.9899, 0.9893, 1.0030, 0.9959])\n",
            "2 search x tensor([-0.2844, -0.8156,  0.5040])\n",
            "2 search loss tensor([0.9942, 0.9929, 0.9761, 0.9467, 0.9701, 0.9647, 1.0006, 0.9086, 1.0071,\n",
            "        0.9894, 0.9329, 0.9714, 0.9939, 0.9386, 0.9869, 0.9966])\n",
            "3 search x tensor([-0.2966, -0.7973,  0.5258])\n",
            "3 search loss tensor([0.9537, 0.9798, 0.9235, 1.0328, 0.9147, 0.9414, 1.0006, 0.9577, 0.9733,\n",
            "        0.9920, 0.9230, 1.0489, 0.9725, 0.9387, 0.9653, 0.9882])\n",
            "4 search x tensor([-0.1720, -0.8092,  0.5618])\n",
            "4 search loss tensor([0.8993, 0.9675, 0.8579, 0.8510, 0.9152, 0.9252, 0.9811, 0.9581, 0.9420,\n",
            "        0.9649, 0.9409, 0.9742, 0.9387, 0.8983, 1.0218, 0.9738])\n",
            "5 search x tensor([ 0.0256, -0.8075,  0.5893])\n",
            "5 search loss tensor([0.9419, 0.8833, 0.9063, 0.7366, 0.8830, 0.9253, 0.9840, 0.9587, 0.8870,\n",
            "        0.9654, 0.9451, 0.9750, 0.9387, 0.8985, 0.9542, 0.9684])\n",
            "6 search x tensor([-0.1155, -0.7888,  0.6037])\n",
            "6 search loss tensor([0.9167, 0.9040, 0.9080, 0.9024, 0.9811, 0.9253, 0.9841, 0.9491, 0.9475,\n",
            "        0.9654, 0.9398, 0.9683, 0.9387, 0.8510, 0.9453, 0.9588])\n",
            "tensor([ 6,  5,  6,  7, 10,  2])\n",
            "search loss[idx] 0.8510161638259888\n",
            "update_h0 loss, lz 0 0.012597505003213882 tensor([[-0.0789,  0.1586, -0.0338,  0.0438, -0.0248, -0.0640,  0.0093, -0.0570],\n",
            "        [-0.0284, -0.1467,  0.0910, -0.0670, -0.1051,  0.1946, -0.0219, -0.0043],\n",
            "        [ 0.0886,  0.0919,  0.0381,  0.0413,  0.0252, -0.1372, -0.0910, -0.2293],\n",
            "        [ 0.0006, -0.0831,  0.2429, -0.0251, -0.1633, -0.0206, -0.0507,  0.1034]])\n",
            "0 search x tensor([ 0.3297, -0.4447,  0.6834])\n",
            "0 search loss tensor([1.1865, 1.1830, 1.1666, 1.1836, 1.1102, 1.1621, 1.1834, 1.1700, 1.2124,\n",
            "        1.1708, 1.2038, 1.1669, 1.1836, 1.1502, 1.2281, 1.1104])\n",
            "1 search x tensor([ 0.2294, -0.5443,  0.7828])\n",
            "1 search loss tensor([1.0943, 1.1158, 1.1027, 0.9744, 1.0738, 1.0421, 1.0642, 1.0725, 1.0839,\n",
            "        1.1036, 1.1403, 1.0726, 1.1156, 1.0785, 1.0445, 1.0592])\n",
            "2 search x tensor([ 0.1300, -0.4437,  0.8669])\n",
            "2 search loss tensor([1.0440, 1.0290, 1.1027, 0.9746, 1.0752, 0.9958, 1.0629, 0.9510, 0.8900,\n",
            "        1.0021, 1.1001, 0.9942, 1.1090, 1.0218, 0.9495, 1.0256])\n",
            "3 search x tensor([ 0.0387, -0.3311,  0.9428])\n",
            "3 search loss tensor([0.9904, 0.9188, 0.7706, 0.7876, 1.0420, 0.8889, 0.9011, 0.8237, 0.8901,\n",
            "        0.9155, 1.0399, 0.8827, 1.0187, 0.9893, 0.9163, 0.9159])\n",
            "4 search x tensor([-0.0348, -0.2709,  0.9620])\n",
            "4 search loss tensor([0.8909, 0.8070, 0.7367, 0.8188, 0.9704, 0.7964, 0.7527, 0.7699, 0.7486,\n",
            "        0.8428, 1.0592, 0.7299, 0.8082, 0.8142, 0.8782, 0.8813])\n",
            "5 search x tensor([-0.1037, -0.2877,  0.9521])\n",
            "5 search loss tensor([0.8479, 0.7233, 0.6370, 0.6947, 0.8183, 0.7180, 0.7532, 0.7227, 0.7484,\n",
            "        0.5901, 0.7597, 0.6441, 0.7193, 0.7675, 0.7526, 0.6955])\n",
            "6 search x tensor([-0.1601, -0.3128,  0.9362])\n",
            "6 search loss tensor([0.7063, 0.7514, 0.7642, 0.6981, 0.8197, 0.7614, 0.6125, 0.6436, 0.7524,\n",
            "        0.5901, 0.6291, 0.6465, 0.8009, 0.6324, 0.6699, 0.8022])\n",
            "tensor([ 7,  2,  6, 12,  6,  5])\n",
            "search loss[idx] 0.5901227593421936\n",
            "update_h0 loss, lz 0 0.012964076362550259 tensor([[-0.0497,  0.2166,  0.0207, -0.1863,  0.1293,  0.0968, -0.0847, -0.0361],\n",
            "        [-0.0797, -0.0886, -0.0043, -0.1726,  0.0383,  0.1421, -0.1567, -0.0147],\n",
            "        [-0.0675,  0.0986,  0.0617, -0.1119, -0.1101,  0.0256, -0.0721, -0.0945],\n",
            "        [-0.0968, -0.0217,  0.0231,  0.0308, -0.0477,  0.0026,  0.0710,  0.0584]])\n",
            "0 search x tensor([ 0.0360, -0.4502,  0.6471])\n",
            "0 search loss tensor([1.0993, 1.0276, 0.9981, 1.1323, 1.3857, 1.1356, 1.1478, 1.1437, 0.9147,\n",
            "        1.1710, 0.9527, 1.1029, 1.0724, 1.0553, 1.1556, 0.7158])\n",
            "1 search x tensor([-0.0641, -0.5498,  0.7464])\n",
            "1 search loss tensor([1.1145, 1.1821, 1.1354, 1.0694, 1.1553, 1.1620, 1.1700, 1.1539, 0.9379,\n",
            "        1.1851, 1.2229, 1.1287, 1.0883, 1.1162, 1.1801, 1.0166])\n",
            "2 search x tensor([-0.1506, -0.6063,  0.7808])\n",
            "2 search loss tensor([1.1021, 0.9198, 0.9227, 1.1655, 1.1553, 1.0179, 1.0008, 1.0078, 1.2042,\n",
            "        0.9958, 1.0291, 1.1030, 1.0492, 1.1682, 0.8231, 1.0834])\n",
            "3 search x tensor([-0.2398, -0.4920,  0.8369])\n",
            "3 search loss tensor([1.0262, 0.7194, 1.1055, 1.0379, 1.1526, 0.9847, 0.9131, 0.9362, 1.0012,\n",
            "        0.9441, 0.9595, 0.9904, 0.9400, 1.0198, 0.8445, 0.8722])\n",
            "4 search x tensor([-0.3000, -0.3198,  0.8987])\n",
            "4 search loss tensor([0.8184, 0.7350, 1.0738, 0.8842, 0.9580, 0.9582, 0.8163, 0.8562, 0.8357,\n",
            "        0.9211, 0.9369, 0.9904, 0.7988, 0.9556, 0.7325, 0.7844])\n",
            "5 search x tensor([-0.3059, -0.3591,  0.8817])\n",
            "5 search loss tensor([0.7723, 0.7346, 0.8027, 0.8842, 0.8706, 0.7868, 0.8277, 0.8563, 0.7851,\n",
            "        0.8780, 0.8916, 0.9393, 0.7771, 0.9566, 0.9032, 0.9396])\n",
            "6 search x tensor([-0.2748, -0.5042,  0.8187])\n",
            "6 search loss tensor([0.7436, 0.9660, 0.7334, 0.8587, 0.8065, 0.8124, 0.7329, 0.8150, 0.7573,\n",
            "        0.8328, 0.8916, 0.7844, 0.7381, 0.9567, 0.6701, 0.8493])\n",
            "tensor([6, 5, 1, 6, 7, 5])\n",
            "search loss[idx] 0.6700536608695984\n",
            "update_h0 loss, lz 0 0.013877877034246922 tensor([[ 0.2453,  0.0036,  0.0158, -0.0022, -0.1062, -0.0636, -0.0968, -0.1005],\n",
            "        [-0.0379,  0.0130,  0.0396,  0.0432,  0.0221, -0.0170,  0.0690,  0.2027],\n",
            "        [ 0.2092, -0.0342,  0.1672, -0.0915, -0.0240, -0.1799,  0.1575, -0.0011],\n",
            "        [ 0.0525,  0.0344,  0.0429, -0.0831,  0.0285, -0.0763,  0.0820, -0.1030]])\n",
            "0 search x tensor([-0.5421, -0.1883,  0.5366])\n",
            "0 search loss tensor([1.2576, 0.7896, 0.7381, 0.7936, 0.7817, 0.7916, 0.8002, 0.7786, 0.7838,\n",
            "        0.8032, 0.7641, 0.7727, 1.1186, 0.7848, 0.7955, 0.7662])\n",
            "1 search x tensor([-0.4416, -0.2881,  0.6361])\n",
            "1 search loss tensor([1.0749, 1.2233, 0.7626, 0.7397, 1.4076, 1.3163, 0.7424, 1.2532, 1.3011,\n",
            "        1.1989, 1.2835, 1.3122, 1.1110, 1.2613, 1.2815, 1.2810])\n",
            "2 search x tensor([-0.3540, -0.3869,  0.7217])\n",
            "2 search loss tensor([0.8342, 0.9761, 1.2149, 0.7545, 1.0132, 0.7444, 0.7328, 1.0882, 1.1905,\n",
            "        1.2633, 1.1510, 1.1415, 0.8662, 0.8770, 1.0960, 1.1471])\n",
            "3 search x tensor([-0.2461, -0.4939,  0.7848])\n",
            "3 search loss tensor([0.7647, 0.8749, 0.8052, 1.4584, 0.8807, 1.2823, 1.2796, 1.0886, 1.2006,\n",
            "        1.1440, 1.1476, 1.1333, 0.7509, 0.7338, 0.9592, 1.0760])\n",
            "4 search x tensor([-0.2155, -0.4768,  0.8001])\n",
            "4 search loss tensor([0.7996, 0.8701, 0.7718, 0.7723, 0.7609, 1.1570, 1.2860, 0.9764, 0.8759,\n",
            "        1.0927, 0.9581, 1.0423, 0.7290, 1.1725, 0.8728, 1.0001])\n",
            "5 search x tensor([-0.1990, -0.4084,  0.8190])\n",
            "5 search loss tensor([1.0778, 0.8701, 0.7344, 0.7406, 0.7640, 1.1097, 1.1479, 0.8749, 0.8575,\n",
            "        0.9942, 0.8750, 1.0423, 0.7399, 1.1307, 0.8728, 1.0001])\n",
            "6 search x tensor([-0.2278, -0.3327,  0.8092])\n",
            "6 search loss tensor([0.9954, 0.8701, 1.0435, 1.1681, 0.7723, 1.1097, 1.0252, 0.8750, 0.8575,\n",
            "        1.0216, 0.8701, 0.8750, 1.2181, 1.1289, 0.8694, 0.8701])\n",
            "tensor([ 6,  5,  6,  7, 11,  6])\n",
            "search loss[idx] 0.7722989320755005\n",
            "update_h0 loss, lz 0 0.015999600291252136 tensor([[ 0.0613, -0.0551, -0.0236,  0.0601,  0.0656, -0.1407,  0.1999,  0.0877],\n",
            "        [-0.0535, -0.0774,  0.1636, -0.0900,  0.0049, -0.1017, -0.0017,  0.0076],\n",
            "        [ 0.0317,  0.1143,  0.1422,  0.0561, -0.0140, -0.0582, -0.1135,  0.2094],\n",
            "        [ 0.0854,  0.1873,  0.1440,  0.0975,  0.0457, -0.0698, -0.0596, -0.2041]])\n",
            "0 search x tensor([ 0.3193,  0.4792, -0.1592])\n",
            "0 search loss tensor([0.7747, 1.4033, 1.3945, 1.3958, 1.3921, 0.9349, 1.4099, 1.3212, 1.3472,\n",
            "        0.7192, 1.3920, 0.7426, 1.2533, 1.3482, 1.3715, 1.3404])\n",
            "1 search x tensor([ 0.2190,  0.5787, -0.2591])\n",
            "1 search loss tensor([1.2369, 1.3981, 1.3909, 1.4025, 1.4051, 1.3181, 1.4177, 1.3822, 1.3800,\n",
            "        1.4011, 1.3993, 1.3385, 1.3699, 1.3158, 1.3909, 1.3696])\n",
            "2 search x tensor([ 0.3426,  0.7072, -0.2207])\n",
            "2 search loss tensor([1.2191, 1.3810, 1.3420, 1.3596, 1.2990, 1.3190, 1.3813, 1.3269, 1.3765,\n",
            "        1.4013, 1.3694, 1.3507, 1.2847, 1.2741, 1.3078, 1.3098])\n",
            "3 search x tensor([ 0.4491,  0.7428, -0.0887])\n",
            "3 search loss tensor([0.8594, 1.2144, 1.1604, 1.2893, 1.1914, 0.7870, 1.2664, 1.0521, 1.3706,\n",
            "        1.3562, 1.3078, 1.2367, 1.0218, 1.2478, 1.1916, 1.0626])\n",
            "4 search x tensor([ 0.4915,  0.7651, -0.0967])\n",
            "4 search loss tensor([1.3841, 1.0381, 1.0088, 1.1399, 1.1327, 0.7764, 1.1740, 0.9257, 1.3564,\n",
            "        1.3178, 1.1672, 1.0274, 0.9341, 1.1758, 1.2748, 1.0899])\n",
            "5 search x tensor([0.4965, 0.7035, 0.0192])\n",
            "5 search loss tensor([1.3717, 0.9410, 1.0174, 1.1266, 0.9666, 0.7768, 1.1745, 0.9296, 1.3247,\n",
            "        1.0024, 1.1159, 0.9879, 0.8765, 1.1295, 1.0778, 0.9802])\n",
            "6 search x tensor([0.4875, 0.6162, 0.1535])\n",
            "6 search loss tensor([1.2665, 0.9445, 0.7625, 1.0300, 0.9667, 0.7768, 1.0893, 0.9297, 1.2815,\n",
            "        0.9952, 1.0457, 0.9462, 0.8317, 1.0516, 0.9892, 0.9296])\n",
            "tensor([11,  8,  7, 13,  9,  0])\n",
            "search loss[idx] 0.7625141143798828\n",
            "update_h0 loss, lz 0 0.012396498583257198 tensor([[-0.0197,  0.0528,  0.0792,  0.1461,  0.0096, -0.0794, -0.0168,  0.1041],\n",
            "        [ 0.0062,  0.0331, -0.0906, -0.1552,  0.1349, -0.1735,  0.0556,  0.0271],\n",
            "        [ 0.1530, -0.0538,  0.1316, -0.0041, -0.2078,  0.1223, -0.0678,  0.1695],\n",
            "        [ 0.0072, -0.1340, -0.1028,  0.0451, -0.1640, -0.0273, -0.0965,  0.1429]])\n",
            "0 search x tensor([ 0.7166,  0.1764, -0.1382])\n",
            "0 search loss tensor([1.2286, 1.2199, 1.0324, 0.9249, 1.2608, 1.2060, 1.1915, 1.2163, 1.2195,\n",
            "        1.2306, 1.2116, 1.0305, 1.2183, 1.0255, 0.7372, 1.1984])\n",
            "1 search x tensor([ 0.8158,  0.2762, -0.0381])\n",
            "1 search loss tensor([1.1709, 1.1800, 1.0677, 1.2427, 0.8278, 1.1881, 1.2029, 1.1986, 1.1950,\n",
            "        1.2307, 1.2233, 1.1963, 1.1252, 1.2500, 1.0252, 1.1921])\n",
            "2 search x tensor([0.7714, 0.1483, 0.0910])\n",
            "2 search loss tensor([1.1549, 1.1497, 1.1455, 0.7295, 1.2374, 1.1885, 1.1846, 1.1905, 1.1663,\n",
            "        1.0891, 1.2087, 1.0684, 1.1253, 1.2042, 0.7374, 1.1942])\n",
            "3 search x tensor([0.6423, 0.0192, 0.2226])\n",
            "3 search loss tensor([1.1401, 1.0919, 1.2718, 0.7296, 1.2267, 1.0869, 1.1565, 1.1550, 1.1311,\n",
            "        0.8252, 1.1211, 1.2182, 1.1284, 1.1979, 1.1929, 1.1355])\n",
            "4 search x tensor([ 0.4861, -0.1152,  0.3573])\n",
            "4 search loss tensor([1.0358, 0.9592, 1.2243, 1.2189, 1.1877, 0.9927, 0.8899, 0.9811, 1.0210,\n",
            "        1.1104, 0.9956, 1.1963, 0.9024, 1.2192, 1.1963, 0.9203])\n",
            "5 search x tensor([ 0.3035, -0.2680,  0.4876])\n",
            "5 search loss tensor([0.9376, 0.9354, 1.2303, 1.1285, 0.9952, 0.8565, 0.9432, 0.8874, 0.9158,\n",
            "        1.0494, 0.8342, 1.1852, 0.8970, 1.2164, 1.1813, 0.8584])\n",
            "6 search x tensor([ 0.2160, -0.2994,  0.5834])\n",
            "6 search loss tensor([0.8351, 0.8726, 1.2243, 1.0650, 0.9951, 0.8327, 0.8540, 0.8612, 0.8585,\n",
            "        0.7920, 0.9553, 1.2252, 0.7373, 1.1490, 1.1840, 0.8420])\n",
            "tensor([10,  8,  6,  4,  0,  0])\n",
            "search loss[idx] 0.7373443841934204\n",
            "update_h0 loss, lz 0 0.01272707898169756 tensor([[ 0.0827, -0.0683, -0.1690,  0.1134, -0.1116, -0.2310,  0.1395,  0.0101],\n",
            "        [-0.1792,  0.0362,  0.0666, -0.0316,  0.2712, -0.0930, -0.2028, -0.0618],\n",
            "        [ 0.0651,  0.0064, -0.0660, -0.0622, -0.1447, -0.0750,  0.0014, -0.1490],\n",
            "        [-0.0396,  0.1059, -0.0485,  0.0020, -0.0473, -0.2214,  0.0248, -0.0486]])\n",
            "0 search x tensor([ 0.3740, -0.2916, -0.3420])\n",
            "0 search loss tensor([1.3992, 1.3481, 1.3842, 1.2055, 0.7491, 0.4959, 1.2703, 0.7491, 0.7494,\n",
            "        0.7492, 1.4081, 0.9181, 0.8334, 1.2147, 1.3260, 1.2456])\n",
            "1 search x tensor([ 0.4737, -0.1913, -0.2416])\n",
            "1 search loss tensor([1.2054, 1.0426, 1.1494, 1.3674, 1.2709, 1.3607, 1.3480, 1.3828, 1.3726,\n",
            "        0.7210, 1.2358, 0.8865, 1.2059, 1.2819, 1.2939, 1.1808])\n",
            "2 search x tensor([ 0.5288, -0.1204, -0.1124])\n",
            "2 search loss tensor([1.0953, 1.1961, 0.9177, 1.3682, 1.3797, 1.3637, 0.8364, 1.3647, 1.1825,\n",
            "        1.0998, 1.1509, 1.2180, 1.3233, 1.3631, 1.1499, 1.2876])\n",
            "3 search x tensor([ 0.5423, -0.0967,  0.0332])\n",
            "3 search loss tensor([1.2260, 0.6256, 1.1641, 1.3310, 1.3535, 1.3521, 1.2433, 1.3659, 1.1832,\n",
            "        1.3832, 1.1210, 1.3387, 1.2242, 1.1319, 1.1391, 1.2275])\n",
            "4 search x tensor([ 0.5453, -0.0686,  0.0424])\n",
            "4 search loss tensor([0.9517, 1.0844, 1.1862, 1.1985, 1.2743, 1.1912, 1.2046, 1.3116, 1.2901,\n",
            "        1.3813, 1.1596, 1.2928, 1.2729, 1.1757, 0.8901, 1.2835])\n",
            "5 search x tensor([ 0.4892, -0.0149,  0.1632])\n",
            "5 search loss tensor([1.0453, 1.0913, 1.1308, 1.1644, 1.2312, 1.1548, 0.8886, 1.2774, 1.2331,\n",
            "        1.3788, 1.2912, 1.3393, 1.2495, 1.3662, 1.1465, 1.3173])\n",
            "6 search x tensor([ 0.5926, -0.0187,  0.3273])\n",
            "6 search loss tensor([1.3514, 1.0516, 1.0606, 1.1677, 1.2705, 1.1457, 0.8487, 1.2439, 1.3523,\n",
            "        1.3735, 1.3099, 1.2653, 1.1278, 1.3541, 1.0265, 1.3126])\n",
            "tensor([ 0,  5, 13, 13,  1,  0])\n",
            "search loss[idx] 0.8486538529396057\n",
            "update_h0 loss, lz 0 0.013309428468346596 tensor([[-0.0889, -0.0723, -0.1333,  0.0395, -0.0360,  0.0419,  0.0802,  0.1736],\n",
            "        [ 0.0905, -0.0253, -0.2182, -0.0099, -0.0223, -0.1093, -0.1144,  0.0167],\n",
            "        [-0.0439,  0.0365, -0.0226,  0.0379, -0.0461,  0.0980, -0.0039,  0.1363],\n",
            "        [-0.1217, -0.0403, -0.0795,  0.2022,  0.1828, -0.2050,  0.1078,  0.1893]])\n",
            "0 search x tensor([0.2497, 0.3517, 0.1456])\n",
            "0 search loss tensor([1.2643, 1.2708, 1.2838, 1.2441, 1.2921, 1.2129, 1.2630, 1.2474, 1.2761,\n",
            "        1.2665, 1.2038, 1.2252, 1.2660, 1.2247, 1.2329, 1.2432])\n",
            "1 search x tensor([0.3495, 0.2513, 0.2455])\n",
            "1 search loss tensor([1.2080, 1.2272, 1.2829, 1.2143, 1.2664, 1.2040, 1.2440, 1.2481, 1.2325,\n",
            "        1.2503, 1.2553, 1.2091, 1.2488, 1.2253, 1.2592, 1.2225])\n",
            "2 search x tensor([0.4418, 0.1668, 0.3332])\n",
            "2 search loss tensor([1.1735, 1.1920, 1.0620, 1.2091, 1.0450, 1.0504, 1.0823, 1.0625, 1.0420,\n",
            "        1.0786, 1.0578, 1.2250, 1.0250, 1.0580, 1.0577, 1.2225])\n",
            "3 search x tensor([0.5481, 0.0986, 0.4162])\n",
            "3 search loss tensor([1.0457, 1.0573, 1.0491, 1.0719, 1.0438, 1.0437, 1.0764, 1.0634, 1.0432,\n",
            "        1.0598, 1.0575, 1.0640, 1.0261, 1.0582, 1.0582, 1.0504])\n",
            "4 search x tensor([ 0.4693, -0.0328,  0.5439])\n",
            "4 search loss tensor([0.9640, 0.8503, 1.0065, 1.0404, 1.0572, 0.9069, 0.8870, 0.8759, 1.0432,\n",
            "        0.8571, 1.0573, 0.9580, 1.0261, 0.8436, 0.8639, 0.9701])\n",
            "5 search x tensor([ 0.2947, -0.1505,  0.6685])\n",
            "5 search loss tensor([0.7861, 0.8081, 0.8162, 0.8614, 0.8731, 0.8317, 0.8161, 0.8676, 0.8619,\n",
            "        0.8200, 0.8482, 0.7997, 0.8416, 0.8481, 0.8463, 0.8344])\n",
            "6 search x tensor([ 0.2576, -0.2397,  0.7754])\n",
            "6 search loss tensor([0.8555, 0.7167, 0.7629, 0.8414, 0.8761, 0.8578, 0.8390, 0.8524, 0.8358,\n",
            "        0.8099, 0.8490, 0.7677, 0.8413, 0.8691, 0.8660, 0.9028])\n",
            "tensor([ 6,  2, 13,  7, 14,  8])\n",
            "search loss[idx] 0.716686487197876\n",
            "update_h0 loss, lz 0 0.010744379833340645 tensor([[ 0.0644, -0.0009,  0.0556, -0.0806,  0.0075, -0.0788,  0.1068, -0.0602],\n",
            "        [ 0.0599,  0.0045,  0.0346,  0.0299, -0.0484, -0.0334,  0.1619,  0.0840],\n",
            "        [ 0.0998,  0.0968,  0.1354, -0.0808,  0.0606, -0.1834,  0.0520, -0.0237],\n",
            "        [ 0.0767,  0.2438,  0.0174,  0.0153, -0.1062, -0.1705,  0.1467,  0.0008]])\n",
            "0 search x tensor([ 0.5803, -0.4927,  0.2207])\n",
            "0 search loss tensor([1.2602, 1.2579, 1.2285, 1.2476, 1.3159, 1.2204, 1.1686, 1.2865, 1.2350,\n",
            "        1.2597, 1.4153, 1.2230, 1.2416, 1.2321, 1.1786, 1.1304])\n",
            "1 search x tensor([ 0.6797, -0.3922,  0.3205])\n",
            "1 search loss tensor([1.2091, 1.1470, 1.2105, 1.2457, 1.2745, 1.1720, 1.2012, 1.2244, 1.2525,\n",
            "        1.2042, 1.2487, 1.2125, 1.2078, 1.2422, 1.2265, 1.2511])\n",
            "2 search x tensor([ 0.5572, -0.4921,  0.4462])\n",
            "2 search loss tensor([1.1759, 1.0849, 1.1357, 1.0667, 1.2108, 1.0860, 1.0930, 1.2124, 1.1395,\n",
            "        1.2304, 1.2146, 1.1780, 1.1581, 1.2015, 1.1862, 1.1749])\n",
            "3 search x tensor([ 0.4225, -0.5432,  0.5754])\n",
            "3 search loss tensor([1.1754, 1.0105, 0.9058, 0.9419, 1.1313, 1.1469, 1.0435, 1.1214, 1.0375,\n",
            "        1.0413, 1.2149, 1.0734, 0.9924, 1.1421, 1.1778, 1.1480])\n",
            "4 search x tensor([ 0.2777, -0.6689,  0.6895])\n",
            "4 search loss tensor([0.9141, 1.0106, 0.8645, 0.7709, 1.0986, 1.0474, 0.9930, 1.0065, 0.8323,\n",
            "        1.1189, 1.1703, 0.8507, 0.9338, 1.0610, 0.8456, 1.1234])\n",
            "5 search x tensor([ 0.0735, -0.7104,  0.7000])\n",
            "5 search loss tensor([0.8512, 0.8471, 0.8656, 0.8339, 0.9996, 0.8735, 0.7954, 1.0178, 0.8323,\n",
            "        0.8763, 1.1251, 0.7676, 0.6748, 1.0287, 0.7951, 1.0044])\n",
            "6 search x tensor([-0.0715, -0.7392,  0.6696])\n",
            "6 search loss tensor([0.8512, 0.8471, 0.8656, 0.6979, 0.7087, 0.6997, 1.0100, 0.7978, 0.8323,\n",
            "        0.7714, 0.9744, 0.6595, 0.6756, 0.7942, 0.8531, 0.6649])\n",
            "tensor([12,  2,  6,  6,  6,  5])\n",
            "search loss[idx] 0.6594778299331665\n",
            "update_h0 loss, lz 0 0.010007821023464203 tensor([[-0.2099,  0.0976, -0.1575,  0.1273,  0.0558, -0.0594, -0.1204,  0.0906],\n",
            "        [ 0.0860,  0.0007, -0.1085,  0.1061,  0.0881,  0.1094,  0.1534,  0.0933],\n",
            "        [-0.1148,  0.1361, -0.0768,  0.0562,  0.0204, -0.0600, -0.0794, -0.1737],\n",
            "        [-0.1300, -0.0665, -0.0948,  0.0809, -0.0637,  0.1112, -0.0287,  0.0494]])\n",
            "0 search x tensor([-0.3065, -0.4849,  0.3448])\n",
            "0 search loss tensor([1.1489, 0.7544, 0.9060, 1.0144, 0.7146, 0.6782, 0.7683, 0.9073, 0.9296,\n",
            "        0.9736, 0.8957, 0.7109, 0.6887, 0.9012, 0.8912, 1.1666])\n",
            "1 search x tensor([-0.4062, -0.5844,  0.4444])\n",
            "1 search loss tensor([1.1704, 0.9930, 1.1276, 0.8096, 0.6736, 0.7870, 1.1723, 1.0569, 1.1217,\n",
            "        1.1267, 0.8346, 1.1737, 0.6559, 0.9699, 1.1952, 1.1366])\n",
            "2 search x tensor([-0.4976, -0.6650,  0.5364])\n",
            "2 search loss tensor([1.1723, 0.7397, 1.0575, 0.9240, 1.0827, 1.1354, 1.2296, 0.7305, 0.8506,\n",
            "        1.3260, 0.8010, 1.1307, 1.0224, 0.9852, 1.0933, 1.0782])\n",
            "3 search x tensor([-0.5302, -0.6326,  0.5646])\n",
            "3 search loss tensor([1.1099, 0.7420, 0.8795, 1.2233, 1.1300, 0.8593, 1.0562, 1.0893, 0.8521,\n",
            "        1.1206, 0.9675, 1.1663, 1.0512, 1.1351, 0.7691, 0.8765])\n",
            "4 search x tensor([-0.5476, -0.6019,  0.5813])\n",
            "4 search loss tensor([0.9189, 0.7208, 0.8855, 0.9215, 0.7118, 1.1536, 1.0280, 1.0658, 0.8521,\n",
            "        1.0167, 0.8933, 0.9419, 0.7047, 0.9902, 0.8814, 0.7128])\n",
            "5 search x tensor([-0.4653, -0.6518,  0.5989])\n",
            "5 search loss tensor([0.8143, 1.1729, 0.8856, 0.9226, 0.8750, 1.1265, 0.8244, 0.9504, 0.8755,\n",
            "        1.0167, 0.8420, 0.8196, 0.7561, 0.9203, 0.7233, 0.7186])\n",
            "6 search x tensor([-0.3966, -0.6853,  0.6108])\n",
            "6 search loss tensor([0.7972, 1.0967, 0.8856, 0.9226, 1.0565, 1.0914, 0.8698, 0.8787, 0.8013,\n",
            "        0.9397, 0.8259, 0.8196, 0.7621, 0.9211, 0.7140, 0.7368])\n",
            "tensor([7, 5, 0, 6, 6, 1])\n",
            "search loss[idx] 0.7139626741409302\n",
            "update_h0 loss, lz 0 0.0036846892908215523 tensor([[ 0.0083,  0.0554, -0.1464,  0.0081, -0.0850,  0.0292, -0.1139, -0.0831],\n",
            "        [ 0.0433, -0.0681,  0.1366, -0.0576,  0.1018,  0.0571, -0.0420, -0.0730],\n",
            "        [-0.2513,  0.1176, -0.0939,  0.0380, -0.0814,  0.2652, -0.2533,  0.0792],\n",
            "        [-0.1060,  0.1102,  0.0555,  0.0163,  0.2231, -0.0777,  0.2151, -0.0576]])\n",
            "0 search x tensor([ 0.1052, -0.2671,  0.3089])\n",
            "0 search loss tensor([0.8947, 0.8950, 0.8972, 0.9072, 0.8964, 0.8915, 0.8961, 0.8896, 0.8892,\n",
            "        0.8806, 0.9059, 0.9049, 0.8908, 1.2130, 0.8941, 0.9081])\n",
            "1 search x tensor([ 0.0051, -0.1669,  0.2086])\n",
            "1 search loss tensor([1.3049, 0.8262, 1.2787, 0.8743, 1.3147, 0.8637, 1.1721, 0.8567, 1.0762,\n",
            "        0.8307, 0.8569, 0.8411, 0.8983, 0.9246, 1.3215, 0.8751])\n",
            "2 search x tensor([ 0.1331, -0.2924,  0.3321])\n",
            "2 search loss tensor([0.9448, 1.3308, 1.1267, 1.1069, 1.0119, 0.8694, 0.9356, 0.8383, 0.8753,\n",
            "        0.8218, 0.8527, 1.1260, 0.8412, 0.8991, 1.0872, 0.8435])\n",
            "3 search x tensor([ 0.0865, -0.4466,  0.4817])\n",
            "3 search loss tensor([0.9449, 1.0993, 0.9687, 0.9599, 0.9764, 1.3055, 0.8792, 0.8183, 0.8760,\n",
            "        1.3686, 0.8527, 1.0610, 0.8409, 0.8798, 0.9892, 0.8486])\n",
            "4 search x tensor([ 0.0020, -0.5832,  0.6010])\n",
            "4 search loss tensor([0.8680, 0.8378, 0.8670, 0.8892, 0.8666, 1.2478, 0.8570, 1.2752, 0.8767,\n",
            "        1.0769, 0.8965, 0.8623, 0.8409, 0.8814, 0.9127, 1.2680])\n",
            "5 search x tensor([-0.0425, -0.6116,  0.6093])\n",
            "5 search loss tensor([0.8446, 0.8380, 0.8288, 0.8867, 0.8653, 1.0327, 0.8361, 1.2507, 0.8630,\n",
            "        1.0226, 1.3235, 0.8255, 0.8172, 0.8814, 0.9067, 1.1153])\n",
            "6 search x tensor([-0.0637, -0.6206,  0.6068])\n",
            "6 search loss tensor([0.8437, 0.8380, 0.8303, 0.8867, 0.8728, 0.8691, 0.8361, 0.8889, 0.8588,\n",
            "        0.8351, 1.3293, 0.9467, 0.8164, 0.8734, 0.8655, 1.3043])\n",
            "tensor([ 0, 11,  7, 13,  1,  6])\n",
            "search loss[idx] 0.8164214491844177\n",
            "update_h0 loss, lz 0 0.010554594919085503 tensor([[ 0.0276,  0.1365,  0.1021,  0.0713, -0.0913, -0.0089, -0.0259, -0.0930],\n",
            "        [-0.0862,  0.0095, -0.0718, -0.0115,  0.0730,  0.1220, -0.1587, -0.0794],\n",
            "        [ 0.0169,  0.2035, -0.0993,  0.1392, -0.1689, -0.1048, -0.0450, -0.1368],\n",
            "        [-0.1656, -0.0639,  0.1017,  0.1064,  0.2641, -0.1661, -0.1583,  0.0598]])\n",
            "0 search x tensor([-0.0181, -0.1689,  0.3198])\n",
            "0 search loss tensor([0.7895, 0.7690, 0.7555, 0.8670, 0.7672, 0.8164, 0.8044, 0.7786, 0.7797,\n",
            "        0.7792, 0.7839, 0.7884, 0.7797, 0.8020, 0.7605, 0.8236])\n",
            "1 search x tensor([-0.1181, -0.2687,  0.2195])\n",
            "1 search loss tensor([1.3842, 0.7439, 0.7427, 0.7844, 0.6977, 0.7737, 0.7609, 1.3458, 1.4097,\n",
            "        0.7663, 0.7681, 0.7650, 0.7438, 0.7791, 0.7421, 0.7664])\n",
            "2 search x tensor([-1.0386e-05, -2.0237e-01,  3.1985e-01])\n",
            "2 search loss tensor([1.2550, 1.3894, 1.4420, 0.7664, 0.7079, 0.7640, 1.3116, 0.7580, 0.7707,\n",
            "        0.7667, 0.7672, 0.7650, 1.4274, 0.7569, 0.7422, 0.7680])\n",
            "3 search x tensor([-0.1472, -0.3513,  0.4757])\n",
            "3 search loss tensor([1.2022, 1.3225, 1.4444, 1.4307, 1.4201, 0.7640, 1.3098, 0.7601, 0.7687,\n",
            "        0.7553, 0.7611, 0.7650, 1.3374, 0.7569, 1.3886, 0.7633])\n",
            "4 search x tensor([-0.2766, -0.4733,  0.6044])\n",
            "4 search loss tensor([1.1446, 1.1560, 1.3325, 0.7376, 1.3685, 1.2740, 1.0808, 0.7601, 0.7687,\n",
            "        0.7183, 0.7487, 0.7592, 1.3259, 0.7536, 1.3181, 0.7353])\n",
            "5 search x tensor([-0.3485, -0.5588,  0.6958])\n",
            "5 search loss tensor([1.1060, 1.1560, 1.2507, 1.3639, 1.3279, 1.0585, 0.9782, 0.7601, 0.7459,\n",
            "        1.4438, 0.7235, 1.3211, 1.2319, 1.4171, 1.2538, 1.3750])\n",
            "6 search x tensor([-0.3608, -0.5544,  0.7462])\n",
            "6 search loss tensor([1.1060, 1.1560, 1.2740, 1.3578, 1.3096, 1.0387, 0.9154, 0.7601, 1.3100,\n",
            "        1.4026, 1.4050, 0.7268, 1.1864, 1.1436, 1.1840, 0.7857])\n",
            "tensor([ 4,  6,  5, 13,  0,  1])\n",
            "search loss[idx] 0.726804256439209\n",
            "update_h0 loss, lz 0 0.011266626417636871 tensor([[ 0.0306,  0.0653,  0.0827, -0.0432, -0.0333, -0.1379, -0.0470,  0.0767],\n",
            "        [-0.0629, -0.0932,  0.1554, -0.0711, -0.1928, -0.0142, -0.0728, -0.1562],\n",
            "        [-0.1335,  0.1366,  0.0632, -0.0408, -0.0035,  0.0526, -0.0087, -0.0616],\n",
            "        [ 0.0078,  0.1585, -0.1450,  0.0460,  0.0515, -0.0739, -0.0840, -0.0004]])\n",
            "0 search x tensor([ 0.2927, -0.1569, -0.0256])\n",
            "0 search loss tensor([1.3887, 1.4366, 1.3762, 1.2915, 1.4148, 1.4007, 1.4821, 1.4519, 1.3466,\n",
            "        1.3143, 1.4744, 1.3960, 1.4203, 1.3957, 1.3516, 1.4820])\n",
            "1 search x tensor([ 0.3925, -0.2568,  0.0744])\n",
            "1 search loss tensor([1.2542, 1.2895, 1.1920, 1.2970, 1.2396, 1.2400, 1.2704, 1.2622, 1.2431,\n",
            "        1.2301, 1.2828, 1.2326, 1.2292, 1.2432, 1.2292, 1.2984])\n",
            "2 search x tensor([ 0.4994, -0.3495,  0.1636])\n",
            "2 search loss tensor([1.1418, 1.2178, 1.0706, 1.0726, 1.1287, 1.2464, 1.1341, 1.2622, 1.1468,\n",
            "        1.2312, 1.2829, 1.1043, 1.1274, 1.1469, 1.0987, 1.2306])\n",
            "3 search x tensor([ 0.4580, -0.4421,  0.2465])\n",
            "3 search loss tensor([1.1087, 1.1107, 1.0842, 1.0598, 1.1148, 1.2482, 1.0805, 1.0964, 1.1112,\n",
            "        1.0943, 1.1042, 1.1051, 1.1274, 1.1469, 1.0988, 1.0997])\n",
            "4 search x tensor([ 0.5247, -0.5064,  0.3046])\n",
            "4 search loss tensor([1.0935, 1.1030, 1.0478, 1.0338, 1.1118, 1.1363, 1.0926, 1.1011, 0.9146,\n",
            "        1.1106, 0.9437, 1.2018, 1.0909, 0.9190, 1.1038, 0.9052])\n",
            "5 search x tensor([ 0.4621, -0.5706,  0.3629])\n",
            "5 search loss tensor([1.0792, 0.9504, 1.0273, 1.0058, 1.0636, 0.9072, 1.0832, 1.1011, 0.9200,\n",
            "        1.1067, 0.9291, 1.0778, 0.8632, 0.9189, 1.1038, 0.9083])\n",
            "6 search x tensor([ 0.3470, -0.6332,  0.4218])\n",
            "6 search loss tensor([0.8153, 0.6494, 0.8738, 0.9985, 1.0320, 0.9273, 0.9135, 0.9670, 0.8121,\n",
            "        0.9759, 0.9291, 1.1982, 0.9104, 0.8103, 0.9474, 0.9068])\n",
            "tensor([ 6,  2,  0, 12,  1,  6])\n",
            "search loss[idx] 0.6494359970092773\n",
            "update_h0 loss, lz 0 0.013264652341604233 tensor([[ 0.1447,  0.1295, -0.0911,  0.1383,  0.1580,  0.0267,  0.0133, -0.1187],\n",
            "        [ 0.0036,  0.0470, -0.0357,  0.0564, -0.0925,  0.0714, -0.0765,  0.0110],\n",
            "        [ 0.1106, -0.0083, -0.0817,  0.1485, -0.0941,  0.1388,  0.0760, -0.0021],\n",
            "        [ 0.0797, -0.0872, -0.0401, -0.1272,  0.1367,  0.0562, -0.1022, -0.0633]])\n",
            "0 search x tensor([0.3118, 0.2959, 0.0204])\n",
            "0 search loss tensor([1.3713, 1.4087, 1.3831, 1.4175, 1.3836, 1.3407, 1.4143, 1.3408, 1.3400,\n",
            "        1.4014, 1.3308, 1.3762, 1.3832, 1.3832, 1.3444, 1.3341])\n",
            "1 search x tensor([0.4115, 0.3956, 0.1204])\n",
            "1 search loss tensor([1.3348, 1.3563, 1.3467, 1.3606, 1.3838, 1.3380, 1.3728, 1.2840, 1.3467,\n",
            "        1.3296, 1.3208, 1.3321, 1.3280, 1.3838, 1.3454, 1.2933])\n",
            "2 search x tensor([0.4358, 0.4197, 0.2486])\n",
            "2 search loss tensor([1.2742, 1.2990, 1.3053, 1.3208, 1.3068, 1.3349, 1.3263, 1.2342, 1.2898,\n",
            "        1.2411, 1.2349, 1.2959, 1.2013, 1.2686, 1.2835, 1.3433])\n",
            "3 search x tensor([0.3633, 0.3352, 0.3929])\n",
            "3 search loss tensor([1.2553, 1.2361, 1.1859, 1.2698, 1.1731, 1.2570, 1.3241, 1.2836, 1.2700,\n",
            "        1.1729, 1.2350, 1.2569, 1.1500, 1.2195, 1.2228, 1.2182])\n",
            "4 search x tensor([0.5241, 0.5128, 0.2223])\n",
            "4 search loss tensor([1.1888, 1.1465, 1.1766, 1.1504, 1.1152, 1.1781, 1.1968, 1.1680, 1.1000,\n",
            "        1.0998, 1.0259, 1.1606, 1.1515, 1.1598, 1.2076, 1.1704])\n",
            "5 search x tensor([0.4321, 0.4559, 0.3095])\n",
            "5 search loss tensor([1.0896, 0.9167, 1.1075, 0.9803, 1.0712, 1.1060, 1.1734, 1.0416, 1.0185,\n",
            "        1.0846, 1.2029, 1.1071, 1.1382, 1.1215, 1.1808, 1.1445])\n",
            "6 search x tensor([0.3210, 0.3629, 0.4238])\n",
            "6 search loss tensor([1.0878, 1.0005, 1.1519, 1.1970, 1.0101, 1.0210, 1.2445, 1.0125, 1.0374,\n",
            "        1.1014, 1.0016, 1.0266, 1.1469, 1.1058, 1.0442, 1.2041])\n",
            "tensor([ 1,  2,  6, 12,  1, 11])\n",
            "search loss[idx] 1.000532627105713\n",
            "update_h0 loss, lz 0 0.01597869023680687 tensor([[-0.1698, -0.0500, -0.0610,  0.0242,  0.0086,  0.0388, -0.1485, -0.0418],\n",
            "        [-0.1081, -0.1573,  0.0404,  0.0256,  0.1923,  0.0443,  0.0003,  0.0009],\n",
            "        [-0.2716, -0.1035, -0.1472,  0.0237, -0.0012, -0.0590,  0.0109, -0.1184],\n",
            "        [-0.0324,  0.1919, -0.0653,  0.0427, -0.1134, -0.1227, -0.2163, -0.0896]])\n",
            "0 search x tensor([ 0.1798, -0.0030,  0.5479])\n",
            "0 search loss tensor([1.2107, 1.2190, 1.2403, 1.2310, 1.2152, 1.2105, 1.2427, 1.2773, 1.2121,\n",
            "        1.2389, 1.1995, 1.1916, 1.2126, 1.2323, 1.2205, 1.2251])\n",
            "1 search x tensor([ 0.0797, -0.1030,  0.6473])\n",
            "1 search loss tensor([1.0565, 1.0567, 1.0138, 1.0875, 1.0683, 1.0632, 1.0171, 1.1206, 0.9517,\n",
            "        1.1036, 1.0097, 1.0374, 0.9881, 1.0659, 0.9869, 1.0817])\n",
            "2 search x tensor([-0.0340, -0.1428,  0.7473])\n",
            "2 search loss tensor([1.0565, 0.9712, 1.0132, 1.0182, 1.0683, 0.8373, 0.8967, 0.9901, 0.9521,\n",
            "        1.0394, 0.9041, 0.9831, 0.9754, 0.9521, 0.9825, 0.8353])\n",
            "3 search x tensor([-0.1434, -0.1280,  0.8382])\n",
            "3 search loss tensor([0.8650, 0.6364, 0.7419, 0.8616, 0.6927, 0.6983, 0.8902, 0.8644, 0.6309,\n",
            "        0.7767, 0.7282, 0.6852, 0.8260, 0.6308, 0.7952, 0.6869])\n",
            "4 search x tensor([-0.2497, -0.1317,  0.9291])\n",
            "4 search loss tensor([0.7091, 0.6084, 0.8213, 0.8383, 0.6936, 0.6267, 0.6360, 0.7360, 0.6083,\n",
            "        0.6365, 0.6081, 0.6267, 0.7061, 0.6380, 0.6366, 0.6198])\n",
            "5 search x tensor([-0.3156, -0.0719,  0.9462])\n",
            "5 search loss tensor([0.7200, 0.6084, 0.6309, 0.7111, 0.6355, 0.6273, 0.6866, 0.7899, 0.6084,\n",
            "        0.6367, 0.6084, 0.6272, 0.6080, 0.7482, 0.6367, 0.6202])\n",
            "6 search x tensor([-0.3671,  0.0231,  0.9299])\n",
            "6 search loss tensor([0.6606, 0.6084, 0.6310, 0.6339, 0.6271, 0.6273, 0.6440, 0.6430, 0.6084,\n",
            "        0.6084, 0.6084, 0.6273, 0.6708, 0.8428, 0.6367, 0.5990])\n",
            "tensor([7, 5, 3, 7, 6, 2])\n",
            "search loss[idx] 0.5990282893180847\n",
            "update_h0 loss, lz 0 0.018816933035850525 tensor([[ 0.0451,  0.0147, -0.0606,  0.1344, -0.0230, -0.0242, -0.0588, -0.0359],\n",
            "        [-0.0812, -0.2292, -0.0309, -0.0219,  0.1044,  0.0525, -0.0480, -0.0212],\n",
            "        [ 0.1862, -0.1586,  0.0722, -0.0338, -0.1321, -0.0477,  0.2399,  0.0566],\n",
            "        [ 0.1882,  0.0264, -0.1594,  0.1539,  0.0093, -0.0197, -0.0577, -0.0248]])\n",
            "0 search x tensor([-0.3177, -0.6681,  0.6728])\n",
            "0 search loss tensor([0.9326, 0.7644, 0.9927, 0.9931, 1.0154, 0.9927, 1.0138, 0.9927, 0.9257,\n",
            "        0.8157, 0.9195, 1.0079, 0.9760, 1.0236, 0.9866, 0.9962])\n",
            "1 search x tensor([-0.3994, -0.5429,  0.7388])\n",
            "1 search loss tensor([0.9184, 0.9012, 0.9326, 0.9491, 0.9140, 0.9491, 0.9681, 0.9489, 0.9136,\n",
            "        0.9170, 0.8974, 0.8683, 0.9192, 0.9413, 0.9491, 0.9491])\n",
            "2 search x tensor([-0.4220, -0.5605,  0.7126])\n",
            "2 search loss tensor([0.9058, 0.8201, 0.9019, 0.9061, 0.9309, 0.9061, 0.9684, 0.9121, 0.8163,\n",
            "        0.9184, 0.8974, 0.8683, 0.9192, 0.8761, 0.9491, 0.9491])\n",
            "3 search x tensor([-0.4315, -0.5778,  0.6928])\n",
            "3 search loss tensor([0.7071, 0.7711, 0.9019, 0.7902, 0.9204, 0.8316, 0.8844, 0.9122, 0.7808,\n",
            "        0.9184, 0.7773, 0.8683, 0.9049, 0.8122, 0.8227, 0.8944])\n",
            "4 search x tensor([-0.3501, -0.6266,  0.6963])\n",
            "4 search loss tensor([0.7290, 0.7558, 0.8334, 0.6374, 0.9204, 0.6406, 0.6733, 0.9122, 0.7605,\n",
            "        0.7492, 0.6725, 0.8683, 0.8280, 0.7317, 0.6213, 0.8752])\n",
            "5 search x tensor([-0.2448, -0.6718,  0.6992])\n",
            "5 search loss tensor([0.6456, 0.7143, 0.7717, 0.6213, 0.8486, 0.6377, 0.6733, 0.8396, 0.6214,\n",
            "        0.6361, 0.6734, 0.7780, 0.7905, 0.7020, 0.6214, 0.7344])\n",
            "6 search x tensor([-0.1961, -0.6954,  0.6913])\n",
            "6 search loss tensor([0.6482, 0.7254, 0.5248, 0.6214, 0.8223, 0.5238, 0.6733, 0.8036, 0.6214,\n",
            "        0.6213, 0.6734, 0.7780, 0.7905, 0.7247, 0.6214, 0.6806])\n",
            "tensor([6, 5, 6, 6, 6, 5])\n",
            "search loss[idx] 0.5237865447998047\n",
            "update_h0 loss, lz 0 0.020754830911755562 tensor([[-0.0177,  0.0360,  0.0283, -0.0308, -0.0431,  0.1731,  0.0047,  0.0726],\n",
            "        [-0.0201,  0.0318,  0.0266, -0.0095,  0.0664, -0.1745, -0.1487, -0.1389],\n",
            "        [ 0.1118, -0.1651, -0.2053,  0.1321, -0.0375, -0.1383, -0.0784,  0.1287],\n",
            "        [ 0.0221, -0.0175, -0.2578, -0.0362, -0.0170, -0.0174, -0.0836, -0.1462]])\n",
            "0 search x tensor([-0.1527, -0.5842,  0.4448])\n",
            "0 search loss tensor([1.2290, 1.3677, 1.2293, 1.2307, 0.7988, 1.0758, 1.2039, 1.1910, 0.8773,\n",
            "        1.1805, 1.2069, 1.2251, 1.2308, 1.0512, 1.2081, 0.8182])\n",
            "1 search x tensor([-0.2526, -0.6836,  0.5443])\n",
            "1 search loss tensor([1.2397, 1.1984, 1.2145, 1.0908, 0.8213, 1.2147, 1.2296, 1.1894, 0.9925,\n",
            "        1.1959, 1.1682, 1.1647, 1.2338, 1.1707, 1.1367, 0.8175])\n",
            "2 search x tensor([-0.3246, -0.7269,  0.6052])\n",
            "2 search loss tensor([1.0367, 1.1473, 1.2067, 0.9804, 1.1174, 1.1891, 1.1892, 1.1928, 1.1717,\n",
            "        1.1362, 1.1688, 1.1478, 1.1495, 1.1762, 1.1523, 1.2167])\n",
            "3 search x tensor([-0.2651, -0.7293,  0.6308])\n",
            "3 search loss tensor([1.0367, 1.0000, 0.9797, 0.9804, 0.9846, 0.9975, 1.1744, 1.1091, 1.1292,\n",
            "        1.0722, 1.1443, 1.1098, 1.0757, 1.1706, 0.9526, 1.1686])\n",
            "4 search x tensor([-0.1983, -0.7346,  0.6489])\n",
            "4 search loss tensor([0.9735, 0.9605, 0.9523, 0.9804, 0.9773, 0.9976, 0.8840, 1.0928, 1.1328,\n",
            "        1.0040, 1.1991, 1.0729, 0.8727, 1.1671, 0.8753, 1.1785])\n",
            "5 search x tensor([-0.1888, -0.7274,  0.6598])\n",
            "5 search loss tensor([0.9521, 0.9228, 0.9523, 0.8702, 1.0500, 0.8702, 0.8495, 0.8914, 0.9534,\n",
            "        0.8913, 1.0314, 1.0730, 0.8727, 0.9902, 0.8761, 1.1785])\n",
            "6 search x tensor([-0.1223, -0.7397,  0.6617])\n",
            "6 search loss tensor([0.9523, 0.9358, 0.8754, 0.8462, 0.9364, 0.8702, 0.8495, 0.8914, 0.9012,\n",
            "        0.8949, 0.9109, 1.0730, 0.8463, 0.9903, 0.8773, 1.1489])\n",
            "tensor([6, 5, 3, 7, 6, 5])\n",
            "search loss[idx] 0.8462409973144531\n",
            "update_h0 loss, lz 0 0.016117636114358902 tensor([[-0.2251,  0.2262, -0.1555,  0.1939, -0.1247,  0.0256, -0.2025, -0.0203],\n",
            "        [ 0.0441, -0.1665,  0.0279,  0.0393, -0.1182,  0.1172, -0.0848,  0.0299],\n",
            "        [ 0.1059,  0.0521, -0.0921, -0.1487,  0.0995, -0.0240, -0.2085, -0.0043],\n",
            "        [-0.2075, -0.0026, -0.0580,  0.0760, -0.1238, -0.0916,  0.1074,  0.1892]])\n",
            "0 search x tensor([-0.1530, -0.7702,  0.6192])\n",
            "0 search loss tensor([1.0385, 1.0467, 1.0357, 1.0250, 1.0491, 1.0308, 1.0490, 1.0578, 1.0378,\n",
            "        1.0473, 1.0455, 1.0005, 1.0384, 1.0165, 1.0491, 1.0308])\n",
            "1 search x tensor([-0.2188, -0.7522,  0.6216])\n",
            "1 search loss tensor([1.0126, 1.0294, 1.0293, 1.0291, 1.0450, 1.0130, 1.0290, 1.0326, 1.0296,\n",
            "        1.0088, 1.0363, 1.0006, 1.0573, 1.0180, 1.0326, 1.0387])\n",
            "2 search x tensor([-0.2757, -0.7318,  0.6233])\n",
            "2 search loss tensor([1.0127, 1.0230, 0.9868, 1.0294, 1.0433, 0.9687, 0.9323, 1.0154, 1.0306,\n",
            "        0.7849, 1.0148, 0.9608, 1.0580, 1.0181, 0.9827, 1.0388])\n",
            "3 search x tensor([-0.3229, -0.7111,  0.6246])\n",
            "3 search loss tensor([0.9975, 0.9839, 0.9403, 1.0081, 0.9872, 0.9533, 0.7847, 0.9799, 0.9687,\n",
            "        0.9800, 0.9930, 0.9023, 1.0006, 1.0090, 0.9503, 1.0388])\n",
            "4 search x tensor([-0.3458, -0.6965,  0.6288])\n",
            "4 search loss tensor([0.9975, 0.9611, 0.7748, 0.9279, 0.9294, 0.9533, 0.7847, 0.9807, 0.9726,\n",
            "        0.8683, 1.0397, 0.8694, 0.9434, 0.9805, 0.9403, 1.0219])\n",
            "5 search x tensor([-0.3686, -0.6825,  0.6311])\n",
            "5 search loss tensor([0.9569, 0.9612, 0.9622, 0.9289, 0.9332, 0.9533, 0.7200, 0.9487, 0.9562,\n",
            "        0.8684, 0.9699, 0.8076, 0.9435, 0.9228, 0.9093, 0.9947])\n",
            "6 search x tensor([-0.3803, -0.6701,  0.6375])\n",
            "6 search loss tensor([0.9151, 0.8969, 0.7987, 0.9291, 0.9374, 0.9533, 0.7868, 0.9487, 0.9247,\n",
            "        0.8462, 0.8356, 0.8962, 0.9236, 0.9274, 0.8683, 0.9699])\n",
            "tensor([6, 5, 6, 7, 6, 5])\n",
            "search loss[idx] 0.7867599725723267\n",
            "update_h0 loss, lz 0 0.019169790670275688 tensor([[-0.1108, -0.0167,  0.0131,  0.2204,  0.1055,  0.0715, -0.0474,  0.0923],\n",
            "        [-0.0206, -0.1556,  0.0374,  0.1018, -0.2817,  0.1296,  0.1325,  0.1332],\n",
            "        [-0.0279, -0.0845,  0.1101, -0.0357, -0.1226, -0.1427,  0.0067, -0.0051],\n",
            "        [ 0.0061,  0.0049,  0.0313,  0.0109,  0.1714, -0.1791,  0.0053,  0.0576]])\n",
            "0 search x tensor([-0.1390, -0.6399,  0.6430])\n",
            "0 search loss tensor([1.1421, 1.1264, 1.1401, 1.1232, 1.1302, 1.1441, 1.1430, 1.1211, 1.1424,\n",
            "        1.1427, 1.1357, 1.0729, 1.1543, 1.1428, 1.1537, 1.1371])\n",
            "1 search x tensor([-0.2223, -0.6879,  0.6909])\n",
            "1 search loss tensor([1.1429, 1.0806, 1.1255, 1.1276, 1.1303, 1.1453, 1.1433, 1.1212, 1.1433,\n",
            "        1.0565, 1.1358, 1.0396, 1.1028, 1.1433, 1.1478, 1.1228])\n",
            "2 search x tensor([-0.2700, -0.6734,  0.6882])\n",
            "2 search loss tensor([1.1239, 1.0806, 1.0598, 1.1276, 1.1200, 1.0950, 1.1224, 0.9931, 1.1275,\n",
            "        1.0565, 1.1224, 0.9946, 1.0934, 1.1033, 1.0355, 1.1240])\n",
            "3 search x tensor([-0.3121, -0.6557,  0.6875])\n",
            "3 search loss tensor([1.0522, 0.9852, 0.8810, 1.0859, 1.0809, 1.0950, 1.1224, 0.9134, 1.0635,\n",
            "        1.0565, 0.9914, 0.9949, 0.9339, 1.0827, 1.0355, 1.0462])\n",
            "4 search x tensor([-0.3276, -0.6428,  0.6925])\n",
            "4 search loss tensor([0.9674, 0.8417, 0.8210, 1.0490, 0.9095, 1.0258, 1.0725, 0.8778, 1.0635,\n",
            "        0.8416, 0.9939, 0.9949, 0.9348, 0.8913, 0.9667, 0.9444])\n",
            "5 search x tensor([-0.1481, -0.6955,  0.7031])\n",
            "5 search loss tensor([0.9899, 0.8417, 0.8210, 1.0491, 0.9157, 0.8167, 1.0387, 0.8779, 1.0382,\n",
            "        0.8416, 0.8673, 0.8666, 0.8500, 0.8205, 0.8497, 0.8207])\n",
            "6 search x tensor([-0.1132, -0.7104,  0.6946])\n",
            "6 search loss tensor([0.8538, 0.8417, 0.8210, 1.0491, 0.8585, 0.8175, 1.0323, 0.8537, 1.0382,\n",
            "        0.8207, 0.9153, 0.8686, 0.8210, 0.8210, 0.8501, 0.8210])\n",
            "tensor([ 6,  5,  6,  7,  7, 11])\n",
            "search loss[idx] 0.8175035119056702\n",
            "update_h0 loss, lz 0 0.018117520958185196 tensor([[ 0.0327, -0.0684, -0.0326, -0.0474,  0.0184, -0.0058, -0.0065,  0.0729],\n",
            "        [-0.1230,  0.0753, -0.0013, -0.0088, -0.1017,  0.0930, -0.0910, -0.0398],\n",
            "        [ 0.0267, -0.1142, -0.0028,  0.1018,  0.1386,  0.1550, -0.0892,  0.0692],\n",
            "        [-0.0128,  0.1633,  0.1401, -0.0253, -0.0629, -0.0683,  0.0694, -0.1107]])\n",
            "0 search x tensor([-0.6285, -0.2811,  0.7252])\n",
            "0 search loss tensor([1.0485, 1.0482, 1.0140, 1.0792, 1.0876, 1.0358, 1.0550, 1.0605, 1.0435,\n",
            "        0.9997, 1.0686, 1.0787, 1.0750, 1.0688, 1.0724, 1.0717])\n",
            "1 search x tensor([-0.6254, -0.3272,  0.7084])\n",
            "1 search loss tensor([1.0313, 0.9987, 1.0087, 1.0549, 1.0545, 1.0459, 1.0444, 1.0086, 1.0037,\n",
            "        1.0015, 1.0689, 1.0791, 1.0580, 1.0688, 1.0726, 1.0217])\n",
            "2 search x tensor([-0.6238, -0.3624,  0.6925])\n",
            "2 search loss tensor([0.9467, 0.9875, 1.0088, 1.0168, 1.0545, 0.9587, 0.9371, 1.0088, 0.9769,\n",
            "        0.9728, 1.0245, 1.0534, 1.0580, 1.0329, 1.0458, 1.0221])\n",
            "3 search x tensor([-0.5999, -0.4122,  0.6857])\n",
            "3 search loss tensor([0.9861, 0.9671, 0.9501, 0.8288, 0.9950, 0.9588, 0.9372, 1.0088, 0.9977,\n",
            "        0.9427, 1.0078, 1.0534, 1.0580, 1.0262, 0.9761, 1.0049])\n",
            "4 search x tensor([-0.4055, -0.5415,  0.7365])\n",
            "4 search loss tensor([0.9262, 0.9851, 0.9501, 0.7373, 0.8641, 0.8121, 0.8152, 0.9157, 0.8716,\n",
            "        0.9566, 0.9830, 1.0378, 0.9867, 0.9927, 0.8936, 0.9501])\n",
            "5 search x tensor([-0.3877, -0.5697,  0.7247])\n",
            "5 search loss tensor([0.7809, 0.7601, 0.9321, 0.7387, 0.7830, 0.7991, 0.7875, 0.9321, 0.8387,\n",
            "        0.9321, 0.7386, 0.9278, 0.7653, 0.9735, 0.8415, 0.9750])\n",
            "6 search x tensor([-0.3968, -0.5886,  0.7044])\n",
            "6 search loss tensor([0.7810, 0.7601, 0.9251, 0.7387, 0.7830, 0.7570, 0.7876, 0.8799, 0.8387,\n",
            "        0.9251, 0.7387, 0.7844, 0.7698, 0.9355, 0.7714, 1.0317])\n",
            "tensor([6, 5, 6, 7, 6, 5])\n",
            "search loss[idx] 0.7386689782142639\n",
            "update_h0 loss, lz 0 0.007934288121759892 tensor([[ 8.9442e-02, -1.5630e-01,  2.4859e-01, -8.9192e-02,  7.6622e-02,\n",
            "         -1.6039e-03, -1.1660e-02,  1.2655e-01],\n",
            "        [ 5.8981e-03, -8.3284e-02,  1.4003e-01,  3.8943e-02,  2.6907e-05,\n",
            "         -2.8312e-01, -7.3020e-02, -1.6511e-01],\n",
            "        [-4.9920e-02, -5.1936e-02,  9.2740e-02, -5.1914e-02,  3.9587e-02,\n",
            "         -1.1779e-01,  1.6462e-01,  3.5346e-02],\n",
            "        [-5.5164e-02,  9.1318e-02, -3.4168e-02,  9.3142e-02, -3.4096e-02,\n",
            "          6.2833e-02,  2.0542e-02, -7.1247e-02]])\n",
            "0 search x tensor([-0.3640, -0.4065,  0.5038])\n",
            "0 search loss tensor([1.0853, 1.0411, 1.0504, 1.0677, 1.0787, 1.1086, 1.0752, 1.0631, 1.0834,\n",
            "        1.0713, 1.0911, 1.0961, 1.0889, 1.2279, 1.0655, 1.0877])\n",
            "1 search x tensor([-0.4636, -0.5061,  0.6033])\n",
            "1 search loss tensor([1.0857, 1.0415, 1.0514, 1.0680, 1.0788, 1.1022, 1.0595, 1.0326, 1.0888,\n",
            "        1.0494, 1.0912, 1.0971, 1.0679, 1.0469, 1.0493, 1.0620])\n",
            "2 search x tensor([-0.5174, -0.5531,  0.6530])\n",
            "2 search loss tensor([0.9815, 1.0494, 1.0303, 1.0493, 1.0577, 1.0186, 1.0242, 1.0326, 1.0221,\n",
            "        1.0304, 1.0667, 1.0198, 1.0388, 1.0469, 0.9815, 1.0197])\n",
            "3 search x tensor([-0.4956, -0.5706,  0.6548])\n",
            "3 search loss tensor([0.9638, 0.9815, 0.9971, 1.0337, 0.9287, 0.8838, 0.9967, 0.8960, 1.0221,\n",
            "        1.0067, 1.0342, 0.8181, 1.0455, 1.0302, 0.8636, 0.9724])\n",
            "4 search x tensor([-0.4734, -0.5876,  0.6562])\n",
            "4 search loss tensor([0.9146, 0.9638, 0.9385, 0.8636, 0.7636, 0.8274, 0.7373, 0.8700, 0.9710,\n",
            "        1.0067, 1.0342, 0.7901, 0.9867, 1.0126, 0.8636, 0.9724])\n",
            "5 search x tensor([-0.4450, -0.6031,  0.6620])\n",
            "5 search loss tensor([0.8182, 0.8636, 0.9385, 0.8636, 0.7636, 0.7952, 0.7387, 0.8895, 0.9341,\n",
            "        0.9675, 0.9790, 0.7662, 0.9867, 1.0126, 0.7871, 0.7654])\n",
            "6 search x tensor([-0.4007, -0.6226,  0.6721])\n",
            "6 search loss tensor([0.7662, 0.7930, 0.9385, 0.7636, 0.7636, 0.7662, 0.7658, 0.8072, 0.9341,\n",
            "        0.9339, 0.7944, 0.7662, 0.9867, 0.9754, 0.7607, 0.7662])\n",
            "tensor([6, 5, 6, 7, 6, 2])\n",
            "search loss[idx] 0.7607349753379822\n",
            "update_h0 loss, lz 0 0.01249910518527031 tensor([[ 0.0344, -0.0014, -0.0662,  0.0270, -0.1417, -0.1390,  0.1533, -0.0320],\n",
            "        [-0.0692,  0.1358, -0.3083,  0.1318,  0.0110, -0.0945, -0.0490,  0.0645],\n",
            "        [-0.1468,  0.0747,  0.0199,  0.1135, -0.0744,  0.1972, -0.0181,  0.0717],\n",
            "        [-0.0123, -0.1578,  0.0908,  0.0603, -0.0106,  0.2081,  0.1698, -0.1097]])\n",
            "0 search x tensor([ 0.2292, -0.3864,  0.5461])\n",
            "0 search loss tensor([1.0598, 1.1058, 1.0443, 1.0442, 1.0348, 1.0087, 0.9821, 1.0105, 1.0669,\n",
            "        1.1591, 1.0637, 1.0659, 1.0502, 1.0782, 1.0876, 1.0438])\n",
            "1 search x tensor([ 0.1290, -0.4860,  0.6456])\n",
            "1 search loss tensor([1.0613, 1.0046, 1.0345, 1.0255, 0.9635, 0.9969, 1.0121, 1.0220, 1.0539,\n",
            "        1.0599, 1.0325, 1.0525, 1.0252, 1.0214, 1.0525, 1.0003])\n",
            "2 search x tensor([ 0.0297, -0.5867,  0.7344])\n",
            "2 search loss tensor([1.0507, 0.9707, 1.0403, 1.0176, 0.9750, 1.0053, 0.9431, 1.0290, 1.0161,\n",
            "        1.0440, 0.9769, 1.0290, 1.0065, 1.0189, 1.0078, 0.9575])\n",
            "3 search x tensor([-0.0721, -0.6683,  0.7404])\n",
            "3 search loss tensor([1.0167, 0.9707, 1.0403, 1.0176, 0.9750, 0.9963, 0.9432, 1.0139, 0.9857,\n",
            "        0.9850, 0.9249, 1.0110, 0.9764, 0.9965, 0.9881, 0.8550])\n",
            "4 search x tensor([-0.1385, -0.6981,  0.7025])\n",
            "4 search loss tensor([0.9611, 0.9707, 1.0226, 0.9814, 0.9232, 0.9613, 0.9432, 0.9761, 0.9857,\n",
            "        0.8680, 0.9285, 0.8762, 0.9765, 0.9517, 0.9881, 0.9217])\n",
            "5 search x tensor([-0.1617, -0.7218,  0.6730])\n",
            "5 search loss tensor([0.8925, 0.9707, 1.0227, 0.9537, 0.9225, 0.7573, 0.9432, 0.9231, 0.9451,\n",
            "        0.8073, 0.8961, 0.9115, 0.8959, 0.8546, 0.9174, 0.8963])\n",
            "6 search x tensor([-0.1598, -0.7330,  0.6612])\n",
            "6 search loss tensor([0.8925, 0.9154, 0.9853, 0.7837, 0.8053, 0.7573, 0.8400, 0.8557, 0.8659,\n",
            "        0.9127, 0.7943, 0.7878, 0.7838, 0.7864, 0.7758, 0.8248])\n",
            "tensor([6, 5, 6, 7, 6, 5])\n",
            "search loss[idx] 0.7573496103286743\n",
            "update_h0 loss, lz 0 0.007595202419906855 tensor([[-1.1772e-04, -6.5595e-02,  4.1740e-02,  1.7643e-01, -1.1374e-01,\n",
            "         -4.9200e-03,  8.0131e-03,  2.1021e-01],\n",
            "        [-9.0501e-02,  1.0809e-01, -4.6308e-02, -1.6241e-01, -2.7399e-02,\n",
            "         -6.2013e-02,  7.0914e-02, -6.6162e-02],\n",
            "        [ 3.8589e-03, -1.6622e-01,  1.2475e-01,  1.0125e-01,  2.1031e-02,\n",
            "          3.3715e-03, -1.0920e-01, -1.2527e-01],\n",
            "        [ 1.8325e-01, -1.2837e-01, -8.6299e-02, -8.1982e-02,  8.6418e-02,\n",
            "          1.4601e-01,  1.0420e-01,  3.2880e-02]])\n",
            "0 search x tensor([-0.2002, -0.4389,  0.7363])\n",
            "0 search loss tensor([1.0722, 1.0799, 1.0222, 1.0688, 1.0049, 1.0468, 1.0544, 1.0563, 1.0503,\n",
            "        1.0274, 1.0864, 1.0764, 1.0800, 1.0576, 1.0069, 1.0552])\n",
            "1 search x tensor([-0.2889, -0.5186,  0.8047])\n",
            "1 search loss tensor([1.0513, 1.0721, 0.9882, 1.0710, 0.9986, 1.0476, 1.0721, 1.0318, 0.9777,\n",
            "        1.0335, 1.0866, 1.0765, 1.0831, 1.0043, 1.0070, 1.0341])\n",
            "2 search x tensor([-0.3291, -0.5271,  0.7835])\n",
            "2 search loss tensor([0.9500, 1.0721, 0.9259, 1.0156, 0.9859, 1.0240, 0.8826, 0.9859, 0.9140,\n",
            "        0.9372, 1.0122, 1.0596, 1.0677, 1.0050, 0.9570, 0.9761])\n",
            "3 search x tensor([-0.3257, -0.5501,  0.7690])\n",
            "3 search loss tensor([0.9723, 1.0721, 0.7708, 0.8795, 0.9437, 0.9508, 0.8544, 0.8401, 0.9140,\n",
            "        0.9124, 0.7571, 0.9820, 1.0371, 0.9493, 0.8511, 0.8555])\n",
            "4 search x tensor([-0.3198, -0.5718,  0.7555])\n",
            "4 search loss tensor([0.9763, 0.8317, 0.7708, 0.7572, 0.9350, 0.7970, 0.8150, 0.8672, 0.8937,\n",
            "        0.9127, 0.7572, 0.8377, 0.9972, 0.8402, 0.7585, 0.7350])\n",
            "5 search x tensor([-0.2749, -0.6134,  0.7404])\n",
            "5 search loss tensor([0.9073, 0.8128, 0.7708, 0.7351, 0.7333, 0.7622, 0.7815, 0.8241, 0.7687,\n",
            "        0.7622, 0.7572, 0.8106, 0.9217, 0.8130, 0.7356, 0.7351])\n",
            "6 search x tensor([-0.2110, -0.6505,  0.7296])\n",
            "6 search loss tensor([0.7561, 0.7816, 0.7708, 0.7351, 0.7351, 0.7624, 0.7816, 0.8283, 0.7687,\n",
            "        0.7338, 0.7572, 0.7816, 0.7642, 0.6739, 0.7399, 0.7351])\n",
            "tensor([6, 5, 4, 6, 6, 5])\n",
            "search loss[idx] 0.6739199161529541\n",
            "update_h0 loss, lz 0 0.007979616522789001 tensor([[-0.0335, -0.1075,  0.1218,  0.1616,  0.1141, -0.0509, -0.0389, -0.0635],\n",
            "        [ 0.0535,  0.0787, -0.0351, -0.0944,  0.0906, -0.0385, -0.0918,  0.0069],\n",
            "        [ 0.0938,  0.0467,  0.1182, -0.1100, -0.0958, -0.0470,  0.0854, -0.0725],\n",
            "        [-0.0679,  0.2276,  0.0453,  0.0272, -0.0147, -0.0348,  0.2238,  0.0547]])\n",
            "0 search x tensor([-0.0183, -0.3126,  0.5736])\n",
            "0 search loss tensor([0.7757, 0.7981, 0.8069, 0.8116, 0.8018, 0.8013, 0.8014, 0.8251, 0.8015,\n",
            "        0.7777, 0.8250, 0.8024, 0.7471, 0.7753, 0.8012, 0.7785])\n",
            "1 search x tensor([ 0.0817, -0.2123,  0.4731])\n",
            "1 search loss tensor([0.7544, 0.7648, 0.7622, 0.7543, 0.7552, 0.7695, 0.7698, 0.7688, 0.7688,\n",
            "        0.7544, 0.7680, 0.7690, 0.7697, 0.7544, 0.7686, 0.7554])\n",
            "2 search x tensor([ 0.1896, -0.0969,  0.3639])\n",
            "2 search loss tensor([0.7513, 0.7626, 0.7486, 0.7544, 0.7466, 0.7692, 0.7552, 0.7696, 0.7688,\n",
            "        0.7537, 0.7813, 0.7714, 0.7720, 0.7483, 0.7538, 0.7365])\n",
            "3 search x tensor([ 0.2827, -0.0194,  0.2508])\n",
            "3 search loss tensor([0.7405, 0.7616, 0.7486, 0.7537, 0.7303, 0.7419, 0.7379, 0.7680, 0.7680,\n",
            "        0.7447, 0.7662, 0.7682, 0.7492, 0.7475, 0.7438, 0.7365])\n",
            "4 search x tensor([0.3686, 0.0597, 0.1386])\n",
            "4 search loss tensor([0.7405, 0.7354, 0.7435, 0.7537, 0.7311, 0.7401, 0.7343, 0.7400, 0.7266,\n",
            "        0.7113, 0.7697, 0.7680, 0.7492, 0.7343, 0.7364, 0.7354])\n",
            "5 search x tensor([0.4502, 0.1470, 0.0274])\n",
            "5 search loss tensor([0.7405, 0.7449, 0.7265, 0.7264, 0.7212, 0.7401, 0.7234, 0.7349, 0.7331,\n",
            "        0.7063, 0.7531, 0.7270, 0.7418, 0.7331, 0.7315, 0.7259])\n",
            "6 search x tensor([ 0.5257,  0.2472, -0.0823])\n",
            "6 search loss tensor([0.7264, 0.7322, 0.7265, 0.7113, 1.2110, 0.7210, 0.7114, 0.7379, 0.7264,\n",
            "        0.7591, 0.7305, 0.7403, 0.7404, 0.7631, 0.7155, 0.7322])\n",
            "tensor([ 1,  5, 12,  8,  6,  0])\n",
            "search loss[idx] 0.7112520933151245\n",
            "update_h0 loss, lz 0 0.007378004491329193 tensor([[ 0.0947, -0.0924,  0.0096,  0.1295, -0.0851, -0.1311,  0.0419, -0.0392],\n",
            "        [-0.1132,  0.0028,  0.0014,  0.0340, -0.0428, -0.0021, -0.1506, -0.0542],\n",
            "        [ 0.0319,  0.0623, -0.2050, -0.0588,  0.1137, -0.0738, -0.0725, -0.1800],\n",
            "        [ 0.1056, -0.0377, -0.1089, -0.0744,  0.0402,  0.1548, -0.0537, -0.0520]])\n",
            "0 search x tensor([ 0.1462, -0.7704,  0.6205])\n",
            "0 search loss tensor([1.2710, 1.3089, 1.1904, 1.3035, 1.2616, 1.2157, 1.2693, 1.2591, 1.2732,\n",
            "        1.2147, 1.2836, 1.2689, 1.2139, 1.2709, 1.2806, 1.2225])\n",
            "1 search x tensor([ 0.0408, -0.7697,  0.6371])\n",
            "1 search loss tensor([1.2749, 1.2559, 1.2848, 1.2359, 1.2729, 1.2294, 1.2773, 1.2855, 1.2773,\n",
            "        1.2238, 1.2479, 1.2749, 1.2240, 1.2773, 1.2401, 1.2019])\n",
            "2 search x tensor([-0.0450, -0.7715,  0.6346])\n",
            "2 search loss tensor([1.0373, 0.9444, 1.0562, 1.0426, 0.9790, 1.0423, 0.9894, 1.1008, 1.0843,\n",
            "        0.9742, 1.0568, 1.0840, 1.0811, 1.0565, 1.0576, 0.8848])\n",
            "3 search x tensor([-0.0928, -0.7747,  0.6255])\n",
            "3 search loss tensor([0.9124, 0.7841, 1.0574, 1.0438, 1.0752, 1.0197, 1.0577, 1.0441, 0.9445,\n",
            "        1.0154, 1.0436, 1.0818, 1.0094, 1.0582, 1.0582, 0.8118])\n",
            "4 search x tensor([-0.1101, -0.7622,  0.6379])\n",
            "4 search loss tensor([0.8833, 0.9125, 1.0020, 0.9982, 1.0763, 0.9761, 1.0225, 0.9989, 0.9446,\n",
            "        0.9115, 0.9280, 0.9985, 0.8671, 1.0036, 1.0020, 0.7700])\n",
            "5 search x tensor([-0.1137, -0.7597,  0.6403])\n",
            "5 search loss tensor([0.8833, 0.8548, 0.9971, 0.9672, 0.9995, 0.9483, 1.0227, 0.9604, 0.9773,\n",
            "        0.8071, 0.8316, 0.8318, 0.7981, 0.8876, 0.9971, 0.7350])\n",
            "6 search x tensor([-0.1169, -0.7579,  0.6418])\n",
            "6 search loss tensor([0.8248, 0.7668, 0.9496, 0.9146, 0.9844, 0.8961, 1.0226, 0.9311, 0.9496,\n",
            "        0.8011, 0.8321, 0.8321, 0.8157, 0.8886, 0.9525, 0.7351])\n",
            "tensor([6, 2, 7, 0, 9, 0])\n",
            "search loss[idx] 0.7350539565086365\n",
            "update_h0 loss, lz 0 0.015031062066555023 tensor([[-0.1188, -0.1031,  0.1491, -0.2101, -0.0828, -0.0429, -0.0865,  0.0381],\n",
            "        [ 0.1702,  0.0014, -0.0542,  0.1567,  0.0240, -0.2168, -0.0290, -0.0670],\n",
            "        [-0.1377,  0.0673,  0.1749,  0.0005,  0.0111,  0.0207, -0.1839, -0.0396],\n",
            "        [-0.1453, -0.0202,  0.0003,  0.1106, -0.0300, -0.1352,  0.0846,  0.2090]])\n",
            "0 search x tensor([ 0.7047, -0.0239, -0.1175])\n",
            "0 search loss tensor([1.3849, 1.3510, 1.3570, 1.1760, 1.3744, 1.3838, 1.0958, 1.2200, 1.3898,\n",
            "        1.0600, 1.3667, 1.0905, 1.0892, 1.0804, 1.1157, 1.3503])\n",
            "1 search x tensor([ 0.6040, -0.1239, -0.0174])\n",
            "1 search loss tensor([1.3829, 1.3630, 1.3676, 1.3749, 1.3695, 1.3672, 1.0735, 1.1975, 1.3638,\n",
            "        1.3122, 1.3710, 1.0479, 1.1115, 1.3909, 1.0773, 1.3679])\n",
            "2 search x tensor([ 0.5098, -0.1586,  0.0699])\n",
            "2 search loss tensor([1.3443, 1.3630, 1.3674, 1.3872, 1.3065, 1.2731, 1.3438, 1.3607, 1.3393,\n",
            "        1.3673, 1.2531, 1.3549, 1.3513, 1.3571, 1.3575, 1.3680])\n",
            "3 search x tensor([ 0.3763, -0.2844,  0.1924])\n",
            "3 search loss tensor([1.2659, 1.3116, 1.3488, 1.3812, 1.2854, 1.2424, 1.3670, 1.3440, 1.2505,\n",
            "        1.3676, 1.3460, 1.3672, 1.0449, 1.2800, 1.3727, 1.3666])\n",
            "4 search x tensor([ 0.4675, -0.3938,  0.3508])\n",
            "4 search loss tensor([1.0381, 1.3577, 1.3127, 1.3810, 1.2344, 1.0128, 1.3668, 1.3463, 1.1488,\n",
            "        1.3676, 0.9142, 1.3672, 1.1392, 1.1171, 1.3723, 1.2908])\n",
            "5 search x tensor([ 0.6631, -0.2137,  0.3714])\n",
            "5 search loss tensor([1.0570, 1.1351, 1.2136, 1.3111, 1.1297, 1.0128, 1.3087, 1.2636, 1.0057,\n",
            "        1.3102, 0.9139, 1.3186, 1.1604, 1.1038, 1.3726, 1.1462])\n",
            "6 search x tensor([ 0.7496, -0.3862,  0.5375])\n",
            "6 search loss tensor([0.8570, 0.8202, 1.3541, 1.2153, 1.2272, 1.1153, 1.2400, 1.1989, 1.0073,\n",
            "        1.3124, 1.1886, 1.2477, 1.2777, 1.0357, 1.3713, 1.2948])\n",
            "tensor([1, 2, 6, 7, 1, 5])\n",
            "search loss[idx] 0.820210337638855\n",
            "update_h0 loss, lz 0 0.005495177116245031 tensor([[-0.0464,  0.2263, -0.1678, -0.0166, -0.1177,  0.2237, -0.1029, -0.0975],\n",
            "        [ 0.0934, -0.0526,  0.1722, -0.0994,  0.0800,  0.1325, -0.0211, -0.1624],\n",
            "        [-0.0343,  0.0788, -0.0401, -0.0632,  0.0236, -0.1232,  0.0748, -0.0952],\n",
            "        [-0.0678, -0.0975,  0.0414,  0.0780, -0.0607,  0.0503, -0.3105, -0.0559]])\n",
            "0 search x tensor([0.4791, 0.0050, 0.3108])\n",
            "0 search loss tensor([0.7404, 0.7401, 0.7377, 0.7235, 0.7231, 1.2710, 0.7136, 0.7490, 0.7388,\n",
            "        0.7626, 1.2326, 0.7470, 0.7413, 0.7388, 0.7450, 0.7401])\n",
            "1 search x tensor([0.5786, 0.1050, 0.2105])\n",
            "1 search loss tensor([0.7282, 0.7439, 0.7277, 0.7280, 0.7296, 1.1877, 0.7188, 0.7451, 0.7424,\n",
            "        0.7278, 1.2101, 0.7279, 0.7190, 0.7429, 0.7285, 0.7367])\n",
            "2 search x tensor([0.6756, 0.0470, 0.1450])\n",
            "2 search loss tensor([0.7282, 0.7439, 0.7278, 0.7216, 0.7015, 1.1361, 0.7206, 0.7441, 0.7274,\n",
            "        0.7278, 1.1011, 0.7162, 0.7182, 0.7429, 0.7285, 0.7278])\n",
            "3 search x tensor([ 0.7710, -0.0455,  0.0778])\n",
            "3 search loss tensor([0.7015, 0.7439, 1.1037, 0.7117, 0.6938, 0.8834, 0.7024, 0.7183, 0.7229,\n",
            "        0.7270, 1.0956, 0.7161, 0.7116, 0.7273, 0.7122, 0.7194])\n",
            "4 search x tensor([ 0.6992, -0.2109,  0.0838])\n",
            "4 search loss tensor([1.0928, 0.7142, 1.2815, 1.0445, 0.6938, 0.7763, 1.1024, 0.7102, 0.7209,\n",
            "        0.6822, 0.9854, 0.6775, 0.6938, 0.7034, 0.7109, 0.7005])\n",
            "5 search x tensor([ 0.5187, -0.0576, -0.0360])\n",
            "5 search loss tensor([0.8242, 0.7233, 1.2225, 0.8789, 0.6447, 0.7849, 0.7216, 0.6979, 0.7209,\n",
            "        0.6822, 0.8317, 0.7963, 0.6706, 0.6813, 0.7109, 0.7002])\n",
            "6 search x tensor([ 0.3121, -0.2409,  0.1738])\n",
            "6 search loss tensor([1.2172, 0.7202, 1.0242, 1.1502, 0.6775, 0.7850, 1.0152, 1.1530, 0.7109,\n",
            "        0.7027, 0.8317, 1.2075, 0.6706, 0.7082, 0.6822, 0.6889])\n",
            "tensor([14, 11, 10,  8,  6,  9])\n",
            "search loss[idx] 0.6705817580223083\n",
            "update_h0 loss, lz 0 0.0073328400030732155 tensor([[-0.0260,  0.0296,  0.0922,  0.0125,  0.0605, -0.2066, -0.1353, -0.2268],\n",
            "        [ 0.0900, -0.0637,  0.0051, -0.2571,  0.0637,  0.0766, -0.0154,  0.2373],\n",
            "        [ 0.0718,  0.0681, -0.0148,  0.3230, -0.0662, -0.0310,  0.0907,  0.1001],\n",
            "        [-0.0301, -0.0730, -0.0338,  0.0892, -0.0664,  0.1058, -0.1764,  0.2295]])\n",
            "0 search x tensor([-0.0176, -0.8429,  0.5287])\n",
            "0 search loss tensor([1.2625, 1.2804, 1.2678, 1.2536, 1.2698, 1.2723, 1.2574, 1.2822, 1.2321,\n",
            "        1.2893, 1.2695, 1.2851, 1.2450, 1.2697, 1.2703, 1.2594])\n",
            "1 search x tensor([-0.1176, -0.7420,  0.6281])\n",
            "1 search loss tensor([1.0692, 1.0803, 1.0600, 1.0638, 1.0830, 1.0831, 1.1099, 1.0691, 1.0835,\n",
            "        1.0830, 1.0830, 1.0790, 1.0534, 1.0515, 1.0636, 1.0815])\n",
            "2 search x tensor([-0.0363, -0.7756,  0.6302])\n",
            "2 search loss tensor([1.0530, 1.0656, 1.0600, 1.0387, 1.0636, 1.0581, 1.0339, 1.0273, 1.0558,\n",
            "        1.0636, 1.0571, 1.0127, 1.0580, 1.0084, 1.0355, 1.1494])\n",
            "3 search x tensor([-0.1053, -0.7732,  0.6254])\n",
            "3 search loss tensor([1.0580, 1.0656, 0.9838, 1.0596, 1.0636, 1.0272, 1.0339, 1.0273, 0.9893,\n",
            "        1.1140, 1.0107, 1.0128, 1.0387, 0.9770, 1.0355, 0.9373])\n",
            "4 search x tensor([-0.1241, -0.7608,  0.6371])\n",
            "4 search loss tensor([1.0387, 0.9830, 0.7745, 1.0075, 1.0553, 0.9969, 1.0339, 1.0220, 0.9837,\n",
            "        1.0326, 1.0024, 0.9517, 0.9838, 0.9772, 0.9753, 1.0218])\n",
            "5 search x tensor([-0.1341, -0.7494,  0.6484])\n",
            "5 search loss tensor([0.9836, 0.9831, 0.8754, 0.9770, 0.9522, 0.9290, 1.0546, 1.0993, 1.0080,\n",
            "        0.9748, 0.9388, 0.9374, 0.9838, 0.9772, 0.9274, 1.0232])\n",
            "6 search x tensor([-0.1331, -0.7457,  0.6529])\n",
            "6 search loss tensor([0.9837, 1.0097, 0.9662, 0.9485, 0.9831, 0.9969, 1.0062, 1.0017, 0.9128,\n",
            "        0.9748, 0.9703, 0.9505, 1.0044, 0.9810, 0.9692, 1.0036])\n",
            "tensor([6, 5, 6, 7, 1, 2])\n",
            "search loss[idx] 0.9127877354621887\n",
            "update_h0 loss, lz 0 0.01539065781980753 tensor([[ 0.1069, -0.2201,  0.0618,  0.0424, -0.0044, -0.0288, -0.1071,  0.0145],\n",
            "        [-0.1883,  0.0758,  0.0331,  0.1091,  0.0221,  0.1450,  0.1129,  0.0053],\n",
            "        [-0.0019,  0.0044, -0.0234, -0.0343,  0.0350,  0.1045, -0.0451,  0.1435],\n",
            "        [-0.0389, -0.0222, -0.0357, -0.1291,  0.0143,  0.0084,  0.3245,  0.1583]])\n",
            "0 search x tensor([ 0.5738, -0.0093,  0.3938])\n",
            "0 search loss tensor([1.1420, 1.1879, 1.1900, 1.1977, 1.1896, 1.1875, 1.1831, 1.1898, 1.1878,\n",
            "        1.2023, 1.1823, 1.2009, 1.1915, 1.1819, 1.1997, 1.1864])\n",
            "1 search x tensor([ 0.4732, -0.1093,  0.4935])\n",
            "1 search loss tensor([1.0913, 1.1404, 1.1159, 1.1483, 1.1348, 1.1258, 1.1299, 1.1071, 1.1253,\n",
            "        1.1485, 1.1263, 0.9108, 1.1298, 1.1103, 1.1036, 1.1405])\n",
            "2 search x tensor([ 0.3588, -0.2087,  0.5954])\n",
            "2 search loss tensor([1.0827, 1.1404, 1.0820, 1.1362, 1.0784, 1.1264, 1.0606, 1.1168, 1.1109,\n",
            "        1.0447, 1.1151, 0.7596, 1.0844, 1.0002, 1.0687, 1.0554])\n",
            "3 search x tensor([ 0.2513, -0.2956,  0.6890])\n",
            "3 search loss tensor([0.9272, 0.8898, 0.9572, 0.9360, 0.9716, 0.8243, 0.9445, 0.9720, 1.0181,\n",
            "        0.7317, 1.0342, 0.8922, 0.9522, 0.8852, 0.8716, 0.7392])\n",
            "4 search x tensor([ 0.1362, -0.3760,  0.7794])\n",
            "4 search loss tensor([0.7768, 0.8395, 0.8714, 0.6782, 0.7825, 0.8348, 0.9391, 0.7932, 0.9811,\n",
            "        0.6783, 1.0021, 0.8265, 0.6756, 0.7021, 0.7685, 0.6991])\n",
            "5 search x tensor([-0.0048, -0.4910,  0.8689])\n",
            "5 search loss tensor([0.7254, 0.7848, 0.7153, 0.6783, 0.7098, 0.7081, 0.7107, 0.7153, 0.8337,\n",
            "        0.6783, 0.8465, 0.7682, 0.6783, 0.7025, 0.7090, 0.6486])\n",
            "6 search x tensor([-0.0963, -0.5338,  0.8401])\n",
            "6 search loss tensor([0.7255, 0.6781, 0.6759, 0.6783, 0.7102, 0.7086, 0.7109, 0.6783, 0.6739,\n",
            "        0.6783, 0.8465, 0.7694, 0.6783, 0.7025, 0.7094, 0.6487])\n",
            "tensor([6, 5, 6, 7, 7, 5])\n",
            "search loss[idx] 0.6486615538597107\n",
            "update_h0 loss, lz 0 0.022393371909856796 tensor([[ 0.0191, -0.1120,  0.0476,  0.0225,  0.0355,  0.1796, -0.1346, -0.1790],\n",
            "        [ 0.0131, -0.0011, -0.1304,  0.0316,  0.1226,  0.0571, -0.0753,  0.0590],\n",
            "        [ 0.1272, -0.0179, -0.2291, -0.1915,  0.0114,  0.0187, -0.0400, -0.1861],\n",
            "        [ 0.1801, -0.1012,  0.0614, -0.0258, -0.0638,  0.0069,  0.1732,  0.0128]])\n",
            "0 search x tensor([-0.3921, -0.1674,  0.7153])\n",
            "0 search loss tensor([1.1058, 1.1071, 1.1953, 1.1273, 1.1282, 1.1192, 1.1119, 1.1131, 1.1159,\n",
            "        1.0455, 1.1856, 1.1231, 1.1145, 1.1257, 1.0872, 1.2075])\n",
            "1 search x tensor([-0.4918, -0.2672,  0.8146])\n",
            "1 search loss tensor([1.0855, 1.0709, 1.0850, 1.1122, 1.1131, 1.0786, 1.0638, 1.1131, 1.0735,\n",
            "        1.0293, 1.1033, 1.1232, 1.0947, 1.1147, 1.0802, 1.1128])\n",
            "2 search x tensor([-0.4931, -0.3037,  0.8153])\n",
            "2 search loss tensor([1.0825, 1.0466, 1.0458, 0.9572, 1.0955, 1.0786, 1.0638, 1.0664, 1.0041,\n",
            "        1.0295, 1.1020, 1.1054, 1.0587, 1.0735, 1.0466, 1.0860])\n",
            "3 search x tensor([-0.4850, -0.3415,  0.8051])\n",
            "3 search loss tensor([1.0746, 1.0471, 0.9930, 0.8465, 1.0528, 1.0511, 1.0416, 1.0562, 0.9579,\n",
            "        1.0208, 1.0926, 1.0634, 1.0723, 0.9270, 0.9270, 1.0394])\n",
            "4 search x tensor([-0.4693, -0.3913,  0.7916])\n",
            "4 search loss tensor([0.9920, 1.0249, 0.9830, 0.8465, 1.0077, 0.7999, 0.8464, 1.0029, 0.9262,\n",
            "        0.9977, 1.0503, 1.0042, 0.9450, 0.9125, 0.9387, 1.1358])\n",
            "5 search x tensor([-0.4476, -0.4516,  0.7718])\n",
            "5 search loss tensor([0.9685, 0.9070, 0.9193, 0.8406, 1.0079, 0.9577, 0.8406, 0.9592, 0.7695,\n",
            "        0.8993, 1.0527, 1.0090, 0.8406, 0.7939, 0.8993, 1.1045])\n",
            "6 search x tensor([-0.4292, -0.5225,  0.7367])\n",
            "6 search loss tensor([0.7939, 0.8396, 0.9193, 0.8406, 1.0234, 0.8150, 0.7918, 0.9593, 0.8900,\n",
            "        0.7918, 1.0529, 1.0092, 0.8406, 0.7918, 0.8105, 1.1045])\n",
            "tensor([6, 5, 6, 7, 6, 5])\n",
            "search loss[idx] 0.7918232679367065\n",
            "update_h0 loss, lz 0 0.008350636810064316 tensor([[ 0.0470, -0.0238, -0.0632, -0.0971, -0.1302, -0.1820, -0.0739, -0.1324],\n",
            "        [ 0.1083,  0.1096, -0.0598, -0.0803,  0.1141,  0.0391,  0.0433,  0.0828],\n",
            "        [-0.0370, -0.2578, -0.1586,  0.1071, -0.0126, -0.0939,  0.1356,  0.0541],\n",
            "        [ 0.1044,  0.1511,  0.1043, -0.1824,  0.1086,  0.1066,  0.1754,  0.0237]])\n",
            "0 search x tensor([-0.1325, -0.5437,  0.5399])\n",
            "0 search loss tensor([1.1513, 1.1866, 1.1191, 1.1626, 1.1601, 1.1373, 1.1659, 1.1604, 1.1744,\n",
            "        1.1657, 1.1609, 1.1758, 1.1515, 1.1916, 1.1319, 1.1459])\n",
            "1 search x tensor([-0.2324, -0.6432,  0.6393])\n",
            "1 search loss tensor([1.1620, 1.1252, 1.1290, 1.1403, 1.0963, 1.1442, 1.1505, 1.1627, 1.1746,\n",
            "        1.1662, 1.1380, 1.1435, 1.1512, 1.0773, 1.1380, 1.1319])\n",
            "2 search x tensor([-0.2972, -0.6755,  0.6749])\n",
            "2 search loss tensor([1.1380, 1.0779, 1.1290, 1.0348, 1.0965, 1.1442, 1.0826, 1.1505, 1.1193,\n",
            "        1.1198, 1.1380, 1.1435, 1.1318, 1.0026, 1.1380, 1.1028])\n",
            "3 search x tensor([-0.3252, -0.6626,  0.6747])\n",
            "3 search loss tensor([1.0829, 0.9137, 1.0924, 0.9656, 1.0965, 1.1291, 1.0826, 1.0174, 0.8886,\n",
            "        0.9974, 1.0458, 1.0163, 1.1319, 0.9653, 0.9770, 1.1028])\n",
            "4 search x tensor([-0.3108, -0.6603,  0.6837])\n",
            "4 search loss tensor([0.9339, 0.9146, 1.0558, 0.9342, 1.0220, 1.0566, 1.0189, 0.8576, 0.8887,\n",
            "        0.8907, 0.8820, 0.8997, 1.0049, 0.9653, 0.9471, 1.0658])\n",
            "5 search x tensor([-0.1655, -0.6993,  0.6954])\n",
            "5 search loss tensor([0.8578, 0.8855, 1.0182, 0.8738, 0.9628, 1.0568, 0.8592, 0.8330, 0.8681,\n",
            "        0.8908, 0.8820, 0.9142, 0.9760, 0.9653, 0.8391, 1.0323])\n",
            "6 search x tensor([-0.1391, -0.7171,  0.6829])\n",
            "6 search loss tensor([0.8603, 0.8391, 1.0182, 0.8742, 0.9051, 1.0568, 0.8592, 0.8330, 0.8682,\n",
            "        0.8908, 0.8390, 0.9143, 0.8616, 0.9052, 0.8391, 1.0323])\n",
            "tensor([6, 5, 3, 7, 6, 2])\n",
            "search loss[idx] 0.8329985737800598\n",
            "update_h0 loss, lz 0 0.005502602551132441 tensor([[ 0.1782, -0.0916, -0.1066,  0.0010, -0.0833, -0.0800, -0.0427, -0.1506],\n",
            "        [ 0.0004, -0.1836, -0.0381,  0.0095, -0.0850, -0.0162, -0.1268,  0.0439],\n",
            "        [ 0.0779, -0.1194,  0.0418, -0.0473,  0.2532,  0.0518,  0.2178, -0.0445],\n",
            "        [ 0.2449,  0.1708, -0.0570,  0.0585,  0.1223, -0.0191,  0.0416, -0.2064]])\n",
            "0 search x tensor([-0.1994, -0.8107,  0.5505])\n",
            "0 search loss tensor([0.9466, 0.9147, 0.9710, 1.0245, 0.9503, 0.9322, 0.8976, 0.9501, 0.9460,\n",
            "        0.9422, 0.9720, 0.9480, 0.9447, 0.9431, 0.9457, 0.9562])\n",
            "1 search x tensor([-0.2585, -0.7861,  0.5615])\n",
            "1 search loss tensor([0.8876, 0.8853, 0.8807, 0.8723, 0.8819, 0.8528, 0.8642, 0.9034, 0.9050,\n",
            "        0.8861, 0.9064, 0.9032, 0.8879, 0.8605, 0.8684, 0.7825])\n",
            "2 search x tensor([-0.2935, -0.7738,  0.5613])\n",
            "2 search loss tensor([0.8877, 0.8560, 0.8809, 0.8615, 0.8228, 0.8159, 0.8479, 0.8704, 0.8272,\n",
            "        0.8914, 0.8529, 0.8679, 0.8879, 0.8615, 0.8332, 0.7242])\n",
            "3 search x tensor([-0.3258, -0.7597,  0.5627])\n",
            "3 search loss tensor([0.8696, 0.8373, 0.8468, 0.8615, 0.8238, 0.6539, 0.8480, 0.8705, 0.7103,\n",
            "        0.8488, 0.8396, 0.8685, 0.8573, 0.8445, 0.8078, 0.6523])\n",
            "4 search x tensor([-0.3507, -0.7453,  0.5671])\n",
            "4 search loss tensor([0.8266, 0.8373, 0.8157, 0.8615, 0.7571, 0.6539, 0.8480, 0.8705, 0.7517,\n",
            "        0.8489, 0.7047, 0.8440, 0.8573, 0.8445, 0.7032, 0.7135])\n",
            "5 search x tensor([-0.3601, -0.7342,  0.5756])\n",
            "5 search loss tensor([0.7634, 0.8016, 0.8157, 0.7517, 0.7571, 0.7138, 0.7769, 0.8074, 0.6557,\n",
            "        0.8229, 0.7053, 0.7867, 0.6256, 0.7866, 0.7244, 0.5918])\n",
            "6 search x tensor([-0.3269, -0.7392,  0.5888])\n",
            "6 search loss tensor([0.7634, 0.8016, 0.7860, 0.7517, 0.6227, 0.6653, 0.6756, 0.7720, 0.7856,\n",
            "        0.7810, 0.7053, 0.6252, 0.7815, 0.7635, 0.6307, 0.5988])\n",
            "tensor([6, 5, 6, 7, 6, 5])\n",
            "search loss[idx] 0.5988309979438782\n",
            "update_h0 loss, lz 0 0.01428193785250187 tensor([[-0.0532,  0.1434,  0.0083,  0.0819, -0.2073,  0.0653,  0.0484, -0.0565],\n",
            "        [-0.1614, -0.1239, -0.0827,  0.2150,  0.0507,  0.1785,  0.0407,  0.0641],\n",
            "        [ 0.0897, -0.0375, -0.0051, -0.0536, -0.0859,  0.0128,  0.0218, -0.0647],\n",
            "        [-0.0696, -0.0780, -0.0151, -0.2130, -0.0738,  0.1762,  0.0311,  0.0166]])\n",
            "0 search x tensor([-0.2407, -0.6093,  0.6057])\n",
            "0 search loss tensor([0.7307, 0.7456, 1.0423, 0.7452, 0.7412, 0.7424, 1.0075, 0.9982, 1.0563,\n",
            "        0.7413, 1.2012, 0.7303, 1.0462, 0.7412, 0.9378, 1.1615])\n",
            "1 search x tensor([-0.3224, -0.6711,  0.6676])\n",
            "1 search loss tensor([0.7330, 0.7415, 1.0278, 0.7466, 0.7434, 0.7434, 1.0297, 1.0328, 1.0653,\n",
            "        0.7428, 1.0032, 0.7330, 1.0557, 1.2056, 0.7414, 0.9995])\n",
            "2 search x tensor([-0.3570, -0.6957,  0.6233])\n",
            "2 search loss tensor([1.0688, 0.7415, 1.0123, 0.7420, 1.1778, 0.7428, 0.9369, 0.9983, 0.9816,\n",
            "        0.7331, 1.1036, 0.7330, 1.0374, 1.1593, 0.7421, 0.9404])\n",
            "3 search x tensor([-0.5126, -0.5557,  0.4671])\n",
            "3 search loss tensor([0.7325, 0.7100, 0.9065, 0.7084, 1.0028, 0.7423, 0.7388, 0.9191, 0.8882,\n",
            "        0.7089, 0.9955, 0.7318, 1.0047, 0.8761, 0.7421, 0.9404])\n",
            "4 search x tensor([-0.5507, -0.5850,  0.4673])\n",
            "4 search loss tensor([0.7347, 0.7058, 0.8573, 0.7058, 0.9360, 0.7417, 0.7389, 0.7486, 0.9087,\n",
            "        0.9798, 0.9449, 0.7089, 0.9300, 0.8802, 0.7421, 0.7640])\n",
            "5 search x tensor([-0.5694, -0.6312,  0.4877])\n",
            "5 search loss tensor([0.7347, 0.7058, 0.7755, 0.7019, 0.7965, 0.7320, 0.7386, 0.7376, 0.7625,\n",
            "        0.8541, 0.8997, 0.7073, 0.9300, 0.8771, 1.2293, 0.7386])\n",
            "6 search x tensor([-0.5673, -0.6600,  0.4926])\n",
            "6 search loss tensor([1.0476, 0.7058, 0.7755, 0.7058, 0.7377, 0.7061, 0.7386, 0.7160, 0.7666,\n",
            "        0.7418, 0.9056, 0.9695, 0.9238, 0.8271, 1.1200, 0.7299])\n",
            "tensor([6, 5, 6, 8, 6, 9])\n",
            "search loss[idx] 0.7058168649673462\n",
            "update_h0 loss, lz 0 0.009720677509903908 tensor([[-0.1261, -0.0433, -0.0034,  0.1557,  0.0641,  0.0368, -0.0737, -0.1910],\n",
            "        [ 0.0392,  0.1210, -0.0889, -0.0464, -0.1030,  0.0507,  0.0136,  0.0705],\n",
            "        [-0.0283,  0.0607,  0.0543, -0.0696, -0.0492,  0.0550,  0.1158,  0.0859],\n",
            "        [-0.0439, -0.0207,  0.0381,  0.0352, -0.0860, -0.0974, -0.0152,  0.0045]])\n",
            "0 search x tensor([-0.0517, -0.5044,  0.4628])\n",
            "0 search loss tensor([0.7638, 0.7657, 0.7684, 0.7668, 1.2610, 0.7644, 0.7511, 0.7651, 0.7645,\n",
            "        1.2757, 0.7627, 1.2475, 0.7664, 1.2883, 0.7701, 0.7700])\n",
            "1 search x tensor([-0.1516, -0.6039,  0.5623])\n",
            "1 search loss tensor([0.7684, 0.7697, 0.7680, 0.7609, 1.2664, 0.7668, 1.2339, 0.7688, 0.7684,\n",
            "        1.1986, 0.7659, 1.1969, 0.7988, 1.1946, 0.7742, 1.2143])\n",
            "2 search x tensor([-0.2173, -0.6952,  0.5571])\n",
            "2 search loss tensor([0.7685, 0.7606, 0.7598, 0.7607, 1.2416, 0.7668, 1.2255, 0.7607, 0.7556,\n",
            "        1.1341, 0.7561, 1.1026, 0.7680, 1.1029, 1.2045, 1.2206])\n",
            "3 search x tensor([-0.2678, -0.7778,  0.4818])\n",
            "3 search loss tensor([0.7387, 0.7458, 0.7272, 0.7212, 0.7610, 0.7198, 0.9746, 0.7458, 0.7380,\n",
            "        1.1125, 0.7396, 0.7691, 1.2976, 1.0815, 0.9337, 0.9461])\n",
            "4 search x tensor([-0.2849, -0.7944,  0.5364])\n",
            "4 search loss tensor([0.7212, 0.7369, 1.4096, 0.7145, 0.7577, 0.7443, 0.9159, 0.7212, 1.2912,\n",
            "        0.7641, 0.7331, 0.7694, 1.0431, 0.8737, 0.9336, 0.7968])\n",
            "5 search x tensor([-0.3463, -0.8451,  0.4074])\n",
            "5 search loss tensor([0.7146, 0.7191, 1.0797, 1.1461, 0.7577, 0.7340, 0.7362, 0.7145, 0.8779,\n",
            "        0.7675, 0.7156, 0.7694, 0.9819, 0.8205, 0.7469, 0.7490])\n",
            "6 search x tensor([-0.4422, -0.8728,  0.2067])\n",
            "6 search loss tensor([1.0262, 0.7212, 1.0205, 1.0432, 0.7577, 0.7175, 0.8720, 0.7085, 0.7762,\n",
            "        0.7498, 0.7156, 0.7694, 0.9819, 0.8206, 0.7467, 0.8432])\n",
            "tensor([ 3,  5, 12,  8,  6,  0])\n",
            "search loss[idx] 0.7085084319114685\n",
            "update_h0 loss, lz 0 0.00789507757872343 tensor([[ 0.0203,  0.0005, -0.0098, -0.0768,  0.0743,  0.1180,  0.0019,  0.2008],\n",
            "        [ 0.1360,  0.1001,  0.2430, -0.1087,  0.0354, -0.0305, -0.1290,  0.0700],\n",
            "        [ 0.0434, -0.0438, -0.0558, -0.1739, -0.2682, -0.0830, -0.0720,  0.0573],\n",
            "        [-0.1767, -0.0530, -0.0186, -0.0670, -0.0336,  0.1375,  0.0009, -0.1047]])\n",
            "0 search x tensor([-0.0510, -0.2895,  0.5178])\n",
            "0 search loss tensor([1.3512, 1.3570, 1.3504, 1.3880, 1.3866, 1.3485, 1.3102, 1.3482, 1.3863,\n",
            "        1.3490, 1.3860, 1.3496, 1.3481, 1.4292, 1.3115, 1.3882])\n",
            "1 search x tensor([-0.1510, -0.3892,  0.6173])\n",
            "1 search loss tensor([1.3534, 1.3510, 1.3531, 1.3578, 1.3562, 1.3460, 1.2856, 1.3562, 1.3908,\n",
            "        1.3585, 1.3295, 1.3176, 1.3409, 1.3824, 1.3181, 1.3908])\n",
            "2 search x tensor([-0.2400, -0.4798,  0.7070])\n",
            "2 search loss tensor([1.3531, 1.3231, 1.3045, 1.3279, 1.3459, 1.3120, 1.2912, 1.3203, 1.3713,\n",
            "        1.3585, 1.3610, 1.3185, 1.3409, 1.3768, 1.3181, 1.3215])\n",
            "3 search x tensor([-0.3012, -0.5495,  0.7793])\n",
            "3 search loss tensor([1.3204, 1.2749, 1.1792, 1.3333, 1.3119, 1.3185, 1.2727, 1.2781, 1.0160,\n",
            "        1.1658, 1.3203, 1.2860, 1.2906, 1.1094, 1.3057, 1.3803])\n",
            "4 search x tensor([-0.2775, -0.5181,  0.8090])\n",
            "4 search loss tensor([1.0697, 1.1141, 1.0447, 1.1416, 1.1231, 1.1522, 1.0393, 1.0426, 1.2010,\n",
            "        1.0701, 1.0680, 1.2862, 1.0806, 0.9997, 1.0595, 1.1483])\n",
            "5 search x tensor([-0.3183, -0.5135,  0.7969])\n",
            "5 search loss tensor([1.0710, 1.0607, 1.0461, 0.8996, 0.8961, 1.1175, 1.0410, 0.9996, 1.0997,\n",
            "        1.0395, 0.9807, 0.9853, 1.0039, 1.0466, 1.0719, 1.1620])\n",
            "6 search x tensor([-0.3517, -0.5194,  0.7788])\n",
            "6 search loss tensor([1.0710, 1.0529, 1.0157, 0.9039, 1.0515, 1.0469, 0.9719, 1.0439, 1.1072,\n",
            "        1.0398, 0.9830, 1.0655, 0.8564, 0.9866, 1.0441, 0.9244])\n",
            "tensor([6, 2, 6, 7, 1, 8])\n",
            "search loss[idx] 0.8563959002494812\n",
            "update_h0 loss, lz 0 0.0034841131418943405 tensor([[-0.1888, -0.1764,  0.0600,  0.0179,  0.0624, -0.0729, -0.0600, -0.0441],\n",
            "        [ 0.0527,  0.1277, -0.0658,  0.0099, -0.1683,  0.1146,  0.1153,  0.0330],\n",
            "        [ 0.0098, -0.0758, -0.0136, -0.0597,  0.0394,  0.2524, -0.0046, -0.0433],\n",
            "        [ 0.1741, -0.0046, -0.0127, -0.1436,  0.0565,  0.1145, -0.0326, -0.0123]])\n",
            "0 search x tensor([ 0.4295, -0.0997,  0.3158])\n",
            "0 search loss tensor([0.7925, 0.7949, 0.8007, 0.7808, 0.7969, 0.7816, 0.7667, 0.7612, 0.7664,\n",
            "        0.7905, 0.7928, 0.7957, 0.7851, 0.7610, 0.7923, 0.7666])\n",
            "1 search x tensor([5.2906e-01, 3.8594e-04, 2.1544e-01])\n",
            "1 search loss tensor([0.7503, 0.7666, 0.7666, 0.7669, 0.7850, 0.7673, 0.7503, 0.7472, 0.7511,\n",
            "        0.7521, 0.7151, 0.7789, 0.7508, 0.7264, 0.7503, 0.7503])\n",
            "2 search x tensor([0.5866, 0.0258, 0.1177])\n",
            "2 search loss tensor([0.7254, 0.7492, 0.7666, 0.7670, 0.7753, 0.7674, 0.7406, 0.7582, 0.7512,\n",
            "        0.7172, 0.7507, 0.7960, 0.7504, 0.9481, 0.7504, 0.7504])\n",
            "3 search x tensor([ 0.5978, -0.0534,  0.0322])\n",
            "3 search loss tensor([1.0902, 0.7231, 0.7659, 0.7787, 0.7572, 0.7625, 1.0740, 1.0278, 0.7341,\n",
            "        0.7167, 0.7191, 0.7648, 0.7446, 0.9688, 1.2459, 0.7280])\n",
            "4 search x tensor([ 0.6212, -0.2173,  0.0604])\n",
            "4 search loss tensor([1.3003, 0.7502, 0.6646, 0.7268, 0.7502, 0.7282, 0.9543, 1.2090, 0.7273,\n",
            "        0.6891, 0.7002, 0.7364, 0.7603, 1.1503, 1.0062, 0.7320])\n",
            "5 search x tensor([ 0.7011, -0.2783,  0.1392])\n",
            "5 search loss tensor([1.1573, 0.6909, 1.1361, 0.7278, 0.7387, 0.7226, 1.1120, 0.9440, 0.7159,\n",
            "        0.6807, 0.7016, 0.6952, 0.7276, 0.9085, 1.0599, 0.7262])\n",
            "6 search x tensor([ 0.5860, -0.3815,  0.3210])\n",
            "6 search loss tensor([1.1028, 0.6975, 0.7948, 0.6911, 0.7101, 0.7034, 0.8057, 0.9369, 0.7160,\n",
            "        0.6519, 0.6960, 1.2747, 0.6843, 0.7941, 0.9630, 0.7159])\n",
            "tensor([ 9, 13, 12,  2,  6,  5])\n",
            "search loss[idx] 0.6519069671630859\n",
            "update_h0 loss, lz 0 0.003948950208723545 tensor([[ 0.1980, -0.0607, -0.0678,  0.0675,  0.0915,  0.0860,  0.0410,  0.0412],\n",
            "        [ 0.0316, -0.0658,  0.0358, -0.1599,  0.0642,  0.0219,  0.2233,  0.0958],\n",
            "        [-0.0927, -0.0178, -0.0940, -0.1168,  0.0854, -0.0028, -0.0969, -0.0579],\n",
            "        [-0.0573,  0.0005, -0.0599,  0.0528,  0.0085,  0.0700,  0.0308,  0.1202]])\n",
            "0 search x tensor([-0.0027, -0.6226,  0.3766])\n",
            "0 search loss tensor([1.0216, 1.0877, 1.1019, 1.0407, 1.0689, 1.0873, 1.0658, 1.0732, 1.0627,\n",
            "        1.1023, 1.0878, 1.0586, 1.0696, 1.0651, 1.1023, 1.0696])\n",
            "1 search x tensor([-0.1027, -0.7220,  0.4762])\n",
            "1 search loss tensor([1.0218, 1.0633, 1.1019, 1.0419, 1.0690, 1.0350, 1.0739, 1.0238, 1.0631,\n",
            "        1.0902, 1.0879, 1.0588, 1.0698, 1.0677, 1.1007, 1.0419])\n",
            "2 search x tensor([-0.1576, -0.8079,  0.5679])\n",
            "2 search loss tensor([1.0133, 1.0448, 1.0818, 1.0419, 1.0406, 0.9139, 1.0742, 0.9866, 1.0631,\n",
            "        1.0540, 1.0690, 1.0398, 1.0331, 1.0677, 1.0945, 1.0055])\n",
            "3 search x tensor([-0.1733, -0.7885,  0.5900])\n",
            "3 search loss tensor([1.0434, 1.0180, 1.0611, 1.0411, 0.9739, 0.9413, 1.0034, 0.9396, 1.0518,\n",
            "        1.0000, 1.0300, 0.9532, 1.0137, 1.0677, 1.0486, 1.0416])\n",
            "4 search x tensor([-0.0820, -0.7964,  0.5992])\n",
            "4 search loss tensor([0.9723, 0.9118, 0.9804, 1.0234, 0.9248, 0.8352, 0.8507, 0.9580, 1.0082,\n",
            "        1.0447, 1.0229, 0.9532, 0.9978, 1.0611, 0.9626, 0.9785])\n",
            "5 search x tensor([-0.0774, -0.7869,  0.6123])\n",
            "5 search loss tensor([1.0120, 0.8517, 0.9804, 0.8809, 0.9532, 0.8911, 0.9430, 0.8560, 0.9964,\n",
            "        0.9795, 0.9616, 0.9488, 0.9255, 1.0362, 0.8268, 0.9208])\n",
            "6 search x tensor([-0.0272, -0.7922,  0.6096])\n",
            "6 search loss tensor([0.8437, 0.8770, 0.9804, 0.8811, 0.9450, 0.8325, 0.9467, 0.9145, 0.9966,\n",
            "        0.8376, 1.0156, 0.8198, 0.9730, 0.9982, 0.8391, 0.9208])\n",
            "tensor([6, 5, 6, 7, 6, 5])\n",
            "search loss[idx] 0.8197938799858093\n",
            "update_h0 loss, lz 0 0.01448905561119318 tensor([[-0.0556, -0.1593,  0.0332,  0.0321, -0.0847, -0.1137, -0.1337,  0.1060],\n",
            "        [-0.2059,  0.0977, -0.1803,  0.1264,  0.0039, -0.0176, -0.0472,  0.0532],\n",
            "        [-0.0878, -0.0280,  0.0229, -0.0156, -0.1164,  0.0848,  0.0128,  0.0594],\n",
            "        [-0.0789, -0.0555, -0.0118,  0.1554,  0.1249, -0.0571,  0.0587, -0.0755]])\n",
            "0 search x tensor([ 0.2555, -0.4115,  0.6453])\n",
            "0 search loss tensor([0.7786, 0.7694, 0.7386, 0.7752, 0.9397, 0.7474, 0.9967, 0.7709, 0.7582,\n",
            "        0.7641, 0.7657, 1.1637, 0.7658, 1.1156, 0.7784, 0.7645])\n",
            "1 search x tensor([ 0.3552, -0.3111,  0.5446])\n",
            "1 search loss tensor([0.7660, 1.1503, 0.7691, 0.7582, 0.9496, 1.1750, 1.0029, 0.7567, 0.7605,\n",
            "        0.7665, 0.7576, 1.1563, 0.7599, 0.9729, 0.7576, 0.7560])\n",
            "2 search x tensor([ 0.4625, -0.2077,  0.4420])\n",
            "2 search loss tensor([0.7588, 1.1233, 0.9662, 0.7565, 0.9625, 0.8064, 0.9791, 0.7567, 0.7528,\n",
            "        0.7585, 0.7576, 0.9816, 1.2885, 1.0083, 0.7567, 0.7578])\n",
            "3 search x tensor([ 0.5571, -0.1301,  0.3486])\n",
            "3 search loss tensor([0.7477, 1.0387, 1.1138, 0.7472, 0.9031, 0.7705, 0.9294, 0.7567, 0.7528,\n",
            "        0.7382, 0.7454, 0.9197, 0.9692, 1.0137, 0.7567, 0.7511])\n",
            "4 search x tensor([ 0.6238, -0.1399,  0.2876])\n",
            "4 search loss tensor([0.7411, 1.0019, 0.8343, 0.7369, 0.9258, 0.7724, 0.9050, 0.7450, 0.7528,\n",
            "        0.7349, 0.7257, 0.8790, 0.8997, 0.9640, 0.7391, 0.7319])\n",
            "5 search x tensor([ 0.6750, -0.2330,  0.2426])\n",
            "5 search loss tensor([0.7401, 0.7642, 0.8651, 0.7272, 0.8791, 0.7724, 0.9050, 0.7208, 0.7311,\n",
            "        0.7103, 1.0641, 0.8693, 0.8894, 0.9640, 0.7265, 0.9341])\n",
            "6 search x tensor([ 0.7274, -0.3161,  0.1937])\n",
            "6 search loss tensor([0.9925, 0.7682, 0.8148, 0.7111, 0.8791, 0.7724, 0.8700, 1.0484, 0.7311,\n",
            "        0.7103, 1.1832, 0.7940, 0.8298, 0.8338, 0.7191, 1.1167])\n",
            "tensor([14,  5,  6,  2,  6,  0])\n",
            "search loss[idx] 0.7102876901626587\n",
            "update_h0 loss, lz 0 0.007786220870912075 tensor([[ 0.0346, -0.0317, -0.1543,  0.1687, -0.1279,  0.1132,  0.1234,  0.0447],\n",
            "        [-0.0238,  0.0092,  0.1448,  0.0102,  0.0136, -0.1387,  0.0516,  0.0084],\n",
            "        [ 0.0451,  0.0554,  0.1007,  0.0456, -0.0720,  0.0102,  0.0555, -0.0058],\n",
            "        [ 0.0784,  0.0615,  0.1976,  0.0573,  0.1253, -0.0091,  0.1458,  0.0710]])\n",
            "0 search x tensor([-0.0115, -0.7483,  0.6633])\n",
            "0 search loss tensor([0.8976, 0.9082, 0.9124, 0.8827, 0.9647, 0.8952, 0.8242, 0.8296, 0.8865,\n",
            "        0.9011, 0.8592, 0.8601, 0.8725, 0.8332, 0.8091, 0.9416])\n",
            "1 search x tensor([-0.1089, -0.8282,  0.5498])\n",
            "1 search loss tensor([0.8466, 0.8072, 0.9167, 0.8755, 0.8787, 0.9062, 0.8404, 0.7871, 0.8899,\n",
            "        0.9188, 0.8424, 0.8632, 0.8301, 0.8400, 0.8078, 0.9517])\n",
            "2 search x tensor([-0.1579, -0.8659,  0.4746])\n",
            "2 search loss tensor([0.8218, 0.8281, 0.8394, 0.8874, 0.8326, 0.7997, 0.7985, 0.7891, 0.8152,\n",
            "        0.8065, 0.7935, 0.8147, 0.8331, 0.8117, 0.8087, 0.8116])\n",
            "3 search x tensor([-0.2144, -0.8860,  0.4111])\n",
            "3 search loss tensor([0.8005, 0.7995, 0.8450, 0.8039, 0.8333, 0.7738, 0.7720, 0.7757, 0.8050,\n",
            "        0.8008, 0.7830, 1.1568, 0.7999, 0.8118, 0.7731, 0.8119])\n",
            "4 search x tensor([-0.2440, -0.8887,  0.3881])\n",
            "4 search loss tensor([0.8080, 0.8080, 0.8244, 0.8040, 0.7997, 0.7753, 0.7746, 0.7757, 0.8052,\n",
            "        0.8008, 0.7609, 0.9959, 0.7999, 0.8118, 0.7731, 0.8189])\n",
            "5 search x tensor([-0.1480, -0.8656,  0.4783])\n",
            "5 search loss tensor([0.8225, 0.8028, 0.8361, 0.8253, 0.8004, 0.7757, 0.7749, 0.7757, 0.8048,\n",
            "        0.8008, 0.7641, 0.9959, 0.7999, 0.8178, 0.6709, 0.8053])\n",
            "6 search x tensor([-0.1791, -0.8774,  0.4450])\n",
            "6 search loss tensor([0.8323, 0.8028, 0.7933, 0.8042, 0.8010, 0.7280, 0.7654, 0.7673, 0.7935,\n",
            "        0.8008, 0.7541, 0.9959, 0.7879, 0.8229, 0.9997, 0.8069])\n",
            "tensor([3, 0, 7, 5, 0, 0])\n",
            "search loss[idx] 0.7280339598655701\n",
            "update_h0 loss, lz 0 0.005286761559545994 tensor([[-0.2187, -0.3025, -0.1046, -0.2337,  0.0530,  0.1443, -0.1549,  0.0378],\n",
            "        [ 0.0254, -0.1021, -0.1514,  0.0651, -0.0350, -0.2505,  0.0837, -0.1399],\n",
            "        [ 0.1866, -0.0447,  0.0148, -0.0953, -0.0186, -0.0587, -0.0532, -0.1096],\n",
            "        [-0.0270,  0.0299,  0.0950,  0.0380, -0.0634,  0.0916, -0.0915,  0.0588]])\n",
            "0 search x tensor([ 0.2657, -0.2720,  0.1609])\n",
            "0 search loss tensor([0.8258, 0.7849, 0.7852, 0.8072, 0.7694, 0.7902, 0.7746, 0.8461, 0.7647,\n",
            "        0.8189, 0.7934, 0.7717, 0.7845, 0.7869, 0.8340, 0.8370])\n",
            "1 search x tensor([ 0.1654, -0.3717,  0.0608])\n",
            "1 search loss tensor([0.9898, 0.7446, 0.7896, 0.7711, 0.7712, 0.7769, 0.7463, 0.8046, 0.7611,\n",
            "        0.7658, 0.7807, 0.6941, 0.7648, 0.7806, 1.0004, 0.8373])\n",
            "2 search x tensor([ 0.2145, -0.4988,  0.1128])\n",
            "2 search loss tensor([1.2957, 1.0772, 0.7741, 0.7654, 0.7383, 0.8143, 1.0841, 0.7780, 0.7453,\n",
            "        0.7446, 0.7721, 1.0370, 0.7445, 0.7595, 1.4277, 1.0733])\n",
            "3 search x tensor([ 0.3067, -0.6316,  0.2403])\n",
            "3 search loss tensor([1.1319, 1.3874, 0.7503, 0.7461, 0.7497, 0.7581, 1.4819, 0.7559, 0.7455,\n",
            "        0.7503, 0.7724, 1.3920, 0.7445, 0.7371, 1.3522, 1.4855])\n",
            "4 search x tensor([ 0.4460, -0.7251,  0.3400])\n",
            "4 search loss tensor([1.0093, 1.2219, 0.7393, 0.7462, 0.6848, 0.7537, 1.1345, 0.7563, 0.7455,\n",
            "        0.7444, 0.8919, 1.1314, 0.7121, 0.7252, 0.9079, 1.3292])\n",
            "5 search x tensor([ 0.5841, -0.7028,  0.3738])\n",
            "5 search loss tensor([0.9778, 0.8783, 0.7218, 0.7528, 0.7362, 0.7511, 1.0944, 0.7563, 0.6846,\n",
            "        1.1922, 0.9791, 1.0098, 1.0671, 0.7041, 0.8025, 1.0699])\n",
            "6 search x tensor([ 0.6227, -0.6875,  0.3736])\n",
            "6 search loss tensor([0.9880, 0.8796, 0.7183, 1.1329, 0.6884, 0.7411, 1.0959, 0.7493, 0.6708,\n",
            "        1.2192, 0.9191, 0.9066, 1.4050, 1.2149, 0.7557, 1.0488])\n",
            "tensor([ 8,  3,  1,  5, 14,  6])\n",
            "search loss[idx] 0.6707847118377686\n",
            "update_h0 loss, lz 0 0.003959187306463718 tensor([[-0.1654, -0.0640, -0.3006,  0.0374, -0.0044,  0.0835, -0.1101,  0.0498],\n",
            "        [ 0.1961, -0.1067, -0.0891,  0.0215,  0.0653,  0.0073, -0.0564, -0.1288],\n",
            "        [ 0.0609,  0.0773,  0.0171, -0.1119, -0.0703,  0.0073,  0.1591, -0.0083],\n",
            "        [-0.0660, -0.0451,  0.2136,  0.1009,  0.0152,  0.1231,  0.1261, -0.0708]])\n",
            "0 search x tensor([ 0.3662, -0.5138,  0.2138])\n",
            "0 search loss tensor([0.8580, 0.8733, 0.8283, 0.8505, 0.8661, 0.7962, 0.8616, 0.8966, 0.8215,\n",
            "        0.9035, 0.8486, 0.8504, 0.8841, 0.8742, 0.8850, 0.8800])\n",
            "1 search x tensor([ 0.2658, -0.6133,  0.1135])\n",
            "1 search loss tensor([0.7958, 0.7920, 0.7923, 0.8169, 0.8347, 0.7368, 0.7563, 0.7520, 0.7859,\n",
            "        0.8416, 0.7820, 0.8277, 0.8078, 0.8165, 0.8409, 0.8022])\n",
            "2 search x tensor([ 0.1525, -0.7226,  0.0271])\n",
            "2 search loss tensor([0.7934, 0.7935, 0.8091, 0.8160, 0.8347, 0.7582, 0.9624, 0.7314, 0.7883,\n",
            "        0.8064, 0.7626, 0.8001, 0.8071, 0.7933, 0.7039, 0.7891])\n",
            "3 search x tensor([ 0.0440, -0.8098, -0.0585])\n",
            "3 search loss tensor([0.7020, 0.7709, 0.7629, 0.8019, 0.7643, 0.7041, 0.8840, 0.7239, 0.7847,\n",
            "        0.8077, 0.7455, 0.8002, 0.7451, 0.7935, 0.7039, 0.7270])\n",
            "4 search x tensor([ 0.0065, -0.9281, -0.0429])\n",
            "4 search loss tensor([0.7026, 0.7386, 0.7633, 0.8023, 0.7702, 0.7042, 0.8840, 0.7239, 0.7637,\n",
            "        0.7768, 0.7471, 0.8002, 0.6805, 0.7935, 0.7492, 0.7121])\n",
            "5 search x tensor([-0.0243, -0.9997, -0.0098])\n",
            "5 search loss tensor([0.7020, 0.7133, 0.7615, 0.8023, 0.7145, 0.7498, 0.8624, 0.7239, 0.7603,\n",
            "        0.7563, 0.7104, 0.8002, 0.8275, 0.7829, 0.7006, 0.7161])\n",
            "6 search x tensor([-0.0496, -0.9983,  0.0301])\n",
            "6 search loss tensor([0.7000, 0.9072, 0.7749, 0.7933, 0.7155, 0.7026, 1.2472, 0.9850, 0.7084,\n",
            "        0.7374, 0.7142, 0.7917, 0.6714, 0.7129, 0.7035, 0.7165])\n",
            "tensor([ 3,  6, 13,  5,  0, 10])\n",
            "search loss[idx] 0.6713773012161255\n",
            "update_h0 loss, lz 0 0.002370221307501197 tensor([[ 7.7784e-02, -1.9036e-01,  2.0459e-01,  2.4966e-02, -2.0533e-02,\n",
            "         -2.9162e-05, -1.4124e-01, -2.7599e-02],\n",
            "        [ 1.9653e-01,  1.3218e-01,  1.2165e-01,  6.2242e-03,  8.1740e-03,\n",
            "          2.4631e-02, -8.6283e-02,  1.1608e-01],\n",
            "        [ 9.1148e-02, -9.4671e-02, -1.7788e-01, -6.6526e-02,  5.4957e-03,\n",
            "         -1.1902e-01,  1.3192e-01,  1.0241e-02],\n",
            "        [ 9.9935e-02, -6.2138e-02,  3.6604e-02, -1.5175e-01,  9.2916e-02,\n",
            "          1.2055e-01, -2.9363e-02, -5.5279e-02]])\n",
            "0 search x tensor([ 0.1699, -0.5011,  0.1577])\n",
            "0 search loss tensor([1.4800, 1.4783, 1.4224, 1.4299, 1.4795, 1.5751, 1.4434, 1.4699, 1.5176,\n",
            "        1.5173, 1.4224, 1.6085, 1.5161, 1.5702, 1.5176, 1.4301])\n",
            "1 search x tensor([ 0.0697, -0.6006,  0.2576])\n",
            "1 search loss tensor([1.1010, 1.1283, 1.0979, 1.0832, 1.0959, 1.1265, 1.1017, 1.0981, 1.1259,\n",
            "        1.1168, 1.1265, 1.0653, 1.1373, 1.1420, 1.1259, 1.0803])\n",
            "2 search x tensor([-0.0592, -0.7234,  0.3731])\n",
            "2 search loss tensor([1.1017, 1.0774, 1.0802, 1.0834, 1.0666, 1.0834, 1.1018, 1.0983, 1.0986,\n",
            "        1.1169, 1.0840, 1.0661, 1.1374, 1.1069, 1.0986, 1.0808])\n",
            "3 search x tensor([-0.1715, -0.8350,  0.4837])\n",
            "3 search loss tensor([1.0894, 1.1174, 1.0305, 1.0221, 1.0665, 1.0833, 1.1139, 1.0814, 1.0666,\n",
            "        1.0666, 1.0297, 1.0604, 1.1014, 1.1154, 1.0868, 1.0801])\n",
            "4 search x tensor([-0.1871, -0.8377,  0.5132])\n",
            "4 search loss tensor([1.0353, 1.0382, 1.0305, 1.0234, 1.0091, 1.0316, 1.0615, 1.0200, 1.0830,\n",
            "        1.0295, 1.0305, 1.0220, 1.0237, 0.9166, 1.0456, 0.8821])\n",
            "5 search x tensor([-0.1733, -0.8281,  0.5331])\n",
            "5 search loss tensor([1.0394, 1.0221, 1.0251, 1.0482, 1.0222, 1.0324, 1.0745, 1.0200, 1.0243,\n",
            "        1.0127, 1.0215, 1.0596, 1.0240, 0.9367, 1.0222, 0.8821])\n",
            "6 search x tensor([-0.1828, -0.8130,  0.5527])\n",
            "6 search loss tensor([1.0126, 1.0446, 0.8139, 0.8028, 1.0239, 1.0344, 1.0343, 0.8006, 1.0123,\n",
            "        1.0428, 0.8035, 1.0233, 1.0524, 1.0451, 1.0255, 0.9110])\n",
            "tensor([ 6,  5,  9,  0,  1, 13])\n",
            "search loss[idx] 0.8005525469779968\n",
            "update_h0 loss, lz 0 0.0016391301760450006 tensor([[ 0.0870,  0.0519,  0.0669, -0.1020, -0.0460, -0.1355, -0.0242,  0.0611],\n",
            "        [-0.0130, -0.0451, -0.0034,  0.0039, -0.0327, -0.0098,  0.0111,  0.0797],\n",
            "        [ 0.0140, -0.1088, -0.0213,  0.2090,  0.0515, -0.1655, -0.0859, -0.0518],\n",
            "        [-0.0099,  0.0579,  0.0186, -0.0728, -0.0229,  0.1456, -0.0103, -0.0415]])\n",
            "0 search x tensor([0.3075, 0.1269, 0.1454])\n",
            "0 search loss tensor([1.2073, 1.1572, 1.2895, 1.1871, 1.2351, 1.2800, 1.2613, 1.3627, 1.2286,\n",
            "        1.2300, 1.2085, 1.3072, 1.3045, 1.1807, 1.2894, 1.2335])\n",
            "1 search x tensor([0.2072, 0.0268, 0.0453])\n",
            "1 search loss tensor([1.1144, 1.2150, 1.0213, 1.1325, 1.1761, 1.0934, 1.2116, 1.2407, 1.1683,\n",
            "        1.1511, 1.2122, 1.1249, 1.1789, 1.1723, 1.2304, 1.1503])\n",
            "2 search x tensor([ 0.1217, -0.0503,  0.0834])\n",
            "2 search loss tensor([1.0570, 1.0495, 0.9610, 1.0378, 1.0790, 1.0713, 1.0552, 1.0376, 1.0813,\n",
            "        1.1405, 1.1788, 1.0375, 1.0403, 1.0449, 1.1142, 0.9773])\n",
            "3 search x tensor([ 0.0241, -0.1164, -0.0557])\n",
            "3 search loss tensor([1.0351, 0.9795, 0.9534, 1.0491, 1.1914, 1.0379, 1.0567, 1.0315, 1.0744,\n",
            "        1.0633, 1.1371, 1.0202, 1.0483, 1.0435, 0.9964, 0.9778])\n",
            "4 search x tensor([-0.0893, -0.1789, -0.2127])\n",
            "4 search loss tensor([1.0356, 0.9801, 0.9539, 1.0501, 1.0695, 0.9802, 0.9621, 1.0315, 1.0482,\n",
            "        1.0107, 0.9440, 1.0207, 0.9881, 1.0013, 0.9948, 0.9778])\n",
            "5 search x tensor([-0.2004, -0.2434, -0.3429])\n",
            "5 search loss tensor([1.0211, 0.9804, 0.9539, 0.9856, 0.9597, 0.9805, 0.9779, 1.0315, 1.0485,\n",
            "        1.0111, 0.9560, 0.9857, 0.9884, 0.9860, 0.9949, 0.9778])\n",
            "6 search x tensor([-0.3071, -0.2898, -0.4760])\n",
            "6 search loss tensor([0.9272, 1.0107, 0.9129, 0.9399, 0.9439, 0.9640, 0.9800, 0.9441, 1.0477,\n",
            "        0.9802, 0.9562, 0.9868, 0.9884, 0.9337, 0.9949, 0.9778])\n",
            "tensor([ 3,  4, 13,  5,  0,  6])\n",
            "search loss[idx] 0.912886381149292\n",
            "update_h0 loss, lz 0 0.0045947786420583725 tensor([[-0.0089,  0.1415,  0.0495,  0.1840,  0.0522, -0.1489, -0.1641, -0.0552],\n",
            "        [ 0.0089,  0.0531, -0.0173, -0.0035,  0.3407,  0.0908, -0.2083,  0.0286],\n",
            "        [ 0.2372,  0.0320,  0.0130,  0.1551, -0.0366,  0.0259, -0.2103,  0.0280],\n",
            "        [ 0.0477,  0.1622, -0.2112,  0.0176,  0.0950,  0.1366,  0.0378, -0.1795]])\n",
            "0 search x tensor([-0.0331, -0.3744,  0.0157])\n",
            "0 search loss tensor([0.7270, 0.7272, 0.7727, 0.7538, 0.7268, 0.7805, 0.7695, 0.7555, 0.7299,\n",
            "        0.7550, 0.7665, 0.7280, 0.7604, 0.7269, 0.7564, 0.7511])\n",
            "1 search x tensor([-0.1331, -0.4740, -0.0843])\n",
            "1 search loss tensor([0.7278, 0.7275, 1.3742, 0.7560, 0.7275, 0.7979, 0.7697, 0.7579, 0.7304,\n",
            "        0.7790, 0.7679, 0.7281, 0.7599, 0.7225, 0.7510, 0.7669])\n",
            "2 search x tensor([-0.2343, -0.5627, -0.1841])\n",
            "2 search loss tensor([0.7161, 0.7275, 1.3331, 0.6869, 0.7200, 0.7535, 0.7274, 0.6964, 0.6682,\n",
            "        0.7433, 0.6959, 0.7238, 0.7553, 0.6687, 0.7498, 0.7631])\n",
            "3 search x tensor([-0.3353, -0.6217, -0.2892])\n",
            "3 search loss tensor([1.4631, 1.0962, 1.0844, 0.6994, 0.6721, 0.7466, 1.0974, 0.6710, 0.6644,\n",
            "        1.1081, 1.0928, 1.1415, 1.2760, 0.6579, 0.7019, 1.0430])\n",
            "4 search x tensor([-0.4664, -0.8002, -0.1173])\n",
            "4 search loss tensor([1.4169, 1.3250, 0.9791, 1.1189, 1.3272, 1.4111, 1.2604, 1.1103, 1.1646,\n",
            "        1.2135, 1.3984, 1.4005, 0.7541, 1.1780, 0.7019, 1.0136])\n",
            "5 search x tensor([-0.4937, -0.8688, -0.0387])\n",
            "5 search loss tensor([1.2713, 1.1675, 1.1980, 1.3329, 1.3842, 0.7358, 1.1587, 0.9308, 1.1362,\n",
            "        1.0135, 1.2979, 1.2752, 1.1081, 1.1459, 1.3185, 1.1619])\n",
            "6 search x tensor([-0.4789, -0.8747,  0.0740])\n",
            "6 search loss tensor([1.1883, 1.1432, 1.1661, 1.1793, 1.3856, 1.1766, 1.2391, 1.1709, 1.1686,\n",
            "        1.1196, 1.3044, 1.2444, 1.3858, 1.1535, 1.2235, 1.1294])\n",
            "tensor([ 3, 13,  2,  9,  1, 10])\n",
            "search loss[idx] 1.1196454763412476\n",
            "update_h0 loss, lz 0 0.011199015192687511 tensor([[-0.2135,  0.0819,  0.0901,  0.0256, -0.0849,  0.0343,  0.1828, -0.0245],\n",
            "        [ 0.3005,  0.0956, -0.0126, -0.0196,  0.1828, -0.2559, -0.0606,  0.0843],\n",
            "        [-0.1032, -0.1910,  0.0056,  0.0243, -0.0267, -0.0867,  0.0307, -0.1060],\n",
            "        [-0.0565,  0.0229, -0.0737,  0.2014, -0.1949,  0.0943, -0.0329, -0.1108]])\n",
            "0 search x tensor([-0.0346, -0.0167,  0.2108])\n",
            "0 search loss tensor([0.8080, 0.8774, 0.9549, 0.9761, 0.9529, 0.9071, 0.9344, 0.9357, 0.8873,\n",
            "        0.8666, 0.8827, 0.9457, 0.9351, 0.9330, 0.9216, 0.9075])\n",
            "1 search x tensor([-0.1345, -0.1167,  0.1106])\n",
            "1 search loss tensor([0.7682, 0.8648, 0.8724, 0.8308, 0.8395, 0.8289, 0.7779, 0.8134, 0.9134,\n",
            "        0.8410, 0.9664, 0.9507, 0.8257, 0.8171, 0.7844, 0.7712])\n",
            "2 search x tensor([-0.2503, -0.1549, -0.0111])\n",
            "2 search loss tensor([1.0980, 1.1464, 0.8368, 0.8160, 0.8246, 0.8258, 0.7819, 0.9208, 0.8630,\n",
            "        1.0337, 0.8406, 0.9381, 0.7772, 0.7743, 0.7943, 0.7716])\n",
            "3 search x tensor([-0.2172, -0.0381, -0.1151])\n",
            "3 search loss tensor([0.7681, 1.4399, 0.7865, 1.1884, 0.8547, 0.7489, 0.6976, 0.8208, 0.8303,\n",
            "        1.5722, 0.7826, 0.9381, 0.7529, 0.7322, 1.2999, 0.7738])\n",
            "4 search x tensor([-0.3242, -0.0487, -0.2257])\n",
            "4 search loss tensor([0.9069, 0.7842, 0.7598, 0.7915, 0.7761, 0.7310, 0.6981, 0.7051, 0.6993,\n",
            "        1.5125, 0.7832, 0.8944, 0.7531, 0.6906, 1.6061, 0.7657])\n",
            "5 search x tensor([-0.2469,  0.0482, -0.3368])\n",
            "5 search loss tensor([0.6986, 0.7851, 0.7501, 0.7799, 0.7767, 1.1581, 0.6714, 0.7059, 0.7004,\n",
            "        0.7931, 1.5709, 0.8665, 0.7010, 0.7322, 1.4654, 0.7469])\n",
            "6 search x tensor([-0.2706, -0.0435, -0.3323])\n",
            "6 search loss tensor([0.6987, 0.7851, 0.6905, 0.7377, 0.7653, 1.4295, 0.6719, 0.9408, 0.7004,\n",
            "        0.7762, 0.7737, 0.8328, 0.7011, 0.6909, 1.2693, 0.7001])\n",
            "tensor([13,  6, 13,  5,  0, 13])\n",
            "search loss[idx] 0.6719106435775757\n",
            "update_h0 loss, lz 0 0.005191980395466089 tensor([[-0.2887,  0.1763, -0.0343,  0.2883, -0.1522,  0.1299, -0.1347, -0.0856],\n",
            "        [-0.0540,  0.0243,  0.0387, -0.0659, -0.0980,  0.0861,  0.0591, -0.0136],\n",
            "        [ 0.3630,  0.0073,  0.0487,  0.0054, -0.0582, -0.0743,  0.1623, -0.1963],\n",
            "        [ 0.0235, -0.0462,  0.0820, -0.0675, -0.1095, -0.1824, -0.0906, -0.1639]])\n",
            "0 search x tensor([-0.2859, -0.1718, -0.1924])\n",
            "0 search loss tensor([0.7580, 0.7660, 0.7457, 0.7653, 0.7682, 0.7655, 0.7798, 0.7595, 0.7616,\n",
            "        0.7491, 0.7601, 0.7675, 0.7590, 1.0114, 0.7588, 0.7600])\n",
            "1 search x tensor([-0.3856, -0.2716, -0.0922])\n",
            "1 search loss tensor([0.7390, 0.7326, 0.8407, 0.7518, 1.0545, 0.7500, 0.7523, 0.7424, 0.7443,\n",
            "        1.2806, 0.7424, 1.2111, 1.0958, 0.7301, 0.7453, 1.1304])\n",
            "2 search x tensor([-0.4785, -0.3448, -0.0716])\n",
            "2 search loss tensor([0.7409, 0.7327, 1.2209, 0.7521, 0.9614, 0.7500, 0.7548, 0.7460, 0.7443,\n",
            "        1.1809, 0.7395, 1.1284, 0.9832, 0.8811, 1.0115, 1.0053])\n",
            "3 search x tensor([-0.5812, -0.4251, -0.0250])\n",
            "3 search loss tensor([1.0188, 1.1915, 1.1759, 1.0374, 0.9614, 1.0274, 1.2464, 1.1817, 1.0343,\n",
            "        1.0068, 1.0430, 1.1314, 1.1907, 1.0473, 1.0190, 1.0238])\n",
            "4 search x tensor([-0.6914, -0.5956,  0.1548])\n",
            "4 search loss tensor([1.0266, 1.0880, 0.7990, 1.0237, 0.9026, 1.0240, 1.2623, 1.0371, 1.0403,\n",
            "        0.8465, 1.2104, 0.9754, 1.0406, 1.0204, 1.2980, 0.7086])\n",
            "5 search x tensor([-0.6761, -0.6821,  0.2785])\n",
            "5 search loss tensor([1.2946, 1.0571, 0.7792, 1.0282, 0.8517, 1.0137, 0.9725, 1.0168, 1.0406,\n",
            "        1.4363, 1.0075, 0.9137, 1.2414, 0.7835, 0.9549, 1.2859])\n",
            "6 search x tensor([-0.6784, -0.6682,  0.3054])\n",
            "6 search loss tensor([1.2847, 1.0897, 1.2150, 1.2632, 0.8517, 0.9129, 0.9602, 0.9200, 0.9997,\n",
            "        0.7717, 1.0248, 0.7570, 0.8756, 1.0532, 0.9137, 0.8688])\n",
            "tensor([ 6, 13,  5,  6, 13, 13])\n",
            "search loss[idx] 0.7569921016693115\n",
            "update_h0 loss, lz 0 0.002714861650019884 tensor([[-1.3987e-01, -1.5356e-01,  3.7162e-02, -1.4403e-01, -2.8431e-02,\n",
            "          8.6452e-02, -3.0545e-03,  5.7085e-03],\n",
            "        [-4.8921e-02,  1.2693e-01,  2.0509e-03, -1.2885e-01,  4.3058e-02,\n",
            "          3.9033e-03, -1.8473e-04, -2.5222e-01],\n",
            "        [-8.6499e-02,  3.1891e-02,  7.1114e-02, -1.9129e-02,  3.3292e-02,\n",
            "          2.4448e-02, -1.1548e-01,  1.5998e-01],\n",
            "        [ 7.7032e-02, -1.5922e-01,  2.5634e-02,  8.1097e-04,  1.6383e-02,\n",
            "          3.0006e-02, -2.4132e-01,  8.8243e-02]])\n",
            "0 search x tensor([-0.8077, -0.1644, -0.0186])\n",
            "0 search loss tensor([0.7971, 0.8125, 0.8218, 0.8249, 0.9068, 0.8131, 0.8271, 0.7971, 0.8527,\n",
            "        0.7969, 0.8291, 0.8412, 0.8161, 0.8039, 0.8736, 0.8285])\n",
            "1 search x tensor([-0.7069, -0.0642, -0.1186])\n",
            "1 search loss tensor([0.8166, 0.8408, 0.8230, 0.8387, 0.8236, 0.8224, 0.7928, 0.8335, 0.8343,\n",
            "        0.8141, 0.8274, 0.8122, 0.8168, 0.7903, 0.7949, 0.8245])\n",
            "2 search x tensor([-7.8340e-01, -2.8384e-04, -2.4230e-01])\n",
            "2 search loss tensor([0.8250, 0.8150, 0.8147, 0.8196, 0.8041, 0.8128, 0.8007, 0.8078, 0.7976,\n",
            "        0.8048, 0.8169, 0.8126, 0.7953, 0.8042, 0.8069, 0.8476])\n",
            "3 search x tensor([-0.7254,  0.0574, -0.3587])\n",
            "3 search loss tensor([0.7982, 0.8246, 0.8167, 0.8241, 0.7937, 0.8369, 0.7945, 0.8082, 0.8134,\n",
            "        0.8049, 0.8183, 0.8126, 0.8127, 0.8010, 0.7945, 0.8008])\n",
            "4 search x tensor([-0.5988,  0.2029, -0.4473])\n",
            "4 search loss tensor([0.8480, 0.8144, 0.8045, 0.8335, 0.8108, 0.8008, 1.0043, 0.8082, 0.8101,\n",
            "        0.8049, 0.8083, 0.7963, 0.8155, 0.7953, 0.7984, 0.7904])\n",
            "5 search x tensor([-0.6921,  0.0760, -0.5588])\n",
            "5 search loss tensor([0.8172, 0.8009, 0.8111, 0.8014, 0.7920, 0.7951, 0.9087, 0.8064, 0.7425,\n",
            "        0.8011, 0.7418, 0.7377, 0.8009, 0.8147, 0.7689, 0.8072])\n",
            "6 search x tensor([-0.6960,  0.1123, -0.6865])\n",
            "6 search loss tensor([0.7410, 0.8010, 0.7202, 0.7818, 0.8248, 0.8103, 1.0178, 0.7361, 1.3502,\n",
            "        0.7510, 0.7431, 1.2609, 0.7494, 0.7431, 0.7581, 0.7156])\n",
            "tensor([ 2,  6,  1, 13,  0, 13])\n",
            "search loss[idx] 0.7156493067741394\n",
            "update_h0 loss, lz 0 0.005215517710894346 tensor([[ 0.1049,  0.0024,  0.0944,  0.0540, -0.0452, -0.0780,  0.1149, -0.1375],\n",
            "        [ 0.0818, -0.0740, -0.0330, -0.2036,  0.0431,  0.1880, -0.2329, -0.0517],\n",
            "        [ 0.0087, -0.0155,  0.0909,  0.2228, -0.0091, -0.0483,  0.0388, -0.0980],\n",
            "        [-0.1003, -0.0952,  0.1902, -0.0782, -0.1489,  0.1195, -0.1380, -0.0808]])\n",
            "0 search x tensor([ 0.2971, -0.0271, -0.0524])\n",
            "0 search loss tensor([0.8782, 0.8270, 0.8365, 0.8836, 0.8518, 0.8520, 0.8555, 0.8876, 0.8432,\n",
            "        0.9094, 0.8269, 0.8566, 0.8451, 0.8453, 0.8396, 0.8398])\n",
            "1 search x tensor([ 0.1968, -0.1270, -0.1524])\n",
            "1 search loss tensor([0.8846, 0.8289, 0.8345, 0.8846, 0.8414, 0.8594, 0.8571, 0.8901, 0.8274,\n",
            "        0.8403, 0.8273, 0.8269, 0.8317, 0.8593, 0.8405, 0.8406])\n",
            "2 search x tensor([ 0.0947, -0.2483, -0.2342])\n",
            "2 search loss tensor([0.8183, 0.8289, 0.8323, 0.8179, 0.8286, 0.8195, 0.8523, 0.8189, 0.8266,\n",
            "        0.8405, 0.8273, 0.8273, 0.8062, 0.8487, 0.8405, 0.8243])\n",
            "3 search x tensor([ 0.0349, -0.3044, -0.3175])\n",
            "3 search loss tensor([0.8191, 0.8282, 0.7858, 0.8191, 0.8203, 0.8207, 0.8523, 0.8198, 0.8040,\n",
            "        0.8390, 0.8273, 0.8273, 0.7934, 0.8444, 0.8236, 0.8253])\n",
            "4 search x tensor([-0.0240, -0.3489, -0.3982])\n",
            "4 search loss tensor([0.8035, 0.8205, 0.7690, 0.8191, 0.8106, 0.8182, 0.8240, 0.7834, 0.7882,\n",
            "        0.8390, 0.8201, 0.8273, 0.7928, 0.8333, 0.8063, 0.7565])\n",
            "5 search x tensor([ 0.0406, -0.3127, -0.3821])\n",
            "5 search loss tensor([0.7536, 0.7777, 0.7355, 0.7746, 0.7762, 0.8090, 0.8246, 0.8098, 0.7681,\n",
            "        0.8256, 0.7503, 0.7911, 0.7890, 0.8190, 0.7368, 0.7895])\n",
            "6 search x tensor([ 0.1034, -0.2823, -0.3458])\n",
            "6 search loss tensor([0.8066, 0.7773, 0.8029, 0.7538, 0.7664, 0.7590, 0.8246, 0.7850, 0.7932,\n",
            "        0.8257, 0.7458, 0.7690, 0.7488, 0.8190, 0.7627, 0.7647])\n",
            "tensor([8, 4, 1, 2, 3, 0])\n",
            "search loss[idx] 0.7457854747772217\n",
            "dided\n",
            "time\n",
            "[11, 2, 13, 6, 6, 11, 4, 7, 6, 5, 6, 7, 7, 2, 6, 12, 6, 5, 1, 6, 6, 5, 6, 7, 11, 8, 7, 13, 10, 8, 6, 4, 0, 5, 13, 13, 6, 2, 13, 7, 12, 2, 6, 6, 7, 5, 0, 6, 0, 11, 7, 13, 4, 6, 5, 13, 6, 2, 0, 12, 1, 2, 6, 12, 7, 5, 3, 7, 6, 5, 6, 6, 6, 5, 3, 7, 6, 5, 6, 7, 6, 5, 6, 7, 6, 5, 6, 7, 6, 5, 6, 7, 6, 5, 6, 7, 6, 5, 4, 6, 1, 5, 12, 8, 6, 2, 7, 0, 1, 2, 6, 7, 14, 11, 10, 8, 6, 5, 6, 7, 6, 5, 6, 7, 6, 5, 6, 7, 6, 5, 3, 7, 6, 5, 6, 7, 6, 5, 6, 8, 3, 5, 12, 8, 6, 2, 6, 7, 9, 13, 12, 2, 6, 5, 6, 7, 14, 5, 6, 2, 3, 0, 7, 5, 8, 3, 1, 5, 3, 6, 13, 5, 6, 5, 9, 0, 3, 4, 13, 5, 3, 13, 2, 9, 13, 6, 13, 5, 6, 13, 5, 6, 2, 6, 1, 13, 8, 4]\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 4\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import time\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# buffer=[]\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# print(env.action_space) # 15\n",
        "\n",
        "def simulate(agent, buffer=[], k=4):\n",
        "    # agent.eval()\n",
        "    out=None\n",
        "    writer = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    # writer = cv2.VideoWriter('video{}.avi'.format(time.time()), cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    act=[]\n",
        "    act_list=[]\n",
        "    lstate=[]\n",
        "    # h0 = torch.randn((agent.jepa.pred.num_layers, agent.d_model), device=device)\n",
        "    while True:\n",
        "    # for i in range(400):\n",
        "    # while not done:\n",
        "        state = transform(state).unsqueeze(0).to(device)\n",
        "        # state = transform(state).unsqueeze(0).to(device)[0]\n",
        "        # with torch.no_grad():\n",
        "        #     st = agent.jepa.enc(state)\n",
        "        #     # st_ = agent.jepa.pred(st)\n",
        "        #     stt = agent.tcost(st).squeeze(-1)\n",
        "        #     imshow(state.detach().cpu().squeeze(0))\n",
        "        #     print(stt)\n",
        "            # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # if len(act)<=0: act = agent(state).cpu()[:1].tolist()\n",
        "        # if len(act)<=0: act = agent(state).cpu()[0,:4].tolist()\n",
        "        # print(act.shape, h0.shape) # [1, 6], [1, 256]\n",
        "        lstate.append(state)\n",
        "        if len(act)<=0:\n",
        "            # lact, lh0, lx, lz = agent(state, h0)\n",
        "            # act = lact.cpu()[0,:k].tolist()\n",
        "            # act = agent(state, k)\n",
        "            act = agent(lstate, k=k)\n",
        "            lstate=[]\n",
        "        action = act.pop(0)\n",
        "        state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        # print(i, 'act: ',action, 'reward: ',reward)\n",
        "        act_list.append(action)\n",
        "        writer.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            print(\"dided\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    print('time')\n",
        "    print(act_list)\n",
        "    env.close()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "_=simulate(agent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "oFZDopEKGCO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cm6KjvBrnNO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title alllll\n",
        "for i in range(200):\n",
        "    # print(\"#### simulate ####\")\n",
        "    # buffer_=[]\n",
        "    for _ in range(5):\n",
        "        buffer = simulate(agent, buffer)\n",
        "        # buffer_ = simulate(agent, buffer_)\n",
        "\n",
        "    train_data = BufferDataset(buffer, seq_len)\n",
        "    # train_loader = DataLoader(train_data, shuffle = True, collate_fn=collate_fn, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "    train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # [3,batch, T]\n",
        "    agent.tcost.update_loss_weight(train_data)\n",
        "\n",
        "    print(i,\"#### train ####\")\n",
        "    agent.train_jepa(train_loader, optim)\n",
        "\n",
        "    checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "    torch.save(checkpoint, folder+'agentgru1tcost3goscratch.pkl')\n",
        "\n",
        "    # buffer = [episode for episode in buffer if episode[-1][2]==-1]\n",
        "    with open(folder+'buffergo.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "\n",
        "    # agentsd, _ = rename_sd(agent.state_dict())\n",
        "    # all_sd = store_sd(all_sd, agentsd)\n",
        "    # torch.save(all_sd, folder+'all_sd.pkl')\n",
        "\n",
        "    print(\"train_data.data\",len(train_data.data))\n",
        "    while len(train_data.data)>10000: # 10000:6.9gb, 20000:5.5gb\n",
        "        buffer.pop(random.randrange(len(buffer)))\n",
        "        train_data = BufferDataset(buffer, seq_len)\n",
        "\n",
        "# repr, std, cov 0.009419754147529602 0.478271484375 0.005037273280322552\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 533,
      "metadata": {
        "id": "b8zxYU9jpE8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "03f4b486-8f48-4a84-ff4f-fccb72105a38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=400 controls autoplay><source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"></video>"
            ]
          },
          "metadata": {},
          "execution_count": 533
        }
      ],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i video.avi video.mp4 -y\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4', \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"<video width=400 controls autoplay><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkK_9AQm8_q"
      },
      "source": [
        "##save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792,
          "referenced_widgets": [
            "52b55d07f1314d26952ce0db31baf2e2",
            "1f2296a217ed49d29ede116c277d12e7",
            "4f6e405a7bc540b89549c02b54332093",
            "a8b37cd81d8843a3a7a7295494a74603",
            "0320a1972db44611919ee6c1fc3d480d",
            "b5835eb4fd7f4e8cb1a766d5fd4859fc",
            "034d841416ac4b7cb6c46ec418294902",
            "e99fb80c43a04637a55de2c5bbb17471"
          ]
        },
        "id": "uT9m-J1BUWyz",
        "outputId": "2cbfd032-eed9-45ea-a493-5abc3b6a3155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.15.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:mf406vc1) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.224 MB of 0.224 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52b55d07f1314d26952ce0db31baf2e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>closs</td><td>▇█▇▇█▇▇▇▇▆▆▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▂▁</td></tr><tr><td>cov</td><td>▁▁▁▅▄▄▄▆▅▆▅▄█▆▆▇▅▅▅▅▇▅▆█▇▆▆▅▇▆▆█▇▅▆▅▅▇▇▇</td></tr><tr><td>repr</td><td>▁▁▁▁▂▂▅▄█▆▆▆▆▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▃▄▃▃▃▃▂▂▂▂</td></tr><tr><td>std</td><td>█▆▆▆▅▅▆▄▅▅▃▃▃▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▁</td></tr><tr><td>z_norm</td><td>▂▄▂▄▂▁▇▃▃▅▆▃▇▅▅▄█▃▂▃▅▃▄▅▁▃▄▂▂▂▃▂▃▄▅▃▆▄▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>closs</td><td>0.08859</td></tr><tr><td>cov</td><td>0.0153</td></tr><tr><td>repr</td><td>0.00908</td></tr><tr><td>std</td><td>0.42993</td></tr><tr><td>z_norm</td><td>0.01045</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">spring-morning-130</strong> at: <a href='https://wandb.ai/bobdole/procgen/runs/mf406vc1' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/mf406vc1</a><br/> View project at: <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241007_114935-mf406vc1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:mf406vc1). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241007_124110-utlpvyzo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/procgen/runs/utlpvyzo' target=\"_blank\">glorious-feather-131</a></strong> to <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/procgen' target=\"_blank\">https://wandb.ai/bobdole/procgen</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/procgen/runs/utlpvyzo' target=\"_blank\">https://wandb.ai/bobdole/procgen/runs/utlpvyzo</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "# https://docs.wandb.ai/quickstart\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login() # 487a2109e55dce4e13fc70681781de9f50f27be7\n",
        "run = wandb.init(project=\"procgen\",\n",
        "    config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RCD647ZpPrGf"
      },
      "outputs": [],
      "source": [
        "# @title agent save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = get_res(d_model)\n",
        "        self.sense.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.critic = GRU(\n",
        "        # self.critic = nn.Sequential(\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model, d_model),\n",
        "            # )\n",
        "        # self.actor = nn.Sequential( # -> goal sx/ssx/sssx/...\n",
        "        #     nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "        #     nn.Linear(d_model, d_model),\n",
        "        #     )\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.quantizer = FSQ(levels = [3,3,2])\n",
        "        self.conv = Conv()\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state.flatten()).unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        la, lact = self.search(sx, T=2) # 20\n",
        "        # a, act = la[0][0], lact[0][0]\n",
        "        # return act\n",
        "        return lact[0]\n",
        "\n",
        "    # def search(self, sx, T=256, bptt=32):\n",
        "    def search(self, sx, T=None, bptt=None):\n",
        "        if T==None: T = 256\n",
        "        if bptt==None: bptt = min(T,32)\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.rand((batch, T, 3),device=device)*2 -1) # FSQ 3 levels\n",
        "        optim = torch.optim.SGD([x], lr=1e5)\n",
        "        xx = torch.split(x, bptt, dim=1)\n",
        "        for _ in range(5): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "            for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "                la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "                loss, sx_ = self.rnn_pred(sx_, la)\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "                sx_ = sx_.detach()\n",
        "        print(\"search\",loss.item())\n",
        "        return la, lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        # out=[]\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        # print(\"rnn pred\",lsx[0][:5])\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            # sx = self.jepa.pred(sxaz)\n",
        "            sx = sx + self.jepa.pred(sxaz)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.1*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            tcost = self.tcost(sx)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            # out.append(sx)\n",
        "        # out=torch.cat(out)\n",
        "        # out = out[:, -1, :] # out: (n, 128)\n",
        "        return cost, sx#, z\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        # print(\"get\", state.shape)\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        # current = self.sense(state.unsqueeze(-1)) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            _mem = Stm()\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sx_ = self.jepa.enc(world_state.flatten(start_dim=1))\n",
        "            sx_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "            # print(lst,len(Sar[0]))\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.quantizer.indices_to_codes(action)\n",
        "                    z = self.jepa.argm(sx_, a, sy)\n",
        "                    sxaz = torch.cat([sx_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(sxaz)\n",
        "                    sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # print(\"train jepa sy_\", sy_) # 11.7910 # 1.3963e-06\n",
        "                    # repr_loss = self.jepa.sim_coeff * F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = self.jepa.sim_coeff * F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = repr_loss + std_loss + cov_loss\n",
        "                    # c_ = torch.cat([c_, self.tcost(sy_).squeeze(-1)]) # [batch_size, 1] -> [batch_size]\n",
        "                    # c = torch.cat([c, self.icost(sy) + reward.to(torch.float32)])\n",
        "                    # with torch.no_grad(): c = torch.cat([c, self.icost(sy.detach()) + reward.to(torch.float32)])\n",
        "\n",
        "                    state_ = self.conv(world_state_.detach())\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    loss = loss + jloss + conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(c_)\n",
        "                    # print(c)\n",
        "                    # closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # loss = loss + 100*closs\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sx_ = sx_.detach()\n",
        "                    loss=0\n",
        "                    c,c_= torch.tensor([], device=device), torch.tensor([], device=device)\n",
        "                else:\n",
        "                    scaler.scale(jloss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "                # if batch % 100 == 0:\n",
        "                #     loss, current = loss.item(), batch * len(X)\n",
        "                #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "    # def save(self, folder, name='agent.pth'):\n",
        "    #     torch.save(self.state_dict(), folder+name)\n",
        "    #     self.mem.save(file=folder+name)\n",
        "    # def load(self, folder, name='agent.pth'):\n",
        "    #     self.load_state_dict(torch.load(folder+name), strict=False)\n",
        "    #     # self.mem.load(file=folder+name)\n",
        "\n",
        "\n",
        "# lsx, lc\n",
        "# self.tcost(sx).squeeze(-1)\n",
        "# self.icost(sx_) + reward.to(torch.float32)\n",
        "#                     closs=F.l1_loss(c_, c) # mse_loss, l1_loss\n",
        "\n",
        "\n",
        "agent = Agent().to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "optim = torch.optim.AdamW([{'params': others, 'lr': 1e-3},\n",
        "    {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xLh80kPvEzwX"
      },
      "outputs": [],
      "source": [
        "# @title agent pixel save\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 #\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.emb = torch.nn.Embedding(15, dim_a) # env.action_space # 15\n",
        "        self.deconv = Deconv(d_model)\n",
        "        self.jepa.sim_coeff=2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 20.0 # 1.0 # ν cov Covariance\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        for i in range(20): # num epochs\n",
        "            sx_ = sx.detach()\n",
        "\n",
        "            dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "\n",
        "            # loss, sx_ = self.rnn_pred(sx_, x)\n",
        "            loss, sx_ = self.rnn_pred(sx_, x_)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "    def rnn_pred(self, sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        if z is None: z=torch.zeros((batch,self.dim_z),device=device) # average case?\n",
        "        # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len): # simple single layer\n",
        "            a = la[:,t] # [1, dim_a]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                sx = self.jepa.pred(sxaz)\n",
        "                # sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0.5*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # loss=torch.tensor(0, dtype=torch.float)\n",
        "            state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    sy_ = self.jepa.pred(syaz)\n",
        "                    # sy_ = sx_ + self.jepa.pred(sxaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # # # ae loss\n",
        "                    # state_ = self.deconv(sy.detach()) # not self.deconv(sy)\n",
        "                    # conv_loss = F.mse_loss(state_, state)\n",
        "\n",
        "                    # cost loss\n",
        "                    # reward_ = self.tcost(sy).squeeze(-1) # [batch_size]\n",
        "                    # clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    stt = self.tcost(self.jepa.enc(st)).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb #+ clossl\n",
        "\n",
        "                    loss = loss + jloss + closs #+ conv_loss\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    # print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, conv\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    # print(\"repr, std, cov, conv, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), conv_loss.item(), closs.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    sy_ = sy_.detach()\n",
        "                    loss=0\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item(), \"closs\": closs.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29O1eyvhnRSD",
        "outputId": "c470e601-d5da-4b94-bb69-928dd9d823af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-77-bbc83a6aed37>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent combine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "if not 'sim_coeff' in locals(): # locals() globals()\n",
        "    sim_coeff, std_coeff, cov_coeff = 0.08, 0.033, 1. # 0.1,0.487,0.01 # expected starting loss?\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=1, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model, 1),\n",
        "            )\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=2. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=1. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=30 # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        # 0.0083 0.06 1.0 = 1, 7, 120.5\n",
        "\n",
        "    def forward(self, state): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            self.icost.update(sx)\n",
        "        lact = self.search(sx, T=6) # 20\n",
        "        return lact\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        optim_z = torch.optim.SGD([z], lr=1e2, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.95)) #\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.data)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i,x.data, z.squeeze(), loss.item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        # print(\"search\",loss.item())\n",
        "        return lact#, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        _,T,_ = sx.shape\n",
        "        batch = 1\n",
        "        lr = 1e-1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                x[:,:self.lx.shape[1]] = self.lx[:,:T]\n",
        "                z[:,:self.lz.shape[1]] = self.lz[:,:T]\n",
        "\n",
        "        # min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(\"search\",x.data, z.squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=min, max=max)\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            # print(i,x.data, z.squeeze(), loss.item())\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        return lact, lh0, x, z # [batch_size, T]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, gamma=0.9): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        lsx=sx\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                # sx = self.jepa.pred(sxaz)\n",
        "                sx = sx + self.jepa.pred(sxaz)\n",
        "                tcost = -self.tcost(sx)\n",
        "            lsx = torch.cat([lsx, sx], dim=0)\n",
        "            # print(lsx.requires_grad, sx.requires_grad)\n",
        "            icost = 0*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(icost.requires_grad)\n",
        "            # cost += tcost + icost\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "            print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        return cost, sx\n",
        "\n",
        "\n",
        "    def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "        # if _mem==None: _mem = self.mem\n",
        "        if world_state==None: world_state = self.world_state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        Q = self.q(current) # [batch_size, d_model]\n",
        "        # mem = _mem(Q) # _mem(current)\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "        return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            # loss=0\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    # sy_ = self.jepa.pred(syaz)\n",
        "                    sy_ = sy_ + self.jepa.pred(syaz)\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "                    # balance jepa coeffs\n",
        "                    decay=0.99\n",
        "                    sim_coeff, std_coeff, cov_coeff = sim_coeff*decay + (1-decay)*repr_loss.detach(), std_coeff*decay + (1-decay)*std_loss.detach(), cov_coeff*decay + (1-decay)*cov_loss.detach()\n",
        "                    step=0.001\n",
        "                    if repr_loss.detach()>sim_coeff: self.jepa.sim_coeff=self.jepa.sim_coeff*(1+step)\n",
        "                    if std_loss.detach()>std_coeff: self.jepa.std_coeff=self.jepa.std_coeff*(1+step)\n",
        "                    if cov_loss.detach()>cov_coeff: self.jepa.cov_coeff=self.jepa.cov_coeff*(1+step)\n",
        "                    self.jepa.sim_coeff, self.jepa.std_coeff = self.jepa.sim_coeff/self.jepa.cov_coeff, self.jepa.std_coeff/self.jepa.cov_coeff\n",
        "                    self.jepa.cov_coeff = 1.\n",
        "\n",
        "                    # cost loss\n",
        "                    reward_ = self.tcost(sy_).squeeze(-1) # [batch_size]\n",
        "                    clossl = F.mse_loss(reward_, reward)\n",
        "                    try: st, r = next(trainiter)\n",
        "                    except StopIteration:\n",
        "                        st, r = next(trainiter)\n",
        "                        trainiter = iter(c_loader)\n",
        "                    st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "                    _, st = self.get(st, world_state=world_zero)\n",
        "                    # print(\"stt\",st.shape)\n",
        "                    stt = self.tcost(self.jepa.enc(st.unsqueeze(1))).squeeze(-1)\n",
        "                    clossb = F.mse_loss(stt, r)\n",
        "                    closs =  clossb + clossl\n",
        "\n",
        "                    # loss = loss + jloss + closs\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, closs\", repr_loss.item(), std_loss.item(), cov_loss.item(), closs.item())\n",
        "                    print(\"repr, std, cov, closslb\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), clossb.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    print(self.jepa.sim_coeff, self.jepa.std_coeff, self.jepa.cov_coeff)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    # loss=0\n",
        "                else:\n",
        "                    scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"clossl\": clossl.item(), \"clossb\": clossb.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "\n",
        "# tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "# others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "# optim = torch.optim.AdamW([{'params': others, 'lr': 1e-4},\n",
        "#     {'params': tcost_params, 'lr': 1e-2}], betas=(0.9, 0.95))\n",
        "\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 28488545\n",
        "# dreamer v3 https://arxiv.org/pdf/2301.04104 https://vitalab.github.io/article/2023/01/19/DreamerV3.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mY7BITKjSKC",
        "outputId": "cbad0ffc-e8e9-4a4d-bd3c-d6d9ddaf6e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2336301\n",
            "1278976\n",
            "399360\n",
            "1024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-76-e20d23bca149>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=3, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v, drop=0.2)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 2.4 # 100.0 # 25.0 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=50. # 1.0 # 1.0 # 25.0 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 30 # 20.0 # 1.0 # ν cov Covariance\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # e = d_model**-0.5\n",
        "        # self.h0 = torch.empty((self.jepa.pred.num_layers, 1, d_model), device=device).uniform_(-e, e) # [num_layers, batch, d_model]\n",
        "        # self.h0 = torch.normal(mean=0, std=e, size=(self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        # torch.nn.init.xavier_uniform_(self.h0) # xavier_uniform_, kaiming_normal_\n",
        "\n",
        "        # self.lx, self.lz = torch.empty(1,0,dim_a), torch.empty(1,0,dim_z)\n",
        "        self.lx, self.lz = None, None\n",
        "        state = torch.zeros((1, 3,64,64), device=device)\n",
        "        self.sx = self.jepa.enc(state)\n",
        "\n",
        "    # def forward(self, state, k=1): # live run in env # np (64, 64, 3)\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        self.update_h0(lstate, laction)\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "            sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "            # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.h0=lh0[k].unsqueeze(1) # [num_layers, 1, d_model]\n",
        "        # self.lx, self.lz = lx[:,k:], lz[:,k:] # [batch, T, dim_a], [batch, T, dim_z]\n",
        "        self.lx, self.lz = lx[k:], lz[k:] # [T, dim_a], [T, dim_z]\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        # self.eval()\n",
        "        with torch.no_grad():\n",
        "            # # self.mem, self.world_state = self.get(state, self.mem, self.world_state)\n",
        "            # _, self.world_state = self.get(state, world_state=self.world_state)\n",
        "            # sx = self.jepa.enc(self.world_state[None,None,...]) # [1, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "\n",
        "                # sx = self.jepa.enc(state)#.unsqueeze(0)\n",
        "                # print(torch.cat(lstate, dim=0).shape)\n",
        "                # lsx = self.jepa.enc(torch.stack(lstate, dim=0))#.unsqueeze(0)\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx-torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                # batch, seq_len, _ = lstate.shape\n",
        "                # seq_len, _ = lstate.shape\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    try: la = self.emb(self.la[:seq_len])\n",
        "                    except:\n",
        "                        print(\"err self.la\")\n",
        "                        # la = self.emb([0]*seq_len)\n",
        "                        la = self.emb(torch.zeros(seq_len, dtype=int, device=device))\n",
        "\n",
        "        # lz = nn.Parameter(torch.zeros((batch, seq_len, self.dim_z),device=device))\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        # optim_z = torch.optim.SGD([lz], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([lz], 1e0, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "\n",
        "        for i in range(20): # num epochs\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                # print(sxaz.shape, self.h0.shape)\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                # sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                loss = F.mse_loss(out_, out)\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            print(lz.data)\n",
        "            with torch.no_grad(): lz.clamp_(min=-1, max=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1]\n",
        "        self.la = la[k:]\n",
        "        return h0\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim_x = torch.optim.SGD([x], lr=1e-1)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_normal_(z)\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e0, maximize=True) # 3e3\n",
        "        optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        if self.lx is not None:\n",
        "            with torch.no_grad():\n",
        "                # x[:,:self.lx.shape[1]], z[:,:self.lz.shape[1]] = self.lx[:,:T], self.lz[:,:T]\n",
        "                x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].repeat(batch,1,1), self.lz[:T].repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        sx = sx.detach()\n",
        "        h0 = h0.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            # print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            # print(\"loss\",loss)\n",
        "            loss.sum().backward()\n",
        "            optim_x.step(); optim_z.step()\n",
        "            optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z.clamp_(min=-1, max=1)\n",
        "            print(i, \"loss\", loss.squeeze().data)\n",
        "            # print(x.shape,torch.argmax(-dist,dim=-1).shape,z.shape,loss.shape) # [16, 6, 3], [16, 6], [16, 6, 1], [16, 1]\n",
        "            # print(i, torch.cat([x,torch.argmax(-dist,dim=-1),z],dim=-1).squeeze().data)\n",
        "            print(i, \"x act z\", torch.cat([x[0],torch.argmax(-dist,dim=-1)[0].unsqueeze(-1),z[0]],dim=-1).squeeze().data)\n",
        "            # print(i,x[0].squeeze()[0].data, z[0].squeeze().data, loss.squeeze().item())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, t, dim_a], [batch, t, dim_z]\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        x = nn.Parameter(torch.empty((T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        optim_x = torch.optim.SGD([x], lr=1e3) # 1e-1,1e-0,1e4 ; 1e2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        with torch.no_grad(): x[:self.lx.shape[0]] = self.lx[:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        # print(\"search x\",x.squeeze().data)\n",
        "        for i in range(2): # 5\n",
        "            dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0) # [T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_.unsqueeze(0), z.unsqueeze(0), h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i, \"search x loss\", x.squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        dist = torch.norm(self.emb.weight.data.unsqueeze(0) - x.unsqueeze(-2), dim=-1) # [1,act_space,emb_dim], [T,1,emb_dim] -> [T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        return lact, lh0, x.data, z # [T], [T, num_layers, batch, d_model], [T, dim_a], [T, dim_z]\n",
        "\n",
        "\n",
        "    def search_optimxz(self, sx, T=6, h0=None):\n",
        "        self.eval()\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch = 4 # 16\n",
        "        lr = 1e1 # adamw 1e-1, 3e-1 ; sgd\n",
        "        ratio = 4\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "        z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        # torch.nn.init.xavier_uniform_(z) # xavier_normal_, xavier_uniform_\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        # optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.SGD([z], lr=1e1, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "        optim_z = torch.optim.AdamW([z], 1e2, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x[:,:self.lx.shape[0]], z[:,:self.lz.shape[0]] = self.lx[:T].unsqueeze(0).repeat(batch,1,1), self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_az]\n",
        "\n",
        "        # print(\"search\",x[0].data, z[0].squeeze())\n",
        "        print(\"search\", z[0].squeeze())\n",
        "        sx, h0 = sx.detach(), h0.detach()\n",
        "        for i in range(10): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, lsx, lh0,c = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            # loss, sx_ = self.rnn_pred(sx, x, z) # use raw x as act emb\n",
        "            loss.sum().backward()\n",
        "            # optim_x.step(); optim_z.step()\n",
        "            # optim_x.zero_grad(); optim_z.zero_grad()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            print(i, \"search loss\", loss.squeeze().data)\n",
        "            # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "            print(i, \"search z\", z[0].squeeze().data)\n",
        "            # print(torch.argmin(dist,dim=-1).int())\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        print(\"c\",torch.stack(c)[:,idx])\n",
        "        return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "\n",
        "    def argm_s(self, sx, x, h0): # [1, d_model], [batch_, T, dim_a], [num_layers, 1, d_model] # batch argm z for search\n",
        "        batch_, T, _ = x.shape\n",
        "        batch = 16 # 16\n",
        "        # z = nn.Parameter(torch.zeros((batch, T, self.dim_z),device=device))\n",
        "        z = nn.Parameter(torch.zeros((batch*batch_, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        optim_z = torch.optim.SGD([z], lr=1e4, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # with torch.no_grad(): z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch,1,1) # [batch, seq_len, dim_z]\n",
        "        with torch.no_grad(): z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch*batch_,1,1) # [batch, seq_len, dim_z]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, T, dim_a]\n",
        "        # print(\"argm\", z[0].squeeze())\n",
        "        for i in range(2): # 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm z loss\", z[0].squeeze().data, loss[0].squeeze().data)\n",
        "        # idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "        idx = torch.argmin(loss.sum(-1).unflatten(0, (batch,batch_)), dim=0) # loss [batch*batch_, T]\n",
        "        return torch.index_select(z, 0, idx) # [batch_, T,dim_z]\n",
        "\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # cost += tcost + icost\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, dim_a = la.shape\n",
        "        cost = 0\n",
        "        sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "        lsx=sx.unsqueeze(1)\n",
        "        h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        # print(lsx.shape, la.shape, lz.shape)\n",
        "        c=[]\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            # print(sx.shape, a.shape, z.shape)\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "                syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                tcost = -self.tcost(syh0)\n",
        "            c.append(tcost)\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "            icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "            # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "            cost += (tcost + icost)*gamma**t\n",
        "        return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                # with torch.amp.GradScaler('cuda'):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "                    z = self.jepa.argm(sy_, a, sy)\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "\n",
        "                    # imshow(state[0].cpu())\n",
        "                    # print(\"norm\", torch.norm(sy[0]-sy_[0], dim=-1))\n",
        "                    # # if torch.norm(sy[0]-sy_[0], dim=-1) > 1:\n",
        "                    # print(i, reward[0])\n",
        "                    # print(sy)\n",
        "                    # print(sy_)\n",
        "                    # print(sy[0]-sy_[0])\n",
        "\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    # jloss = repr_loss + std_loss + cov_loss\n",
        "\n",
        "\n",
        "                    # cost loss\n",
        "                    # syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = 100*clossl\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "\n",
        "\n",
        "\n",
        "    def train_jepa(self, dataloader, c_loader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        global sim_coeff, std_coeff, cov_coeff\n",
        "        trainiter = iter(c_loader)\n",
        "        for batch, Sar in enumerate(dataloader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "            # _mem = Stm()\n",
        "            lst=list(range(0,len(Sar[0]),bptt))[1:]+[len(Sar[0])] # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            loss=0\n",
        "            # world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # world_zero = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "            # sy_ = self.jepa.enc(world_state.unsqueeze(1)) # [batch_size, 1, d_model, d_model]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "            sy_ = self.jepa.enc(state) # [batc h_size, d_model]\n",
        "            # sx=sy_\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "                    # _mem, world_state_ = self.get(state, _mem, world_state)\n",
        "                    # _, world_state_ = self.get(state, world_state=world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    a = self.emb(action)\n",
        "\n",
        "                    # z = self.jepa.argm(sy_, a, sy)\n",
        "                    z = self.argm(sy, sy_, h0, a, reward)\n",
        "                    with torch.no_grad(): z.mul_(torch.rand_like(z)).mul_((torch.rand_like(z)>0.5).bool()) # dropout without scailing\n",
        "\n",
        "                    syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "                    out, h0 = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    out = out[:, -1, :]\n",
        "                    sy_ = sy_ + out\n",
        "\n",
        "                    # repr_loss = F.mse_loss(sy.detach(), sy_) # s(sy, sy~) # invariance loss\n",
        "                    repr_loss = F.mse_loss(sy, sy_) # s(sy, sy~) # invariance loss\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "\n",
        "                    # cost loss\n",
        "                    syh0 = torch.cat([sy.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    # syh0 = torch.cat([sy.flatten(1),F.dropout(h0, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "                    clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "                    closs = self.closs_coeff * clossl\n",
        "\n",
        "                    # print(h0.requires_grad)\n",
        "                    # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "                    # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "                    # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # torch.norm(sy-sx, dim=-1)\n",
        "                    # sx=sy\n",
        "\n",
        "                    loss = loss + jloss + closs # for no retain_graph\n",
        "                    # loss = jloss + closs\n",
        "\n",
        "                if i+1 in lst:\n",
        "                    # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                    norm = torch.norm(sy, dim=-1)[0].item()\n",
        "                    z_norm = torch.norm(z)\n",
        "                    # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "                    # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                    print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                    # loss.backward()\n",
        "                    # optim.step()\n",
        "                    scaler.scale(loss).backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # world_state = world_state_.detach()\n",
        "                    sy_ = sy_.detach()\n",
        "                    h0 = h0.detach()\n",
        "                    loss=0 # no retain_graph\n",
        "                # else:\n",
        "                #     scaler.scale(loss).backward(retain_graph=True)\n",
        "\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                except: pass\n",
        "\n",
        "                # lh0 = torch.zeros((rwd.shape[1],)+h0.shape, device=device)\n",
        "                # lz = torch.zeros((lsy.shape[0], lsy.shape[1], self.dim_z), device=device)\n",
        "                    # for name, param in agent.tcost.named_parameters():\n",
        "                    #     print(\"param.data\",param.max().item(),param.min().item())\n",
        "                    #     print(\"agent.tcost\",param.data)\n",
        "\n",
        "# # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "# ema_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.999))\n",
        "# for epoch in range(300):\n",
        "#       for input, target in loader:\n",
        "#           optimizer.zero_grad()\n",
        "#           loss_fn(model(input), target).backward()\n",
        "#           optimizer.step()\n",
        "#           ema_model.update_parameters(model)\n",
        "# # Update bn statistics for the ema_model at the end\n",
        "# torch.optim.swa_utils.update_bn(loader, ema_model)\n",
        "# # Use ema_model to make predictions on test data\n",
        "# preds = ema_model(test_input)\n",
        "\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd): # best case z for train\n",
        "        # self.tcost.eval() # disable tcost dropout\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(2): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lsy_, lh0 = self.rnn_it(sy_, la, lz, h0_)\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            clossl = self.tcost.loss(syh0, rwd.flatten(), reduction='none')\n",
        "            # z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "\n",
        "print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb0b4b7-e261-48ff-aac0-65f53ba04747",
        "cellView": "form",
        "id": "B_EPhszEbbwD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-4f4b4824202d>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "# @title agent gru batch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torchvision.transforms as transforms\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, d_model=256, dim_a=3, dim_z=8, dim_v=512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dim_a, self.dim_z, self.dim_v = dim_a, dim_z, dim_v\n",
        "        # self.sense = Conv(d_model)\n",
        "        # self.sense = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "        # self.mem = Mem()\n",
        "        # self.world_state = torch.zeros((d_model, d_model), device=device) # Sum i] vi kiT\n",
        "        self.jepa = JEPA(d_model**2, d_model, dim_a, dim_z, dim_v)\n",
        "        # self.icost = ICost(d_model) # intrinsic cost\n",
        "        self.tcost = TCost((1+self.jepa.pred.num_layers)*d_model)\n",
        "        # self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        # self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.emb = torch.nn.Embedding(15, dim_a, max_norm=1.) # env.action_space # 15\n",
        "        self.jepa.sim_coeff=10. # 10 # λ repr Invariance reconstruction, ->0 slowly\n",
        "        self.jepa.std_coeff=3. # 50 # µ std Variance\n",
        "        self.jepa.cov_coeff=1. # 1 # ν cov Covariance\n",
        "        self.closs_coeff=10. # 10\n",
        "        # self.zloss_coeff=0. # 10 1\n",
        "        self.h0 = torch.zeros((self.jepa.pred.num_layers, 1, d_model), device=device) # [num_layers, batch, d_model]\n",
        "        self.lx, self.lz = torch.empty((0,dim_a),device=device), torch.empty((0,dim_z),device=device) # [T,dim_az]\n",
        "        self.sx = self.jepa.enc(torch.zeros((1, 3,64,64)))\n",
        "        self.la = torch.empty(0,device=device)\n",
        "\n",
        "    def forward(self, lstate, laction=None, k=1): # live run in env # np (64, 64, 3)\n",
        "        self.eval()\n",
        "        if len(self.la)>1 or laction!=None:\n",
        "            self.update_h0(lstate, laction)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                self.sx = self.jepa.enc(lstate[-1])#.unsqueeze(0)\n",
        "                # self.icost.update(sx)\n",
        "        lact, lh0, lx, lz = self.search(self.sx, T=6, h0=self.h0) # [T], [T, num_layers, d_model], [T, dim_a], [T, dim_z]\n",
        "        act = lact.cpu()[:k].tolist()\n",
        "        self.la, self.lx, self.lz = lact, lx, lz\n",
        "        return act\n",
        "\n",
        "    def update_h0(self, lstate, laction=None): # live run in env # np (64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            with torch.cuda.amp.autocast():\n",
        "                lsx = self.jepa.enc(torch.cat(lstate, dim=0))\n",
        "                # self.icost.update(sx)\n",
        "                out_ = lsx - torch.cat([self.sx, lsx[:-1]], dim=0)\n",
        "                seq_len = len(lstate)\n",
        "                if laction!=None:\n",
        "                    self.la = torch.cat([torch.tensor(laction, device=device), self.la[len(laction):]], dim=-1)\n",
        "                la = self.emb(self.la[:seq_len])\n",
        "\n",
        "        lz = nn.Parameter(torch.zeros((seq_len, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5) # torch.nn.init.xavier_normal_(lz) # xavier_normal_ xavier_uniform_\n",
        "        optim_z = torch.optim.SGD([lz], lr=1e1) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e0 ; 3e-2 1e-1\n",
        "        lsx, la = lsx.detach(), la.detach() # [T, d_model], [T, dim_a]\n",
        "        # print(\"update_h0 lz\", lz.data)\n",
        "        self.jepa.pred.train()\n",
        "        for i in range(1): # 1?\n",
        "            sxaz = torch.cat([lsx, la, lz], dim=-1).unsqueeze(0) # [1, seq_len, d_model+dim_a+dim_z]\n",
        "            with torch.cuda.amp.autocast(): # with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, self.h0.detach()) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                loss = F.mse_loss(out_, out.squeeze(0))\n",
        "            loss.backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            # print(\"update_h0 loss, lz\",i,loss.item(), lz.data)\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        self.h0 = h0\n",
        "        self.sx = lsx[-1].unsqueeze(0)\n",
        "        # print(\"update_h0\", self.lx.data)\n",
        "        self.la, self.lx, self.lz = self.la[seq_len:], self.lx[seq_len:], self.lz[seq_len:] # [T, dim_a], [T, dim_z]\n",
        "        return h0\n",
        "\n",
        "    def argm_s(self, sx, x, h0): # [1, d_model], [batch_, T, dim_a], [num_layers, 1, d_model] # batch argm z for search\n",
        "        batch_, T, _ = x.shape\n",
        "        batch = 16 # 16\n",
        "        z = nn.Parameter(torch.zeros((batch*batch_, T, self.dim_z),device=device))\n",
        "        torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "        optim_z = torch.optim.SGD([z], lr=1e4, maximize=True) # 3e3\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "        with torch.no_grad(): z[:,:self.lz.shape[0]] = self.lz[:T].unsqueeze(0).repeat(batch*batch_,1,1) # [batch*batch_, seq_len, dim_z]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        x = x.detach().repeat(batch,1,1) # [batch, T, dim_a]\n",
        "        # print(\"argm\", z[0].squeeze())\n",
        "        for i in range(2): # 5\n",
        "            loss, lh0 = self.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_z.step()\n",
        "            optim_z.zero_grad()\n",
        "            with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "            # print(i, \"argm z loss\", z[0].squeeze().data, loss[0].squeeze().data)\n",
        "        idx = torch.argmin(loss.sum(-1).unflatten(0, (batch,batch_)), dim=0) # loss [batch*batch_, T] -> [batch_]\n",
        "        return torch.index_select(z, 0, idx) # [batch_, T,dim_z]\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch = 16\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "        optim_x = torch.optim.SGD([x], lr=1e3) # 1e-1,1e-0,1e4 ; 1e2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        with torch.no_grad(): x[:,:self.lx.shape[0]] = self.lx.repeat(batch,1,1)[:,:T] # [seq_len, dim_az]\n",
        "        sx, h0 = sx.detach(), h0.detach() # [1, d_model], [num_layers, 1, d_model]\n",
        "        # print(\"search x\",x.squeeze().data)\n",
        "        for i in range(2): # 5\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data # [batch, T, dim_a]\n",
        "            z = self.argm_s(sx, x_,h0) # [batch,T, dim_z]\n",
        "            loss, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i, \"search x loss\", x.squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [T]\n",
        "        idx = torch.argmin(loss.sum(-1)) # loss [batch, T]\n",
        "        return lact[idx], lh0[:,:,idx], x.data[idx], z[idx] # [batch,T], [T, num_layers, batch, d_model], [batch,T, dim_a], [batch,T, dim_z]\n",
        "\n",
        "\n",
        "    def rnn_pred(self, sx, la, lz, h0, gamma=0.9): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        lsx, lh0 = self.rnn_it(sx, la, lz, h0)\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        syh0 = torch.cat([lsx, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,T,d_model], [T,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "        tcost = -self.tcost(syh0).unflatten(0, (batch, seq_len)).squeeze(-1)\n",
        "        c = (tcost + icost)*gamma**torch.arange(seq_len, device=device)\n",
        "        # if len(c.shape) == 1: print(\"rnn_pred c\", [f'{cc.item():g}' for cc in c.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        if len(tcost.shape) == 1: print(\"rnn_pred tcost\", [f'{cc.item():g}' for cc in tcost.squeeze(0)]) # print(f'{cc:6f}')\n",
        "        return c, lh0\n",
        "\n",
        "    def rnn_it(self, sx, la, lz, h0): # 0.95 [1, d_model], [batch, T, dim_a/z], [num_layers,1, d_model]\n",
        "        self.jepa.pred.train()\n",
        "        batch, seq_len, _ = la.shape\n",
        "        batch_ = batch//sx.shape[0]\n",
        "        sx, h0 = sx.repeat(batch_, 1), h0.repeat(1, batch_, 1)\n",
        "        lsx = torch.empty((batch, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        for t in range(seq_len):\n",
        "            a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "            sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1) # [batch, d_model+dim_a/z]\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            # sx = sx + out.squeeze(1) # [batch,seq_len,d_model] # h0 = h0 +\n",
        "            sx = out.squeeze(1) # [batch,1,d_model]\n",
        "            lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "            lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        return lsx, lh0\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd): # best case z for train\n",
        "        # self.tcost.eval() # disable tcost dropout\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        batch = 64 # 16\n",
        "        lsy, la, rwd = lsy.repeat(batch,1,1), la.repeat(batch,1,1), rwd.repeat(batch,1) # [batch*batch_size, bptt, d_model], [batch*batch_size, d_model, dim_a], [batch*batch_size, bptt]\n",
        "        lz = nn.Parameter(torch.zeros((batch*batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lsy_, lh0 = self.rnn_it(sy_, la, lz, h0_)\n",
        "            # repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            repr_loss = ((lsy-lsy_)**2).unflatten(0, (batch,batch_size)).flatten(1).mean(-1)\n",
        "            syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch*batch_size,bptt,d_model], [bptt,num_layers,batch*batch_size,d_model] -> [batch*batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "            clossl = self.tcost.loss(syh0, rwd.flatten(), reduction='none').unflatten(0, (batch,batch_size*bptt)).mean(-1) # [batch*batch_size*bptt] -> [batch]\n",
        "            # z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl# + self.zloss_coeff * z_loss\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        idx = torch.argmin(cost)\n",
        "        return lz.unflatten(0, (batch,batch_size))[idx].squeeze(0).detach()\n",
        "\n",
        "    # def get(self, state, _mem=None, world_state=None): # update world_state and mem from state\n",
        "    #     # if _mem==None: _mem = self.mem\n",
        "    #     if world_state==None: world_state = self.world_state\n",
        "    #     current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "    #     Q = self.q(current) # [batch_size, d_model]\n",
        "    #     # mem = _mem(Q) # _mem(current)\n",
        "    #     obs = current# + mem # [batch_size, d_model]\n",
        "    #     K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "    #     # self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "    #     # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "    #     K = F.normalize(K, dim=-1)\n",
        "    #     if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    #     V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "    #     world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "    #     # _mem.add(K, V) # [batch_size, 1, d_model] or [1, d_model]\n",
        "    #     return _mem, world_state#, cost\n",
        "\n",
        "    def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "        self.train()\n",
        "        for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "            h0 = torch.zeros((self.jepa.pred.num_layers, batch_size, self.d_model), device=device) # [num_layers, batch, d_model]\n",
        "            sy_ = self.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device)).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "            state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "            for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    lsy = self.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "                    la = self.emb(act) # [batch_size, bptt, dim_a]\n",
        "                    lz = self.argm(lsy, sy_.squeeze(1), h0, la, rwd) # [batch_size, bptt, d_model],\n",
        "                    # with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0.5)).mul_((torch.rand_like(lz)>0.1).bool()) # dropout without scaling\n",
        "                    with torch.no_grad(): lz.mul_(torch.rand_like(lz).uniform_(0)).mul_((torch.rand_like(lz)>0.5).bool()) # dropout without scaling\n",
        "                    lsy_, lh0 = self.rnn_it(sy_.squeeze(1), la, lz, h0)\n",
        "                    repr_loss = F.mse_loss(lsy, lsy_) # [batch_size, bptt, d_model]\n",
        "                    std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "                    jloss = self.jepa.sim_coeff * repr_loss + self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "                    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model] # not lsy_, else unstable\n",
        "                    clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                    closs = self.closs_coeff * clossl\n",
        "                    loss = jloss + closs\n",
        "\n",
        "                    # pred = self.tcost(syh0).squeeze(-1).unflatten(0, rwd.shape) # [batch_size, bptt]\n",
        "                    # print(\"pred\",pred[0])\n",
        "                    # print(\"rwd\",rwd[0])\n",
        "                    # mask = torch.where(abs(rwd- pred)>0.5,1,0).bool()\n",
        "                    # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "                    # reprloss = ((lsy-lsy_)**2).mean(-1) # [batch_size, bptt]\n",
        "                    # print(\"reprloss\",reprloss[0])\n",
        "                    # mask = (reprloss>0.05)[0]\n",
        "                    # # imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "                    # try: imshow(torchvision.utils.make_grid(st[0][mask].cpu(), nrow=10))\n",
        "                    # except ZeroDivisionError: pass\n",
        "\n",
        "                # torch.norm(lsy-torch.cat([sy_,lsy[:-1]], dim=1), dim=-1) # -(z*torch.log(z)).sum(-1) # Shannon entropy archive.is/CaYrq\n",
        "                # prob = F.softmax(output, dim=-1)\n",
        "                # entropy = -torch.sum(prob * torch.log(prob + 1e-5), dim=-1)\n",
        "\n",
        "                # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "                norm = torch.norm(lsy[0][0], dim=-1).item()\n",
        "                z_norm = torch.norm(lz[0][-1], dim=-1)\n",
        "                # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "                # print(\"clossl, wrong\", clossl.item(), mask.sum())\n",
        "                # print(\"repr, std, cov, clossl, wrong\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "                print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "                scaler.scale(loss).backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad()\n",
        "                sy_, h0 = sy_.detach(), h0.detach()\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "                try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item(), \"z_norm\": z_norm.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "agent = Agent(d_model=256).to(device)\n",
        "# agent = torch.compile(Agent(d_model=256), mode='max-autotune').to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(agent.parameters(), 1e-3, (0.9, 0.999)) # lr = 1e-4 #3e-4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4\n",
        "# !pip show torch triton\n",
        "# # !pip install --upgrade torch\n",
        "# !pip install --upgrade triton\n",
        "\n",
        "# print(sum(p.numel() for p in agent.parameters() if p.requires_grad)) # 1lyr:2727982, 2lyr:4401710\n",
        "# print(sum(p.numel() for p in agent.jepa.enc.parameters() if p.requires_grad)) # 1278976\n",
        "# print(sum(p.numel() for p in agent.jepa.pred.parameters() if p.requires_grad)) # 1lyr:397824, 2lyr:792576\n",
        "# print(sum(p.numel() for p in agent.tcost.parameters() if p.requires_grad)) # 197633\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# rnn = nn.GRU(4, 5, 2) # [in_dim, out_dim, num_layers]\n",
        "rnn = nn.GRU(4, 5, 2, batch_first=True) # [in_dim, out_dim, num_layers]\n",
        "input = torch.randn(1, 3, 4) # [batch_size, seq_len, in_dim]\n",
        "h0 = torch.randn(2, 1, 5) # [num_layers, batch_size, out_dim]\n",
        "output, hn = rnn(input, h0) # [batch_size, seq_len, out_dim], [num_layers, batch_size, out_dim]\n",
        "print(output)\n",
        "print(hn)\n",
        "# print(hn[-1,:,:])\n",
        "print(output[:,-1,:])\n",
        "print(hn[-1,:,:])\n"
      ],
      "metadata": {
        "id": "3AAXyi7QJRRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cg0BI2TwY9-p"
      },
      "outputs": [],
      "source": [
        "# @title z.grad.data = -z.grad.data\n",
        "\n",
        "# self.eval()\n",
        "batch = 4 # 16\n",
        "x = nn.Parameter(torch.empty((batch, T, agent.dim_a),device=device))\n",
        "torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "# optim_ = torch.optim.SGD([x,z], lr=1e1) # 3e3\n",
        "optim_ = torch.optim.AdamW([x,z], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "print(\"search z\", z[0].squeeze())\n",
        "print(\"search x\", x[0].squeeze())\n",
        "sx, h0 = sx.detach(), h0.detach()\n",
        "for i in range(10): # num epochs\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    z.grad.data = -z.grad.data\n",
        "    optim_.step()\n",
        "    optim_.zero_grad()\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "    print(i, \"search loss\", loss.squeeze().data)\n",
        "    print(i, \"search z\", z[0].squeeze().data)\n",
        "    print(i, \"search x\", x[0].squeeze().data)\n",
        "dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "print(\"c\",torch.stack(c)[:,idx])\n",
        "# return lact[idx], lh0[:,:,idx,:], x[idx], z[idx] # [batch, T], [T, num_layers, batch, d_model], [batch, T, dim_a], [batch, T, dim_z]\n",
        "# print(lact[idx], lh0[:,:,idx,:], x[idx], z[idx])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VMebkQ1mJtD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title argm agent.rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def argm(sx, x,h0, lr=3e3): # 3e3\n",
        "    # agent.eval()\n",
        "    # batch_size, T, _ = sx.shape\n",
        "    batch = 16 # 16\n",
        "    z = nn.Parameter(torch.zeros((batch, T, agent.dim_z),device=device))\n",
        "    torch.nn.init.normal_(z, mean=0., std=1./z.shape[-1]**0.5) # norm ~1\n",
        "    optim_z = torch.optim.SGD([z], lr=1e3, maximize=True) # 3e3\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-2, (0.9, 0.999), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.AdamW([z], 1e-0, (0.9, 0.95), maximize=True) # ? 1e0 ; 3e-2 1e-1\n",
        "    # optim_z = torch.optim.LBFGS([z], max_iter=5, lr=1)\n",
        "\n",
        "    # print(\"argm\", z[0].squeeze())\n",
        "    sx, h0 = sx.detach(), h0.detach()\n",
        "    x = x.detach().repeat(batch,1,1)\n",
        "    for i in range(5): # num epochs\n",
        "        # print(sx.shape, x.shape, z.shape, h0.shape) # [1, 256], [4, 1, 3], [4, 1, 8], [1, 1, 256]\n",
        "        loss, lsx, lh0,c = agent.rnn_pred(sx, x, z, h0) # snap x to act emb\n",
        "        loss.sum().backward()\n",
        "        optim_z.step()\n",
        "        optim_z.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1) # z.clamp_(min=-1, max=1)\n",
        "        # print(i, \"argm loss\", loss.squeeze().data)\n",
        "        # print(i, \"argm z\", z[0].squeeze().data)\n",
        "    idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "    return z[idx].unsqueeze(0)\n",
        "\n",
        "\n",
        "T=1\n",
        "xx = torch.empty((1, T, agent.dim_a))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "# print(x.shape)\n",
        "optim_x = torch.optim.SGD([x], lr=1e1) # 1e-1,1e-0,1e4 ; 1e2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# optim_x = torch.optim.AdamW([x], 1e1, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, 1, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "\n",
        "state = torch.zeros((1, 3,64,64))\n",
        "with torch.no_grad():\n",
        "    sx = agent.jepa.enc(state).detach()\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "print(time.time()-start)\n",
        "\n",
        "print(\"search\",x.squeeze().data)\n",
        "for i in range(20): # 5\n",
        "    dist = torch.norm(agent.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    x_ = ste_argmax(-dist) @ agent.emb.weight.data\n",
        "    z = argm(sx, x_,h0)\n",
        "    # print(sx.shape, x_.shape, z.shape, h0.shape) # [1, 256], [1, 1, 3], [1, 1, 8], [1, 1, 256]\n",
        "    loss, lsx, lh0,c = agent.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "    print(i, \"search loss\", x.squeeze().data, loss.item())\n",
        "    # print(i, \"search x z\", x[0].data, z[0].squeeze().data)\n",
        "\n",
        "# z sgd 1e3\n",
        "# 9 search loss tensor([0.0142, 0.0142, 0.0142, 0.0142])\n",
        "# 9 search z tensor([-0.3381, -0.7005, -0.5877, -0.0664, -0.1439,  0.0283,  0.0541, -0.1439])\n",
        "\n",
        "# x sgd 1e2\n",
        "# 1 tensor([0.3561, 0.3059, 0.8830]) 0.014148875139653683\n",
        "# 9 tensor([0.3560, 0.3064, 0.8828]) 2.328815611463142e-07\n",
        "\n",
        "# 1e0\n",
        "# 19 tensor([-0.5768,  0.5778,  0.5774]) 6.543130552927323e-07\n",
        "# 19 tensor([0.3570, 0.6689, 0.6521]) 2.474381801675918e-07\n",
        "# 19 tensor([0.5783, 0.5765, 0.5772]) 1.519319567933053e-07\n",
        "# 19 tensor([0.3427, 0.6795, 0.6487]) 4.220427456402831e-07\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KZeny7pRU6bG"
      },
      "outputs": [],
      "source": [
        "# @title test search, argm\n",
        "# # def search(self, sx, T=None, bptt=None):\n",
        "T=20\n",
        "bptt=None\n",
        "if T==None: T = 256\n",
        "if bptt==None: bptt = min(T,32)\n",
        "d_model=agent.d_model\n",
        "# sx=torch.randn((1, d_model), device=device)\n",
        "# batch=sx.size(dim=0)\n",
        "batch=32\n",
        "# scale = torch.sqrt(torch.tensor((d_model,), device=device))\n",
        "\n",
        "# x_ = torch.rand((batch, T, 3),device=device)*2 -1\n",
        "# *self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "# x_ = torch.zeros((batch, T, 3),device=device) # dont, deterministic, stuck\n",
        "x=nn.Parameter(x_.clone())\n",
        "# optim = torch.optim.SGD([x], lr=1e3, momentum=0.9)\n",
        "optim = torch.optim.SGD([x], lr=1e2)\n",
        "# optim = torch.optim.SGD([x], lr=1e5)\n",
        "# optim = torch.optim.SGD([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=3e2)\n",
        "# optim = torch.optim.AdamW([x], lr=1e5)\n",
        "\n",
        "# xx = torch.split(x, bptt, dim=1)\n",
        "# for _ in range(10): # num epochs\n",
        "#     sx_ = sx.detach()\n",
        "#     # print(sx_[0][:10])\n",
        "#     for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "#         la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "#         print(lact)\n",
        "#         loss, sx_ = agent.rnn_pred(sx_, la)\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         optim.zero_grad()\n",
        "#         sx_ = sx_.detach()\n",
        "#         print(\"search\",loss.item())\n",
        "\n",
        "\n",
        "# argm\n",
        "# sx = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# sy = torch.rand((batch, d_model),device=device)*2 -1\n",
        "# a = torch.rand((batch, agent.dim_a),device=device)*2 -1\n",
        "# z_ = torch.rand((batch, agent.dim_z),device=device)*2 -1\n",
        "# # z_ = torch.rand((batch, agent.dim_z),device=device)\n",
        "# # z_ = z_/scale\n",
        "\n",
        "z=nn.Parameter(z_.clone()) # argm 0.38188403844833374 3.86767578125\n",
        "# torch.nn.init.zeros_(z)\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# print(z)\n",
        "# optim = torch.optim.SGD([z], lr=1e2, momentum=0.9)\n",
        "# optim = torch.optim.SGD([z], lr=1e4)\n",
        "optim = torch.optim.SGD([z], lr=3e3)\n",
        "# optim = torch.optim.SGD([z], lr=3e1)\n",
        "# optim = torch.optim.AdamW([z], lr=3e-1)\n",
        "lossfn = torch.nn.MSELoss()\n",
        "num_steps = 100\n",
        "agent.jepa.eval()\n",
        "import time\n",
        "start=time.time()\n",
        "for i in range(num_steps):\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # loss, sx = agent.rnn_pred(sx, la)s\n",
        "    sy_ = agent.jepa.pred(sxaz)\n",
        "    # print(\"y_, y\",y_.shape, y.shape)\n",
        "    loss = lossfn(sy_, sy)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(\"argm\",loss.item(), z[0].item())\n",
        "# print(time.time()-start)\n",
        "print(z.squeeze())\n",
        "\n",
        "want z around [-1,1], large lr, few steps, punish large z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6):\n",
        "        batch=sx.size(dim=0)\n",
        "        x = nn.Parameter(torch.empty((batch, T, self.dim_a),device=device))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "        # optim = torch.optim.SGD([x], lr=1e4) #, maximize=True)\n",
        "        optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.95))\n",
        "        min, max = self.emb.weight.data.min(dim=0).values, self.emb.weight.data.max(dim=0).values\n",
        "        print(x)\n",
        "        sx = sx.detach()\n",
        "        for i in range(20): # num epochs\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            loss, sx_ = self.rnn_pred(sx, x_)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                # x.clamp_(min=-1, max=1)\n",
        "                x.clamp_(min=min, max=max)\n",
        "            print(i,x)\n",
        "        # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "        dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "        lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "        print(\"search\",loss.item())\n",
        "        return lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "    # def argm(self, sx, a, lr=3e3): # 3e3\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z = nn.Parameter(torch.zeros((batch,self.dim_z),device=device))\n",
        "    #     optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    #     # optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    #     sx, a = sx.detach(), a.detach()\n",
        "    #     for i in range(5): # 10\n",
        "    #         sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #         with torch.amp.autocast('cuda'):\n",
        "    #             # sx_ = self.jepa.pred(sxaz)\n",
        "    #             sx_ = sx + self.jepa.pred(sxaz)\n",
        "    #             cost = -self.tcost(sx_)\n",
        "\n",
        "    #         cost.backward()\n",
        "    #         optim.step()\n",
        "    #         # scaler.scale(cost).backward()\n",
        "    #         # scaler.step(optim)\n",
        "    #         # scaler.update()\n",
        "    #         optim.zero_grad()\n",
        "    #         with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "    #         print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    #     return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def argm(self, sx, lr=3e3): # 3e3\n",
        "        # batch=sx.size(dim=0)\n",
        "        batch_size, T, _ = sx.shape\n",
        "        batch = 16\n",
        "        # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "        z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "        torch.nn.init.xavier_uniform_(z)\n",
        "        # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "        optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "        sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "        # sx = sx.detach()\n",
        "        for i in range(20): # 10\n",
        "            # print(sx.shape,z.shape)\n",
        "            sxz = torch.cat([sx, z], dim=-1)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                cost = model(sxz)\n",
        "            cost.sum().backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "            # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "            # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        # return z.detach()\n",
        "        # print(\"argm z\",z.squeeze().data)\n",
        "        # print(\"cost\",cost.squeeze())\n",
        "        idx = torch.argmax(loss)\n",
        "        # return z[idx].detach().unsqueeze(0)\n",
        "        return z[:,idx].detach()\n",
        "\n",
        "\n",
        "    def search(self, sx, T=6, h0=None):\n",
        "        batch=1\n",
        "        T=1\n",
        "        x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "        torch.nn.init.xavier_uniform_(x)\n",
        "\n",
        "        lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "        # ratio = 6e0\n",
        "        lr = 1e-1 # adamw 1e-1\n",
        "        ratio = 4\n",
        "        # optim_x = torch.optim.SGD([x], lr=lr)\n",
        "        # optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "        optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze())\n",
        "        # print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "        for i in range(50):\n",
        "            dist = torch.norm(self.emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "            print(\"act\",torch.argmax(-dist,dim=-1))\n",
        "            x_ = ste_argmax(-dist) @ self.emb.weight.data\n",
        "            z = argm(x)\n",
        "            # loss, sx_ = self.rnn_pred(sx, x_, z) # snap x to act emb\n",
        "            loss, lsx, lh0 = self.rnn_pred(sx, x_, z, h0) # snap x to act emb\n",
        "            loss.sum().backward()\n",
        "            optim_x.step()\n",
        "            optim_x.zero_grad()\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "            # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "            # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "            # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "            with torch.no_grad():\n",
        "                # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "                x.clamp_(min=-1, max=1)\n",
        "            # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "        idx = torch.argmax(loss)\n",
        "        print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "    def argm(self, lsy, sy, h0, la, rwd):\n",
        "        self.tcost.eval()\n",
        "        batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "        lz = nn.Parameter(torch.zeros((batch_size, bptt, self.dim_z), device=device))\n",
        "        torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "        # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "        # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "        optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "        lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "        for i in range(3): # 10\n",
        "            sy_, h0_ = sy.detach(), h0.detach()\n",
        "            lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "            lsy_ = torch.empty((batch_size, 0, self.d_model), device=device) # [batch_size, T, d_model]\n",
        "            with torch.cuda.amp.autocast():\n",
        "                for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                    syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                    out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                    sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                    lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                    lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "                repr_loss = F.mse_loss(lsy, lsy_)\n",
        "                syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "                clossl = self.tcost.loss(syh0, rwd.flatten())\n",
        "                z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "                # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "                cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "            cost.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "            # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "            # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "        self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "        return lz.detach()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8nNzai_b-G5"
      },
      "outputs": [],
      "source": [
        "# @title test quant icost search rnn_pred\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "d_model=16\n",
        "sicost = ICost(d_model, n=4)\n",
        "stcost=nn.Sequential(nn.Linear(d_model, 1)).to(device)\n",
        "dim_z=1\n",
        "jepa_pred=nn.Sequential(nn.Linear(d_model+dim_z+3, d_model)).to(device)\n",
        "\n",
        "\n",
        "def search(sx, T=None, bptt=None):\n",
        "    if T==None: T = 256\n",
        "    if bptt==None: bptt = min(T,32)\n",
        "    batch=sx.size(dim=0)\n",
        "    # with torch.amp.autocast('cuda'):\n",
        "    x = nn.Parameter(torch.zeros((batch, T, 3),device=device))\n",
        "    torch.nn.init.xavier_uniform_(x)\n",
        "    # optim = torch.optim.SGD([x], lr=1e5, maximize=True)\n",
        "    optim = torch.optim.SGD([x], lr=1e5)\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    for _ in range(3): # num epochs\n",
        "        sx_ = sx.detach()\n",
        "        for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "            loss, sx_ = rnn_pred(sx_, la)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            print(loss)\n",
        "            # scaler.scale(loss).backward()\n",
        "            # scaler.step(optim)\n",
        "            # scaler.update()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            with torch.no_grad(): x = torch.clamp(x, min=-1, max=1)\n",
        "            sx_ = sx_.detach()\n",
        "            # print(loss.item(), lact)\n",
        "    # print(\"search\",loss.item())\n",
        "    # return la, lact # [batch_size, T]\n",
        "    return la, lact, x # [batch_size, T]\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.95): # [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    if z is None: z=torch.zeros((batch,dim_z),device=device) # average case?\n",
        "    # z = self.jepa.argm(sx, a, sx_) # worst case\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    # for t in range(seq_len): # simple single layer\n",
        "    t=0\n",
        "    a = la[:,t] # [1, dim_a]\n",
        "    sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    # sx = sx + jepa_pred(sxaz)\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        sx = jepa_pred(sxaz)\n",
        "    print(lsx)\n",
        "    lsx = torch.cat([lsx, sx], dim=0)\n",
        "    print(lsx)\n",
        "    # print(lsx.requires_grad, sx.requires_grad)\n",
        "    # icost = 0.5*sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    icost = sicost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "    # print(icost.requires_grad)\n",
        "    tcost = -stcost(sx.squeeze(0)).squeeze(0)\n",
        "    cost += (tcost + icost)*gamma**t\n",
        "    print(\"tcost, icost\", tcost, icost)\n",
        "    # cost=icost\n",
        "    # print(cost)\n",
        "    return cost, sx#, z\n",
        "\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "\n",
        "batch=1\n",
        "sx=torch.rand((batch,d_model), device=device)\n",
        "la, lact, x = search(sx, T=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uivwksBdwVH"
      },
      "outputs": [],
      "source": [
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "sx_ = agent.jepa.enc(state.unsqueeze(0))\n",
        "out= agent.deconv(sx_).squeeze(0)\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjm2kV3H7ZVR"
      },
      "outputs": [],
      "source": [
        "for name, p in agent.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(name, p.numel())\n",
        "\n",
        "\n",
        "# 23921665 # agent # 6872065\n",
        "# 12219840 # jepa # 3695040\n",
        "# 24M params\n",
        "# 24M * 3 * 4bytes\n",
        "# 288MB\n",
        "\n",
        "# 4 byte *3*64*64\n",
        "# 4 *3*64*64 = 49152 # 1 img 50kb\n",
        "# 64 img -> 3.2mb\n",
        "# seq len 50 -> 160mb\n",
        "\n",
        "# 64*64*3=12288\n",
        "# 256*256=65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mhTHWmEjI0JO"
      },
      "outputs": [],
      "source": [
        "# @title gym\n",
        "# https://gymnasium.farama.org/\n",
        "# https://github.com/Farama-Foundation/Gymnasium\n",
        "import gymnasium as gym\n",
        "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
        "env = gym.make(\"Pendulum-v1\") # https://gymnasium.farama.org/environments/classic_control/pendulum/\n",
        "observation, info = env.reset(seed=42)\n",
        "for _ in range(1000):\n",
        "   action = env.action_space.sample()  # this is where you would insert your policy\n",
        "   observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "   if terminated or truncated:\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "\n",
        "quantizer = FSQ(levels = [2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKAELerd8MuR"
      },
      "outputs": [],
      "source": [
        "# @title simulate\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "# history = []\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "buffer = []\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    state = transform(state).unsqueeze(0)\n",
        "    action = agent(state) # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    state, reward, done, info = env.step(action) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "    # print(action.item(), reward)\n",
        "    out.write(state)\n",
        "    if done:\n",
        "        buffer.append((state, action, reward-100))\n",
        "        break\n",
        "    buffer.append((state, action, reward))\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TA_rcOQQTxan"
      },
      "outputs": [],
      "source": [
        "# @title simulate save\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "\n",
        "# print(env.action_space)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    # action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "    action = agent(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    # print(state.shape) # 0-255 (64, 64, 3)\n",
        "    print(action, reward, done)\n",
        "    out.write(state)\n",
        "\n",
        "    # break\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "6c79ab20-46bb-4299-c26b-0a27e138c717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2775104\n",
            "2362625\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = get_res(d_model)\n",
        "        # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 1, 1, 1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        # self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.Conv2d(3, d_model, 3, 2, 1), nn.ReLU(), # 256\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     nn.Conv2d(d_model, d_model, 3, 2, 1), nn.ReLU(),\n",
        "        #     # nn.Conv2d(d_model, 3, 3, 1, 1), nn.ReLU(), # 32\n",
        "        # )\n",
        "        self.deconv = Deconv(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder(256).to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzzjgoXCnhT7"
      },
      "outputs": [],
      "source": [
        "# @title train autoencoder\n",
        "# print(train_data.data)\n",
        "# sar=train_data.data\n",
        "# state, action, reward = zip(*sar)\n",
        "\n",
        "# loader = DataLoader(state, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "optim = torch.optim.AdamW(model.parameters(), 3e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    print(i)\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[7][80][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    sx_ = model.encode(state.unsqueeze(0))\n",
        "    out= model.decode(sx_)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf-rtGL1q1W",
        "outputId": "3586547e-37cc-4514-caab-e92d7354bd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.039520263671875\n"
          ]
        }
      ],
      "source": [
        "# @title text E norm (d/3)^(1/2)\n",
        "# a=torch.rand(16, 1, 256)\n",
        "# b=torch.tensor([])\n",
        "# c=torch.cat((a,b),dim=1)\n",
        "\n",
        "# a=torch.rand(16, 1, 1)\n",
        "# b=torch.rand(16, 1, 256)\n",
        "# # c=torch.bmm(a,b)\n",
        "# c=a@b\n",
        "# print(c.shape)\n",
        "\n",
        "d=16\n",
        "# a=torch.rand(d)/(d/3)**(1/2)\n",
        "# a=torch.rand(d)*2-1\n",
        "# # a=torch.rand(d,d)\n",
        "# print(a)\n",
        "# print(a.norm().item())\n",
        "\n",
        "# w=torch.rand(d,d)*2-1\n",
        "# w=(torch.rand(d,d)*2-1)*(3**0.5)/d\n",
        "# print(w)\n",
        "w = F.normalize(w)\n",
        "k,v = torch.rand(1,d), torch.rand(1,d)\n",
        "k,v = k*2-1, v*2-1\n",
        "# k,v = F.normalize(k), F.normalize(v)\n",
        "# print(k)\n",
        "# print(k.T@v)\n",
        "# print(k@v.T)\n",
        "print((k.T@v).norm().item())\n",
        "# print(w.norm().item())\n",
        "# print(w[0].norm().item())\n",
        "# print(w[:,0].norm().item())\n",
        "# print((w@k.T).norm().item())\n",
        "\n",
        "# (d/3)^(1/2) # E norm of dim d vec [0-1] or [-1-1]\n",
        "# print(4/(3**0.5))\n",
        "# k@v.T d/4 [0-1], 0 [-1-1],\n",
        "# w norm: d^2 a^2 = print(16/(3**0.5))\n",
        "\n",
        "# int int ab db da = int [1/2 a b^2] da = int 1/2 a da =\n",
        "# 1/4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ErwMF9NijD17"
      },
      "outputs": [],
      "source": [
        "# @title 514\n",
        "n=100\n",
        "a=torch.linspace(n,0,n)\n",
        "i=0\n",
        "o=0\n",
        "# oo=[]\n",
        "while True:\n",
        "    m = torch.randint(0, n, (1,))\n",
        "    a[m] = i\n",
        "    o_=i-a.min()\n",
        "    oo.append(o_.item())\n",
        "    print(sum(oo)/len(oo))\n",
        "    i+=1\n",
        "# 514?\n",
        "# p=1.064422028?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jx0k_ndHOEMe"
      },
      "outputs": [],
      "source": [
        "# @title visualise kernels\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import utils\n",
        "# https://stackoverflow.com/questions/55594969/how-to-visualise-filters-in-a-cnn-with-pytorch\n",
        "\n",
        "layers = [0,3,6,9]\n",
        "layers = [0,3,6,9,12]\n",
        "layer = 9\n",
        "\n",
        "def visualise(model,layer):\n",
        "    kernels = model.cnn[layer].weight.data.clone()\n",
        "    n,c,w,h = kernels.shape\n",
        "    print(kernels.shape)\n",
        "    if c not in [1,3]:\n",
        "        # kernels = kernels.mean(dim=1, keepdim=True)\n",
        "        kernels = kernels[:,2,:,:].unsqueeze(dim=1)\n",
        "    nrow=10\n",
        "    rows = np.min((kernels.shape[0]//nrow + 1, 64))\n",
        "    grid = utils.make_grid(kernels, nrow=nrow, normalize=True, padding=1)\n",
        "    plt.figure(figsize=(nrow,rows))\n",
        "\n",
        "    kernels = kernels - kernels.min()\n",
        "    kernels = kernels / kernels.max()\n",
        "    filter_img = utils.make_grid(kernels, nrow = 12)\n",
        "    # change ordering since matplotlib requires images to\n",
        "    # be (H, W, C)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0))\n",
        "\n",
        "    # plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
        "\n",
        "# visualise(agent.sense,layer)\n",
        "visualise(agent.jepa.enc,layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "N2TGs69fnrZo",
        "outputId": "e7624553-e17a-4a9f-85a4-512720ed329a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tcost.1.weight torch.Size([2, 512])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1920x1440 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRU(267, 256, batch_first=True, dropout=0.2)\n"
          ]
        }
      ],
      "source": [
        "# @title visualise lin\n",
        "# https://matplotlib.org/stable/plot_types/index.html\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for name, param in agent.jepa.pred.named_parameters(): # for param in model.parameters():\n",
        "# for name, param in agent.emb.named_parameters():\n",
        "for name, param in agent.tcost.named_parameters():\n",
        "    print(name, param.shape)\n",
        "    if len(param.shape)==1: param=param.unsqueeze(0)\n",
        "    Z=param.detach()#.numpy()\n",
        "\n",
        "    filter_img = utils.make_grid(Z, nrow = 12, normalize=True, padding=1)\n",
        "    plt.imshow(filter_img.cpu().permute(1, 2, 0)) # (H, W, C)\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "    # pos=ax.imshow(Z)\n",
        "    # fig.colorbar(pos)\n",
        "    plt.show()\n",
        "\n",
        "print(agent.jepa.pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEWGq2WGi9a",
        "outputId": "649e3612-f156-496e-d8d5-fc576110e2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0015, -0.0132,  0.0280,  ...,  0.0297,  0.0289,  0.0152],\n",
            "        [ 0.0168,  0.0031, -0.0288,  ..., -0.0064, -0.0137, -0.0085]])\n"
          ]
        }
      ],
      "source": [
        "# print(vars(agent.jepa.pred.))\n",
        "# print(vars(agent.tcost.state_dict()))\n",
        "# print(agent.jepa.pred._parameters.keys())\n",
        "# print(agent.jepa.pred._parameters['weight_ih_l0'])\n",
        "# print(agent.jepa.pred._parameters['weight_hh_l2']) # weight_hh_l0, weight_hh_l2\n",
        "# print(agent.tcost.state_dict().keys())\n",
        "print(agent.tcost.state_dict()['tcost.1.weight']) # tcost.2.bias, tcost.4.bias\n",
        "# print(agent.tcost.named_parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S_xnBFjXVxgz"
      },
      "outputs": [],
      "source": [
        "# @title transfer weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "d = 10  # size of the first dimension\n",
        "a = 5   # size of the extra nodes to omit\n",
        "m = 8   # output dimension\n",
        "\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "target_layer = nn.Linear(d, m)\n",
        "# source_layer = nn.Linear(d, m)\n",
        "# target_layer = nn.Linear(d+a, m)\n",
        "\n",
        "def transfer(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt.weight[:, :src.weight.shape[1]].copy_(src.weight[:, :tgt.weight.shape[1]])\n",
        "        tgt.bias.copy_(src.bias)\n",
        "    return tgt,src\n",
        "\n",
        "target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "src_sd = source_layer.state_dict()\n",
        "tgt_sd = target_layer.state_dict()\n",
        "\n",
        "def transfersd(tgt,src):\n",
        "    with torch.no_grad():\n",
        "        tgt['weight'][:, :src['weight'].shape[1]].copy_(src['weight'][:, :tgt['weight'].shape[1]])\n",
        "        tgt['bias'].copy_(src['bias'])\n",
        "    return tgt\n",
        "\n",
        "tgt_sd = transfersd(tgt_sd, src_sd)\n",
        "target_layer.load_state_dict(tgt_sd)\n",
        "\n",
        "\n",
        "agent_src = Agent(d_model=256, dim_a=3, dim_z=1, dim_v=512).to(device)\n",
        "\n",
        "# agent.tcost = TCost((1+agent.jepa.pred.num_layers)*agent.d_model) # replace tcost\n",
        "\n",
        "agent = Agent(d_model=256, dim_a=3, dim_z=3, dim_v=512).to(device)\n",
        "\n",
        "# agent.jepa.pred\n",
        "# target_layer, source_layer = transfer(target_layer, source_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(vars(agent.jepa.pred))\n",
        "# gru = agent.jepa.pred\n",
        "# gru = agent_src.jepa.pred\n",
        "# for wht_name in gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, gru._parameters[wht_name].shape)\n",
        "\n",
        "# weight_ih_l0 dim_z=3: [768, 262] , dim_z=1: [768, 260]\n",
        "# weight_hh_l0 torch.Size([768, 256])\n",
        "# bias_ih_l0 torch.Size([768])\n",
        "# bias_hh_l0 torch.Size([768])\n",
        "\n",
        "# tgt_gru = agent.jepa.pred\n",
        "# src_gru = agent_src.jepa.pred\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "\n",
        "tgt_gru[]\n",
        "def transfer_gru(tgt_gru, src_gru): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for i in range(min(len(tgt_gru._all_weights), len(src_gru._all_weights))):\n",
        "        # for lyr in tgt_gru._all_weights:\n",
        "            lyr = tgt_gru._all_weights[i]\n",
        "            for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "                # print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "                tgt_wht, src_wht = tgt_gru._parameters[wht_name], src_gru._parameters[wht_name]\n",
        "                if len(tgt_wht.shape)==2:\n",
        "                    tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "                elif len(tgt_wht.shape)==1:\n",
        "                    tgt_gru._parameters[wht_name] = src_wht\n",
        "    return tgt_gru\n",
        "tgt_gru = transfer_gru(tgt_gru, src_gru)\n",
        "\n",
        "# for wht_name in tgt_gru._all_weights[0]: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "#     print(wht_name, tgt_gru._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d_model=256; dim_a=3; dim_z=1; dim_v=512\n",
        "\n",
        "pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "# pred = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "print(pred._all_weights)\n",
        "for lyr in pred._all_weights:\n",
        "    for wht_name in lyr: # weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0\n",
        "        print(wht_name, pred._parameters[wht_name].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(pred.state_dict().keys())\n",
        "\n",
        "tgt_gru = torch.nn.GRU(d_model+dim_a+dim_z+2, d_model, num_layers=3, batch_first=True, dropout=0.0)\n",
        "src_gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "print(tgt_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "print(src_gru.state_dict()['weight_ih_l0'][0][:10])\n",
        "\n",
        "print(tgt_gru.state_dict()['bias_ih_l0'][:10])\n",
        "print(src_gru.state_dict()['bias_ih_l0'][:10])\n",
        "tgt_gru.state_dict().keys()\n",
        "src_gru.state_dict().keys()\n",
        "\n",
        "# tgt_gru\n",
        "# src_gru\n",
        "for wht_name in tgt_gru.state_dict().keys():\n",
        "    if not wht_name in src_gru.state_dict().keys(): continue\n",
        "    print(wht_name)\n",
        "    # print(tgt_gru.state_dict()[wht_name])\n",
        "    # tgt_gru.state_dict()[wht_name].copy_(src_gru.state_dict()[wht_name])\n",
        "\n",
        "tgt_sd = tgt_gru.state_dict()\n",
        "src_sd = src_gru.state_dict()\n",
        "def transfer_sd(tgt_sd, src_sd): # change input dim of gru\n",
        "    with torch.no_grad():\n",
        "        for wht_name in tgt_sd.keys():\n",
        "            if not wht_name in src_sd.keys(): continue\n",
        "            # print(wht_name)\n",
        "            tgt_wht, src_wht = tgt_sd[wht_name], src_sd[wht_name]\n",
        "            if len(tgt_wht.shape)==2:\n",
        "                tgt_wht[:, :src_wht.shape[1]].copy_(src_wht[:, :tgt_wht.shape[1]])\n",
        "            elif len(tgt_wht.shape)==1:\n",
        "                tgt_wht.copy_(src_wht)\n",
        "    return tgt_sd\n",
        "tgt_sd = transfer_sd(tgt_sd, src_sd)\n",
        "print(tgt_sd['weight_ih_l0'][0][:10])\n",
        "print(tgt_sd['bias_ih_l0'][:10])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwApoQMMKzB",
        "outputId": "55f16b74-1895-4f1d-d8a8-1d2599b24e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4819, 0.6553, 0.9985, 1.0000, 0.9985, 0.9994, 0.9359, 0.9996, 0.9644,\n",
            "        0.9341, 0.9024, 0.9997, 1.0000, 0.7107, 0.9998])\n",
            "0.0003056526184082031\n",
            "tensor([0.2441, 0.1957, 0.3679, 0.2116, 0.2805, 0.2153, 0.2356, 0.2736])\n"
          ]
        }
      ],
      "source": [
        "# @title test init norm\n",
        "print(agent.emb.state_dict()['weight'].norm(dim=-1))\n",
        "\n",
        "# x = torch.rand(16)\n",
        "x = torch.rand(8,16)\n",
        "# print(x)\n",
        "# torch.nn.init.normal_(x, mean=0.0, std=1.0)\n",
        "# torch.nn.init.xavier_normal_(x)\n",
        "import time\n",
        "start = time.time()\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# with torch.no_grad(): x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # 0.00966, 0.000602, 0.0004\n",
        "torch.nn.init.normal_(x, mean=0.0, std=.25/x.shape[-1]**0.5)\n",
        "# torch.nn.init.normal_(x, mean=0., std=.3/x.shape[-1]**0.5)\n",
        "print(time.time()-start)\n",
        "# std = ((Sum (xi-mean)^2)/ N)^(1/2)\n",
        "# print(x)\n",
        "# print(((x**2).sum())**(0.5))\n",
        "print(torch.norm(x, dim=-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_VgsenYLpM",
        "outputId": "8c7b23ae-8cdb-4846-dae3-32fd046a4d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[0.0437, 0.3097, 0.4537]]], requires_grad=True)\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n",
            "tensor([[[-0.5242, -0.2421,  0.2851]]])\n"
          ]
        }
      ],
      "source": [
        "# @title test rnn_pred symlog\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "# fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # xx = fsq(x)\n",
        "    # xx = fsq(x.clone())\n",
        "    # print(xx)\n",
        "    # x = torch.tanh(x)\n",
        "    # loss = x.sum()\n",
        "    # loss = model(xx)\n",
        "    loss = model(x)\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    # x = torch.clamp(x, min=-1, max=1)\n",
        "    # x = torch.clamp(x.clone(), min=-1, max=1)\n",
        "    with torch.no_grad():\n",
        "        # x.clamp_(min=-1, max=1)\n",
        "        x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # model = nn.Sequential(nn.Linear(3,1))\n",
        "# model = nn.Sequential(nn.Linear(3*2,1))\n",
        "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# batch_size = 1\n",
        "# seq_len = 3\n",
        "# x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# # torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "\n",
        "# def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "#     batch, seq_len, dim_a = la.shape\n",
        "#     cost = 0\n",
        "#     lsx=sx\n",
        "#     for t in range(seq_len): # simple single layer\n",
        "#         a = la[:,t] # [1, dim_a]\n",
        "#         sxaz = torch.cat([sx, a], dim=-1)\n",
        "#         # with torch.amp.autocast('cuda'):\n",
        "#         cost = cost + model(sxaz)\n",
        "#         lsx = torch.cat([lsx, sx], dim=0)\n",
        "#     return cost, sx\n",
        "\n",
        "\n",
        "# # def ste_clamp(input, min=-1, max=1):\n",
        "# #     clamped_output = torch.clamp(input, min, max)\n",
        "# #     clamp_mask = (input < min) | (input > max)\n",
        "# #     return torch.where(clamp_mask, input, clamped_output)\n",
        "\n",
        "# def ste_clamp(x, min=-1, max=1):\n",
        "#     return torch.clamp(x, min, max).detach() + x - x.detach()\n",
        "\n",
        "# def ste_abs(x): return x.sign() * x\n",
        "# def symlog(x): return torch.sign(x) * torch.log(ste_abs(x) + 1.0)\n",
        "# def symexp(x): return torch.sign(x) * torch.exp(ste_abs(x) - 1.0)\n",
        "\n",
        "\n",
        "# sx = torch.rand((batch_size,3),device=device)\n",
        "# sx_ = sx.detach()\n",
        "# for i in range(10): # num epochs\n",
        "#     # la = fsq(x.clone())\n",
        "#     la = fsq(x)\n",
        "#     print(i)\n",
        "#     print(x,x.requires_grad)\n",
        "#     print(la,la.requires_grad)\n",
        "#     loss, sx_ = rnn_pred(sx_, la)\n",
        "#     # loss.backward()\n",
        "#     loss.backward(retain_graph=True) # retain_graph bec fsq got tanh that creates new graph?\n",
        "#     optim.step()\n",
        "#     optim.zero_grad()\n",
        "#     # x = torch.tanh(x)\n",
        "#     # x = torch.clamp(x, min=-1, max=1)\n",
        "#     # x = ste_clamp(x.clone(), min=-1, max=1)\n",
        "#     # x = symlog(x.clone())\n",
        "#     # sx_ = sx_.detach()\n",
        "\n",
        "\n",
        "# # print(xx)\n",
        "# print(x)\n",
        "# # print(xhat)\n",
        "# print(la)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pGZld_gLH1RA"
      },
      "outputs": [],
      "source": [
        "# @title test bptt\n",
        "\n",
        "x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    loss=0\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        # loss = loss -stcost(xxx.clone()).sum()\n",
        "        loss = loss -stcost(xxx).sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "# RuntimeError: Output 1 of SplitBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size, T = 1,6\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device))\n",
        "# optim = torch.optim.SGD([x], lr=1e-3)\n",
        "# # xx = torch.split(x, bptt, dim=1)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    loss=0\n",
        "    # xx = torch.split(x, bptt, dim=1)\n",
        "    for xxx in xx:\n",
        "        # loss = -stcost(xxx).sum()\n",
        "        loss = loss -stcost(xxx.clone()).sum()\n",
        "        # loss = loss -stcost(xxx).sum()\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jepapred = nn.Sequential(nn.Linear(3*2,3))\n",
        "stcost = nn.Sequential(nn.Linear(3,1))\n",
        "\n",
        "def rnn_pred(sx, la, z=None, gamma=0.7): # 0.95 [1, d_model], [seq_len, dim_a/z]\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    lsx=sx\n",
        "    # print(\"rnn pred\",lsx[0][:5])\n",
        "    for t in range(seq_len): # simple single layer\n",
        "        # print(la.shape)\n",
        "        a = la[:,t,:].clone() # [1, dim_a]\n",
        "        # sxaz = torch.cat([sx, a], dim=-1)\n",
        "        sxaz = torch.cat([sx.clone(), a.clone()], dim=-1)\n",
        "        # sxaz = torch.cat([sx.clone(), a], dim=-1)\n",
        "        sx = jepapred(sxaz)\n",
        "        tcost = -stcost(sx).sum()\n",
        "        lsx = torch.cat([lsx, sx], dim=0)\n",
        "        # print(lsx.requires_grad, sx.requires_grad)\n",
        "        # icost = 0.5*icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(icost.requires_grad)\n",
        "        cost += tcost# + icost\n",
        "    return cost, sx#, z\n",
        "\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "sx = torch.rand((batch_size,3),device=device)\n",
        "T = 6\n",
        "bptt = 3\n",
        "# x = nn.Parameter(torch.empty((batch_size, T, 3),device=device)) # FSQ 3 levels\n",
        "x = torch.empty((batch_size, T, 3),device=device) # FSQ 3 levels\n",
        "torch.nn.init.xavier_uniform_(x)\n",
        "# optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "# optim = torch.optim.SGD([x], lr=1e-3) #, maximize=True)\n",
        "# print(x.shape)\n",
        "# print(len(xx))\n",
        "# print(xx[0].shape)\n",
        "\n",
        "x = torch.rand((batch_size, T, 3),device=device)\n",
        "bptt=2\n",
        "xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "optim = torch.optim.SGD(xx, lr=1e-3)\n",
        "\n",
        "for _ in range(10): # num epochs\n",
        "    xx = torch.split(x, bptt, dim=1)\n",
        "    sx_ = sx.detach()\n",
        "    for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "\n",
        "        # xxx=x\n",
        "        # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "        la = fsq(xxx)\n",
        "        # la = xxx\n",
        "        # print(x,x.requires_grad)\n",
        "        # print(la,la.requires_grad)\n",
        "        # loss, sx_ = rnn_pred(sx_, la)\n",
        "        loss = -stcost(la).sum()\n",
        "\n",
        "        print(\"loss\",loss)\n",
        "        loss.backward()\n",
        "        # loss.backward(retain_graph=True)\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # sx_ = sx_.detach()\n",
        "        # print(loss.item(), lact)\n",
        "\n",
        "    x = torch.cat(xx,dim=1)\n",
        "    x = torch.tanh(x) # clamp\n",
        "    print(x)\n",
        "    # print(x)\n",
        "print(\"search\",loss.item())\n",
        "# print(lact)\n",
        "# return la, lact # [batch_size, T]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # def search(self, sx, T=256, bptt=32):\n",
        "    # def search(self, sx, T=None, bptt=None):\n",
        "    #     if T==None: T = 256\n",
        "    #     if bptt==None: bptt = min(T,3)\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     x = nn.Parameter(torch.empty((batch, T, 3),device=device)) # FSQ 3 levels\n",
        "    #     torch.nn.init.xavier_uniform_(x)\n",
        "    #     # optim = torch.optim.SGD([x], lr=1e5) #, maximize=True)\n",
        "    #     # xx = torch.split(x, bptt, dim=1)\n",
        "    #     xx = [nn.Parameter(xxx) for xxx in torch.split(x, bptt, dim=1)]\n",
        "    #     optim = torch.optim.SGD(xx, lr=1e7) #, maximize=True)\n",
        "\n",
        "    #     for _ in range(10): # num epochs\n",
        "    #         sx_ = sx.detach()\n",
        "    #         for xxx in xx: # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "    #             # la, lact = quantizer(x) # xhat, indices [batch_size, T, num_levels], [batch_size, T]\n",
        "    #             la = fsq(xxx.clone())\n",
        "    #             # print(x,x.requires_grad)\n",
        "    #             # print(la,la.requires_grad)\n",
        "    #             loss, sx_ = self.rnn_pred(sx_, la)\n",
        "    #             loss.backward(retain_graph=True)\n",
        "    #             optim.step()\n",
        "    #             optim.zero_grad()\n",
        "    #             sx_ = sx_.detach()\n",
        "    #             # print(loss.item(), lact)\n",
        "    #             # xx = torch.tanh(xx) # clamp\n",
        "    #         xx = [torch.tanh(xxx) for xxx in xx]\n",
        "    #         x = torch.cat(xx,dim=1)\n",
        "    #         # x = torch.tanh(x) # clamp\n",
        "    #         print(x)\n",
        "    #     print(\"search\",loss.item())\n",
        "    #     # print(lact)\n",
        "    #     return la, lact # [batch_size, T]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YWmwVYhVVh5R"
      },
      "outputs": [],
      "source": [
        "# @title test ste_argmin\n",
        "import torch\n",
        "emb = torch.nn.Embedding(15, 3) # env.action_space # 15\n",
        "x = torch.rand(1,3)\n",
        "\n",
        "# def ste_argmin(x, dim=-1):\n",
        "#     idx = torch.argmin(x, dim)\n",
        "#     # out = torch.zeros_like(x)\n",
        "#     out = torch.zeros_like(idx).unsqueeze(-1)\n",
        "#     print(idx.shape, out.shape)\n",
        "#     out.scatter_(1, idx, 1)\n",
        "#     return out\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# def softargmin(x, beta=10):\n",
        "#     # Apply softmax to the negative of the input to approximate argmin\n",
        "#     weights = F.softmax(-x * beta, dim=-1)\n",
        "#     indices = torch.arange(x.size(-1), dtype=x.dtype, device=x.device)\n",
        "#     soft_argmin = torch.sum(weights * indices, dim=-1)\n",
        "#     return soft_argmin\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ste_argmax(x, temp=1.0):\n",
        "    x_soft = F.softmax(x / temp, dim=-1)\n",
        "    x_hard = torch.zeros_like(x)\n",
        "    x_hard.scatter_(-1, x_soft.argmax(dim=-1, keepdim=True), 1.0)\n",
        "    x_hard = (x_hard - x_soft).detach() + x_soft\n",
        "    return x_hard # one hot\n",
        "# out = differentiable_argmax(-x)\n",
        "# print(out)\n",
        "\n",
        "\n",
        "# def softargmax1d(input, beta=100): # https://github.com/david-wb/softargmax/blob/master/softargmax.py\n",
        "#     *_, n = input.shape\n",
        "#     input = nn.functional.softmin(beta * input, dim=-1)\n",
        "#     indices = torch.linspace(0, 1, n)\n",
        "#     result = torch.sum((n - 1) * input * indices, dim=-1)\n",
        "#     return result\n",
        "\n",
        "# ste_round\n",
        "\n",
        "# # dist = torch.norm(self.emb.weight.data - x, dim=-1)\n",
        "# dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "# lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "# print(lact)\n",
        "\n",
        "device='cpu'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "model = nn.Sequential(nn.Linear(3,1)).to(device)\n",
        "batch_size = 1\n",
        "seq_len = 1\n",
        "x = nn.Parameter(torch.rand((batch_size, seq_len,3),device=device)) # [batch_size, seq_len, FSQ 3 levels]\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "optim = torch.optim.SGD([x], lr=1e0)\n",
        "\n",
        "pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "\n",
        "for i in range(5): # num epochs\n",
        "    print(x)\n",
        "    # dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "    dist = torch.norm(emb.weight.data[None,None,...] - x.unsqueeze(-2), dim=-1) # [1,1,act_space,emb_dim], [batch,T,1,emb_dim] -> [batch,T,act_space]\n",
        "    A=differentiable_argmax(-dist)\n",
        "    # print(A.shape)\n",
        "    print(torch.argmax(A))\n",
        "    x_=A@emb.weight.data\n",
        "    # print(\"dist\", dist.shape)\n",
        "    # lact = torch.argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = ste_argmin(dist, dim=-1) # [batch,T]\n",
        "    # lact = softargmin(dist)\n",
        "    # print(lact)\n",
        "    # x = emb.weight.data[lact]\n",
        "\n",
        "    # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "    print(\"x_\",x_)\n",
        "    # x = emb(x_)\n",
        "\n",
        "    loss = model(x_).sum()\n",
        "    loss.backward(retain_graph=True)\n",
        "    # loss.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "x_ = torch.tensor([14])\n",
        "x = emb(x_)\n",
        "# print(x)\n",
        "# # print(emb.weight)\n",
        "# pseudo_inverse_weight = torch.pinverse(emb.weight)\n",
        "pseudo_inverse_weight = torch.linalg.pinv(emb.weight)\n",
        "# weight_inv = torch.pinverse(emb.weight.T)\n",
        "\n",
        "dist = torch.norm(emb.weight.data - x, dim=-1)\n",
        "# print(x@pseudo_inverse_weight)\n",
        "# A=differentiable_argmax(-x@pseudo_inverse_weight)\n",
        "A=differentiable_argmax(-dist)\n",
        "print(A)\n",
        "\n",
        "# print(pseudo_inverse_weight.shape, pseudo_inverse_weight)\n",
        "# # x_ = torch.matmul(x, pseudo_inverse_weight)\n",
        "# x_ = x@ pseudo_inverse_weight\n",
        "# print(\"x_\",x_)\n",
        "\n",
        "# print(emb.weight@ pseudo_inverse_weight)\n",
        "# dist=torch.dist(emb.weight@ pseudo_inverse_weight, torch.eye(15))\n",
        "# print(dist)\n",
        "# print(pseudo_inverse_weight@ emb.weight)\n",
        "\n",
        "# print(emb.weight@ weight_inv.T)\n",
        "# print(weight_inv.T@ emb.weight)\n",
        "\n",
        "# torch.linalg.lstsq(A, B).solution\n",
        "\n",
        "\n",
        "x_ = torch.tensor([4])\n",
        "embx = emb(x_) # emb.weight[x_,:]\n",
        "print(embx)\n",
        "\n",
        "Apinv = torch.linalg.pinv(A)\n",
        "x = embx@Apinv\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT5j864BIn",
        "outputId": "ac676107-a22d-4315-a3c7-785e3c6456c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        }
      ],
      "source": [
        "# @title simulate 512\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def simulate(agent, buffer=[]):\n",
        "    out = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 20, (64,64))\n",
        "    state = env.reset()\n",
        "    episode=[]\n",
        "    while True:\n",
        "    # while not done:\n",
        "        # state = transform(state).unsqueeze(0).to(device)\n",
        "        # action = agent(state).cpu() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        # state, reward, done, info = env.step(action[0]) # np(64,64,3) 0.0 False {'prev_level_seed': 736820912, 'prev_level_complete': 0, 'level_seed': 736820912, 'rgb': array([[[  0, 125, 222], ...)\n",
        "        action = env.action_space.sample() # https://github.com/openai/procgen/blob/master/procgen/env.py#L155\n",
        "        state, reward, done, info = env.step(action)\n",
        "        # print(i, 'act: ',action.item(), 'reward: ',reward)\n",
        "        out.write(state)\n",
        "        if done:\n",
        "            episode.append((state, action, -1))\n",
        "            # print(\"ded\")\n",
        "            break\n",
        "        episode.append((state, action, 0))\n",
        "    # print('time')\n",
        "    env.close()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    buffer.append(episode)\n",
        "    return buffer\n",
        "\n",
        "# buffer = simulate(agent, buffer)\n",
        "# _=simulate(agent)\n",
        "\n",
        "buffer=[]\n",
        "for i in range(512):\n",
        "    buffer = simulate(agent, buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUCet57LcPdf"
      },
      "outputs": [],
      "source": [
        "n=100\n",
        "tt=0\n",
        "a=1+1/(n*(n-1))\n",
        "print(a)\n",
        "for i in range(n-1):\n",
        "    a=(1+ 1/(n-i))*a\n",
        "    print(a)\n",
        "    tt+=a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_UlGz6Xoq3"
      },
      "source": [
        "## archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hEUffQ24mkRY"
      },
      "outputs": [],
      "source": [
        "# @title augmentations\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/augmentations.py\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class TrainTransform(object):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=1.0),\n",
        "                # transforms.RandomSolarize(threshold=130, p=0.0)\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, interpolation=InterpolationMode.BICUBIC),#224\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)), # clamp else ColorJitter will return nan https://discuss.pytorch.org/t/input-is-nan-after-transformation/125455/6\n",
        "                transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8,),\n",
        "                transforms.RandomGrayscale(p=0.2),\n",
        "                transforms.RandomApply([transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),], p=0.1),\n",
        "                # transforms.RandomSolarize(threshold=130/255, p=0.2) # og threshold=130, /255 bec after normalising\n",
        "                transforms.RandomSolarize(threshold=.9, p=0.2),\n",
        "                # transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "                # transforms.RandomPerspective(distortion_scale=0.3, p=0.5), # me\n",
        "                # transforms.RandomErasing(p=0.5, scale=(0.1, 0.11), ratio=(1,1), value=0, inplace=True), # default p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
        "        # dims = len(sample.shape)\n",
        "        # if dims==3: x1 = self.transform(sample) # same transforms per minibatch\n",
        "        # elif dims==4: x1 = transforms.Lambda(lambda x: torch.stack([self.transform(x_) for x_ in x]))(sample) # diff transforms per img in minibatch\n",
        "    def __call__(self, sample):\n",
        "        x1 = self.transform(sample)\n",
        "        x2 = self.transform_prime(sample)\n",
        "        return x1, x2\n",
        "\n",
        "trs=TrainTransform()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# print(get_res(256).to(device))\n",
        "# model = get_res(256).to(device)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AodVas3L4ZS",
        "outputId": "f1940ab6-b72d-4c8d-f97d-6d876f1b92e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 256])\n",
            "136960\n",
            "136960\n"
          ]
        }
      ],
      "source": [
        "# @title efficientnet\n",
        "# https://arxiv.org/pdf/2207.10318 # visualise kernal\n",
        "\n",
        "# https://pytorch.org/hub/research-models\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/shufflenetv2.py\n",
        "\n",
        "import torch\n",
        "# https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py\n",
        "from torchvision.models.efficientnet import *\n",
        "from torchvision.models import efficientnet\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # https://arxiv.org/pdf/2104.00298\n",
        "# Stage Operator Stride #Channels #Layers\n",
        "# 0 Conv3x3 2 24 1\n",
        "# 1 Fused-MBConv1, k3x3 1 24 2\n",
        "# 2 Fused-MBConv4, k3x3 2 48 4\n",
        "# 3 Fused-MBConv4, k3x3 2 64 4\n",
        "# 4 MBConv4, k3x3, SE0.25 2 128 6\n",
        "# 5 MBConv6, k3x3, SE0.25 1 160 9\n",
        "# 6 MBConv6, k3x3, SE0.25 2 256 15\n",
        "# 7 Conv1x1 & Pooling & FC - 1280 1\n",
        "\n",
        "# # elif arch.startswith(\"efficientnet_v2_s\"):\n",
        "# inverted_residual_setting = [\n",
        "#     FusedMBConvConfig(1, 3, 1, 24, 24, 2),\n",
        "#     FusedMBConvConfig(4, 3, 2, 24, 48, 4),\n",
        "#     FusedMBConvConfig(4, 3, 2, 48, 64, 4),\n",
        "#     MBConvConfig(4, 3, 2, 64, 128, 6),\n",
        "#     MBConvConfig(6, 3, 1, 128, 160, 9),\n",
        "#     MBConvConfig(6, 3, 2, 160, 256, 15),\n",
        "# ]\n",
        "# last_channel = 1280\n",
        "\n",
        "# d_list=[24, 48, 64, 128, 160, 256] #\n",
        "d_list=[16, 32, 48, 96, 108, 172] #\n",
        "inverted_residual_setting = [\n",
        "    efficientnet.FusedMBConvConfig(1, 3, 1, d_list[0], d_list[0], 2),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[0], d_list[1], 4),\n",
        "    efficientnet.FusedMBConvConfig(4, 3, 2, d_list[1], d_list[2], 4),\n",
        "    efficientnet.MBConvConfig(4, 3, 2, d_list[2], d_list[3], 6),\n",
        "    efficientnet.MBConvConfig(6, 3, 1, d_list[3], d_list[4], 9),\n",
        "    efficientnet.MBConvConfig(6, 3, 2, d_list[4], d_list[5], 15),\n",
        "]\n",
        "last_channel = 512\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "\n",
        "effnet = EfficientNet(inverted_residual_setting, dropout=0.1, last_channel=last_channel, num_classes=256)\n",
        "effnet.features = efficientnet.Conv2dNormActivation(1, last_channel, kernel_size=3, stride=2, norm_layer=partial(nn.BatchNorm2d, eps=1e-03), activation_layer=nn.SiLU)\n",
        "\n",
        "#   (features): Sequential(\n",
        "#     (0): Conv2dNormActivation(\n",
        "#       (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "#       (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "#       (2): SiLU(inplace=True)\n",
        "\n",
        "input = torch.rand((1,1,256,256), device=device)\n",
        "out = effnet(input)\n",
        "print(out.shape)\n",
        "# print(effnet)\n",
        "print(sum(p.numel() for p in effnet.parameters() if p.requires_grad)) #\n",
        "print(sum(p.numel() for p in effnet.parameters())) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V15LtR8myLL9",
        "outputId": "cebfa4c2-53bf-4353-9765-520fe0f561c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title vicreg next\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "# https://github.com/facebookresearch/vicreg/blob/main/resnet.py\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, dim_embd=256, ema=False):\n",
        "        super().__init__()\n",
        "        self.conv = get_res(dim_embd=dim_embd)\n",
        "\n",
        "        # f=[dim_embd,1024,1024,1024]\n",
        "        # f=[dim_embd,512,512,512]\n",
        "        f=[dim_embd,256,256,256]\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(f[0], f[1]), nn.BatchNorm1d(f[1]), nn.ReLU(),\n",
        "            nn.Linear(f[1], f[2]), nn.BatchNorm1d(f[2]), nn.ReLU(),\n",
        "            nn.Linear(f[-2], f[-1], bias=False)\n",
        "            )\n",
        "        self.ema = ema\n",
        "        if ema:\n",
        "            self.conv_ema = AveragedModel(self.conv, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "            self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size=x.size(dim=0)\n",
        "        num_features=32\n",
        "        sim_coeff=10.0 # 25.0 # λ\n",
        "        std_coeff=10.0 # 25.0 # µ\n",
        "        cov_coeff=1.0 # 1.0 # ν\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        print(\"in vicreg \",(sim_coeff * repr_loss).item() , (std_coeff * std_loss).item() , (cov_coeff * cov_loss).item())\n",
        "        return loss\n",
        "\n",
        "    def loss(self, sx, sy):\n",
        "        sx = self.forward(sx)\n",
        "        sy = self.forward(sy)\n",
        "        with torch.no_grad(): # target encoder is ema\n",
        "            sy = self.conv_ema(sy)\n",
        "            vy = self.exp_ema(sy)\n",
        "        vx = self.exp(sx)\n",
        "        vy = self.exp(sy)\n",
        "        loss = self.vicreg(vx,vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "model = VICReg().to(device) # create an instance and move it to device (cache?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ko5qJO7Et09L"
      },
      "outputs": [],
      "source": [
        "# @title vector quantize\n",
        "# https://github.com/lucidrains/vector-quantize-pytorch?tab=readme-ov-file#finite-scalar-quantization\n",
        "# !pip install -qq vector-quantize-pytorch\n",
        "\n",
        "import torch\n",
        "from vector_quantize_pytorch import FSQ\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "quantizer = FSQ(levels = [3,3,2]).to(device) # https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/finite_scalar_quantization.py\n",
        "\n",
        "# # x = torch.randn(1, 1024, 3) # last dim is num levels\n",
        "# x = torch.randn(4, 256, 3)*3 -1.5 # [batch_size, T, num_levels]\n",
        "# xhat, indices = quantizer(x) # [batch_size, T, num_levels], [batch_size, T]\n",
        "# # print(xhat[0])\n",
        "# # print(indices[0])\n",
        "\n",
        "# # assert torch.all(xhat == quantizer.indices_to_codes(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LK5u500Vad2P"
      },
      "outputs": [],
      "source": [
        "# @title FSQ jax\n",
        "# https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "import itertools\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "Codeword = jax.Array\n",
        "Indices = jax.Array\n",
        "\n",
        "def round_ste(z):\n",
        "  \"\"\"Round with straight through gradients.\"\"\"\n",
        "  zhat = jnp.round(z)\n",
        "  return z + jax.lax.stop_gradient(zhat - z)\n",
        "\n",
        "class FSQ:\n",
        "  \"\"\"Quantizer.\"\"\"\n",
        "  def __init__(self, levels: list[int], eps: float = 1e-3):\n",
        "    self._levels = levels\n",
        "    self._eps = eps\n",
        "    self._levels_np = np.asarray(levels)\n",
        "    self._basis = np.concatenate(([1], np.cumprod(self._levels_np[:-1]))).astype(np.uint32)\n",
        "    self._implicit_codebook = self.indexes_to_codes(np.arange(self.codebook_size))\n",
        "    print(\"self._basis\",self._basis)\n",
        "    print(\"self._implicit_codebook\",self._implicit_codebook)\n",
        "\n",
        "  @property\n",
        "  def num_dimensions(self):\n",
        "    \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
        "    return len(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook_size(self):\n",
        "    \"\"\"Size of the codebook.\"\"\"\n",
        "    return np.prod(self._levels)\n",
        "\n",
        "  @property\n",
        "  def codebook(self):\n",
        "    \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
        "    return self._implicit_codebook\n",
        "\n",
        "  def bound(self, z: jax.Array) -> jax.Array:\n",
        "    \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "    half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
        "    offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
        "    shift = jnp.tan(offset / half_l)\n",
        "    return jnp.tanh(z + shift) * half_l - offset\n",
        "\n",
        "  def quantize(self, z: jax.Array) -> Codeword:\n",
        "    \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
        "    quantized = round_ste(self.bound(z))\n",
        "\n",
        "    # Renormalize to [-1, 1].\n",
        "    half_width = self._levels_np // 2\n",
        "    return quantized / half_width\n",
        "\n",
        "  def _scale_and_shift(self, zhat_normalized):\n",
        "    # Scale and shift to range [0, ..., L-1]\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "  def _scale_and_shift_inverse(self, zhat):\n",
        "    half_width = self._levels_np // 2\n",
        "    return (zhat - half_width) / half_width\n",
        "\n",
        "  def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
        "    \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
        "    assert zhat.shape[-1] == self.num_dimensions\n",
        "    zhat = self._scale_and_shift(zhat)\n",
        "    return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
        "\n",
        "  def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
        "    \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
        "    indices = indices[..., jnp.newaxis]\n",
        "    print(indices, self._basis, self._levels_np)\n",
        "    print(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    codes_non_centered = np.mod(np.floor_divide(indices, self._basis), self._levels_np)\n",
        "    return self._scale_and_shift_inverse(codes_non_centered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xHxv7ptuwVHX"
      },
      "outputs": [],
      "source": [
        "# @title FSQ torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module): # https://colab.research.google.com/github/google-research/google-research/blob/master/fsq/fsq.ipynb\n",
        "    def __init__(self, levels, eps = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cat([torch.ones(1, device=device), torch.cumprod(self.levels[:-1], dim=0)]).long()\n",
        "        self.num_dimensions = len(levels)\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        # self.mean = self.codebook.mean(dim=0)\n",
        "        # self.max = self.codebook.max(dim=0).values\n",
        "        # self.min = self.codebook.min(dim=0).values\n",
        "\n",
        "    def bound(self, z):\n",
        "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
        "        half_l = (self.levels - 1) * (1 - self.eps) / 2 # [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "        # half_l = (self.levels-1)/2 # me ?\n",
        "        offset = torch.where(self.levels % 2 == 1, 0.0, 0.5) # [0.0000, 0.0000, 0.5000] mean?\n",
        "        # print(\"half_l\", half_l)\n",
        "        # shift = torch.tan(offset / half_l) # [0.0000, 0.0000, 1.5608] < tan(1)\n",
        "\n",
        "        # print(\"shift\", shift)\n",
        "        # print(\"bound\", torch.tanh(z + shift) * half_l - offset)\n",
        "\n",
        "        # print(f'half_l {half_l}, shift {shift}, bound {torch.tanh(z + shift) * half_l - offset}')\n",
        "        # return torch.tanh(z + shift) * half_l - offset\n",
        "        # return torch.tanh(z - shift) * half_l + offset\n",
        "        return torch.tanh(z) * half_l + offset\n",
        "\n",
        "    def forward(self, z):\n",
        "        quantized = ste_round(self.bound(z))\n",
        "        # print(\"quantized\", quantized)\n",
        "        half_width = self.levels // 2 # Renormalize to [-1, 1]\n",
        "        return quantized / half_width\n",
        "\n",
        "    def _scale_and_shift(self, zhat_normalized): # Scale and shift to range [0, ..., L-1]\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat_normalized * half_width) + half_width\n",
        "\n",
        "    def _scale_and_shift_inverse(self, zhat):\n",
        "        half_width = self.levels // 2\n",
        "        return (zhat - half_width) / half_width\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        assert zhat.shape[-1] == self.num_dimensions\n",
        "        zhat = self._scale_and_shift(zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).long()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes_non_centered = torch.fmod(indices // self.basis, self.levels)\n",
        "        return self._scale_and_shift_inverse(codes_non_centered)\n",
        "\n",
        "fsq = FSQ(levels = [3,3,2])\n",
        "\n",
        "# print(fsq.codebook)\n",
        "\n",
        "# batch_size, seq_len = 1, 1\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SnfcKPses5X",
        "outputId": "7c50a3e3-281a-4375-b86f-ece58f6775c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "half_l tensor([0.9990, 0.9990, 0.4995]), shift tensor([0.0000, 0.0000, 1.5608]), bound tensor([-0.4617,  0.5365, -0.0515])\n",
            "quantized tensor([0., 1., 0.])\n",
            "tensor([0., 1., 0.])\n"
          ]
        }
      ],
      "source": [
        "# @title test fsq\n",
        "fsq = FSQ(levels = [4])\n",
        "\n",
        "# 2: 1.6 half_l tensor([0.4995]), shift tensor([1.5608]), bound tensor([-0.5195])\n",
        "# 3: 0.6 # half_l tensor([0.9990]), shift tensor([0.]), bound tensor([-0.9207])\n",
        "# 4: 0.4, 1.3 # half_l tensor([1.4985]), shift tensor([0.3466]), bound tensor([-1.7726])\n",
        "# 5: 0.5, 1 # half_l [1.9980], shift [0.], bound [-1.8415]\n",
        "x = torch.tensor([.9],device=device)\n",
        "# x = torch.tensor([-1.6],device=device)\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "\n",
        "\n",
        "x = torch.tensor([-0.6,0.6,-1.6],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,-1.5],device=device)\n",
        "# x = torch.tensor([-0.6,0.6,1.6],device=device)\n",
        "x = torch.tensor([-0.5,0.6,-0.1],device=device)\n",
        "\n",
        "la = fsq(x)\n",
        "print(la)\n",
        "\n",
        "round emb\n",
        "\n",
        "# half_l [0.9990, 0.9990, 0.4995] < 1,1,0.5\n",
        "# offset [0.0000, 0.0000, 0.5000] mean?\n",
        "# shift [0.0000, 0.0000, 1.5608] torch.tan(offset / half_l)\n",
        "# bound [-0.5365,  0.5365, -0.4696] tanh(z + shift) * half_l - offset\n",
        "\n",
        "\n",
        "\n",
        "levels = torch.tensor([3,3,2])\n",
        "eps = 1e-3\n",
        "\n",
        "half_l = (levels - 1) * (1 - eps) / 2\n",
        "offset = torch.where(levels % 2 == 1, 0.0, 0.5)\n",
        "# print(\"half_l\", half_l)\n",
        "shift = torch.tan(offset / half_l)\n",
        "# print(\"shift\", shift)\n",
        "# print(\"bound\", torch.tanh(x + shift) * half_l - offset)\n",
        "# return torch.tanh(x + shift) * half_l - offset\n",
        "out = torch.tanh(x) * half_l + offset\n",
        "print(out)\n",
        "\n",
        "shift=torch.tan(torch.tensor([1.]))\n",
        "print(shift)\n",
        "bound = torch.tanh(x - shift)\n",
        "print(bound)\n",
        "\n",
        "print(torch.tanh(torch.tensor([0.])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90BTTw0Lr-t",
        "outputId": "a95870e2-bc89-43ba-d40b-febea4ce2382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 256])\n",
            "690080\n"
          ]
        }
      ],
      "source": [
        "# @title ConvEnc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ConvEnc(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[5], d_list[5], 3, 2, 1), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[5], d_list[5], 2, 2, 0), nn.BatchNorm2d(d_list[5]), nn.ReLU(),\n",
        "            # # 2457024\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # 685248\n",
        "\n",
        "            # nn.Conv2d(1, d_list[0], 4, 2, 2), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 4, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 4, 2, 2), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 4, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # # #\n",
        "\n",
        "\n",
        "            nn.Conv2d(1, d_list[0], 4, 4, 0), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 4, 4, 0), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 4, 4, 0), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 4, 4, 0), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            #\n",
        "\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[5],d_model), nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "\n",
        "\n",
        "convenc = ConvEnc(256).to(device)\n",
        "input = torch.rand((4,1,256,256), device=device)\n",
        "out = convenc(input)\n",
        "print(out.shape)\n",
        "print(sum(p.numel() for p in convenc.parameters() if p.requires_grad)) #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B1yvJkX89C_o"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein\n",
        "import torch\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "def wasserstein(x, y, weight=1):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "    # cdf_x, cdf_y = x.cumsum(dim=-1), y.cumsum(dim=-1)\n",
        "    # dist = weight * torch.abs(cdf_x - cdf_y) # Wasserstein dist = L1 norm between CDFs\n",
        "    # cs = (x-y).cumsum(dim=-1)\n",
        "    cs = (x-y) @ torch.tril(torch.ones(x.shape[0], x.shape[0]))\n",
        "    # dist = weight * torch.abs(cs)\n",
        "    dist = weight * cs**2\n",
        "    # dist = weight * (cdf_x - cdf_y)**2 # me\n",
        "    return dist.sum()\n",
        "\n",
        "\n",
        "def soft_wasserstein_loss(x, y, smoothing=0.1):\n",
        "    # Normalise distributions\n",
        "    x = x / x.sum()\n",
        "    y = y / y.sum()\n",
        "    # Compute the cumulative distributions (CDFs) with a small smoothing factor\n",
        "    cdf_x = torch.cumsum(x, dim=-1) + smoothing\n",
        "    cdf_y = torch.cumsum(y, dim=-1) + smoothing\n",
        "    # Compute smooth Wasserstein distance (L2 distance between CDFs)\n",
        "    distance = torch.norm(cdf_x - cdf_y, p=2)  # L2 distance instead of L1 for smoother gradients\n",
        "    return distance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5], dtype=float))\n",
        "x = nn.Parameter(torch.tensor([-0.01, -0.0, -0.99], dtype=torch.float))\n",
        "y = torch.tensor([0.0, 0.0, -1.0], dtype=torch.float)\n",
        "\n",
        "# x = nn.Parameter(torch.rand(1024, dtype=float))\n",
        "# y = torch.rand(1024, dtype=float)\n",
        "# a = len(train_data.buffer)/len(train_data.data) # ratio dided/tt steps\n",
        "a=1/45\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "print(weight)\n",
        "dist = wasserstein(x, y, weight=weight)\n",
        "print(time.time() - start)\n",
        "print(dist)  # Should output 0.7\n",
        "# dist.backward()\n",
        "\n",
        "# 0.0004496574401855469\n",
        "# 0.000331878662109375\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3nfZRhVc9Ssp"
      },
      "outputs": [],
      "source": [
        "# @title wasserstein sinkhorn train\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# agent.eval()\n",
        "# batch_size, T, _ = sx.shape\n",
        "x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "optim = torch.optim.SGD([x], lr=1e-3) # 3e3\n",
        "# optim = torch.optim.AdamW([x], 1e-1, (0.9, 0.999)) # ? 1e0 ; 3e-2 1e-1\n",
        "# optim = torch.optim.AdamW([x], 1e-0, (0.9, 0.95)) # ? 1e0 ; 3e-2 1e-1\n",
        "y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=torch.float)\n",
        "a=1/45\n",
        "weight = torch.where(y < -0.5, 1/a, 1/(1-a))\n",
        "# print(weight)\n",
        "\n",
        "# loss = wasserstein(x, y, weight=weight)\n",
        "# loss = wasserstein(x, y)\n",
        "# loss = sinkhorn(x, y)\n",
        "# loss.backward()\n",
        "# print(x.grad)\n",
        "\n",
        "\n",
        "for i in range(50): # num epochs\n",
        "    loss = wasserstein(x, y, weight=weight)\n",
        "    # loss = sinkhorn(x, y)\n",
        "    # loss = sinkhorn(x, y,0.05,80)\n",
        "    loss.sum().backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    print(x.data, loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "def sinkhorn(x, y, epsilon=0.05, max_iters=100):\n",
        "    # x, y = x / x.sum(), y / y.sum()\n",
        "\n",
        "    # Compute the cost matrix: here the cost is the squared distance between indices\n",
        "    # (|i-j|^2 for each position i, j)\n",
        "    posx = torch.arange(x.shape[-1], dtype=torch.float).unsqueeze(1)\n",
        "    posy = torch.arange(y.shape[-1], dtype=torch.float).unsqueeze(0)\n",
        "    cost_matrix = (posx - posy).pow(2)  # squared distance\n",
        "\n",
        "    # Initialize the dual variables\n",
        "    u = torch.zeros_like(x)\n",
        "    v = torch.zeros_like(y)\n",
        "\n",
        "    # Sinkhorn iterations\n",
        "    K = torch.exp(-cost_matrix / epsilon)  # Kernel matrix, regularised with epsilon\n",
        "    for _ in range(max_iters):\n",
        "        u = x / (K @ (y / (K.t() @ u + 1e-8)) + 1e-8)\n",
        "        v = y / (K.t() @ (x / (K @ v + 1e-8)) + 1e-8)\n",
        "    # print(K,u.data,v.data)\n",
        "    plan = torch.diag(u) @ K @ torch.diag(v)\n",
        "    dist = torch.sum(plan * cost_matrix)\n",
        "    return dist\n",
        "\n",
        "# Example\n",
        "x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float, requires_grad=True)\n",
        "y = torch.tensor([0.0, 0.0, 1.0], dtype=torch.float)\n",
        "# x = nn.Parameter(torch.tensor([0,0,-1,0,0,0,-0.1, 0], device=device))\n",
        "# y = torch.tensor([0,0,0,0,0,0,-1,0], dtype=float)\n",
        "\n",
        "# dist = sinkhorn(x, y)\n",
        "dist = sinkhorn(x, y, 0.05,80)\n",
        "dist.backward()  # To compute gradients with respect to x\n",
        "\n",
        "print(dist.item())\n",
        "print(x.grad)\n",
        "\n",
        "# [2.0000e+07, 3.0000e+07, 1.0000e-08]) tensor([       0.,        0., 49999996.] episodes>=80\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s1_GgDzoDyYB"
      },
      "outputs": [],
      "source": [
        "# @title torchrl.data.PrioritizedReplayBuffer\n",
        "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
        "buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
        "\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "buffer_lazymemmap = ReplayBuffer(storage=LazyMemmapStorage(size), batch_size=32, sampler=SamplerWithoutReplacement())\n",
        "\n",
        "\n",
        "from torchrl.data import ListStorage, PrioritizedReplayBuffer\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "rb = PrioritizedReplayBuffer(alpha=0.7, beta=0.9, storage=ListStorage(10))\n",
        "data = range(10)\n",
        "rb.extend(data)\n",
        "# rb.extend(buffer)\n",
        "\n",
        "\n",
        "sample = rb.sample(3)\n",
        "print(sample)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gcvgdCB1h1_E"
      },
      "outputs": [],
      "source": [
        "# @title torch.optim.LBFGS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Example of a deep nonlinear model f(x)\n",
        "class DeepNonlinearModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNonlinearModel, self).__init__()\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(10, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 50), nn.ReLU(),\n",
        "            nn.Linear(50, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "f = DeepNonlinearModel()\n",
        "# x = torch.randn(1, 10, requires_grad=True)\n",
        "# xx = torch.randn((1,10))\n",
        "x = nn.Parameter(xx.clone())#.repeat(batch,1,1))\n",
        "\n",
        "# Define loss function (mean squared error for this example)\n",
        "target = torch.tensor([[0.0]])  # Target output\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    return loss\n",
        "\n",
        "optimizer = torch.optim.LBFGS([x], lr=1.0, max_iter=5)  # Limit to 2-3 iterations for speed\n",
        "start_time = time.time()\n",
        "for _ in range(2):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step(closure)  # Perform a step of optimisation\n",
        "    print(loss.item())\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "start_time = time.time()\n",
        "optimizer = torch.optim.SGD([x], lr=1e1, maximize=True) # 3e3\n",
        "for _ in range(5):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step()  # Perform a step of optimisation\n",
        "    output = f(x)          # Forward pass through the model\n",
        "    loss = loss_fn(output, target)  # Calculate the loss\n",
        "    loss.backward()         # Backpropagate\n",
        "    optimizer.zero_grad()  # Zero out the gradients\n",
        "    print(loss.item())\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Optimisation completed in {end_time - start_time:.4f} seconds\")\n",
        "print(f\"Final loss: {loss.item()}\")\n",
        "print(f\"Optimised x: {x.detach().numpy()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gfzJ6zoL6vGc"
      },
      "outputs": [],
      "source": [
        "# @title torch.optim.LBFGS\n",
        "\n",
        "# def closure():\n",
        "#     optimizer.zero_grad()  # Zero out the gradients\n",
        "#     output = f(x)          # Forward pass through the model\n",
        "#     loss = loss_fn(output, target)  # Calculate the loss\n",
        "#     loss.backward()         # Backpropagate\n",
        "#     return loss\n",
        "\n",
        "batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "z = nn.Parameter(torch.zeros((batch_size, bptt, 1), device=device))\n",
        "torch.nn.init.normal_(z, mean=0., std=.3/z.shape[-1]**0.5)\n",
        "lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "print(z.squeeze().data[-1])\n",
        "# print(lz.squeeze().data[-1])\n",
        "\n",
        "\n",
        "# for batch, (state, action, reward) in enumerate(train_loader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "sy = agent.jepa.enc(torch.zeros((batch_size, 3,64,64), device=device))#.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "\n",
        "def closure():\n",
        "    lz = torch.cat([z, torch.zeros((batch_size, bptt, agent.dim_z-z.shape[-1]), device=device)], dim=-1)\n",
        "    sy_, h0_ = sy.detach(), h0.detach()\n",
        "    lsy_, lh0 = agent.rnn_it(sy_, la, lz, h0_)\n",
        "    repr_loss = F.mse_loss(lsy, lsy_)\n",
        "    syh0 = torch.cat([lsy, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "    clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "    cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl\n",
        "    cost.backward()\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "    with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "    return cost\n",
        "\n",
        "import time\n",
        "optimizer = torch.optim.LBFGS([z], lr=1e-2, max_iter=10)  # Limit to 2-3 iterations for speed\n",
        "start_time = time.time()\n",
        "for _ in range(20):  # LBFGS does multiple iterations internally\n",
        "    loss = optimizer.step(closure)  # Perform a step of optimisation\n",
        "    print(loss.item())\n",
        "\n",
        "end_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viimAIpYSJq_",
        "outputId": "2377ee32-2d6a-4c90-a91f-93ff4b885315",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6931, 0.3133, 0.6931])\n",
            "tensor([[0.6931, 0.6931],\n",
            "        [0.3133, 1.3133],\n",
            "        [0.6931, 0.6931]])\n"
          ]
        }
      ],
      "source": [
        "# @title test CrossEntropyLoss\n",
        "\n",
        "labels = torch.tensor([0,0,0])\n",
        "pred = torch.tensor([[50.,50.],[1.,0.],[1.,1.]])\n",
        "\n",
        "a=10\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "# loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1/a, 1/(1-a)]))\n",
        "print(loss_fn(pred, labels))\n",
        "\n",
        "# weight=torch.tensor([1/a, 1/(1-a)])\n",
        "weight=torch.tensor([1, 1])\n",
        "# weight=torch.tensor([1/2, 1/2])\n",
        "\n",
        "\n",
        "# print((pred@torch.log(pred).T).sum())\n",
        "# print(nn.Softmax(dim=-1)(pred))\n",
        "# print(-(weight*torch.log(nn.Softmax(dim=-1)(pred))).mean(-1))\n",
        "# print(-(labels.float()@torch.log(nn.Softmax(dim=-1)(pred))))\n",
        "print(-(torch.log(nn.Softmax(dim=-1)(pred))))\n",
        "# print(pred,torch.log(pred).T)\n",
        "\n",
        "arange = torch.arange(pred.shape[-1]).repeat(pred.shape[0],1)\n",
        "# torch.where(1,0).bool()\n",
        "mask=(arange==pred)\n",
        "\n",
        "# 2*pred-1\n",
        "# (1-pred)\n",
        "(pred[mask] + (1-pred[mask]))\n",
        "\n",
        "log_preds = torch.log(torch.softmax(pred, dim=1))\n",
        "target_log_probs = log_preds[range(pred.shape[0]), labels]\n",
        "loss = -torch.mean(target_log_probs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title tensorboard\n",
        "# !pip install tensorboard\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter('runs/molecules')\n",
        "\n",
        "# writer.add_scalar(\"Loss/train\", 3.0, 1)\n",
        "# writer.add_scalar(\"Loss/train\", 2.0, 2)\n",
        "# writer.add_scalar(\"Loss/train\", 1.5, 3)\n",
        "# writer.flush()\n",
        "# writer.close()\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AwRYdovgABiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8WHjFn2gmzI"
      },
      "source": [
        "## plot 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VX5IExbRriwm"
      },
      "outputs": [],
      "source": [
        "# @title sklearn RBF\n",
        "# https://gist.github.com/eljost/2c4e1af652ef02b2989da341c5569af7\n",
        "# from nn_plot.ipynb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import scipy.stats as st\n",
        "\n",
        "# np.random.seed(1)\n",
        "def func(x):\n",
        "    # print(x.shape)\n",
        "    # x= np.sum(x**2, axis=-1)\n",
        "    x=np.random.rand(x.shape[0])\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "res = 50\n",
        "num_pts=15\n",
        "X=np.random.rand(num_pts,2)*res\n",
        "# Y = func(X)\n",
        "Y=np.random.rand(num_pts)\n",
        "# print(X);print(Y)\n",
        "\n",
        "lim = 1\n",
        "# lin = np.linspace(-lim, lim, res)\n",
        "lin = np.linspace(0, res, res)\n",
        "x1, x2 = np.meshgrid(lin, lin)\n",
        "xx = np.vstack((x1.flatten(), x2.flatten())).T\n",
        "\n",
        "kernel = RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
        "gp.fit(X, Y)\n",
        "# print(\"Learned kernel\", gp.kernel_)\n",
        "y_mean, y_cov = gp.predict(xx, return_cov=True)\n",
        "\n",
        "posteriors = st.multivariate_normal.rvs(mean=y_mean, cov=y_cov, size=1)\n",
        "\n",
        "ax = plt.figure().add_subplot(projection='3d')\n",
        "Z=posteriors.reshape(-1, res)\n",
        "# ax.plot_surface(x1, x2, Z)\n",
        "ax.plot_surface(x1, x2, Z, cmap='rainbow', alpha=0.7)\n",
        "\n",
        "# ax.plot_surface(x1, x2, posteriors.reshape(-1, res))\n",
        "ax.contour(x1, x2, Z, zdir='z', offset=-1, cmap='coolwarm') # https://matplotlib.org/stable/gallery/mplot3d/contour3d_3.html#sphx-glr-gallery-mplot3d-contour3d-3-py\n",
        "# ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-0.4, 0.5))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "ax.set(xlim=(0, 50), ylim=(0, 50), zlim=(-1, 2))#, xlabel='X', ylabel='Y', zlabel='Z')\n",
        "\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, c=zdata, cmap='Greens');\n",
        "# ax.scatter3D(X[:, 0], X[:, 1],Y, cmap='Greens');\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusX7gpzxFNL",
        "outputId": "9f14a9da-e188-49ba-f5f5-70192ff33134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.6321], grad_fn=<AddBackward0>)\n",
            "tensor([2.7358]) tensor([-4.7358])\n"
          ]
        }
      ],
      "source": [
        "# @title chatgpt RBFKernelLayer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RBFKernelLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(RBFKernelLayer, self).__init__()\n",
        "        self.centres = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        dists = torch.cdist(x, self.centres, p=2) ** 2\n",
        "        return torch.exp(-dists / (2 * self.sigma ** 2))\n",
        "\n",
        "class SaddlePointNetwork(nn.Module):\n",
        "    def __init__(self, in_features, out_features, sigma=1.0):\n",
        "        super(SaddlePointNetwork, self).__init__()\n",
        "        self.rbf_layer = RBFKernelLayer(in_features, out_features, sigma)\n",
        "        self.linear = nn.Linear(out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rbf_output = self.rbf_layer(x)\n",
        "        # Introduce a saddle point structure\n",
        "        linear_output = self.linear(rbf_output)\n",
        "        # Example saddle function: x^2 - y^2\n",
        "        saddle_output = torch.sum(linear_output[:, :1]**2 - linear_output[:, 1:]**2, dim=1, keepdim=True)\n",
        "        return saddle_output\n",
        "\n",
        "# sin(ax)sin(bx)\n",
        "# (x^2 - y^2)\n",
        "import torch\n",
        "\n",
        "def rbf_saddle(x, y, gamma=1.0, a=1.0, b=1.0):\n",
        "    # RBF-like term\n",
        "    rbf_term = torch.exp(-gamma * torch.norm(x - y, p=2)**2)\n",
        "    # Saddle point term\n",
        "    saddle_term = (a * x)**2 - (b * y)**2\n",
        "    return rbf_term + saddle_term\n",
        "\n",
        "# Example usage\n",
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "output = rbf_saddle(x, y)\n",
        "print(output)\n",
        "\n",
        "# Compute gradients\n",
        "output.backward()\n",
        "print(x.grad, y.grad)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rTmCo7pm0NxL"
      },
      "outputs": [],
      "source": [
        "# @title plot 3d\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "y = torch.linspace(-2 * torch.pi, 2 * torch.pi, 100)\n",
        "X, Y = torch.meshgrid(x, y)\n",
        "Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7fWZaQTDFg1",
        "outputId": "4c5ced88-54f1-436e-89f9-66f1c8396373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000, -0.7231,  0.3792,  0.0000]]) tensor([0.3362])\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# @title shape NN\n",
        "num_pts=1\n",
        "\n",
        "# X=torch.rand(num_pts,4)*2-1\n",
        "# X=torch.cat([torch.tensor([0,0]).unsqueeze(0),torch.rand(num_pts,2)*2-1], dim=-1)\n",
        "X=torch.cat([torch.zeros(1,1),torch.rand(num_pts,2)*2-1,torch.zeros(1,1)], dim=-1)\n",
        "Y=torch.rand(num_pts)\n",
        "print(X,Y)\n",
        "optim = torch.optim.SGD(model.parameters(), 1e-1)\n",
        "\n",
        "# model.train()\n",
        "pred = model(X)\n",
        "# print(Y.shape,pred.shape)\n",
        "# loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "loss = F.mse_loss(Y, pred.squeeze(-1))\n",
        "loss.backward()\n",
        "optim.step()\n",
        "optim.zero_grad()\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "boDd__PE2sGy"
      },
      "outputs": [],
      "source": [
        "# @title plot NN\n",
        "\n",
        "xx = torch.linspace(-1, 1, 100)\n",
        "yy = torch.linspace(-1, 1, 100)\n",
        "X, Y = torch.meshgrid(xx, yy) # [100,100]\n",
        "xy = torch.cat([X.unsqueeze(-1), torch.zeros(X.shape+(2,)), Y.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "with torch.no_grad(): Z = model(xy).squeeze(-1)\n",
        "# print(Z)\n",
        "# print(Z.shape)\n",
        "\n",
        "# Z = rbf_saddle(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X.numpy(), Y.numpy(), Z.numpy(), cmap='viridis')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qW6BYoXsX57o"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle same time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def f(x, y):\n",
        "    return x ** 2 - y ** 2 + x * y\n",
        "# (x-y)(x+y)+xy\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "dim_x, dim_z = 3, 8\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "xx = torch.empty((1, T, dim_x))\n",
        "torch.nn.init.xavier_uniform_(xx)\n",
        "# x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "\n",
        "# tensor([[0.6478, 0.0531, 0.0861]]) tensor([[-1.,  1.]]) 0.2974517047405243\n",
        "# tensor([-0.9419, -1.0000,  0.4416, -1.0000,  1.0000,  0.2963])\n",
        "\n",
        "# x = nn.Parameter(torch.tensor([[0.6478, 0.0531, 0.0861]]))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "\n",
        "z = nn.Parameter(torch.empty((batch, T, dim_z)))\n",
        "# z = torch.empty((1, T, 1))\n",
        "torch.nn.init.xavier_uniform_(z)\n",
        "# z = nn.Parameter(z.repeat(batch,1,1))\n",
        "# z = nn.Parameter(torch.tensor([[-1.,  1.]]))\n",
        "# optim_z = torch.optim.SGD([z], lr=ratio*lr, maximize=True) # 3e3\n",
        "# optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.95), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "optim_z = torch.optim.AdamW([z], ratio*lr, (0.9, 0.999), maximize=True) # 1e0 ; 3e-2 1e-1\n",
        "# .95,1e-1,3e-1\n",
        "# .99,\n",
        "\n",
        "d_model = 4\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(x.shape[-1]+z.shape[-1],d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model,1), nn.LeakyReLU(),\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(10): # num epochs\n",
        "    # loss = f(x,z)\n",
        "    # loss = f(x.sum(-1),z)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step(); optim_z.step()\n",
        "    optim_x.zero_grad(); optim_z.zero_grad()\n",
        "    # print(i,x.squeeze(), z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    print(i,x.squeeze()[0].data, z[0].squeeze().data, loss[0].squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "        z.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "print(loss.squeeze())\n",
        "idx = torch.argmin(loss) # choose best x even with greatest adv z\n",
        "# idx = torch.argmax(loss)\n",
        "# print(x[idx],z[idx],loss[idx])\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx].data,loss[idx].item())\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GJdFpDr2wIMT"
      },
      "outputs": [],
      "source": [
        "# @title test optim saddle argm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def argm(sx, lr=3e3): # 3e3\n",
        "    # batch=sx.size(dim=0)\n",
        "    batch_size, T, _ = sx.shape\n",
        "    batch = 16\n",
        "    # z = nn.Parameter(torch.zeros((batch,1),device=device))\n",
        "    # z = nn.Parameter(torch.empty((1,batch, T, dim_z)))\n",
        "    z = nn.Parameter(torch.empty((batch_size,batch, T, dim_z)))\n",
        "    torch.nn.init.xavier_uniform_(z)\n",
        "    # optim = torch.optim.SGD([z], lr=lr, maximize=True)\n",
        "    optim = torch.optim.AdamW([z], 1e1, (0.9, 0.95), maximize=True)\n",
        "    sx = sx.detach().unsqueeze(1).repeat(1,batch,1,1)\n",
        "    # sx = sx.detach()\n",
        "    for i in range(20): # 10\n",
        "        # print(sx.shape,z.shape)\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            cost = model(sxz)\n",
        "        cost.sum().backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "        # print(\"argm cost z\",i,cost.item(), z.detach().item())\n",
        "        # print(\"argm cost z\",i,cost.squeeze(), z.detach().squeeze())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    # return z.detach()\n",
        "    print(cost.squeeze().data)\n",
        "    idx = torch.argmax(cost.squeeze(), dim=1)\n",
        "    return z[torch.arange(z.shape[0]),idx].detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch=16\n",
        "T=1\n",
        "# x = nn.Parameter(torch.empty((batch, T, dim_x)))\n",
        "# torch.nn.init.xavier_uniform_(x)\n",
        "# x = nn.Parameter(xx.clone())\n",
        "x = nn.Parameter(xx.clone().repeat(batch,1,1))\n",
        "\n",
        "lr = 3e-2 # sgd 1e-1,1e-0,1e4 ; adamw 1e-1\n",
        "# ratio = 6e0\n",
        "lr = 1e-1 # adamw 1e-1\n",
        "ratio = 4\n",
        "# optim_x = torch.optim.SGD([x], lr=lr)\n",
        "# optim_x = torch.optim.AdamW([x], lr, (0.9, 0.95)) # 1e-1 ; 1e-2 3e-2\n",
        "optim_x = torch.optim.AdamW([x], lr, (0.9, 0.999)) # 1e-1 ; 1e-2 3e-2\n",
        "# print(x.shape)\n",
        "\n",
        "\n",
        "# print(\"search\",x.squeeze().data, z.squeeze())\n",
        "# print(\"search\",x.squeeze().data, z.squeeze().item())\n",
        "for i in range(50):\n",
        "    z = argm(x)\n",
        "    # print(x.shape,z.shape)\n",
        "    xz = torch.cat([x,z], dim=-1)\n",
        "    loss = model(xz)\n",
        "    loss.sum().backward()\n",
        "    optim_x.step()\n",
        "    optim_x.zero_grad()\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.sum().item())\n",
        "    # print(i,x.squeeze().data, z.squeeze().data, loss.squeeze().item())\n",
        "    # print(i,x.squeeze()[0], z.squeeze(), loss.squeeze().item())\n",
        "    # print(i,x[0].squeeze().data, z[0].squeeze().data, loss.squeeze().item())\n",
        "    with torch.no_grad():\n",
        "        # x /= torch.norm(x, dim=-1).unsqueeze(-1).clamp_(min=1) # need x in place\n",
        "        x.clamp_(min=-1, max=1)\n",
        "    # print(i,x.squeeze().data, z.squeeze().item(), loss.squeeze().item())\n",
        "\n",
        "# xz = torch.cat([x,z], dim=-1)\n",
        "# loss = model(xz)\n",
        "# print(\"z\",z)\n",
        "# print(loss.squeeze())\n",
        "idx = torch.argmin(loss)\n",
        "print(x[idx].data,z[idx],loss[idx].item())\n",
        "\n",
        "print(torch.cat([x,z,loss],dim=-1).squeeze().data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvjIJP6RlEv2",
        "outputId": "447fdefd-452b-437d-c228-1847492b36f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.randn(16, 16)\n",
        "# print((b==torch.max(b)).nonzero())\n",
        "x = torch.randn(10, 3)\n",
        "idx = torch.randint(3,(10,))\n",
        "# print(x[:,idx].shape)\n",
        "print(x[torch.arange(x.shape[0]),idx].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUhKd009Qvk3"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fsealXK3OPQa"
      },
      "outputs": [],
      "source": [
        "# @title train test function\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def strain(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            x1, x2 = trs(x)\n",
        "            loss = model.loss(x1,x2)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        optimizer.zero_grad()\n",
        "        # model.conv_ema.update_parameters(model.conv)\n",
        "        # model.exp_ema.update_parameters(model.exp)\n",
        "\n",
        "        scaler.update()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        train_loss = loss.item()/len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x1, x2 = trs(x)\n",
        "        loss = model.loss(x1,x2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    return loss_list\n",
        "\n",
        "\n",
        "# def ctrain(dataloader, model, loss_fn, optimizer, scheduler=None, verbose=True):\n",
        "def ctrain(dataloader, model, loss_fn, optimizer, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = model(x)\n",
        "        pred = model.classify(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch % (size//10) == 0:\n",
        "        # if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(x)\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x = model(x)\n",
        "            pred = model.classify(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= len(dataloader)\n",
        "    correct /= len(dataloader.dataset)\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zOB1Kh3jL6YV"
      },
      "outputs": [],
      "source": [
        "# @title rnn train, gen\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred,_ = model(X)\n",
        "        loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = loss.item()/ len(X)\n",
        "\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, bptt=32):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # hid = model.init_hidden(bptt)\n",
        "        hid = model.init_hidden(X.shape[0])\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # print(\"X.shape:\",X.shape) # [batch_size, seq_len]\n",
        "        Xs, ys = torch.split(X, bptt, dim=1), torch.split(y, bptt, dim=1)\n",
        "        for (X, y) in zip(Xs, ys): # https://discuss.pytorch.org/t/how-to-train-a-many-to-many-lstm-with-bptt/13005/10\n",
        "            optimizer.zero_grad()\n",
        "            # print(\"X.shape:\",X.shape) # [batch_size, bptt]\n",
        "            pred, hid = model(X, hid)\n",
        "            loss = loss_fn(pred.reshape(-1,pred.shape[-1]), y.flatten())\n",
        "            # loss = loss_fn(pred.flatten(0,1), y.flatten())\n",
        "            # loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            hid = hid.detach()\n",
        "\n",
        "        train_loss = loss.item()/ len(X)\n",
        "        try: wandb.log({\"train loss\": train_loss})\n",
        "        except: pass\n",
        "        # if batch % 100 == 0:\n",
        "        #     loss, current = loss.item(), batch * len(X)\n",
        "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "def generate(model, context, max_steps = 64, temperature=1):\n",
        "    # x = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    x=ix = torch.tensor([train_dataset.stoi.get(c) for c in context], device=device).unsqueeze(0)\n",
        "    model.eval()\n",
        "    hidden=None\n",
        "    with torch.no_grad():\n",
        "        for n in range(max_steps):\n",
        "            # output, hidden = model(x, hidden)\n",
        "            output, hidden = model(ix, hidden)\n",
        "            hidden=hidden[:, -1, :].unsqueeze(1)\n",
        "            output = output[:, -1, :] # get logit for last character\n",
        "            output = output/temperature\n",
        "            output = F.softmax(output, dim = -1) # vocab_size to char\n",
        "            ix = torch.multinomial(output, num_samples = 1) # rand sample by output distribution\n",
        "            x = torch.cat((x, ix),1)\n",
        "        completion = ''.join([train_dataset.itos[int(i)] for i in x.flatten()])\n",
        "        return completion\n",
        "\n",
        "# out=generate(model, \"A wi\")\n",
        "# print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9OFjAK232GNp"
      },
      "outputs": [],
      "source": [
        "# @title mha\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "\n",
        "class MHAme(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor((self.head_dim,), dtype=torch.float, device=device))\n",
        "\n",
        "    def forward(self, query, key, value, mask=None): # [batch_size, seq_len, d_model]\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.q(query).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # [batch_size, n_heads, seq_len, head_dim]\n",
        "        K = self.k(key).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v(value).view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        # attn = torch.matmul(Q, K.transpose(2, 3)) / self.scale\n",
        "        attn = Q @ K.transpose(2, 3) / self.scale # [batch_size, n_heads, seq_len, seq_len]\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(attn, dim=-1)\n",
        "        # x = torch.matmul(self.drop(attention), V)\n",
        "        x = self.drop(attention) @ V # [batch_size, n_heads, seq_len, head_dim]\n",
        "        x = x.transpose(1, 2).reshape(batch_size, -1, self.d_model) # [batch_size, seq_len, d_model]\n",
        "        x = self.lin(x)\n",
        "        return x, attention\n",
        "\n",
        "# @title test mha\n",
        "# import torch\n",
        "# batch_size=3\n",
        "# L=5\n",
        "# d_model=8\n",
        "# n_heads=2\n",
        "\n",
        "# trg = torch.rand(batch_size,L, d_model)\n",
        "# src = torch.rand(batch_size,L, d_model)\n",
        "\n",
        "# mha = MultiHeadAttention(d_model, n_heads)\n",
        "# x, attn = mha(trg,src,src)\n",
        "\n",
        "# head_dim = d_model // n_heads\n",
        "\n",
        "# # trg1=trg.view(batch_size, -1, n_heads, head_dim).transpose(1, 2)\n",
        "# trg=trg.view(batch_size, n_heads, -1, head_dim)\n",
        "# src=src.view(batch_size, n_heads, -1, head_dim)\n",
        "# # print(trg1)\n",
        "# # print(\"##########\")\n",
        "# # print(trg2)\n",
        "# attn = trg @ src.transpose(2, 3)\n",
        "# x=attn@trg\n",
        "# print(x.shape)\n",
        "# print(attn.shape)\n",
        "\n",
        "# # trg1=trg1.view(batch_size,L, d_model)\n",
        "# trg1=trg1.reshape(batch_size,L, d_model)\n",
        "# trg2=trg2.view(batch_size,L, d_model)\n",
        "# print(trg1)\n",
        "# print(\"##########\")\n",
        "# print(trg2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HcOidvtW9KAH"
      },
      "outputs": [],
      "source": [
        "# @title from RNN2\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, h0=None, c0=None): # [batch_size, seq_len, input_size]\n",
        "        if h0 is None: h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        if c0 is None: c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        out, h0 = self.rnn(x, h0)\n",
        "        # out, (h0,c0) = self.lstm(x, (h0,c0))\n",
        "        # out:(batch_size, seq_length, hidden_size) (n, 28, 128)\n",
        "        out = out[:, -1, :] # out: (n, 128)\n",
        "        out = self.fc(out) # out: (n, 10)\n",
        "        return out\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "\n",
        "d_model,dim_a,dim_z = 256,3,1\n",
        "pred = nn.Sequential(\n",
        "    nn.Linear(d_model+dim_a+dim_z, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "    nn.Linear(d_model, d_model),\n",
        "    )\n",
        "gru = torch.nn.GRU(d_model+dim_a+dim_z, d_model, num_layers=1, batch_first=True, dropout=0.0)\n",
        "\n",
        "print(sum(p.numel() for p in pred.parameters() if p.requires_grad)) # 264192\n",
        "print(sum(p.numel() for p in gru.parameters() if p.requires_grad)) # 397824\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZDtHEU4tCo5z"
      },
      "outputs": [],
      "source": [
        "# @title torch gru\n",
        "# text_generation.ipynb https://colab.research.google.com/drive/1SguQZQYZBaalRuElJcxGdgF3YxhiwkAM\n",
        "# RNNs.ipynb https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR\n",
        "\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class gru(nn.Module):\n",
        "    def __init__(self, emb_dim, rnn_units, num_layers):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(emb_dim, rnn_units, num_layers=num_layers, dropout=0.0, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.rnn_units = rnn_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.rnn_units, device=device) # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        if hidden is None: hidden = self.init_hidden(x.shape[0])\n",
        "        # print('fwd',x.shape, hidden.shape) # fwd [batch_size, bptt, emb_dim], [num_layers, batch_size, rnn_units]\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.dense(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "emb_dim = 256#256\n",
        "rnn_units = 1024#1024\n",
        "num_layers = 1\n",
        "# model = gru(emb_dim, rnn_units, num_layers).to(device)\n",
        "# model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5pscE7mtaPAq"
      },
      "outputs": [],
      "source": [
        "# @title ltm\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "class Ltm():\n",
        "    def __init__(self, ltmk=None, ltmv=None):\n",
        "        self.index = None\n",
        "        if ltmk is None:\n",
        "            self.ltmk = torch.tensor([])\n",
        "            self.ltmv = torch.tensor([])\n",
        "        else:\n",
        "            self.ltmk = ltmk # [len_ltm, d_model]\n",
        "            self.ltmv = ltmv\n",
        "        if len(self.ltmk)>=100:\n",
        "            self.index = makefaissindex(ltmk)\n",
        "\n",
        "    # def add(self, k, v):\n",
        "    def add(self, k, v, mask=None):\n",
        "        # self.ltmk.append(k)\n",
        "        # self.ltmv.append(v)\n",
        "        if k==None: return\n",
        "        if k.ndim==1: k, v = k.unsqueeze(0), v.unsqueeze(0)\n",
        "        if mask==None:\n",
        "            self.ltmk = torch.cat([self.ltmk, k], dim=1)\n",
        "            self.ltmv = torch.cat([self.ltmv, v], dim=1)\n",
        "        else:\n",
        "            self.ltmk[mask] = torch.cat([self.ltmk[mask], k], dim=1)\n",
        "            self.ltmv[mask] = torch.cat([self.ltmv[mask], v], dim=1)\n",
        "        if self.index:\n",
        "            self.index.add(k)\n",
        "            if torch.rand(1)<0.1:\n",
        "                self.index.train(self.ltmk)\n",
        "\n",
        "    def makefaissindex(self, vert_store):\n",
        "        d = vert_store.shape[-1]\n",
        "        nlist = 100\n",
        "        index = faiss.IndexFlatL2(d) # no need train # 1-Flat.py\n",
        "        index = faiss.IndexIVFFlat(index, d, nlist, faiss.METRIC_L2) # 2-IVFFlat.py\n",
        "        if not index.is_trained: index.train(vert_store)\n",
        "        index.add(vert_store)\n",
        "        return index\n",
        "\n",
        "    def vecsearch(self, query, k=5, treshold=36): # k nearest neighbors\n",
        "        # index.nprobe = 5 # 1\n",
        "        D, I = self.index.search(query, k) # dist, idx\n",
        "        D, I = D[0], I[0]\n",
        "        mask = I[D<treshold]\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, query, k=5, treshold=36): # [batch_size, d_model]\n",
        "        if self.index!=None and len(self.ltmk)>=100:\n",
        "            mask = self.vecsearch(query, k, treshold)\n",
        "            rag = self.ltmk[mask] # [len_rag, d_model]\n",
        "        else:\n",
        "            rag = self.ltmk\n",
        "        if len(rag)==0: return 0\n",
        "        # print(\"ltm call\", query.shape, rag.shape)\n",
        "        # attn = query @ rag.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ rag.transpose(-1,-2) # [batch_size, 1, d_model] @ [batch_size, d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.ltmv\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def remove_ids(self, removing): # torch.tensor indexes\n",
        "        mask = torch.ones(len(self.ltmk), dtype=torch.bool)\n",
        "        mask[removing] = False\n",
        "        self.ltmk, self.ltmv = self.ltmk[mask], self.ltmv[mask]\n",
        "        if self.index: self.index = makefaissindex(ltmk)\n",
        "\n",
        "    def save(file='ltm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.ltmk, self.ltmv), f)\n",
        "\n",
        "    def load(file='ltm.pkl'):\n",
        "        with open(file, 'rb') as f: self.ltmk, self.ltmv = pickle.load(f)\n",
        "\n",
        "ltm = Ltm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2V6qDLPrOlBU"
      },
      "outputs": [],
      "source": [
        "# @title stm\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "class Stm():\n",
        "    def __init__(self, stmk=None, stmv=None, meta=None):\n",
        "        self.stmk = stmk # [len_ltm, d_model]\n",
        "        self.stmv = stmv\n",
        "        self.meta = meta\n",
        "\n",
        "    def __call__(self, query):\n",
        "        # if len(rag)==0: return 0\n",
        "        # print(\"stm call\", query.shape, self.stmk.shape)\n",
        "        # attn = query @ self.stmk.T # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attn = query.unsqueeze(1) @ self.stmk.transpose(-1,-2) # [batch_size, d_model] @ [d_model, len_ltm] = [batch_size, len_ltm]\n",
        "        attention = torch.softmax(attn, dim=-1) # [batch_size, len_ltm]\n",
        "        x = attention @ self.stmv\n",
        "        self.meta = self.meta + attn.squeeze() # attention\n",
        "        return x # [batch_size, d_model]\n",
        "\n",
        "    def add(self, k, v):\n",
        "        if k.ndim==1:\n",
        "            k=k.unsqueeze(0)\n",
        "            v=v.unsqueeze(0)\n",
        "        self.stmk = torch.cat([self.stmk, k], dim=1)\n",
        "        self.stmv = torch.cat([self.stmv, v], dim=1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1,1)], dim=-1)\n",
        "        self.meta = torch.cat([self.meta, torch.ones(self.meta.shape[0],1)], dim=-1)\n",
        "        # self.meta = torch.cat([self.meta, torch.ones(1)])\n",
        "\n",
        "    def decay(self, g=0.9, k=256):\n",
        "        self.meta = g*self.meta # decay\n",
        "        mask = self.meta>0.001 # forget not retrieved\n",
        "        self.stmk, self.stmv = self.stmk[mask], self.stmv[mask]\n",
        "        self.meta = self.meta[mask]\n",
        "\n",
        "        topk = torch.topk(self.meta, k)#, dim=None, largest=True, sorted=True\n",
        "        self.meta = topk.values # cap stm size\n",
        "        self.stmk, self.stmv = self.stmk[topk.indices], self.stmv[topk.indices]\n",
        "\n",
        "    def pop(self, t=5):\n",
        "        # if important long term, if\n",
        "        mask = self.meta>t # to pop to ltm\n",
        "        popk, popv = self.stmk[mask], self.stmv[mask]\n",
        "        self.stmk, self.stmv = self.stmk[~mask], self.stmv[~mask]\n",
        "        self.meta = self.meta[~mask]\n",
        "        return popk, popv, mask.any(dim=-1)\n",
        "\n",
        "    def save(file='stm.pkl'):\n",
        "        with open(file, 'wb') as f: pickle.dump((self.stmk, self.stmv, self.meta), f)\n",
        "\n",
        "    def load(file='stm.pkl'):\n",
        "        with open(file, 'rb') as f: self.stmk, self.stmv, self.meta = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3EGwfW9HxOMj"
      },
      "outputs": [],
      "source": [
        "# @title split params to train\n",
        "# qkv for useful for critic predicting cost?\n",
        "\n",
        "# train after each step: jepa(pred)(using SL)?\n",
        "\n",
        "# train after each episode: critic, jepa()\n",
        "\n",
        "\n",
        "# jepa is batch of same length episodes, take from history\n",
        "# cost is single full episode buffer\n",
        "\n",
        "# or combine string of episode buffers, batchify like rnn training\n",
        "\n",
        "\n",
        "# batch_size = 64\n",
        "# weights = torch.ones(len(buffer))#.expand(batch_size, -1)\n",
        "# index = torch.multinomial(weights, num_samples=batch_size, replacement=False)\n",
        "# buffer[index]\n",
        "\n",
        "\n",
        "for name, p in agent.named_parameters():\n",
        "    print(name, 'tcost' in name)\n",
        "# https://pytorch.org/docs/stable/optim.html#per-parameter-options4\n",
        "# optim.SGD([\n",
        "#                 {'params': others},\n",
        "#                 {'params': bias_params, 'weight_decay': 0}\n",
        "#             ], weight_decay=1e-2, lr=1e-2)\n",
        "\n",
        "tcost_params = [p for name, p in agent.named_parameters() if 'tcost' in name]\n",
        "others = [p for name, p in agent.named_parameters() if 'tcost' not in name]\n",
        "\n",
        "# # joptim = torch.optim.AdamW(agent.jepa.parameters(), lr=1e-3)\n",
        "# joptim = torch.optim.AdamW([agent.jepa.parameters(),agent.q.parameters(), agent.k.parameters(), agent.v.parameters()], lr=1e-3)\n",
        "# coptim = torch.optim.AdamW(agent.tcost.parameters(), lr=1e-3)\n",
        "joptim = torch.optim.AdamW(tcost_params, lr=1e-3)\n",
        "coptim = torch.optim.AdamW(others, lr=1e-3)\n",
        "agent.train(buffer, joptim, coptim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IcEM4HCwCKbl"
      },
      "outputs": [],
      "source": [
        "# @title assorted\n",
        "# print(type(buffer[0][0]))\n",
        "# print(buffer[0][0])\n",
        "# print(buffer[0][0].dtype)\n",
        "import numpy as np\n",
        "\n",
        "# b=np.random.randint(low=0, high=256, size=(1000, 64, 64, 3), dtype='uint8')\n",
        "b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(1000)]\n",
        "# print(b.shape)\n",
        "# print(b[0])\n",
        "def custom_collate(original_batch):\n",
        "    return original_batch\n",
        "\n",
        "train_data = BufferDataset(b, seq_len) # one line of poem is roughly 50 characters\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = False, batch_size = batch_size, collate_fn=custom_collate) # num_workers = 4\n",
        "# train_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "    # def plan(self, ): # mpc\n",
        "    #     # xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "    #     xs, us = locuslab_mpc(x_init, goal_state, self.jepa)\n",
        "\n",
        "# def train_cost(self, dataloader, buffer, optim):\n",
        "\n",
        "#         c = c + self.icost(world_state_) + reward\n",
        "#         c_ = c_ + cost\n",
        "#     closs = nn.MSELoss()(c,c_) # L1Loss MSELoss ; Sum reward\n",
        "#     closs.backward()\n",
        "#     optim.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j058IfyZKWUj",
        "outputId": "afb580da-32c1-4fa3-c5eb-9af659a24945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "16\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title custom transforms ToTensorme\n",
        "import torchvision.transforms as transforms\n",
        "# 100,3\n",
        "# seq_len,\n",
        "# for batch, Sar in enumerate(train_data):\n",
        "for batch, Sar in enumerate(train_loader):\n",
        "# for batch, (State, Action, Reward) in enumerate(train_loader):\n",
        "# for batch, (Sar,_) in enumerate(train_loader):\n",
        "    # print(len(Sar[0]))\n",
        "    # print(Sar[0][0].shape)\n",
        "    # State, Action, Reward = zip(*Sar)\n",
        "    # State=Sar\n",
        "    break\n",
        "for s,a,r in zip(*Sar):\n",
        "    state=s\n",
        "    break\n",
        "print(len(State))\n",
        "print(len(State[0]))\n",
        "print(type(State[0]))\n",
        "\n",
        "\n",
        "# transforms.Lambda(lambda x : torch.clamp(x, 0., 1.)),\n",
        "\n",
        "# def ToTensorme(x):\n",
        "#     print(\"ToTensorme\",type(x))\n",
        "#     # if type(x) == np.ndarray: return x.astype(np.float32)\n",
        "#     # if type(x) == np.ndarray: return torch.from_numpy(x).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.permute(2,0,1).to(torch.float32)\n",
        "#     if type(x) == torch.Tensor: return x.permute(0,3,1,2).to(torch.float32)\n",
        "#     # if type(x) == torch.Tensor: return x.to(torch.float32)\n",
        "\n",
        "# # transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# transform = transforms.Compose([transforms.Lambda(ToTensorme), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# # transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Lambda(ToTensorme)])\n",
        "# # https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
        "\n",
        "print(State[0].shape)\n",
        "# out=transform(State[0][0])\n",
        "# out=transform(State[0])\n",
        "# out=transform(list(State[0]))\n",
        "# print(out)\n",
        "\n",
        "# State = torch.tensor(State)\n",
        "# print(State.shape)\n",
        "\n",
        "# State[:,,]\n",
        "# l=99\n",
        "# lst=list(range(0,l,7))[1:]+[l]\n",
        "# print(lst)\n",
        "\n",
        "\n",
        "# b=[np.random.randint(low=0, high=256, size=(64, 64, 3), dtype='uint8') for _ in range(10)]\n",
        "# for state in b:\n",
        "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#     transform(state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jp3Bx_W_TqZ3"
      },
      "outputs": [],
      "source": [
        "# @title batch pop to ltm\n",
        "import torch\n",
        "batch_size=8\n",
        "d_model=4\n",
        "# stmk=torch.rand(batch_size, 5, d_model)\n",
        "# stmv=torch.rand(batch_size, 5, d_model)\n",
        "# ltmk=torch.rand(batch_size, 5, d_model)\n",
        "# ltmv=torch.rand(batch_size, 5, d_model)\n",
        "# meta=torch.rand(batch_size, 5)*7\n",
        "# mask = meta>5 # to pop to ltm\n",
        "# popk, popv = stmk[mask], stmv[mask]\n",
        "# print(popk.shape, popv.shape)\n",
        "# stmk, stmv = stmk[~mask], stmv[~mask]\n",
        "# meta = meta[~mask]\n",
        "# # return popk, popv\n",
        "\n",
        "\n",
        "# out=torch.rand(batch_size, 1, d_model)\n",
        "out=[torch.rand(1, d_model) for _ in range(batch_size)]\n",
        "lst=torch.rand(batch_size, 5, d_model)\n",
        "mask=torch.rand(batch_size, 5) > 0.5\n",
        "# out = torch.cat([out,lst[mask]], dim=1)\n",
        "# batch, row = torch.where(mask)\n",
        "# print(batch, row)\n",
        "# out = torch.cat([out,lst[torch.where(mask)]], dim=1)\n",
        "# print(out[batch].shape,lst[batch, row,:].shape)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:]], dim=1)\n",
        "# out[batch] = torch.cat([out[batch],lst[batch, row,:].unsqueeze(1)], dim=1)\n",
        "\n",
        "for b, m in enumerate(mask):\n",
        "    # out[b] = torch.cat([out[b],lst[b][m]], dim=1)\n",
        "    out[b] = torch.cat([out[b],lst[b][m]])\n",
        "\n",
        "\n",
        "\n",
        "# num_masked = mask.sum(dim=1, keepdim=True)\n",
        "# masked_elements = lst[torch.arange(lst.size(0))[:, None], mask]\n",
        "# zeros = torch.zeros(batch_size, num_masked.max(), d_model)\n",
        "# output = zeros.scatter(dim=1, index=masked_elements.nonzero(as_tuple=True)[1], src=masked_elements)\n",
        "# torch.cat([out, output], dim=1)\n",
        "\n",
        "# empty_mask = ~mask.any(dim=1)  # Find rows where all mask values are False\n",
        "# padded_lst = torch.zeros(batch_size, 1, d_model)  # Create a zero tensor for padding\n",
        "# padded_lst[~empty_mask] = lst[mask][~empty_mask]  # Fill non-empty masks with selected values\n",
        "# out = torch.cat([out, padded_lst], dim=1)\n",
        "\n",
        "\n",
        "# print(mask)\n",
        "# print(mask[:, None])\n",
        "# print(mask[:, None].expand(-1, lst.size(1), -1))\n",
        "\n",
        "# out = torch.cat([out, lst[mask[:, None].expand(-1, lst.size(1), -1)]], dim=1)\n",
        "# out = torch.cat([out, lst[mask[:, None]]], dim=1)\n",
        "\n",
        "# print(out.shape)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4vBx6CBgoTG"
      },
      "outputs": [],
      "source": [
        "# @title straight through estimator\n",
        "class STEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return (input > 0).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return F.hardtanh(grad_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gJ3X_hQelW2x"
      },
      "outputs": [],
      "source": [
        "# @title train\n",
        "\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(1, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            # nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[3],d_model), nn.ReLU(),\n",
        "            # nn.Linear(d_model,10),\n",
        "        )\n",
        "\n",
        "        mul=4\n",
        "        self.tcost = nn.Sequential( # trained cost\n",
        "            # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "            nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "            nn.Dropout(), nn.Linear(mul*d_model, 10),\n",
        "            )\n",
        "    # def forward(self, x): return self.cnn(x)\n",
        "\n",
        "model = Agent(d_model=256).to(device)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.no_grad(): sx = model.cnn(image)\n",
        "        # print(sx.shape, r.shape)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(model.tcost(sx), r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        # except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wi4ODp-XlZoU"
      },
      "outputs": [],
      "source": [
        "# @title mnist data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "# test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 64 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QYbOgNoZn6JL"
      },
      "outputs": [],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = get_res(10).to(device)\n",
        "# model = get_res(2).to(device)\n",
        "\n",
        "class Agent(torch.nn.Module):\n",
        "    def __init__(self, d_model = 256):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "        d_list=[32, 64, 128, 256, 256, 256] #\n",
        "        # d_list = [min(d, d_model) for d in d_list]\n",
        "        self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "            nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "            nn.Linear(d_model,1),\n",
        "        )\n",
        "    def forward(self, x): return self.cnn(x)\n",
        "model=Agent().to(device)\n",
        "\n",
        "\n",
        "# loss_function = torch.nn.CrossEntropyLoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    for image, r in train_loader:\n",
        "        image, r = image.to(device), r.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            pred = model(image).squeeze(-1) # squeeze impt for regression!!!\n",
        "            # print(pred.shape, r.shape)\n",
        "            loss = loss_function(pred, r)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "\n",
        "    images,r = next(iter(train_loader))\n",
        "    with torch.no_grad():\n",
        "        # pred = model(images.to(device)).argmax(-1).cpu()\n",
        "        pred = model(images.to(device)).squeeze(-1).cpu()\n",
        "        print(r)\n",
        "        print(pred)\n",
        "        print((r==pred).sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_kcajtpjr7Io"
      },
      "outputs": [],
      "source": [
        "# @title bin clss\n",
        "# def train(model, train_loader, loss_function, optimizer):\n",
        "#     model.train()\n",
        "#     for image, _ in train_loader:\n",
        "#         image = image.to(device)#.reshape(-1, 28*28)\n",
        "#         reconstructed = model(image)\n",
        "#         loss = loss_function(reconstructed, image)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "\n",
        "# class Agent(torch.nn.Module):\n",
        "#     def __init__(self, d_model = 256):\n",
        "#         super().__init__()\n",
        "#         # d_list=[32, 64, 128, 256, 512, 1024] #\n",
        "#         d_list=[32, 64, 128, 256, 256, 256] #\n",
        "#         # d_list = [min(d, d_model) for d in d_list]\n",
        "#         self.cnn = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "#             nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "#             nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(),\n",
        "#             # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "#             nn.Flatten(start_dim=1),\n",
        "#             # nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "#             nn.Linear(4*d_list[4],d_model), nn.ReLU(),\n",
        "#             nn.Linear(d_model,1),\n",
        "#         )\n",
        "#     def forward(self, x): return self.cnn(x)\n",
        "\n",
        "d_model = 256\n",
        "# tcost = nn.Sequential( # trained cost\n",
        "#     # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.LeakyReLU(),\n",
        "#     nn.Linear(d_model, 1),\n",
        "#     ).to(device)\n",
        "mul=4\n",
        "tcost = nn.Sequential( # trained cost\n",
        "    # nn.Linear(d_model+dim_a, d_model), nn.ReLU(),\n",
        "    nn.Dropout(), nn.Linear(d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, mul*d_model), nn.LeakyReLU(),\n",
        "    nn.Dropout(), nn.Linear(mul*d_model, 2),\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "# agent = Agent(d_model=256).to(device)\n",
        "# optim = torch.optim.AdamW(agent.parameters(), 1e-2, (0.9, 0.95))\n",
        "optim = torch.optim.AdamW(tcost.parameters(), 1e-3, (0.9, 0.95))\n",
        "# optim.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# loss_function = torch.nn.MSELoss()\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "def train_cost(model, dataloader, optim, loss_function=loss_function):\n",
        "    model.train()\n",
        "    tcost.train()\n",
        "    for batch, (st, r) in enumerate(dataloader):\n",
        "        st, r = st.to(device), r.to(device)#.squeeze(-1)\n",
        "        # st.requires_grad=True; r.requires_grad=True\n",
        "        # print(st.requires_grad, r.requires_grad)\n",
        "        # loss = F.mse_loss(model.tcost(model.jepa.enc(st)), r)\n",
        "        # print(model.jepa.enc(st))\n",
        "        # loss = loss_function(model.tcost(model.jepa.enc(st)), r)\n",
        "        with torch.no_grad(): sx = model.jepa.enc(st)\n",
        "        with torch.amp.autocast('cuda'): loss = loss_function(tcost(sx), r)\n",
        "        # print(tcost(sx).squeeze(-1))\n",
        "        # loss = loss_function(model(st), r)\n",
        "        # print(next(model.tcost[0].parameters()).grad)\n",
        "        # print(next(model.jepa.enc.parameters()).grad)\n",
        "        # print(model.tcost.parameters()[0].grad)\n",
        "        # print(loss)\n",
        "        # loss.backward()\n",
        "        # optim.step()\n",
        "        # optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "        optim.zero_grad()\n",
        "        print(loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except: pass\n",
        "\n",
        "\n",
        "# for i in range(30):\n",
        "#     train_cost(agent, c_loader, optim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Su8Op3bw0OIT"
      },
      "outputs": [],
      "source": [
        "# @title train_ae\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'): # automatic mixed percision\n",
        "                    # print(\"train jepa world_state_\", world_state_) # 8.2697 # 2.0750e-11\n",
        "                    sy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "                    # sy = self.jepa.enc_ema(world_state_.flatten(start_dim=1)) # [batch_size, d_model]\n",
        "\n",
        "                    # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(sy))\n",
        "                    # jloss = std_loss + cov_loss\n",
        "\n",
        "                    # state_ = self.deconv(sy.detach()) # pure jepa\n",
        "                    state_ = self.deconv(sy) # ae\n",
        "                    # tsmall = torch.nn.Sequential(transforms.Resize((32,32)), transforms.Grayscale(1))\n",
        "\n",
        "                    conv_loss = F.mse_loss(state_, state)\n",
        "                    # conv_loss = F.mse_loss(state_, tsmall(state))\n",
        "                    # loss = jloss + conv_loss\n",
        "                    loss = conv_loss\n",
        "\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n",
        "    def get_down(self, state, world_state=None): # update world_state and mem from state\n",
        "        current = self.sense(state) # [batch_size, d_model] or [1, d_model]\n",
        "        obs = current# + mem # [batch_size, d_model]\n",
        "        K, V = self.k(obs), self.v(obs) # [batch_size, d_model]\n",
        "        # K, V = F.normalize(K, dim=-1), F.normalize(V, dim=-1)\n",
        "        K = F.normalize(K, dim=-1)\n",
        "        if V.shape[0]>1 and V.ndim==2: K, V = K.unsqueeze(1), V.unsqueeze(1) # [batch_size, 1, d_model]\n",
        "        V_ = world_state @ K.transpose(-1,-2) # [batch_size, d_model, d_model] @ [batch_size, d_model, 1] = [batch_size, d_model, 1]\n",
        "        world_state = world_state + (V.transpose(-1,-2) - V_) @ K#.T # -V_.K^T, + V.K^T # update world state\n",
        "        return world_state\n",
        "\n",
        "    def train_ae(self, dataloader, optim, bptt=32):\n",
        "        self.train()\n",
        "        for batch, Sar in enumerate(dataloader):\n",
        "            # state = torch.rand((batch_size, 3,64,64), device=device)\n",
        "            # sx_ = self.jepa.enc(state) # [batch_size, d_model]\n",
        "            world_state = torch.zeros((batch_size, self.d_model, self.d_model), device=device) # Sum i] vi kiT\n",
        "\n",
        "            for i, (state, action, reward) in enumerate(zip(*Sar)):\n",
        "                state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    world_state = self.get_down(state, world_state)\n",
        "                    # sy = self.jepa.enc(world_state_.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1)) # [batch_size, d_model]\n",
        "                    # sy = self.convenc(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "                    sy = self.effnet(world_state.unsqueeze(1).detach()) # [batch_size, d_model]\n",
        "\n",
        "                    world_state_ = self.deconvenc(sy).squeeze(1) # ae\n",
        "                    # loss = F.mse_loss(world_state_, world_state)\n",
        "                    loss = F.mse_loss(world_state_, world_state.detach())\n",
        "                    # print(\"std, cov, conv\", std_loss.item(), cov_loss.item(), conv_loss.item())\n",
        "                    print(\"loss\", loss.item())\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optim)\n",
        "                    scaler.update()\n",
        "                    optim.zero_grad()\n",
        "                    # sx_ = sx_.detach()\n",
        "\n",
        "                # try: wandb.log({\"repr\": repr_loss.item(), \"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": closs.item()})\n",
        "                try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"conv\": conv_loss.item()})\n",
        "                except: pass\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0u9XYJvdIf6p"
      },
      "outputs": [],
      "source": [
        "# @title dataloader from transformer\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        # self.data = buffer\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        state, action, reward = zip(*sar)\n",
        "        state = [self.transform(s) for s in state]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return state, action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Datasetme(torch.utils.data.Dataset):\n",
        "    def __init__(self, buffer, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.data = [step for episode in buffer for step in episode]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "        seq_len = data.size(0) // batch_size\n",
        "        data = data[:seq_len * batch_size]\n",
        "        # data = data.view(bsz, seq_len).t().contiguous()\n",
        "        data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "        # self.bptt = 35\n",
        "        # self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = self.ind[index]\n",
        "        seq_len = min(self.bptt, len(self.data) - i)\n",
        "        data = self.data[i:i+seq_len]\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # sar = self.data[idx*self.seq_len : (idx+1)*self.seq_len]\n",
        "        # state, action, reward = zip(*sar)\n",
        "        # state = [self.transform(s) for s in state]\n",
        "        state, action, reward = self.data[idx]\n",
        "        # print(state.shape, action.shape, reward.shape)\n",
        "        return self.transform(state), action, torch.tensor(reward, dtype=torch.float)\n",
        "\n",
        "\n",
        "def collate_fn(sar):\n",
        "    # x,y=zip(*data)\n",
        "    state, action, reward = zip(*sar)\n",
        "    # print(\"collate\",len(x),len(y))\n",
        "    # x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "    state=torch.stack(list(state), dim=0)\n",
        "    action=torch.stack(list(action), dim=0)\n",
        "    reward=torch.stack(list(reward), dim=0)\n",
        "    # y=torch.stack(list(y)).T.flatten()\n",
        "    return state, action, reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title Datasetme\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data, batch_size):\n",
        "#         data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#         seq_len = data.size(0) // batch_size\n",
        "#         data = data[:seq_len * batch_size]\n",
        "#         # data = data.view(bsz, seq_len).t().contiguous()\n",
        "#         data = data.view(batch_size, seq_len).T.contiguous()\n",
        "\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0), step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.data.size(0) // self.batch_size\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         i = self.ind[index]\n",
        "#         seq_len = min(self.bptt, len(self.data) - i)\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         return data\n",
        "\n",
        "\n",
        "\n",
        "# class Datasetme(torch.utils.data.Dataset):\n",
        "#     def __init__(self, raw_data):\n",
        "#         self.data = self.data_process(raw_data) # list of int, [2049990]\n",
        "#         self.bptt = 35\n",
        "#         self.ind = torch.arange(0, self.data.size(0) - 1, step=self.bptt)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) // self.bptt\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         i=idx*self.bptt\n",
        "#         seq_len = self.bptt\n",
        "#         data = self.data[i:i+seq_len]\n",
        "#         target = self.data[i+1:i+1+seq_len].reshape(-1)\n",
        "#         return data, target\n",
        "\n",
        "# train_iter, val_iter, test_iter = WikiText2() # line by line of wiki  = Valkyria Chronicles III =\n",
        "# batch_size=128\n",
        "# train_iter = Datasetme(train_iter)\n",
        "# # train_loader = Datasetme(train_iter, batch_size)\n",
        "\n",
        "\n",
        "# def collate_fn(data):\n",
        "#     x,y=zip(*data)\n",
        "#     # print(\"collate\",len(x),len(y))\n",
        "#     x=torch.stack(list(x), dim=1) # batch_first->dim=0\n",
        "#     y=torch.stack(list(y)).T.flatten()\n",
        "#     return x, y\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# seq_len = 50 # 50\n",
        "batch_size = 64 #512\n",
        "train_data = BufferDataset(buffer, batch_size)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "train_loader = DataLoader(train_data, shuffle = True,collate_fn=torch.utils.data._utils.collate.default_convert, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cX71EprCMSNG"
      },
      "outputs": [],
      "source": [
        "# @title transfer_optim bad?\n",
        "\n",
        "import torch\n",
        "\n",
        "def transfer_optim(src_optim, tgt_optim, param_mapping):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    tgt_sd = tgt_optim.state_dict()\n",
        "\n",
        "    # Iterate over each parameter in the target optimizer\n",
        "    for (tgt_idx, target_param) in enumerate(tgt_optim.param_groups[0]['params']):\n",
        "        target_id = id(target_param)\n",
        "\n",
        "        # Find the corresponding source parameter using param_mapping\n",
        "        if target_id in param_mapping:\n",
        "            source_param = param_mapping[target_id]\n",
        "            source_id = id(source_param)\n",
        "\n",
        "            # If there's an existing state for the source parameter, transfer it\n",
        "            if source_id in src_sd['state']:\n",
        "                source_state = src_sd['state'][source_id]\n",
        "                target_state = {}\n",
        "\n",
        "                # Handle momentum/first and second moments (e.g., `exp_avg`, `exp_avg_sq` in Adam)\n",
        "                for key in source_state.keys():\n",
        "                    if source_state[key].shape == target_param.shape: target_state[key] = source_state[key].clone()\n",
        "                    # If size doesn't match, either copy what you can or initialise new values\n",
        "                    elif key in ['exp_avg', 'exp_avg_sq']:  # Momentums (specific to Adam-like optimizers)\n",
        "                        target_state[key] = torch.zeros_like(target_param)\n",
        "                        target_state[key][:source_param.numel()] = source_state[key].flatten()[:target_param.numel()]\n",
        "                    else: target_state[key] = torch.zeros_like(target_param) # init\n",
        "                tgt_sd['state'][target_id] = target_state\n",
        "\n",
        "    # Load the updated state dict back into the target optimizer\n",
        "    tgt_optim.load_state_dict(tgt_sd)\n",
        "    return tgt_optim\n",
        "# {'state': {0: {'step': tensor(1.), 'exp_avg': tensor, 'exp_avg_sq': tensor}, 1: }}\n",
        "\n",
        "\n",
        "\n",
        "model_src = torch.nn.Linear(10, 5)  # Example source model\n",
        "model_tgt = torch.nn.Linear(20, 5)  # Example target model (with more input dimensions)\n",
        "\n",
        "# model_src = nn.Sequential( # trained cost\n",
        "#     nn.Linear(10, 5, bias=False), nn.Softmax(),\n",
        "#     )\n",
        "# d_model=4\n",
        "# model_tgt = nn.Sequential( # trained cost\n",
        "#     nn.Linear(20, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, d_model), nn.ReLU(),\n",
        "#     nn.Linear(d_model, 5), nn.Softmax(),\n",
        "#     )\n",
        "\n",
        "source_optimizer = optim.AdamW(model_src.parameters())\n",
        "target_optimizer = optim.AdamW(model_tgt.parameters())\n",
        "\n",
        "dummy_input = torch.randn(3, 10)\n",
        "dummy_target = torch.randn(3, 5)\n",
        "criterion = torch.nn.MSELoss()\n",
        "output = model_src(dummy_input)\n",
        "loss = criterion(output, dummy_target)\n",
        "loss.backward()\n",
        "source_optimizer.step()\n",
        "\n",
        "param_mapping = {id(tgt_param): src_param for src_param, tgt_param in zip(model_src.parameters(), model_tgt.parameters())}\n",
        "target_optimizer = transfer_optim(source_optimizer, target_optimizer, param_mapping)\n",
        "\n",
        "print(source_optimizer.state_dict())\n",
        "print(target_optimizer.state_dict())\n",
        "\n",
        "\n",
        "# checkpoint = {'model': agent.state_dict(), 'optimizer': optim.state_dict(),}\n",
        "# torch.save(checkpoint, folder+'agentoptim.pkl')\n",
        "\n",
        "# modelsd, optimsd = torch.load('agentoptim.pkl').values()\n",
        "\n",
        "# optim.load_state_dict(optimsd)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title transfer_optim bad? 2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    opt_state_dict = optimizer.state_dict()\n",
        "    for group in opt_state_dict['param_groups']:\n",
        "        # For each parameter index (p in param group refers to the layer parameters)\n",
        "        for param_idx, p in enumerate(group['params']):\n",
        "            print(p,source_layer.weight)\n",
        "            if p == source_layer.weight:\n",
        "                # Find the corresponding target layer parameter (in this case, target_layer.weight)\n",
        "                target_param = target_layer.weight\n",
        "                source_state = optimizer.state[p]  # Get the state for the source parameter\n",
        "\n",
        "                # If the parameter is found in the optimizer's state dict\n",
        "                if 'exp_avg' in source_state and 'exp_avg_sq' in source_state:\n",
        "                    exp_avg = source_state['exp_avg']  # First moment (momentum)\n",
        "                    exp_avg_sq = source_state['exp_avg_sq']  # Second moment (variance)\n",
        "\n",
        "                    # Handle input dimension mismatch (copy/truncate or pad)\n",
        "                    source_in_dim = source_layer.weight.shape[1]\n",
        "                    target_in_dim = target_layer.weight.shape[1]\n",
        "\n",
        "                    # Copy optimizer state (exp_avg and exp_avg_sq) accordingly\n",
        "                    with torch.no_grad():\n",
        "                        # Copy the available part and initialize new dimensions to zero\n",
        "                        new_exp_avg = torch.zeros_like(target_param)\n",
        "                        new_exp_avg_sq = torch.zeros_like(target_param)\n",
        "                        # new_exp_avg[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        # new_exp_avg_sq[:, source_in_dim:] = 0  # Initialize extra dimensions\n",
        "                        new_exp_avg[:, :source_in_dim] = exp_avg[:, :target_in_dim]\n",
        "                        new_exp_avg_sq[:, :source_in_dim] = exp_avg_sq[:, :target_in_dim]\n",
        "\n",
        "                    # Update the target layer's optimizer state\n",
        "                    optimizer.state[target_param] = {\n",
        "                        'exp_avg': new_exp_avg,\n",
        "                        'exp_avg_sq': new_exp_avg_sq,\n",
        "                        'step': source_state['step']  # Keep the same step count\n",
        "                    }\n",
        "\n",
        "                # Handle the bias (if it exists)\n",
        "                if hasattr(source_layer, 'bias') and hasattr(target_layer, 'bias'):\n",
        "                    source_bias = optimizer.state[source_layer.bias]\n",
        "                    target_bias = target_layer.bias\n",
        "\n",
        "                    optimizer.state[target_bias] = source_bias\n",
        "    return optimizer\n",
        "\n",
        "# Example usage:\n",
        "d = 10  # Input dimension of the source layer\n",
        "a = 5   # Extra nodes to be omitted or added in the target layer\n",
        "m = 8   # Output dimension (same for both)\n",
        "\n",
        "# Source layer (input dimension d+a)\n",
        "source_layer = nn.Linear(d+a, m)\n",
        "\n",
        "# Target layer (input dimension d, or d+a, or arbitrary)\n",
        "target_layer = nn.Linear(d, m)\n",
        "\n",
        "# Optimizer (using AdamW in this case)\n",
        "optimizer = torch.optim.AdamW(source_layer.parameters())\n",
        "\n",
        "# Perform weight transfer (from d+a to d or vice versa) here (assumed done already)\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "# Transfer optimizer states\n",
        "optimizer = transfer_optimizer_state(source_layer, target_layer, optimizer)\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optimizer_state(source_layer, target_layer, optimizer):\n",
        "    state_dict = optimizer.state_dict()\n",
        "    for old_param, new_param in zip(source_layer.parameters(), target_layer.parameters()):\n",
        "        # If old_param exists in optimizer state\n",
        "        if old_param in state_dict['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = state_dict['state'][old_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                if key in ['exp_avg', 'exp_avg_sq']:  # for Adam or AdamW momentum estimates\n",
        "                    # Handle the shape adjustment (copy, shrink, or randomly initialise the extra nodes)\n",
        "                    new_state[key] = torch.zeros_like(new_param)  # Initialise with zeros\n",
        "                    new_state[key][:old_param.shape[0]] = value[:new_param.shape[0]]  # Copy old values\n",
        "                    # else:\n",
        "                    #     new_state[key] = value.clone()  # Copy directly if shapes match\n",
        "                else:\n",
        "                    new_state[key] = value  # Copy other states directly if they exist\n",
        "\n",
        "            # Set the new parameter in optimizer state\n",
        "            state_dict['state'][new_param] = new_state\n",
        "            # Remove the old parameter from the optimizer state\n",
        "            del state_dict['state'][old_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(state_dict)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transfer_optim(src_model, tgt_model, src_optim, tgt_optim):\n",
        "    src_sd = src_optim.state_dict()\n",
        "    for src_param, tgt_param in zip(src_model.parameters(), tgt_model.parameters()):\n",
        "        # If src_param exists in optimizer state\n",
        "        if src_param in src_sd['state']:\n",
        "            # Get the state for the old parameter\n",
        "            old_state = src_sd['state'][src_param]\n",
        "            new_state = {}\n",
        "\n",
        "            for key, value in old_state.items():\n",
        "                new_state[key] = torch.zeros_like(tgt_param)  # Initialise with zeros\n",
        "                new_state[key][:src_param.shape[0]] = value[:tgt_param.shape[0]]  # Copy old values\n",
        "\n",
        "            src_sd['state'][tgt_param] = new_state\n",
        "            del src_sd['state'][src_param]\n",
        "\n",
        "    # Load the updated state dict into the optimizer\n",
        "    optimizer.load_state_dict(src_sd)\n",
        "    return optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "LKUSzmYLLuRh",
        "outputId": "07ca4b89-257b-4205-c5c8-6a96474ae82a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-186620617543>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# j=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mwht_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwht_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "# @title rename wht_name\n",
        "# wht_name='jepa.enc.cnn.0.weight'\n",
        "wht_name='jepa.pred.weight_ih_l0'\n",
        "# wht_name='emb.weight'\n",
        "# print(o.isnumeric())\n",
        "# mask = [x.isnumeric() for x in o]\n",
        "# print(o[mask])\n",
        "na_=''\n",
        "# j=0\n",
        "\n",
        "for wht_name in agent.state_dict().keys():\n",
        "    o=wht_name.split('.')\n",
        "    # print(o)\n",
        "    name=wht_name\n",
        "    print(\"####\", wht_name)\n",
        "    for i in range(len(o)):\n",
        "        c = o[i]\n",
        "        if c.isnumeric():\n",
        "            na = '.'.join(o[:i])\n",
        "            me = '.'.join(o[i+1:])\n",
        "            # print(c_,c, c_<c, )\n",
        "            c=int(c)\n",
        "            if na!=na_: # param name diff\n",
        "                j=0 # reset num\n",
        "                c_=c # track wht_name num\n",
        "                na_=na # track param name\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('1', name)\n",
        "            elif c_<c: # same param name, diff num\n",
        "                j+=1\n",
        "                c_=c\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('2', name)\n",
        "            else: # same param name, same num\n",
        "                name = f'{na}.{j}.{me}'\n",
        "                print('3', name)\n",
        "    print('4', name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CACQCCaxA_Y",
        "outputId": "b5d127cd-18ce-49e5-b1e2-d883cb34125a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1746836772511624\n"
          ]
        }
      ],
      "source": [
        "# @title geomloss, Python Optimal Transport\n",
        "# !pip install geomloss[full]\n",
        "\n",
        "import torch\n",
        "from geomloss import SamplesLoss  # See also ImagesLoss, VolumesLoss\n",
        "\n",
        "# # Create some large point clouds in 3D\n",
        "# x = torch.randn(100000, 3, requires_grad=True).cuda()\n",
        "# y = torch.randn(200000, 3).cuda()\n",
        "\n",
        "# x = torch.rand(1000, 1)\n",
        "# y = torch.rand(1000, 1)\n",
        "x = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "y = torch.tensor([0, 1, 0]).float().unsqueeze(-1)\n",
        "# k=1.\n",
        "# y = torch.tensor([k, k, k]).float().unsqueeze(-1)\n",
        "\n",
        "\n",
        "\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01) # 0.05, quadratic, Wasserstein-2. low blur => closer to true Wasserstein dist but slower compute\n",
        "\n",
        "loss = loss_fn(x, y)  # By default, use constant weights = 1/number of samples\n",
        "print(loss)\n",
        "# g_x, = torch.autograd.grad(L, [x])\n",
        "\n",
        "# [0, 1, 0]: 2.4253e-12, 2.4253e-12\n",
        "# [0, 0, 0.1]: 0.1350; [0, 0, 0.5]: 0.0417; [0, 0, 1]: 0\n",
        "# k=0.: 0.1666; k=0.1: 0.1383; k=0.333: 0.1111; k=0.5: 0.1250; k=1.: 0.3333\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from geomloss import SamplesLoss\n",
        "\n",
        "# Define x and y as n-dimensional tensors representing mass distributions\n",
        "# x = torch.tensor([0.2, 0.3, 0.5], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# y = torch.tensor([0, 0, 1], dtype=torch.float32, requires_grad=True).cuda()\n",
        "# x = torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1)\n",
        "# x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float().unsqueeze(-1))\n",
        "x = nn.Parameter(torch.tensor([0,1.5,0]).float().unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float().unsqueeze(-1)\n",
        "\n",
        "# Create a position tensor representing the index of each element\n",
        "positions_x = torch.arange(x.shape[0], dtype=float).unsqueeze(1)\n",
        "positions_y = torch.arange(y.shape[0], dtype=float).unsqueeze(1)\n",
        "\n",
        "# Sinkhorn loss using GeomLoss\n",
        "loss_fn = SamplesLoss(\"sinkhorn\", p=1, blur=0.05)  # p=1 for Wasserstein-1\n",
        "# loss_fn = SamplesLoss(loss=\"sinkhorn\", p=1, blur=0.05, scaling=0.9, debias=True)\n",
        "\n",
        "transport_cost = loss_fn(positions_x, x, positions_y, y)\n",
        "\n",
        "print(transport_cost.item())\n",
        "# 1.298424361328248\n",
        "\n",
        "transport_cost.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pip install POT\n",
        "\n",
        "import ot\n",
        "import numpy as np\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / np.sum(x)\n",
        "    # y = y / np.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = np.abs(np.arange(n)[:, None] - np.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = np.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "x = np.array([0.2, 0.3, 0.5])\n",
        "y = np.array([0, 0, 1])\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "# distance.backward()\n",
        "\n",
        "def sinkhorn_distance(x, y, reg=0.01):\n",
        "    # x = x / torch.sum(x)\n",
        "    # y = y / torch.sum(y)\n",
        "    # Create the cost matrix (1D example, Euclidean distances between positions)\n",
        "    n = len(x)\n",
        "    cost_matrix = torch.abs(torch.arange(n)[:, None] - torch.arange(n)[None, :])\n",
        "    # print(cost_matrix)\n",
        "    # Compute Sinkhorn distance using POT's Sinkhorn algorithm\n",
        "    print(x, y, cost_matrix, reg)\n",
        "    transport_plan = ot.sinkhorn(x, y, cost_matrix, reg)\n",
        "    print(transport_plan)\n",
        "    distance = torch.sum(transport_plan * cost_matrix)\n",
        "    return distance\n",
        "\n",
        "# x = np.array([0.2, 0.3, 0.5])\n",
        "# y = np.array([0, 0, 1])\n",
        "x = nn.Parameter(torch.tensor([0.2, 0.3, 0.5]).float())#.unsqueeze(-1))\n",
        "y = torch.tensor([0, 0, 1]).float()#.unsqueeze(-1)\n",
        "\n",
        "distance = sinkhorn_distance(x, y)\n",
        "print(f'Sinkhorn distance: {distance}')\n",
        "distance.backward()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MqBL9hljvW-5"
      },
      "outputs": [],
      "source": [
        "# @title batchify argm train\n",
        "\n",
        "def rnn_pred(self, sx, la, lz=None, h0=None, gamma=0.9): # 0.95 [1, d_model], [batch, seq_len, dim_a/z], [num_layers, d_model]\n",
        "    self.jepa.pred.train()\n",
        "    batch, seq_len, dim_a = la.shape\n",
        "    cost = 0\n",
        "    sx=sx.repeat(batch, 1) # [batch, d_model]\n",
        "    lsx=sx.unsqueeze(1)\n",
        "    h0=h0.repeat(1, batch, 1) # [num_layers, batch, d_model]\n",
        "    lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "    # print(lsx.shape, la.shape, lz.shape)\n",
        "    c=[]\n",
        "    for t in range(seq_len):\n",
        "        a, z = la[:,t], lz[:,t] # [1, dim_a], [1, dim_z]\n",
        "        # print(sx.shape, a.shape, z.shape)\n",
        "        sxaz = torch.cat([sx, a, z], dim=-1).unsqueeze(1)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out, h0 = self.jepa.pred(sxaz, h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            sx = sx + out.squeeze(1) # [batch,seq_len,d_model]\n",
        "            syh0 = torch.cat([sx.flatten(1),h0.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            tcost = -self.tcost(syh0)\n",
        "        c.append(tcost)\n",
        "        lsx = torch.cat([lsx, sx.unsqueeze(1)], dim=1) # [batch, T, d_model]\n",
        "        lh0 = torch.cat([lh0, h0.unsqueeze(0)], dim=0) # [seq_len, num_layers, batch, d_model]\n",
        "        icost = 0#*0.0005*self.icost.boredom(lsx, linsx=None) # + self.icost(sx)\n",
        "        # print(\"tcost icost\", tcost.item(), icost.item())\n",
        "        cost += (tcost + icost)*gamma**t\n",
        "    return cost, lsx, lh0, c\n",
        "\n",
        "\n",
        "\n",
        "def argm(self, sy, sy_, h0, a, reward, lr=3e3): # 3e3\n",
        "    self.tcost.eval()\n",
        "    batch_size = sy.shape[0] # [batch_size, d_model]\n",
        "    z = nn.Parameter(torch.zeros((batch_size, self.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(z)\n",
        "    torch.nn.init.normal_(z, mean=0., std=.3/z.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([z], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([z], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    sy, sy_ = sy.detach(), sy_.detach()\n",
        "    out = sy - sy_\n",
        "    h0, a, reward = h0.detach(), a.detach(), reward.detach()\n",
        "    for i in range(10): # 10\n",
        "        with torch.amp.autocast('cuda'):\n",
        "\n",
        "\n",
        "\n",
        "            syaz = torch.cat([sy_, a, z], dim=-1)\n",
        "            out_, h0_ = self.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "            repr_loss = F.mse_loss(out, out_[:, -1, :])\n",
        "            # syh0 = torch.cat([sy.flatten(1),F.dropout(h0_, p=0.5).permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            syh0 = torch.cat([sy.flatten(1),h0_.permute(1,0,2).flatten(1)], dim=-1) # [batch_size,seq_len,d_model], [num_layers,batch_size,d_model]\n",
        "            clossl = self.tcost.loss(syh0, reward).squeeze(-1)\n",
        "            z_loss = torch.abs(z).sum() # z_loss = torch.norm(z)\n",
        "            print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = self.jepa.sim_coeff * repr_loss + self.closs_coeff * clossl + self.zloss_coeff * z_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        # with torch.no_grad(): z.clamp_(min=-1, max=1)\n",
        "        with torch.no_grad(): z /= torch.norm(z, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    self.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return z.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def argm(lsy, sy, h0, la, rwd):\n",
        "    # lz = agent.argm(out, h0, la, reward)\n",
        "    agent.tcost.eval()\n",
        "    batch_size, bptt, _ = lsy.shape # [batch_size, bptt, d_model]\n",
        "    lz = nn.Parameter(torch.zeros((batch_size, bptt, agent.dim_z), device=device))\n",
        "    # torch.nn.init.xavier_uniform_(lz)\n",
        "    torch.nn.init.normal_(lz, mean=0., std=.3/lz.shape[-1]**0.5)\n",
        "    # optim = torch.optim.SGD([lz], lr=1e-2) # 1e-2\n",
        "    # optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.95)) # 1e-1\n",
        "    optim = torch.optim.AdamW([lz], 1e-1, (0.9, 0.999)) # 1e-1\n",
        "    lsy, la, rwd = lsy.detach(), la.detach(), rwd.detach()\n",
        "    for i in range(3): # 10\n",
        "        sy_, h0_ = sy.detach(), h0.detach()\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "        with torch.cuda.amp.autocast():\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0_ = agent.jepa.pred(syaz.unsqueeze(1), h0_) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0_.unsqueeze(0)), dim=0)\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            z_loss = torch.abs(lz).sum() # z_loss = torch.norm(z)\n",
        "            # print(\"z_loss\", i, z[0].data, z_loss)\n",
        "            cost = agent.jepa.sim_coeff * repr_loss + agent.closs_coeff * clossl + agent.zloss_coeff * z_loss\n",
        "        cost.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        with torch.no_grad(): lz /= torch.norm(lz, dim=-1).unsqueeze(-1).clamp_(min=1)\n",
        "        # print(i, \"repr c z loss, z\", torch.cat([torch.tensor([repr_loss, clossl, z_loss]), z[0].cpu()],dim=-1).squeeze().data)\n",
        "        # print(\"worst case\",i,cost.item(), torch.mean(abs(z.detach())).item())\n",
        "    # if loss.item()>0.9: print(\"argm\",loss.item(), torch.mean(abs(z.detach())).item())\n",
        "    agent.tcost.train() # https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html#no_grad # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval\n",
        "    return lz.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# closs_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=.01)\n",
        "bptt = 25\n",
        "for batch, Sar in enumerate(train_loader): # [seq_len, batch_size, ] -> [batch_size, ]\n",
        "    h0 = torch.zeros((agent.jepa.pred.num_layers, batch_size, agent.d_model), device=device) # [num_layers, batch, d_model]\n",
        "    state = torch.zeros((batch_size, 3,64,64), device=device)\n",
        "    sy_ = agent.jepa.enc(state).unsqueeze(1) # [batch_size, 1, d_model]\n",
        "    # sx=sy_\n",
        "    state, action, reward = Sar # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "    state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "\n",
        "    for st, act, rwd in zip(torch.split(state, bptt, dim=1), torch.split(action, bptt, dim=1), torch.split(reward, bptt, dim=1)):\n",
        "        lh0 = torch.empty((0,)+h0.shape, device=device)\n",
        "        lsy_ = torch.empty((batch_size, 0, agent.d_model), device=device) # [batch_size, T, d_model]\n",
        "\n",
        "        with torch.cuda.amp.autocast(): # with torch.amp.GradScaler('cuda'):\n",
        "            lsy = agent.jepa.enc(st.flatten(end_dim=1)).unflatten(0, (batch_size, -1)) # [batch_size, bptt, d_model]\n",
        "            la = agent.emb(act) # [batch_size, bptt, dim_a]\n",
        "            out = lsy - torch.cat([sy_, lsy[:,:-1]], dim=1)\n",
        "            # lz = agent.argm(out, h0, la, reward)\n",
        "            lz = argm(lsy, sy_, h0, la, rwd)\n",
        "            # lz = torch.zeros((batch_size, bptt, agent.dim_z), device=device)\n",
        "\n",
        "            for i, (a, z) in enumerate(zip(la.permute(1,0,2), lz.permute(1,0,2))):\n",
        "                syaz = torch.cat([sy_.squeeze(1), a, z], dim=-1) # [batch_size, 1, d_model], [batch_size, dim_az]\n",
        "                out_, h0 = agent.jepa.pred(syaz.unsqueeze(1), h0) # [batch,seq_len,d_model], [num_layers,batch,d_model]\n",
        "                sy_ = sy_ + out_[:, -1, :].unsqueeze(1)\n",
        "                lsy_ = torch.cat((lsy_, sy_), dim=1)\n",
        "                lh0 = torch.cat((lh0, h0.unsqueeze(0)), dim=0)\n",
        "\n",
        "            repr_loss = F.mse_loss(lsy, lsy_)\n",
        "            std_loss, cov_loss = agent.jepa.v_creg(agent.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "            jloss = agent.jepa.sim_coeff * repr_loss + agent.jepa.std_coeff * std_loss + agent.jepa.cov_coeff * cov_loss\n",
        "\n",
        "            syh0 = torch.cat([lsy_, lh0.permute(2,0,1,3).flatten(2)], dim=-1).flatten(end_dim=1) # [batch_size,bptt,d_model], [bptt,num_layers,batch_size,d_model] -> [batch_size*bptt, (1+num_layers)*d_model]\n",
        "            # print(\"syh0, rwd\",syh0.shape,rwd.shape)\n",
        "            clossl = agent.tcost.loss(syh0, rwd.flatten())\n",
        "            # reward_ = agent.tcost(syh0)\n",
        "            # clossl = wasserstein(rwd, reward_)#.squeeze(-1)\n",
        "            closs = agent.closs_coeff * clossl\n",
        "\n",
        "            # print(h0.requires_grad)\n",
        "            # pred = agent.tcost(syh0).squeeze(-1).cpu()\n",
        "            # mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "            # print(\"reward, pred, clossl\", reward[mask].data, pred[mask].data, clossl.item())\n",
        "            # try: imshow(torchvision.utils.make_grid(state[mask], nrow=10))\n",
        "            # except ZeroDivisionError: pass\n",
        "\n",
        "\n",
        "            loss = jloss + closs\n",
        "\n",
        "            # print(\"norm\", torch.norm(sy, dim=-1)[0].item())\n",
        "            norm = torch.norm(lsy, dim=-1)[0][0].item()\n",
        "            z_norm = torch.norm(z)\n",
        "            # print(\"repr, std, cov\", repr_loss.item(), std_loss.item(), cov_loss.item())\n",
        "            # print(\"repr, std, cov, clossl\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item())\n",
        "            print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "            scaler.scale(loss).backward()\n",
        "            # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "            optim.zero_grad()\n",
        "            sy_, h0 = sy_.detach(), h0.detach()\n",
        "    break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o0UHSueqx9W8"
      },
      "outputs": [],
      "source": [
        "# @title test tcost3\n",
        "# def train_jepa(self, dataloader, optim, bptt=25): #32\n",
        "#     self.train()\n",
        "#     for batch, (state, action, reward) in enumerate(dataloader): # collate: [seq_len, batch_length], default: [batch_size, seq_len]\n",
        "#         state, action, reward = state.to(device), action.to(device), reward.to(device)\n",
        "#         with torch.cuda.amp.autocast():\n",
        "#             lsy = self.jepa.enc(state.flatten(end_dim=1)) # [batch_size, bptt, d_model]\n",
        "#             # std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy.flatten(end_dim=1)))\n",
        "#             # lsy = self.jepa.enc(state) # [batch_size, d_model]\n",
        "#             std_loss, cov_loss = self.jepa.v_creg(self.jepa.exp(lsy))\n",
        "#             jloss = self.jepa.std_coeff * std_loss + self.jepa.cov_coeff * cov_loss\n",
        "#             clossl = self.tcost.loss(lsy, reward.flatten(end_dim=1))\n",
        "#             closs = self.closs_coeff * clossl\n",
        "\n",
        "#             pred = self.tcost(lsy).squeeze(-1).unflatten(0, reward.shape) # [batch_size, bptt]\n",
        "#             print(\"pred\",pred[0])\n",
        "#             print(\"rwd\",reward[0])\n",
        "#             mask = torch.where(abs(reward- pred)>0.5,1,0).bool()\n",
        "#             # # print(\"rwd, pred, clossl\", rwd[mask].data, pred[mask].data, clossl.item())\n",
        "#             # try: imshow(torchvision.utils.make_grid(st[0].cpu(), nrow=10))\n",
        "#             # # try: imshow(torchvision.utils.make_grid(st[mask].cpu(), nrow=10))\n",
        "#             # except ZeroDivisionError: pass\n",
        "\n",
        "#         loss = jloss + closs\n",
        "\n",
        "#         print(\"std, cov, clossl, wrong\", std_loss.item(), cov_loss.item(), clossl.item(), mask.sum().item())\n",
        "#         # print(\"repr, std, cov, clossl, z, norm\", repr_loss.item(), std_loss.item(), cov_loss.item(), clossl.item(), z_norm.item(), norm)\n",
        "#         scaler.scale(loss).backward()\n",
        "#         # torch.nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "#         scaler.step(optim)\n",
        "#         scaler.update()\n",
        "#         optim.zero_grad()\n",
        "#         try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"closs\": clossl.item()})\n",
        "#         except: pass\n",
        "\n",
        "# # for i in range(5):\n",
        "# #     print(i)\n",
        "# #     train_jepa(agent, train_loader, optim)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Jt_UlGz6Xoq3",
        "m8WHjFn2gmzI"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52b55d07f1314d26952ce0db31baf2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f2296a217ed49d29ede116c277d12e7",
              "IPY_MODEL_4f6e405a7bc540b89549c02b54332093"
            ],
            "layout": "IPY_MODEL_a8b37cd81d8843a3a7a7295494a74603"
          }
        },
        "1f2296a217ed49d29ede116c277d12e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0320a1972db44611919ee6c1fc3d480d",
            "placeholder": "​",
            "style": "IPY_MODEL_b5835eb4fd7f4e8cb1a766d5fd4859fc",
            "value": "0.224 MB of 0.224 MB uploaded\r"
          }
        },
        "4f6e405a7bc540b89549c02b54332093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034d841416ac4b7cb6c46ec418294902",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e99fb80c43a04637a55de2c5bbb17471",
            "value": 1
          }
        },
        "a8b37cd81d8843a3a7a7295494a74603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0320a1972db44611919ee6c1fc3d480d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5835eb4fd7f4e8cb1a766d5fd4859fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "034d841416ac4b7cb6c46ec418294902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99fb80c43a04637a55de2c5bbb17471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}