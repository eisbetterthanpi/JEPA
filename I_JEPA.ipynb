{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "s3EO3PgMPH1x"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/JEPA/blob/main/I_JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "LxACli7GdyGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242b0844-2326-47c0-ad97-e8f020af9a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 47.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "transform = transforms.Compose([transforms.ToTensor(),])\n",
        "# transform = transforms.Compose([transforms.RandomResizedCrop((32,32), scale=(.3,1.)), transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_data = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transform)\n",
        "batch_size = 64 # 4\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# dataiter = iter(train_loader) # get some random training images\n",
        "# images, labels = next(dataiter)\n",
        "# print(images.shape) # [batch, 3, 32, 32]\n",
        "# imshow(torchvision.utils.make_grid(images))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hiera"
      ],
      "metadata": {
        "id": "s3EO3PgMPH1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ResBlock\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def zero_module(module):\n",
        "    for p in module.parameters(): p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, kernel=3):\n",
        "        super().__init__()\n",
        "        out_ch = out_ch or in_ch\n",
        "        act = nn.SiLU() #\n",
        "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "        # self.block = nn.Sequential( # best?\n",
        "        #     nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), act,\n",
        "        #     zero_module(nn.Conv2d(out_ch, out_ch, 3, padding=1)), nn.BatchNorm2d(out_ch), act,\n",
        "        #     )\n",
        "        self.block = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_ch), act, nn.Conv2d(in_ch, out_ch, kernel, padding=kernel//2),\n",
        "            nn.BatchNorm2d(out_ch), act, zero_module(nn.Conv2d(out_ch, out_ch, kernel, padding=kernel//2)),\n",
        "            )\n",
        "\n",
        "    def forward(self, x): # [b,c,h,w]\n",
        "        return self.block(x) + self.res_conv(x)\n"
      ],
      "metadata": {
        "id": "j3-vvMS1-gVn",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title UpDownBlock_me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class PixelShuffleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, kernel=1, r=1):\n",
        "        super().__init__()\n",
        "        self.r = r\n",
        "        r = max(r, int(1/r))\n",
        "        out_ch = out_ch or in_ch\n",
        "        if self.r>1: self.net = nn.Sequential(ResBlock(in_ch, out_ch*r**2, kernel), nn.PixelShuffle(r))\n",
        "        # if self.r>1: self.net = nn.Sequential(Attention(in_ch, out_ch*r**2), nn.PixelShuffle(r))\n",
        "\n",
        "        elif self.r<1: self.net = nn.Sequential(nn.PixelUnshuffle(r), ResBlock(in_ch*r**2, out_ch, kernel))\n",
        "        # elif self.r<1: self.net = nn.Sequential(nn.PixelUnshuffle(r), Attention(in_ch*r**2, out_ch))\n",
        "        elif in_ch != out_ch: self.net = ResBlock(in_ch*r**2, out_ch, kernel)\n",
        "        else: self.net = lambda x: torch.zeros_like(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def AdaptiveAvgPool_nd(n, *args, **kwargs): return [nn.Identity, nn.AdaptiveAvgPool1d, nn.AdaptiveAvgPool2d, nn.AdaptiveAvgPool3d][n](*args, **kwargs)\n",
        "def AdaptiveMaxPool_nd(n, *args, **kwargs): return [nn.Identity, nn.AdaptiveMaxPool1d, nn.AdaptiveMaxPool2d, nn.AdaptiveMaxPool3d][n](*args, **kwargs)\n",
        "\n",
        "def adaptive_avg_pool_nd(n, x, output_size): return [nn.Identity, F.adaptive_avg_pool1d, F.adaptive_avg_pool2d, F.adaptive_avg_pool3d][n](x, output_size)\n",
        "def adaptive_max_pool_nd(n, x, output_size): return [nn.Identity, F.adaptive_max_pool1d, F.adaptive_max_pool2d, F.adaptive_max_pool3d][n](x, output_size)\n",
        "\n",
        "class AdaptivePool_at(nn.AdaptiveAvgPool1d): # AdaptiveAvgPool1d AdaptiveMaxPool1d\n",
        "    def __init__(self, dim=1, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.dim=dim\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(self.dim,-1)\n",
        "        shape = x.shape\n",
        "        return super().forward(x.flatten(0,-2)).unflatten(0, shape[:-1]).transpose(self.dim,-1)\n",
        "\n",
        "\n",
        "def adaptive_pool_at(x, dim, output_size, pool='avg'): # [b,c,h,w]\n",
        "    x = x.transpose(dim,-1)\n",
        "    shape = x.shape\n",
        "    parent={'avg':F.adaptive_avg_pool1d, 'max':F.adaptive_max_pool1d}[pool]\n",
        "    return parent(x.flatten(0,-2), output_size).unflatten(0, shape[:-1]).transpose(dim,-1)\n",
        "\n",
        "\n",
        "class ZeroExtend():\n",
        "    def __init__(self, dim=1, output_size=16):\n",
        "        self.dim, self.out = dim, output_size\n",
        "    def __call__(self, x): # [b,c,h,w]\n",
        "        return torch.cat((x, torch.zeros(*x.shape[:self.dim], self.out - x.shape[self.dim], *x.shape[self.dim+1:])), dim=self.dim)\n",
        "\n",
        "def make_pool_at(pool='avg', dim=1, output_size=5):\n",
        "    parent={'avg':nn.AdaptiveAvgPool1d, 'max':nn.AdaptiveMaxPool1d}[pool]\n",
        "    class AdaptivePool_at(parent): # AdaptiveAvgPool1d AdaptiveMaxPool1d\n",
        "        def __init__(self, dim=1, *args, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.dim=dim\n",
        "        def forward(self, x):\n",
        "            x = x.transpose(self.dim,-1)\n",
        "            shape = x.shape\n",
        "            return super().forward(x.flatten(0,-2)).unflatten(0, shape[:-1]).transpose(self.dim,-1)\n",
        "    return AdaptivePool_at(dim, output_size=output_size)\n",
        "\n",
        "class Shortcut():\n",
        "    def __init__(self, dim=1, c=3, sp=(3,3), nd=2):\n",
        "        self.dim = dim\n",
        "        # self.ch_pool = make_pool_at(pool='avg', dim=dim, output_size=c)\n",
        "        self.ch_pool = make_pool_at(pool='max', dim=dim, output_size=c)\n",
        "        # self.ch_pool = ZeroExtend(dim, output_size=c) # only for out_dim>=in_dim\n",
        "        # self.sp_pool = AdaptiveAvgPool_nd(nd, sp)\n",
        "        self.sp_pool = AdaptiveMaxPool_nd(nd, sp)\n",
        "\n",
        "    def __call__(self, x): # [b,c,h,w]\n",
        "        x = self.sp_pool(x) # spatial first preserves spatial more?\n",
        "        x = self.ch_pool(x)\n",
        "        return x\n",
        "\n",
        "class UpDownBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=7, r=1):\n",
        "        super().__init__()\n",
        "        act = nn.SiLU()\n",
        "        self.r = r\n",
        "        self.block = PixelShuffleConv(in_ch, out_ch, kernel=kernel, r=r)\n",
        "        # self.block = nn.Sequential(\n",
        "        #     nn.BatchNorm2d(in_ch), act, PixelShuffleConv(in_ch, out_ch, kernel=kernel, r=r)\n",
        "        # )\n",
        "        # if self.r>1: self.res_conv = nn.Sequential(nn.ConvTranspose2d(in_ch, out_ch, kernel, 2, kernel//2, output_padding=1))\n",
        "        # if self.r>1: self.res_conv = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'), nn.Conv2d(in_ch, out_ch, kernel, 1, kernel//2) if in_ch != out_ch else nn.Identity())\n",
        "        # if self.r>1: self.res_conv = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), nn.Conv2d(in_ch, out_ch, kernel, 1, kernel//2) if in_ch != out_ch else nn.Identity())\n",
        "        # if self.r>1: self.res_conv = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), nn.Conv2d(in_ch, out_ch, kernel, 1, kernel//2) if in_ch != out_ch else nn.Identity())\n",
        "\n",
        "\n",
        "        # elif self.r<1: self.res_conv = nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel, 2, kernel//2))\n",
        "        # elif self.r<1: self.res_conv = nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel, 1, kernel//2) if in_ch != out_ch else nn.Identity(), nn.MaxPool2d(2,2))\n",
        "        # elif self.r<1: self.res_conv = nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel, 1, kernel//2) if in_ch != out_ch else nn.Identity(), nn.AvgPool2d(2,2))\n",
        "        # elif self.r<1: self.res_conv = AttentionBlock(in_ch, out_ch, n_heads=4, q_stride=(2,2))\n",
        "\n",
        "        # else: self.res_conv = nn.Conv2d(in_ch, out_ch, kernel, 1, kernel//2) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x): # [b,c,h,w]\n",
        "        b, num_tok, c, *win = x.shape\n",
        "        x = x.flatten(0,1)\n",
        "        out = self.block(x)\n",
        "        # # shortcut = F.interpolate(x.unsqueeze(1), size=out.shape[1:], mode='nearest-exact').squeeze(1) # pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html\n",
        "        # shortcut = F.adaptive_avg_pool3d(x, out.shape[1:]) # https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
        "        # # shortcut = F.adaptive_max_pool3d(x, out.shape[1:]) # https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
        "        # # shortcut = F.adaptive_avg_pool3d(x, out.shape[1:]) if out.shape[1]>=x.shape[1] else F.adaptive_max_pool3d(x, out.shape[1:])\n",
        "        # shortcut(x)\n",
        "        shortcut = Shortcut(dim=1, c=out.shape[1], sp=out.shape[-2:], nd=2)(x)\n",
        "        out = out + shortcut\n",
        "        out = out.unflatten(0, (b, num_tok))\n",
        "        return out\n",
        "\n",
        "        # return out + shortcut + self.res_conv(x)\n",
        "        # return out + self.res_conv(x)\n",
        "        # return self.res_conv(x)\n",
        "\n",
        "# if out>in, inter=max=ave=near.\n",
        "# if out<in, inter=ave. max=max\n",
        "\n",
        "# stride2\n",
        "# interconv/convpool\n",
        "# pixelconv\n",
        "# pixeluib\n",
        "# pixelres\n",
        "# shortcut\n",
        "\n",
        "# in_ch, out_ch = 16,3\n",
        "in_ch, out_ch = 3,16\n",
        "model = UpDownBlock(in_ch, out_ch, r=1/2).to(device)\n",
        "# model = UpDownBlock(in_ch, out_ch, r=2).to(device)\n",
        "\n",
        "x = torch.rand(12, in_ch, 64,64, device=device)\n",
        "x = torch.rand(12, 2, in_ch, 64,64, device=device)\n",
        "out = model(x)\n",
        "\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0lclc9myo2c",
        "outputId": "625bf63f-a171-4cef-ff53-81b3be43f6df",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 2, 16, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title maxpool path bchw\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def conv_nd(n, *args, **kwargs): return [nn.Identity, nn.Conv1d, nn.Conv2d, nn.Conv3d][n](*args, **kwargs)\n",
        "def maxpool_nd(n, *args, **kwargs): return [nn.Identity, nn.MaxPool1d, nn.MaxPool2d, nn.MaxPool3d][n](*args, **kwargs)\n",
        "def avgpool_nd(n, *args, **kwargs): return [nn.Identity, nn.AvgPool1d, nn.AvgPool2d, nn.AvgPool3d][n](*args, **kwargs)\n",
        "\n",
        "import math\n",
        "class MaskUnitAttention(nn.Module):\n",
        "    # def __init__(self, d_model=16, n_heads=4, q_stride=None, nd=2):\n",
        "    def __init__(self, in_dim, d_model=16, n_heads=4, q_stride=None, nd=2):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads, self.d_head = n_heads, d_model // n_heads\n",
        "        self.scale = self.d_head**-.5\n",
        "        # self.qkv = conv_nd(nd, d_model, 3*d_model, 1, bias=False)\n",
        "        self.qkv = conv_nd(nd, in_dim, 3*d_model, 1, bias=False)\n",
        "        # self.out = conv_nd(nd, d_model, d_model, 1)\n",
        "        self.out = nn.Linear(d_model, d_model, 1)\n",
        "        self.q_stride = q_stride # If greater than 1, pool q with this stride. The stride should be flattened (e.g., 2x2 = 4).\n",
        "        if q_stride:\n",
        "            self.q_stride = (q_stride,)*nd if type(q_stride)==int else q_stride\n",
        "            self.q_pool = maxpool_nd(nd, self.q_stride, stride=self.q_stride)\n",
        "\n",
        "    def forward(self, x): # [b,num_tok,c,win1,win2]\n",
        "        b, num_tok, c, *win = x.shape\n",
        "        x = x.flatten(0,1) # [b*num_tok,c,win1,win2]\n",
        "        # print(x.shape)\n",
        "        # q, k, v = self.qkv(x).reshape(b, 3, self.n_heads, self.d_head, num_tok, win*win).permute(1,0,2,4,5,3) # [b,3*d_model,num_tok*win,win] -> 3* [b, n_heads, num_tok, win*win, d_head]\n",
        "        # self.qkv(x).flatten(1,-2).unflatten(-1, (self.heads,-1)).chunk(3, dim=-1) # [b,sp,n_heads,d_head]\n",
        "        q,k,v = self.qkv(x).chunk(3, dim=1) # [b*num_tok,d,win,win]\n",
        "        if self.q_stride:\n",
        "            q = self.q_pool(q)\n",
        "            win=[w//s for w,s in zip(win, self.q_stride)] # win = win/q_stride\n",
        "        if math.prod(win) >= 200:\n",
        "            print('MUattn', math.prod(win))\n",
        "            q, k, v = map(lambda t: t.reshape(b*num_tok, self.n_heads, self.d_head, -1).transpose(-2,-1), (q,k,v)) # [b*num_tok, n_heads, win*win, d_head]\n",
        "        else:\n",
        "            # q, k, v = map(lambda t: t.reshape(b, num_tok, self.n_heads, self.d_head, -1).permute(0,2,4,1,3), (q,k,v)) # downsampling attention # [b, n_heads, win*win, num_tok, d_head]\n",
        "            q, k, v = map(lambda t: t.reshape(b, num_tok, self.n_heads, self.d_head, -1).permute(0,2,1,4,3).flatten(2,3), (q,k,v)) # [b, n_heads, num_tok*win*win, d_head]\n",
        "\n",
        "        # x = F.scaled_dot_product_attention(q,k,v, attn_mask=None) # https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "        q, k = q.softmax(dim=-1)*self.scale, k.softmax(dim=-2) # [b, n_heads, t(/pool), d_head]\n",
        "        context = k.transpose(-2,-1) @ v # [b, n_heads, d_head, d_head]\n",
        "        x = q @ context # [b, n_heads, t(/pool), d_head]\n",
        "\n",
        "        # print('attn fwd 2',x.shape)\n",
        "        # x = x.transpose(1, 3).reshape(B, -1, self.d_model)\n",
        "        x = x.transpose(1,2).reshape(b, -1, self.d_model) # [b,t,d]\n",
        "        # x = x.transpose(-2,-1).reshape(x.shape[0], self.d_model, ) # [b,t,d]\n",
        "        # [b, n_heads, num_tok, win*win, d_head] -> [b, n_heads, d_head, num_tok, win*win] -> [b,c,num_tok*win,win]\n",
        "        # x = x.permute(0,1,4,2,3).reshape(b, self.d_model, num_tok*win,win) # [b, n_heads, num_tok, win*win, d_head]\n",
        "        # x = x.transpose(-2,-1).reshape(b, self.d_model, num_tok, *win) # [b*num_tok, n_heads, win*win, d_head]\n",
        "        x = self.out(x)\n",
        "        L=len(win)\n",
        "        x = x.reshape(b, num_tok, *win, self.d_model).permute(0,1,L+2,*range(2,L+2)) # [b, num_tok, out_dim, *win]\n",
        "        # x = x.unflatten(0, (b, num_tok))\n",
        "        return x # [b,num_tok,c,win1,win2]\n",
        "\n",
        "d_model=16\n",
        "model = MaskUnitAttention(d_model, n_heads=4, q_stride=2)\n",
        "# MaskUnitAttention(d_model=16, n_heads=4, q_stride=None, nd=2)\n",
        "# x=torch.randn(2,4,4,3)\n",
        "# x=torch.randn(2,3,d_model,8,8)\n",
        "x=torch.randn(2,3,d_model,32,32)\n",
        "# [b*num_tok,c,win,win]\n",
        "\n",
        "out = model(x)\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b840c4-6b0a-42a9-8d54-ec4cf23b4ae8",
        "id": "ZAyKHKivc0j7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MUattn 256\n",
            "torch.Size([2, 3, 16, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title hiera vit me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def zero_module(module):\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class LayerNorm_at(nn.RMSNorm): # LayerNorm RMSNorm\n",
        "    def __init__(self, dim=1, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.dim=dim\n",
        "    def forward(self, x):\n",
        "        return super().forward(x.transpose(self.dim,-1)).transpose(self.dim,-1)\n",
        "\n",
        "# # [b, h/win1* w/win2, c, win1,win2] -> [b,c,h,w]\n",
        "# def shuffle(x, window_shape): # [b,win*win, c, h/win, w/win] -> [b,1,c,h,w]\n",
        "#     # out_shape = [x.shape[0], -1, x.shape[2]] + [x*w for x,w in zip(x.shape[3:], window_shape)] # [b,1,c,h/win*wim, w/win*wim]\n",
        "#     out_shape = [x.shape[0], -1, x.shape[2]] + [x*w for x,w in zip(x.shape[3:], window_shape)] # [b,1,c,h/win*wim, w/win*wim]\n",
        "#     x = x.unflatten(1, (-1, *window_shape)) # [b,num_tok,win,win, c, h/win, w/win]\n",
        "#     D=x.dim()+1\n",
        "#     permute = [0,1,D//2] + [val for tup in zip(range(1+D//2, D), range(2, D//2)) for val in tup]\n",
        "#     x = x.permute(permute).reshape(out_shape)\n",
        "#     return x\n",
        "\n",
        "def unshuffle(x, window_shape): # [b,c,h,w] -> [b, h/win1* w/win2, c, win1,win2]\n",
        "    new_shape = list(x.shape[:2]) + [val for xx, win in zip(list(x.shape[2:]), window_shape) for val in [xx//win, win]] # [h,w]->[h/win1, win1, w/win2, win2]\n",
        "    x = x.reshape(new_shape) # [b, c, h/win1, win1, w/win2, win2]\n",
        "    # print('unsh',x.shape, window_shape, new_shape)\n",
        "    L = len(new_shape)\n",
        "    permute = ([0] + list(range(2, L - 1, 2)) + [1] + list(range(3, L, 2))) # [0,2,4,1,3,5] / [0,2,4,6,1,3,5,6]\n",
        "    return x.permute(permute).flatten(1, L//2-1) # [b, h/win1* w/win2, c, win1,win2]\n",
        "\n",
        "class HieraBlock(nn.Module):\n",
        "    # def __init__(self, d_model, n_heads, q_stride=None, mult=4, drop=0, nd=2):\n",
        "    def __init__(self, in_dim, d_model, n_heads, q_stride=None, mult=4, drop=0, nd=2):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # self.norm = LayerNorm_at(2, d_model) # LayerNorm RMSNorm\n",
        "        self.norm = LayerNorm_at(2, in_dim) # LayerNorm RMSNorm\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        # self.attn = MaskUnitAttention(d_model, n_heads, q_stride)\n",
        "        self.attn = MaskUnitAttention(in_dim, d_model, n_heads, q_stride)\n",
        "        ff_dim=d_model*mult\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.RMSNorm(d_model), nn.Linear(d_model, ff_dim), nn.ReLU(), # ReLU GELU\n",
        "            nn.RMSNorm(ff_dim), nn.Dropout(drop), nn.Linear(ff_dim, d_model)\n",
        "            # nn.RMSNorm(d_model), act, nn.Linear(d_model, ff_dim),\n",
        "            # nn.RMSNorm(ff_dim), act, nn.Linear(ff_dim, d_model)\n",
        "            # nn.RMSNorm(d_model), nn.Linear(d_model, ff_dim), nn.ReLU(), nn.Dropout(dropout), # ReLU GELU\n",
        "            # nn.Linear(ff_dim, d_model), nn.Dropout(dropout),\n",
        "        )\n",
        "        # self.res = conv_nd(nd, d_model, d_model, q_stride, q_stride) if q_stride else nn.Identity()\n",
        "\n",
        "        # self.res = nn.Sequential(\n",
        "        #     conv_nd(nd, in_dim, d_model, 1, 1) if in_dim!=d_model else nn.Identity(),\n",
        "        #     # maxpool_nd(nd, q_stride, q_stride) if q_stride else nn.Identity(),\n",
        "        #     avgpool_nd(nd, q_stride, q_stride) if q_stride else nn.Identity(),\n",
        "        # )\n",
        "        self.res = UpDownBlock(in_dim, d_model, kernel=1, r=1/2 if q_stride else 1)\n",
        "\n",
        "        # x = self.proj(x_norm).unflatten(1, (self.attn.q_stride, -1)).max(dim=1).values # pooling res # [b, (Sy, Sx, h/Sy, w/Sx), c] -> [b, (Sy, Sx), (h/Sy, w/Sx), c] -> [b, (h/Sy, w/Sx), c]\n",
        "\n",
        "\n",
        "    def forward(self, x): # [b, num_tok, c, *win]\n",
        "        b, num_tok, c, *win = x.shape\n",
        "        # print('attnblk fwd',x.shape)\n",
        "        # x = x + self.drop(self.self(self.norm(x)))\n",
        "        # print('attnblk fwd',self.res(x.flatten(0,1)).shape, self.drop(self.attn(self.norm(x))).flatten(0,1).shape)\n",
        "        # x = self.res(x.flatten(0,1)) + self.drop(self.attn(self.norm(x))).flatten(0,1) # [b*num_tok,c,win1,win2,win3]\n",
        "        x = self.res(x) + self.drop(self.attn(self.norm(x))) # [b*num_tok,c,win1,win2,win3]\n",
        "        # x = x + self.ff(x)\n",
        "        # x = x + self.ff(x.transpose(1,-1)).transpose(1,-1)\n",
        "        x = x + self.ff(x.transpose(2,-1)).transpose(2,-1)\n",
        "        # x = self.ff(x)\n",
        "        # x = x.unflatten(0, (b, num_tok))\n",
        "        return x\n",
        "\n",
        "    # def forward(self, x): # [b,t,c] # [b, (Sy, Sx, h/Sy, w/Sx), c]\n",
        "    #     # Attention + Q Pooling\n",
        "    #     x_norm = self.norm1(x)\n",
        "    #     if self.dim != self.dim_out:\n",
        "    #         x = self.proj(x_norm).unflatten(1, (self.attn.q_stride, -1)).max(dim=1).values # pooling res # [b, (Sy, Sx, h/Sy, w/Sx), c] -> [b, (Sy, Sx), (h/Sy, w/Sx), c] -> [b, (h/Sy, w/Sx), c]\n",
        "    #     x = x + self.drop_path(self.attn(x_norm))\n",
        "    #     x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "    #     return x\n",
        "\n",
        "\n",
        "class levelBlock(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, n_heads=None, depth=1, r=1):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            UpDownBlock(in_ch, out_ch, r=min(1,r)) if in_ch != out_ch or r<1 else nn.Identity(),\n",
        "            # AttentionBlock(d_model, d_model, n_heads, q_stride) if in_ch != out_ch or r<1 else nn.Identity(),\n",
        "            # AttentionBlock(d_model, d_model, n_heads, q_stride=(2,2)),\n",
        "            *[HieraBlock(d_model, d_model, n_heads) for i in range(1)],\n",
        "            # UpDownBlock(out_ch, out_ch, r=r) if r>1 else nn.Identity(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)\n",
        "\n",
        "\n",
        "class Hiera(nn.Module):\n",
        "    def __init__(self, patch_size, in_dim, d_model, out_dim=None, n_heads=4, nlayers=1, drop=0.):\n",
        "    # def __init__(self, in_dim, out_dim, d_model, n_heads, depth):\n",
        "        # patch_size=4\n",
        "        super().__init__()\n",
        "        self.embed = nn.Sequential( # in, out, kernel, stride, pad\n",
        "            # nn.Conv2d(in_dim, d_model, 7, 2, 7//2, bias=False), nn.MaxPool2d(3,2,1), # nn.MaxPool2d(2,2)\n",
        "            nn.Conv2d(in_dim, d_model, 7, 1, 7//2, bias=False),\n",
        "            # nn.Conv2d(in_dim, d_model, patch_size, patch_size), # like patch\n",
        "            # nn.Conv2d(in_dim, d_model, 3, 2, 3//2, bias=False), nn.BatchNorm2d(d_model), nn.ReLU(),\n",
        "            # UpDownBlock(in_dim, dim, r=1/2, kernel=3), UpDownBlock(dim, dim, r=1/2, kernel=3)\n",
        "            # nn.PixelUnshuffle(2), nn.Conv2d(in_dim*2**2, dim, 1, bias=False),\n",
        "            # ResBlock(in_dim, d_model, kernel),\n",
        "            )\n",
        "        # # self.pos_emb = LearnedRoPE2D(dim) # LearnedRoPE2D, RoPE2D\n",
        "\n",
        "        emb_shape = (32,32)\n",
        "        # emb_shape = (8,32,32)\n",
        "        if len(emb_shape) == 3: # for video\n",
        "            pos_spatial = nn.Parameter(torch.randn(1, emb_shape[1]*emb_shape[2], d_model)*.02)\n",
        "            pos_temporal = nn.Parameter(torch.randn(1, emb_shape[0], d_model)*.02)\n",
        "            self.pos_emb = pos_spatial.repeat(1, emb_shape[0], 1) + torch.repeat_interleave(pos_temporal, emb_shape[1] * emb_shape[2], dim=1)\n",
        "        elif len(emb_shape) == 2: # for img\n",
        "            self.pos_emb = nn.Parameter(torch.randn(1, d_model, *emb_shape)*.02) # 56*56=3136\n",
        "        # self.pos_emb = self.pos_emb.flatten(2).transpose(-2,-1)\n",
        "\n",
        "        # self.blocks = nn.Sequential(*[AttentionBlock(d_model, n_heads, q_stride=(2,2) if i in [1,3] else None) for i in range(depth)])\n",
        "        mult = [1,1,1,1]\n",
        "        # mult = [1,2,4,8] # [1,2,3,4] [1,2,2,2]\n",
        "        ch_list = [d_model * m for m in mult] # [128, 256, 384, 512]\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            # HieraBlock(ch_list[0], ch_list[1], n_heads, q_stride=(2,2)),\n",
        "            # UpDownBlock(ch_list[0], ch_list[1], kernel=1, r=1/2),\n",
        "            HieraBlock(ch_list[1], ch_list[1], n_heads),\n",
        "            # HieraBlock(ch_list[1], ch_list[2], n_heads, q_stride=(2,2)),\n",
        "            # UpDownBlock(ch_list[1], ch_list[2], kernel=1, r=1/2),\n",
        "            # HieraBlock(ch_list[2], ch_list[2], n_heads),\n",
        "            )\n",
        "        self.norm = nn.RMSNorm(ch_list[2]) # LayerNorm RMSNorm\n",
        "        self.out = nn.Linear(ch_list[2], out_dim, bias=False) if out_dim and out_dim != ch_list[2] else None\n",
        "\n",
        "\n",
        "    def forward(self, x, context_indices=None): # [b,c,h,w], [b,num_tok]\n",
        "        x = self.embed(x)\n",
        "        # print('vit fwd', x.shape, self.pos_emb.shape)\n",
        "        x = x + self.pos_emb\n",
        "        x = unshuffle(x, (4,4)) # [b,num_tok,c,win1,win2,win3] or [b,1,c,f,h,w]\n",
        "        if context_indices != None: x = x[torch.arange(x.shape[0]).unsqueeze(-1), context_indices] # [batch, num_context_toks, d_model]\n",
        "\n",
        "        # print('vit fwd1', x.shape)\n",
        "        x = self.blocks(x) # [b,num_tok,c,1,1,1]\n",
        "        # print('vit fwd2', x.shape)\n",
        "        # x = x.mean(-1).mean(-1)\n",
        "        x = x.flatten(-2).max(-1)[0]\n",
        "        # print('vit fwd3', x.shape)\n",
        "        x = x.squeeze() # [b,num_tok,d]\n",
        "        out = self.norm(x)\n",
        "        if self.out: out = self.out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# pos_emb rope < learn < learned\n",
        "# conv > pixel?\n",
        "# droppath not required\n",
        "\n",
        "# norm,act,conv < conv,norm,act\n",
        "# 2*s1 < uib < resblock\n",
        "# gatedadaln 3 < 2 = 1 < ffmult4 = 2*gatedadaln\n",
        "# MaxPool2d(2,2) < MaxPool2d(3,2,3//2)\n",
        "\n",
        "# patchattn only for\n",
        "\n",
        "# multiendfusion negligible diff\n",
        "\n",
        "\n",
        "d_model = 64\n",
        "in_dim = 3\n",
        "patch_size = 2\n",
        "# model = Hiera(patch_size, in_dim, d_model, n_heads=4, nlayers=4, drop=0.).to(device)\n",
        "model = Hiera(patch_size, in_dim, d_model, n_heads=4, nlayers=1, drop=0.).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 27584\n",
        "x = torch.rand((4, in_dim, 32, 32), device=device)\n",
        "out = model(x)\n",
        "print(out.shape)\n",
        "\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 59850\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lec1Nq7nkbgt",
        "outputId": "9b8822b2-5716-4944-bdd7-1e3ee04d47e5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124928\n",
            "torch.Size([4, 64, 64])\n",
            "124928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((4, in_dim, 32, 32), device=device)\n",
        "print(x.max(-1)[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJidzmh4FE5U",
        "outputId": "9108c4f6-3fb4-4836-c36f-8ff633cfcb5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vit"
      ],
      "metadata": {
        "id": "g3XSZZyUPY1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title FSQ me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module):\n",
        "    def __init__(self, levels):\n",
        "        super().__init__()\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cumprod(torch.tensor([*levels[1:], 1], device=device).flip(-1), dim=0).flip(-1)\n",
        "        self.half_width = (self.levels-1)/2\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "\n",
        "    def forward(self, z, beta=1): # beta in (0,1). beta->0 => values more spread out\n",
        "        offset = (self.levels+1) % 2 /2 # .5 if even, 0 if odd\n",
        "        bound = (F.sigmoid(z)-1/2) * (self.levels-beta) + offset\n",
        "        # print('fwd', bound) #\n",
        "        quantized = ste_round(bound)\n",
        "        # print('fwd', quantized) # 4: -1012\n",
        "        return (quantized-offset) / self.half_width # split [-1,1]\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        zhat = (zhat + 1) * self.half_width\n",
        "        return (zhat * self.basis).sum(axis=-1)#.int()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes = torch.remainder(indices//self.basis, self.levels)\n",
        "        # print(\"codes\",codes)\n",
        "        return codes / self.half_width - 1\n",
        "\n",
        "# fsq = FSQ(levels = [5,4,3,2])\n",
        "# # print(fsq.codebook)\n",
        "# batch_size, seq_len = 2, 4\n",
        "# # x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "# x = torch.linspace(-2,2,7).repeat(4,1).T\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "# # la = fsq.indexes_to_codes(lact)\n",
        "# # print(la)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eDqkaM2v0_zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title AttentionBlock\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def zero_module(module):\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class SelfAttn(nn.Module):\n",
        "    def __init__(self, dim, n_heads):\n",
        "        super().__init__()\n",
        "        self.dim, self.n_heads = dim, n_heads\n",
        "        d_head = dim//n_heads\n",
        "        self.qkv = nn.Linear(dim, dim*3, bias=False)\n",
        "        # self.lin = nn.Linear(dim, dim)\n",
        "        self.lin = zero_module(nn.Linear(dim, dim))\n",
        "        # self.rope = RoPE(d_head, seq_len=512, base=10000)\n",
        "        # self.rope = RoPE2D(d_head, h=64, w=64, base=100)\n",
        "        self.scale = d_head**-.5\n",
        "\n",
        "    def forward(self, x): # [b,t,d]\n",
        "        q,k,v = self.qkv(x).unflatten(-1, (self.n_heads,-1)).transpose(1,2).chunk(3, dim=-1) # [b, t, n_heads, d_head] -> [b, n_heads, t, d_head]\n",
        "        # q, k = self.rope(q), self.rope(k)\n",
        "        # x = F.scaled_dot_product_attention(q,k,v, attn_mask=None) # https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "        q, k = q.softmax(dim=-1)*self.scale, k.softmax(dim=-2)\n",
        "        context = k.transpose(-2,-1) @ v # [batch, n_heads, d_head, d_head]\n",
        "        x = q @ context # [b, n_heads, t, d_head]\n",
        "        # # print('SelfAttn', x.shape)\n",
        "        x = x.transpose(1,2).flatten(2)\n",
        "        return self.lin(x)\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, mult=4, drop=0.):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # self.norm = nn.RMSNorm(d_model, elementwise_affine=False) # LayerNorm RMSNorm\n",
        "        self.norm1, self.norm2 = nn.LayerNorm(d_model), nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.attn = SelfAttn(d_model, n_heads)\n",
        "        act = nn.GELU() # ReLU GELU\n",
        "        ff_dim=d_model*mult\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.RMSNorm(d_model), act, nn.Dropout(drop), nn.Linear(d_model, ff_dim),\n",
        "            # nn.RMSNorm(ff_dim), act, nn.Dropout(drop), nn.Linear(ff_dim, d_model)\n",
        "            nn.RMSNorm(ff_dim), act, nn.Dropout(drop), zero_module(nn.Linear(ff_dim, d_model))\n",
        "            # nn.RMSNorm(d_model), nn.Dropout(drop), nn.Linear(d_model, ff_dim), act,\n",
        "            # nn.RMSNorm(ff_dim), nn.Dropout(drop), nn.Linear(ff_dim, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # [batch, seq_len, d_model]\n",
        "        # print('attnblk fwd',x.shape)\n",
        "        x = x + self.drop(self.attn(self.norm1(x)))\n",
        "        x = x + self.ff(x)\n",
        "        # x = x + self.drop(self.ff(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    # def __init__(self, in_dim, d_model, out_dim=None, nhead=8, d_hid=None, nlayers=1, dropout = 0.):\n",
        "    def __init__(self, patch_size, in_dim, d_model, out_dim=None, n_heads=4, nlayers=1, drop=0.):\n",
        "        super().__init__()\n",
        "        patch_size=2\n",
        "        self.embed = nn.Sequential(\n",
        "            # nn.Conv2d(in_dim, d_model, patch_size, patch_size), # like patch\n",
        "            nn.Conv2d(in_dim, d_model, 7, 1, 7//2, bias=False)\n",
        "            # nn.Conv2d(in_dim, d_model, kernel_size=7, stride=2, padding=7//2, bias=False), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "            # nn.Conv2d(in_dim, d_model, 3, 2, 3//2, bias=False), nn.BatchNorm2d(d_model), nn.ReLU(),\n",
        "            )\n",
        "        # self.embed.requires_grad=False\n",
        "        # self.pos_enc = RotEmb(d_model, top=1, base=10000)\n",
        "        self.pos_emb = nn.Parameter(torch.randn(1, 32*32, d_model)*.02)\n",
        "        # self.pos_emb = nn.Parameter(RoPE2D(dim=d_model, h=8, w=8, base=1000), requires_grad=False)\n",
        "\n",
        "        # self.pos_emb = nn.Parameter(RoPE(d_model, seq_len=(32//patch_size)**2, base=10000), requires_grad=False)\n",
        "        self.transformer = nn.Sequential(*[AttentionBlock(d_model, d_model, n_heads) for _ in range(nlayers)])\n",
        "        self.norm = nn.RMSNorm(d_model) # LayerNorm RMSNorm\n",
        "        self.lin = nn.Linear(d_model, out_dim) if out_dim and out_dim != d_model else None\n",
        "\n",
        "    def forward(self, x, context_indices=None): # [batch, num_context_toks, 3], [batch, num_context_toks] # True will be ignored by the attention # https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "        x = self.embed(x).flatten(2).transpose(1,2) # [b,c,h,w]->[b,h*w,c] # [batch, seq_len, d_model] or [batch, num_context_toks, d_model]\n",
        "        # x = self.pos_enc(x)\n",
        "        # print(\"TransformerModel\",x.shape, self.pos_emb.shape)\n",
        "        x = x + self.pos_emb[:,:x.shape[1]]\n",
        "        if context_indices != None: x = x[torch.arange(x.shape[0]).unsqueeze(-1), context_indices] # [batch, num_context_toks, d_model]\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        out = self.norm(x)\n",
        "        if self.lin: out = self.lin(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "d_model = 64\n",
        "in_dim = 3\n",
        "patch_size = 2\n",
        "# model = ViT(patch_size, in_dim, d_model, n_heads=4, nlayers=4, drop=0.).to(device)\n",
        "model = ViT(patch_size, in_dim, d_model, n_heads=4, nlayers=1, drop=0.).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 27584\n",
        "x = torch.rand((4, in_dim, 32, 32), device=device)\n",
        "out = model(x)\n",
        "print(out.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f6T4F651kmGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad110d6-9b44-4701-d836-58dedbf1ead6",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125120\n",
            "torch.Size([4, 1024, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title simplex\n",
        "# !pip install -q opensimplex\n",
        "import opensimplex\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def simplexmask2d(hw=(32,32), ctx_scale=(.85,1), trg_scale=(.6,.8), B=64, chaos=2):\n",
        "    seed = np.random.randint(1e10, size=B)\n",
        "    ix = iy = np.linspace(0, chaos, num=max(hw))\n",
        "    noise = opensimplex.noise3array(ix, iy, seed) # [b,h,w]\n",
        "    # plt.pcolormesh(noise[:1])\n",
        "    # plt.rcParams[\"figure.figsize\"] = (20,3)\n",
        "    # plt.show()\n",
        "    noise = torch.from_numpy(noise)\n",
        "    ctx_mask_scale = torch.rand(1) * (ctx_scale[1] - ctx_scale[0]) + ctx_scale[0] # in (min_s, max_s) # all blocks same size\n",
        "    trg_mask_scale = torch.rand(1) * (trg_scale[1] - trg_scale[0]) + trg_scale[0]\n",
        "    val, ind = noise.flatten(1).sort() # [b,h*w]\n",
        "    seq = hw[0]*hw[1]\n",
        "    trg_index = ind[:,-int(seq*trg_mask_scale):]\n",
        "    ctx_index = ind[:,-int(seq*ctx_mask_scale):-int(seq*trg_mask_scale)] # ctx wraps trg ; most similar to multiblock\n",
        "    # ctx_index = ind[:,:int(seq*ctx_mask_scale)-int(seq*trg_mask_scale)] # ctx hug bottom\n",
        "    # ctx_index = ind[:,-int(seq*ctx_mask_scale)-int(seq*trg_mask_scale):-int(seq*trg_mask_scale)] # ctx wraps trg ; most similar to multiblock\n",
        "    # ctx_index = ind[:,:int(seq*ctx_mask_scale)] # ctx hug bottom\n",
        "    return ctx_index, trg_index\n",
        "\n",
        "b=16\n",
        "# trg_index, ctx_index = simplexmask1d(seq=500, ctx_scale=(.85,1), trg_scale=(.6,.8), B=b, chaos=3)\n",
        "\n",
        "# ctx_index, trg_index = simplexmask2d(hw=(32,32), ctx_scale=(.6,.7), trg_scale=(.4,.5), B=b, chaos=2)\n",
        "# ctx_index, trg_index = simplexmask2d(hw=(32,32), ctx_scale=(.2,.3), trg_scale=(.4,.5), B=b, chaos=3)\n",
        "ctx_index, trg_index = simplexmask2d(hw=(32,32), ctx_scale=(.85,1), trg_scale=(.7,.8), B=b, chaos=1)\n",
        "# mask = torch.zeros(1 ,32*32)\n",
        "# mask[:, trg_index[:1]] = 1\n",
        "# mask[:, ctx_index[:1]] = .5\n",
        "# mask = mask.reshape(1,32,32)\n",
        "# print(mask)\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# imshow(mask)\n",
        "\n",
        "mask = torch.zeros(b ,32*32)\n",
        "mask[torch.arange(b).unsqueeze(-1), trg_index] = 1\n",
        "mask[torch.arange(b).unsqueeze(-1), ctx_index] = .5\n",
        "mask = mask.reshape(b,1,32,32)\n",
        "import torchvision\n",
        "imshow(torchvision.utils.make_grid(mask, nrow=8))\n"
      ],
      "metadata": {
        "id": "Fh9o__m2-j7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f726ccd8-f21e-4409-b054-54a866017570",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m266.2/268.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.0/268.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title masks\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def multiblock(seq, min_s, max_s, M=1): # https://github.com/facebookresearch/ijepa/blob/main/src/masks/multiblock.py\n",
        "    mask_len = torch.rand(1) * (max_s - min_s) + min_s # in (min_s, max_s) # all blocks same size\n",
        "    mask_pos = torch.rand(M) * (1 - mask_len) # in (0, 1 - mask_len)\n",
        "    mask_len, mask_pos = (mask_len * seq).int(), mask_pos * seq\n",
        "    indices = torch.arange(seq).unsqueeze(0) # [1, seq]\n",
        "    target_mask = (indices >= mask_pos.unsqueeze(-1)) & (indices < (mask_pos + mask_len).unsqueeze(-1)) # [M, seq]\n",
        "    return target_mask\n",
        "\n",
        "\n",
        "def multiblock2d(hw=(8,8), scale=(.15,.2), aspect_ratio=(.75,1.5), M=1): # https://github.com/facebookresearch/ijepa/blob/main/src/masks/multiblock.py\n",
        "    mask_aspect = torch.rand(1) * (aspect_ratio[1] - aspect_ratio[0]) + aspect_ratio[0] # in (min_s, max_s) # all blocks same size\n",
        "    mask_scale = torch.rand(1) * (scale[1] - scale[0]) + scale[0] # in (min_s, max_s) # all blocks same size\n",
        "    h = (mask_scale/mask_aspect)**.5# h*(h*aspect) = scale\n",
        "    w = h * mask_aspect\n",
        "    h_pos, w_pos = torch.rand(M)*(1-w), torch.rand(M)*(1-h) # in (0, 1 - mask_len)\n",
        "    h_len, h_pos = (h*hw[0]).int(), h_pos*hw[0]\n",
        "    w_len, w_pos = (w*hw[1]).int(), w_pos*hw[1]\n",
        "    h_ind, w_ind = torch.arange(hw[0]).unsqueeze(0), torch.arange(hw[1]).unsqueeze(0) # [1, seq]\n",
        "    h_mask = (h_ind>=h_pos.unsqueeze(-1)) & (h_ind<(h_pos+h_len).unsqueeze(-1)) # [M, seq]\n",
        "    w_mask = (w_ind>=w_pos.unsqueeze(-1)) & (w_ind<(w_pos+w_len).unsqueeze(-1)) # [M, seq]\n",
        "    target_mask = h_mask.unsqueeze(-1) & w_mask.unsqueeze(-2) # [M, seq, seq]\n",
        "    return target_mask\n",
        "\n",
        "# https://arxiv.org/pdf/2210.07224\n",
        "def randpatch(seq, mask_size=8, gamma=0.9): # num patches of seq, mask patch size, masking ratio\n",
        "    # mask = torch.rand(seq//mask_size)<gamma\n",
        "    length = seq//mask_size\n",
        "    g = torch.normal(gamma, std=.1, size=(1,)).clamp(.5,.9)\n",
        "    # g = gamma\n",
        "    idx = torch.randperm(length)[:int(length*g)]\n",
        "    mask = torch.zeros(length, dtype=bool)\n",
        "    mask[idx] = True\n",
        "    mask = mask.repeat_interleave(mask_size, dim=-1)\n",
        "    return mask # [seq] , True -> mask\n",
        "\n",
        "\n",
        "import torch\n",
        "def apply_masks(x, mask): # [b,t,d], [mask_size] # https://github.com/facebookresearch/ijepa/blob/main/src/masks/utils.py\n",
        "    mask_keep = mask.unsqueeze(-1).repeat(x.size(0), 1, x.size(-1)) # [batch,T,dim]\n",
        "    return torch.gather(x, dim=1, index=mask_keep) # [batch,mask_size,dim]\n",
        "\n",
        "\n",
        "# @title ijepa multiblock next\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/masks/multiblock.py\n",
        "import math\n",
        "from multiprocessing import Value\n",
        "import torch\n",
        "\n",
        "class MaskCollator(object):\n",
        "    def __init__(self, hw=(224, 224), enc_mask_scale=(.85,1), pred_mask_scale=(.15,.2), aspect_ratio=(.75,1.25),\n",
        "        nenc=1, npred=2, min_keep=4, allow_overlap=False):\n",
        "        super().__init__()\n",
        "        self.height, self.width = hw\n",
        "        self.enc_mask_scale = enc_mask_scale\n",
        "        self.pred_mask_scale = pred_mask_scale\n",
        "        self.aspect_ratio = aspect_ratio\n",
        "        self.nenc = nenc\n",
        "        self.npred = npred\n",
        "        self.min_keep = min_keep  # minimum number of patches to keep\n",
        "        self.allow_overlap = allow_overlap  # whether to allow overlap b/w enc and pred masks\n",
        "\n",
        "    def _sample_block_size(self, scale, aspect_ratio_scale):\n",
        "        _rand = torch.rand(1).item()\n",
        "        # -- Sample block scale\n",
        "        min_s, max_s = scale\n",
        "        mask_scale = min_s + _rand * (max_s - min_s)\n",
        "        max_keep = int(self.height * self.width * mask_scale) # num patches to keep\n",
        "        # -- Sample block aspect-ratio\n",
        "        min_ar, max_ar = aspect_ratio_scale\n",
        "        aspect_ratio = min_ar + _rand * (max_ar - min_ar)\n",
        "        # -- Compute block height and width (given scale and aspect-ratio)\n",
        "        h = int(round(math.sqrt(max_keep * aspect_ratio)))\n",
        "        w = int(round(math.sqrt(max_keep / aspect_ratio)))\n",
        "        while h >= self.height: h -= 1 # crop mask to be smaller than img\n",
        "        while w >= self.width: w -= 1\n",
        "        return (h, w)\n",
        "\n",
        "    def _sample_block_mask(self, b_size, acceptable_regions=None):\n",
        "        h, w = b_size\n",
        "\n",
        "        def constrain_mask(mask, tries=0):\n",
        "            \"\"\" Helper to restrict given mask to a set of acceptable regions \"\"\"\n",
        "            N = max(int(len(acceptable_regions)-tries), 0)\n",
        "            for k in range(N):\n",
        "                mask *= acceptable_regions[k]\n",
        "        # --\n",
        "        # -- Loop to sample masks until we find a valid one\n",
        "        tries = 0\n",
        "        timeout = og_timeout = 20\n",
        "        valid_mask = False\n",
        "        while not valid_mask:\n",
        "            # -- Sample block top-left corner\n",
        "            top = torch.randint(0, self.height - h, (1,))\n",
        "            left = torch.randint(0, self.width - w, (1,))\n",
        "            mask = torch.zeros((self.height, self.width), dtype=torch.int32)\n",
        "            mask[top:top+h, left:left+w] = 1\n",
        "            # -- Constrain mask to a set of acceptable regions\n",
        "            if acceptable_regions is not None:\n",
        "                constrain_mask(mask, tries)\n",
        "            mask = torch.nonzero(mask.flatten())\n",
        "            # -- If mask too small try again\n",
        "            valid_mask = len(mask) > self.min_keep\n",
        "            if not valid_mask:\n",
        "                timeout -= 1\n",
        "                if timeout == 0:\n",
        "                    tries += 1\n",
        "                    timeout = og_timeout\n",
        "        mask = mask.squeeze()\n",
        "        # --\n",
        "        mask_complement = torch.ones((self.height, self.width), dtype=torch.int32)\n",
        "        mask_complement[top:top+h, left:left+w] = 0\n",
        "        # --\n",
        "        return mask, mask_complement\n",
        "\n",
        "    def __call__(self, B):\n",
        "        '''\n",
        "        Create encoder and predictor masks when collating imgs into a batch\n",
        "        # 1. sample enc block (size + location) using seed\n",
        "        # 2. sample pred block (size) using seed\n",
        "        # 3. sample several enc block locations for each image (w/o seed)\n",
        "        # 4. sample several pred block locations for each image (w/o seed)\n",
        "        # 5. return enc mask and pred mask\n",
        "        '''\n",
        "        p_size = self._sample_block_size(scale=self.pred_mask_scale, aspect_ratio_scale=self.aspect_ratio)\n",
        "        e_size = self._sample_block_size(scale=self.enc_mask_scale, aspect_ratio_scale=(1., 1.))\n",
        "\n",
        "        collated_masks_pred, collated_masks_enc = [], []\n",
        "        min_keep_pred = self.height * self.width\n",
        "        min_keep_enc = self.height * self.width\n",
        "        for _ in range(B):\n",
        "\n",
        "            masks_p, masks_C = [], []\n",
        "            for _ in range(self.npred):\n",
        "                mask, mask_C = self._sample_block_mask(p_size)\n",
        "                masks_p.append(mask)\n",
        "                masks_C.append(mask_C)\n",
        "                min_keep_pred = min(min_keep_pred, len(mask))\n",
        "            collated_masks_pred.append(masks_p)\n",
        "\n",
        "            acceptable_regions = masks_C\n",
        "            try:\n",
        "                if self.allow_overlap:\n",
        "                    acceptable_regions= None\n",
        "            except Exception as e:\n",
        "                print(f'Encountered exception in mask-generator {e}')\n",
        "\n",
        "            masks_e = []\n",
        "            for _ in range(self.nenc):\n",
        "                mask, _ = self._sample_block_mask(e_size, acceptable_regions=acceptable_regions)\n",
        "                masks_e.append(mask)\n",
        "                min_keep_enc = min(min_keep_enc, len(mask))\n",
        "            collated_masks_enc.append(masks_e)\n",
        "        collated_masks_pred = [[cm[:min_keep_pred] for cm in cm_list] for cm_list in collated_masks_pred]\n",
        "        collated_masks_pred = torch.utils.data.default_collate(collated_masks_pred)\n",
        "        # --\n",
        "        collated_masks_enc = [[cm[:min_keep_enc] for cm in cm_list] for cm_list in collated_masks_enc]\n",
        "        collated_masks_enc = torch.utils.data.default_collate(collated_masks_enc)\n",
        "        return collated_masks_enc, collated_masks_pred\n",
        "\n",
        "mask_collator = MaskCollator(hw=(32,32), enc_mask_scale=(.85, 1.), pred_mask_scale=(.15, .2), aspect_ratio=(.75, 1.5),\n",
        "        nenc=1, npred=4, min_keep=4,\n",
        "        # allow_overlap=True)\n",
        "        allow_overlap=False)\n",
        "\n",
        "b=16\n",
        "collated_masks_enc, collated_masks_pred = mask_collator(b)\n",
        "ctx_index, trg_index = torch.stack(collated_masks_enc).squeeze(0), torch.stack(collated_masks_pred).transpose(0,1).flatten(1).unique(dim=1) # [num_msk, b,num_tok]->[b,num_tok] # [64, 65], [64, 32]\n",
        "\n",
        "# mask = torch.zeros(1 ,32*32)\n",
        "# mask[:, trg_index[:1]] = 1\n",
        "# mask[:, ctx_index[:1]] = .5\n",
        "# mask = mask.reshape(1,32,32)\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "# imshow(mask)\n",
        "\n",
        "mask = torch.zeros(b ,32*32)\n",
        "mask[torch.arange(b).unsqueeze(-1), trg_index] = 1\n",
        "mask[torch.arange(b).unsqueeze(-1), ctx_index] = .5\n",
        "mask = mask.reshape(b,1,32,32)\n",
        "import torchvision\n",
        "imshow(torchvision.utils.make_grid(mask, nrow=8))\n"
      ],
      "metadata": {
        "id": "pQfM2fYvcTh6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "c948aa9c-3b40-4a0b-d28f-b3503c7d38bf",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transformer Predictor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class TransformerPredictor(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, out_dim=None, n_heads=4, nlayers=1, drop=0.):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(in_dim, d_model)# if in_dim != d_model else None\n",
        "        # self.pos_enc = RotEmb(d_model, top=1, base=10000)\n",
        "        self.pos_emb = nn.Parameter(torch.randn(1, 32*32, d_model)*0.02)\n",
        "        # self.pos_emb = nn.Parameter(RoPE2D(dim=d_model, h=8, w=8, base=1000), requires_grad=False)\n",
        "        # self.pos_emb = nn.Parameter(RoPE(d_model, seq_len=32*32, base=10000), requires_grad=False)\n",
        "\n",
        "        self.transformer = nn.Sequential(*[AttentionBlock(d_model, d_model, n_heads) for _ in range(nlayers)])\n",
        "\n",
        "        self.cls = nn.Parameter(torch.randn(1,1,d_model)*0.02) # randn zeros\n",
        "        out_dim = out_dim or d_model\n",
        "        self.norm = nn.RMSNorm(d_model) # LayerNorm RMSNorm\n",
        "        self.lin = nn.Linear(d_model, out_dim)# if out_dim != d_model else None\n",
        "\n",
        "    def forward(self, x, context_indices, trg_indices): # [batch, seq_len, d_model], [batch, seq_len] # True will be ignored by the attention # https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "        x = self.embed(x) # [batch, seq_len, d_model] or [batch, num_context_toks, d_model]\n",
        "        batch, seq, dim = x.shape\n",
        "        # x = x * self.pos_enc(context_indices)\n",
        "        x = x + self.pos_emb[0,context_indices]\n",
        "\n",
        "        # pred_tokens = self.cls * self.pos_enc(trg_indices) # [M, num_trg_toks, d_model]\n",
        "        pred_tokens = self.cls + self.pos_emb[0,trg_indices]\n",
        "        # print(\"pred fwd\", x.shape, pred_tokens.shape)\n",
        "        x = torch.cat([x, pred_tokens], dim=1) # [batch, seq_len+num_trg_toks, d_model]\n",
        "        out = self.transformer(x)\n",
        "\n",
        "        out = self.norm(out)\n",
        "        out = out[:,seq:] # [batch, num_trg_toks, d_model]\n",
        "        out = self.lin(out)\n",
        "        # print(\"pred fwd\", out.shape)\n",
        "        return out # [seq_len, batch_size, ntoken]\n"
      ],
      "metadata": {
        "id": "M-zdjdJixtOu",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title IJEPA\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class IJEPA(nn.Module):\n",
        "    def __init__(self, in_dim=3, d_model=32, out_dim=None, nlayers=2, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.out_dim = out_dim = out_dim or d_model\n",
        "        self.patch_size = 4 # 4\n",
        "        # self.student = Hiera(self.patch_size, in_dim, d_model, out_dim=out_dim, n_heads=n_heads, nlayers=nlayers, drop=0.)\n",
        "        self.student = ViT(self.patch_size, in_dim, d_model, out_dim=out_dim, n_heads=n_heads, nlayers=nlayers, drop=0.)\n",
        "        # self.predicter = TransformerPredictor(out_dim, d_model//2, out_dim, n_heads=n_heads, nlayers=nlayers//2, drop=0.)\n",
        "        self.predicter = TransformerPredictor(out_dim, 3*d_model//8, out_dim, n_heads=4, nlayers=1, drop=0.)\n",
        "        import copy\n",
        "        self.teacher = copy.deepcopy(self.student)\n",
        "        self.teacher.requires_grad_(False)\n",
        "\n",
        "    def loss(self, x): #\n",
        "        b,c,h,w = x.shape\n",
        "        # print('ijepa loss x',x.shape)\n",
        "        # hw=(8,8)\n",
        "        hw=(32,32)\n",
        "        mask_collator = MaskCollator(hw, enc_mask_scale=(.85, 1.), pred_mask_scale=(.15, .2), aspect_ratio=(.75, 1.5), nenc=1, npred=4, min_keep=4, allow_overlap=False)\n",
        "        collated_masks_enc, collated_masks_pred = mask_collator(b)\n",
        "        context_indices, trg_indices = torch.stack(collated_masks_enc).squeeze(0), torch.stack(collated_masks_pred).transpose(0,1).flatten(1).unique(dim=1) # [num_msk, b,num_tok]->[b,num_tok] # [64, 65], [64, 32]\n",
        "        # print(context_indices.shape, trg_indices.shape)\n",
        "\n",
        "        # context_indices, trg_indices = simplexmask2d(hw, ctx_scale=(.85,1), trg_scale=(.6,.8), B=b, chaos=3)\n",
        "\n",
        "        # zero_mask = torch.zeros(b ,*hw, device=device).flatten(1)\n",
        "        # zero_mask[torch.arange(b).unsqueeze(-1), context_indices] = 1\n",
        "        # x_ = x * F.interpolate(zero_mask.reshape(b,1,*hw), size=x.shape[2:], mode='nearest-exact') # zero masked locations\n",
        "\n",
        "        sx = self.student(x, context_indices=context_indices) # [batch, num_context_toks, out_dim]\n",
        "        # print('ijepa loss sx',sx.shape)\n",
        "        sy_ = self.predicter(sx, context_indices=context_indices, trg_indices=trg_indices) # [batch*M, num_trg_toks, out_dim]\n",
        "        sy_ = F.layer_norm(sy_, (sy_.size(-1),))\n",
        "        with torch.no_grad():\n",
        "            sy = self.teacher(x.detach()) # [batch, num_trg_toks, out_dim]\n",
        "            sy = sy[torch.arange(sy.shape[0]).unsqueeze(-1), trg_indices] # [batch, num_context_toks, d_model] # nan bec len(trg_ind)==0 # print('loss sy',torch.isnan(sy).any())\n",
        "            sy = F.layer_norm(sy, (sy.size(-1),))\n",
        "        loss = F.mse_loss(sy, sy_)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x): # [batch, T, 3]\n",
        "        sx = self.student(x)\n",
        "        out = sx.mean(dim=1)\n",
        "        return out\n",
        "\n",
        "# min_s=0.15, max_s, M\n",
        "# trg.15.2M4 C.85 1\n",
        "# dont normalise data\n",
        "# randmsk < multiblk < simplex\n",
        "# teacher=trans ~? teacher=copy\n",
        "# learn convemb\n",
        "# lr pred,student: 3e-3/1e-2, 1e-3\n",
        "\n",
        "# vit 1lyr 15.4sec 15.6\n",
        "\n",
        "# ijepa = IJEPA(in_dim=3, d_model=64, out_dim=64, nlayers=4, n_heads=4).to(device)\n",
        "ijepa = IJEPA(in_dim=3, d_model=64, out_dim=64, nlayers=1, n_heads=4).to(device)\n",
        "# ijepa = IJEPA(in_dim=3, d_model=32, out_dim=32, nlayers=1, n_heads=4).to(device)\n",
        "optim = torch.optim.AdamW(ijepa.parameters(), lr=1e-3) # 1e-3?\n",
        "# optim = torch.optim.AdamW([{'params': ijepa.student.parameters()},\n",
        "#     {'params': ijepa.predicter.parameters(), 'lr': 3e-3}], lr=1e-3, weight_decay=1e-2) # good 3e-3,1e-3 ; default 1e-2, 5e-2\n",
        "#     # {'params': ijepa.predicter.parameters(), 'lr': 1e-2}], lr=1e-3, weight_decay=1e-2)\n",
        "\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/configs/in1k_vith14_ep300.yaml\n",
        "# d_model 1024,384\n",
        "# depth 12,6/12\n",
        "# wd 5e-2 - 4e-1\n",
        "# adamw 1e-4 - 1e-3 - 1e-6\n",
        "# ema 0.996-1\n",
        "\n",
        "print(sum(p.numel() for p in ijepa.parameters() if p.requires_grad)) # 27584\n",
        "# print(sum(p.numel() for p in ijepa.parameters())) # 27584\n",
        "# print(sum(p.numel() for p in ijepa.predicter.transformer_encoder.parameters() if p.requires_grad)) # 27584\n",
        "# d_model^2 * nlayers\n",
        "\n",
        "x = torch.rand((64,3,32,32), device=device)\n",
        "out = ijepa.loss(x)\n",
        "print(out.shape)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Linear(in_dim, num_classes)\n",
        "    def forward(self, x): return self.classifier(x)\n",
        "classifier = Classifier(ijepa.out_dim, 10).to(device)\n",
        "coptim = torch.optim.SGD(classifier.parameters(), lr=1e-3)\n",
        "# optim = torch.optim.AdamW([{'params': ijepa.parameters()}, {'params': classifier.parameters(), 'lr': 1e-3}], lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "id": "ardu1zJwdHM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98edf74-fb77-4c0d-8ffc-6d1b30c4ea80"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160176\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TransformerVICReg\n",
        "import torch\n",
        "from torch import nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class TransformerVICReg(nn.Module):\n",
        "    def __init__(self, in_dim, d_model, out_dim=None, d_head=4, d_hid=None, nlayers=1, drop=0):\n",
        "        super().__init__()\n",
        "        act = nn.GELU()\n",
        "        patch_size=4\n",
        "        self.embed = nn.Sequential(\n",
        "            # nn.Linear(in_dim, d_model), act\n",
        "            # nn.Conv1d(in_dim, d_model,3,2,3//2), nn.BatchNorm1d(d_model), nn.ReLU(), nn.MaxPool1d(2,2),\n",
        "            # nn.Conv1d(d_model, d_model,3,2,3//2), nn.BatchNorm1d(d_model), nn.ReLU(), nn.MaxPool1d(2,2),\n",
        "            # nn.Conv1d(d_model, d_model,3,2,3//2),\n",
        "            nn.Conv2d(in_dim, d_model, patch_size, patch_size), # patch\n",
        "            )\n",
        "        self.pos_enc = RoPE(d_model, seq_len=200, base=10000)\n",
        "        # self.pos_emb = nn.Parameter(torch.randn(1, 8*8, d_model))\n",
        "        # self.pos_emb = nn.Parameter(RoPE2D(dim=d_model, h=8, w=8, base=10000).unsqueeze(0), requires_grad=False)\n",
        "\n",
        "        self.transformer = nn.Sequential(*[AttentionBlock(d_model, d_head=d_head) for _ in range(nlayers)])\n",
        "\n",
        "        # out_dim = out_dim or d_model\n",
        "        self.lin = nn.Linear(d_model, out_dim)\n",
        "        self.attn_pool = nn.Linear(d_model, 1, bias=False)\n",
        "\n",
        "        dim_v = d_model * 4\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(out_dim, dim_v), act,\n",
        "            nn.Linear(dim_v, dim_v), act,\n",
        "            nn.Linear(dim_v, dim_v, bias=False),\n",
        "            )\n",
        "\n",
        "    def forward(self, x): # [b,t,d] / [b,c,h,w]\n",
        "        x = self.embed(x).flatten(2).transpose(1,2) # [b,c,h,w]->[b,h*w,c]\n",
        "        # x = self.embed(x.transpose(-2,-1)).transpose(-2,-1) # [b,t,d]\n",
        "        x = self.pos_enc(x)\n",
        "        # x = x + self.pos_emb\n",
        "\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        attn = self.attn_pool(x).squeeze(-1) # [batch, seq] # seq_pool\n",
        "        out = (torch.softmax(attn, dim=-1).unsqueeze(1) @ x).squeeze(1) # [batch, 1, seq] @ [batch, seq, dim] -> [batch, dim]\n",
        "        out = self.lin(out)\n",
        "        return out # [seq_len, batch, ntoken]\n",
        "\n",
        "    def expand(self, x):\n",
        "        sx = self.forward(x)\n",
        "        vx = self.exp(sx)\n",
        "        return vx\n",
        "\n",
        "batch, seq_len, d_model = 4,3500,512\n",
        "in_dim, out_dim=3,16\n",
        "model = TransformerVICReg(in_dim, d_model, out_dim, d_head=4, nlayers=2, drop=0.).to(device)\n",
        "# x =  torch.rand((batch, seq_len, in_dim), device=device)\n",
        "x =  torch.rand((batch, in_dim, 32,32), device=device)\n",
        "out = model(x)\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "id": "ODpKypTCsfIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f4380b-03a8-49be-95b5-eed2b564dc05",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Violet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class Violet(nn.Module):\n",
        "    def __init__(self, in_dim=3, d_model=32, out_dim=None, nlayers=2, d_head=4):\n",
        "        super().__init__()\n",
        "        out_dim = out_dim or d_model\n",
        "        self.student = TransformerVICReg(in_dim, d_model, out_dim=out_dim, d_head=d_head, nlayers=nlayers, drop=0.)\n",
        "        import copy\n",
        "        self.teacher = copy.deepcopy(self.student)\n",
        "        self.teacher.requires_grad_(False)\n",
        "\n",
        "        # vicreg\n",
        "        self.sim_coeff=25. # 10.0 # 25.0 # λ\n",
        "        self.std_coeff=25. # 1.0 # 25.0 # µ\n",
        "        self.cov_coeff=1. # 25.0 # 1.0 # ν\n",
        "\n",
        "    def loss(self, x): # [batch, T, 3]c/ [b,c,h,w]\n",
        "        # print(x.shape)\n",
        "        # mask = simplexmask(hw=(8,8), scale=(.7,.8)).unsqueeze(0) # .6.8\n",
        "        # vx = self.student.expand(x, mask) # [batch, num_context_toks, out_dim]\n",
        "\n",
        "        vx = self.student.expand(x) # [batch, num_context_toks, out_dim]\n",
        "\n",
        "        with torch.no_grad(): vy = self.teacher.expand(x.detach()) # [batch, num_trg_toks, out_dim]\n",
        "        loss = self.vicreg(vx, vy)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x): # [batch, T, 3]\n",
        "        return self.student(x)\n",
        "\n",
        "    # https://arxiv.org/pdf/2105.04906.pdf\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y) # s(Z, Z')\n",
        "\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        batch_size, num_features = x.shape\n",
        "\n",
        "        if x.dim() == 1: x = x.unsqueeze(0)\n",
        "        if y.dim() == 1: y = y.unsqueeze(0)\n",
        "\n",
        "        # # covariance loss\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features) #c(Z)\n",
        "        loss = self.sim_coeff * repr_loss + self.std_coeff * std_loss + self.cov_coeff * cov_loss\n",
        "        print(\"in vicreg \",self.sim_coeff * repr_loss.item() , self.std_coeff * std_loss.item() , self.cov_coeff * cov_loss.item())\n",
        "        # return loss\n",
        "        return repr_loss, std_loss, cov_loss\n",
        "\n",
        "\n",
        "violet = Violet(in_dim=3, d_model=32, out_dim=16, nlayers=2, d_head=4).to(device)\n",
        "voptim = torch.optim.AdamW(violet.parameters(), lr=1e-3) # 1e-3?\n",
        "# voptim = torch.optim.AdamW([{'params': violet.student.transformer.parameters()},\n",
        "#     {'params': violet.student.exp.parameters(), 'lr': 3e-3}], lr=1e-3, weight_decay=1e-2) # default 1e-2\n",
        "print(sum(p.numel() for p in violet.parameters() if p.requires_grad)) # 27584\n",
        "\n",
        "# x = torch.rand((2,1000,3), device=device)\n",
        "x = torch.rand((2,3,32,32), device=device)\n",
        "# x = torch.rand((2,1,16), device=device)\n",
        "loss = violet.loss(x)\n",
        "# print(out.shape)\n",
        "print(loss)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Linear(in_dim, num_classes)\n",
        "    def forward(self, x): return self.classifier(x)\n",
        "classifier = Classifier(16).to(device)\n",
        "# classifier = Classifier(16, 18).to(device)\n",
        "coptim = torch.optim.SGD(classifier.parameters(), lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "id": "5qwg9dG4sQ3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f0092f5-5bb7-4725-db2b-dcf7b0ba1a96",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62850\n",
            "in vicreg  0.00019920778413506923 24.74469393491745 4.793645480560826e-09\n",
            "(tensor(7.9683e-06, grad_fn=<MseLossBackward0>), tensor(0.9898, grad_fn=<AddBackward0>), tensor(4.7936e-09, grad_fn=<AddBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in ijepa.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param)"
      ],
      "metadata": {
        "id": "m_BFm8Kh-j3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title RankMe\n",
        "# RankMe: Assessing the Downstream Performance of Pretrained Self-Supervised Representations by Their Rank jun 2023 https://arxiv.org/pdf/2210.02885\n",
        "import torch\n",
        "\n",
        "# https://github.com/Spidartist/IJEPA_endoscopy/blob/main/src/helper.py#L22\n",
        "def RankMe(Z):\n",
        "    \"\"\"\n",
        "    Calculate the RankMe score (the higher, the better).\n",
        "    RankMe(Z) = exp(-sum_{k=1}^{min(N, K)} p_k * log(p_k)),\n",
        "    where p_k = sigma_k (Z) / ||sigma_k (Z)||_1 + epsilon\n",
        "    where sigma_k is the kth singular value of Z.\n",
        "    where Z is the matrix of embeddings (N × K)\n",
        "    \"\"\"\n",
        "    # compute the singular values of the embeddings\n",
        "    # _u, s, _vh = torch.linalg.svd(Z, full_matrices=False)  # s.shape = (min(N, K),)\n",
        "    # s = torch.linalg.svd(Z, full_matrices=False).S\n",
        "    s = torch.linalg.svdvals(Z)\n",
        "    p = s / torch.sum(s, axis=0) + 1e-7\n",
        "    return torch.exp(-torch.sum(p * torch.log(p)))\n",
        "\n",
        "# Z = torch.randn(5, 3)\n",
        "# rankme = RankMe(Z)\n",
        "# print(rankme)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eb1n4BhimG_N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title LiDAR\n",
        "# LiDAR: Sensing Linear Probing Performance In Joint Embedding SSL Architectures https://arxiv.org/pdf/2312.04000\n",
        "# https://github.com/rbalestr-lab/stable-ssl/blob/main/stable_ssl/monitors.py#L106\n",
        "\n",
        "def LiDAR(sx, eps=1e-7, delta=1e-3):\n",
        "    sx = sx.unflatten(0, (-1, 2))\n",
        "    n, q, d = sx.shape\n",
        "    mu_x = sx.mean(dim=1) # mu_x # [n,d]\n",
        "    mu = mu_x.mean(dim=0) # mu # [d]\n",
        "\n",
        "    diff_b = (mu_x - mu).unsqueeze(-1) # [n,d,1]\n",
        "    S_b = (diff_b @ diff_b.transpose(-2,-1)).sum(0) / (n - 1) # [n,d,d] -> [d,d]\n",
        "    diff_w = (sx - mu_x.unsqueeze(1)).reshape(-1,d,1) # [n,q,d] -> [nq,d,1]\n",
        "    S_w = (diff_w @ diff_w.transpose(-2,-1)).sum(0) / (n * (q - 1)) + delta * torch.eye(d, device=sx.device) # [nq,d,d] -> [d,d]\n",
        "\n",
        "    eigvals_w, eigvecs_w = torch.linalg.eigh(S_w)\n",
        "    eigvals_w = torch.clamp(eigvals_w, min=eps)\n",
        "\n",
        "    invsqrt_w = (eigvecs_w * (1. / torch.sqrt(eigvals_w))) @ eigvecs_w.transpose(-1, -2)\n",
        "    S_lidar = invsqrt_w @ S_b @ invsqrt_w\n",
        "    lam = torch.linalg.eigh(S_lidar)[0].clamp(min=0)\n",
        "    p = lam / lam.sum() + eps\n",
        "    return torch.exp(-torch.sum(p * torch.log(p)))\n",
        "\n",
        "# sx = torch.randn(32, 128)\n",
        "# print(sx.shape)\n",
        "# lidar = LiDAR(sx)\n",
        "# print(lidar.item())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y24ZNFqW7woQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2Nd-sGe6Ku4S",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "1b5d0352-c3db-4484-d016-008c3434edd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250410_133132-hirej9m2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/ijepa/runs/hirej9m2' target=\"_blank\">lunar-fog-71</a></strong> to <a href='https://wandb.ai/bobdole/ijepa' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/ijepa' target=\"_blank\">https://wandb.ai/bobdole/ijepa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/ijepa/runs/hirej9m2' target=\"_blank\">https://wandb.ai/bobdole/ijepa/runs/hirej9m2</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "!pip install -q wandb\n",
        "import wandb # https://docs.wandb.ai/quickstart\n",
        "wandb.login(key='487a2109e55dce4e13fc70681781de9f50f27be7')\n",
        "try: run.finish()\n",
        "except NameError: pass\n",
        "run = wandb.init(project=\"ijepa\", config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34de8800-fa4b-4460-803c-3cd8dbfb6c70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05db5bb9-1a97-4049-e883-b8b4b00e236c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "strain 2.299301862716675\n",
            "strain 0.6035044193267822\n",
            "strain 0.34167221188545227\n",
            "strain 0.23178429901599884\n",
            "strain 0.1922752857208252\n",
            "strain 0.16321751475334167\n",
            "strain 0.13986451923847198\n",
            "strain 0.1335754692554474\n",
            "strain 0.14954839646816254\n",
            "strain 0.148408904671669\n",
            "strain 0.12808838486671448\n",
            "classify 2.418212890625\n",
            "classify 2.4212646484375\n",
            "classify 2.4293212890625\n",
            "classify 2.3277587890625\n",
            "classify 2.420166015625\n",
            "classify 2.3797607421875\n",
            "0.109375\n",
            "0.234375\n",
            "0.140625\n",
            "0.125\n",
            "0.15625\n",
            "0.0625\n",
            "time: 25.289469480514526 25.289470911026\n",
            "1\n",
            "strain 0.1182330921292305\n",
            "strain 0.1400981843471527\n",
            "strain 0.14115767180919647\n",
            "strain 0.13232572376728058\n",
            "strain 0.14658766984939575\n",
            "strain 0.1062578409910202\n",
            "strain 0.14341270923614502\n",
            "strain 0.11296924948692322\n",
            "strain 0.11817234009504318\n",
            "strain 0.10409268736839294\n",
            "strain 0.10557320713996887\n",
            "classify 2.408935546875\n",
            "classify 2.4761962890625\n",
            "classify 2.472900390625\n",
            "classify 2.4312744140625\n",
            "classify 2.4293212890625\n",
            "classify 2.3961181640625\n",
            "0.078125\n",
            "0.015625\n",
            "0.125\n",
            "0.15625\n",
            "0.046875\n",
            "0.09375\n",
            "time: 14.952760457992554 20.1213561296463\n",
            "2\n",
            "strain 0.1111428365111351\n",
            "strain 0.11726830899715424\n",
            "strain 0.11139015853404999\n",
            "strain 0.10188592970371246\n",
            "strain 0.08873821794986725\n",
            "strain 0.10313557088375092\n",
            "strain 0.1079624816775322\n",
            "strain 0.10930219292640686\n",
            "strain 0.10010576993227005\n",
            "strain 0.10098864138126373\n",
            "strain 0.09645286202430725\n",
            "classify 2.3157958984375\n",
            "classify 2.40087890625\n",
            "classify 2.4166259765625\n",
            "classify 2.496337890625\n",
            "classify 2.3778076171875\n",
            "classify 2.3743896484375\n",
            "0.109375\n",
            "0.109375\n",
            "0.140625\n",
            "0.15625\n",
            "0.125\n",
            "0.109375\n",
            "time: 14.908025741577148 18.383710145950317\n",
            "3\n",
            "strain 0.08542215824127197\n",
            "strain 0.08991887420415878\n",
            "strain 0.0933448001742363\n",
            "strain 0.0836239904165268\n",
            "strain 0.08400077372789383\n",
            "strain 0.09986559301614761\n",
            "strain 0.09454707056283951\n",
            "strain 0.0975150540471077\n",
            "strain 0.097017303109169\n",
            "strain 0.08512677997350693\n",
            "strain 0.09350455552339554\n",
            "classify 2.322509765625\n",
            "classify 2.3829345703125\n",
            "classify 2.3974609375\n",
            "classify 2.3861083984375\n",
            "classify 2.4046630859375\n",
            "classify 2.430908203125\n",
            "0.15625\n",
            "0.171875\n",
            "0.140625\n",
            "0.140625\n",
            "0.125\n",
            "0.15625\n",
            "time: 15.300407648086548 17.613023102283478\n",
            "4\n",
            "strain 0.09683948755264282\n",
            "strain 0.10043475776910782\n",
            "strain 0.08509448915719986\n",
            "strain 0.08725029975175858\n",
            "strain 0.11609674990177155\n",
            "strain 0.09277745336294174\n",
            "strain 0.08915675431489944\n",
            "strain 0.11287384480237961\n",
            "strain 0.08752483874559402\n",
            "strain 0.09839902073144913\n",
            "strain 0.09696178883314133\n",
            "classify 2.4224853515625\n",
            "classify 2.379150390625\n",
            "classify 2.4312744140625\n",
            "classify 2.3751220703125\n",
            "classify 2.305908203125\n",
            "classify 2.3603515625\n",
            "0.203125\n",
            "0.09375\n",
            "0.09375\n",
            "0.15625\n",
            "0.078125\n",
            "0.078125\n",
            "time: 15.115042209625244 17.113844442367554\n",
            "5\n",
            "strain 0.13140228390693665\n",
            "strain 0.10369095951318741\n",
            "strain 0.10067161917686462\n",
            "strain 0.10839051753282547\n",
            "strain 0.12274379283189774\n",
            "strain 0.11494413763284683\n",
            "strain 0.11738233268260956\n",
            "strain 0.1024959534406662\n",
            "strain 0.1120370477437973\n",
            "strain 0.12501154839992523\n",
            "strain 0.10359106212854385\n",
            "classify 2.4053955078125\n",
            "classify 2.4591064453125\n",
            "classify 2.3914794921875\n",
            "classify 2.3077392578125\n",
            "classify 2.339111328125\n",
            "classify 2.3646240234375\n",
            "0.125\n",
            "0.140625\n",
            "0.09375\n",
            "0.15625\n",
            "0.203125\n",
            "0.15625\n",
            "time: 16.110443115234375 16.946691592534382\n",
            "6\n",
            "strain 0.10562092810869217\n",
            "strain 0.12255967408418655\n",
            "strain 0.10383881628513336\n",
            "strain 0.12085217982530594\n",
            "strain 0.11345867812633514\n",
            "strain 0.12681624293327332\n",
            "strain 0.11920448392629623\n",
            "strain 0.13550175726413727\n",
            "strain 0.12628374993801117\n",
            "strain 0.11811870336532593\n",
            "strain 0.13023681938648224\n",
            "classify 2.4259033203125\n",
            "classify 2.337646484375\n",
            "classify 2.43408203125\n",
            "classify 2.4344482421875\n",
            "classify 2.3084716796875\n",
            "classify 2.48388671875\n",
            "0.15625\n",
            "0.140625\n",
            "0.125\n",
            "0.078125\n",
            "0.140625\n",
            "0.21875\n",
            "time: 15.090880155563354 16.681645461491176\n",
            "7\n",
            "strain 0.10804322361946106\n",
            "strain 0.1186458021402359\n",
            "strain 0.11536398530006409\n",
            "strain 0.1265150010585785\n",
            "strain 0.12771350145339966\n",
            "strain 0.14333418011665344\n",
            "strain 0.13394592702388763\n",
            "strain 0.12257565557956696\n",
            "strain 0.11025257408618927\n",
            "strain 0.14219535887241364\n",
            "strain 0.15340887010097504\n",
            "classify 2.4537353515625\n",
            "classify 2.24951171875\n",
            "classify 2.36474609375\n",
            "classify 2.4061279296875\n",
            "classify 2.391357421875\n",
            "classify 2.388671875\n",
            "0.09375\n",
            "0.171875\n",
            "0.265625\n",
            "0.140625\n",
            "0.125\n",
            "0.1875\n",
            "time: 15.127908945083618 16.48749217391014\n",
            "8\n",
            "strain 0.12836198508739471\n",
            "strain 0.1327778846025467\n",
            "strain 0.13521218299865723\n",
            "strain 0.15226712822914124\n",
            "strain 0.13500377535820007\n",
            "strain 0.14175347983837128\n",
            "strain 0.1425497680902481\n",
            "strain 0.1415684074163437\n",
            "strain 0.14895746111869812\n",
            "strain 0.14550398290157318\n",
            "strain 0.1295401155948639\n",
            "classify 2.42578125\n",
            "classify 2.303955078125\n",
            "classify 2.3533935546875\n",
            "classify 2.4254150390625\n",
            "classify 2.3433837890625\n",
            "classify 2.34619140625\n",
            "0.140625\n",
            "0.109375\n",
            "0.125\n",
            "0.1875\n",
            "0.21875\n",
            "0.046875\n",
            "time: 15.406005620956421 16.367396301693386\n",
            "9\n",
            "strain 0.14008449018001556\n",
            "strain 0.1277589201927185\n",
            "strain 0.15751808881759644\n",
            "strain 0.152251198887825\n",
            "strain 0.1388273686170578\n",
            "strain 0.14288438856601715\n",
            "strain 0.15655122697353363\n",
            "strain 0.1667039543390274\n",
            "strain 0.1550406962633133\n",
            "strain 0.14631541073322296\n",
            "strain 0.1512540876865387\n",
            "classify 2.3824462890625\n",
            "classify 2.386962890625\n",
            "classify 2.2923583984375\n",
            "classify 2.334716796875\n",
            "classify 2.3458251953125\n",
            "classify 2.30615234375\n",
            "0.125\n",
            "0.171875\n",
            "0.15625\n",
            "0.125\n",
            "0.140625\n",
            "0.203125\n",
            "time: 15.164817094802856 16.24718370437622\n",
            "10\n",
            "strain 0.17460277676582336\n",
            "strain 0.14331571757793427\n",
            "strain 0.16611482203006744\n",
            "strain 0.14958348870277405\n",
            "strain 0.1439313441514969\n",
            "strain 0.16113640367984772\n",
            "strain 0.14992602169513702\n",
            "strain 0.15053728222846985\n",
            "strain 0.14508451521396637\n",
            "strain 0.1423255056142807\n",
            "strain 0.17086029052734375\n",
            "classify 2.314453125\n",
            "classify 2.2926025390625\n",
            "classify 2.3126220703125\n",
            "classify 2.354736328125\n",
            "classify 2.404541015625\n",
            "classify 2.29541015625\n",
            "0.078125\n",
            "0.109375\n",
            "0.15625\n",
            "0.09375\n",
            "0.21875\n",
            "0.15625\n",
            "time: 15.017329454421997 16.135421817952935\n",
            "11\n",
            "strain 0.1519114375114441\n",
            "strain 0.14957550168037415\n",
            "strain 0.14780893921852112\n",
            "strain 0.1603505164384842\n",
            "strain 0.17024102807044983\n",
            "strain 0.18322119116783142\n",
            "strain 0.1792050302028656\n",
            "strain 0.1733897179365158\n",
            "strain 0.14995500445365906\n",
            "strain 0.18674995005130768\n",
            "strain 0.1464046686887741\n",
            "classify 2.4029541015625\n",
            "classify 2.32568359375\n",
            "classify 2.3594970703125\n",
            "classify 2.2568359375\n",
            "classify 2.425537109375\n",
            "classify 2.3775634765625\n",
            "0.125\n",
            "0.171875\n",
            "0.125\n",
            "0.109375\n",
            "0.140625\n",
            "0.09375\n",
            "time: 15.046324729919434 16.044704357783\n",
            "12\n",
            "strain 0.15799450874328613\n",
            "strain 0.14991413056850433\n",
            "strain 0.15047362446784973\n",
            "strain 0.1757543981075287\n",
            "strain 0.16605861485004425\n",
            "strain 0.1461554765701294\n",
            "strain 0.15993957221508026\n",
            "strain 0.15407466888427734\n",
            "strain 0.17187757790088654\n",
            "strain 0.16345642507076263\n",
            "strain 0.1451748013496399\n",
            "classify 2.2698974609375\n",
            "classify 2.294921875\n",
            "classify 2.220458984375\n",
            "classify 2.1806640625\n",
            "classify 2.4156494140625\n",
            "classify 2.3597412109375\n",
            "0.140625\n",
            "0.125\n",
            "0.234375\n",
            "0.078125\n",
            "0.21875\n",
            "0.1875\n",
            "time: 15.186991214752197 15.97876867881188\n",
            "13\n",
            "strain 0.1538446694612503\n",
            "strain 0.1615058034658432\n",
            "strain 0.1806681752204895\n",
            "strain 0.1821318417787552\n",
            "strain 0.17059221863746643\n",
            "strain 0.18417888879776\n",
            "strain 0.1697445511817932\n",
            "strain 0.17305071651935577\n",
            "strain 0.17142298817634583\n",
            "strain 0.17902137339115143\n",
            "strain 0.1857926845550537\n",
            "classify 2.378662109375\n",
            "classify 2.3770751953125\n",
            "classify 2.3131103515625\n",
            "classify 2.211181640625\n",
            "classify 2.276611328125\n",
            "classify 2.2972412109375\n",
            "0.125\n",
            "0.0625\n",
            "0.1875\n",
            "0.09375\n",
            "0.078125\n",
            "0.140625\n",
            "time: 15.454905986785889 15.94143293585096\n",
            "14\n",
            "strain 0.1760106086730957\n",
            "strain 0.16340743005275726\n",
            "strain 0.16059830784797668\n",
            "strain 0.16686373949050903\n",
            "strain 0.18459457159042358\n",
            "strain 0.1769414097070694\n",
            "strain 0.16335174441337585\n",
            "strain 0.1565496176481247\n",
            "strain 0.18850591778755188\n",
            "strain 0.16341359913349152\n",
            "strain 0.18159008026123047\n",
            "classify 2.310302734375\n",
            "classify 2.2740478515625\n",
            "classify 2.378662109375\n",
            "classify 2.270751953125\n",
            "classify 2.3140869140625\n",
            "classify 2.3199462890625\n",
            "0.125\n",
            "0.09375\n",
            "0.109375\n",
            "0.125\n",
            "0.0625\n",
            "0.125\n",
            "time: 15.049671649932861 15.88201510111491\n",
            "15\n",
            "strain 0.16191524267196655\n",
            "strain 0.17790308594703674\n",
            "strain 0.19174744188785553\n",
            "strain 0.17800135910511017\n",
            "strain 0.16320505738258362\n",
            "strain 0.1745181381702423\n",
            "strain 0.17326712608337402\n",
            "strain 0.19157838821411133\n",
            "strain 0.17731241881847382\n",
            "strain 0.1559419333934784\n",
            "strain 0.1703581064939499\n",
            "classify 2.402587890625\n",
            "classify 2.3663330078125\n",
            "classify 2.3011474609375\n",
            "classify 2.389404296875\n",
            "classify 2.232666015625\n",
            "classify 2.3311767578125\n",
            "0.078125\n",
            "0.125\n",
            "0.171875\n",
            "0.1875\n",
            "0.1875\n",
            "0.125\n",
            "time: 15.048928022384644 15.829978063702583\n",
            "16\n",
            "strain 0.1632729172706604\n",
            "strain 0.18051722645759583\n",
            "strain 0.19482837617397308\n",
            "strain 0.20727136731147766\n",
            "strain 0.16141793131828308\n",
            "strain 0.19839973747730255\n",
            "strain 0.1827070564031601\n",
            "strain 0.18019114434719086\n",
            "strain 0.16038446128368378\n",
            "strain 0.18324702978134155\n",
            "strain 0.16961143910884857\n",
            "classify 2.303955078125\n",
            "classify 2.247802734375\n",
            "classify 2.364013671875\n",
            "classify 2.3193359375\n",
            "classify 2.254150390625\n",
            "classify 2.2462158203125\n",
            "0.140625\n",
            "0.09375\n",
            "0.09375\n",
            "0.15625\n",
            "0.109375\n",
            "0.1875\n",
            "time: 15.289625644683838 15.79821893748115\n",
            "17\n",
            "strain 0.18724998831748962\n",
            "strain 0.1781986504793167\n",
            "strain 0.1893598884344101\n",
            "strain 0.18548868596553802\n",
            "strain 0.20918622612953186\n",
            "strain 0.1745743751525879\n",
            "strain 0.2283431440591812\n",
            "strain 0.18691854178905487\n",
            "strain 0.16053557395935059\n",
            "strain 0.1995050013065338\n",
            "strain 0.18497511744499207\n",
            "classify 2.2303466796875\n",
            "classify 2.3363037109375\n",
            "classify 2.23193359375\n",
            "classify 2.3170166015625\n",
            "classify 2.28564453125\n",
            "classify 2.3221435546875\n",
            "0.21875\n",
            "0.140625\n",
            "0.09375\n",
            "0.125\n",
            "0.078125\n",
            "0.171875\n",
            "time: 15.149721384048462 15.762216263347202\n",
            "18\n",
            "strain 0.1614627093076706\n",
            "strain 0.18962030112743378\n",
            "strain 0.1805911362171173\n",
            "strain 0.16475379467010498\n",
            "strain 0.1952071189880371\n",
            "strain 0.19125071167945862\n",
            "strain 0.22291603684425354\n",
            "strain 0.186109721660614\n",
            "strain 0.19132114946842194\n",
            "strain 0.18352960050106049\n",
            "strain 0.16621644794940948\n",
            "classify 2.3563232421875\n",
            "classify 2.27197265625\n",
            "classify 2.3841552734375\n",
            "classify 2.293701171875\n",
            "classify 2.20849609375\n",
            "classify 2.270263671875\n",
            "0.125\n",
            "0.109375\n",
            "0.046875\n",
            "0.078125\n",
            "0.15625\n",
            "0.125\n",
            "time: 15.374662637710571 15.741868395554391\n",
            "19\n",
            "strain 0.17450971901416779\n",
            "strain 0.19876304268836975\n",
            "strain 0.1565283089876175\n",
            "strain 0.17796391248703003\n",
            "strain 0.21243588626384735\n",
            "strain 0.1781456470489502\n",
            "strain 0.16847306489944458\n",
            "strain 0.20956793427467346\n",
            "strain 0.1747506707906723\n",
            "strain 0.20160749554634094\n",
            "strain 0.16147449612617493\n",
            "classify 2.295654296875\n",
            "classify 2.27490234375\n",
            "classify 2.315185546875\n",
            "classify 2.328125\n",
            "classify 2.318603515625\n",
            "classify 2.2672119140625\n",
            "0.21875\n",
            "0.078125\n",
            "0.15625\n",
            "0.1875\n",
            "0.125\n",
            "0.140625\n",
            "time: 15.093401193618774 15.709468770027161\n",
            "20\n",
            "strain 0.1920183151960373\n",
            "strain 0.17881685495376587\n",
            "strain 0.18459923565387726\n",
            "strain 0.19484896957874298\n",
            "strain 0.16812719404697418\n",
            "strain 0.20309492945671082\n",
            "strain 0.17549405992031097\n",
            "strain 0.1723925620317459\n",
            "strain 0.17710581421852112\n",
            "strain 0.16936323046684265\n",
            "strain 0.17951010167598724\n",
            "classify 2.3951416015625\n",
            "classify 2.3568115234375\n",
            "classify 2.3150634765625\n",
            "classify 2.3023681640625\n",
            "classify 2.2894287109375\n",
            "classify 2.4097900390625\n",
            "0.1875\n",
            "0.09375\n",
            "0.15625\n",
            "0.125\n",
            "0.171875\n",
            "0.09375\n",
            "time: 15.118558645248413 15.681358575820923\n",
            "21\n",
            "strain 0.19767296314239502\n",
            "strain 0.1554184854030609\n",
            "strain 0.1509643942117691\n",
            "strain 0.19262856245040894\n",
            "strain 0.173564150929451\n",
            "strain 0.19874536991119385\n",
            "strain 0.16775937378406525\n",
            "strain 0.17872768640518188\n",
            "strain 0.21371538937091827\n",
            "strain 0.18156231939792633\n",
            "strain 0.16663016378879547\n",
            "classify 2.3369140625\n",
            "classify 2.3521728515625\n",
            "classify 2.230712890625\n",
            "classify 2.233154296875\n",
            "classify 2.28466796875\n",
            "classify 2.293212890625\n",
            "0.046875\n",
            "0.203125\n",
            "0.21875\n",
            "0.125\n",
            "0.1875\n",
            "0.125\n",
            "time: 15.080462217330933 15.654067787257107\n",
            "22\n",
            "strain 0.19991575181484222\n",
            "strain 0.20965589582920074\n",
            "strain 0.16627101600170135\n",
            "strain 0.18109604716300964\n",
            "strain 0.1674693524837494\n",
            "strain 0.15649577975273132\n",
            "strain 0.1629037857055664\n",
            "strain 0.1822911947965622\n",
            "strain 0.17407704889774323\n",
            "strain 0.18058815598487854\n",
            "strain 0.1855621188879013\n",
            "classify 2.379638671875\n",
            "classify 2.19775390625\n",
            "classify 2.3564453125\n",
            "classify 2.22021484375\n",
            "classify 2.2694091796875\n",
            "classify 2.3623046875\n",
            "0.09375\n",
            "0.109375\n",
            "0.1875\n",
            "0.109375\n",
            "0.078125\n",
            "0.125\n",
            "time: 15.230516195297241 15.635673201602438\n",
            "23\n",
            "strain 0.16177795827388763\n",
            "strain 0.17494091391563416\n",
            "strain 0.1638510376214981\n",
            "strain 0.1702621430158615\n",
            "strain 0.17851535975933075\n",
            "strain 0.15730097889900208\n",
            "strain 0.17770734429359436\n",
            "strain 0.2240857183933258\n",
            "strain 0.16926643252372742\n",
            "strain 0.18026883900165558\n",
            "strain 0.1728307008743286\n",
            "classify 2.4210205078125\n",
            "classify 2.2833251953125\n",
            "classify 2.3221435546875\n",
            "classify 2.2750244140625\n",
            "classify 2.2261962890625\n",
            "classify 2.2989501953125\n",
            "0.171875\n",
            "0.09375\n",
            "0.09375\n",
            "0.15625\n",
            "0.078125\n",
            "0.140625\n",
            "time: 15.33571171760559 15.623197664817175\n",
            "24\n",
            "strain 0.18434539437294006\n",
            "strain 0.1706494837999344\n",
            "strain 0.19099673628807068\n",
            "strain 0.1948188990354538\n",
            "strain 0.1885446310043335\n",
            "strain 0.17326556146144867\n",
            "strain 0.18682920932769775\n",
            "strain 0.16800320148468018\n",
            "strain 0.19022560119628906\n",
            "strain 0.1688600480556488\n",
            "strain 0.20262320339679718\n",
            "classify 2.2232666015625\n",
            "classify 2.2969970703125\n",
            "classify 2.36083984375\n",
            "classify 2.333984375\n",
            "classify 2.326904296875\n",
            "classify 2.2490234375\n",
            "0.125\n",
            "0.15625\n",
            "0.1875\n",
            "0.140625\n",
            "0.15625\n",
            "0.15625\n",
            "time: 14.885560989379883 15.59371057510376\n",
            "25\n",
            "strain 0.17739813029766083\n",
            "strain 0.20044252276420593\n",
            "strain 0.2207995504140854\n",
            "strain 0.1743178516626358\n",
            "strain 0.1938663274049759\n",
            "strain 0.18713857233524323\n",
            "strain 0.19412672519683838\n",
            "strain 0.17323659360408783\n",
            "strain 0.16485455632209778\n",
            "strain 0.16645585000514984\n",
            "strain 0.23936167359352112\n",
            "classify 2.296630859375\n",
            "classify 2.3287353515625\n",
            "classify 2.28076171875\n",
            "classify 2.1876220703125\n",
            "classify 2.200439453125\n",
            "classify 2.275146484375\n",
            "0.0625\n",
            "0.109375\n",
            "0.0625\n",
            "0.078125\n",
            "0.125\n",
            "0.15625\n",
            "time: 14.93461275100708 15.568379750618568\n",
            "26\n",
            "strain 0.15848276019096375\n",
            "strain 0.1795433610677719\n",
            "strain 0.18153269588947296\n",
            "strain 0.16986395418643951\n",
            "strain 0.17217117547988892\n",
            "strain 0.18822570145130157\n",
            "strain 0.18922112882137299\n",
            "strain 0.15680724382400513\n",
            "strain 0.17930340766906738\n",
            "strain 0.16857880353927612\n",
            "strain 0.17634093761444092\n",
            "classify 2.333251953125\n",
            "classify 2.2515869140625\n",
            "classify 2.309326171875\n",
            "classify 2.2811279296875\n",
            "classify 2.266845703125\n",
            "classify 2.2735595703125\n",
            "0.09375\n",
            "0.203125\n",
            "0.09375\n",
            "0.171875\n",
            "0.21875\n",
            "0.15625\n",
            "time: 15.010404109954834 15.54773042820118\n",
            "27\n",
            "strain 0.1672206073999405\n",
            "strain 0.1677672564983368\n",
            "strain 0.17364269495010376\n",
            "strain 0.17719505727291107\n",
            "strain 0.1803760975599289\n",
            "strain 0.16669659316539764\n",
            "strain 0.174093097448349\n",
            "strain 0.18183186650276184\n",
            "strain 0.20191404223442078\n",
            "strain 0.1870122104883194\n",
            "strain 0.19646689295768738\n",
            "classify 2.3099365234375\n",
            "classify 2.1903076171875\n",
            "classify 2.2530517578125\n",
            "classify 2.281982421875\n",
            "classify 2.3690185546875\n",
            "classify 2.340576171875\n",
            "0.15625\n",
            "0.15625\n",
            "0.03125\n",
            "0.125\n",
            "0.109375\n",
            "0.140625\n",
            "time: 15.143056154251099 15.533294226442065\n",
            "28\n",
            "strain 0.1929987370967865\n",
            "strain 0.17176823318004608\n",
            "strain 0.165836900472641\n",
            "strain 0.18845710158348083\n",
            "strain 0.19761726260185242\n",
            "strain 0.16974222660064697\n",
            "strain 0.1617303490638733\n",
            "strain 0.21654343605041504\n",
            "strain 0.1903531849384308\n",
            "strain 0.1698308140039444\n",
            "strain 0.15971621870994568\n",
            "classify 2.3603515625\n",
            "classify 2.288818359375\n",
            "classify 2.279296875\n",
            "classify 2.2723388671875\n",
            "classify 2.27734375\n",
            "classify 2.3309326171875\n",
            "0.109375\n",
            "0.109375\n",
            "0.140625\n",
            "0.140625\n",
            "0.109375\n",
            "0.125\n",
            "time: 15.305578470230103 15.525460728283587\n",
            "29\n",
            "strain 0.2171137034893036\n",
            "strain 0.17632362246513367\n",
            "strain 0.16563189029693604\n",
            "strain 0.16845504939556122\n",
            "strain 0.16741549968719482\n",
            "strain 0.1703442633152008\n",
            "strain 0.16620129346847534\n",
            "strain 0.14468684792518616\n",
            "strain 0.17308196425437927\n",
            "strain 0.16151142120361328\n",
            "strain 0.16756203770637512\n",
            "classify 2.296630859375\n",
            "classify 2.2261962890625\n",
            "classify 2.2716064453125\n",
            "classify 2.3330078125\n",
            "classify 2.3443603515625\n",
            "classify 2.231689453125\n",
            "0.125\n",
            "0.015625\n",
            "0.09375\n",
            "0.125\n",
            "0.125\n",
            "0.09375\n",
            "time: 15.017202138900757 15.508535472551982\n",
            "30\n",
            "strain 0.17748668789863586\n",
            "strain 0.1720437854528427\n",
            "strain 0.1607203483581543\n",
            "strain 0.14848054945468903\n",
            "strain 0.17337468266487122\n",
            "strain 0.1582200825214386\n",
            "strain 0.15465004742145538\n",
            "strain 0.17307721078395844\n",
            "strain 0.18176494538784027\n",
            "strain 0.17127305269241333\n",
            "strain 0.2189759761095047\n",
            "classify 2.28369140625\n",
            "classify 2.2918701171875\n",
            "classify 2.2276611328125\n",
            "classify 2.3232421875\n",
            "classify 2.2332763671875\n",
            "classify 2.2811279296875\n",
            "0.203125\n",
            "0.109375\n",
            "0.109375\n",
            "0.046875\n",
            "0.171875\n",
            "0.171875\n",
            "time: 14.975427627563477 15.491356334378642\n",
            "31\n",
            "strain 0.1643735021352768\n",
            "strain 0.17550800740718842\n",
            "strain 0.15855921804904938\n",
            "strain 0.17852115631103516\n",
            "strain 0.14820922911167145\n",
            "strain 0.19750535488128662\n",
            "strain 0.1878795176744461\n",
            "strain 0.182891383767128\n",
            "strain 0.17052103579044342\n",
            "strain 0.21902379393577576\n",
            "strain 0.19947217404842377\n",
            "classify 2.2928466796875\n",
            "classify 2.2918701171875\n",
            "classify 2.248779296875\n",
            "classify 2.3140869140625\n",
            "classify 2.2880859375\n",
            "classify 2.267333984375\n",
            "0.125\n",
            "0.078125\n",
            "0.125\n",
            "0.140625\n",
            "0.171875\n",
            "0.203125\n",
            "time: 21.14880347251892 15.668166190385818\n",
            "32\n",
            "strain 0.17020562291145325\n",
            "strain 0.1838621199131012\n",
            "strain 0.18066421151161194\n",
            "strain 0.14353425800800323\n",
            "strain 0.1955849826335907\n",
            "strain 0.18196114897727966\n",
            "strain 0.15654049813747406\n",
            "strain 0.1872113198041916\n",
            "strain 0.17773741483688354\n",
            "strain 0.18595552444458008\n",
            "strain 0.17777039110660553\n",
            "classify 2.3074951171875\n",
            "classify 2.249267578125\n",
            "classify 2.3184814453125\n",
            "classify 2.2117919921875\n",
            "classify 2.325927734375\n",
            "classify 2.257568359375\n",
            "0.125\n",
            "0.140625\n",
            "0.171875\n",
            "0.125\n",
            "0.109375\n",
            "0.1875\n",
            "time: 15.406273603439331 15.66024569309119\n",
            "33\n",
            "strain 0.19917535781860352\n",
            "strain 0.17168796062469482\n",
            "strain 0.18411214649677277\n",
            "strain 0.19610686600208282\n",
            "strain 0.1448775827884674\n",
            "strain 0.17615292966365814\n",
            "strain 0.1891811490058899\n",
            "strain 0.14972911775112152\n",
            "strain 0.16118158400058746\n",
            "strain 0.16197410225868225\n",
            "strain 0.16160224378108978\n",
            "classify 2.2652587890625\n",
            "classify 2.269775390625\n",
            "classify 2.218017578125\n",
            "classify 2.184326171875\n",
            "classify 2.2666015625\n",
            "classify 2.287109375\n",
            "0.09375\n",
            "0.1875\n",
            "0.140625\n",
            "0.15625\n",
            "0.25\n",
            "0.109375\n",
            "time: 18.743602752685547 15.75094985961914\n",
            "34\n",
            "strain 0.16271790862083435\n",
            "strain 0.16651731729507446\n",
            "strain 0.17928378283977509\n",
            "strain 0.15082550048828125\n",
            "strain 0.180623859167099\n",
            "strain 0.2091698795557022\n",
            "strain 0.19610846042633057\n",
            "strain 0.15577836334705353\n",
            "strain 0.15951275825500488\n",
            "strain 0.16847948729991913\n",
            "strain 0.19992077350616455\n",
            "classify 2.233642578125\n",
            "classify 2.283203125\n",
            "classify 2.2318115234375\n",
            "classify 2.2403564453125\n",
            "classify 2.251220703125\n",
            "classify 2.3828125\n",
            "0.109375\n",
            "0.171875\n",
            "0.078125\n",
            "0.09375\n",
            "0.1875\n",
            "0.109375\n",
            "time: 16.461575269699097 15.771290104729788\n",
            "35\n",
            "strain 0.15037554502487183\n",
            "strain 0.1835012137889862\n",
            "strain 0.18258512020111084\n",
            "strain 0.2130347490310669\n",
            "strain 0.1594683676958084\n",
            "strain 0.15896955132484436\n",
            "strain 0.15120816230773926\n",
            "strain 0.18186628818511963\n",
            "strain 0.15885719656944275\n",
            "strain 0.16191637516021729\n",
            "strain 0.15223661065101624\n",
            "classify 2.235107421875\n",
            "classify 2.2012939453125\n",
            "classify 2.33251953125\n",
            "classify 2.2587890625\n",
            "classify 2.276611328125\n",
            "classify 2.2596435546875\n",
            "0.09375\n",
            "0.1875\n",
            "0.171875\n",
            "0.140625\n",
            "0.171875\n",
            "0.1875\n",
            "time: 16.928970336914062 15.803477744261423\n",
            "36\n",
            "strain 0.15819206833839417\n",
            "strain 0.1731177121400833\n",
            "strain 0.15509696304798126\n",
            "strain 0.17093823850154877\n",
            "strain 0.16046598553657532\n",
            "strain 0.15534280240535736\n",
            "strain 0.16184304654598236\n",
            "strain 0.17227227985858917\n",
            "strain 0.15628592669963837\n",
            "strain 0.17390823364257812\n",
            "strain 0.17978663742542267\n",
            "classify 2.3055419921875\n",
            "classify 2.19970703125\n",
            "classify 2.240234375\n",
            "classify 2.232177734375\n",
            "classify 2.2579345703125\n",
            "classify 2.2022705078125\n",
            "0.125\n",
            "0.1875\n",
            "0.171875\n",
            "0.125\n",
            "0.15625\n",
            "0.15625\n",
            "time: 16.649569511413574 15.826361952601252\n",
            "37\n",
            "strain 0.20967647433280945\n",
            "strain 0.2050209641456604\n",
            "strain 0.16289477050304413\n",
            "strain 0.18318921327590942\n",
            "strain 0.1752508580684662\n",
            "strain 0.1965147852897644\n",
            "strain 0.2021101415157318\n",
            "strain 0.19510604441165924\n",
            "strain 0.18727385997772217\n",
            "strain 0.15058550238609314\n",
            "strain 0.17371556162834167\n",
            "classify 2.2113037109375\n",
            "classify 2.2705078125\n",
            "classify 2.237548828125\n",
            "classify 2.32177734375\n",
            "classify 2.291015625\n",
            "classify 2.21875\n",
            "0.25\n",
            "0.1875\n",
            "0.15625\n",
            "0.171875\n",
            "0.046875\n",
            "0.125\n",
            "time: 15.553555011749268 15.819196770065709\n",
            "38\n",
            "strain 0.17104773223400116\n",
            "strain 0.17151354253292084\n",
            "strain 0.12468662858009338\n",
            "strain 0.1499648243188858\n",
            "strain 0.18250079452991486\n",
            "strain 0.1545977145433426\n",
            "strain 0.1751672774553299\n",
            "strain 0.16145138442516327\n",
            "strain 0.1689605563879013\n",
            "strain 0.17784452438354492\n",
            "strain 0.15134495496749878\n",
            "classify 2.325927734375\n",
            "classify 2.25048828125\n",
            "classify 2.2650146484375\n",
            "classify 2.2818603515625\n",
            "classify 2.2720947265625\n",
            "classify 2.2889404296875\n",
            "0.078125\n",
            "0.109375\n",
            "0.171875\n",
            "0.15625\n",
            "0.078125\n",
            "0.140625\n",
            "time: 15.505874395370483 15.811176422314766\n",
            "39\n",
            "strain 0.20023338496685028\n",
            "strain 0.1685529351234436\n",
            "strain 0.16474071145057678\n",
            "strain 0.15597407519817352\n",
            "strain 0.16286669671535492\n",
            "strain 0.15179690718650818\n",
            "strain 0.16021738946437836\n",
            "strain 0.1540481150150299\n",
            "strain 0.1787990927696228\n",
            "strain 0.16869711875915527\n",
            "strain 0.1726960688829422\n",
            "classify 2.2822265625\n",
            "classify 2.2823486328125\n",
            "classify 2.277587890625\n",
            "classify 2.279541015625\n",
            "classify 2.2308349609375\n",
            "classify 2.1986083984375\n",
            "0.09375\n",
            "0.15625\n",
            "0.109375\n",
            "0.1875\n",
            "0.140625\n",
            "0.15625\n",
            "time: 14.974830150604248 15.79027938246727\n",
            "40\n",
            "strain 0.17455142736434937\n",
            "strain 0.16530318558216095\n",
            "strain 0.16445957124233246\n",
            "strain 0.1685810536146164\n",
            "strain 0.19258618354797363\n",
            "strain 0.1334673911333084\n",
            "strain 0.2129759043455124\n",
            "strain 0.18436159193515778\n",
            "strain 0.1693885326385498\n",
            "strain 0.1417480856180191\n",
            "strain 0.1803625375032425\n",
            "classify 2.25439453125\n",
            "classify 2.2174072265625\n",
            "classify 2.2452392578125\n",
            "classify 2.2237548828125\n",
            "classify 2.2059326171875\n",
            "classify 2.205078125\n",
            "0.203125\n",
            "0.140625\n",
            "0.078125\n",
            "0.15625\n",
            "0.109375\n",
            "0.1875\n",
            "time: 15.2406485080719 15.776886736474387\n",
            "41\n",
            "strain 0.187429279088974\n",
            "strain 0.17599232494831085\n",
            "strain 0.17648036777973175\n",
            "strain 0.1505318135023117\n",
            "strain 0.19062907993793488\n",
            "strain 0.16589456796646118\n",
            "strain 0.1566718965768814\n",
            "strain 0.17399467527866364\n",
            "strain 0.1703902631998062\n",
            "strain 0.16140855848789215\n",
            "strain 0.17766034603118896\n",
            "classify 2.207275390625\n",
            "classify 2.2542724609375\n",
            "classify 2.18798828125\n",
            "classify 2.2752685546875\n",
            "classify 2.2459716796875\n",
            "classify 2.264892578125\n",
            "0.171875\n",
            "0.203125\n",
            "0.140625\n",
            "0.109375\n",
            "0.15625\n",
            "0.171875\n",
            "time: 15.04395604133606 15.759448528289795\n",
            "42\n",
            "strain 0.1573232114315033\n",
            "strain 0.20534180104732513\n",
            "strain 0.21092259883880615\n",
            "strain 0.20836655795574188\n",
            "strain 0.24238987267017365\n",
            "strain 0.19497008621692657\n",
            "strain 0.1660270243883133\n",
            "strain 0.1846867799758911\n",
            "strain 0.14607179164886475\n",
            "strain 0.17107056081295013\n",
            "strain 0.15774855017662048\n",
            "classify 2.2808837890625\n",
            "classify 2.170654296875\n",
            "classify 2.216552734375\n",
            "classify 2.177978515625\n",
            "classify 2.2432861328125\n",
            "classify 2.2257080078125\n",
            "0.109375\n",
            "0.125\n",
            "0.140625\n",
            "0.171875\n",
            "0.140625\n",
            "0.15625\n",
            "time: 15.189577102661133 15.746207187342089\n",
            "43\n",
            "strain 0.1479511559009552\n",
            "strain 0.1754188984632492\n",
            "strain 0.17301923036575317\n",
            "strain 0.17844915390014648\n",
            "strain 0.15938694775104523\n",
            "strain 0.14875005185604095\n",
            "strain 0.16213783621788025\n",
            "strain 0.13054491579532623\n",
            "strain 0.16370359063148499\n",
            "strain 0.19105316698551178\n",
            "strain 0.19463130831718445\n",
            "classify 2.3560791015625\n",
            "classify 2.201904296875\n",
            "classify 2.225341796875\n",
            "classify 2.1934814453125\n",
            "classify 2.244384765625\n",
            "classify 2.185302734375\n",
            "0.09375\n",
            "0.078125\n",
            "0.15625\n",
            "0.140625\n",
            "0.1875\n",
            "0.09375\n",
            "time: 15.445639848709106 15.739387756044215\n",
            "44\n",
            "strain 0.20157237350940704\n",
            "strain 0.198530375957489\n",
            "strain 0.15493501722812653\n",
            "strain 0.16763727366924286\n",
            "strain 0.16388985514640808\n",
            "strain 0.16141505539417267\n",
            "strain 0.20141306519508362\n",
            "strain 0.18882177770137787\n",
            "strain 0.16563701629638672\n",
            "strain 0.19042614102363586\n",
            "strain 0.15077842772006989\n",
            "classify 2.1302490234375\n",
            "classify 2.2030029296875\n",
            "classify 2.29443359375\n",
            "classify 2.2928466796875\n",
            "classify 2.25146484375\n",
            "classify 2.18798828125\n",
            "0.21875\n",
            "0.140625\n",
            "0.046875\n",
            "0.109375\n",
            "0.125\n",
            "0.15625\n",
            "time: 14.972172737121582 15.722351784176297\n",
            "45\n",
            "strain 0.14570507407188416\n",
            "strain 0.17463883757591248\n",
            "strain 0.1928703784942627\n",
            "strain 0.17423614859580994\n",
            "strain 0.16814416646957397\n",
            "strain 0.17821525037288666\n",
            "strain 0.15832437574863434\n",
            "strain 0.14783340692520142\n",
            "strain 0.23080883920192719\n",
            "strain 0.15141193568706512\n",
            "strain 0.15349067747592926\n",
            "classify 2.20458984375\n",
            "classify 2.278564453125\n",
            "classify 2.2763671875\n",
            "classify 2.2437744140625\n",
            "classify 2.2491455078125\n",
            "classify 2.2589111328125\n",
            "0.140625\n",
            "0.078125\n",
            "0.140625\n",
            "0.234375\n",
            "0.15625\n",
            "0.15625\n",
            "time: 14.977511882781982 15.706169465313787\n",
            "46\n",
            "strain 0.17812888324260712\n",
            "strain 0.17294621467590332\n",
            "strain 0.1746920496225357\n",
            "strain 0.17491427063941956\n",
            "strain 0.18517468869686127\n",
            "strain 0.1805572211742401\n",
            "strain 0.18191799521446228\n",
            "strain 0.18565306067466736\n",
            "strain 0.2000255286693573\n",
            "strain 0.15783360600471497\n",
            "strain 0.17457516491413116\n",
            "classify 2.2354736328125\n",
            "classify 2.1265869140625\n",
            "classify 2.189453125\n",
            "classify 2.2286376953125\n",
            "classify 2.289306640625\n",
            "classify 2.1806640625\n",
            "0.078125\n",
            "0.109375\n",
            "0.09375\n",
            "0.09375\n",
            "0.171875\n",
            "0.15625\n",
            "time: 14.945226192474365 15.689989150838649\n",
            "47\n",
            "strain 0.23064561188220978\n",
            "strain 0.1699472814798355\n",
            "strain 0.15425634384155273\n",
            "strain 0.18294884264469147\n",
            "strain 0.2296002358198166\n",
            "strain 0.1689704954624176\n",
            "strain 0.16782985627651215\n",
            "strain 0.1815931499004364\n",
            "strain 0.1638113558292389\n",
            "strain 0.17522238194942474\n",
            "strain 0.2193448692560196\n",
            "classify 2.311279296875\n",
            "classify 2.22509765625\n",
            "classify 2.2830810546875\n",
            "classify 2.3140869140625\n",
            "classify 2.3050537109375\n",
            "classify 2.2520751953125\n",
            "0.0625\n",
            "0.125\n",
            "0.203125\n",
            "0.125\n",
            "0.171875\n",
            "0.140625\n",
            "time: 15.021510601043701 15.676074549555779\n",
            "48\n",
            "strain 0.16168901324272156\n",
            "strain 0.16001902520656586\n",
            "strain 0.16830483078956604\n",
            "strain 0.13521742820739746\n",
            "strain 0.15419507026672363\n",
            "strain 0.26867228746414185\n",
            "strain 0.17579756677150726\n",
            "strain 0.135894313454628\n",
            "strain 0.24395595490932465\n",
            "strain 0.20531173050403595\n",
            "strain 0.1537410318851471\n",
            "classify 2.1837158203125\n",
            "classify 2.2484130859375\n",
            "classify 2.226806640625\n",
            "classify 2.25244140625\n",
            "classify 2.150146484375\n",
            "classify 2.20263671875\n",
            "0.15625\n",
            "0.125\n",
            "0.234375\n",
            "0.140625\n",
            "0.109375\n",
            "0.234375\n",
            "time: 15.327271938323975 15.668966196021255\n",
            "49\n",
            "strain 0.157126784324646\n",
            "strain 0.20948044955730438\n",
            "strain 0.18207567930221558\n",
            "strain 0.20539799332618713\n",
            "strain 0.1434118151664734\n",
            "strain 0.20364513993263245\n",
            "strain 0.21441686153411865\n",
            "strain 0.17434251308441162\n",
            "strain 0.2104843407869339\n",
            "strain 0.15396356582641602\n",
            "strain 0.16990900039672852\n",
            "classify 2.281005859375\n",
            "classify 2.2763671875\n",
            "classify 2.1890869140625\n",
            "classify 2.234375\n",
            "classify 2.1571044921875\n",
            "classify 2.111328125\n",
            "0.21875\n",
            "0.078125\n",
            "0.171875\n",
            "0.1875\n",
            "0.171875\n",
            "0.203125\n",
            "time: 15.221547603607178 15.660036897659301\n",
            "50\n",
            "strain 0.18037952482700348\n",
            "strain 0.18575480580329895\n",
            "strain 0.1668144166469574\n",
            "strain 0.1369401067495346\n",
            "strain 0.14465965330600739\n",
            "strain 0.17244446277618408\n",
            "strain 0.14796370267868042\n",
            "strain 0.1415395587682724\n",
            "strain 0.2108476758003235\n",
            "strain 0.20136800408363342\n",
            "strain 0.16881586611270905\n",
            "classify 2.2069091796875\n",
            "classify 2.134765625\n",
            "classify 2.275390625\n",
            "classify 2.2650146484375\n",
            "classify 2.2232666015625\n",
            "classify 2.160888671875\n",
            "0.09375\n",
            "0.078125\n",
            "0.15625\n",
            "0.125\n",
            "0.140625\n",
            "0.109375\n",
            "time: 14.952901601791382 15.646180269764919\n",
            "51\n",
            "strain 0.18449050188064575\n",
            "strain 0.17312464118003845\n",
            "strain 0.15121851861476898\n",
            "strain 0.17868836224079132\n",
            "strain 0.15906144678592682\n",
            "strain 0.1728883981704712\n",
            "strain 0.18520797789096832\n",
            "strain 0.17466962337493896\n",
            "strain 0.18783128261566162\n",
            "strain 0.22324439883232117\n",
            "strain 0.14550621807575226\n",
            "classify 2.32958984375\n",
            "classify 2.2476806640625\n",
            "classify 2.2802734375\n",
            "classify 2.2652587890625\n",
            "classify 2.3089599609375\n",
            "classify 2.2752685546875\n",
            "0.140625\n",
            "0.25\n",
            "0.171875\n",
            "0.078125\n",
            "0.171875\n",
            "0.1875\n",
            "time: 14.940796613693237 15.63262474995393\n",
            "52\n",
            "strain 0.1793101727962494\n",
            "strain 0.2033897191286087\n",
            "strain 0.17486290633678436\n",
            "strain 0.19740089774131775\n",
            "strain 0.16498151421546936\n",
            "strain 0.15217208862304688\n",
            "strain 0.16710145771503448\n",
            "strain 0.14034496247768402\n",
            "strain 0.15253272652626038\n",
            "strain 0.16507957875728607\n",
            "strain 0.16166304051876068\n",
            "classify 2.215087890625\n",
            "classify 2.17041015625\n",
            "classify 2.1986083984375\n",
            "classify 2.2010498046875\n",
            "classify 2.167236328125\n",
            "classify 2.281494140625\n",
            "0.15625\n",
            "0.140625\n",
            "0.15625\n",
            "0.140625\n",
            "0.125\n",
            "0.203125\n",
            "time: 15.000038862228394 15.62069905029153\n",
            "53\n",
            "strain 0.1449628621339798\n",
            "strain 0.15739081799983978\n",
            "strain 0.21826396882534027\n",
            "strain 0.2270335555076599\n",
            "strain 0.1944301873445511\n",
            "strain 0.21432821452617645\n",
            "strain 0.14466795325279236\n",
            "strain 0.20467637479305267\n",
            "strain 0.1621657907962799\n",
            "strain 0.153656005859375\n",
            "strain 0.15420310199260712\n",
            "classify 2.1812744140625\n",
            "classify 2.182373046875\n",
            "classify 2.2835693359375\n",
            "classify 2.236572265625\n",
            "classify 2.1990966796875\n",
            "classify 2.1485595703125\n",
            "0.125\n",
            "0.09375\n",
            "0.21875\n",
            "0.15625\n",
            "0.1875\n",
            "0.109375\n",
            "time: 15.320958852767944 15.615157352553474\n",
            "54\n",
            "strain 0.14283250272274017\n",
            "strain 0.2071525752544403\n",
            "strain 0.17681163549423218\n",
            "strain 0.2006482183933258\n",
            "strain 0.2082744687795639\n",
            "strain 0.1888100951910019\n",
            "strain 0.2328263223171234\n",
            "strain 0.18621917068958282\n",
            "strain 0.2079675793647766\n",
            "strain 0.16387486457824707\n",
            "strain 0.15469782054424286\n",
            "classify 2.1778564453125\n",
            "classify 2.2196044921875\n",
            "classify 2.2593994140625\n",
            "classify 2.097412109375\n",
            "classify 2.2216796875\n",
            "classify 2.2149658203125\n",
            "0.140625\n",
            "0.140625\n",
            "0.203125\n",
            "0.140625\n",
            "0.125\n",
            "0.125\n",
            "time: 15.190220832824707 15.607441759109497\n",
            "55\n",
            "strain 0.1653551310300827\n",
            "strain 0.18449079990386963\n",
            "strain 0.21600565314292908\n",
            "strain 0.16907218098640442\n",
            "strain 0.16363799571990967\n",
            "strain 0.15254978835582733\n",
            "strain 0.22941191494464874\n",
            "strain 0.13883858919143677\n",
            "strain 0.1832512617111206\n",
            "strain 0.17956450581550598\n",
            "strain 0.16975419223308563\n",
            "classify 2.321533203125\n",
            "classify 2.173583984375\n",
            "classify 2.1925048828125\n",
            "classify 2.2427978515625\n",
            "classify 2.2611083984375\n",
            "classify 2.14306640625\n",
            "0.21875\n",
            "0.15625\n",
            "0.109375\n",
            "0.125\n",
            "0.15625\n",
            "0.296875\n",
            "time: 15.274123668670654 15.601498497383934\n",
            "56\n",
            "strain 0.18128085136413574\n",
            "strain 0.1737598478794098\n",
            "strain 0.1854645013809204\n",
            "strain 0.20300060510635376\n",
            "strain 0.1602374017238617\n",
            "strain 0.16027702391147614\n",
            "strain 0.22122038900852203\n",
            "strain 0.15580792725086212\n",
            "strain 0.19406643509864807\n",
            "strain 0.2533021867275238\n",
            "strain 0.2449754923582077\n",
            "classify 2.198974609375\n",
            "classify 2.2803955078125\n",
            "classify 2.1905517578125\n",
            "classify 2.359375\n",
            "classify 2.29345703125\n",
            "classify 2.13330078125\n",
            "0.265625\n",
            "0.109375\n",
            "0.140625\n",
            "0.171875\n",
            "0.234375\n",
            "0.171875\n",
            "time: 15.081358194351196 15.592381431345354\n",
            "57\n",
            "strain 0.2179725468158722\n",
            "strain 0.16018013656139374\n",
            "strain 0.13992485404014587\n",
            "strain 0.1637592613697052\n",
            "strain 0.1824893206357956\n",
            "strain 0.2682431936264038\n",
            "strain 0.21389077603816986\n",
            "strain 0.18981248140335083\n",
            "strain 0.2042732685804367\n",
            "strain 0.1684691458940506\n",
            "strain 0.2025177925825119\n",
            "classify 2.181640625\n",
            "classify 2.17041015625\n",
            "classify 2.2816162109375\n",
            "classify 2.22265625\n",
            "classify 2.30126953125\n",
            "classify 2.261962890625\n",
            "0.171875\n",
            "0.078125\n",
            "0.1875\n",
            "0.15625\n",
            "0.171875\n",
            "0.171875\n",
            "time: 14.966560125350952 15.581599391739944\n",
            "58\n",
            "strain 0.13638387620449066\n",
            "strain 0.1895948350429535\n",
            "strain 0.18251675367355347\n",
            "strain 0.15109486877918243\n",
            "strain 0.1538098305463791\n",
            "strain 0.16844777762889862\n",
            "strain 0.17337284982204437\n",
            "strain 0.19330517947673798\n",
            "strain 0.17069195210933685\n",
            "strain 0.168783038854599\n",
            "strain 0.17525698244571686\n",
            "classify 2.2628173828125\n",
            "classify 2.2525634765625\n",
            "classify 2.287109375\n",
            "classify 2.1771240234375\n",
            "classify 2.23681640625\n",
            "classify 2.1395263671875\n",
            "0.046875\n",
            "0.1875\n",
            "0.140625\n",
            "0.28125\n",
            "0.171875\n",
            "0.125\n",
            "time: 15.42984414100647 15.579035298298981\n",
            "59\n",
            "strain 0.19558420777320862\n",
            "strain 0.19500946998596191\n",
            "strain 0.17718257009983063\n",
            "strain 0.1826244741678238\n",
            "strain 0.1949705183506012\n",
            "strain 0.20973734557628632\n",
            "strain 0.17545700073242188\n",
            "strain 0.16424714028835297\n",
            "strain 0.1756620556116104\n",
            "strain 0.18145877122879028\n",
            "strain 0.18896374106407166\n",
            "classify 2.118408203125\n",
            "classify 2.1624755859375\n",
            "classify 2.2579345703125\n",
            "classify 2.2296142578125\n",
            "classify 2.176513671875\n",
            "classify 2.1812744140625\n",
            "0.1875\n",
            "0.125\n",
            "0.1875\n",
            "0.203125\n",
            "0.25\n",
            "0.140625\n",
            "time: 15.017028570175171 15.569689091046651\n",
            "60\n",
            "strain 0.15640586614608765\n",
            "strain 0.14751514792442322\n",
            "strain 0.24895982444286346\n",
            "strain 0.17404863238334656\n",
            "strain 0.21021927893161774\n",
            "strain 0.22375868260860443\n",
            "strain 0.156528502702713\n",
            "strain 0.20152834057807922\n",
            "strain 0.16878733038902283\n",
            "strain 0.18321539461612701\n",
            "strain 0.14039874076843262\n",
            "classify 2.1326904296875\n",
            "classify 2.1324462890625\n",
            "classify 2.1527099609375\n",
            "classify 2.1004638671875\n",
            "classify 2.2252197265625\n",
            "classify 2.1650390625\n",
            "0.234375\n",
            "0.15625\n",
            "0.203125\n",
            "0.203125\n",
            "0.109375\n",
            "0.21875\n",
            "time: 15.002680540084839 15.560401701536335\n",
            "61\n",
            "strain 0.18746750056743622\n",
            "strain 0.2097405195236206\n",
            "strain 0.16358453035354614\n",
            "strain 0.20900510251522064\n",
            "strain 0.16921298205852509\n",
            "strain 0.17856459319591522\n",
            "strain 0.136015385389328\n",
            "strain 0.1658293902873993\n",
            "strain 0.20091326534748077\n",
            "strain 0.2408713549375534\n",
            "strain 0.24680344760417938\n",
            "classify 2.2510986328125\n",
            "classify 2.2481689453125\n",
            "classify 2.1884765625\n",
            "classify 2.1988525390625\n",
            "classify 2.2293701171875\n",
            "classify 2.2576904296875\n",
            "0.1875\n",
            "0.125\n",
            "0.078125\n",
            "0.15625\n",
            "0.1875\n",
            "0.21875\n",
            "time: 14.956640243530273 15.55067140056241\n",
            "62\n",
            "strain 0.1697973906993866\n",
            "strain 0.2120785266160965\n",
            "strain 0.14499418437480927\n",
            "strain 0.1827874630689621\n",
            "strain 0.17977374792099\n",
            "strain 0.17109480500221252\n",
            "strain 0.15492266416549683\n",
            "strain 0.21237672865390778\n",
            "strain 0.15151357650756836\n",
            "strain 0.16475264728069305\n",
            "strain 0.1288161426782608\n",
            "classify 2.2059326171875\n",
            "classify 2.198486328125\n",
            "classify 2.221435546875\n",
            "classify 2.2320556640625\n",
            "classify 2.2293701171875\n",
            "classify 2.1585693359375\n",
            "0.1875\n",
            "0.234375\n",
            "0.140625\n",
            "0.15625\n",
            "0.25\n",
            "0.265625\n",
            "time: 14.890267610549927 15.540195847314502\n",
            "63\n",
            "strain 0.1626565009355545\n",
            "strain 0.1687421351671219\n",
            "strain 0.16243813931941986\n",
            "strain 0.18657544255256653\n",
            "strain 0.17932277917861938\n",
            "strain 0.17502181231975555\n",
            "strain 0.22972552478313446\n",
            "strain 0.2217281609773636\n",
            "strain 0.16802091896533966\n",
            "strain 0.20741938054561615\n",
            "strain 0.17291049659252167\n",
            "classify 2.1993408203125\n",
            "classify 2.1319580078125\n",
            "classify 2.11962890625\n",
            "classify 2.2508544921875\n",
            "classify 2.0843505859375\n",
            "classify 2.1781005859375\n",
            "0.203125\n",
            "0.21875\n",
            "0.21875\n",
            "0.25\n",
            "0.21875\n",
            "0.171875\n",
            "time: 15.156641006469727 15.534210592508316\n",
            "64\n",
            "strain 0.16282141208648682\n",
            "strain 0.20912186801433563\n",
            "strain 0.160696342587471\n",
            "strain 0.15680281817913055\n",
            "strain 0.1509757936000824\n",
            "strain 0.169353187084198\n",
            "strain 0.17250750958919525\n",
            "strain 0.16830630600452423\n",
            "strain 0.16458642482757568\n",
            "strain 0.2548968195915222\n",
            "strain 0.14823845028877258\n",
            "classify 2.2303466796875\n",
            "classify 2.164306640625\n",
            "classify 2.2689208984375\n",
            "classify 2.2467041015625\n",
            "classify 2.262939453125\n",
            "classify 2.31298828125\n",
            "0.15625\n",
            "0.109375\n",
            "0.125\n",
            "0.15625\n",
            "0.15625\n",
            "0.125\n",
            "time: 15.166954040527344 15.528579433147724\n",
            "65\n",
            "strain 0.15821559727191925\n",
            "strain 0.1813855916261673\n",
            "strain 0.16555212438106537\n",
            "strain 0.19116389751434326\n",
            "strain 0.20495884120464325\n",
            "strain 0.1427755355834961\n",
            "strain 0.17309145629405975\n",
            "strain 0.15155074000358582\n",
            "strain 0.1559462994337082\n",
            "strain 0.18540777266025543\n",
            "strain 0.15995150804519653\n",
            "classify 2.172607421875\n",
            "classify 2.2484130859375\n",
            "classify 2.1588134765625\n",
            "classify 2.2235107421875\n",
            "classify 2.245361328125\n",
            "classify 2.2513427734375\n",
            "0.171875\n",
            "0.140625\n",
            "0.15625\n",
            "0.203125\n",
            "0.125\n",
            "0.109375\n",
            "time: 15.106823682785034 15.522196484334541\n",
            "66\n",
            "strain 0.2018752545118332\n",
            "strain 0.20324398577213287\n",
            "strain 0.21918073296546936\n",
            "strain 0.19167020916938782\n",
            "strain 0.2523491382598877\n",
            "strain 0.19978109002113342\n",
            "strain 0.1952168494462967\n",
            "strain 0.20978522300720215\n",
            "strain 0.19528703391551971\n",
            "strain 0.20998132228851318\n",
            "strain 0.14589092135429382\n",
            "classify 2.18310546875\n",
            "classify 2.184326171875\n",
            "classify 2.2545166015625\n",
            "classify 2.126708984375\n",
            "classify 2.2354736328125\n",
            "classify 2.2569580078125\n",
            "0.21875\n",
            "0.28125\n",
            "0.125\n",
            "0.171875\n",
            "0.171875\n",
            "0.203125\n",
            "time: 15.000891923904419 15.514422804562013\n",
            "67\n",
            "strain 0.18742406368255615\n",
            "strain 0.21044212579727173\n",
            "strain 0.18116101622581482\n",
            "strain 0.17109869420528412\n",
            "strain 0.18557803332805634\n",
            "strain 0.23669910430908203\n",
            "strain 0.18637312948703766\n",
            "strain 0.15984027087688446\n",
            "strain 0.15251794457435608\n",
            "strain 0.1649116426706314\n",
            "strain 0.1542426347732544\n",
            "classify 2.21826171875\n",
            "classify 2.1707763671875\n",
            "classify 2.186767578125\n",
            "classify 2.199951171875\n",
            "classify 2.227783203125\n",
            "classify 2.18701171875\n",
            "0.171875\n",
            "0.25\n",
            "0.140625\n",
            "0.109375\n",
            "0.140625\n",
            "0.15625\n",
            "time: 14.911947250366211 15.505566737231087\n",
            "68\n",
            "strain 0.19827409088611603\n",
            "strain 0.16820476949214935\n",
            "strain 0.16805365681648254\n",
            "strain 0.13410572707653046\n",
            "strain 0.18004301190376282\n",
            "strain 0.14812129735946655\n",
            "strain 0.2517247796058655\n",
            "strain 0.15568777918815613\n",
            "strain 0.18311624228954315\n",
            "strain 0.1837816685438156\n",
            "strain 0.2730233669281006\n",
            "classify 2.31787109375\n",
            "classify 2.2259521484375\n",
            "classify 2.1695556640625\n",
            "classify 2.2740478515625\n",
            "classify 2.19873046875\n",
            "classify 2.156005859375\n",
            "0.140625\n",
            "0.171875\n",
            "0.171875\n",
            "0.234375\n",
            "0.203125\n",
            "0.140625\n",
            "time: 15.259421825408936 15.50200657222582\n",
            "69\n",
            "strain 0.1730811595916748\n",
            "strain 0.18027645349502563\n",
            "strain 0.241622656583786\n",
            "strain 0.2508316934108734\n",
            "strain 0.19006238877773285\n",
            "strain 0.17169517278671265\n",
            "strain 0.27114415168762207\n",
            "strain 0.1626512110233307\n",
            "strain 0.18513944745063782\n",
            "strain 0.17818473279476166\n",
            "strain 0.2097454071044922\n",
            "classify 2.341064453125\n",
            "classify 2.2315673828125\n",
            "classify 2.2816162109375\n",
            "classify 2.318603515625\n",
            "classify 2.381103515625\n",
            "classify 2.23388671875\n",
            "0.3125\n",
            "0.140625\n",
            "0.140625\n",
            "0.203125\n",
            "0.1875\n",
            "0.203125\n",
            "time: 15.220539808273315 15.497999038015093\n",
            "70\n",
            "strain 0.20653502643108368\n",
            "strain 0.20681729912757874\n",
            "strain 0.23788559436798096\n",
            "strain 0.1877089887857437\n",
            "strain 0.15792980790138245\n",
            "strain 0.21537695825099945\n",
            "strain 0.15238834917545319\n",
            "strain 0.20171619951725006\n",
            "strain 0.19324684143066406\n",
            "strain 0.16486933827400208\n",
            "strain 0.160040020942688\n",
            "classify 2.25048828125\n",
            "classify 2.159912109375\n",
            "classify 2.216064453125\n",
            "classify 2.2156982421875\n",
            "classify 2.3065185546875\n",
            "classify 2.2364501953125\n",
            "0.15625\n",
            "0.125\n",
            "0.140625\n",
            "0.21875\n",
            "0.171875\n",
            "0.140625\n",
            "time: 14.994541645050049 15.490914291059466\n",
            "71\n",
            "strain 0.18363775312900543\n",
            "strain 0.21477244794368744\n",
            "strain 0.1827595978975296\n",
            "strain 0.18632173538208008\n",
            "strain 0.1629108041524887\n",
            "strain 0.17056326568126678\n",
            "strain 0.17516234517097473\n",
            "strain 0.22773094475269318\n",
            "strain 0.15498042106628418\n",
            "strain 0.2849763035774231\n",
            "strain 0.2195674180984497\n",
            "classify 2.1468505859375\n",
            "classify 2.18505859375\n",
            "classify 2.2279052734375\n",
            "classify 2.2000732421875\n",
            "classify 2.29150390625\n",
            "classify 2.171630859375\n",
            "0.078125\n",
            "0.21875\n",
            "0.21875\n",
            "0.234375\n",
            "0.140625\n",
            "0.28125\n",
            "time: 15.040390968322754 15.484663390451008\n",
            "72\n",
            "strain 0.21561941504478455\n",
            "strain 0.2452145665884018\n",
            "strain 0.2383723109960556\n",
            "strain 0.22434882819652557\n",
            "strain 0.23405520617961884\n",
            "strain 0.1870674341917038\n",
            "strain 0.2318742573261261\n",
            "strain 0.17647208273410797\n",
            "strain 0.17461909353733063\n",
            "strain 0.24182376265525818\n",
            "strain 0.17849856615066528\n",
            "classify 2.2177734375\n",
            "classify 2.2139892578125\n",
            "classify 2.164794921875\n",
            "classify 2.1767578125\n",
            "classify 2.197265625\n",
            "classify 2.26806640625\n",
            "0.28125\n",
            "0.109375\n",
            "0.203125\n",
            "0.09375\n",
            "0.078125\n",
            "0.109375\n",
            "time: 14.951523303985596 15.477366486640825\n",
            "73\n",
            "strain 0.16461648046970367\n",
            "strain 0.2407509982585907\n",
            "strain 0.2263096421957016\n",
            "strain 0.20502234995365143\n",
            "strain 0.19843164086341858\n",
            "strain 0.20255056023597717\n",
            "strain 0.21180255711078644\n",
            "strain 0.23965275287628174\n",
            "strain 0.23669911921024323\n",
            "strain 0.180953249335289\n",
            "strain 0.2207087278366089\n",
            "classify 2.1248779296875\n",
            "classify 2.1688232421875\n",
            "classify 2.136474609375\n",
            "classify 2.1510009765625\n",
            "classify 2.288330078125\n",
            "classify 2.2117919921875\n",
            "0.171875\n",
            "0.203125\n",
            "0.25\n",
            "0.109375\n",
            "0.15625\n",
            "0.234375\n",
            "time: 15.169409036636353 15.4732115655332\n",
            "74\n",
            "strain 0.16551709175109863\n",
            "strain 0.23589597642421722\n",
            "strain 0.2937399744987488\n",
            "strain 0.17224156856536865\n",
            "strain 0.16377605497837067\n",
            "strain 0.2071262001991272\n",
            "strain 0.13733027875423431\n",
            "strain 0.15982316434383392\n",
            "strain 0.18718557059764862\n",
            "strain 0.2392841875553131\n",
            "strain 0.20745772123336792\n",
            "classify 2.14794921875\n",
            "classify 2.228515625\n",
            "classify 2.1826171875\n",
            "classify 2.25439453125\n",
            "classify 2.1943359375\n",
            "classify 2.2462158203125\n",
            "0.203125\n",
            "0.140625\n",
            "0.109375\n",
            "0.203125\n",
            "0.25\n",
            "0.1875\n",
            "time: 15.406094789505005 15.472323430379232\n",
            "75\n",
            "strain 0.17284917831420898\n",
            "strain 0.19173477590084076\n",
            "strain 0.19626839458942413\n",
            "strain 0.1883179247379303\n",
            "strain 0.2645096480846405\n",
            "strain 0.19909623265266418\n",
            "strain 0.18678301572799683\n",
            "strain 0.1715703159570694\n",
            "strain 0.1717049926519394\n",
            "strain 0.17504964768886566\n",
            "strain 0.1632891297340393\n",
            "classify 2.1588134765625\n",
            "classify 2.210693359375\n",
            "classify 2.1885986328125\n",
            "classify 2.2044677734375\n",
            "classify 2.1910400390625\n",
            "classify 2.2174072265625\n",
            "0.203125\n",
            "0.1875\n",
            "0.140625\n",
            "0.171875\n",
            "0.15625\n",
            "0.125\n",
            "time: 15.061564922332764 15.466925119098864\n",
            "76\n",
            "strain 0.22137631475925446\n",
            "strain 0.186674103140831\n",
            "strain 0.21084438264369965\n",
            "strain 0.2542329728603363\n",
            "strain 0.20740851759910583\n",
            "strain 0.16044384241104126\n",
            "strain 0.1898299604654312\n",
            "strain 0.20941875874996185\n",
            "strain 0.2179344892501831\n",
            "strain 0.17875663936138153\n",
            "strain 0.19218704104423523\n",
            "classify 2.0916748046875\n",
            "classify 2.265869140625\n",
            "classify 2.3294677734375\n",
            "classify 2.177978515625\n",
            "classify 2.19970703125\n",
            "classify 2.209228515625\n",
            "0.1875\n",
            "0.09375\n",
            "0.21875\n",
            "0.265625\n",
            "0.171875\n",
            "0.265625\n",
            "time: 14.954456567764282 15.460276129957917\n",
            "77\n",
            "strain 0.21674980223178864\n",
            "strain 0.17542676627635956\n",
            "strain 0.2267656922340393\n",
            "strain 0.22587475180625916\n",
            "strain 0.20535701513290405\n",
            "strain 0.16692355275154114\n",
            "strain 0.14226315915584564\n",
            "strain 0.1900295615196228\n",
            "strain 0.20154623687267303\n",
            "strain 0.3718683123588562\n",
            "strain 0.1938033550977707\n",
            "classify 2.23046875\n",
            "classify 2.2041015625\n",
            "classify 2.2255859375\n",
            "classify 2.2508544921875\n",
            "classify 2.2061767578125\n",
            "classify 2.1590576171875\n",
            "0.171875\n",
            "0.1875\n",
            "0.234375\n",
            "0.203125\n",
            "0.25\n",
            "0.171875\n",
            "time: 14.938973188400269 15.453599807543632\n",
            "78\n",
            "strain 0.2445164918899536\n",
            "strain 0.1909475028514862\n",
            "strain 0.1435922235250473\n",
            "strain 0.2031410187482834\n",
            "strain 0.17854458093643188\n",
            "strain 0.16100016236305237\n",
            "strain 0.22376945614814758\n",
            "strain 0.21472011506557465\n",
            "strain 0.16911113262176514\n",
            "strain 0.19138407707214355\n",
            "strain 0.15252093970775604\n",
            "classify 2.153564453125\n",
            "classify 2.1405029296875\n",
            "classify 2.1983642578125\n",
            "classify 2.2896728515625\n",
            "classify 2.13330078125\n",
            "classify 2.202880859375\n",
            "0.25\n",
            "0.09375\n",
            "0.203125\n",
            "0.25\n",
            "0.265625\n",
            "0.0625\n",
            "time: 15.260286092758179 15.451158964181248\n",
            "79\n",
            "strain 0.1876329481601715\n",
            "strain 0.21249614655971527\n",
            "strain 0.34410175681114197\n",
            "strain 0.18767163157463074\n",
            "strain 0.17835424840450287\n"
          ]
        }
      ],
      "source": [
        "# @title strain ctrain test\n",
        "import torch\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.GradScaler()\n",
        "\n",
        "def strain(model, dataloader, optim, scheduler=None): # train function with automatic mixed precision\n",
        "    model.train()\n",
        "    for i, (x, _) in enumerate(dataloader):\n",
        "        x = x.to(device)#.to(torch.bfloat16) # [b,c,h,w] -> [b,h*w,c]\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16): # bfloat16 float16\n",
        "            loss = model.loss(x)\n",
        "\n",
        "            # repr_loss, std_loss, cov_loss = model.loss(x)\n",
        "            # loss = model.sim_coeff * repr_loss + model.std_coeff * std_loss + model.cov_coeff * cov_loss\n",
        "\n",
        "        optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        # scaler.unscale_(optim)\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 5) # 0.5\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            m=0.999 # 0.99 m = next(momentum_scheduler)\n",
        "            norms=[]\n",
        "            for param_q, param_k in zip(model.student.parameters(), model.teacher.parameters()):\n",
        "                param_k.data.mul_(m).add_((1.-m) * param_q.detach().data)\n",
        "\n",
        "        # if scheduler is not None: scheduler.step()\n",
        "        if i%10==0: print(\"strain\",loss.item())\n",
        "        # try: wandb.log({\"loss\": loss.item(), \"repr/I\": repr_loss.item(), \"std/V\": std_loss.item(), \"cov/C\": cov_loss.item()})\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except NameError: pass\n",
        "        if i>=100: break\n",
        "\n",
        "\n",
        "def ctrain(model, classifier, dataloader, coptim, scheduler=None): # train function with automatic mixed precision\n",
        "    model.eval()\n",
        "    classifier.train()\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device) # [batch, ]\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16): # bfloat16 float16\n",
        "            with torch.no_grad():\n",
        "                sx = model(x).detach()\n",
        "            y_ = classifier(sx)\n",
        "            loss = F.cross_entropy(y_, y)\n",
        "        coptim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(coptim)\n",
        "        scaler.update()\n",
        "        print(\"classify\",loss.item())\n",
        "        try: wandb.log({\"closs\": loss.item()})\n",
        "        except NameError: pass\n",
        "        if i>=10: break\n",
        "\n",
        "\n",
        "def test(model, classifier, dataloader):\n",
        "    model.eval()\n",
        "    classifier.eval()\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device) # [batch, ]\n",
        "        with torch.no_grad():\n",
        "            sx = model(x)\n",
        "            rankme = RankMe(sx).item()\n",
        "            lidar = LiDAR(sx).item()\n",
        "            y_ = classifier(sx)\n",
        "        correct = (y==y_.argmax(dim=1)).sum().item()\n",
        "        print(correct/len(y))\n",
        "        # try: wandb.log({\"correct\": correct/len(y)})\n",
        "        try: wandb.log({\"correct\": correct/len(y), \"rankme\": rankme, \"lidar\": lidar})\n",
        "        except NameError: pass\n",
        "        if i>=10: break\n",
        "\n",
        "import time\n",
        "start = begin = time.time()\n",
        "# for i in range(1):\n",
        "for i in range(500):\n",
        "    print(i)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    strain(ijepa, train_loader, optim)\n",
        "    ctrain(ijepa, classifier, train_loader, coptim)\n",
        "    test(ijepa, classifier, test_loader)\n",
        "\n",
        "    # strain(violet, train_loader, voptim)\n",
        "    # ctrain(violet, classifier, train_loader, coptim)\n",
        "    # test(violet, classifier, test_loader)\n",
        "\n",
        "    print('time:',time.time() - start, (time.time()-begin)/(i+1))\n",
        "    start = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title supervised train test\n",
        "import torch\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.GradScaler()\n",
        "\n",
        "# def strain(model, dataloader, optim, scheduler=None):\n",
        "def strain(model, classifier, dataloader, optim, coptim, scheduler=None):\n",
        "    model.train()\n",
        "    classifier.train()\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        x = x.to(device)#.to(torch.bfloat16) # [b,c,h,w] -> [b,h*w,c]\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16): # bfloat16 float16\n",
        "            sx = model(x)\n",
        "            y_ = classifier(sx)\n",
        "            loss = F.cross_entropy(y_, y)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        # print(loss)\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # for p in list(filter(lambda p: p.grad is not None, model.parameters())):\n",
        "        #     print(p.grad.data.norm(2).item())\n",
        "        # print(\"max grad norm\", max([p.grad.data.norm(2).item() for p in list(filter(lambda p: p.grad is not None, model.parameters()))]))\n",
        "        # scaler.unscale_(optim)\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 10) # 0.5\n",
        "\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        # if scheduler is not None: scheduler.step()\n",
        "        print(\"strain\",loss.item())\n",
        "        # for param in ijepa.student.cls: print(param.data)\n",
        "        # for param in ijepa.predicter.cls: print(param.data)\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except NameError: pass\n",
        "        if i>=50: break\n",
        "\n",
        "\n",
        "# def test(model, dataloader):\n",
        "def test(model, classifier, dataloader):\n",
        "    model.eval()\n",
        "    classifier.eval()\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device) # [batch, ]\n",
        "        # .to(torch.bfloat16)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sx = model(x)\n",
        "            y_ = classifier(sx)\n",
        "        loss = F.cross_entropy(y_, y)\n",
        "        correct = (y==y_.argmax(dim=1)).sum().item()\n",
        "        print(correct/len(y))\n",
        "        try: wandb.log({\"correct\": correct/len(y), \"closs\": loss.item()})\n",
        "        except NameError: pass\n",
        "        if i>=10: break\n",
        "\n",
        "\n",
        "for i in range(1000):\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # np.random.shuffle(train_indices); np.random.shuffle(val_indices)\n",
        "    # train_sampler, valid_sampler = SubsetRandomSampler(train_indices), SubsetRandomSampler(val_indices)\n",
        "    # # batch_size = 64 #512\n",
        "    # train_loader = DataLoader(train_data, sampler=train_sampler, pin_memory=True, batch_size=batch_size, num_workers=2, drop_last=True) # num_workers = 4\n",
        "    # test_loader = DataLoader(train_data, sampler=valid_sampler, pin_memory=True, batch_size=batch_size, num_workers=2, drop_last=True)\n",
        "\n",
        "    # strain(ijepa, train_loader, optim)\n",
        "    strain(ijepa, classifier, train_loader, optim, coptim)\n",
        "    test(ijepa, classifier, test_loader)\n",
        "\n",
        "    # strain(violet, train_loader, voptim)\n",
        "    # test(violet, test_loader)\n"
      ],
      "metadata": {
        "id": "4J2ahp3wmqcg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "\n",
        "# # modelsd, optimsd = torch.load(folder+'SeqJEPA.pkl', map_location=device).values()\n",
        "# modelsd, optimsd = torch.load('SeqJEPA.pkl', map_location=device).values()\n",
        "# seq_jepa.load_state_dict(modelsd, strict=False)\n",
        "# optim.load_state_dict(optimsd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzo9DMDPcOxu",
        "outputId": "2aa950ff-7a1c-46e0-924c-c6922b2ca522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'model': seq_jepa.state_dict(), 'optimizer': optim.state_dict()}\n",
        "torch.save(checkpoint, folder+'IJEPA.pkl')\n",
        "# torch.save(checkpoint, 'IJEPA.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "DNNPOuUmcSNf",
        "outputId": "9c0fdeca-f315-457a-a102-ff87f9290f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'seq_jepa' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-06e8be6b0f78>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_jepa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'IJEPA.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# torch.save(checkpoint, 'IJEPA.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq_jepa' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## drawer"
      ],
      "metadata": {
        "id": "aLT74ihtMnh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title RoPE2D & RotEmb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def RoPE(dim, seq_len=512, base=10000):\n",
        "    theta = 1.0 / (base ** (torch.arange(0, dim, step=2) / dim))\n",
        "    pos = torch.arange(seq_len).unsqueeze(-1)\n",
        "    angles = (pos * theta)[None,...,None] # [seq_len, 1] * [dim // 2] -> [1, seq_len, dim // 2, 1]\n",
        "    rot_emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1).flatten(-2).to(device) # [1, seq_len, dim // 2, 2] -> [1, seq_len, dim]\n",
        "    return rot_emb\n",
        "\n",
        "# class RoPE(nn.Module): # Rotary Positional Embeddings\n",
        "#     def __init__(self, dim, seq_len=512, base=10000):\n",
        "#         super().__init__()\n",
        "#         self.dim, self.base = dim, base\n",
        "#         theta = 1.0 / (base ** (torch.arange(0, dim, step=2) / dim))\n",
        "#         pos = torch.arange(seq_len).unsqueeze(-1)\n",
        "#         angles = (pos * theta)[None,...,None] # [seq_len, 1] * [dim // 2] -> [1, seq_len, dim // 2, 1]\n",
        "#         self.rot_emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1).flatten(-2).to(device) # [1, seq_len, dim // 2, 2] -> [1, seq_len, dim]\n",
        "\n",
        "#     def forward(self, x): # [batch, T, dim] / [batch, T, n_heads, d_head]\n",
        "#         seq_len = x.size(1)\n",
        "#         if self.rot_emb.shape[0] < seq_len: self.__init__(self.dim, seq_len, self.base)\n",
        "#         # print('rope fwd', x.shape, self.rot_emb.shape)\n",
        "#         if x.dim()==4: return x * self.rot_emb[:,:seq_len].unsqueeze(2)\n",
        "#         return x * self.rot_emb[:,:seq_len]\n",
        "\n",
        "\n",
        "def RoPE2D(dim=16, h=8, w=8, base=10000):\n",
        "    # theta = 1. / (base ** (torch.arange(0, dim, step=4) / dim))\n",
        "    # theta = 1. / (base**torch.linspace(0,1,dim//4)).unsqueeze(0)\n",
        "    theta = 1. / (base**torch.linspace(0,1,dim//2)).unsqueeze(0)\n",
        "    y, x = torch.meshgrid(torch.arange(h), torch.arange(w), indexing=\"ij\") # print(y,x) # [h,w], y:row_num, x:col_num\n",
        "    y, x = (y.reshape(-1,1) * theta).unsqueeze(-1), (x.reshape(-1,1) * theta).unsqueeze(-1) # [h*w,1]*[1,dim//4] = [h*w, dim//4, 1]\n",
        "    # rot_emb = torch.cat([x.sin(), x.cos(), y.sin(), y.cos()], dim=-1).flatten(-2) # [h*w, dim//4 ,4] -> [h*w, dim]\n",
        "    # rot_emb = torch.cat([x.sin(), x.cos(), y.sin(), y.cos()], dim=-1)#.reshape(dim, h, w).to(device) # [h*w, dim//4 ,4] -> [h, w, dim]\n",
        "    rot_emb = torch.cat([x.sin(), y.sin()], dim=-1).flatten(-2).to(device) # [h*w, dim//4 ,4] -> [h, w, dim]\n",
        "    # rot_emb = torch.cat([x.cos(), y.cos()], dim=-1).reshape(h, w, dim).to(device) # [h*w, dim//4 ,4] -> [h, w, dim]\n",
        "    return rot_emb\n",
        "\n",
        "\n",
        "\n",
        "# class RoPE2D(nn.Module): # Rotary Positional Embeddings\n",
        "#     def __init__(self, dim, h=224, w=224, base=10000):\n",
        "#         super().__init__()\n",
        "#         self.dim, self.h, self.w = dim, h, w\n",
        "#         # # theta = 1. / (base ** (torch.arange(0, dim, step=4) / dim))\n",
        "#         # theta = 1. / (base**torch.linspace(0,1,dim//4)).unsqueeze(0)\n",
        "#         theta = 1. / (base**torch.linspace(0,1,dim//2)).unsqueeze(0)\n",
        "#         y, x = torch.meshgrid(torch.arange(h), torch.arange(w), indexing=\"ij\") # print(y,x) # [h,w], y:row_num, x:col_num\n",
        "#         y, x = (y.reshape(-1,1) * theta).unsqueeze(-1), (x.reshape(-1,1) * theta).unsqueeze(-1) # [h*w,1]*[1,dim//4] = [h*w, dim//4, 1]\n",
        "#         # # self.rot_emb = torch.cat([x.sin(), x.cos(), y.sin(), y.cos()], dim=-1).flatten(-2) # [h*w, dim//4 ,4] -> [h*w, dim]\n",
        "#         # self.rot_emb = torch.cat([x.sin(), x.cos(), y.sin(), y.cos()], dim=-1).reshape(h, w, dim).to(device) # [h*w, dim//4 ,4] -> [h, w, dim]\n",
        "#         self.rot_emb = torch.cat([x.sin(), y.sin()], dim=-1).reshape(h, w, dim).to(device) # [h*w, dim//4 ,4] -> [h, w, dim]\n",
        "#         # self.rot_emb = torch.cat([x.cos(), y.cos()], dim=-1).reshape(h, w, dim).to(device) # [h*w, dim//4 ,4] -> [h, w, dim]\n",
        "\n",
        "#     def forward(self, img): #\n",
        "#         # batch, dim, h, w = img.shape\n",
        "#         # print(img.shape)\n",
        "#         hw = img.shape[1] # [b, hw, dim] / [b, hw, n_heads, d_head]\n",
        "#         h=w=int(hw**.5)\n",
        "#         if self.h < h or self.w < w: self.__init__(self.dim, h, w)\n",
        "#         # print(self.rot_emb.shape)\n",
        "#         # rot_emb = self.rot_emb[:, :h, :w].unsqueeze(0) # [1, h, w, dim]\n",
        "#         rot_emb = self.rot_emb[:h, :w] # [h, w, dim]\n",
        "#         # return img * rot_emb.flatten(end_dim=1).unsqueeze(0) # [b, hw, dim] * [1, hw, dim]\n",
        "#         return img * rot_emb.flatten(end_dim=1)[None,:,None,:] # [b, hw, n_heads, d_head] * [1, hw, 1, dim]\n",
        "#         # return img * self.rot_emb\n",
        "\n",
        "class RotEmb(nn.Module): # Rotary Positional Embeddings\n",
        "    def __init__(self, dim, top=torch.pi, base=10000):\n",
        "        super().__init__()\n",
        "        self.theta = top / (base ** (torch.arange(0, dim, step=2, device=device) / dim))\n",
        "        # self.theta = top / (base ** torch.linspace(0, 1, dim//2, device=device))\n",
        "\n",
        "    def forward(self, pos): # [batch] in [0,1]\n",
        "        angles = (pos.unsqueeze(-1) * self.theta).unsqueeze(-1) # [seq_len, 1] * [dim // 2] -> [seq_len, dim // 2, 1]\n",
        "        rot_emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1) # [seq_len, dim // 2, 2]\n",
        "        return rot_emb.flatten(-2) # [seq_len, dim]\n"
      ],
      "metadata": {
        "id": "ge36SCxOl2Oq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# @title test multiblock params\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(train_data)\n",
        "img,y = next(dataiter)\n",
        "img = img.unsqueeze(0)\n",
        "img = F.interpolate(img, (8,8))\n",
        "b,c,h,w = img.shape\n",
        "# img = img.flatten(2).transpose(-2,-1).to(torch.bfloat16) # [b,c,h,w] -> [b,h*w,c]\n",
        "print(img.shape)\n",
        "# batch, seq,_ = img.shape\n",
        "\n",
        "\n",
        "# # target_mask = randpatch(seq, mask_size=8, gamma=.9) # 8.9 [seq]\n",
        "# target_mask = multiblock(seq, min_s=0.2, max_s=0.3, M=4).any(0) # best.2.3M4 og.15.2M4# mask out targets to be predicted # [M, seq]\n",
        "# target_mask = multiblock(seq, min_s=0.2, max_s=0.3, M=4).any(0)\n",
        "\n",
        "target_mask = multiblock2d((8,8), M=4).any(0).unsqueeze(0)\n",
        "\n",
        "\n",
        "# context_mask = ~multiblock(seq, min_s=0.85, max_s=1., M=1)|target_mask # [1, seq], True->Mask\n",
        "context_mask = ~multiblock2d((8,8), scale=(.85,.85), aspect_ratio=(.9,1.1), M=1)|target_mask # [1, seq], True->Mask\n",
        "\n",
        "# print(target_mask, context_mask)\n",
        "\n",
        "print(target_mask.shape, context_mask.shape)\n",
        "# target_img, context_img = img*target_mask.unsqueeze(-1), img*context_mask.unsqueeze(-1)\n",
        "# target_img, context_img = img*~target_mask.unsqueeze(-1), img*~context_mask.unsqueeze(-1)\n",
        "target_img, context_img = img*~target_mask.unsqueeze(0), img*~context_mask.unsqueeze(0)\n",
        "# print(target_img.shape, context_img.shape)\n",
        "target_img, context_img = target_img.transpose(-2,-1).reshape(b,c,h,w), context_img.transpose(-2,-1).reshape(b,c,h,w)\n",
        "target_img, context_img = target_img.float(), context_img.float()\n",
        "\n",
        "# imshow(out.detach().cpu())\n",
        "imshow(target_img[0])\n",
        "imshow(context_img[0])\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3bpiybH7M0O1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "3d5e3a1a-7e09-4033-a6ad-5e68f9844da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 8, 8])\n",
            "torch.Size([1, 8, 8]) torch.Size([1, 8, 8])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ViT me more\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def zero_module(module):\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "# class LayerNorm2d(nn.LayerNorm):\n",
        "class LayerNorm2d(nn.RMSNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = super().forward(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads=None, d_head=8, cond_dim=None, dropout=0.): # .1\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_head = d_head\n",
        "        self.n_heads = d_model // d_head\n",
        "        # self.d_head = d_model // n_heads\n",
        "        self.cond_dim = cond_dim\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.kv = nn.Linear(cond_dim or d_model, 2*d_model, bias=False)\n",
        "        # self.k = nn.Sequential(nn.Dropout(dropout), nn.Linear(cond_dim, d_model, bias=False))\n",
        "        self.lin = nn.Linear(d_model, d_model)\n",
        "        # self.lin = zero_module(nn.Linear(d_model, d_model))\n",
        "        # self.lin = nn.Sequential(nn.Dropout(dropout), zero_module(nn.Linear(d_model, d_model)))\n",
        "        self.drop = nn.Dropout(dropout) # indp before q,k,v; after linout\n",
        "        self.scale = self.d_head ** -.5\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [batch, T, d_model]=[batch, h*w, c], [batch, num_tok, cond_dim], [batch,T]\n",
        "        if self.cond_dim==None: cond=x # is self attn\n",
        "        Q = self.q(x).unflatten(-1, (self.n_heads, self.d_head)).transpose(1, 2) # [batch, T, d_model] -> [batch, n_heads, T, d_head]\n",
        "        # K = self.k(x).unflatten(-1, (self.n_heads, self.d_head)).transpose(1, 2)\n",
        "        K, V = self.kv(cond).unflatten(-1, (self.n_heads, 2*self.d_head)).transpose(1, 2).chunk(2, dim=-1) # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # # linear attention # Softmax(Q) @ (Softmax(K).T @ V)\n",
        "        if mask != None:\n",
        "            mask = mask[:, None, :, None] # [batch,T] -> [batch,1,T,1]\n",
        "            K, V = K.masked_fill(mask, -torch.finfo(x.dtype).max), V.masked_fill(mask, -torch.finfo(x.dtype).max)\n",
        "        Q, K = Q.softmax(dim=-1)*self.scale, K.softmax(dim=-2)\n",
        "        context = K.transpose(-2,-1) @ V # [batch, n_heads, d_head, d_head]\n",
        "        out = Q @ context # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # # (quadratic) attention # Softmax(Q @ K.T) @ V\n",
        "        # attn = Q @ K.transpose(-2,-1) * self.scale # [batch, n_heads, T] # [batch, n_heads, T, T/num_tok]\n",
        "        # if mask != None: attn = attn.masked_fill(mask[:, None, :, None], -torch.finfo(attn.dtype).max) # [batch,T]->[batch,1,T,1]\n",
        "        # attention = torch.softmax(attn, dim=-1)\n",
        "        # out = self.drop(attention) @ V # [batch, n_heads, T, d_head]\n",
        "\n",
        "        out = out.transpose(1, 2).flatten(2)\n",
        "        return self.drop(self.lin(out)) # [batch, T, d_model]\n",
        "\n",
        "# if self, dont pass cond_dim in init, dont pass cond in fwd\n",
        "# Softmax(Q @ K.T) @ V ~ Softmax(Q) @ Softmax(K).T @ V\n",
        "\n",
        "# https://github.com/lucidrains/x-transformers/blob/main/x_transformers/x_transformers.py#L1855\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, d_head, cond_dim=None, mult=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.norm = nn.RMSNorm(d_model) # LayerNorm RMSNorm\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.cond_dim = cond_dim\n",
        "        self.self = MultiHeadAttention(d_model, d_head=d_head, dropout=0) # 16448\n",
        "        # self.self = Pooling()\n",
        "        act = nn.GELU() # ReLU GELU\n",
        "        # self.ff = nn.Sequential(\n",
        "        #     *[nn.BatchNorm2d(d_model), act, SeparableConv2d(d_model, d_model),]*3\n",
        "        #     )\n",
        "        # self.ff = ResBlock(d_model) # 74112\n",
        "        # self.ff = UIB(d_model, mult=4) # uib m4 36992, m2 18944\n",
        "        ff_dim=d_model*mult\n",
        "        self.ff = nn.Sequential(\n",
        "            # nn.RMSNorm(d_model), nn.Dropout(dropout), nn.Linear(d_model, ff_dim), act, # ReLU GELU\n",
        "            # nn.RMSNorm(d_model), nn.Dropout(dropout), zero_module(nn.Linear(ff_dim, d_model))\n",
        "            nn.RMSNorm(d_model), act, nn.Dropout(dropout), nn.Linear(d_model, ff_dim),\n",
        "            nn.RMSNorm(ff_dim), act, nn.Dropout(dropout), zero_module(nn.Linear(ff_dim, d_model))\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [b,c,h,w], [batch, num_tok, cond_dim], [batch,T]\n",
        "        bchw = x.shape\n",
        "        # x = x.flatten(2).transpose(1,2) # [b,h*w,c]\n",
        "        # print('attnblk fwd',x.shape)\n",
        "\n",
        "        # if self.cond_dim==None: cond=None # is self attn\n",
        "        x = x + self.drop(self.self(self.norm(x)))\n",
        "        # x = x.transpose(1,2).reshape(*bchw)\n",
        "        x = x + self.ff(x)\n",
        "        # x = self.ff(x)\n",
        "        # x = x + self.drop(self.norm2(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "import torch\n",
        "# def apply_masks(x, masks): # [b,t,d], [M,mask_size] # https://github.com/facebookresearch/ijepa/blob/main/src/masks/utils.py\n",
        "#     all_x = []\n",
        "#     for m in masks: # [1,T]\n",
        "#         mask_keep = m.unsqueeze(-1).repeat(1, 1, x.size(-1)) # [1,T,dim]\n",
        "#         all_x += [torch.gather(x, dim=1, index=mask_keep)] # M * [batch,mask_size,dim]\n",
        "#     return torch.cat(all_x, dim=0)  # [M*batch,mask_size,dim]\n",
        "\n",
        "def apply_masks(x, mask): # [b,t,d], [mask_size] # https://github.com/facebookresearch/ijepa/blob/main/src/masks/utils.py\n",
        "    mask_keep = mask.unsqueeze(-1).repeat(1, 1, x.size(-1)) # [1,T,dim]\n",
        "    # return torch.cat(torch.gather(x, dim=1, index=mask_keep), dim=0)  # [M*batch,mask_size,dim]\n",
        "    return torch.gather(x, dim=1, index=mask_keep) # [M*batch,mask_size,dim]\n",
        "\n",
        "\n",
        "class TransformerPredictor(nn.Module):\n",
        "    # def __init__(self, in_dim, d_model, out_dim=None, nhead=8, d_hid=None, nlayers=1, dropout = 0.):\n",
        "    def __init__(self, in_dim, d_model, out_dim=None, d_head=4, d_hid=None, nlayers=1, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Linear(in_dim, d_model)# if in_dim != d_model else None\n",
        "        # self.pos_encoder = RotEmb(d_model, top=1, base=10000)\n",
        "        self.positional_emb = nn.Parameter(torch.zeros(1, 8*8, d_model)) # positional_embedding == 'learnable'\n",
        "        # self.positional_emb = nn.Parameter(torch.zeros(1, dim, 8,8))\n",
        "        self.transformer_encoder = nn.Sequential(*[AttentionBlock(d_model, d_head=d_head) for _ in range(nlayers)])\n",
        "\n",
        "        self.cls = nn.Parameter(torch.zeros(1,1,d_model)) # randn zeros\n",
        "        nn.init.trunc_normal_(self.cls, std=.02)\n",
        "        out_dim = out_dim or d_model\n",
        "        self.norm = nn.RMSNorm(d_model)\n",
        "        self.lin = nn.Linear(d_model, out_dim)# if out_dim != d_model else None\n",
        "\n",
        "    def forward(self, x, context_indices, trg_indices): # [batch, seq_len, d_model], [batch, seq_len] # True will be ignored by the attention # https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "        x = self.embed(x) # [batch, seq_len, d_model] or [batch, num_context_toks, d_model]\n",
        "        batch, seq, dim = x.shape\n",
        "        # x = x * self.pos_encoder(context_indices)\n",
        "        x = x + self.positional_emb[:,context_indices]\n",
        "        # x = apply_masks(x, [context_indices])\n",
        "\n",
        "        # pred_tokens = self.cls * self.pos_encoder(trg_indices) # [M, num_trg_toks, d_model]\n",
        "        pred_tokens = self.cls + self.positional_emb[0,trg_indices]\n",
        "        print(self.cls.shape, self.positional_emb[0,trg_indices].shape, trg_indices.shape)\n",
        "        pred_tokens = pred_tokens.repeat(batch, 1, 1) # [batch*M, num_trg_toks, d_model]\n",
        "        # print(pred_tokens.requires_grad)\n",
        "        print(\"pred fwd\", x.shape, pred_tokens.shape)\n",
        "        # x = x.repeat_interleave(trg_indices.shape[0], dim=0) # [batch, seq_len, d_model] -> [batch*M, seq_len, d_model]\n",
        "        x = torch.cat([x, pred_tokens], dim=1) # [batch*M, seq_len+num_trg_toks, d_model]\n",
        "\n",
        "        # x = x.transpose(1,2).unflatten(-1, (8,8))#.reshape(*bchw)\n",
        "        out = self.transformer_encoder(x) # float [seq_len, batch_size, d_model]\n",
        "        # x = x.flatten(2).transpose(1,2) # [b,h*w,c]\n",
        "\n",
        "        out = self.norm(out)\n",
        "        out = out[:,seq:] # [batch*M, num_trg_toks, d_model]\n",
        "        out = self.lin(out)\n",
        "        return out # [seq_len, batch_size, ntoken]\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    # def __init__(self, in_dim, d_model, out_dim=None, nhead=8, d_hid=None, nlayers=1, dropout = 0.):\n",
        "    def __init__(self, in_dim, d_model, out_dim=None, d_head=4, d_hid=None, nlayers=1, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Sequential(\n",
        "            # # nn.Conv1d(in_dim, d_model,7,2,7//2), nn.MaxPool1d(2,2), #nn.MaxPool1d(3, 2, 3//2),\n",
        "            # # nn.Conv1d(in_dim, d_model,3,2,3//2), nn.BatchNorm1d(d_model), nn.ReLU(), nn.Conv1d(d_model, d_model,3,2,3//2)\n",
        "            # nn.Conv1d(in_dim, d_model,3,2,3//2), nn.BatchNorm1d(d_model), nn.ReLU(), nn.MaxPool1d(2,2),\n",
        "            # nn.Conv1d(d_model, d_model,3,2,3//2), nn.BatchNorm1d(d_model), nn.ReLU(), nn.MaxPool1d(2,2),\n",
        "            # nn.Conv1d(d_model, d_model,3,2,3//2),\n",
        "            # # nn.Conv1d(in_dim, d_model,2,2,0), # like patch\n",
        "            nn.Conv2d(in_dim, d_model, kernel_size=7, stride=2, padding=7//2, bias=False), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "            )\n",
        "        # self.pos_encoder = RotEmb(d_model, top=1, base=10000)\n",
        "        self.positional_emb = nn.Parameter(torch.zeros(1, 8*8, d_model)) # positional_embedding == 'learnable'\n",
        "        # self.positional_emb = nn.Parameter(torch.zeros(1, dim, 8,8)) # positional_embedding == 'learnable'\n",
        "        self.transformer_encoder = nn.Sequential(*[AttentionBlock(d_model, d_head=d_head) for _ in range(nlayers)])\n",
        "        self.norm = nn.RMSNorm(d_model)\n",
        "        self.lin = nn.Linear(d_model, out_dim) if out_dim and out_dim != d_model else None\n",
        "\n",
        "    def forward(self, x, context_indices=None): # [batch, num_context_toks, 3], [batch, num_context_toks] # True will be ignored by the attention # https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "        # x = self.embed(x.transpose(-2,-1)).transpose(-2,-1) # [batch, T, d_model]\n",
        "        x = self.embed(x)\n",
        "        # bchw = x.shape\n",
        "        x = x.flatten(2).transpose(1,2) # [b,c,h,w]->[b,h*w,c] # [batch, seq_len, d_model] or [batch, num_context_toks, d_model]\n",
        "\n",
        "        # x = self.pos_encoder(x)\n",
        "        # x = x * self.pos_encoder(torch.arange(seq, device=device)).unsqueeze(0)\n",
        "        # print(x.shape, self.positional_emb.shape)\n",
        "        x = x + self.positional_emb\n",
        "        if context_indices != None:\n",
        "            # x = apply_masks(x, [context_indices])\n",
        "            x = apply_masks(x, context_indices)\n",
        "\n",
        "\n",
        "        # x = x.transpose(1,2).reshape(*bchw)\n",
        "        x = self.transformer_encoder(x) # float [seq_len, batch_size, d_model]\n",
        "        # x = x.flatten(2).transpose(1,2) # [b,h*w,c]\n",
        "        out = self.norm(x)\n",
        "        if self.lin: out = self.lin(out)\n",
        "        return out # [seq_len, batch_size, ntoken]\n",
        "\n",
        "\n",
        "\n",
        "# pos_emb rope < learn < learned\n",
        "# conv > pixel?\n",
        "# droppath not required\n",
        "\n",
        "# norm,act,conv < conv,norm,act\n",
        "# 2*s1 < uib < resblock\n",
        "# gatedadaln 3 < 2 = 1 < ffmult4 = 2*gatedadaln\n",
        "# MaxPool2d(2,2) < MaxPool2d(3,2,3//2)\n",
        "\n",
        "\n",
        "# dim = 64\n",
        "# dim_head = 8\n",
        "# heads = dim // dim_head\n",
        "# num_classes = 10\n",
        "# # model = SimpleViT(image_size=32, patch_size=4, num_classes=num_classes, dim=dim, depth=1, heads=heads, mlp_dim=dim*4, channels = 3, dim_head = dim_head)\n",
        "# model = SimpleViT(in_dim=3, out_dim=num_classes, dim=dim, depth=1, heads=heads, mlp_dim=dim*4, channels = 3, dim_head = dim_head).to(device)\n",
        "# print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 59850\n",
        "# optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "# # print(images.shape) # [batch, 3, 32, 32]\n",
        "# logits = model(x)\n",
        "# print(logits.shape)\n",
        "# # print(logits[0])\n",
        "# # print(logits[0].argmax(1))\n",
        "# pred_probab = nn.Softmax(dim=1)(logits)\n",
        "# y_pred = pred_probab.argmax(1)\n",
        "# # print(f\"Predicted class: {y_pred}\")\n",
        "\n",
        "\n",
        "batch, seq_len, d_model = 4,1024,16\n",
        "in_dim = 3\n",
        "model = TransformerModel(in_dim, d_model, d_head=4, nlayers=2, dropout=0.).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 27584\n",
        "x = torch.rand((batch, in_dim, 32, 32), device=device)\n",
        "# x =  torch.rand((batch, seq_len, in_dim), device=device)\n",
        "out = model(x)\n",
        "print(out.shape)\n",
        "# # # print(out)\n",
        "# model = TransformerPredictor(in_dim, d_model, out_dim=None, d_head=4, d_hid=None, nlayers=1).to(device)\n",
        "# out = model(out)\n",
        "# print(out.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5554e8f3-71ec-4b70-c7d7-219b59e9a1d3",
        "cellView": "form",
        "id": "C1iZQ6UNwoty"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9920\n",
            "torch.Size([4, 64, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title simplex\n",
        "!pip install opensimplex\n",
        "from opensimplex import OpenSimplex\n",
        "\n",
        "seed=0\n",
        "noise = OpenSimplex(seed)  # Replace 'seed' with your starting value\n",
        "noise_scale = 10  # Adjust for desired noise range\n",
        "\n",
        "def get_noise(x, y):\n",
        "    global seed  # Assuming seed is a global variable\n",
        "    # noise_val = noise.noise2(x / noise_scale, y / noise_scale)\n",
        "    noise_val = noise.noise2(x, y)\n",
        "    # seed += 1  # Increment seed after each call\n",
        "    return noise_val\n",
        "\n",
        "x,y=0,0\n",
        "a=[[],[],[],[],[]]\n",
        "\n",
        "fps=2\n",
        "f=[]\n",
        "for i in range(10*fps):\n",
        "    f.append(i/fps)\n",
        "    x = x+0.3\n",
        "    # y = y+1\n",
        "    # noise_value = get_noise(x, y)\n",
        "    for k,j in enumerate([0,1,2,3,4]):\n",
        "        a[k].append(get_noise(x, y+j))\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "for aa in a:\n",
        "    plt.plot(f,aa)\n",
        "plt.show()\n",
        "\n",
        "# b,y,g,"
      ],
      "metadata": {
        "id": "e3dAhWh45F4M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title pos_embed.py\n",
        "# https://github.com/facebookresearch/mae/blob/main/util/pos_embed.py#L20\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def get_2d_sincos_pos_embed(embed_dim=16, grid_size=8, cls_token=False): #\n",
        "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
        "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
        "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
        "    grid = np.stack(grid, axis=0)\n",
        "\n",
        "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token: pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
        "    return pos_embed # [(1+)grid_size*grid_size, embed_dim]\n",
        "\n",
        "\n",
        "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
        "    # assert embed_dim % 2 == 0\n",
        "\n",
        "    # use half of dimensions to encode grid_h\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
        "\n",
        "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos): #\n",
        "    \"\"\"\n",
        "    embed_dim: output dimension for each position\n",
        "    pos: a list of positions to be encoded: size (M,)\n",
        "    out: (M, D)\n",
        "    \"\"\"\n",
        "    assert embed_dim % 2 == 0\n",
        "    omega = np.arange(embed_dim // 2, dtype=float)\n",
        "    omega /= embed_dim / 2.\n",
        "    omega = 1. / 10000**omega  # (D/2,)\n",
        "\n",
        "    pos = pos.reshape(-1)  # (M,)\n",
        "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
        "\n",
        "    emb_sin = np.sin(out) # (M, D/2)\n",
        "    emb_cos = np.cos(out) # (M, D/2)\n",
        "\n",
        "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def interpolate_pos_embed(model, checkpoint_model):\n",
        "    if 'pos_embed' in checkpoint_model:\n",
        "        pos_embed_checkpoint = checkpoint_model['pos_embed']\n",
        "        embedding_size = pos_embed_checkpoint.shape[-1]\n",
        "        num_patches = model.patch_embed.num_patches\n",
        "        num_extra_tokens = model.pos_embed.shape[-2] - num_patches\n",
        "        # height (== width) for the checkpoint position embedding\n",
        "        orig_size = int((pos_embed_checkpoint.shape[-2] - num_extra_tokens) ** 0.5)\n",
        "        # height (== width) for the new position embedding\n",
        "        new_size = int(num_patches ** 0.5)\n",
        "        # class_token and dist_token are kept unchanged\n",
        "        if orig_size != new_size:\n",
        "            print(\"Position interpolate from %dx%d to %dx%d\" % (orig_size, orig_size, new_size, new_size))\n",
        "            extra_tokens = pos_embed_checkpoint[:, :num_extra_tokens]\n",
        "            # only the position tokens are interpolated\n",
        "            pos_tokens = pos_embed_checkpoint[:, num_extra_tokens:]\n",
        "            pos_tokens = pos_tokens.reshape(-1, orig_size, orig_size, embedding_size).permute(0, 3, 1, 2)\n",
        "            pos_tokens = torch.nn.functional.interpolate(\n",
        "                pos_tokens, size=(new_size, new_size), mode='bicubic', align_corners=False)\n",
        "            pos_tokens = pos_tokens.permute(0, 2, 3, 1).flatten(1, 2)\n",
        "            new_pos_embed = torch.cat((extra_tokens, pos_tokens), dim=1)\n",
        "            checkpoint_model['pos_embed'] = new_pos_embed\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vtPSM8mbnJZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ijepa src.utils.tensors\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/utils/tensors.py\n",
        "\n",
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
        "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        "\n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    # type: (Tensor, float, float, float, float) -> Tensor\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
        "\n",
        "def repeat_interleave_batch(x, B, repeat): # [batch*M,...]? , M?\n",
        "    N = len(x) // B\n",
        "    x = torch.cat([\n",
        "        torch.cat([x[i*B:(i+1)*B] for _ in range(repeat)], dim=0)\n",
        "        for i in range(N)\n",
        "    ], dim=0)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "dLbXQ-3XXRMq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ijepa multiblock down\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/masks/multiblock.py\n",
        "import math\n",
        "from multiprocessing import Value\n",
        "import torch\n",
        "_GLOBAL_SEED = 0\n",
        "\n",
        "\n",
        "class MaskCollator(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=(224, 224),\n",
        "        patch_size=16,\n",
        "        enc_mask_scale=(0.2, 0.8),\n",
        "        pred_mask_scale=(0.2, 0.8),\n",
        "        aspect_ratio=(0.3, 3.0),\n",
        "        nenc=1,\n",
        "        npred=2,\n",
        "        min_keep=4,\n",
        "        allow_overlap=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if not isinstance(input_size, tuple):\n",
        "            input_size = (input_size, ) * 2\n",
        "        self.patch_size = patch_size\n",
        "        self.height, self.width = input_size[0] // patch_size, input_size[1] // patch_size\n",
        "        self.enc_mask_scale = enc_mask_scale\n",
        "        self.pred_mask_scale = pred_mask_scale\n",
        "        self.aspect_ratio = aspect_ratio\n",
        "        self.nenc = nenc\n",
        "        self.npred = npred\n",
        "        self.min_keep = min_keep  # minimum number of patches to keep\n",
        "        self.allow_overlap = allow_overlap  # whether to allow overlap b/w enc and pred masks\n",
        "        self._itr_counter = Value('i', -1)  # collator is shared across worker processes\n",
        "\n",
        "    def step(self):\n",
        "        i = self._itr_counter\n",
        "        with i.get_lock():\n",
        "            i.value += 1\n",
        "            v = i.value\n",
        "        return v\n",
        "\n",
        "    def _sample_block_size(self, generator, scale, aspect_ratio_scale):\n",
        "        _rand = torch.rand(1, generator=generator).item()\n",
        "        # -- Sample block scale\n",
        "        min_s, max_s = scale\n",
        "        mask_scale = min_s + _rand * (max_s - min_s)\n",
        "        max_keep = int(self.height * self.width * mask_scale)\n",
        "        # -- Sample block aspect-ratio\n",
        "        min_ar, max_ar = aspect_ratio_scale\n",
        "        aspect_ratio = min_ar + _rand * (max_ar - min_ar)\n",
        "        # -- Compute block height and width (given scale and aspect-ratio)\n",
        "        h = int(round(math.sqrt(max_keep * aspect_ratio)))\n",
        "        w = int(round(math.sqrt(max_keep / aspect_ratio)))\n",
        "        while h >= self.height:\n",
        "            h -= 1\n",
        "        while w >= self.width:\n",
        "            w -= 1\n",
        "        return (h, w)\n",
        "\n",
        "    def _sample_block_mask(self, b_size, acceptable_regions=None):\n",
        "        h, w = b_size\n",
        "\n",
        "        def constrain_mask(mask, tries=0):\n",
        "            \"\"\" Helper to restrict given mask to a set of acceptable regions \"\"\"\n",
        "            N = max(int(len(acceptable_regions)-tries), 0)\n",
        "            for k in range(N):\n",
        "                mask *= acceptable_regions[k]\n",
        "        # --\n",
        "        # -- Loop to sample masks until we find a valid one\n",
        "        tries = 0\n",
        "        timeout = og_timeout = 20\n",
        "        valid_mask = False\n",
        "        while not valid_mask:\n",
        "            # -- Sample block top-left corner\n",
        "            top = torch.randint(0, self.height - h, (1,))\n",
        "            left = torch.randint(0, self.width - w, (1,))\n",
        "            mask = torch.zeros((self.height, self.width), dtype=torch.int32)\n",
        "            mask[top:top+h, left:left+w] = 1\n",
        "            # -- Constrain mask to a set of acceptable regions\n",
        "            if acceptable_regions is not None:\n",
        "                constrain_mask(mask, tries)\n",
        "            mask = torch.nonzero(mask.flatten())\n",
        "            # -- If mask too small try again\n",
        "            valid_mask = len(mask) > self.min_keep\n",
        "            if not valid_mask:\n",
        "                timeout -= 1\n",
        "                if timeout == 0:\n",
        "                    tries += 1\n",
        "                    timeout = og_timeout\n",
        "        mask = mask.squeeze()\n",
        "        # --\n",
        "        mask_complement = torch.ones((self.height, self.width), dtype=torch.int32)\n",
        "        mask_complement[top:top+h, left:left+w] = 0\n",
        "        # --\n",
        "        return mask, mask_complement\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        '''\n",
        "        Create encoder and predictor masks when collating imgs into a batch\n",
        "        # 1. sample enc block (size + location) using seed\n",
        "        # 2. sample pred block (size) using seed\n",
        "        # 3. sample several enc block locations for each image (w/o seed)\n",
        "        # 4. sample several pred block locations for each image (w/o seed)\n",
        "        # 5. return enc mask and pred mask\n",
        "        '''\n",
        "        B = len(batch)\n",
        "\n",
        "        collated_batch = torch.utils.data.default_collate(batch)\n",
        "\n",
        "        seed = self.step()\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(seed)\n",
        "        p_size = self._sample_block_size(\n",
        "            generator=g,\n",
        "            scale=self.pred_mask_scale,\n",
        "            aspect_ratio_scale=self.aspect_ratio)\n",
        "        e_size = self._sample_block_size(\n",
        "            generator=g,\n",
        "            scale=self.enc_mask_scale,\n",
        "            aspect_ratio_scale=(1., 1.))\n",
        "\n",
        "        collated_masks_pred, collated_masks_enc = [], []\n",
        "        min_keep_pred = self.height * self.width\n",
        "        min_keep_enc = self.height * self.width\n",
        "        for _ in range(B):\n",
        "\n",
        "            masks_p, masks_C = [], []\n",
        "            for _ in range(self.npred):\n",
        "                mask, mask_C = self._sample_block_mask(p_size)\n",
        "                masks_p.append(mask)\n",
        "                masks_C.append(mask_C)\n",
        "                min_keep_pred = min(min_keep_pred, len(mask))\n",
        "            collated_masks_pred.append(masks_p)\n",
        "\n",
        "            acceptable_regions = masks_C\n",
        "            try:\n",
        "                if self.allow_overlap:\n",
        "                    acceptable_regions= None\n",
        "            except Exception as e:\n",
        "                print(f'Encountered exception in mask-generator {e}')\n",
        "\n",
        "            masks_e = []\n",
        "            for _ in range(self.nenc):\n",
        "                mask, _ = self._sample_block_mask(e_size, acceptable_regions=acceptable_regions)\n",
        "                masks_e.append(mask)\n",
        "                min_keep_enc = min(min_keep_enc, len(mask))\n",
        "            collated_masks_enc.append(masks_e)\n",
        "        collated_masks_pred = [[cm[:min_keep_pred] for cm in cm_list] for cm_list in collated_masks_pred]\n",
        "        collated_masks_pred = torch.utils.data.default_collate(collated_masks_pred)\n",
        "        # --\n",
        "        collated_masks_enc = [[cm[:min_keep_enc] for cm in cm_list] for cm_list in collated_masks_enc]\n",
        "        collated_masks_enc = torch.utils.data.default_collate(collated_masks_enc)\n",
        "        return collated_batch, collated_masks_enc, collated_masks_pred\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "COvEnBXPYth3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH1UOD4WW8I2",
        "outputId": "e8671cd3-eba7-4649-84ca-94c6467ce62d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Mask generator says: \"Valid mask not found, decreasing acceptable-regions [1]\"\n",
            "WARNING:root:Mask generator says: \"Valid mask not found, decreasing acceptable-regions [2]\"\n",
            "WARNING:root:Mask generator says: \"Valid mask not found, decreasing acceptable-regions [3]\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vit fwd torch.Size([4, 3, 224, 224])\n",
            "vit fwd torch.Size([4, 196, 768])\n",
            "vit fwd torch.Size([4, 11, 768])\n",
            "predictor fwd1 torch.Size([4, 11, 384]) torch.Size([4, 196, 384])\n"
          ]
        }
      ],
      "source": [
        "# @title ijepa vision_transformer.py\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/models/vision_transformer.py\n",
        "import math\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# from src.utils.tensors import (trunc_normal_, repeat_interleave_batch)\n",
        "\n",
        "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid height and width\n",
        "    return:\n",
        "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
        "    \"\"\"\n",
        "    grid_h = np.arange(grid_size, dtype=float)\n",
        "    grid_w = np.arange(grid_size, dtype=float)\n",
        "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
        "    grid = np.stack(grid, axis=0)\n",
        "\n",
        "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token:\n",
        "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0) # [1+h*w, dim]\n",
        "    return pos_embed\n",
        "\n",
        "\n",
        "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
        "    assert embed_dim % 2 == 0\n",
        "    # use half of dimensions to encode grid_h\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
        "    emb = np.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def get_1d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid length\n",
        "    return:\n",
        "    pos_embed: [grid_size, embed_dim] or [1+grid_size, embed_dim] (w/ or w/o cls_token)\n",
        "    \"\"\"\n",
        "    grid = np.arange(grid_size, dtype=float)\n",
        "    pos_embed = get_1d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token:\n",
        "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
        "    return pos_embed\n",
        "\n",
        "\n",
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
        "    \"\"\"\n",
        "    embed_dim: output dimension for each position\n",
        "    pos: a list of positions to be encoded: size (M,)\n",
        "    out: (M, D)\n",
        "    \"\"\"\n",
        "    assert embed_dim % 2 == 0\n",
        "    omega = np.arange(embed_dim // 2, dtype=float)\n",
        "    omega /= embed_dim / 2.\n",
        "    omega = 1. / 10000**omega   # (D/2,)\n",
        "    pos = pos.reshape(-1)   # (M,)\n",
        "    out = np.einsum('m,d->md', pos, omega)   # (M, D/2), outer product\n",
        "    emb = np.concatenate([np.sin(out), np.cos(out)], axis=1)  # (M, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()  # binarize\n",
        "    output = x.div(keep_prob) * random_tensor\n",
        "    return output\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x, attn\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = MLP(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, x, return_attention=False):\n",
        "        y, attn = self.attn(self.norm1(x))\n",
        "        if return_attention:\n",
        "            return attn\n",
        "        x = x + self.drop_path(y)\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        num_patches = (img_size // patch_size) * (img_size // patch_size)\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2) # ->[b,h*w,c]\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvEmbed(nn.Module):\n",
        "    \"\"\"3x3 Convolution stems for ViT following ViTC models\"\"\"\n",
        "    def __init__(self, channels, strides, img_size=224, in_chans=3, batch_norm=True):\n",
        "        super().__init__()\n",
        "        # Build the stems\n",
        "        stem = []\n",
        "        channels = [in_chans] + channels\n",
        "        for i in range(len(channels) - 2):\n",
        "            stem += [nn.Conv2d(channels[i], channels[i+1], kernel_size=3, stride=strides[i], padding=1, bias=(not batch_norm))]\n",
        "            if batch_norm:\n",
        "                stem += [nn.BatchNorm2d(channels[i+1])]\n",
        "            stem += [nn.ReLU(inplace=True)]\n",
        "        stem += [nn.Conv2d(channels[-2], channels[-1], kernel_size=1, stride=strides[-1])]\n",
        "        self.stem = nn.Sequential(*stem)\n",
        "\n",
        "        # Comptute the number of patches\n",
        "        stride_prod = int(np.prod(strides))\n",
        "        self.num_patches = (img_size[0] // stride_prod)**2\n",
        "\n",
        "    def forward(self, x):\n",
        "        p = self.stem(x)\n",
        "        return p.flatten(2).transpose(1, 2)\n",
        "\n",
        "\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/masks/utils.py\n",
        "def apply_masks(x, masks):\n",
        "    \"\"\":param x: tensor of shape [B (batch-size), N (num-patches), D (feature-dim)]\n",
        "    :param masks: list of tensors containing indices of patches in [N] to keep\"\"\"\n",
        "    all_x = []\n",
        "    for m in masks:\n",
        "        mask_keep = m.unsqueeze(-1).repeat(1, 1, x.size(-1)) # [batch,T,dim]\n",
        "        all_x += [torch.gather(x, dim=1, index=mask_keep)] # M * [batch,mask_size,dim]\n",
        "    return torch.cat(all_x, dim=0)  # [M*batch,mask_size,dim]\n",
        "\n",
        "\n",
        "class VisionTransformerPredictor(nn.Module):\n",
        "    \"\"\" Vision Transformer \"\"\"\n",
        "    def __init__(self, num_patches, embed_dim=768, predictor_embed_dim=384,\n",
        "        depth=6, num_heads=12, drop_rate=0.0, drop_path_rate=0.0, init_std=0.02, **kwargs):\n",
        "        super().__init__()\n",
        "        self.init_std = init_std\n",
        "        self.predictor_embed = nn.Linear(embed_dim, predictor_embed_dim, bias=True)\n",
        "        self.mask_token = nn.Parameter(torch.zeros(1, 1, predictor_embed_dim))\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
        "        # --\n",
        "        self.predictor_pos_embed = nn.Parameter(torch.zeros(1, num_patches, predictor_embed_dim), requires_grad=False)\n",
        "        predictor_pos_embed = get_2d_sincos_pos_embed(self.predictor_pos_embed.shape[-1], int(num_patches**.5), cls_token=False)\n",
        "        self.predictor_pos_embed.data.copy_(torch.from_numpy(predictor_pos_embed).float().unsqueeze(0)) # [1, num_patches, predictor_embed_dim]\n",
        "        # --\n",
        "        self.predictor_blocks = nn.ModuleList([Block(dim=predictor_embed_dim, num_heads=num_heads, drop=drop_rate, drop_path=dpr[i]) for i in range(depth)])\n",
        "        self.predictor_norm = nn.LayerNorm(predictor_embed_dim)\n",
        "        self.predictor_proj = nn.Linear(predictor_embed_dim, embed_dim, bias=True)\n",
        "        # ------\n",
        "        # trunc_normal_(self.mask_token, std=self.init_std)\n",
        "\n",
        "    def forward(self, x, masks_x, masks): # [batch, num_context_patches, embed_dim], nenc*[batch, num_context_patches], npred*[batch, num_target_patches]\n",
        "        assert (masks is not None) and (masks_x is not None), 'Cannot run predictor without mask indices'\n",
        "        if not isinstance(masks_x, list): masks_x = [masks_x] # context mask\n",
        "        if not isinstance(masks, list): masks = [masks] # pred mask\n",
        "\n",
        "        # -- Batch Size\n",
        "        B = len(x) // len(masks_x)\n",
        "        # print(\"predictor fwd0\", x.shape) # [3, 121, 768])\n",
        "        # -- map from encoder-dim to pedictor-dim\n",
        "        x = self.predictor_embed(x) # [batch, num_patches, predictor_embed_dim]\n",
        "\n",
        "        # -- add positional embedding to x tokens\n",
        "        x_pos_embed = self.predictor_pos_embed.repeat(B, 1, 1) # [batch, num_patches, predictor_embed_dim]\n",
        "        print(\"predictor fwd1\", x.shape, x_pos_embed.shape) # [3, 121 or 11, 384], [3, 196, 384]\n",
        "        # print(\"predictor fwd masks_x\", masks_x)\n",
        "        x += apply_masks(x_pos_embed, masks_x) # get pos emb of context patches\n",
        "\n",
        "        # print(\"predictor fwd x\", x.shape) # [4, 11, 384])\n",
        "        _, N_ctxt, D = x.shape\n",
        "\n",
        "        # -- concat mask tokens to x\n",
        "        pos_embs = self.predictor_pos_embed.repeat(B, 1, 1) # [batch, num_patches, predictor_embed_dim]\n",
        "        pos_embs = apply_masks(pos_embs, masks) # [16, 104, predictor_embed_dim]\n",
        "        pos_embs = repeat_interleave_batch(pos_embs, B, repeat=len(masks_x)) # [16, 104, predictor_embed_dim]\n",
        "        # --\n",
        "        pred_tokens = self.mask_token.repeat(pos_embs.size(0), pos_embs.size(1), 1) # [16, 104, predictor_embed_dim]\n",
        "        # --\n",
        "        # print(\"predictor fwd pred_tokens\", pred_tokens.shape)\n",
        "\n",
        "        pred_tokens += pos_embs\n",
        "        x = x.repeat(len(masks), 1, 1)\n",
        "        x = torch.cat([x, pred_tokens], dim=1)\n",
        "\n",
        "        # -- fwd prop\n",
        "        for blk in self.predictor_blocks:\n",
        "            x = blk(x)\n",
        "        x = self.predictor_norm(x)\n",
        "\n",
        "        # -- return preds for mask tokens\n",
        "        x = x[:, N_ctxt:]\n",
        "        x = self.predictor_proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    \"\"\" Vision Transformer \"\"\"\n",
        "    def __init__(self, img_size=[224], patch_size=16, in_chans=3, embed_dim=768, predictor_embed_dim=384, depth=12, predictor_depth=12,\n",
        "        num_heads=12, mlp_ratio=4.0, qkv_bias=True, qk_scale=None, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, norm_layer=nn.LayerNorm, init_std=0.02, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_features = self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.init_std = init_std\n",
        "        # --\n",
        "        self.patch_embed = PatchEmbed(img_size=img_size[0], patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        # --\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim), requires_grad=False)\n",
        "        pos_embed = get_2d_sincos_pos_embed(self.pos_embed.shape[-1], int(self.patch_embed.num_patches**.5), cls_token=False)\n",
        "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
        "        # --\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
        "            for i in range(depth)])\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "    def forward(self, x, masks=None): # [batch,3,224,224]\n",
        "        if masks is not None:\n",
        "            if not isinstance(masks, list): masks = [masks]\n",
        "\n",
        "        print(\"vit fwd\", x.shape)\n",
        "        x = self.patch_embed(x)\n",
        "        B, N, D = x.shape # [batch, num_patches, embed_dim]\n",
        "\n",
        "        print(\"vit fwd\", x.shape)\n",
        "        # -- add positional embedding to x\n",
        "        pos_embed = self.interpolate_pos_encoding(x, self.pos_embed)\n",
        "        x = x + pos_embed\n",
        "\n",
        "        if masks is not None: x = apply_masks(x, masks) # [batch, num_context_patches, embed_dim]\n",
        "\n",
        "        print(\"vit fwd\", x.shape)\n",
        "        for i, blk in enumerate(self.blocks):\n",
        "            x = blk(x)\n",
        "\n",
        "        if self.norm is not None: x = self.norm(x)\n",
        "        return x # [batch, num_context_patches, embed_dim]\n",
        "\n",
        "    def interpolate_pos_encoding(self, x, pos_embed):\n",
        "        npatch = x.shape[1] - 1\n",
        "        N = pos_embed.shape[1] - 1\n",
        "        if npatch == N: return pos_embed\n",
        "        class_emb, pos_embed = pos_embed[:, 0], pos_embed[:, 1:]\n",
        "        dim = x.shape[-1]\n",
        "        pos_embed = nn.functional.interpolate(pos_embed.reshape(1, int(math.sqrt(N)), int(math.sqrt(N)), dim).permute(0, 3, 1, 2), scale_factor=math.sqrt(npatch / N), mode='bicubic',)\n",
        "        pos_embed = pos_embed.permute(0, 2, 3, 1).view(1, -1, dim)\n",
        "        return torch.cat((class_emb.unsqueeze(0), pos_embed), dim=1)\n",
        "\n",
        "# from functools import partial\n",
        "# def vit_predictor(**kwargs):\n",
        "#     model = VisionTransformerPredictor(\n",
        "#         mlp_ratio=4, qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "#     return model\n",
        "\n",
        "def vit(patch_size=16, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=patch_size, embed_dim=192, depth=12, num_heads=3, mlp_ratio=4, # tiny\n",
        "        # patch_size=patch_size, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, # small\n",
        "        # patch_size=patch_size, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, # base\n",
        "        qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    return model\n",
        "\n",
        "# encoder = vit()\n",
        "encoder = VisionTransformer(\n",
        "        patch_size=16, embed_dim=768, depth=1, num_heads=3, mlp_ratio=1,\n",
        "        qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6))\n",
        "\n",
        "# num_patches = (224/patch_size)^2\n",
        "# model = VisionTransformerPredictor(num_patches, embed_dim=768, predictor_embed_dim=384, depth=6, num_heads=12, drop_rate=0.0, drop_path_rate=0.0, init_std=0.02, **kwargs)\n",
        "model = VisionTransformerPredictor(num_patches=196, embed_dim=768, predictor_embed_dim=384, depth=1, num_heads=12, drop_rate=0.0, drop_path_rate=0.0, init_std=0.02)\n",
        "\n",
        "batch = 4\n",
        "img = torch.rand(batch, 3, 224, 224)\n",
        "\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/train.py\n",
        "mask_collator = MaskCollator(\n",
        "        input_size=(224, 224),\n",
        "        patch_size=16,\n",
        "        enc_mask_scale=(0.2, 0.8),\n",
        "        pred_mask_scale=(0.2, 0.8),\n",
        "        aspect_ratio=(0.3, 3.0),\n",
        "        nenc=1,\n",
        "        npred=4,\n",
        "        min_keep=4,\n",
        "        # allow_overlap=True)\n",
        "        allow_overlap=False)\n",
        "# self.height, self.width = input_size[0] // patch_size, input_size[1] // patch_size\n",
        "\n",
        "\n",
        "\n",
        "# v = mask_collator.step()\n",
        "# should pass the collater a list batch of idx?\n",
        "# collated_batch, collated_masks_enc, collated_masks_pred = mask_collator([batch,3,8])\n",
        "collated_batch, collated_masks_enc, collated_masks_pred = mask_collator([0,1,2,3])\n",
        "# print(v)\n",
        "\n",
        "\n",
        "def forward_target():\n",
        "    with torch.no_grad():\n",
        "        h = target_encoder(imgs)\n",
        "        h = F.layer_norm(h, (h.size(-1),))  # normalize over feature-dim\n",
        "        B = len(h)\n",
        "        # -- create targets (masked regions of h)\n",
        "        h = apply_masks(h, masks_pred)\n",
        "        h = repeat_interleave_batch(h, B, repeat=len(masks_enc))\n",
        "        return h\n",
        "\n",
        "def forward_context():\n",
        "    z = encoder(imgs, masks_enc)\n",
        "    z = predictor(z, masks_enc, masks_pred)\n",
        "    return z\n",
        "\n",
        "# # num_context_patches = 121 if allow_overlap=True else 11\n",
        "z = encoder(img, collated_masks_enc) # [batch, num_context_patches, embed_dim]\n",
        "# print(len(collated_masks_enc), len(collated_masks_pred)) # nenc, npred\n",
        "# print(collated_masks_enc[0].shape, collated_masks_pred[0].shape) # , [batch, num_context_patches = 121 or 11], [batch, num_target_patches]\n",
        "out = model(z, collated_masks_enc, collated_masks_pred)\n",
        "# # print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print(224/16) # 14\n",
        "# print(len(collated_masks_enc), len(collated_masks_pred))\n",
        "print(collated_masks_enc, collated_masks_pred)\n",
        "# multiples of 14\n",
        "\n",
        "# print(collated_masks_pred[1])\n"
      ],
      "metadata": {
        "id": "Or3eQvUVg7l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(collated_masks_enc, collated_masks_pred)"
      ],
      "metadata": {
        "id": "u2mLjXAmXcwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ijepa multiblock.py\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/masks/multiblock.py\n",
        "import math\n",
        "from multiprocessing import Value\n",
        "from logging import getLogger\n",
        "import torch\n",
        "_GLOBAL_SEED = 0\n",
        "logger = getLogger()\n",
        "\n",
        "\n",
        "class MaskCollator(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=(224, 224),\n",
        "        patch_size=16,\n",
        "        enc_mask_scale=(0.2, 0.8),\n",
        "        pred_mask_scale=(0.2, 0.8),\n",
        "        aspect_ratio=(0.3, 3.0),\n",
        "        nenc=1,\n",
        "        npred=2,\n",
        "        min_keep=4,\n",
        "        allow_overlap=False\n",
        "    ):\n",
        "        super(MaskCollator, self).__init__()\n",
        "        if not isinstance(input_size, tuple):\n",
        "            input_size = (input_size, ) * 2\n",
        "        self.patch_size = patch_size\n",
        "        self.height, self.width = input_size[0] // patch_size, input_size[1] // patch_size\n",
        "        self.enc_mask_scale = enc_mask_scale\n",
        "        self.pred_mask_scale = pred_mask_scale\n",
        "        self.aspect_ratio = aspect_ratio\n",
        "        self.nenc = nenc\n",
        "        self.npred = npred\n",
        "        self.min_keep = min_keep  # minimum number of patches to keep\n",
        "        self.allow_overlap = allow_overlap  # whether to allow overlap b/w enc and pred masks\n",
        "        self._itr_counter = Value('i', -1)  # collator is shared across worker processes\n",
        "\n",
        "    def step(self):\n",
        "        i = self._itr_counter\n",
        "        with i.get_lock():\n",
        "            i.value += 1\n",
        "            v = i.value\n",
        "        return v\n",
        "\n",
        "    def _sample_block_size(self, generator, scale, aspect_ratio_scale):\n",
        "        _rand = torch.rand(1, generator=generator).item()\n",
        "        # -- Sample block scale\n",
        "        min_s, max_s = scale\n",
        "        mask_scale = min_s + _rand * (max_s - min_s)\n",
        "        max_keep = int(self.height * self.width * mask_scale)\n",
        "        # -- Sample block aspect-ratio\n",
        "        min_ar, max_ar = aspect_ratio_scale\n",
        "        aspect_ratio = min_ar + _rand * (max_ar - min_ar)\n",
        "        # -- Compute block height and width (given scale and aspect-ratio)\n",
        "        h = int(round(math.sqrt(max_keep * aspect_ratio)))\n",
        "        w = int(round(math.sqrt(max_keep / aspect_ratio)))\n",
        "        while h >= self.height:\n",
        "            h -= 1\n",
        "        while w >= self.width:\n",
        "            w -= 1\n",
        "\n",
        "        return (h, w)\n",
        "\n",
        "    def _sample_block_mask(self, b_size, acceptable_regions=None):\n",
        "        h, w = b_size\n",
        "\n",
        "        def constrain_mask(mask, tries=0):\n",
        "            \"\"\" Helper to restrict given mask to a set of acceptable regions \"\"\"\n",
        "            N = max(int(len(acceptable_regions)-tries), 0)\n",
        "            for k in range(N):\n",
        "                mask *= acceptable_regions[k]\n",
        "        # --\n",
        "        # -- Loop to sample masks until we find a valid one\n",
        "        tries = 0\n",
        "        timeout = og_timeout = 20\n",
        "        valid_mask = False\n",
        "        while not valid_mask:\n",
        "            # -- Sample block top-left corner\n",
        "            top = torch.randint(0, self.height - h, (1,))\n",
        "            left = torch.randint(0, self.width - w, (1,))\n",
        "            mask = torch.zeros((self.height, self.width), dtype=torch.int32)\n",
        "            mask[top:top+h, left:left+w] = 1\n",
        "            # -- Constrain mask to a set of acceptable regions\n",
        "            if acceptable_regions is not None:\n",
        "                constrain_mask(mask, tries)\n",
        "            mask = torch.nonzero(mask.flatten())\n",
        "            # -- If mask too small try again\n",
        "            valid_mask = len(mask) > self.min_keep\n",
        "            if not valid_mask:\n",
        "                timeout -= 1\n",
        "                if timeout == 0:\n",
        "                    tries += 1\n",
        "                    timeout = og_timeout\n",
        "                    logger.warning(f'Mask generator says: \"Valid mask not found, decreasing acceptable-regions [{tries}]\"')\n",
        "        mask = mask.squeeze()\n",
        "        # --\n",
        "        mask_complement = torch.ones((self.height, self.width), dtype=torch.int32)\n",
        "        mask_complement[top:top+h, left:left+w] = 0\n",
        "        # --\n",
        "        return mask, mask_complement\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        '''\n",
        "        Create encoder and predictor masks when collating imgs into a batch\n",
        "        # 1. sample enc block (size + location) using seed\n",
        "        # 2. sample pred block (size) using seed\n",
        "        # 3. sample several enc block locations for each image (w/o seed)\n",
        "        # 4. sample several pred block locations for each image (w/o seed)\n",
        "        # 5. return enc mask and pred mask\n",
        "        '''\n",
        "        B = len(batch)\n",
        "\n",
        "        collated_batch = torch.utils.data.default_collate(batch)\n",
        "\n",
        "        seed = self.step()\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(seed)\n",
        "        p_size = self._sample_block_size(\n",
        "            generator=g,\n",
        "            scale=self.pred_mask_scale,\n",
        "            aspect_ratio_scale=self.aspect_ratio)\n",
        "        e_size = self._sample_block_size(\n",
        "            generator=g,\n",
        "            scale=self.enc_mask_scale,\n",
        "            aspect_ratio_scale=(1., 1.))\n",
        "\n",
        "        collated_masks_pred, collated_masks_enc = [], []\n",
        "        min_keep_pred = self.height * self.width\n",
        "        min_keep_enc = self.height * self.width\n",
        "        for _ in range(B):\n",
        "\n",
        "            masks_p, masks_C = [], []\n",
        "            for _ in range(self.npred):\n",
        "                mask, mask_C = self._sample_block_mask(p_size)\n",
        "                masks_p.append(mask)\n",
        "                masks_C.append(mask_C)\n",
        "                min_keep_pred = min(min_keep_pred, len(mask))\n",
        "            collated_masks_pred.append(masks_p)\n",
        "\n",
        "            acceptable_regions = masks_C\n",
        "            try:\n",
        "                if self.allow_overlap:\n",
        "                    acceptable_regions= None\n",
        "            except Exception as e:\n",
        "                logger.warning(f'Encountered exception in mask-generator {e}')\n",
        "\n",
        "            masks_e = []\n",
        "            for _ in range(self.nenc):\n",
        "                mask, _ = self._sample_block_mask(e_size, acceptable_regions=acceptable_regions)\n",
        "                masks_e.append(mask)\n",
        "                min_keep_enc = min(min_keep_enc, len(mask))\n",
        "            collated_masks_enc.append(masks_e)\n",
        "\n",
        "        collated_masks_pred = [[cm[:min_keep_pred] for cm in cm_list] for cm_list in collated_masks_pred]\n",
        "        collated_masks_pred = torch.utils.data.default_collate(collated_masks_pred)\n",
        "        # --\n",
        "        collated_masks_enc = [[cm[:min_keep_enc] for cm in cm_list] for cm_list in collated_masks_enc]\n",
        "        collated_masks_enc = torch.utils.data.default_collate(collated_masks_enc)\n",
        "\n",
        "        return collated_batch, collated_masks_enc, collated_masks_pred\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XQ7PxBMlsYCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ijepa train.py\n",
        "# https://github.com/facebookresearch/ijepa/blob/main/src/train.py\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import copy\n",
        "import logging\n",
        "import sys\n",
        "import yaml\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.multiprocessing as mp\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "from src.masks.multiblock import MaskCollator as MBMaskCollator\n",
        "from src.masks.utils import apply_masks\n",
        "from src.utils.distributed import (\n",
        "    init_distributed,\n",
        "    AllReduce\n",
        ")\n",
        "from src.utils.logging import (\n",
        "    CSVLogger,\n",
        "    gpu_timer,\n",
        "    grad_logger,\n",
        "    AverageMeter)\n",
        "from src.utils.tensors import repeat_interleave_batch\n",
        "from src.datasets.imagenet1k import make_imagenet1k\n",
        "\n",
        "from src.helper import (\n",
        "    load_checkpoint,\n",
        "    init_model,\n",
        "    init_opt)\n",
        "from src.transforms import make_transforms\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "def main(args, resume_preempt=False):\n",
        "\n",
        "    # ----------------------------------------------------------------------- #\n",
        "    #  PASSED IN PARAMS FROM CONFIG FILE\n",
        "    # ----------------------------------------------------------------------- #\n",
        "\n",
        "    # -- META\n",
        "    use_bfloat16 = args['meta']['use_bfloat16']\n",
        "    model_name = args['meta']['model_name']\n",
        "    load_model = args['meta']['load_checkpoint'] or resume_preempt\n",
        "    r_file = args['meta']['read_checkpoint']\n",
        "    copy_data = args['meta']['copy_data']\n",
        "    pred_depth = args['meta']['pred_depth']\n",
        "    pred_emb_dim = args['meta']['pred_emb_dim']\n",
        "    if not torch.cuda.is_available():\n",
        "        device = torch.device('cpu')\n",
        "    else:\n",
        "        device = torch.device('cuda:0')\n",
        "        torch.cuda.set_device(device)\n",
        "\n",
        "    # -- DATA\n",
        "    use_gaussian_blur = args['data']['use_gaussian_blur']\n",
        "    use_horizontal_flip = args['data']['use_horizontal_flip']\n",
        "    use_color_distortion = args['data']['use_color_distortion']\n",
        "    color_jitter = args['data']['color_jitter_strength']\n",
        "    # --\n",
        "    batch_size = args['data']['batch_size']\n",
        "    pin_mem = args['data']['pin_mem']\n",
        "    num_workers = args['data']['num_workers']\n",
        "    root_path = args['data']['root_path']\n",
        "    image_folder = args['data']['image_folder']\n",
        "    crop_size = args['data']['crop_size']\n",
        "    crop_scale = args['data']['crop_scale']\n",
        "    # --\n",
        "\n",
        "    # -- MASK\n",
        "    allow_overlap = args['mask']['allow_overlap']  # whether to allow overlap b/w context and target blocks\n",
        "    patch_size = args['mask']['patch_size']  # patch-size for model training\n",
        "    num_enc_masks = args['mask']['num_enc_masks']  # number of context blocks\n",
        "    min_keep = args['mask']['min_keep']  # min number of patches in context block\n",
        "    enc_mask_scale = args['mask']['enc_mask_scale']  # scale of context blocks\n",
        "    num_pred_masks = args['mask']['num_pred_masks']  # number of target blocks\n",
        "    pred_mask_scale = args['mask']['pred_mask_scale']  # scale of target blocks\n",
        "    aspect_ratio = args['mask']['aspect_ratio']  # aspect ratio of target blocks\n",
        "    # --\n",
        "\n",
        "    # -- OPTIMIZATION\n",
        "    ema = args['optimization']['ema']\n",
        "    ipe_scale = args['optimization']['ipe_scale']  # scheduler scale factor (def: 1.0)\n",
        "    wd = float(args['optimization']['weight_decay'])\n",
        "    final_wd = float(args['optimization']['final_weight_decay'])\n",
        "    num_epochs = args['optimization']['epochs']\n",
        "    warmup = args['optimization']['warmup']\n",
        "    start_lr = args['optimization']['start_lr']\n",
        "    lr = args['optimization']['lr']\n",
        "    final_lr = args['optimization']['final_lr']\n",
        "\n",
        "    # -- LOGGING\n",
        "    folder = args['logging']['folder']\n",
        "    tag = args['logging']['write_tag']\n",
        "\n",
        "    dump = os.path.join(folder, 'params-ijepa.yaml')\n",
        "    with open(dump, 'w') as f:\n",
        "        yaml.dump(args, f)\n",
        "    # ----------------------------------------------------------------------- #\n",
        "\n",
        "    try:\n",
        "        mp.set_start_method('spawn')\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # -- init torch distributed backend\n",
        "    world_size, rank = init_distributed()\n",
        "    logger.info(f'Initialized (rank/world-size) {rank}/{world_size}')\n",
        "    if rank > 0:\n",
        "        logger.setLevel(logging.ERROR)\n",
        "\n",
        "    # -- log/checkpointing paths\n",
        "    log_file = os.path.join(folder, f'{tag}_r{rank}.csv')\n",
        "    save_path = os.path.join(folder, f'{tag}' + '-ep{epoch}.pth.tar')\n",
        "    latest_path = os.path.join(folder, f'{tag}-latest.pth.tar')\n",
        "    load_path = None\n",
        "    if load_model:\n",
        "        load_path = os.path.join(folder, r_file) if r_file is not None else latest_path\n",
        "\n",
        "    # -- make csv_logger\n",
        "    csv_logger = CSVLogger(log_file,\n",
        "                           ('%d', 'epoch'),\n",
        "                           ('%d', 'itr'),\n",
        "                           ('%.5f', 'loss'),\n",
        "                           ('%.5f', 'mask-A'),\n",
        "                           ('%.5f', 'mask-B'),\n",
        "                           ('%d', 'time (ms)'))\n",
        "\n",
        "    # -- init model\n",
        "    encoder, predictor = init_model(\n",
        "        device=device,\n",
        "        patch_size=patch_size,\n",
        "        crop_size=crop_size,\n",
        "        pred_depth=pred_depth,\n",
        "        pred_emb_dim=pred_emb_dim,\n",
        "        model_name=model_name)\n",
        "    target_encoder = copy.deepcopy(encoder)\n",
        "\n",
        "    # -- make data transforms\n",
        "    mask_collator = MBMaskCollator(\n",
        "        input_size=crop_size,\n",
        "        patch_size=patch_size,\n",
        "        pred_mask_scale=pred_mask_scale,\n",
        "        enc_mask_scale=enc_mask_scale,\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        nenc=num_enc_masks,\n",
        "        npred=num_pred_masks,\n",
        "        allow_overlap=allow_overlap,\n",
        "        min_keep=min_keep)\n",
        "\n",
        "    transform = make_transforms(\n",
        "        crop_size=crop_size,\n",
        "        crop_scale=crop_scale,\n",
        "        gaussian_blur=use_gaussian_blur,\n",
        "        horizontal_flip=use_horizontal_flip,\n",
        "        color_distortion=use_color_distortion,\n",
        "        color_jitter=color_jitter)\n",
        "\n",
        "    # -- init data-loaders/samplers\n",
        "    _, unsupervised_loader, unsupervised_sampler = make_imagenet1k(\n",
        "            transform=transform,\n",
        "            batch_size=batch_size,\n",
        "            collator=mask_collator,\n",
        "            pin_mem=pin_mem,\n",
        "            training=True,\n",
        "            num_workers=num_workers,\n",
        "            world_size=world_size,\n",
        "            rank=rank,\n",
        "            root_path=root_path,\n",
        "            image_folder=image_folder,\n",
        "            copy_data=copy_data,\n",
        "            drop_last=True)\n",
        "    ipe = len(unsupervised_loader)\n",
        "\n",
        "    # -- init optimizer and scheduler\n",
        "    optimizer, scaler, scheduler, wd_scheduler = init_opt(\n",
        "        encoder=encoder,\n",
        "        predictor=predictor,\n",
        "        wd=wd,\n",
        "        final_wd=final_wd,\n",
        "        start_lr=start_lr,\n",
        "        ref_lr=lr,\n",
        "        final_lr=final_lr,\n",
        "        iterations_per_epoch=ipe,\n",
        "        warmup=warmup,\n",
        "        num_epochs=num_epochs,\n",
        "        ipe_scale=ipe_scale,\n",
        "        use_bfloat16=use_bfloat16)\n",
        "    encoder = DistributedDataParallel(encoder, static_graph=True)\n",
        "    predictor = DistributedDataParallel(predictor, static_graph=True)\n",
        "    target_encoder = DistributedDataParallel(target_encoder)\n",
        "    for p in target_encoder.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # -- momentum schedule\n",
        "    momentum_scheduler = (ema[0] + i*(ema[1]-ema[0])/(ipe*num_epochs*ipe_scale)\n",
        "                          for i in range(int(ipe*num_epochs*ipe_scale)+1))\n",
        "\n",
        "    start_epoch = 0\n",
        "    # -- load training checkpoint\n",
        "    if load_model:\n",
        "        encoder, predictor, target_encoder, optimizer, scaler, start_epoch = load_checkpoint(\n",
        "            device=device,\n",
        "            r_path=load_path,\n",
        "            encoder=encoder,\n",
        "            predictor=predictor,\n",
        "            target_encoder=target_encoder,\n",
        "            opt=optimizer,\n",
        "            scaler=scaler)\n",
        "        for _ in range(start_epoch*ipe):\n",
        "            scheduler.step()\n",
        "            wd_scheduler.step()\n",
        "            next(momentum_scheduler)\n",
        "            mask_collator.step()\n",
        "\n",
        "    def save_checkpoint(epoch):\n",
        "        save_dict = {\n",
        "            'encoder': encoder.state_dict(),\n",
        "            'predictor': predictor.state_dict(),\n",
        "            'target_encoder': target_encoder.state_dict(),\n",
        "            'opt': optimizer.state_dict(),\n",
        "            'scaler': None if scaler is None else scaler.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'loss': loss_meter.avg,\n",
        "            'batch_size': batch_size,\n",
        "            'world_size': world_size,\n",
        "            'lr': lr\n",
        "        }\n",
        "        if rank == 0:\n",
        "            torch.save(save_dict, latest_path)\n",
        "            if (epoch + 1) % checkpoint_freq == 0:\n",
        "                torch.save(save_dict, save_path.format(epoch=f'{epoch + 1}'))\n",
        "\n",
        "    # -- TRAINING LOOP\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        logger.info('Epoch %d' % (epoch + 1))\n",
        "\n",
        "        # -- update distributed-data-loader epoch\n",
        "        unsupervised_sampler.set_epoch(epoch)\n",
        "\n",
        "        loss_meter = AverageMeter()\n",
        "        maskA_meter = AverageMeter()\n",
        "        maskB_meter = AverageMeter()\n",
        "        time_meter = AverageMeter()\n",
        "\n",
        "        for itr, (udata, masks_enc, masks_pred) in enumerate(unsupervised_loader):\n",
        "\n",
        "            def load_imgs():\n",
        "                # -- unsupervised imgs\n",
        "                imgs = udata[0].to(device, non_blocking=True)\n",
        "                masks_1 = [u.to(device, non_blocking=True) for u in masks_enc]\n",
        "                masks_2 = [u.to(device, non_blocking=True) for u in masks_pred]\n",
        "                return (imgs, masks_1, masks_2)\n",
        "            imgs, masks_enc, masks_pred = load_imgs()\n",
        "            maskA_meter.update(len(masks_enc[0][0]))\n",
        "            maskB_meter.update(len(masks_pred[0][0]))\n",
        "\n",
        "            def train_step():\n",
        "                _new_lr = scheduler.step()\n",
        "                _new_wd = wd_scheduler.step()\n",
        "                # --\n",
        "\n",
        "                def forward_target():\n",
        "                    with torch.no_grad():\n",
        "                        h = target_encoder(imgs)\n",
        "                        h = F.layer_norm(h, (h.size(-1),))  # normalize over feature-dim\n",
        "                        B = len(h)\n",
        "                        # -- create targets (masked regions of h)\n",
        "                        h = apply_masks(h, masks_pred)\n",
        "                        h = repeat_interleave_batch(h, B, repeat=len(masks_enc))\n",
        "                        return h\n",
        "\n",
        "                def forward_context():\n",
        "                    z = encoder(imgs, masks_enc)\n",
        "                    z = predictor(z, masks_enc, masks_pred)\n",
        "                    return z\n",
        "\n",
        "                def loss_fn(z, h):\n",
        "                    loss = F.smooth_l1_loss(z, h)\n",
        "                    loss = AllReduce.apply(loss)\n",
        "                    return loss\n",
        "\n",
        "                # Step 1. Forward\n",
        "                with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=use_bfloat16):\n",
        "                    h = forward_target()\n",
        "                    z = forward_context()\n",
        "                    loss = loss_fn(z, h)\n",
        "\n",
        "                #  Step 2. Backward & step\n",
        "                if use_bfloat16:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                grad_stats = grad_logger(encoder.named_parameters())\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Step 3. momentum update of target encoder\n",
        "                with torch.no_grad():\n",
        "                    m = next(momentum_scheduler)\n",
        "                    for param_q, param_k in zip(encoder.parameters(), target_encoder.parameters()):\n",
        "                        param_k.data.mul_(m).add_((1.-m) * param_q.detach().data)\n",
        "\n",
        "                return (float(loss), _new_lr, _new_wd, grad_stats)\n",
        "            (loss, _new_lr, _new_wd, grad_stats), etime = gpu_timer(train_step)\n",
        "            loss_meter.update(loss)\n",
        "            time_meter.update(etime)\n",
        "\n",
        "            # -- Logging\n",
        "            def log_stats():\n",
        "                csv_logger.log(epoch + 1, itr, loss, maskA_meter.val, maskB_meter.val, etime)\n",
        "                if (itr % log_freq == 0) or np.isnan(loss) or np.isinf(loss):\n",
        "                    logger.info('[%d, %5d] loss: %.3f '\n",
        "                                'masks: %.1f %.1f '\n",
        "                                '[wd: %.2e] [lr: %.2e] '\n",
        "                                '[mem: %.2e] '\n",
        "                                '(%.1f ms)'\n",
        "                                % (epoch + 1, itr,\n",
        "                                   loss_meter.avg,\n",
        "                                   maskA_meter.avg,\n",
        "                                   maskB_meter.avg,\n",
        "                                   _new_wd,\n",
        "                                   _new_lr,\n",
        "                                   torch.cuda.max_memory_allocated() / 1024.**2,\n",
        "                                   time_meter.avg))\n",
        "\n",
        "                    if grad_stats is not None:\n",
        "                        logger.info('[%d, %5d] grad_stats: [%.2e %.2e] (%.2e, %.2e)'\n",
        "                                    % (epoch + 1, itr,\n",
        "                                       grad_stats.first_layer,\n",
        "                                       grad_stats.last_layer,\n",
        "                                       grad_stats.min,\n",
        "                                       grad_stats.max))\n",
        "\n",
        "            log_stats()\n",
        "\n",
        "            assert not np.isnan(loss), 'loss is nan'\n",
        "\n",
        "        # -- Save Checkpoint after every epoch\n",
        "        logger.info('avg. loss %.3f' % loss_meter.avg)\n",
        "        save_checkpoint(epoch+1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iVUPGP93dpAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}